Map (num_proc=32):   0%|          | 0/33590720 [00:00<?, ? examples/s]Map (num_proc=32):   0%|          | 3000/33590720 [00:04<13:45:11, 678.38 examples/s]Map (num_proc=32):   0%|          | 7000/33590720 [00:04<4:53:18, 1908.34 examples/s]Map (num_proc=32):   0%|          | 35000/33590720 [00:04<41:22, 13516.88 examples/s]Map (num_proc=32):   0%|          | 47000/33590720 [00:04<29:28, 18968.16 examples/s]Map (num_proc=32):   0%|          | 59000/33590720 [00:04<22:04, 25320.49 examples/s]Map (num_proc=32):   0%|          | 71000/33590720 [00:05<17:14, 32413.27 examples/s]Map (num_proc=32):   0%|          | 83000/33590720 [00:05<14:01, 39803.77 examples/s]Map (num_proc=32):   0%|          | 95000/33590720 [00:05<11:51, 47064.97 examples/s]Map (num_proc=32):   0%|          | 107000/33590720 [00:05<10:23, 53739.51 examples/s]Map (num_proc=32):   0%|          | 119000/33590720 [00:05<09:25, 59152.40 examples/s]Map (num_proc=32):   0%|          | 127000/33590720 [00:05<08:52, 62807.79 examples/s]Map (num_proc=32):   0%|          | 135000/33590720 [00:05<08:25, 66174.73 examples/s]Map (num_proc=32):   0%|          | 143000/33590720 [00:06<08:03, 69135.55 examples/s]Map (num_proc=32):   0%|          | 151000/33590720 [00:06<15:29, 35971.63 examples/s]Map (num_proc=32):   0%|          | 159000/33590720 [00:07<25:40, 21707.15 examples/s]Map (num_proc=32):   0%|          | 167000/33590720 [00:07<24:11, 23024.03 examples/s]Map (num_proc=32):   1%|          | 309000/33590720 [00:07<03:23, 163407.08 examples/s]Map (num_proc=32):   1%|          | 345000/33590720 [00:07<03:19, 166333.40 examples/s]Map (num_proc=32):   1%|          | 377000/33590720 [00:08<03:22, 163759.17 examples/s]Map (num_proc=32):   1%|          | 405000/33590720 [00:08<03:29, 158761.99 examples/s]Map (num_proc=32):   1%|▏         | 429000/33590720 [00:08<03:28, 158836.32 examples/s]Map (num_proc=32):   1%|▏         | 453000/33590720 [00:08<03:28, 158809.25 examples/s]Map (num_proc=32):   1%|▏         | 473000/33590720 [00:08<03:22, 163310.81 examples/s]Map (num_proc=32):   1%|▏         | 493000/33590720 [00:08<03:30, 157181.82 examples/s]Map (num_proc=32):   2%|▏         | 513000/33590720 [00:09<03:25, 160607.96 examples/s]Map (num_proc=32):   2%|▏         | 533000/33590720 [00:09<03:30, 157111.69 examples/s]Map (num_proc=32):   2%|▏         | 553000/33590720 [00:10<12:07, 45431.71 examples/s] Map (num_proc=32):   2%|▏         | 569000/33590720 [00:10<11:30, 47819.16 examples/s]Map (num_proc=32):   2%|▏         | 825000/33590720 [00:10<01:56, 280097.39 examples/s]Map (num_proc=32):   3%|▎         | 910000/33590720 [00:11<02:02, 267394.88 examples/s]Map (num_proc=32):   3%|▎         | 978000/33590720 [00:11<02:05, 259674.95 examples/s]Map (num_proc=32):   3%|▎         | 1030000/33590720 [00:11<02:08, 254240.19 examples/s]Map (num_proc=32):   3%|▎         | 1074000/33590720 [00:11<02:09, 251003.12 examples/s]Map (num_proc=32):   3%|▎         | 1114000/33590720 [00:12<02:11, 246664.49 examples/s]Map (num_proc=32):   3%|▎         | 1150000/33590720 [00:12<02:12, 244291.87 examples/s]Map (num_proc=32):   4%|▎         | 1182000/33590720 [00:12<03:50, 140560.88 examples/s]Map (num_proc=32):   4%|▎         | 1206000/33590720 [00:13<07:32, 71626.10 examples/s] Map (num_proc=32):   5%|▍         | 1594000/33590720 [00:13<01:31, 350462.08 examples/s]Map (num_proc=32):   5%|▌         | 1726000/33590720 [00:14<01:34, 335648.17 examples/s]Map (num_proc=32):   5%|▌         | 1826000/33590720 [00:14<01:35, 332579.31 examples/s]Map (num_proc=32):   6%|▌         | 1906000/33590720 [00:14<01:36, 328360.11 examples/s]Map (num_proc=32):   6%|▌         | 1974000/33590720 [00:15<01:36, 327182.20 examples/s]Map (num_proc=32):   6%|▌         | 2030000/33590720 [00:15<01:39, 317971.53 examples/s]Map (num_proc=32):   6%|▌         | 2078000/33590720 [00:16<04:06, 127912.72 examples/s]Map (num_proc=32):   6%|▋         | 2115000/33590720 [00:16<04:07, 127153.48 examples/s]Map (num_proc=32):   8%|▊         | 2585000/33590720 [00:17<01:03, 487352.63 examples/s]Map (num_proc=32):   8%|▊         | 2747000/33590720 [00:17<01:07, 459234.59 examples/s]Map (num_proc=32):   9%|▊         | 2873710/33590720 [00:17<01:11, 430524.54 examples/s]Map (num_proc=32):   9%|▉         | 2973710/33590720 [00:18<01:15, 403844.74 examples/s]Map (num_proc=32):   9%|▉         | 3053710/33590720 [00:18<01:20, 381594.74 examples/s]Map (num_proc=32):   9%|▉         | 3117710/33590720 [00:19<02:33, 198270.55 examples/s]Map (num_proc=32):   9%|▉         | 3167710/33590720 [00:20<03:19, 152661.51 examples/s]Map (num_proc=32):  10%|▉         | 3204710/33590720 [00:21<05:23, 93852.74 examples/s] Map (num_proc=32):  12%|█▏        | 4020420/33590720 [00:21<00:58, 508978.76 examples/s]Map (num_proc=32):  13%|█▎        | 4272420/33590720 [00:23<01:42, 286813.77 examples/s]Map (num_proc=32):  13%|█▎        | 4452420/33590720 [00:24<02:01, 239966.98 examples/s]Map (num_proc=32):  15%|█▌        | 5044130/33590720 [00:24<01:02, 456577.15 examples/s]Map (num_proc=32):  16%|█▌        | 5271130/33590720 [00:28<02:21, 200537.67 examples/s]Map (num_proc=32):  18%|█▊        | 6145840/33590720 [00:28<01:04, 426571.38 examples/s]Map (num_proc=32):  19%|█▉        | 6512840/33590720 [00:31<01:42, 264885.34 examples/s]Map (num_proc=32):  21%|██        | 7106550/33590720 [00:31<01:05, 403606.91 examples/s]Map (num_proc=32):  22%|██▏       | 7449550/33590720 [00:34<01:44, 250649.11 examples/s]Map (num_proc=32):  24%|██▍       | 8118260/33590720 [00:34<01:03, 401559.84 examples/s]Map (num_proc=32):  25%|██▌       | 8490260/33590720 [00:37<01:36, 259088.18 examples/s]Map (num_proc=32):  27%|██▋       | 9150260/33590720 [00:37<01:00, 403791.90 examples/s]Map (num_proc=32):  28%|██▊       | 9508970/33590720 [00:39<01:15, 317213.67 examples/s]Map (num_proc=32):  29%|██▉       | 9765970/33590720 [00:40<01:20, 297175.07 examples/s]Map (num_proc=32):  30%|███       | 10219970/33590720 [00:40<00:55, 424217.22 examples/s]Map (num_proc=32):  31%|███       | 10484680/33590720 [00:42<01:18, 292885.24 examples/s]Map (num_proc=32):  32%|███▏      | 10672680/33590720 [00:43<01:27, 260531.06 examples/s]Map (num_proc=32):  34%|███▎      | 11273680/33590720 [00:44<00:49, 450784.86 examples/s]Map (num_proc=32):  34%|███▍      | 11515390/33590720 [00:46<01:15, 291898.27 examples/s]Map (num_proc=32):  35%|███▍      | 11688390/33590720 [00:47<01:27, 249314.66 examples/s]Map (num_proc=32):  37%|███▋      | 12369390/33590720 [00:47<00:45, 469394.48 examples/s]Map (num_proc=32):  38%|███▊      | 12613100/33590720 [00:49<01:15, 278414.31 examples/s]Map (num_proc=32):  38%|███▊      | 12790100/33590720 [00:50<01:25, 242337.46 examples/s]Map (num_proc=32):  40%|████      | 13517810/33590720 [00:50<00:42, 467824.97 examples/s]Map (num_proc=32):  41%|████      | 13778810/33590720 [00:54<01:22, 241488.44 examples/s]Map (num_proc=32):  43%|████▎     | 14549520/33590720 [00:54<00:43, 435649.35 examples/s]Map (num_proc=32):  44%|████▍     | 14865520/33590720 [00:57<01:13, 255737.13 examples/s]Map (num_proc=32):  46%|████▋     | 15553230/33590720 [00:57<00:43, 415069.99 examples/s]Map (num_proc=32):  47%|████▋     | 15912230/33590720 [01:00<01:07, 260953.92 examples/s]Map (num_proc=32):  49%|████▉     | 16544940/33590720 [01:00<00:42, 400150.15 examples/s]Map (num_proc=32):  50%|█████     | 16881940/33590720 [01:02<00:56, 293606.66 examples/s]Map (num_proc=32):  51%|█████▏    | 17278940/33590720 [01:02<00:41, 390462.45 examples/s]Map (num_proc=32):  52%|█████▏    | 17562940/33590720 [01:03<00:40, 391263.69 examples/s]Map (num_proc=32):  53%|█████▎    | 17775650/33590720 [01:05<01:01, 256314.61 examples/s]Map (num_proc=32):  54%|█████▎    | 17997650/33590720 [01:06<01:05, 238454.18 examples/s]Map (num_proc=32):  56%|█████▌    | 18662360/33590720 [01:07<00:33, 444288.13 examples/s]Map (num_proc=32):  56%|█████▋    | 18918360/33590720 [01:10<01:05, 222828.11 examples/s]Map (num_proc=32):  59%|█████▉    | 19769070/33590720 [01:10<00:31, 432585.15 examples/s]Map (num_proc=32):  60%|█████▉    | 20133070/33590720 [01:13<00:50, 266056.77 examples/s]Map (num_proc=32):  62%|██████▏   | 20773780/33590720 [01:13<00:31, 411130.37 examples/s]Map (num_proc=32):  63%|██████▎   | 21124780/33590720 [01:17<00:51, 240534.61 examples/s]Map (num_proc=32):  65%|██████▌   | 21913490/33590720 [01:17<00:28, 403980.35 examples/s]Map (num_proc=32):  66%|██████▋   | 22301490/33590720 [01:21<00:45, 245585.30 examples/s]Map (num_proc=32):  68%|██████▊   | 22975200/33590720 [01:23<00:40, 262541.34 examples/s]Map (num_proc=32):  71%|███████   | 23727200/33590720 [01:23<00:24, 404980.63 examples/s]Map (num_proc=32):  72%|███████▏  | 24083910/33590720 [01:24<00:24, 386802.92 examples/s]Map (num_proc=32):  72%|███████▏  | 24343910/33590720 [01:26<00:35, 263395.09 examples/s]Map (num_proc=32):  74%|███████▍  | 24883620/33590720 [01:27<00:22, 387165.24 examples/s]Map (num_proc=32):  75%|███████▍  | 25168620/33590720 [01:29<00:33, 255209.41 examples/s]Map (num_proc=32):  77%|███████▋  | 25734620/33590720 [01:29<00:20, 390125.77 examples/s]Map (num_proc=32):  77%|███████▋  | 26023330/33590720 [01:30<00:20, 376615.51 examples/s]Map (num_proc=32):  78%|███████▊  | 26236330/33590720 [01:34<00:37, 193605.06 examples/s]Map (num_proc=32):  81%|████████  | 27205040/33590720 [01:34<00:15, 410911.20 examples/s]Map (num_proc=32):  82%|████████▏ | 27574040/33590720 [01:37<00:23, 260988.95 examples/s]Map (num_proc=32):  84%|████████▍ | 28208750/33590720 [01:37<00:13, 397252.36 examples/s]Map (num_proc=32):  85%|████████▌ | 28575750/33590720 [01:39<00:16, 296123.36 examples/s]Map (num_proc=32):  86%|████████▌ | 28967750/33590720 [01:39<00:11, 388490.66 examples/s]Map (num_proc=32):  87%|████████▋ | 29260460/33590720 [01:40<00:11, 370703.28 examples/s]Map (num_proc=32):  88%|████████▊ | 29476460/33590720 [01:43<00:16, 244570.29 examples/s]Map (num_proc=32):  89%|████████▉ | 29982170/33590720 [01:43<00:09, 380922.57 examples/s]Map (num_proc=32):  90%|████████▉ | 30202170/33590720 [01:43<00:09, 368722.51 examples/s]Map (num_proc=32):  90%|█████████ | 30369170/33590720 [01:45<00:11, 270164.23 examples/s]Map (num_proc=32):  91%|█████████ | 30626170/33590720 [01:45<00:08, 357775.85 examples/s]Map (num_proc=32):  92%|█████████▏| 30784170/33590720 [01:45<00:07, 361385.85 examples/s]Map (num_proc=32):  92%|█████████▏| 30908170/33590720 [01:46<00:07, 365172.66 examples/s]Map (num_proc=32):  92%|█████████▏| 31008170/33590720 [01:46<00:06, 370112.41 examples/s]Map (num_proc=32):  93%|█████████▎| 31088170/33590720 [01:46<00:06, 373968.03 examples/s]Map (num_proc=32):  93%|█████████▎| 31156170/33590720 [01:46<00:06, 377281.08 examples/s]Map (num_proc=32):  93%|█████████▎| 31216170/33590720 [01:46<00:06, 380176.75 examples/s]Map (num_proc=32):  93%|█████████▎| 31271880/33590720 [01:47<00:06, 379176.91 examples/s]Map (num_proc=32):  93%|█████████▎| 31323880/33590720 [01:47<00:06, 369141.36 examples/s]Map (num_proc=32):  93%|█████████▎| 31367880/33590720 [01:47<00:06, 352473.33 examples/s]Map (num_proc=32):  94%|█████████▎| 31407880/33590720 [01:47<00:06, 341846.18 examples/s]Map (num_proc=32):  94%|█████████▎| 31447880/33590720 [01:47<00:06, 338470.32 examples/s]Map (num_proc=32):  94%|█████████▎| 31483880/33590720 [01:47<00:06, 338759.06 examples/s]Map (num_proc=32):  94%|█████████▍| 31519880/33590720 [01:47<00:06, 323580.40 examples/s]Map (num_proc=32):  94%|█████████▍| 31555880/33590720 [01:48<00:06, 329633.36 examples/s]Map (num_proc=32):  94%|█████████▍| 31591880/33590720 [01:49<00:22, 89432.07 examples/s] Map (num_proc=32):  95%|█████████▌| 31917880/33590720 [01:49<00:04, 362591.27 examples/s]Map (num_proc=32):  95%|█████████▌| 32025880/33590720 [01:49<00:04, 355119.75 examples/s]Map (num_proc=32):  96%|█████████▌| 32113880/33590720 [01:49<00:04, 340664.18 examples/s]Map (num_proc=32):  96%|█████████▌| 32186590/33590720 [01:50<00:04, 324345.19 examples/s]Map (num_proc=32):  96%|█████████▌| 32246590/33590720 [01:50<00:04, 301723.74 examples/s]Map (num_proc=32):  96%|█████████▌| 32294590/33590720 [01:50<00:04, 287105.80 examples/s]Map (num_proc=32):  96%|█████████▋| 32334590/33590720 [01:50<00:04, 280755.50 examples/s]Map (num_proc=32):  96%|█████████▋| 32370590/33590720 [01:50<00:04, 270224.07 examples/s]Map (num_proc=32):  96%|█████████▋| 32404590/33590720 [01:52<00:12, 95893.22 examples/s] Map (num_proc=32):  97%|█████████▋| 32656590/33590720 [01:52<00:03, 279936.48 examples/s]Map (num_proc=32):  97%|█████████▋| 32744590/33590720 [01:52<00:03, 263569.96 examples/s]Map (num_proc=32):  98%|█████████▊| 32812590/33590720 [01:52<00:02, 261183.11 examples/s]Map (num_proc=32):  98%|█████████▊| 32868590/33590720 [01:53<00:02, 255707.24 examples/s]Map (num_proc=32):  98%|█████████▊| 32914300/33590720 [01:53<00:02, 236504.63 examples/s]Map (num_proc=32):  98%|█████████▊| 32954300/33590720 [01:53<00:02, 215821.42 examples/s]Map (num_proc=32):  98%|█████████▊| 32986300/33590720 [01:53<00:02, 202284.93 examples/s]Map (num_proc=32):  98%|█████████▊| 33014300/33590720 [01:54<00:02, 193816.01 examples/s]Map (num_proc=32):  98%|█████████▊| 33038300/33590720 [01:54<00:03, 179007.49 examples/s]Map (num_proc=32):  98%|█████████▊| 33060300/33590720 [01:55<00:07, 69030.80 examples/s] Map (num_proc=32):  99%|█████████▉| 33212300/33590720 [01:55<00:02, 183719.11 examples/s]Map (num_proc=32):  99%|█████████▉| 33264300/33590720 [01:55<00:01, 178420.50 examples/s]Map (num_proc=32):  99%|█████████▉| 33308300/33590720 [01:56<00:01, 171512.58 examples/s]Map (num_proc=32):  99%|█████████▉| 33344300/33590720 [01:56<00:01, 170438.63 examples/s]Map (num_proc=32):  99%|█████████▉| 33373010/33590720 [01:56<00:01, 149237.94 examples/s]Map (num_proc=32):  99%|█████████▉| 33397010/33590720 [01:56<00:01, 127876.40 examples/s]Map (num_proc=32):  99%|█████████▉| 33417010/33590720 [01:57<00:01, 114753.20 examples/s]Map (num_proc=32): 100%|█████████▉| 33433010/33590720 [01:57<00:01, 104731.53 examples/s]Map (num_proc=32): 100%|█████████▉| 33449010/33590720 [01:58<00:03, 46696.60 examples/s] Map (num_proc=32): 100%|█████████▉| 33518010/33590720 [01:58<00:00, 94647.30 examples/s]Map (num_proc=32): 100%|█████████▉| 33546010/33590720 [01:58<00:00, 90330.91 examples/s]Map (num_proc=32): 100%|█████████▉| 33566010/33590720 [01:59<00:00, 87825.17 examples/s]Map (num_proc=32): 100%|█████████▉| 33586010/33590720 [01:59<00:00, 85664.81 examples/s]Map (num_proc=32): 100%|██████████| 33590720/33590720 [02:01<00:00, 275422.18 examples/s]
Map (num_proc=32):   0%|          | 0/27000 [00:00<?, ? examples/s]Map (num_proc=32):   3%|▎         | 844/27000 [00:00<00:05, 4359.42 examples/s]Map (num_proc=32):  47%|████▋     | 12660/27000 [00:00<00:00, 50782.24 examples/s]Map (num_proc=32):  97%|█████████▋| 26157/27000 [00:00<00:00, 80636.85 examples/s]Map (num_proc=32): 100%|██████████| 27000/27000 [00:00<00:00, 40482.52 examples/s]
wandb: Currently logged in as: os415. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /rds/user/os415/hpc-work/tspGPT/wandb/run-20240515_163601-m4hyuhdf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast
wandb: ⭐️ View project at https://wandb.ai/os415/Final-countdown
wandb: 🚀 View run at https://wandb.ai/os415/Final-countdown/runs/m4hyuhdf
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Using auto half precision backend
***** Running training *****
  Num examples = 33,590,720
  Num Epochs = 25
  Instantaneous batch size per device = 65,536
  Total train batch size (w. parallel, distributed & accumulation) = 65,536
  Gradient Accumulation steps = 1
  Total optimization steps = 12,825
  Number of trainable parameters = 926,080
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/12825 [00:00<?, ?it/s]  0%|          | 1/12825 [00:27<98:31:10, 27.66s/it]  0%|          | 2/12825 [00:40<67:20:49, 18.91s/it]  0%|          | 3/12825 [00:53<57:16:20, 16.08s/it]  0%|          | 4/12825 [01:05<52:37:10, 14.78s/it]  0%|          | 5/12825 [01:18<50:00:17, 14.04s/it]  0%|          | 6/12825 [01:31<48:27:59, 13.61s/it]  0%|          | 7/12825 [01:44<47:27:51, 13.33s/it]  0%|          | 8/12825 [01:56<46:48:02, 13.15s/it]  0%|          | 9/12825 [02:09<46:22:09, 13.03s/it]  0%|          | 10/12825 [02:22<46:05:23, 12.95s/it]  0%|          | 11/12825 [02:35<45:53:10, 12.89s/it]  0%|          | 12/12825 [02:48<45:46:45, 12.86s/it]  0%|          | 13/12825 [03:00<45:37:54, 12.82s/it]  0%|          | 14/12825 [03:13<45:33:35, 12.80s/it]  0%|          | 15/12825 [03:26<45:33:37, 12.80s/it]  0%|          | 16/12825 [03:39<45:32:52, 12.80s/it]  0%|          | 17/12825 [03:51<45:31:49, 12.80s/it]  0%|          | 18/12825 [04:04<45:27:47, 12.78s/it]  0%|          | 19/12825 [04:17<45:27:07, 12.78s/it]  0%|          | 20/12825 [04:30<45:25:21, 12.77s/it]  0%|          | 21/12825 [04:42<45:22:17, 12.76s/it]  0%|          | 22/12825 [04:56<45:56:59, 12.92s/it]  0%|          | 23/12825 [05:09<45:49:48, 12.89s/it]  0%|          | 24/12825 [05:21<45:42:27, 12.85s/it]  0%|          | 25/12825 [05:34<45:37:32, 12.83s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 45466.49lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 35112.52lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-25
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-25/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-25/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-25/pytorch_model.bin
  0%|          | 26/12825 [05:48<46:30:32, 13.08s/it]  0%|          | 27/12825 [06:00<46:07:58, 12.98s/it]  0%|          | 28/12825 [06:13<45:52:32, 12.91s/it]  0%|          | 29/12825 [06:26<45:43:30, 12.86s/it]  0%|          | 30/12825 [06:39<45:34:28, 12.82s/it]  0%|          | 31/12825 [06:59<53:42:02, 15.11s/it]  0%|          | 32/12825 [07:12<51:08:56, 14.39s/it]  0%|          | 33/12825 [07:25<49:22:02, 13.89s/it]  0%|          | 34/12825 [07:37<48:07:15, 13.54s/it]  0%|          | 35/12825 [07:50<47:16:51, 13.31s/it]  0%|          | 36/12825 [08:03<46:38:49, 13.13s/it]  0%|          | 37/12825 [08:16<46:13:13, 13.01s/it]  0%|          | 38/12825 [08:28<45:54:23, 12.92s/it]  0%|          | 39/12825 [08:41<45:42:45, 12.87s/it]  0%|          | 40/12825 [08:54<45:33:54, 12.83s/it]  0%|          | 41/12825 [09:06<45:27:15, 12.80s/it]  0%|          | 42/12825 [09:19<45:25:04, 12.79s/it]  0%|          | 43/12825 [09:32<45:22:07, 12.78s/it]  0%|          | 44/12825 [09:45<45:20:19, 12.77s/it]  0%|          | 45/12825 [09:58<45:21:21, 12.78s/it]  0%|          | 46/12825 [10:10<45:17:40, 12.76s/it]  0%|          | 47/12825 [10:23<45:14:23, 12.75s/it]  0%|          | 48/12825 [10:36<45:12:59, 12.74s/it]  0%|          | 49/12825 [10:48<45:14:41, 12.75s/it]  0%|          | 50/12825 [11:01<45:14:27, 12.75s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120396.05lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103614.32lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-50
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-50/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-50/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-50/pytorch_model.bin
  0%|          | 51/12825 [11:14<45:31:11, 12.83s/it]  0%|          | 52/12825 [11:27<45:14:34, 12.75s/it]  0%|          | 53/12825 [11:39<45:03:20, 12.70s/it]  0%|          | 54/12825 [11:52<44:54:37, 12.66s/it]  0%|          | 55/12825 [12:05<44:50:19, 12.64s/it]  0%|          | 56/12825 [12:17<44:47:59, 12.63s/it]  0%|          | 57/12825 [12:30<44:46:11, 12.62s/it]  0%|          | 58/12825 [12:42<44:44:36, 12.62s/it]  0%|          | 59/12825 [12:55<44:46:14, 12.63s/it]  0%|          | 60/12825 [13:08<44:48:08, 12.64s/it]  0%|          | 61/12825 [13:20<44:46:02, 12.63s/it]  0%|          | 62/12825 [13:33<44:41:19, 12.61s/it]  0%|          | 63/12825 [13:45<44:42:16, 12.61s/it]  0%|          | 64/12825 [14:06<52:38:40, 14.85s/it]  1%|          | 65/12825 [14:18<50:13:19, 14.17s/it]  1%|          | 66/12825 [14:31<48:31:43, 13.69s/it]  1%|          | 67/12825 [14:43<47:22:13, 13.37s/it]  1%|          | 68/12825 [14:56<46:31:52, 13.13s/it]  1%|          | 69/12825 [15:08<45:58:21, 12.97s/it]  1%|          | 70/12825 [15:21<45:32:54, 12.86s/it]  1%|          | 71/12825 [15:34<45:16:12, 12.78s/it]  1%|          | 72/12825 [15:46<45:04:50, 12.73s/it]  1%|          | 73/12825 [15:59<44:58:40, 12.70s/it]  1%|          | 74/12825 [16:11<44:50:12, 12.66s/it]  1%|          | 75/12825 [16:24<44:47:16, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120405.90lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103603.04lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-75
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-75/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-75/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-75/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-50] due to args.save_total_limit
  1%|          | 76/12825 [16:37<45:09:49, 12.75s/it]  1%|          | 77/12825 [16:50<45:03:15, 12.72s/it]  1%|          | 78/12825 [17:02<44:54:22, 12.68s/it]  1%|          | 79/12825 [17:15<44:49:20, 12.66s/it]  1%|          | 80/12825 [17:28<44:45:33, 12.64s/it]  1%|          | 81/12825 [17:40<44:42:43, 12.63s/it]  1%|          | 82/12825 [17:53<44:41:45, 12.63s/it]  1%|          | 83/12825 [18:05<44:42:00, 12.63s/it]  1%|          | 84/12825 [18:18<44:41:57, 12.63s/it]  1%|          | 85/12825 [18:31<44:38:43, 12.62s/it]  1%|          | 86/12825 [18:43<44:37:27, 12.61s/it]  1%|          | 87/12825 [18:56<44:33:45, 12.59s/it]  1%|          | 88/12825 [19:08<44:35:44, 12.60s/it]  1%|          | 89/12825 [19:21<44:34:26, 12.60s/it]  1%|          | 90/12825 [19:34<44:35:22, 12.60s/it]  1%|          | 91/12825 [19:46<44:33:50, 12.60s/it]  1%|          | 92/12825 [19:59<44:35:09, 12.61s/it]  1%|          | 93/12825 [20:11<44:33:54, 12.60s/it]  1%|          | 94/12825 [20:24<44:33:47, 12.60s/it]  1%|          | 95/12825 [20:37<44:35:25, 12.61s/it]  1%|          | 96/12825 [20:57<52:35:39, 14.87s/it]  1%|          | 97/12825 [21:09<50:11:10, 14.19s/it]  1%|          | 98/12825 [21:22<48:32:12, 13.73s/it]  1%|          | 99/12825 [21:35<47:20:29, 13.39s/it]  1%|          | 100/12825 [21:47<46:30:35, 13.16s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120421.91lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103641.54lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-75] due to args.save_total_limit
  1%|          | 101/12825 [22:00<46:16:22, 13.09s/it]  1%|          | 102/12825 [22:13<45:41:50, 12.93s/it]  1%|          | 103/12825 [22:25<45:18:40, 12.82s/it]  1%|          | 104/12825 [22:38<45:02:42, 12.75s/it]  1%|          | 105/12825 [22:50<44:49:51, 12.69s/it]  1%|          | 106/12825 [23:03<44:45:25, 12.67s/it]  1%|          | 107/12825 [23:16<44:39:53, 12.64s/it]  1%|          | 108/12825 [23:28<44:37:27, 12.63s/it]  1%|          | 109/12825 [23:41<44:32:23, 12.61s/it]  1%|          | 110/12825 [23:53<44:28:54, 12.59s/it]  1%|          | 111/12825 [24:06<44:28:22, 12.59s/it]  1%|          | 112/12825 [24:19<44:28:03, 12.59s/it]  1%|          | 113/12825 [24:31<44:28:47, 12.60s/it]  1%|          | 114/12825 [24:44<44:34:02, 12.62s/it]  1%|          | 115/12825 [24:56<44:32:54, 12.62s/it]  1%|          | 116/12825 [25:09<44:31:57, 12.61s/it]  1%|          | 117/12825 [25:22<44:28:17, 12.60s/it]  1%|          | 118/12825 [25:34<44:25:33, 12.59s/it]  1%|          | 119/12825 [25:47<44:26:13, 12.59s/it]  1%|          | 120/12825 [25:59<44:27:30, 12.60s/it]  1%|          | 121/12825 [26:12<44:28:50, 12.60s/it]  1%|          | 122/12825 [26:25<44:27:50, 12.60s/it]  1%|          | 123/12825 [26:37<44:26:10, 12.59s/it]  1%|          | 124/12825 [26:50<44:27:32, 12.60s/it]  1%|          | 125/12825 [27:02<44:25:46, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120447.78lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103636.42lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-100] due to args.save_total_limit
  1%|          | 126/12825 [27:15<44:45:24, 12.69s/it]  1%|          | 127/12825 [27:28<44:38:56, 12.66s/it]  1%|          | 128/12825 [27:48<52:33:27, 14.90s/it]  1%|          | 129/12825 [28:01<50:05:58, 14.21s/it]  1%|          | 130/12825 [28:13<48:23:06, 13.72s/it]  1%|          | 131/12825 [28:26<47:10:00, 13.38s/it]  1%|          | 132/12825 [28:38<46:17:36, 13.13s/it]  1%|          | 133/12825 [28:51<45:42:57, 12.97s/it]  1%|          | 134/12825 [29:03<45:18:16, 12.85s/it]  1%|          | 135/12825 [29:16<44:59:49, 12.77s/it]  1%|          | 136/12825 [29:29<44:46:06, 12.70s/it]  1%|          | 137/12825 [29:41<44:40:03, 12.67s/it]  1%|          | 138/12825 [29:54<44:37:51, 12.66s/it]  1%|          | 139/12825 [30:06<44:32:41, 12.64s/it]  1%|          | 140/12825 [30:19<44:29:26, 12.63s/it]  1%|          | 141/12825 [30:32<44:31:23, 12.64s/it]  1%|          | 142/12825 [30:44<44:29:25, 12.63s/it]  1%|          | 143/12825 [30:57<44:26:47, 12.62s/it]  1%|          | 144/12825 [31:09<44:26:22, 12.62s/it]  1%|          | 145/12825 [31:22<44:26:22, 12.62s/it]  1%|          | 146/12825 [31:35<44:25:29, 12.61s/it]  1%|          | 147/12825 [31:47<44:23:12, 12.60s/it]  1%|          | 148/12825 [32:00<44:23:29, 12.61s/it]  1%|          | 149/12825 [32:12<44:21:56, 12.60s/it]  1%|          | 150/12825 [32:25<44:20:52, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120424.60lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103638.88lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-125] due to args.save_total_limit
  1%|          | 151/12825 [32:38<44:41:08, 12.69s/it]  1%|          | 152/12825 [32:51<44:36:32, 12.67s/it]  1%|          | 153/12825 [33:03<44:33:21, 12.66s/it]  1%|          | 154/12825 [33:16<44:28:42, 12.64s/it]  1%|          | 155/12825 [33:28<44:26:36, 12.63s/it]  1%|          | 156/12825 [33:41<44:27:24, 12.63s/it]  1%|          | 157/12825 [33:54<44:23:16, 12.61s/it]  1%|          | 158/12825 [34:06<44:22:19, 12.61s/it]  1%|          | 159/12825 [34:19<44:21:07, 12.61s/it]  1%|          | 160/12825 [34:39<52:26:19, 14.91s/it]  1%|▏         | 161/12825 [34:52<50:02:26, 14.23s/it]  1%|▏         | 162/12825 [35:04<48:17:57, 13.73s/it]  1%|▏         | 163/12825 [35:17<47:06:21, 13.39s/it]  1%|▏         | 164/12825 [35:29<46:12:40, 13.14s/it]  1%|▏         | 165/12825 [35:42<45:35:48, 12.97s/it]  1%|▏         | 166/12825 [35:55<45:10:24, 12.85s/it]  1%|▏         | 167/12825 [36:07<44:52:00, 12.76s/it]  1%|▏         | 168/12825 [36:20<44:41:05, 12.71s/it]  1%|▏         | 169/12825 [36:32<44:32:21, 12.67s/it]  1%|▏         | 170/12825 [36:45<44:26:08, 12.64s/it]  1%|▏         | 171/12825 [36:58<44:23:13, 12.63s/it]  1%|▏         | 172/12825 [37:10<44:18:30, 12.61s/it]  1%|▏         | 173/12825 [37:23<44:18:54, 12.61s/it]  1%|▏         | 174/12825 [37:35<44:15:38, 12.59s/it]  1%|▏         | 175/12825 [37:48<44:14:13, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120565.37lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103693.73lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-150] due to args.save_total_limit
  1%|▏         | 176/12825 [38:01<44:36:37, 12.70s/it]  1%|▏         | 177/12825 [38:13<44:30:05, 12.67s/it]  1%|▏         | 178/12825 [38:26<44:25:10, 12.64s/it]  1%|▏         | 179/12825 [38:39<44:22:02, 12.63s/it]  1%|▏         | 180/12825 [38:51<44:18:04, 12.61s/it]  1%|▏         | 181/12825 [39:04<44:17:46, 12.61s/it]  1%|▏         | 182/12825 [39:16<44:15:25, 12.60s/it]  1%|▏         | 183/12825 [39:29<44:13:59, 12.60s/it]  1%|▏         | 184/12825 [39:42<44:14:54, 12.60s/it]  1%|▏         | 185/12825 [39:54<44:16:24, 12.61s/it]  1%|▏         | 186/12825 [40:07<44:13:01, 12.59s/it]  1%|▏         | 187/12825 [40:19<44:12:37, 12.59s/it]  1%|▏         | 188/12825 [40:32<44:12:19, 12.59s/it]  1%|▏         | 189/12825 [40:44<44:11:03, 12.59s/it]  1%|▏         | 190/12825 [40:57<44:11:01, 12.59s/it]  1%|▏         | 191/12825 [41:10<44:12:53, 12.60s/it]  1%|▏         | 192/12825 [41:22<44:13:20, 12.60s/it]  2%|▏         | 193/12825 [41:43<52:15:48, 14.89s/it]  2%|▏         | 194/12825 [41:55<49:50:30, 14.21s/it]  2%|▏         | 195/12825 [42:08<48:11:25, 13.74s/it]  2%|▏         | 196/12825 [42:20<46:57:36, 13.39s/it]  2%|▏         | 197/12825 [42:33<46:08:03, 13.15s/it]  2%|▏         | 198/12825 [42:46<45:32:19, 12.98s/it]  2%|▏         | 199/12825 [42:58<45:07:07, 12.86s/it]  2%|▏         | 200/12825 [43:11<44:50:05, 12.78s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120334.26lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103590.06lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-175] due to args.save_total_limit
  2%|▏         | 201/12825 [43:25<46:01:41, 13.13s/it]  2%|▏         | 202/12825 [43:37<45:27:41, 12.97s/it]  2%|▏         | 203/12825 [43:50<45:05:41, 12.86s/it]  2%|▏         | 204/12825 [44:02<44:49:09, 12.78s/it]  2%|▏         | 205/12825 [44:15<44:38:06, 12.73s/it]  2%|▏         | 206/12825 [44:28<44:26:29, 12.68s/it]  2%|▏         | 207/12825 [44:40<44:14:44, 12.62s/it]  2%|▏         | 208/12825 [44:53<44:11:21, 12.61s/it]  2%|▏         | 209/12825 [45:05<44:10:09, 12.60s/it]  2%|▏         | 210/12825 [45:18<44:09:06, 12.60s/it]  2%|▏         | 211/12825 [45:30<44:07:43, 12.59s/it]  2%|▏         | 212/12825 [45:43<44:09:14, 12.60s/it]  2%|▏         | 213/12825 [45:56<44:08:06, 12.60s/it]  2%|▏         | 214/12825 [46:08<44:07:15, 12.60s/it]  2%|▏         | 215/12825 [46:21<44:09:12, 12.61s/it]  2%|▏         | 216/12825 [46:33<44:07:06, 12.60s/it]  2%|▏         | 217/12825 [46:46<44:04:08, 12.58s/it]  2%|▏         | 218/12825 [46:59<44:06:56, 12.60s/it]  2%|▏         | 219/12825 [47:11<44:05:10, 12.59s/it]  2%|▏         | 220/12825 [47:24<44:03:57, 12.59s/it]  2%|▏         | 221/12825 [47:36<44:01:20, 12.57s/it]  2%|▏         | 222/12825 [47:49<44:02:53, 12.58s/it]  2%|▏         | 223/12825 [48:02<44:02:33, 12.58s/it]  2%|▏         | 224/12825 [48:14<44:01:01, 12.58s/it]  2%|▏         | 225/12825 [48:34<52:13:04, 14.92s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 108102.99lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 94224.93lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-200] due to args.save_total_limit
  2%|▏         | 226/12825 [48:47<50:07:38, 14.32s/it]  2%|▏         | 227/12825 [49:00<48:15:56, 13.79s/it]  2%|▏         | 228/12825 [49:13<47:01:47, 13.44s/it]  2%|▏         | 229/12825 [49:25<46:09:16, 13.19s/it]  2%|▏         | 230/12825 [49:38<45:31:22, 13.01s/it]  2%|▏         | 231/12825 [49:50<45:05:12, 12.89s/it]  2%|▏         | 232/12825 [50:03<44:47:02, 12.80s/it]  2%|▏         | 233/12825 [50:16<44:32:54, 12.74s/it]  2%|▏         | 234/12825 [50:28<44:20:31, 12.68s/it]  2%|▏         | 235/12825 [50:41<44:22:33, 12.69s/it]  2%|▏         | 236/12825 [50:53<44:16:10, 12.66s/it]  2%|▏         | 237/12825 [51:06<44:10:44, 12.63s/it]  2%|▏         | 238/12825 [51:19<44:20:04, 12.68s/it]  2%|▏         | 239/12825 [51:31<44:14:58, 12.66s/it]  2%|▏         | 240/12825 [51:44<44:06:46, 12.62s/it]  2%|▏         | 241/12825 [51:56<44:02:55, 12.60s/it]  2%|▏         | 242/12825 [52:09<43:59:36, 12.59s/it]  2%|▏         | 243/12825 [52:22<43:58:36, 12.58s/it]  2%|▏         | 244/12825 [52:34<43:56:37, 12.57s/it]  2%|▏         | 245/12825 [52:47<43:52:51, 12.56s/it]  2%|▏         | 246/12825 [52:59<43:50:15, 12.55s/it]  2%|▏         | 247/12825 [53:12<43:52:33, 12.56s/it]  2%|▏         | 248/12825 [53:24<43:49:20, 12.54s/it]  2%|▏         | 249/12825 [53:37<43:49:03, 12.54s/it]  2%|▏         | 250/12825 [53:49<43:49:34, 12.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 115541.56lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 99961.08lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-225] due to args.save_total_limit
  2%|▏         | 251/12825 [54:02<44:13:56, 12.66s/it]  2%|▏         | 252/12825 [54:15<44:04:49, 12.62s/it]  2%|▏         | 253/12825 [54:27<43:59:52, 12.60s/it]  2%|▏         | 254/12825 [54:40<43:52:35, 12.57s/it]  2%|▏         | 255/12825 [54:52<43:52:13, 12.56s/it]  2%|▏         | 256/12825 [55:05<43:50:38, 12.56s/it]  2%|▏         | 257/12825 [55:17<43:47:37, 12.54s/it]  2%|▏         | 258/12825 [55:38<52:32:25, 15.05s/it]  2%|▏         | 259/12825 [55:51<49:56:28, 14.31s/it]  2%|▏         | 260/12825 [56:03<48:05:12, 13.78s/it]  2%|▏         | 261/12825 [56:16<46:50:00, 13.42s/it]  2%|▏         | 262/12825 [56:29<45:57:06, 13.17s/it]  2%|▏         | 263/12825 [56:41<45:18:42, 12.99s/it]  2%|▏         | 264/12825 [56:54<44:52:35, 12.86s/it]  2%|▏         | 265/12825 [57:06<44:31:58, 12.76s/it]  2%|▏         | 266/12825 [57:19<44:15:31, 12.69s/it]  2%|▏         | 267/12825 [57:31<44:10:34, 12.66s/it]  2%|▏         | 268/12825 [57:44<44:04:04, 12.63s/it]  2%|▏         | 269/12825 [57:57<44:03:19, 12.63s/it]  2%|▏         | 270/12825 [58:09<43:59:10, 12.61s/it]  2%|▏         | 271/12825 [58:22<43:56:22, 12.60s/it]  2%|▏         | 272/12825 [58:34<43:53:30, 12.59s/it]  2%|▏         | 273/12825 [58:47<43:50:07, 12.57s/it]  2%|▏         | 274/12825 [58:59<43:47:59, 12.56s/it]  2%|▏         | 275/12825 [59:12<43:59:26, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120481.74lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103694.11lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-250] due to args.save_total_limit
  2%|▏         | 276/12825 [59:25<44:14:23, 12.69s/it]  2%|▏         | 277/12825 [59:38<44:05:22, 12.65s/it]  2%|▏         | 278/12825 [59:50<43:57:38, 12.61s/it]  2%|▏         | 279/12825 [1:00:03<43:52:59, 12.59s/it]  2%|▏         | 280/12825 [1:00:15<43:51:49, 12.59s/it]  2%|▏         | 281/12825 [1:00:28<43:48:58, 12.57s/it]  2%|▏         | 282/12825 [1:00:40<43:45:27, 12.56s/it]  2%|▏         | 283/12825 [1:00:53<43:44:19, 12.55s/it]  2%|▏         | 284/12825 [1:01:05<43:41:05, 12.54s/it]  2%|▏         | 285/12825 [1:01:18<43:40:49, 12.54s/it]  2%|▏         | 286/12825 [1:01:30<43:42:05, 12.55s/it]  2%|▏         | 287/12825 [1:01:43<43:44:11, 12.56s/it]  2%|▏         | 288/12825 [1:01:56<43:45:21, 12.56s/it]  2%|▏         | 289/12825 [1:02:08<43:41:45, 12.55s/it]  2%|▏         | 290/12825 [1:02:29<52:16:19, 15.01s/it]  2%|▏         | 291/12825 [1:02:41<49:43:49, 14.28s/it]  2%|▏         | 292/12825 [1:02:54<47:56:05, 13.77s/it]  2%|▏         | 293/12825 [1:03:07<46:41:01, 13.41s/it]  2%|▏         | 294/12825 [1:03:19<45:48:44, 13.16s/it]  2%|▏         | 295/12825 [1:03:32<45:12:13, 12.99s/it]  2%|▏         | 296/12825 [1:03:44<44:45:24, 12.86s/it]  2%|▏         | 297/12825 [1:03:57<44:24:27, 12.76s/it]  2%|▏         | 298/12825 [1:04:09<44:13:24, 12.71s/it]  2%|▏         | 299/12825 [1:04:22<44:02:56, 12.66s/it]  2%|▏         | 300/12825 [1:04:35<43:58:15, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120408.98lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103641.16lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-275] due to args.save_total_limit
  2%|▏         | 301/12825 [1:04:47<44:14:11, 12.72s/it]  2%|▏         | 302/12825 [1:05:00<44:04:00, 12.67s/it]  2%|▏         | 303/12825 [1:05:13<43:57:39, 12.64s/it]  2%|▏         | 304/12825 [1:05:25<43:52:23, 12.61s/it]  2%|▏         | 305/12825 [1:05:38<43:50:50, 12.61s/it]  2%|▏         | 306/12825 [1:05:50<43:47:21, 12.59s/it]  2%|▏         | 307/12825 [1:06:03<43:42:18, 12.57s/it]  2%|▏         | 308/12825 [1:06:15<43:40:44, 12.56s/it]  2%|▏         | 309/12825 [1:06:28<43:36:46, 12.54s/it]  2%|▏         | 310/12825 [1:06:40<43:36:42, 12.55s/it]  2%|▏         | 311/12825 [1:06:53<43:37:09, 12.55s/it]  2%|▏         | 312/12825 [1:07:06<43:37:26, 12.55s/it]  2%|▏         | 313/12825 [1:07:18<43:37:29, 12.55s/it]  2%|▏         | 314/12825 [1:07:31<43:38:05, 12.56s/it]  2%|▏         | 315/12825 [1:07:43<43:41:00, 12.57s/it]  2%|▏         | 316/12825 [1:07:56<43:40:50, 12.57s/it]  2%|▏         | 317/12825 [1:08:08<43:37:54, 12.56s/it]  2%|▏         | 318/12825 [1:08:21<43:37:19, 12.56s/it]  2%|▏         | 319/12825 [1:08:33<43:35:30, 12.55s/it]  2%|▏         | 320/12825 [1:08:46<43:33:32, 12.54s/it]  3%|▎         | 321/12825 [1:08:58<43:33:35, 12.54s/it]  3%|▎         | 322/12825 [1:09:19<51:20:50, 14.78s/it]  3%|▎         | 323/12825 [1:09:31<49:00:19, 14.11s/it]  3%|▎         | 324/12825 [1:09:44<47:24:32, 13.65s/it]  3%|▎         | 325/12825 [1:09:56<46:15:50, 13.32s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120389.90lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103600.77lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-300] due to args.save_total_limit
  3%|▎         | 326/12825 [1:10:09<45:50:07, 13.20s/it]  3%|▎         | 327/12825 [1:10:22<45:11:39, 13.02s/it]  3%|▎         | 328/12825 [1:10:34<44:43:01, 12.88s/it]  3%|▎         | 329/12825 [1:10:49<46:31:02, 13.40s/it]  3%|▎         | 330/12825 [1:11:01<45:39:57, 13.16s/it]  3%|▎         | 331/12825 [1:11:14<45:03:17, 12.98s/it]  3%|▎         | 332/12825 [1:11:27<44:39:37, 12.87s/it]  3%|▎         | 333/12825 [1:11:39<44:22:10, 12.79s/it]  3%|▎         | 334/12825 [1:11:52<44:08:05, 12.72s/it]  3%|▎         | 335/12825 [1:12:04<43:58:14, 12.67s/it]  3%|▎         | 336/12825 [1:12:17<43:53:43, 12.65s/it]  3%|▎         | 337/12825 [1:12:30<43:49:52, 12.64s/it]  3%|▎         | 338/12825 [1:12:42<43:45:19, 12.61s/it]  3%|▎         | 339/12825 [1:12:55<43:45:04, 12.61s/it]  3%|▎         | 340/12825 [1:13:07<43:44:48, 12.61s/it]  3%|▎         | 341/12825 [1:13:20<43:43:46, 12.61s/it]  3%|▎         | 342/12825 [1:13:33<43:41:45, 12.60s/it]  3%|▎         | 343/12825 [1:13:45<43:44:15, 12.61s/it]  3%|▎         | 344/12825 [1:13:58<43:43:28, 12.61s/it]  3%|▎         | 345/12825 [1:14:10<43:43:36, 12.61s/it]  3%|▎         | 346/12825 [1:14:23<43:44:36, 12.62s/it]  3%|▎         | 347/12825 [1:14:36<43:43:03, 12.61s/it]  3%|▎         | 348/12825 [1:14:48<43:43:23, 12.62s/it]  3%|▎         | 349/12825 [1:15:01<43:42:09, 12.61s/it]  3%|▎         | 350/12825 [1:15:13<43:40:44, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 37625.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 28982.47lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-325] due to args.save_total_limit
  3%|▎         | 351/12825 [1:15:27<44:51:23, 12.95s/it]  3%|▎         | 352/12825 [1:15:40<44:28:27, 12.84s/it]  3%|▎         | 353/12825 [1:15:52<44:09:29, 12.75s/it]  3%|▎         | 354/12825 [1:16:05<43:56:47, 12.69s/it]  3%|▎         | 355/12825 [1:16:25<51:43:48, 14.93s/it]  3%|▎         | 356/12825 [1:16:38<49:16:42, 14.23s/it]  3%|▎         | 357/12825 [1:16:50<47:32:16, 13.73s/it]  3%|▎         | 358/12825 [1:17:03<46:21:08, 13.38s/it]  3%|▎         | 359/12825 [1:17:15<45:31:41, 13.15s/it]  3%|▎         | 360/12825 [1:17:28<44:57:08, 12.98s/it]  3%|▎         | 361/12825 [1:17:41<44:32:06, 12.86s/it]  3%|▎         | 362/12825 [1:17:53<44:13:49, 12.78s/it]  3%|▎         | 363/12825 [1:18:06<44:01:56, 12.72s/it]  3%|▎         | 364/12825 [1:18:18<43:54:22, 12.68s/it]  3%|▎         | 365/12825 [1:18:31<43:49:09, 12.66s/it]  3%|▎         | 366/12825 [1:18:43<43:43:14, 12.63s/it]  3%|▎         | 367/12825 [1:18:56<43:39:07, 12.61s/it]  3%|▎         | 368/12825 [1:19:09<43:36:32, 12.60s/it]  3%|▎         | 369/12825 [1:19:21<43:39:25, 12.62s/it]  3%|▎         | 370/12825 [1:19:34<43:37:08, 12.61s/it]  3%|▎         | 371/12825 [1:19:46<43:35:57, 12.60s/it]  3%|▎         | 372/12825 [1:19:59<43:35:34, 12.60s/it]  3%|▎         | 373/12825 [1:20:12<43:34:12, 12.60s/it]  3%|▎         | 374/12825 [1:20:24<43:31:47, 12.59s/it]  3%|▎         | 375/12825 [1:20:37<43:29:44, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120548.04lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103736.00lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-350] due to args.save_total_limit
  3%|▎         | 376/12825 [1:20:50<43:48:50, 12.67s/it]  3%|▎         | 377/12825 [1:21:02<43:41:19, 12.63s/it]  3%|▎         | 378/12825 [1:21:15<43:35:15, 12.61s/it]  3%|▎         | 379/12825 [1:21:27<43:30:57, 12.59s/it]  3%|▎         | 380/12825 [1:21:40<43:28:39, 12.58s/it]  3%|▎         | 381/12825 [1:21:52<43:26:34, 12.57s/it]  3%|▎         | 382/12825 [1:22:05<43:25:14, 12.56s/it]  3%|▎         | 383/12825 [1:22:17<43:22:05, 12.55s/it]  3%|▎         | 384/12825 [1:22:30<43:22:36, 12.55s/it]  3%|▎         | 385/12825 [1:22:43<43:23:03, 12.55s/it]  3%|▎         | 386/12825 [1:22:55<43:21:48, 12.55s/it]  3%|▎         | 387/12825 [1:23:15<51:18:28, 14.85s/it]  3%|▎         | 388/12825 [1:23:28<48:56:32, 14.17s/it]  3%|▎         | 389/12825 [1:23:40<47:13:55, 13.67s/it]  3%|▎         | 390/12825 [1:23:53<46:05:12, 13.34s/it]  3%|▎         | 391/12825 [1:24:06<45:16:07, 13.11s/it]  3%|▎         | 392/12825 [1:24:18<44:41:57, 12.94s/it]  3%|▎         | 393/12825 [1:24:31<44:18:30, 12.83s/it]  3%|▎         | 394/12825 [1:24:43<44:01:52, 12.75s/it]  3%|▎         | 395/12825 [1:24:56<43:50:50, 12.70s/it]  3%|▎         | 396/12825 [1:25:08<43:43:56, 12.67s/it]  3%|▎         | 397/12825 [1:25:21<43:39:39, 12.65s/it]  3%|▎         | 398/12825 [1:25:34<43:35:23, 12.63s/it]  3%|▎         | 399/12825 [1:25:46<43:30:28, 12.60s/it]  3%|▎         | 400/12825 [1:25:59<43:28:23, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120373.27lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103613.85lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-375] due to args.save_total_limit
  3%|▎         | 401/12825 [1:26:12<43:47:34, 12.69s/it]  3%|▎         | 402/12825 [1:26:24<43:40:11, 12.65s/it]  3%|▎         | 403/12825 [1:26:37<43:34:26, 12.63s/it]  3%|▎         | 404/12825 [1:26:49<43:29:41, 12.61s/it]  3%|▎         | 405/12825 [1:27:02<43:29:08, 12.60s/it]  3%|▎         | 406/12825 [1:27:14<43:25:21, 12.59s/it]  3%|▎         | 407/12825 [1:27:27<43:24:17, 12.58s/it]  3%|▎         | 408/12825 [1:27:40<43:21:00, 12.57s/it]  3%|▎         | 409/12825 [1:27:52<43:22:07, 12.57s/it]  3%|▎         | 410/12825 [1:28:05<43:20:12, 12.57s/it]  3%|▎         | 411/12825 [1:28:17<43:21:01, 12.57s/it]  3%|▎         | 412/12825 [1:28:30<43:19:59, 12.57s/it]  3%|▎         | 413/12825 [1:28:42<43:18:08, 12.56s/it]  3%|▎         | 414/12825 [1:28:55<43:18:37, 12.56s/it]  3%|▎         | 415/12825 [1:29:08<43:21:47, 12.58s/it]  3%|▎         | 416/12825 [1:29:20<43:22:17, 12.58s/it]  3%|▎         | 417/12825 [1:29:33<43:19:36, 12.57s/it]  3%|▎         | 418/12825 [1:29:45<43:21:36, 12.58s/it]  3%|▎         | 419/12825 [1:29:58<43:20:16, 12.58s/it]  3%|▎         | 420/12825 [1:30:18<51:06:42, 14.83s/it]  3%|▎         | 421/12825 [1:30:31<48:47:53, 14.16s/it]  3%|▎         | 422/12825 [1:30:43<47:11:42, 13.70s/it]  3%|▎         | 423/12825 [1:30:56<46:01:59, 13.36s/it]  3%|▎         | 424/12825 [1:31:08<45:12:04, 13.12s/it]  3%|▎         | 425/12825 [1:31:21<44:40:26, 12.97s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120519.69lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103687.85lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-400] due to args.save_total_limit
  3%|▎         | 426/12825 [1:31:34<44:35:29, 12.95s/it]  3%|▎         | 427/12825 [1:31:46<44:09:47, 12.82s/it]  3%|▎         | 428/12825 [1:31:59<43:53:07, 12.74s/it]  3%|▎         | 429/12825 [1:32:11<43:41:24, 12.69s/it]  3%|▎         | 430/12825 [1:32:24<43:33:43, 12.65s/it]  3%|▎         | 431/12825 [1:32:37<43:29:54, 12.63s/it]  3%|▎         | 432/12825 [1:32:49<43:24:01, 12.61s/it]  3%|▎         | 433/12825 [1:33:02<43:22:44, 12.60s/it]  3%|▎         | 434/12825 [1:33:14<43:20:49, 12.59s/it]  3%|▎         | 435/12825 [1:33:27<43:17:52, 12.58s/it]  3%|▎         | 436/12825 [1:33:40<43:19:50, 12.59s/it]  3%|▎         | 437/12825 [1:33:52<43:16:36, 12.58s/it]  3%|▎         | 438/12825 [1:34:05<43:16:11, 12.58s/it]  3%|▎         | 439/12825 [1:34:17<43:13:35, 12.56s/it]  3%|▎         | 440/12825 [1:34:30<43:15:16, 12.57s/it]  3%|▎         | 441/12825 [1:34:42<43:12:45, 12.56s/it]  3%|▎         | 442/12825 [1:34:55<43:13:20, 12.57s/it]  3%|▎         | 443/12825 [1:35:07<43:14:00, 12.57s/it]  3%|▎         | 444/12825 [1:35:20<43:15:19, 12.58s/it]  3%|▎         | 445/12825 [1:35:33<43:12:46, 12.57s/it]  3%|▎         | 446/12825 [1:35:45<43:12:13, 12.56s/it]  3%|▎         | 447/12825 [1:35:58<43:13:05, 12.57s/it]  3%|▎         | 448/12825 [1:36:10<43:13:19, 12.57s/it]  4%|▎         | 449/12825 [1:36:23<43:12:04, 12.57s/it]  4%|▎         | 450/12825 [1:36:35<43:12:03, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120524.31lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 99700.15lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-425] due to args.save_total_limit
  4%|▎         | 451/12825 [1:36:49<43:47:20, 12.74s/it]  4%|▎         | 452/12825 [1:37:09<51:39:37, 15.03s/it]  4%|▎         | 453/12825 [1:37:22<49:07:30, 14.29s/it]  4%|▎         | 454/12825 [1:37:34<47:21:25, 13.78s/it]  4%|▎         | 455/12825 [1:37:47<46:08:18, 13.43s/it]  4%|▎         | 456/12825 [1:37:59<45:17:17, 13.18s/it]  4%|▎         | 457/12825 [1:38:12<44:38:43, 13.00s/it]  4%|▎         | 458/12825 [1:38:24<44:13:44, 12.87s/it]  4%|▎         | 459/12825 [1:38:37<43:56:08, 12.79s/it]  4%|▎         | 460/12825 [1:38:50<43:42:38, 12.73s/it]  4%|▎         | 461/12825 [1:39:02<43:32:42, 12.68s/it]  4%|▎         | 462/12825 [1:39:15<43:25:59, 12.65s/it]  4%|▎         | 463/12825 [1:39:27<43:21:55, 12.63s/it]  4%|▎         | 464/12825 [1:39:40<43:16:57, 12.61s/it]  4%|▎         | 465/12825 [1:39:52<43:12:28, 12.58s/it]  4%|▎         | 466/12825 [1:40:05<43:10:42, 12.58s/it]  4%|▎         | 467/12825 [1:40:18<43:10:45, 12.58s/it]  4%|▎         | 468/12825 [1:40:30<43:07:54, 12.57s/it]  4%|▎         | 469/12825 [1:40:43<43:06:28, 12.56s/it]  4%|▎         | 470/12825 [1:40:55<43:08:12, 12.57s/it]  4%|▎         | 471/12825 [1:41:08<43:08:03, 12.57s/it]  4%|▎         | 472/12825 [1:41:20<43:07:34, 12.57s/it]  4%|▎         | 473/12825 [1:41:33<43:07:45, 12.57s/it]  4%|▎         | 474/12825 [1:41:46<43:08:22, 12.57s/it]  4%|▎         | 475/12825 [1:41:58<43:09:29, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120499.81lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103690.41lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-450] due to args.save_total_limit
  4%|▎         | 476/12825 [1:42:11<43:30:36, 12.68s/it]  4%|▎         | 477/12825 [1:42:24<43:23:54, 12.65s/it]  4%|▎         | 478/12825 [1:42:36<43:16:00, 12.62s/it]  4%|▎         | 479/12825 [1:42:49<43:11:53, 12.60s/it]  4%|▎         | 480/12825 [1:43:01<43:06:41, 12.57s/it]  4%|▍         | 481/12825 [1:43:14<43:06:10, 12.57s/it]  4%|▍         | 482/12825 [1:43:26<43:06:13, 12.57s/it]  4%|▍         | 483/12825 [1:43:39<43:03:54, 12.56s/it]  4%|▍         | 484/12825 [1:43:59<51:05:05, 14.90s/it]  4%|▍         | 485/12825 [1:44:12<48:42:26, 14.21s/it]  4%|▍         | 486/12825 [1:44:24<47:00:12, 13.71s/it]  4%|▍         | 487/12825 [1:44:37<45:50:47, 13.38s/it]  4%|▍         | 488/12825 [1:44:50<45:03:16, 13.15s/it]  4%|▍         | 489/12825 [1:45:02<44:25:27, 12.96s/it]  4%|▍         | 490/12825 [1:45:15<44:00:16, 12.84s/it]  4%|▍         | 491/12825 [1:45:27<43:42:49, 12.76s/it]  4%|▍         | 492/12825 [1:45:40<43:32:10, 12.71s/it]  4%|▍         | 493/12825 [1:45:52<43:23:59, 12.67s/it]  4%|▍         | 494/12825 [1:46:05<43:19:56, 12.65s/it]  4%|▍         | 495/12825 [1:46:18<43:15:00, 12.63s/it]  4%|▍         | 496/12825 [1:46:30<43:11:05, 12.61s/it]  4%|▍         | 497/12825 [1:46:43<43:08:52, 12.60s/it]  4%|▍         | 498/12825 [1:46:55<43:09:24, 12.60s/it]  4%|▍         | 499/12825 [1:47:08<43:05:45, 12.59s/it]  4%|▍         | 500/12825 [1:47:21<43:04:48, 12.58s/it]                                                          4%|▍         | 500/12825 [1:47:21<43:04:48, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120377.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103586.93lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-475] due to args.save_total_limit
  4%|▍         | 501/12825 [1:47:33<43:25:23, 12.68s/it]  4%|▍         | 502/12825 [1:47:46<43:15:17, 12.64s/it]  4%|▍         | 503/12825 [1:47:59<43:14:14, 12.63s/it]  4%|▍         | 504/12825 [1:48:11<43:11:39, 12.62s/it]  4%|▍         | 505/12825 [1:48:24<43:08:16, 12.61s/it]  4%|▍         | 506/12825 [1:48:36<43:07:33, 12.60s/it]  4%|▍         | 507/12825 [1:48:49<43:04:56, 12.59s/it]  4%|▍         | 508/12825 [1:49:01<43:01:49, 12.58s/it]  4%|▍         | 509/12825 [1:49:14<43:00:29, 12.57s/it]  4%|▍         | 510/12825 [1:49:27<43:00:02, 12.57s/it]  4%|▍         | 511/12825 [1:49:39<42:59:04, 12.57s/it]  4%|▍         | 512/12825 [1:49:47<38:13:12, 11.17s/it]  4%|▍         | 513/12825 [1:49:48<27:35:44,  8.07s/it]  4%|▍         | 514/12825 [1:50:14<45:34:52, 13.33s/it]  4%|▍         | 515/12825 [1:50:26<44:53:10, 13.13s/it]  4%|▍         | 516/12825 [1:50:39<44:22:24, 12.98s/it]  4%|▍         | 517/12825 [1:50:59<51:35:58, 15.09s/it]  4%|▍         | 518/12825 [1:51:11<49:03:00, 14.35s/it]  4%|▍         | 519/12825 [1:51:24<47:15:10, 13.82s/it]  4%|▍         | 520/12825 [1:51:37<45:59:51, 13.46s/it]  4%|▍         | 521/12825 [1:51:49<45:09:32, 13.21s/it]  4%|▍         | 522/12825 [1:52:02<44:33:31, 13.04s/it]  4%|▍         | 523/12825 [1:52:15<44:06:54, 12.91s/it]  4%|▍         | 524/12825 [1:52:27<43:45:50, 12.81s/it]  4%|▍         | 525/12825 [1:52:40<43:32:29, 12.74s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120418.07lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103719.28lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-500] due to args.save_total_limit
  4%|▍         | 526/12825 [1:52:53<43:43:59, 12.80s/it]  4%|▍         | 527/12825 [1:53:05<43:30:43, 12.74s/it]  4%|▍         | 528/12825 [1:53:18<43:20:46, 12.69s/it]  4%|▍         | 529/12825 [1:53:30<43:13:50, 12.66s/it]  4%|▍         | 530/12825 [1:53:43<43:10:08, 12.64s/it]  4%|▍         | 531/12825 [1:53:56<43:10:09, 12.64s/it]  4%|▍         | 532/12825 [1:54:08<43:08:50, 12.64s/it]  4%|▍         | 533/12825 [1:54:21<43:06:23, 12.62s/it]  4%|▍         | 534/12825 [1:54:33<43:06:21, 12.63s/it]  4%|▍         | 535/12825 [1:54:46<43:04:37, 12.62s/it]  4%|▍         | 536/12825 [1:54:59<43:03:53, 12.62s/it]  4%|▍         | 537/12825 [1:55:11<43:02:51, 12.61s/it]  4%|▍         | 538/12825 [1:55:24<43:01:50, 12.61s/it]  4%|▍         | 539/12825 [1:55:36<42:58:29, 12.59s/it]  4%|▍         | 540/12825 [1:55:49<42:58:39, 12.59s/it]  4%|▍         | 541/12825 [1:56:02<42:58:25, 12.59s/it]  4%|▍         | 542/12825 [1:56:14<42:59:05, 12.60s/it]  4%|▍         | 543/12825 [1:56:27<42:59:50, 12.60s/it]  4%|▍         | 544/12825 [1:56:39<42:58:58, 12.60s/it]  4%|▍         | 545/12825 [1:56:52<43:00:09, 12.61s/it]  4%|▍         | 546/12825 [1:57:05<43:00:55, 12.61s/it]  4%|▍         | 547/12825 [1:57:17<43:03:30, 12.63s/it]  4%|▍         | 548/12825 [1:57:30<43:02:47, 12.62s/it]  4%|▍         | 549/12825 [1:57:50<50:42:52, 14.87s/it]  4%|▍         | 550/12825 [1:58:03<48:24:29, 14.20s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120422.93lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103580.87lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-525] due to args.save_total_limit
  4%|▍         | 551/12825 [1:58:16<47:08:07, 13.82s/it]  4%|▍         | 552/12825 [1:58:28<45:52:16, 13.46s/it]  4%|▍         | 553/12825 [1:58:41<44:58:57, 13.20s/it]  4%|▍         | 554/12825 [1:58:53<44:21:32, 13.01s/it]  4%|▍         | 555/12825 [1:59:06<43:56:06, 12.89s/it]  4%|▍         | 556/12825 [1:59:19<43:36:28, 12.80s/it]  4%|▍         | 557/12825 [1:59:31<43:23:05, 12.73s/it]  4%|▍         | 558/12825 [1:59:44<43:16:44, 12.70s/it]  4%|▍         | 559/12825 [1:59:56<43:08:30, 12.66s/it]  4%|▍         | 560/12825 [2:00:09<43:03:12, 12.64s/it]  4%|▍         | 561/12825 [2:00:22<42:59:44, 12.62s/it]  4%|▍         | 562/12825 [2:00:34<42:57:47, 12.61s/it]  4%|▍         | 563/12825 [2:00:47<42:56:25, 12.61s/it]  4%|▍         | 564/12825 [2:00:59<42:56:07, 12.61s/it]  4%|▍         | 565/12825 [2:01:12<42:55:47, 12.61s/it]  4%|▍         | 566/12825 [2:01:25<42:55:13, 12.60s/it]  4%|▍         | 567/12825 [2:01:37<42:54:00, 12.60s/it]  4%|▍         | 568/12825 [2:01:50<42:54:19, 12.60s/it]  4%|▍         | 569/12825 [2:02:02<42:57:08, 12.62s/it]  4%|▍         | 570/12825 [2:02:15<42:57:56, 12.62s/it]  4%|▍         | 571/12825 [2:02:28<42:56:27, 12.62s/it]  4%|▍         | 572/12825 [2:02:40<42:56:45, 12.62s/it]  4%|▍         | 573/12825 [2:02:53<42:53:05, 12.60s/it]  4%|▍         | 574/12825 [2:03:05<42:53:08, 12.60s/it]  4%|▍         | 575/12825 [2:03:18<42:52:57, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120517.26lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103685.28lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-550] due to args.save_total_limit
  4%|▍         | 576/12825 [2:03:31<43:10:39, 12.69s/it]  4%|▍         | 577/12825 [2:03:44<43:03:49, 12.66s/it]  5%|▍         | 578/12825 [2:03:56<42:59:13, 12.64s/it]  5%|▍         | 579/12825 [2:04:09<42:57:29, 12.63s/it]  5%|▍         | 580/12825 [2:04:21<42:54:19, 12.61s/it]  5%|▍         | 581/12825 [2:04:34<42:50:11, 12.59s/it]  5%|▍         | 582/12825 [2:04:54<50:23:08, 14.82s/it]  5%|▍         | 583/12825 [2:05:06<48:08:05, 14.15s/it]  5%|▍         | 584/12825 [2:05:19<46:31:58, 13.69s/it]  5%|▍         | 585/12825 [2:05:32<45:22:40, 13.35s/it]  5%|▍         | 586/12825 [2:05:44<44:34:51, 13.11s/it]  5%|▍         | 587/12825 [2:05:57<44:02:37, 12.96s/it]  5%|▍         | 588/12825 [2:06:09<43:37:53, 12.84s/it]  5%|▍         | 589/12825 [2:06:22<43:21:06, 12.75s/it]  5%|▍         | 590/12825 [2:06:34<43:09:49, 12.70s/it]  5%|▍         | 591/12825 [2:06:47<43:03:20, 12.67s/it]  5%|▍         | 592/12825 [2:07:00<42:59:32, 12.65s/it]  5%|▍         | 593/12825 [2:07:12<42:55:54, 12.64s/it]  5%|▍         | 594/12825 [2:07:25<42:50:59, 12.61s/it]  5%|▍         | 595/12825 [2:07:37<42:52:02, 12.62s/it]  5%|▍         | 596/12825 [2:07:50<42:49:40, 12.61s/it]  5%|▍         | 597/12825 [2:08:03<42:48:51, 12.60s/it]  5%|▍         | 598/12825 [2:08:15<42:47:13, 12.60s/it]  5%|▍         | 599/12825 [2:08:28<42:46:48, 12.60s/it]  5%|▍         | 600/12825 [2:08:40<42:46:40, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120414.35lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103604.28lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-575] due to args.save_total_limit
  5%|▍         | 601/12825 [2:08:53<43:06:35, 12.70s/it]  5%|▍         | 602/12825 [2:09:06<42:58:15, 12.66s/it]  5%|▍         | 603/12825 [2:09:18<42:53:28, 12.63s/it]  5%|▍         | 604/12825 [2:09:31<42:48:45, 12.61s/it]  5%|▍         | 605/12825 [2:09:44<42:48:43, 12.61s/it]  5%|▍         | 606/12825 [2:09:56<42:48:00, 12.61s/it]  5%|▍         | 607/12825 [2:10:09<42:44:27, 12.59s/it]  5%|▍         | 608/12825 [2:10:21<42:43:43, 12.59s/it]  5%|▍         | 609/12825 [2:10:34<42:42:58, 12.59s/it]  5%|▍         | 610/12825 [2:10:47<42:41:58, 12.58s/it]  5%|▍         | 611/12825 [2:10:59<42:43:23, 12.59s/it]  5%|▍         | 612/12825 [2:11:12<42:43:51, 12.60s/it]  5%|▍         | 613/12825 [2:11:24<42:43:49, 12.60s/it]  5%|▍         | 614/12825 [2:11:44<50:23:48, 14.86s/it]  5%|▍         | 615/12825 [2:11:57<48:04:46, 14.18s/it]  5%|▍         | 616/12825 [2:12:10<46:25:56, 13.69s/it]  5%|▍         | 617/12825 [2:12:22<45:16:34, 13.35s/it]  5%|▍         | 618/12825 [2:12:35<44:30:19, 13.13s/it]  5%|▍         | 619/12825 [2:12:47<43:57:48, 12.97s/it]  5%|▍         | 620/12825 [2:13:00<43:35:12, 12.86s/it]  5%|▍         | 621/12825 [2:13:13<43:18:30, 12.78s/it]  5%|▍         | 622/12825 [2:13:25<43:07:49, 12.72s/it]  5%|▍         | 623/12825 [2:13:38<43:00:47, 12.69s/it]  5%|▍         | 624/12825 [2:13:50<42:56:35, 12.67s/it]  5%|▍         | 625/12825 [2:14:03<42:51:10, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120502.51lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 99301.58lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-600] due to args.save_total_limit
  5%|▍         | 626/12825 [2:14:16<43:24:54, 12.81s/it]  5%|▍         | 627/12825 [2:14:29<43:12:25, 12.75s/it]  5%|▍         | 628/12825 [2:14:41<43:03:22, 12.71s/it]  5%|▍         | 629/12825 [2:14:54<42:56:44, 12.68s/it]  5%|▍         | 630/12825 [2:15:07<42:51:45, 12.65s/it]  5%|▍         | 631/12825 [2:15:19<42:47:11, 12.63s/it]  5%|▍         | 632/12825 [2:15:32<42:42:20, 12.61s/it]  5%|▍         | 633/12825 [2:15:44<42:42:07, 12.61s/it]  5%|▍         | 634/12825 [2:15:57<42:41:15, 12.61s/it]  5%|▍         | 635/12825 [2:16:10<42:37:14, 12.59s/it]  5%|▍         | 636/12825 [2:16:22<42:34:21, 12.57s/it]  5%|▍         | 637/12825 [2:16:35<42:37:43, 12.59s/it]  5%|▍         | 638/12825 [2:16:47<42:35:39, 12.58s/it]  5%|▍         | 639/12825 [2:17:00<42:36:05, 12.59s/it]  5%|▍         | 640/12825 [2:17:12<42:36:13, 12.59s/it]  5%|▍         | 641/12825 [2:17:25<42:35:10, 12.58s/it]  5%|▌         | 642/12825 [2:17:38<42:35:37, 12.59s/it]  5%|▌         | 643/12825 [2:17:50<42:36:31, 12.59s/it]  5%|▌         | 644/12825 [2:18:03<42:36:22, 12.59s/it]  5%|▌         | 645/12825 [2:18:15<42:34:15, 12.58s/it]  5%|▌         | 646/12825 [2:18:28<42:31:41, 12.57s/it]  5%|▌         | 647/12825 [2:18:48<50:13:02, 14.85s/it]  5%|▌         | 648/12825 [2:19:01<47:56:43, 14.17s/it]  5%|▌         | 649/12825 [2:19:13<46:21:25, 13.71s/it]  5%|▌         | 650/12825 [2:19:26<45:11:58, 13.36s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120457.65lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103674.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-625] due to args.save_total_limit
  5%|▌         | 651/12825 [2:19:39<44:43:24, 13.23s/it]  5%|▌         | 652/12825 [2:19:51<44:03:46, 13.03s/it]  5%|▌         | 653/12825 [2:20:04<43:34:53, 12.89s/it]  5%|▌         | 654/12825 [2:20:16<43:14:46, 12.79s/it]  5%|▌         | 655/12825 [2:20:29<43:02:06, 12.73s/it]  5%|▌         | 656/12825 [2:20:42<42:52:28, 12.68s/it]  5%|▌         | 657/12825 [2:20:54<42:45:14, 12.65s/it]  5%|▌         | 658/12825 [2:21:07<42:40:36, 12.63s/it]  5%|▌         | 659/12825 [2:21:19<42:38:52, 12.62s/it]  5%|▌         | 660/12825 [2:21:32<42:38:20, 12.62s/it]  5%|▌         | 661/12825 [2:21:45<42:35:12, 12.60s/it]  5%|▌         | 662/12825 [2:21:57<42:34:29, 12.60s/it]  5%|▌         | 663/12825 [2:22:10<42:35:21, 12.61s/it]  5%|▌         | 664/12825 [2:22:22<42:36:35, 12.61s/it]  5%|▌         | 665/12825 [2:22:35<42:32:54, 12.60s/it]  5%|▌         | 666/12825 [2:22:48<42:33:11, 12.60s/it]  5%|▌         | 667/12825 [2:23:00<42:31:17, 12.59s/it]  5%|▌         | 668/12825 [2:23:13<42:31:03, 12.59s/it]  5%|▌         | 669/12825 [2:23:25<42:32:28, 12.60s/it]  5%|▌         | 670/12825 [2:23:38<42:31:55, 12.60s/it]  5%|▌         | 671/12825 [2:23:51<42:33:36, 12.61s/it]  5%|▌         | 672/12825 [2:24:03<42:33:46, 12.61s/it]  5%|▌         | 673/12825 [2:24:16<42:30:52, 12.59s/it]  5%|▌         | 674/12825 [2:24:28<42:31:33, 12.60s/it]  5%|▌         | 675/12825 [2:24:41<42:30:50, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120435.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103612.24lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-650] due to args.save_total_limit
  5%|▌         | 676/12825 [2:24:54<42:49:15, 12.69s/it]  5%|▌         | 677/12825 [2:25:06<42:42:11, 12.65s/it]  5%|▌         | 678/12825 [2:25:19<42:36:21, 12.63s/it]  5%|▌         | 679/12825 [2:25:39<50:08:10, 14.86s/it]  5%|▌         | 680/12825 [2:25:52<47:49:34, 14.18s/it]  5%|▌         | 681/12825 [2:26:04<46:11:59, 13.70s/it]  5%|▌         | 682/12825 [2:26:17<45:04:55, 13.37s/it]  5%|▌         | 683/12825 [2:26:29<44:16:11, 13.13s/it]  5%|▌         | 684/12825 [2:26:42<43:44:25, 12.97s/it]  5%|▌         | 685/12825 [2:26:55<43:20:09, 12.85s/it]  5%|▌         | 686/12825 [2:27:07<43:02:52, 12.77s/it]  5%|▌         | 687/12825 [2:27:20<42:53:46, 12.72s/it]  5%|▌         | 688/12825 [2:27:32<42:44:38, 12.68s/it]  5%|▌         | 689/12825 [2:27:45<42:38:59, 12.65s/it]  5%|▌         | 690/12825 [2:27:58<42:37:45, 12.65s/it]  5%|▌         | 691/12825 [2:28:10<42:33:31, 12.63s/it]  5%|▌         | 692/12825 [2:28:23<42:31:34, 12.62s/it]  5%|▌         | 693/12825 [2:28:35<42:29:25, 12.61s/it]  5%|▌         | 694/12825 [2:28:48<42:29:18, 12.61s/it]  5%|▌         | 695/12825 [2:29:00<42:26:55, 12.60s/it]  5%|▌         | 696/12825 [2:29:13<42:27:17, 12.60s/it]  5%|▌         | 697/12825 [2:29:26<42:24:56, 12.59s/it]  5%|▌         | 698/12825 [2:29:38<42:25:31, 12.59s/it]  5%|▌         | 699/12825 [2:29:51<42:24:35, 12.59s/it]  5%|▌         | 700/12825 [2:30:03<42:26:43, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120514.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103690.89lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-675] due to args.save_total_limit
  5%|▌         | 701/12825 [2:30:16<42:45:06, 12.69s/it]  5%|▌         | 702/12825 [2:30:29<42:36:15, 12.65s/it]  5%|▌         | 703/12825 [2:30:41<42:32:04, 12.63s/it]  5%|▌         | 704/12825 [2:30:54<42:28:11, 12.61s/it]  5%|▌         | 705/12825 [2:31:07<42:27:15, 12.61s/it]  6%|▌         | 706/12825 [2:31:19<42:24:09, 12.60s/it]  6%|▌         | 707/12825 [2:31:32<42:20:22, 12.58s/it]  6%|▌         | 708/12825 [2:31:44<42:20:51, 12.58s/it]  6%|▌         | 709/12825 [2:31:57<42:21:29, 12.59s/it]  6%|▌         | 710/12825 [2:32:10<42:20:49, 12.58s/it]  6%|▌         | 711/12825 [2:32:30<50:23:05, 14.97s/it]  6%|▌         | 712/12825 [2:32:43<47:59:47, 14.26s/it]  6%|▌         | 713/12825 [2:32:55<46:18:30, 13.76s/it]  6%|▌         | 714/12825 [2:33:08<45:05:28, 13.40s/it]  6%|▌         | 715/12825 [2:33:20<44:13:39, 13.15s/it]  6%|▌         | 716/12825 [2:33:33<43:39:23, 12.98s/it]  6%|▌         | 717/12825 [2:33:46<43:12:59, 12.85s/it]  6%|▌         | 718/12825 [2:33:58<42:56:39, 12.77s/it]  6%|▌         | 719/12825 [2:34:11<42:42:41, 12.70s/it]  6%|▌         | 720/12825 [2:34:23<42:33:49, 12.66s/it]  6%|▌         | 721/12825 [2:34:36<42:28:08, 12.63s/it]  6%|▌         | 722/12825 [2:34:48<42:24:32, 12.61s/it]  6%|▌         | 723/12825 [2:35:01<42:22:10, 12.60s/it]  6%|▌         | 724/12825 [2:35:13<42:18:57, 12.59s/it]  6%|▌         | 725/12825 [2:35:26<42:16:22, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120476.74lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103657.76lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-725
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-725/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-725/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-700] due to args.save_total_limit
  6%|▌         | 726/12825 [2:35:39<42:34:16, 12.67s/it]  6%|▌         | 727/12825 [2:35:51<42:28:29, 12.64s/it]  6%|▌         | 728/12825 [2:36:04<42:24:04, 12.62s/it]  6%|▌         | 729/12825 [2:36:17<42:18:35, 12.59s/it]  6%|▌         | 730/12825 [2:36:29<42:17:18, 12.59s/it]  6%|▌         | 731/12825 [2:36:42<42:15:40, 12.58s/it]  6%|▌         | 732/12825 [2:36:54<42:17:13, 12.59s/it]  6%|▌         | 733/12825 [2:37:07<42:16:39, 12.59s/it]  6%|▌         | 734/12825 [2:37:19<42:15:02, 12.58s/it]  6%|▌         | 735/12825 [2:37:32<42:13:45, 12.57s/it]  6%|▌         | 736/12825 [2:37:45<42:14:17, 12.58s/it]  6%|▌         | 737/12825 [2:37:57<42:11:10, 12.56s/it]  6%|▌         | 738/12825 [2:38:10<42:13:13, 12.57s/it]  6%|▌         | 739/12825 [2:38:22<42:16:23, 12.59s/it]  6%|▌         | 740/12825 [2:38:35<42:14:18, 12.58s/it]  6%|▌         | 741/12825 [2:38:48<42:14:56, 12.59s/it]  6%|▌         | 742/12825 [2:39:00<42:14:19, 12.58s/it]  6%|▌         | 743/12825 [2:39:13<42:14:33, 12.59s/it]  6%|▌         | 744/12825 [2:39:33<49:44:50, 14.82s/it]  6%|▌         | 745/12825 [2:39:45<47:28:39, 14.15s/it]  6%|▌         | 746/12825 [2:39:58<45:54:32, 13.68s/it]  6%|▌         | 747/12825 [2:40:11<44:47:58, 13.35s/it]  6%|▌         | 748/12825 [2:40:23<44:03:00, 13.13s/it]  6%|▌         | 749/12825 [2:40:36<43:31:59, 12.98s/it]  6%|▌         | 750/12825 [2:40:48<43:07:43, 12.86s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120483.66lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103668.86lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-750
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-750/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-750/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-725] due to args.save_total_limit
  6%|▌         | 751/12825 [2:41:01<43:10:28, 12.87s/it]  6%|▌         | 752/12825 [2:41:14<42:52:33, 12.79s/it]  6%|▌         | 753/12825 [2:41:26<42:37:10, 12.71s/it]  6%|▌         | 754/12825 [2:41:39<42:28:21, 12.67s/it]  6%|▌         | 755/12825 [2:41:51<42:22:33, 12.64s/it]  6%|▌         | 756/12825 [2:42:04<42:16:51, 12.61s/it]  6%|▌         | 757/12825 [2:42:17<42:13:15, 12.59s/it]  6%|▌         | 758/12825 [2:42:29<42:11:07, 12.59s/it]  6%|▌         | 759/12825 [2:42:42<42:09:34, 12.58s/it]  6%|▌         | 760/12825 [2:42:54<42:09:25, 12.58s/it]  6%|▌         | 761/12825 [2:43:07<42:09:25, 12.58s/it]  6%|▌         | 762/12825 [2:43:20<42:11:55, 12.59s/it]  6%|▌         | 763/12825 [2:43:32<42:13:46, 12.60s/it]  6%|▌         | 764/12825 [2:43:45<42:12:06, 12.60s/it]  6%|▌         | 765/12825 [2:43:57<42:11:07, 12.59s/it]  6%|▌         | 766/12825 [2:44:10<42:11:32, 12.60s/it]  6%|▌         | 767/12825 [2:44:22<42:07:23, 12.58s/it]  6%|▌         | 768/12825 [2:44:35<42:08:36, 12.58s/it]  6%|▌         | 769/12825 [2:44:48<42:06:52, 12.58s/it]  6%|▌         | 770/12825 [2:45:00<42:05:41, 12.57s/it]  6%|▌         | 771/12825 [2:45:13<42:05:58, 12.57s/it]  6%|▌         | 772/12825 [2:45:25<42:06:54, 12.58s/it]  6%|▌         | 773/12825 [2:45:38<42:04:48, 12.57s/it]  6%|▌         | 774/12825 [2:45:50<42:07:21, 12.58s/it]  6%|▌         | 775/12825 [2:46:03<42:07:08, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120369.94lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103548.01lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-775
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-775/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-775/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-750] due to args.save_total_limit
  6%|▌         | 776/12825 [2:46:23<49:49:54, 14.89s/it]  6%|▌         | 777/12825 [2:46:36<47:31:12, 14.20s/it]  6%|▌         | 778/12825 [2:46:49<45:55:42, 13.72s/it]  6%|▌         | 779/12825 [2:47:01<44:48:57, 13.39s/it]  6%|▌         | 780/12825 [2:47:14<43:58:52, 13.15s/it]  6%|▌         | 781/12825 [2:47:26<43:27:52, 12.99s/it]  6%|▌         | 782/12825 [2:47:39<43:03:11, 12.87s/it]  6%|▌         | 783/12825 [2:47:52<42:46:28, 12.79s/it]  6%|▌         | 784/12825 [2:48:04<42:34:52, 12.73s/it]  6%|▌         | 785/12825 [2:48:17<42:24:12, 12.68s/it]  6%|▌         | 786/12825 [2:48:29<42:18:00, 12.65s/it]  6%|▌         | 787/12825 [2:48:42<42:16:47, 12.64s/it]  6%|▌         | 788/12825 [2:48:54<42:11:37, 12.62s/it]  6%|▌         | 789/12825 [2:49:07<42:09:28, 12.61s/it]  6%|▌         | 790/12825 [2:49:20<42:16:29, 12.65s/it]  6%|▌         | 791/12825 [2:49:32<42:13:48, 12.63s/it]  6%|▌         | 792/12825 [2:49:45<42:11:28, 12.62s/it]  6%|▌         | 793/12825 [2:49:58<42:08:49, 12.61s/it]  6%|▌         | 794/12825 [2:50:10<42:07:24, 12.60s/it]  6%|▌         | 795/12825 [2:50:23<42:05:23, 12.60s/it]  6%|▌         | 796/12825 [2:50:35<42:02:06, 12.58s/it]  6%|▌         | 797/12825 [2:50:48<42:00:59, 12.58s/it]  6%|▌         | 798/12825 [2:51:00<41:58:32, 12.56s/it]  6%|▌         | 799/12825 [2:51:13<41:57:20, 12.56s/it]  6%|▌         | 800/12825 [2:51:26<41:58:15, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 119444.54lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 100925.16lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-800
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-800/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-800/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-775] due to args.save_total_limit
  6%|▌         | 801/12825 [2:51:38<42:21:26, 12.68s/it]  6%|▋         | 802/12825 [2:51:51<42:15:48, 12.65s/it]  6%|▋         | 803/12825 [2:52:04<42:11:18, 12.63s/it]  6%|▋         | 804/12825 [2:52:16<42:06:26, 12.61s/it]  6%|▋         | 805/12825 [2:52:29<42:05:17, 12.61s/it]  6%|▋         | 806/12825 [2:52:41<42:04:31, 12.60s/it]  6%|▋         | 807/12825 [2:52:54<42:02:45, 12.59s/it]  6%|▋         | 808/12825 [2:53:14<49:26:10, 14.81s/it]  6%|▋         | 809/12825 [2:53:26<47:10:17, 14.13s/it]  6%|▋         | 810/12825 [2:53:39<45:37:36, 13.67s/it]  6%|▋         | 811/12825 [2:53:52<44:30:26, 13.34s/it]  6%|▋         | 812/12825 [2:54:04<43:44:22, 13.11s/it]  6%|▋         | 813/12825 [2:54:17<43:12:02, 12.95s/it]  6%|▋         | 814/12825 [2:54:29<42:51:24, 12.85s/it]  6%|▋         | 815/12825 [2:54:42<42:33:14, 12.76s/it]  6%|▋         | 816/12825 [2:54:55<42:21:17, 12.70s/it]  6%|▋         | 817/12825 [2:55:07<42:13:53, 12.66s/it]  6%|▋         | 818/12825 [2:55:20<42:10:16, 12.64s/it]  6%|▋         | 819/12825 [2:55:32<42:08:25, 12.64s/it]  6%|▋         | 820/12825 [2:55:45<42:05:04, 12.62s/it]  6%|▋         | 821/12825 [2:55:57<42:01:27, 12.60s/it]  6%|▋         | 822/12825 [2:56:10<41:58:48, 12.59s/it]  6%|▋         | 823/12825 [2:56:23<41:58:18, 12.59s/it]  6%|▋         | 824/12825 [2:56:35<41:57:13, 12.59s/it]  6%|▋         | 825/12825 [2:56:48<41:58:34, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120411.41lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 99322.31lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-825
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-825/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-825/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-800] due to args.save_total_limit
  6%|▋         | 826/12825 [2:57:01<42:29:43, 12.75s/it]  6%|▋         | 827/12825 [2:57:13<42:15:44, 12.68s/it]  6%|▋         | 828/12825 [2:57:26<42:07:56, 12.64s/it]  6%|▋         | 829/12825 [2:57:39<42:03:09, 12.62s/it]  6%|▋         | 830/12825 [2:57:51<41:59:08, 12.60s/it]  6%|▋         | 831/12825 [2:58:04<41:56:14, 12.59s/it]  6%|▋         | 832/12825 [2:58:16<41:55:48, 12.59s/it]  6%|▋         | 833/12825 [2:58:29<41:55:16, 12.58s/it]  7%|▋         | 834/12825 [2:58:41<41:56:17, 12.59s/it]  7%|▋         | 835/12825 [2:58:54<41:55:29, 12.59s/it]  7%|▋         | 836/12825 [2:59:07<41:55:01, 12.59s/it]  7%|▋         | 837/12825 [2:59:19<41:54:33, 12.59s/it]  7%|▋         | 838/12825 [2:59:32<41:52:17, 12.58s/it]  7%|▋         | 839/12825 [2:59:44<41:50:35, 12.57s/it]  7%|▋         | 840/12825 [2:59:57<41:51:51, 12.58s/it]  7%|▋         | 841/12825 [3:00:17<49:31:05, 14.88s/it]  7%|▋         | 842/12825 [3:00:30<47:13:33, 14.19s/it]  7%|▋         | 843/12825 [3:00:42<45:38:23, 13.71s/it]  7%|▋         | 844/12825 [3:00:55<44:30:36, 13.37s/it]  7%|▋         | 845/12825 [3:01:07<43:43:23, 13.14s/it]  7%|▋         | 846/12825 [3:01:20<43:09:55, 12.97s/it]  7%|▋         | 847/12825 [3:01:33<42:46:57, 12.86s/it]  7%|▋         | 848/12825 [3:01:45<42:29:32, 12.77s/it]  7%|▋         | 849/12825 [3:01:58<42:16:32, 12.71s/it]  7%|▋         | 850/12825 [3:02:10<42:07:03, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120413.33lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103598.12lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-850
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-850/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-850/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-825] due to args.save_total_limit
  7%|▋         | 851/12825 [3:02:23<42:19:31, 12.73s/it]  7%|▋         | 852/12825 [3:02:36<42:08:10, 12.67s/it]  7%|▋         | 853/12825 [3:02:48<42:05:10, 12.66s/it]  7%|▋         | 854/12825 [3:03:01<41:58:58, 12.63s/it]  7%|▋         | 855/12825 [3:03:13<41:51:27, 12.59s/it]  7%|▋         | 856/12825 [3:03:26<41:48:27, 12.57s/it]  7%|▋         | 857/12825 [3:03:38<41:43:49, 12.55s/it]  7%|▋         | 858/12825 [3:03:51<41:43:36, 12.55s/it]  7%|▋         | 859/12825 [3:04:04<41:43:32, 12.55s/it]  7%|▋         | 860/12825 [3:04:16<41:42:28, 12.55s/it]  7%|▋         | 861/12825 [3:04:29<41:39:35, 12.54s/it]  7%|▋         | 862/12825 [3:04:41<41:37:15, 12.52s/it]  7%|▋         | 863/12825 [3:04:54<41:38:20, 12.53s/it]  7%|▋         | 864/12825 [3:05:06<41:37:17, 12.53s/it]  7%|▋         | 865/12825 [3:05:19<41:36:07, 12.52s/it]  7%|▋         | 866/12825 [3:05:31<41:36:40, 12.53s/it]  7%|▋         | 867/12825 [3:05:44<41:37:34, 12.53s/it]  7%|▋         | 868/12825 [3:05:56<41:35:32, 12.52s/it]  7%|▋         | 869/12825 [3:06:09<41:36:07, 12.53s/it]  7%|▋         | 870/12825 [3:06:21<41:33:50, 12.52s/it]  7%|▋         | 871/12825 [3:06:34<41:34:49, 12.52s/it]  7%|▋         | 872/12825 [3:06:46<41:36:24, 12.53s/it]  7%|▋         | 873/12825 [3:07:06<48:55:25, 14.74s/it]  7%|▋         | 874/12825 [3:07:19<46:43:25, 14.07s/it]  7%|▋         | 875/12825 [3:07:31<45:11:26, 13.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 117144.06lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 100977.00lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-875
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-875/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-875/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-850] due to args.save_total_limit
  7%|▋         | 876/12825 [3:07:44<44:30:44, 13.41s/it]  7%|▋         | 877/12825 [3:07:57<43:36:56, 13.14s/it]  7%|▋         | 878/12825 [3:08:09<42:59:24, 12.95s/it]  7%|▋         | 879/12825 [3:08:22<42:35:26, 12.83s/it]  7%|▋         | 880/12825 [3:08:34<42:18:51, 12.75s/it]  7%|▋         | 881/12825 [3:08:47<42:06:07, 12.69s/it]  7%|▋         | 882/12825 [3:08:59<41:56:02, 12.64s/it]  7%|▋         | 883/12825 [3:09:12<41:47:54, 12.60s/it]  7%|▋         | 884/12825 [3:09:25<41:45:25, 12.59s/it]  7%|▋         | 885/12825 [3:09:37<41:41:18, 12.57s/it]  7%|▋         | 886/12825 [3:09:50<41:39:30, 12.56s/it]  7%|▋         | 887/12825 [3:10:02<41:40:03, 12.57s/it]  7%|▋         | 888/12825 [3:10:15<41:38:21, 12.56s/it]  7%|▋         | 889/12825 [3:10:27<41:38:48, 12.56s/it]  7%|▋         | 890/12825 [3:10:40<41:36:42, 12.55s/it]  7%|▋         | 891/12825 [3:10:52<41:37:20, 12.56s/it]  7%|▋         | 892/12825 [3:11:05<41:38:11, 12.56s/it]  7%|▋         | 893/12825 [3:11:18<41:38:27, 12.56s/it]  7%|▋         | 894/12825 [3:11:30<41:36:38, 12.56s/it]  7%|▋         | 895/12825 [3:11:43<41:36:25, 12.56s/it]  7%|▋         | 896/12825 [3:11:55<41:34:35, 12.55s/it]  7%|▋         | 897/12825 [3:12:08<41:35:22, 12.55s/it]  7%|▋         | 898/12825 [3:12:20<41:33:39, 12.54s/it]  7%|▋         | 899/12825 [3:12:33<41:31:54, 12.54s/it]  7%|▋         | 900/12825 [3:12:45<41:31:35, 12.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120412.31lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103602.38lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-900
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-900/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-900/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-875] due to args.save_total_limit
  7%|▋         | 901/12825 [3:12:58<41:52:25, 12.64s/it]  7%|▋         | 902/12825 [3:13:11<41:45:00, 12.61s/it]  7%|▋         | 903/12825 [3:13:23<41:37:42, 12.57s/it]  7%|▋         | 904/12825 [3:13:36<41:35:06, 12.56s/it]  7%|▋         | 905/12825 [3:13:48<41:32:23, 12.55s/it]  7%|▋         | 906/12825 [3:14:08<48:47:36, 14.74s/it]  7%|▋         | 907/12825 [3:14:21<46:35:51, 14.08s/it]  7%|▋         | 908/12825 [3:14:33<45:04:05, 13.61s/it]  7%|▋         | 909/12825 [3:14:46<43:58:33, 13.29s/it]  7%|▋         | 910/12825 [3:14:58<43:12:12, 13.05s/it]  7%|▋         | 911/12825 [3:15:11<42:40:13, 12.89s/it]  7%|▋         | 912/12825 [3:15:23<42:21:06, 12.80s/it]  7%|▋         | 913/12825 [3:15:36<42:03:58, 12.71s/it]  7%|▋         | 914/12825 [3:15:48<41:52:25, 12.66s/it]  7%|▋         | 915/12825 [3:16:01<41:44:55, 12.62s/it]  7%|▋         | 916/12825 [3:16:13<41:40:20, 12.60s/it]  7%|▋         | 917/12825 [3:16:26<41:39:55, 12.60s/it]  7%|▋         | 918/12825 [3:16:39<41:36:16, 12.58s/it]  7%|▋         | 919/12825 [3:16:51<41:32:47, 12.56s/it]  7%|▋         | 920/12825 [3:17:04<41:32:04, 12.56s/it]  7%|▋         | 921/12825 [3:17:16<41:32:08, 12.56s/it]  7%|▋         | 922/12825 [3:17:29<41:30:52, 12.56s/it]  7%|▋         | 923/12825 [3:17:41<41:31:51, 12.56s/it]  7%|▋         | 924/12825 [3:17:54<41:32:07, 12.56s/it]  7%|▋         | 925/12825 [3:18:06<41:30:17, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120437.92lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103557.47lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-925
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-925/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-925/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-900] due to args.save_total_limit
  7%|▋         | 926/12825 [3:18:19<41:50:52, 12.66s/it]  7%|▋         | 927/12825 [3:18:32<41:46:04, 12.64s/it]  7%|▋         | 928/12825 [3:18:44<41:40:00, 12.61s/it]  7%|▋         | 929/12825 [3:18:57<41:36:37, 12.59s/it]  7%|▋         | 930/12825 [3:19:10<41:33:15, 12.58s/it]  7%|▋         | 931/12825 [3:19:22<41:30:55, 12.57s/it]  7%|▋         | 932/12825 [3:19:35<41:28:27, 12.55s/it]  7%|▋         | 933/12825 [3:19:47<41:26:31, 12.55s/it]  7%|▋         | 934/12825 [3:20:00<41:27:29, 12.55s/it]  7%|▋         | 935/12825 [3:20:12<41:26:06, 12.55s/it]  7%|▋         | 936/12825 [3:20:25<41:20:52, 12.52s/it]  7%|▋         | 937/12825 [3:20:37<41:20:10, 12.52s/it]  7%|▋         | 938/12825 [3:20:57<48:57:21, 14.83s/it]  7%|▋         | 939/12825 [3:21:10<46:41:53, 14.14s/it]  7%|▋         | 940/12825 [3:21:23<45:07:13, 13.67s/it]  7%|▋         | 941/12825 [3:21:35<43:58:15, 13.32s/it]  7%|▋         | 942/12825 [3:21:48<43:11:23, 13.08s/it]  7%|▋         | 943/12825 [3:22:00<42:40:15, 12.93s/it]  7%|▋         | 944/12825 [3:22:13<42:16:21, 12.81s/it]  7%|▋         | 945/12825 [3:22:25<42:00:43, 12.73s/it]  7%|▋         | 946/12825 [3:22:38<41:50:02, 12.68s/it]  7%|▋         | 947/12825 [3:22:50<41:40:51, 12.63s/it]  7%|▋         | 948/12825 [3:23:03<41:35:45, 12.61s/it]  7%|▋         | 949/12825 [3:23:15<41:32:31, 12.59s/it]  7%|▋         | 950/12825 [3:23:28<41:29:57, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120321.73lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103505.98lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-950
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-950/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-950/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-925] due to args.save_total_limit
  7%|▋         | 951/12825 [3:23:41<41:47:43, 12.67s/it]  7%|▋         | 952/12825 [3:23:53<41:37:00, 12.62s/it]  7%|▋         | 953/12825 [3:24:06<41:35:26, 12.61s/it]  7%|▋         | 954/12825 [3:24:18<41:30:38, 12.59s/it]  7%|▋         | 955/12825 [3:24:31<41:28:44, 12.58s/it]  7%|▋         | 956/12825 [3:24:44<41:24:07, 12.56s/it]  7%|▋         | 957/12825 [3:24:56<41:22:20, 12.55s/it]  7%|▋         | 958/12825 [3:25:09<41:22:09, 12.55s/it]  7%|▋         | 959/12825 [3:25:21<41:23:48, 12.56s/it]  7%|▋         | 960/12825 [3:25:34<41:22:54, 12.56s/it]  7%|▋         | 961/12825 [3:25:46<41:22:47, 12.56s/it]  8%|▊         | 962/12825 [3:25:59<41:20:01, 12.54s/it]  8%|▊         | 963/12825 [3:26:11<41:19:52, 12.54s/it]  8%|▊         | 964/12825 [3:26:24<41:17:51, 12.53s/it]  8%|▊         | 965/12825 [3:26:36<41:17:23, 12.53s/it]  8%|▊         | 966/12825 [3:26:49<41:19:29, 12.54s/it]  8%|▊         | 967/12825 [3:27:02<41:18:38, 12.54s/it]  8%|▊         | 968/12825 [3:27:14<41:16:55, 12.53s/it]  8%|▊         | 969/12825 [3:27:27<41:18:28, 12.54s/it]  8%|▊         | 970/12825 [3:27:47<48:37:22, 14.77s/it]  8%|▊         | 971/12825 [3:27:59<46:26:28, 14.10s/it]  8%|▊         | 972/12825 [3:28:12<44:55:48, 13.65s/it]  8%|▊         | 973/12825 [3:28:24<43:45:55, 13.29s/it]  8%|▊         | 974/12825 [3:28:37<43:00:38, 13.07s/it]  8%|▊         | 975/12825 [3:28:49<42:30:56, 12.92s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120427.67lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103624.18lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-975
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-975/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-975/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-950] due to args.save_total_limit
  8%|▊         | 976/12825 [3:29:02<42:31:58, 12.92s/it]  8%|▊         | 977/12825 [3:29:15<42:10:35, 12.82s/it]  8%|▊         | 978/12825 [3:29:27<41:54:55, 12.74s/it]  8%|▊         | 979/12825 [3:29:40<41:40:29, 12.66s/it]  8%|▊         | 980/12825 [3:29:52<41:32:28, 12.63s/it]  8%|▊         | 981/12825 [3:30:05<41:25:50, 12.59s/it]  8%|▊         | 982/12825 [3:30:17<41:22:40, 12.58s/it]  8%|▊         | 983/12825 [3:30:30<41:19:52, 12.56s/it]  8%|▊         | 984/12825 [3:30:43<41:20:50, 12.57s/it]  8%|▊         | 985/12825 [3:30:55<41:18:49, 12.56s/it]  8%|▊         | 986/12825 [3:31:08<41:16:25, 12.55s/it]  8%|▊         | 987/12825 [3:31:20<41:16:19, 12.55s/it]  8%|▊         | 988/12825 [3:31:33<41:16:20, 12.55s/it]  8%|▊         | 989/12825 [3:31:45<41:15:21, 12.55s/it]  8%|▊         | 990/12825 [3:31:58<41:15:41, 12.55s/it]  8%|▊         | 991/12825 [3:32:10<41:15:42, 12.55s/it]  8%|▊         | 992/12825 [3:32:23<41:15:57, 12.55s/it]  8%|▊         | 993/12825 [3:32:35<41:15:48, 12.55s/it]  8%|▊         | 994/12825 [3:32:48<41:12:50, 12.54s/it]  8%|▊         | 995/12825 [3:33:01<41:12:33, 12.54s/it]  8%|▊         | 996/12825 [3:33:13<41:13:59, 12.55s/it]  8%|▊         | 997/12825 [3:33:26<41:15:06, 12.56s/it]  8%|▊         | 998/12825 [3:33:38<41:13:26, 12.55s/it]  8%|▊         | 999/12825 [3:33:51<41:12:02, 12.54s/it]  8%|▊         | 1000/12825 [3:34:03<41:12:05, 12.54s/it]                                                           8%|▊         | 1000/12825 [3:34:03<41:12:05, 12.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120436.00lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103593.95lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1000
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1000/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1000/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-975] due to args.save_total_limit
  8%|▊         | 1001/12825 [3:34:16<41:31:36, 12.64s/it]  8%|▊         | 1002/12825 [3:34:29<41:24:33, 12.61s/it]  8%|▊         | 1003/12825 [3:34:49<48:50:17, 14.87s/it]  8%|▊         | 1004/12825 [3:35:01<46:33:09, 14.18s/it]  8%|▊         | 1005/12825 [3:35:14<44:56:24, 13.69s/it]  8%|▊         | 1006/12825 [3:35:27<44:18:53, 13.50s/it]  8%|▊         | 1007/12825 [3:35:40<43:24:14, 13.22s/it]  8%|▊         | 1008/12825 [3:35:52<42:46:53, 13.03s/it]  8%|▊         | 1009/12825 [3:36:05<42:16:27, 12.88s/it]  8%|▊         | 1010/12825 [3:36:17<41:57:05, 12.78s/it]  8%|▊         | 1011/12825 [3:36:30<41:46:03, 12.73s/it]  8%|▊         | 1012/12825 [3:36:42<41:36:08, 12.68s/it]  8%|▊         | 1013/12825 [3:36:55<41:27:32, 12.64s/it]  8%|▊         | 1014/12825 [3:37:07<41:23:10, 12.61s/it]  8%|▊         | 1015/12825 [3:37:20<41:18:45, 12.59s/it]  8%|▊         | 1016/12825 [3:37:33<41:16:12, 12.58s/it]  8%|▊         | 1017/12825 [3:37:45<41:15:09, 12.58s/it]  8%|▊         | 1018/12825 [3:37:58<41:14:45, 12.58s/it]  8%|▊         | 1019/12825 [3:38:10<41:14:12, 12.57s/it]  8%|▊         | 1020/12825 [3:38:23<41:12:59, 12.57s/it]  8%|▊         | 1021/12825 [3:38:35<41:12:00, 12.57s/it]  8%|▊         | 1022/12825 [3:38:48<41:08:14, 12.55s/it]  8%|▊         | 1023/12825 [3:39:00<41:06:20, 12.54s/it]  8%|▊         | 1024/12825 [3:39:13<41:06:51, 12.54s/it]  8%|▊         | 1025/12825 [3:39:21<36:31:14, 11.14s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120308.56lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103527.75lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1025
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1025/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1025/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1000] due to args.save_total_limit
  8%|▊         | 1026/12825 [3:39:22<26:45:00,  8.16s/it]  8%|▊         | 1027/12825 [3:39:48<43:45:34, 13.35s/it]  8%|▊         | 1028/12825 [3:40:00<42:58:27, 13.11s/it]  8%|▊         | 1029/12825 [3:40:13<42:26:39, 12.95s/it]  8%|▊         | 1030/12825 [3:40:25<42:03:41, 12.84s/it]  8%|▊         | 1031/12825 [3:40:38<41:47:57, 12.76s/it]  8%|▊         | 1032/12825 [3:40:50<41:34:47, 12.69s/it]  8%|▊         | 1033/12825 [3:41:03<41:26:09, 12.65s/it]  8%|▊         | 1034/12825 [3:41:15<41:19:35, 12.62s/it]  8%|▊         | 1035/12825 [3:41:36<48:57:11, 14.95s/it]  8%|▊         | 1036/12825 [3:41:48<46:37:12, 14.24s/it]  8%|▊         | 1037/12825 [3:42:01<44:56:05, 13.72s/it]  8%|▊         | 1038/12825 [3:42:13<43:46:55, 13.37s/it]  8%|▊         | 1039/12825 [3:42:26<42:58:31, 13.13s/it]  8%|▊         | 1040/12825 [3:42:39<42:25:55, 12.96s/it]  8%|▊         | 1041/12825 [3:42:51<42:01:26, 12.84s/it]  8%|▊         | 1042/12825 [3:43:04<41:44:49, 12.75s/it]  8%|▊         | 1043/12825 [3:43:16<41:31:45, 12.69s/it]  8%|▊         | 1044/12825 [3:43:29<41:24:52, 12.66s/it]  8%|▊         | 1045/12825 [3:43:41<41:17:32, 12.62s/it]  8%|▊         | 1046/12825 [3:43:54<41:11:59, 12.59s/it]  8%|▊         | 1047/12825 [3:44:06<41:09:46, 12.58s/it]  8%|▊         | 1048/12825 [3:44:19<41:09:46, 12.58s/it]  8%|▊         | 1049/12825 [3:44:32<41:08:33, 12.58s/it]  8%|▊         | 1050/12825 [3:44:44<41:06:47, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120402.83lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103621.34lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1050
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1050/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1050/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-25] due to args.save_total_limit
  8%|▊         | 1051/12825 [3:44:57<41:26:34, 12.67s/it]  8%|▊         | 1052/12825 [3:45:10<41:18:49, 12.63s/it]  8%|▊         | 1053/12825 [3:45:22<41:12:17, 12.60s/it]  8%|▊         | 1054/12825 [3:45:35<41:11:12, 12.60s/it]  8%|▊         | 1055/12825 [3:45:47<41:07:59, 12.58s/it]  8%|▊         | 1056/12825 [3:46:00<41:08:26, 12.58s/it]  8%|▊         | 1057/12825 [3:46:12<41:07:10, 12.58s/it]  8%|▊         | 1058/12825 [3:46:25<41:05:48, 12.57s/it]  8%|▊         | 1059/12825 [3:46:38<41:07:01, 12.58s/it]  8%|▊         | 1060/12825 [3:46:50<41:06:19, 12.58s/it]  8%|▊         | 1061/12825 [3:47:03<41:04:56, 12.57s/it]  8%|▊         | 1062/12825 [3:47:15<41:03:42, 12.57s/it]  8%|▊         | 1063/12825 [3:47:28<41:04:28, 12.57s/it]  8%|▊         | 1064/12825 [3:47:40<41:03:27, 12.57s/it]  8%|▊         | 1065/12825 [3:47:53<41:03:41, 12.57s/it]  8%|▊         | 1066/12825 [3:48:06<41:02:56, 12.57s/it]  8%|▊         | 1067/12825 [3:48:18<41:03:39, 12.57s/it]  8%|▊         | 1068/12825 [3:48:39<49:03:05, 15.02s/it]  8%|▊         | 1069/12825 [3:48:51<46:37:31, 14.28s/it]  8%|▊         | 1070/12825 [3:49:04<44:59:27, 13.78s/it]  8%|▊         | 1071/12825 [3:49:17<43:49:44, 13.42s/it]  8%|▊         | 1072/12825 [3:49:29<43:02:08, 13.18s/it]  8%|▊         | 1073/12825 [3:49:42<42:27:57, 13.01s/it]  8%|▊         | 1074/12825 [3:49:54<42:03:31, 12.88s/it]  8%|▊         | 1075/12825 [3:50:07<41:45:05, 12.79s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120421.78lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103617.83lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1075
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1075/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1075/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1025] due to args.save_total_limit
  8%|▊         | 1076/12825 [3:50:20<41:51:09, 12.82s/it]  8%|▊         | 1077/12825 [3:50:32<41:34:33, 12.74s/it]  8%|▊         | 1078/12825 [3:50:45<41:24:14, 12.69s/it]  8%|▊         | 1079/12825 [3:50:58<41:16:22, 12.65s/it]  8%|▊         | 1080/12825 [3:51:10<41:11:25, 12.63s/it]  8%|▊         | 1081/12825 [3:51:23<41:08:21, 12.61s/it]  8%|▊         | 1082/12825 [3:51:35<41:05:07, 12.60s/it]  8%|▊         | 1083/12825 [3:51:48<41:02:12, 12.58s/it]  8%|▊         | 1084/12825 [3:52:00<41:00:04, 12.57s/it]  8%|▊         | 1085/12825 [3:52:13<40:59:04, 12.57s/it]  8%|▊         | 1086/12825 [3:52:25<40:56:31, 12.56s/it]  8%|▊         | 1087/12825 [3:52:38<40:55:59, 12.55s/it]  8%|▊         | 1088/12825 [3:52:51<40:56:33, 12.56s/it]  8%|▊         | 1089/12825 [3:53:03<40:54:46, 12.55s/it]  8%|▊         | 1090/12825 [3:53:16<40:52:26, 12.54s/it]  9%|▊         | 1091/12825 [3:53:28<40:52:05, 12.54s/it]  9%|▊         | 1092/12825 [3:53:41<40:50:28, 12.53s/it]  9%|▊         | 1093/12825 [3:53:53<40:49:44, 12.53s/it]  9%|▊         | 1094/12825 [3:54:06<40:49:44, 12.53s/it]  9%|▊         | 1095/12825 [3:54:18<41:03:13, 12.60s/it]  9%|▊         | 1096/12825 [3:54:31<41:05:05, 12.61s/it]  9%|▊         | 1097/12825 [3:54:44<41:00:40, 12.59s/it]  9%|▊         | 1098/12825 [3:54:56<40:59:49, 12.59s/it]  9%|▊         | 1099/12825 [3:55:09<40:58:43, 12.58s/it]  9%|▊         | 1100/12825 [3:55:29<48:35:44, 14.92s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120387.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103594.89lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1050] due to args.save_total_limit
  9%|▊         | 1101/12825 [3:55:42<46:37:46, 14.32s/it]  9%|▊         | 1102/12825 [3:55:55<44:54:49, 13.79s/it]  9%|▊         | 1103/12825 [3:56:07<43:41:05, 13.42s/it]  9%|▊         | 1104/12825 [3:56:20<42:52:30, 13.17s/it]  9%|▊         | 1105/12825 [3:56:32<42:17:06, 12.99s/it]  9%|▊         | 1106/12825 [3:56:45<41:53:08, 12.87s/it]  9%|▊         | 1107/12825 [3:56:58<41:34:32, 12.77s/it]  9%|▊         | 1108/12825 [3:57:10<41:21:44, 12.71s/it]  9%|▊         | 1109/12825 [3:57:23<41:13:20, 12.67s/it]  9%|▊         | 1110/12825 [3:57:35<41:06:59, 12.64s/it]  9%|▊         | 1111/12825 [3:57:48<41:02:41, 12.61s/it]  9%|▊         | 1112/12825 [3:58:00<41:01:42, 12.61s/it]  9%|▊         | 1113/12825 [3:58:13<40:58:18, 12.59s/it]  9%|▊         | 1114/12825 [3:58:25<40:55:29, 12.58s/it]  9%|▊         | 1115/12825 [3:58:38<40:53:17, 12.57s/it]  9%|▊         | 1116/12825 [3:58:51<40:54:31, 12.58s/it]  9%|▊         | 1117/12825 [3:59:03<40:55:30, 12.58s/it]  9%|▊         | 1118/12825 [3:59:16<40:57:14, 12.59s/it]  9%|▊         | 1119/12825 [3:59:28<40:56:33, 12.59s/it]  9%|▊         | 1120/12825 [3:59:41<40:54:12, 12.58s/it]  9%|▊         | 1121/12825 [3:59:54<40:53:06, 12.58s/it]  9%|▊         | 1122/12825 [4:00:06<40:52:59, 12.58s/it]  9%|▉         | 1123/12825 [4:00:19<40:51:07, 12.57s/it]  9%|▉         | 1124/12825 [4:00:31<40:50:37, 12.57s/it]  9%|▉         | 1125/12825 [4:00:44<40:51:41, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120403.22lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103632.53lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1075] due to args.save_total_limit
  9%|▉         | 1126/12825 [4:00:57<41:10:11, 12.67s/it]  9%|▉         | 1127/12825 [4:01:09<41:02:54, 12.63s/it]  9%|▉         | 1128/12825 [4:01:22<40:58:36, 12.61s/it]  9%|▉         | 1129/12825 [4:01:34<40:55:27, 12.60s/it]  9%|▉         | 1130/12825 [4:01:47<40:51:41, 12.58s/it]  9%|▉         | 1131/12825 [4:01:59<40:49:52, 12.57s/it]  9%|▉         | 1132/12825 [4:02:12<40:47:07, 12.56s/it]  9%|▉         | 1133/12825 [4:02:33<48:43:52, 15.00s/it]  9%|▉         | 1134/12825 [4:02:45<46:20:07, 14.27s/it]  9%|▉         | 1135/12825 [4:02:58<44:42:38, 13.77s/it]  9%|▉         | 1136/12825 [4:03:10<43:32:00, 13.41s/it]  9%|▉         | 1137/12825 [4:03:23<42:41:53, 13.15s/it]  9%|▉         | 1138/12825 [4:03:36<42:06:02, 12.97s/it]  9%|▉         | 1139/12825 [4:03:48<41:43:05, 12.85s/it]  9%|▉         | 1140/12825 [4:04:01<41:24:27, 12.76s/it]  9%|▉         | 1141/12825 [4:04:13<41:12:04, 12.69s/it]  9%|▉         | 1142/12825 [4:04:26<41:05:48, 12.66s/it]  9%|▉         | 1143/12825 [4:04:38<41:02:34, 12.65s/it]  9%|▉         | 1144/12825 [4:04:51<40:58:05, 12.63s/it]  9%|▉         | 1145/12825 [4:05:04<40:56:48, 12.62s/it]  9%|▉         | 1146/12825 [4:05:16<40:53:29, 12.60s/it]  9%|▉         | 1147/12825 [4:05:29<40:50:14, 12.59s/it]  9%|▉         | 1148/12825 [4:05:41<40:50:28, 12.59s/it]  9%|▉         | 1149/12825 [4:05:54<40:49:59, 12.59s/it]  9%|▉         | 1150/12825 [4:06:06<40:48:49, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120224.01lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103447.74lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1100] due to args.save_total_limit
  9%|▉         | 1151/12825 [4:06:19<41:08:06, 12.69s/it]  9%|▉         | 1152/12825 [4:06:32<41:02:23, 12.66s/it]  9%|▉         | 1153/12825 [4:06:45<40:57:29, 12.63s/it]  9%|▉         | 1154/12825 [4:06:57<40:56:19, 12.63s/it]  9%|▉         | 1155/12825 [4:07:10<40:52:02, 12.61s/it]  9%|▉         | 1156/12825 [4:07:22<40:49:11, 12.59s/it]  9%|▉         | 1157/12825 [4:07:35<40:47:27, 12.59s/it]  9%|▉         | 1158/12825 [4:07:47<40:48:12, 12.59s/it]  9%|▉         | 1159/12825 [4:08:00<40:46:33, 12.58s/it]  9%|▉         | 1160/12825 [4:08:13<40:45:45, 12.58s/it]  9%|▉         | 1161/12825 [4:08:25<40:43:19, 12.57s/it]  9%|▉         | 1162/12825 [4:08:38<40:43:00, 12.57s/it]  9%|▉         | 1163/12825 [4:08:50<40:42:56, 12.57s/it]  9%|▉         | 1164/12825 [4:09:03<40:42:57, 12.57s/it]  9%|▉         | 1165/12825 [4:09:23<48:19:46, 14.92s/it]  9%|▉         | 1166/12825 [4:09:36<46:03:38, 14.22s/it]  9%|▉         | 1167/12825 [4:09:48<44:29:04, 13.74s/it]  9%|▉         | 1168/12825 [4:10:01<43:21:33, 13.39s/it]  9%|▉         | 1169/12825 [4:10:14<42:33:50, 13.15s/it]  9%|▉         | 1170/12825 [4:10:26<42:00:45, 12.98s/it]  9%|▉         | 1171/12825 [4:10:39<41:36:19, 12.85s/it]  9%|▉         | 1172/12825 [4:10:51<41:20:51, 12.77s/it]  9%|▉         | 1173/12825 [4:11:04<41:09:02, 12.71s/it]  9%|▉         | 1174/12825 [4:11:16<41:00:39, 12.67s/it]  9%|▉         | 1175/12825 [4:11:29<40:51:33, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120442.02lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103629.78lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1125] due to args.save_total_limit
  9%|▉         | 1176/12825 [4:11:42<41:10:11, 12.72s/it]  9%|▉         | 1177/12825 [4:11:54<41:00:02, 12.67s/it]  9%|▉         | 1178/12825 [4:12:07<40:55:25, 12.65s/it]  9%|▉         | 1179/12825 [4:12:20<40:49:45, 12.62s/it]  9%|▉         | 1180/12825 [4:12:32<40:48:16, 12.61s/it]  9%|▉         | 1181/12825 [4:12:45<40:47:38, 12.61s/it]  9%|▉         | 1182/12825 [4:12:57<40:45:44, 12.60s/it]  9%|▉         | 1183/12825 [4:13:10<40:45:37, 12.60s/it]  9%|▉         | 1184/12825 [4:13:23<40:44:44, 12.60s/it]  9%|▉         | 1185/12825 [4:13:35<40:43:46, 12.60s/it]  9%|▉         | 1186/12825 [4:13:48<40:41:53, 12.59s/it]  9%|▉         | 1187/12825 [4:14:00<40:41:11, 12.59s/it]  9%|▉         | 1188/12825 [4:14:13<40:41:04, 12.59s/it]  9%|▉         | 1189/12825 [4:14:25<40:39:07, 12.58s/it]  9%|▉         | 1190/12825 [4:14:38<40:39:09, 12.58s/it]  9%|▉         | 1191/12825 [4:14:51<40:40:00, 12.58s/it]  9%|▉         | 1192/12825 [4:15:03<40:40:07, 12.59s/it]  9%|▉         | 1193/12825 [4:15:16<40:39:10, 12.58s/it]  9%|▉         | 1194/12825 [4:15:28<40:38:50, 12.58s/it]  9%|▉         | 1195/12825 [4:15:41<40:38:00, 12.58s/it]  9%|▉         | 1196/12825 [4:15:54<40:35:48, 12.57s/it]  9%|▉         | 1197/12825 [4:16:15<48:46:25, 15.10s/it]  9%|▉         | 1198/12825 [4:16:27<46:17:45, 14.33s/it]  9%|▉         | 1199/12825 [4:16:40<44:31:41, 13.79s/it]  9%|▉         | 1200/12825 [4:16:52<43:21:07, 13.43s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120411.67lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103618.50lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1150] due to args.save_total_limit
  9%|▉         | 1201/12825 [4:17:05<42:51:46, 13.27s/it]  9%|▉         | 1202/12825 [4:17:18<42:09:40, 13.06s/it]  9%|▉         | 1203/12825 [4:17:30<41:39:59, 12.91s/it]  9%|▉         | 1204/12825 [4:17:43<41:20:28, 12.81s/it]  9%|▉         | 1205/12825 [4:17:55<41:06:54, 12.74s/it]  9%|▉         | 1206/12825 [4:18:08<40:57:13, 12.69s/it]  9%|▉         | 1207/12825 [4:18:21<40:50:28, 12.66s/it]  9%|▉         | 1208/12825 [4:18:33<40:44:28, 12.63s/it]  9%|▉         | 1209/12825 [4:18:46<40:41:25, 12.61s/it]  9%|▉         | 1210/12825 [4:18:58<40:40:52, 12.61s/it]  9%|▉         | 1211/12825 [4:19:11<40:38:56, 12.60s/it]  9%|▉         | 1212/12825 [4:19:23<40:37:25, 12.59s/it]  9%|▉         | 1213/12825 [4:19:36<40:36:28, 12.59s/it]  9%|▉         | 1214/12825 [4:19:49<40:36:49, 12.59s/it]  9%|▉         | 1215/12825 [4:20:01<40:35:09, 12.58s/it]  9%|▉         | 1216/12825 [4:20:14<40:32:47, 12.57s/it]  9%|▉         | 1217/12825 [4:20:26<40:30:57, 12.57s/it]  9%|▉         | 1218/12825 [4:20:39<40:29:44, 12.56s/it] 10%|▉         | 1219/12825 [4:20:51<40:31:33, 12.57s/it] 10%|▉         | 1220/12825 [4:21:04<40:29:13, 12.56s/it] 10%|▉         | 1221/12825 [4:21:16<40:29:35, 12.56s/it] 10%|▉         | 1222/12825 [4:21:29<40:30:09, 12.57s/it] 10%|▉         | 1223/12825 [4:21:42<40:29:30, 12.56s/it] 10%|▉         | 1224/12825 [4:21:54<40:30:56, 12.57s/it] 10%|▉         | 1225/12825 [4:22:07<40:28:10, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120493.02lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103605.60lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1175] due to args.save_total_limit
 10%|▉         | 1226/12825 [4:22:20<40:46:22, 12.65s/it] 10%|▉         | 1227/12825 [4:22:32<40:39:59, 12.62s/it] 10%|▉         | 1228/12825 [4:22:45<40:35:47, 12.60s/it] 10%|▉         | 1229/12825 [4:22:57<40:36:36, 12.61s/it] 10%|▉         | 1230/12825 [4:23:18<48:09:12, 14.95s/it] 10%|▉         | 1231/12825 [4:23:30<45:50:03, 14.23s/it] 10%|▉         | 1232/12825 [4:23:43<44:10:45, 13.72s/it] 10%|▉         | 1233/12825 [4:23:55<43:05:35, 13.38s/it] 10%|▉         | 1234/12825 [4:24:08<42:19:03, 13.14s/it] 10%|▉         | 1235/12825 [4:24:21<41:45:41, 12.97s/it] 10%|▉         | 1236/12825 [4:24:33<41:23:08, 12.86s/it] 10%|▉         | 1237/12825 [4:24:46<41:06:19, 12.77s/it] 10%|▉         | 1238/12825 [4:24:58<40:55:16, 12.71s/it] 10%|▉         | 1239/12825 [4:25:11<40:48:30, 12.68s/it] 10%|▉         | 1240/12825 [4:25:24<40:42:59, 12.65s/it] 10%|▉         | 1241/12825 [4:25:36<40:35:54, 12.62s/it] 10%|▉         | 1242/12825 [4:25:49<40:31:31, 12.60s/it] 10%|▉         | 1243/12825 [4:26:01<40:31:20, 12.60s/it] 10%|▉         | 1244/12825 [4:26:14<40:28:26, 12.58s/it] 10%|▉         | 1245/12825 [4:26:26<40:26:36, 12.57s/it] 10%|▉         | 1246/12825 [4:26:39<40:24:28, 12.56s/it] 10%|▉         | 1247/12825 [4:26:51<40:24:03, 12.56s/it] 10%|▉         | 1248/12825 [4:27:04<40:26:51, 12.58s/it] 10%|▉         | 1249/12825 [4:27:17<40:26:10, 12.58s/it] 10%|▉         | 1250/12825 [4:27:29<40:26:22, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120480.97lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103692.50lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1200] due to args.save_total_limit
 10%|▉         | 1251/12825 [4:27:42<40:47:24, 12.69s/it] 10%|▉         | 1252/12825 [4:27:55<40:39:08, 12.65s/it] 10%|▉         | 1253/12825 [4:28:07<40:34:19, 12.62s/it] 10%|▉         | 1254/12825 [4:28:20<40:30:47, 12.60s/it] 10%|▉         | 1255/12825 [4:28:32<40:27:16, 12.59s/it] 10%|▉         | 1256/12825 [4:28:45<40:25:18, 12.58s/it] 10%|▉         | 1257/12825 [4:28:57<40:26:07, 12.58s/it] 10%|▉         | 1258/12825 [4:29:10<40:26:31, 12.59s/it] 10%|▉         | 1259/12825 [4:29:23<40:27:03, 12.59s/it] 10%|▉         | 1260/12825 [4:29:35<40:25:16, 12.58s/it] 10%|▉         | 1261/12825 [4:29:48<40:23:58, 12.58s/it] 10%|▉         | 1262/12825 [4:30:08<47:55:57, 14.92s/it] 10%|▉         | 1263/12825 [4:30:21<45:40:23, 14.22s/it] 10%|▉         | 1264/12825 [4:30:33<44:05:06, 13.73s/it] 10%|▉         | 1265/12825 [4:30:46<42:57:12, 13.38s/it] 10%|▉         | 1266/12825 [4:30:59<42:11:56, 13.14s/it] 10%|▉         | 1267/12825 [4:31:11<41:39:16, 12.97s/it] 10%|▉         | 1268/12825 [4:31:24<41:18:16, 12.87s/it] 10%|▉         | 1269/12825 [4:31:36<41:04:00, 12.79s/it] 10%|▉         | 1270/12825 [4:31:49<40:50:32, 12.72s/it] 10%|▉         | 1271/12825 [4:32:01<40:42:32, 12.68s/it] 10%|▉         | 1272/12825 [4:32:14<40:36:19, 12.65s/it] 10%|▉         | 1273/12825 [4:32:27<40:32:19, 12.63s/it] 10%|▉         | 1274/12825 [4:32:39<40:27:52, 12.61s/it] 10%|▉         | 1275/12825 [4:32:52<40:24:42, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120464.82lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103665.16lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1225] due to args.save_total_limit
 10%|▉         | 1276/12825 [4:33:05<40:43:09, 12.69s/it] 10%|▉         | 1277/12825 [4:33:17<40:32:19, 12.64s/it] 10%|▉         | 1278/12825 [4:33:30<40:26:09, 12.61s/it] 10%|▉         | 1279/12825 [4:33:42<40:21:41, 12.58s/it] 10%|▉         | 1280/12825 [4:33:55<40:19:14, 12.57s/it] 10%|▉         | 1281/12825 [4:34:07<40:18:53, 12.57s/it] 10%|▉         | 1282/12825 [4:34:20<40:18:18, 12.57s/it] 10%|█         | 1283/12825 [4:34:33<40:18:10, 12.57s/it] 10%|█         | 1284/12825 [4:34:45<40:20:21, 12.58s/it] 10%|█         | 1285/12825 [4:34:58<40:16:41, 12.57s/it] 10%|█         | 1286/12825 [4:35:10<40:15:37, 12.56s/it] 10%|█         | 1287/12825 [4:35:23<40:14:05, 12.55s/it] 10%|█         | 1288/12825 [4:35:35<40:15:44, 12.56s/it] 10%|█         | 1289/12825 [4:35:48<40:15:03, 12.56s/it] 10%|█         | 1290/12825 [4:36:00<40:11:40, 12.54s/it] 10%|█         | 1291/12825 [4:36:13<40:14:59, 12.56s/it] 10%|█         | 1292/12825 [4:36:26<40:17:00, 12.57s/it] 10%|█         | 1293/12825 [4:36:38<40:18:39, 12.58s/it] 10%|█         | 1294/12825 [4:36:59<47:46:30, 14.92s/it] 10%|█         | 1295/12825 [4:37:11<45:28:35, 14.20s/it] 10%|█         | 1296/12825 [4:37:24<43:52:36, 13.70s/it] 10%|█         | 1297/12825 [4:37:36<42:45:37, 13.35s/it] 10%|█         | 1298/12825 [4:37:49<42:00:45, 13.12s/it] 10%|█         | 1299/12825 [4:38:01<41:30:56, 12.97s/it] 10%|█         | 1300/12825 [4:38:14<41:10:01, 12.86s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120445.22lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103649.03lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1250] due to args.save_total_limit
 10%|█         | 1301/12825 [4:38:27<41:13:33, 12.88s/it] 10%|█         | 1302/12825 [4:38:39<40:55:55, 12.79s/it] 10%|█         | 1303/12825 [4:38:52<40:41:40, 12.71s/it] 10%|█         | 1304/12825 [4:39:05<40:35:24, 12.68s/it] 10%|█         | 1305/12825 [4:39:17<40:27:55, 12.65s/it] 10%|█         | 1306/12825 [4:39:30<40:25:45, 12.64s/it] 10%|█         | 1307/12825 [4:39:42<40:21:32, 12.61s/it] 10%|█         | 1308/12825 [4:39:55<40:21:21, 12.61s/it] 10%|█         | 1309/12825 [4:40:08<40:19:04, 12.60s/it] 10%|█         | 1310/12825 [4:40:20<40:15:39, 12.59s/it] 10%|█         | 1311/12825 [4:40:33<40:13:13, 12.58s/it] 10%|█         | 1312/12825 [4:40:45<40:11:37, 12.57s/it] 10%|█         | 1313/12825 [4:40:58<40:11:22, 12.57s/it] 10%|█         | 1314/12825 [4:41:10<40:12:14, 12.57s/it] 10%|█         | 1315/12825 [4:41:23<40:11:52, 12.57s/it] 10%|█         | 1316/12825 [4:41:36<40:11:52, 12.57s/it] 10%|█         | 1317/12825 [4:41:48<40:10:28, 12.57s/it] 10%|█         | 1318/12825 [4:42:01<40:11:34, 12.57s/it] 10%|█         | 1319/12825 [4:42:13<40:09:29, 12.56s/it] 10%|█         | 1320/12825 [4:42:26<40:09:56, 12.57s/it] 10%|█         | 1321/12825 [4:42:38<40:08:06, 12.56s/it] 10%|█         | 1322/12825 [4:42:51<40:09:51, 12.57s/it] 10%|█         | 1323/12825 [4:43:03<40:07:50, 12.56s/it] 10%|█         | 1324/12825 [4:43:16<40:09:23, 12.57s/it] 10%|█         | 1325/12825 [4:43:29<40:06:33, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 117078.66lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101099.87lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1275] due to args.save_total_limit
 10%|█         | 1326/12825 [4:43:41<40:27:50, 12.67s/it] 10%|█         | 1327/12825 [4:44:02<47:37:48, 14.91s/it] 10%|█         | 1328/12825 [4:44:14<45:23:14, 14.21s/it] 10%|█         | 1329/12825 [4:44:27<43:47:59, 13.72s/it] 10%|█         | 1330/12825 [4:44:39<42:42:52, 13.38s/it] 10%|█         | 1331/12825 [4:44:52<41:54:14, 13.12s/it] 10%|█         | 1332/12825 [4:45:04<41:19:31, 12.94s/it] 10%|█         | 1333/12825 [4:45:17<40:57:32, 12.83s/it] 10%|█         | 1334/12825 [4:45:30<40:41:56, 12.75s/it] 10%|█         | 1335/12825 [4:45:42<40:31:19, 12.70s/it] 10%|█         | 1336/12825 [4:45:55<40:23:00, 12.65s/it] 10%|█         | 1337/12825 [4:46:07<40:18:09, 12.63s/it] 10%|█         | 1338/12825 [4:46:20<40:13:09, 12.60s/it] 10%|█         | 1339/12825 [4:46:32<40:10:44, 12.59s/it] 10%|█         | 1340/12825 [4:46:45<40:08:04, 12.58s/it] 10%|█         | 1341/12825 [4:46:57<40:07:11, 12.58s/it] 10%|█         | 1342/12825 [4:47:10<40:07:37, 12.58s/it] 10%|█         | 1343/12825 [4:47:23<40:06:08, 12.57s/it] 10%|█         | 1344/12825 [4:47:35<40:08:03, 12.58s/it] 10%|█         | 1345/12825 [4:47:48<40:07:45, 12.58s/it] 10%|█         | 1346/12825 [4:48:00<40:06:43, 12.58s/it] 11%|█         | 1347/12825 [4:48:13<40:06:25, 12.58s/it] 11%|█         | 1348/12825 [4:48:26<40:06:33, 12.58s/it] 11%|█         | 1349/12825 [4:48:38<40:04:33, 12.57s/it] 11%|█         | 1350/12825 [4:48:51<40:04:38, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120350.88lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103574.14lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1300] due to args.save_total_limit
 11%|█         | 1351/12825 [4:49:04<40:22:45, 12.67s/it] 11%|█         | 1352/12825 [4:49:16<40:15:21, 12.63s/it] 11%|█         | 1353/12825 [4:49:29<40:11:49, 12.61s/it] 11%|█         | 1354/12825 [4:49:41<40:10:27, 12.61s/it] 11%|█         | 1355/12825 [4:49:54<40:08:29, 12.60s/it] 11%|█         | 1356/12825 [4:50:06<40:06:28, 12.59s/it] 11%|█         | 1357/12825 [4:50:20<41:18:53, 12.97s/it] 11%|█         | 1358/12825 [4:50:33<41:12:46, 12.94s/it] 11%|█         | 1359/12825 [4:50:53<47:49:40, 15.02s/it] 11%|█         | 1360/12825 [4:51:06<45:29:53, 14.29s/it] 11%|█         | 1361/12825 [4:51:18<43:50:35, 13.77s/it] 11%|█         | 1362/12825 [4:51:31<42:43:24, 13.42s/it] 11%|█         | 1363/12825 [4:51:43<41:54:49, 13.16s/it] 11%|█         | 1364/12825 [4:51:56<41:22:00, 12.99s/it] 11%|█         | 1365/12825 [4:52:09<40:58:12, 12.87s/it] 11%|█         | 1366/12825 [4:52:21<40:43:23, 12.79s/it] 11%|█         | 1367/12825 [4:52:34<40:30:02, 12.72s/it] 11%|█         | 1368/12825 [4:52:46<40:23:21, 12.69s/it] 11%|█         | 1369/12825 [4:52:59<40:17:29, 12.66s/it] 11%|█         | 1370/12825 [4:53:11<40:12:32, 12.64s/it] 11%|█         | 1371/12825 [4:53:24<40:07:38, 12.61s/it] 11%|█         | 1372/12825 [4:53:37<40:06:55, 12.61s/it] 11%|█         | 1373/12825 [4:53:49<40:04:24, 12.60s/it] 11%|█         | 1374/12825 [4:54:02<40:00:54, 12.58s/it] 11%|█         | 1375/12825 [4:54:14<39:59:41, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 118955.23lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 99807.88lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1325] due to args.save_total_limit
 11%|█         | 1376/12825 [4:54:27<40:18:17, 12.67s/it] 11%|█         | 1377/12825 [4:54:40<40:11:16, 12.64s/it] 11%|█         | 1378/12825 [4:54:52<40:06:27, 12.61s/it] 11%|█         | 1379/12825 [4:55:05<40:02:53, 12.60s/it] 11%|█         | 1380/12825 [4:55:17<40:01:41, 12.59s/it] 11%|█         | 1381/12825 [4:55:30<39:59:41, 12.58s/it] 11%|█         | 1382/12825 [4:55:43<39:59:39, 12.58s/it] 11%|█         | 1383/12825 [4:55:55<40:02:14, 12.60s/it] 11%|█         | 1384/12825 [4:56:08<40:00:03, 12.59s/it] 11%|█         | 1385/12825 [4:56:20<39:57:14, 12.57s/it] 11%|█         | 1386/12825 [4:56:33<39:55:51, 12.57s/it] 11%|█         | 1387/12825 [4:56:45<39:55:58, 12.57s/it] 11%|█         | 1388/12825 [4:56:58<39:54:31, 12.56s/it] 11%|█         | 1389/12825 [4:57:11<40:09:21, 12.64s/it] 11%|█         | 1390/12825 [4:57:23<40:07:11, 12.63s/it] 11%|█         | 1391/12825 [4:57:43<46:59:36, 14.80s/it] 11%|█         | 1392/12825 [4:57:56<44:50:35, 14.12s/it] 11%|█         | 1393/12825 [4:58:08<43:22:16, 13.66s/it] 11%|█         | 1394/12825 [4:58:21<42:18:55, 13.33s/it] 11%|█         | 1395/12825 [4:58:34<41:35:29, 13.10s/it] 11%|█         | 1396/12825 [4:58:46<41:05:20, 12.94s/it] 11%|█         | 1397/12825 [4:58:59<40:44:35, 12.83s/it] 11%|█         | 1398/12825 [4:59:11<40:29:06, 12.75s/it] 11%|█         | 1399/12825 [4:59:24<40:17:54, 12.70s/it] 11%|█         | 1400/12825 [4:59:36<40:12:50, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120446.63lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103637.84lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1350] due to args.save_total_limit
 11%|█         | 1401/12825 [4:59:49<40:29:40, 12.76s/it] 11%|█         | 1402/12825 [5:00:02<40:21:05, 12.72s/it] 11%|█         | 1403/12825 [5:00:15<40:12:51, 12.67s/it] 11%|█         | 1404/12825 [5:00:27<40:04:34, 12.63s/it] 11%|█         | 1405/12825 [5:00:40<39:59:16, 12.61s/it] 11%|█         | 1406/12825 [5:00:52<39:58:44, 12.60s/it] 11%|█         | 1407/12825 [5:01:05<39:56:08, 12.59s/it] 11%|█         | 1408/12825 [5:01:17<39:54:56, 12.59s/it] 11%|█         | 1409/12825 [5:01:30<39:52:31, 12.57s/it] 11%|█         | 1410/12825 [5:01:43<39:53:23, 12.58s/it] 11%|█         | 1411/12825 [5:01:55<39:52:47, 12.58s/it] 11%|█         | 1412/12825 [5:02:08<39:51:30, 12.57s/it] 11%|█         | 1413/12825 [5:02:20<39:51:11, 12.57s/it] 11%|█         | 1414/12825 [5:02:33<39:51:34, 12.58s/it] 11%|█         | 1415/12825 [5:02:45<39:50:14, 12.57s/it] 11%|█         | 1416/12825 [5:02:58<39:51:15, 12.58s/it] 11%|█         | 1417/12825 [5:03:11<39:50:52, 12.57s/it] 11%|█         | 1418/12825 [5:03:23<39:49:11, 12.57s/it] 11%|█         | 1419/12825 [5:03:36<39:50:38, 12.58s/it] 11%|█         | 1420/12825 [5:03:48<39:50:49, 12.58s/it] 11%|█         | 1421/12825 [5:04:01<39:51:16, 12.58s/it] 11%|█         | 1422/12825 [5:04:13<39:52:47, 12.59s/it] 11%|█         | 1423/12825 [5:04:26<39:53:27, 12.59s/it] 11%|█         | 1424/12825 [5:04:46<46:46:23, 14.77s/it] 11%|█         | 1425/12825 [5:04:58<44:40:19, 14.11s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120539.96lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103717.29lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1375] due to args.save_total_limit
 11%|█         | 1426/12825 [5:05:11<43:30:44, 13.74s/it] 11%|█         | 1427/12825 [5:05:24<42:21:12, 13.38s/it] 11%|█         | 1428/12825 [5:05:37<41:37:26, 13.15s/it] 11%|█         | 1429/12825 [5:05:49<41:03:15, 12.97s/it] 11%|█         | 1430/12825 [5:06:02<40:41:51, 12.86s/it] 11%|█         | 1431/12825 [5:06:14<40:28:23, 12.79s/it] 11%|█         | 1432/12825 [5:06:27<40:18:49, 12.74s/it] 11%|█         | 1433/12825 [5:06:39<40:10:09, 12.69s/it] 11%|█         | 1434/12825 [5:06:52<40:03:40, 12.66s/it] 11%|█         | 1435/12825 [5:07:05<39:58:37, 12.64s/it] 11%|█         | 1436/12825 [5:07:17<39:55:18, 12.62s/it] 11%|█         | 1437/12825 [5:07:30<39:52:30, 12.61s/it] 11%|█         | 1438/12825 [5:07:42<39:50:21, 12.60s/it] 11%|█         | 1439/12825 [5:07:55<39:49:54, 12.59s/it] 11%|█         | 1440/12825 [5:08:08<39:49:38, 12.59s/it] 11%|█         | 1441/12825 [5:08:20<39:49:38, 12.59s/it] 11%|█         | 1442/12825 [5:08:33<39:48:38, 12.59s/it] 11%|█▏        | 1443/12825 [5:08:45<39:49:33, 12.60s/it] 11%|█▏        | 1444/12825 [5:08:58<39:49:01, 12.59s/it] 11%|█▏        | 1445/12825 [5:09:11<39:49:04, 12.60s/it] 11%|█▏        | 1446/12825 [5:09:23<39:48:22, 12.59s/it] 11%|█▏        | 1447/12825 [5:09:36<39:46:17, 12.58s/it] 11%|█▏        | 1448/12825 [5:09:48<39:45:07, 12.58s/it] 11%|█▏        | 1449/12825 [5:10:01<39:46:56, 12.59s/it] 11%|█▏        | 1450/12825 [5:10:13<39:47:54, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120435.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103611.57lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1400] due to args.save_total_limit
 11%|█▏        | 1451/12825 [5:10:26<40:06:20, 12.69s/it] 11%|█▏        | 1452/12825 [5:10:39<39:58:34, 12.65s/it] 11%|█▏        | 1453/12825 [5:10:52<39:53:05, 12.63s/it] 11%|█▏        | 1454/12825 [5:11:04<39:50:20, 12.61s/it] 11%|█▏        | 1455/12825 [5:11:17<39:47:25, 12.60s/it] 11%|█▏        | 1456/12825 [5:11:37<46:39:18, 14.77s/it] 11%|█▏        | 1457/12825 [5:11:49<44:34:51, 14.12s/it] 11%|█▏        | 1458/12825 [5:12:02<43:06:09, 13.65s/it] 11%|█▏        | 1459/12825 [5:12:14<42:05:36, 13.33s/it] 11%|█▏        | 1460/12825 [5:12:27<41:21:58, 13.10s/it] 11%|█▏        | 1461/12825 [5:12:39<40:52:06, 12.95s/it] 11%|█▏        | 1462/12825 [5:12:52<40:31:57, 12.84s/it] 11%|█▏        | 1463/12825 [5:13:05<40:16:35, 12.76s/it] 11%|█▏        | 1464/12825 [5:13:17<40:06:36, 12.71s/it] 11%|█▏        | 1465/12825 [5:13:30<39:56:56, 12.66s/it] 11%|█▏        | 1466/12825 [5:13:42<39:51:57, 12.63s/it] 11%|█▏        | 1467/12825 [5:13:55<39:49:37, 12.62s/it] 11%|█▏        | 1468/12825 [5:14:07<39:46:06, 12.61s/it] 11%|█▏        | 1469/12825 [5:14:20<39:43:52, 12.60s/it] 11%|█▏        | 1470/12825 [5:14:33<39:42:07, 12.59s/it] 11%|█▏        | 1471/12825 [5:14:45<39:41:18, 12.58s/it] 11%|█▏        | 1472/12825 [5:14:58<39:40:31, 12.58s/it] 11%|█▏        | 1473/12825 [5:15:10<39:39:41, 12.58s/it] 11%|█▏        | 1474/12825 [5:15:23<39:38:06, 12.57s/it] 12%|█▏        | 1475/12825 [5:15:35<39:38:54, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120460.08lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103604.09lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1425] due to args.save_total_limit
 12%|█▏        | 1476/12825 [5:15:48<39:59:27, 12.69s/it] 12%|█▏        | 1477/12825 [5:16:01<39:51:58, 12.65s/it] 12%|█▏        | 1478/12825 [5:16:14<39:48:54, 12.63s/it] 12%|█▏        | 1479/12825 [5:16:26<39:43:14, 12.60s/it] 12%|█▏        | 1480/12825 [5:16:39<39:41:07, 12.59s/it] 12%|█▏        | 1481/12825 [5:16:51<39:38:01, 12.58s/it] 12%|█▏        | 1482/12825 [5:17:04<39:37:22, 12.58s/it] 12%|█▏        | 1483/12825 [5:17:16<39:36:12, 12.57s/it] 12%|█▏        | 1484/12825 [5:17:29<39:35:33, 12.57s/it] 12%|█▏        | 1485/12825 [5:17:41<39:35:53, 12.57s/it] 12%|█▏        | 1486/12825 [5:17:54<39:36:18, 12.57s/it] 12%|█▏        | 1487/12825 [5:18:07<39:35:51, 12.57s/it] 12%|█▏        | 1488/12825 [5:18:27<46:40:50, 14.82s/it] 12%|█▏        | 1489/12825 [5:18:39<44:30:53, 14.14s/it] 12%|█▏        | 1490/12825 [5:18:52<43:01:31, 13.66s/it] 12%|█▏        | 1491/12825 [5:19:04<42:00:00, 13.34s/it] 12%|█▏        | 1492/12825 [5:19:17<41:16:03, 13.11s/it] 12%|█▏        | 1493/12825 [5:19:30<40:45:51, 12.95s/it] 12%|█▏        | 1494/12825 [5:19:42<40:23:31, 12.83s/it] 12%|█▏        | 1495/12825 [5:19:55<40:08:45, 12.76s/it] 12%|█▏        | 1496/12825 [5:20:07<39:57:48, 12.70s/it] 12%|█▏        | 1497/12825 [5:20:20<39:51:54, 12.67s/it] 12%|█▏        | 1498/12825 [5:20:32<39:47:50, 12.65s/it] 12%|█▏        | 1499/12825 [5:20:45<39:44:26, 12.63s/it] 12%|█▏        | 1500/12825 [5:20:58<39:40:45, 12.61s/it]                                                          12%|█▏        | 1500/12825 [5:20:58<39:40:45, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120557.41lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103714.53lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1450] due to args.save_total_limit
 12%|█▏        | 1501/12825 [5:21:11<40:08:45, 12.76s/it] 12%|█▏        | 1502/12825 [5:21:23<39:57:17, 12.70s/it] 12%|█▏        | 1503/12825 [5:21:36<39:53:36, 12.68s/it] 12%|█▏        | 1504/12825 [5:21:48<39:48:15, 12.66s/it] 12%|█▏        | 1505/12825 [5:22:01<39:45:05, 12.64s/it] 12%|█▏        | 1506/12825 [5:22:14<39:40:39, 12.62s/it] 12%|█▏        | 1507/12825 [5:22:26<39:38:46, 12.61s/it] 12%|█▏        | 1508/12825 [5:22:39<39:35:18, 12.59s/it] 12%|█▏        | 1509/12825 [5:22:51<39:34:16, 12.59s/it] 12%|█▏        | 1510/12825 [5:23:04<39:32:11, 12.58s/it] 12%|█▏        | 1511/12825 [5:23:17<39:33:09, 12.59s/it] 12%|█▏        | 1512/12825 [5:23:29<39:33:26, 12.59s/it] 12%|█▏        | 1513/12825 [5:23:42<39:32:45, 12.59s/it] 12%|█▏        | 1514/12825 [5:23:54<39:31:54, 12.58s/it] 12%|█▏        | 1515/12825 [5:24:07<39:32:38, 12.59s/it] 12%|█▏        | 1516/12825 [5:24:19<39:33:13, 12.59s/it] 12%|█▏        | 1517/12825 [5:24:32<39:32:07, 12.59s/it] 12%|█▏        | 1518/12825 [5:24:45<39:30:44, 12.58s/it] 12%|█▏        | 1519/12825 [5:24:57<39:29:59, 12.58s/it] 12%|█▏        | 1520/12825 [5:25:10<39:31:04, 12.58s/it] 12%|█▏        | 1521/12825 [5:25:30<46:19:04, 14.75s/it] 12%|█▏        | 1522/12825 [5:25:42<44:17:37, 14.11s/it] 12%|█▏        | 1523/12825 [5:25:55<42:52:00, 13.65s/it] 12%|█▏        | 1524/12825 [5:26:07<41:52:27, 13.34s/it] 12%|█▏        | 1525/12825 [5:26:20<41:08:40, 13.11s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120509.18lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103782.68lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1475] due to args.save_total_limit
 12%|█▏        | 1526/12825 [5:26:33<40:58:10, 13.05s/it] 12%|█▏        | 1527/12825 [5:26:46<40:31:35, 12.91s/it] 12%|█▏        | 1528/12825 [5:26:58<40:14:16, 12.82s/it] 12%|█▏        | 1529/12825 [5:27:11<40:01:41, 12.76s/it] 12%|█▏        | 1530/12825 [5:27:23<39:53:23, 12.71s/it] 12%|█▏        | 1531/12825 [5:27:36<39:45:08, 12.67s/it] 12%|█▏        | 1532/12825 [5:27:48<39:39:06, 12.64s/it] 12%|█▏        | 1533/12825 [5:28:01<39:36:14, 12.63s/it] 12%|█▏        | 1534/12825 [5:28:14<39:32:07, 12.61s/it] 12%|█▏        | 1535/12825 [5:28:26<39:30:45, 12.60s/it] 12%|█▏        | 1536/12825 [5:28:39<39:30:53, 12.60s/it] 12%|█▏        | 1537/12825 [5:28:51<39:30:10, 12.60s/it] 12%|█▏        | 1538/12825 [5:28:59<35:03:54, 11.18s/it] 12%|█▏        | 1539/12825 [5:29:00<25:19:01,  8.08s/it] 12%|█▏        | 1540/12825 [5:29:26<42:02:56, 13.41s/it] 12%|█▏        | 1541/12825 [5:29:39<41:18:01, 13.18s/it] 12%|█▏        | 1542/12825 [5:29:51<40:46:18, 13.01s/it] 12%|█▏        | 1543/12825 [5:30:04<40:25:29, 12.90s/it] 12%|█▏        | 1544/12825 [5:30:16<40:09:32, 12.82s/it] 12%|█▏        | 1545/12825 [5:30:29<39:59:11, 12.76s/it] 12%|█▏        | 1546/12825 [5:30:42<39:50:10, 12.71s/it] 12%|█▏        | 1547/12825 [5:30:54<39:42:31, 12.68s/it] 12%|█▏        | 1548/12825 [5:31:07<39:40:07, 12.66s/it] 12%|█▏        | 1549/12825 [5:31:20<39:35:39, 12.64s/it] 12%|█▏        | 1550/12825 [5:31:32<39:31:54, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120580.13lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103753.68lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1500] due to args.save_total_limit
 12%|█▏        | 1551/12825 [5:31:45<39:52:17, 12.73s/it] 12%|█▏        | 1552/12825 [5:31:58<39:45:16, 12.70s/it] 12%|█▏        | 1553/12825 [5:32:18<46:35:46, 14.88s/it] 12%|█▏        | 1554/12825 [5:32:30<44:24:38, 14.18s/it] 12%|█▏        | 1555/12825 [5:32:43<42:54:49, 13.71s/it] 12%|█▏        | 1556/12825 [5:32:55<41:51:51, 13.37s/it] 12%|█▏        | 1557/12825 [5:33:08<41:06:24, 13.13s/it] 12%|█▏        | 1558/12825 [5:33:21<40:34:15, 12.96s/it] 12%|█▏        | 1559/12825 [5:33:33<40:12:24, 12.85s/it] 12%|█▏        | 1560/12825 [5:33:46<39:56:11, 12.76s/it] 12%|█▏        | 1561/12825 [5:33:58<39:46:55, 12.71s/it] 12%|█▏        | 1562/12825 [5:34:11<39:41:03, 12.68s/it] 12%|█▏        | 1563/12825 [5:34:24<39:34:23, 12.65s/it] 12%|█▏        | 1564/12825 [5:34:36<39:29:07, 12.62s/it] 12%|█▏        | 1565/12825 [5:34:49<39:26:20, 12.61s/it] 12%|█▏        | 1566/12825 [5:35:01<39:24:50, 12.60s/it] 12%|█▏        | 1567/12825 [5:35:14<39:24:26, 12.60s/it] 12%|█▏        | 1568/12825 [5:35:27<39:31:26, 12.64s/it] 12%|█▏        | 1569/12825 [5:35:39<39:26:19, 12.61s/it] 12%|█▏        | 1570/12825 [5:35:52<39:24:47, 12.61s/it] 12%|█▏        | 1571/12825 [5:36:04<39:24:33, 12.61s/it] 12%|█▏        | 1572/12825 [5:36:17<39:21:58, 12.59s/it] 12%|█▏        | 1573/12825 [5:36:29<39:22:33, 12.60s/it] 12%|█▏        | 1574/12825 [5:36:42<39:22:33, 12.60s/it] 12%|█▏        | 1575/12825 [5:36:55<39:23:02, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120451.88lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103649.60lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1525] due to args.save_total_limit
 12%|█▏        | 1576/12825 [5:37:08<39:39:40, 12.69s/it] 12%|█▏        | 1577/12825 [5:37:20<39:31:58, 12.65s/it] 12%|█▏        | 1578/12825 [5:37:33<39:29:26, 12.64s/it] 12%|█▏        | 1579/12825 [5:37:45<39:26:00, 12.62s/it] 12%|█▏        | 1580/12825 [5:37:58<39:25:13, 12.62s/it] 12%|█▏        | 1581/12825 [5:38:11<39:23:39, 12.61s/it] 12%|█▏        | 1582/12825 [5:38:23<39:23:42, 12.61s/it] 12%|█▏        | 1583/12825 [5:38:36<39:21:39, 12.60s/it] 12%|█▏        | 1584/12825 [5:38:48<39:21:50, 12.61s/it] 12%|█▏        | 1585/12825 [5:39:01<39:20:23, 12.60s/it] 12%|█▏        | 1586/12825 [5:39:22<46:51:33, 15.01s/it] 12%|█▏        | 1587/12825 [5:39:34<44:34:33, 14.28s/it] 12%|█▏        | 1588/12825 [5:39:47<42:57:25, 13.76s/it] 12%|█▏        | 1589/12825 [5:39:59<41:52:49, 13.42s/it] 12%|█▏        | 1590/12825 [5:40:12<41:07:47, 13.18s/it] 12%|█▏        | 1591/12825 [5:40:25<40:35:20, 13.01s/it] 12%|█▏        | 1592/12825 [5:40:37<40:14:23, 12.90s/it] 12%|█▏        | 1593/12825 [5:40:50<39:59:14, 12.82s/it] 12%|█▏        | 1594/12825 [5:41:02<39:45:14, 12.74s/it] 12%|█▏        | 1595/12825 [5:41:15<39:37:59, 12.71s/it] 12%|█▏        | 1596/12825 [5:41:28<39:32:07, 12.67s/it] 12%|█▏        | 1597/12825 [5:41:40<39:29:27, 12.66s/it] 12%|█▏        | 1598/12825 [5:41:53<39:26:28, 12.65s/it] 12%|█▏        | 1599/12825 [5:42:05<39:24:32, 12.64s/it] 12%|█▏        | 1600/12825 [5:42:18<39:21:43, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120526.62lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103714.15lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1550] due to args.save_total_limit
 12%|█▏        | 1601/12825 [5:42:31<39:37:48, 12.71s/it] 12%|█▏        | 1602/12825 [5:42:44<39:30:50, 12.67s/it] 12%|█▏        | 1603/12825 [5:42:56<39:26:34, 12.65s/it] 13%|█▎        | 1604/12825 [5:43:09<39:25:58, 12.65s/it] 13%|█▎        | 1605/12825 [5:43:21<39:22:06, 12.63s/it] 13%|█▎        | 1606/12825 [5:43:34<39:21:24, 12.63s/it] 13%|█▎        | 1607/12825 [5:43:47<39:21:41, 12.63s/it] 13%|█▎        | 1608/12825 [5:43:59<39:19:33, 12.62s/it] 13%|█▎        | 1609/12825 [5:44:12<39:18:39, 12.62s/it] 13%|█▎        | 1610/12825 [5:44:24<39:17:29, 12.61s/it] 13%|█▎        | 1611/12825 [5:44:37<39:18:18, 12.62s/it] 13%|█▎        | 1612/12825 [5:44:50<39:17:21, 12.61s/it] 13%|█▎        | 1613/12825 [5:45:02<39:18:16, 12.62s/it] 13%|█▎        | 1614/12825 [5:45:15<39:17:51, 12.62s/it] 13%|█▎        | 1615/12825 [5:45:28<39:15:43, 12.61s/it] 13%|█▎        | 1616/12825 [5:45:40<39:15:39, 12.61s/it] 13%|█▎        | 1617/12825 [5:45:53<39:14:25, 12.60s/it] 13%|█▎        | 1618/12825 [5:46:13<46:26:33, 14.92s/it] 13%|█▎        | 1619/12825 [5:46:26<44:19:53, 14.24s/it] 13%|█▎        | 1620/12825 [5:46:38<42:47:00, 13.75s/it] 13%|█▎        | 1621/12825 [5:46:51<41:43:26, 13.41s/it] 13%|█▎        | 1622/12825 [5:47:03<40:55:53, 13.15s/it] 13%|█▎        | 1623/12825 [5:47:16<40:24:17, 12.98s/it] 13%|█▎        | 1624/12825 [5:47:29<40:00:01, 12.86s/it] 13%|█▎        | 1625/12825 [5:47:41<39:45:53, 12.78s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120431.26lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103471.09lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1575] due to args.save_total_limit
 13%|█▎        | 1626/12825 [5:47:54<39:56:12, 12.84s/it] 13%|█▎        | 1627/12825 [5:48:07<39:43:29, 12.77s/it] 13%|█▎        | 1628/12825 [5:48:19<39:33:16, 12.72s/it] 13%|█▎        | 1629/12825 [5:48:32<39:27:57, 12.69s/it] 13%|█▎        | 1630/12825 [5:48:45<39:22:00, 12.66s/it] 13%|█▎        | 1631/12825 [5:48:57<39:19:27, 12.65s/it] 13%|█▎        | 1632/12825 [5:49:10<39:15:26, 12.63s/it] 13%|█▎        | 1633/12825 [5:49:22<39:14:25, 12.62s/it] 13%|█▎        | 1634/12825 [5:49:35<39:10:29, 12.60s/it] 13%|█▎        | 1635/12825 [5:49:48<39:07:05, 12.58s/it] 13%|█▎        | 1636/12825 [5:50:00<39:05:13, 12.58s/it] 13%|█▎        | 1637/12825 [5:50:13<39:03:37, 12.57s/it] 13%|█▎        | 1638/12825 [5:50:25<39:03:44, 12.57s/it] 13%|█▎        | 1639/12825 [5:50:38<39:02:35, 12.57s/it] 13%|█▎        | 1640/12825 [5:50:50<39:03:47, 12.57s/it] 13%|█▎        | 1641/12825 [5:51:03<39:03:45, 12.57s/it] 13%|█▎        | 1642/12825 [5:51:16<39:03:28, 12.57s/it] 13%|█▎        | 1643/12825 [5:51:28<39:04:02, 12.58s/it] 13%|█▎        | 1644/12825 [5:51:41<39:03:31, 12.58s/it] 13%|█▎        | 1645/12825 [5:51:53<39:04:28, 12.58s/it] 13%|█▎        | 1646/12825 [5:52:06<39:04:45, 12.58s/it] 13%|█▎        | 1647/12825 [5:52:18<39:06:17, 12.59s/it] 13%|█▎        | 1648/12825 [5:52:31<39:06:42, 12.60s/it] 13%|█▎        | 1649/12825 [5:52:44<39:05:14, 12.59s/it] 13%|█▎        | 1650/12825 [5:53:04<46:37:04, 15.02s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120463.16lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103707.22lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1600] due to args.save_total_limit
 13%|█▎        | 1651/12825 [5:53:17<44:40:44, 14.39s/it] 13%|█▎        | 1652/12825 [5:53:30<42:58:28, 13.85s/it] 13%|█▎        | 1653/12825 [5:53:42<41:47:39, 13.47s/it] 13%|█▎        | 1654/12825 [5:53:55<40:59:17, 13.21s/it] 13%|█▎        | 1655/12825 [5:54:08<40:24:19, 13.02s/it] 13%|█▎        | 1656/12825 [5:54:20<39:58:00, 12.88s/it] 13%|█▎        | 1657/12825 [5:54:33<39:42:51, 12.80s/it] 13%|█▎        | 1658/12825 [5:54:45<39:32:16, 12.75s/it] 13%|█▎        | 1659/12825 [5:54:58<39:24:15, 12.70s/it] 13%|█▎        | 1660/12825 [5:55:11<39:18:12, 12.67s/it] 13%|█▎        | 1661/12825 [5:55:23<39:13:01, 12.65s/it] 13%|█▎        | 1662/12825 [5:55:36<39:09:13, 12.63s/it] 13%|█▎        | 1663/12825 [5:55:48<39:07:19, 12.62s/it] 13%|█▎        | 1664/12825 [5:56:01<39:06:11, 12.61s/it] 13%|█▎        | 1665/12825 [5:56:14<39:06:24, 12.62s/it] 13%|█▎        | 1666/12825 [5:56:26<39:06:49, 12.62s/it] 13%|█▎        | 1667/12825 [5:56:39<39:04:16, 12.61s/it] 13%|█▎        | 1668/12825 [5:56:51<39:01:33, 12.59s/it] 13%|█▎        | 1669/12825 [5:57:04<39:00:39, 12.59s/it] 13%|█▎        | 1670/12825 [5:57:17<38:59:25, 12.58s/it] 13%|█▎        | 1671/12825 [5:57:29<38:58:38, 12.58s/it] 13%|█▎        | 1672/12825 [5:57:42<38:59:38, 12.59s/it] 13%|█▎        | 1673/12825 [5:57:54<38:59:32, 12.59s/it] 13%|█▎        | 1674/12825 [5:58:07<38:58:18, 12.58s/it] 13%|█▎        | 1675/12825 [5:58:19<38:56:41, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120317.76lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103517.53lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1625] due to args.save_total_limit
 13%|█▎        | 1676/12825 [5:58:32<39:17:03, 12.68s/it] 13%|█▎        | 1677/12825 [5:58:45<39:07:24, 12.63s/it] 13%|█▎        | 1678/12825 [5:58:57<39:03:02, 12.61s/it] 13%|█▎        | 1679/12825 [5:59:10<39:01:35, 12.61s/it] 13%|█▎        | 1680/12825 [5:59:23<39:02:40, 12.61s/it] 13%|█▎        | 1681/12825 [5:59:35<38:59:45, 12.60s/it] 13%|█▎        | 1682/12825 [5:59:48<38:55:48, 12.58s/it] 13%|█▎        | 1683/12825 [6:00:09<47:00:08, 15.19s/it] 13%|█▎        | 1684/12825 [6:00:22<44:34:18, 14.40s/it] 13%|█▎        | 1685/12825 [6:00:34<42:52:42, 13.86s/it] 13%|█▎        | 1686/12825 [6:00:47<41:39:40, 13.46s/it] 13%|█▎        | 1687/12825 [6:00:59<40:48:33, 13.19s/it] 13%|█▎        | 1688/12825 [6:01:12<40:16:22, 13.02s/it] 13%|█▎        | 1689/12825 [6:01:24<39:50:38, 12.88s/it] 13%|█▎        | 1690/12825 [6:01:37<39:31:41, 12.78s/it] 13%|█▎        | 1691/12825 [6:01:50<39:19:34, 12.72s/it] 13%|█▎        | 1692/12825 [6:02:02<39:08:47, 12.66s/it] 13%|█▎        | 1693/12825 [6:02:15<39:04:53, 12.64s/it] 13%|█▎        | 1694/12825 [6:02:27<39:00:58, 12.62s/it] 13%|█▎        | 1695/12825 [6:02:40<38:56:52, 12.60s/it] 13%|█▎        | 1696/12825 [6:02:52<38:55:18, 12.59s/it] 13%|█▎        | 1697/12825 [6:03:05<38:52:52, 12.58s/it] 13%|█▎        | 1698/12825 [6:03:17<38:51:54, 12.57s/it] 13%|█▎        | 1699/12825 [6:03:30<38:52:04, 12.58s/it] 13%|█▎        | 1700/12825 [6:03:43<38:50:45, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120482.25lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103645.52lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1650] due to args.save_total_limit
 13%|█▎        | 1701/12825 [6:03:56<39:09:55, 12.67s/it] 13%|█▎        | 1702/12825 [6:04:08<39:02:10, 12.63s/it] 13%|█▎        | 1703/12825 [6:04:21<38:57:35, 12.61s/it] 13%|█▎        | 1704/12825 [6:04:33<38:54:44, 12.60s/it] 13%|█▎        | 1705/12825 [6:04:46<38:54:32, 12.60s/it] 13%|█▎        | 1706/12825 [6:04:58<38:50:03, 12.57s/it] 13%|█▎        | 1707/12825 [6:05:11<38:47:39, 12.56s/it] 13%|█▎        | 1708/12825 [6:05:23<38:47:00, 12.56s/it] 13%|█▎        | 1709/12825 [6:05:36<38:44:55, 12.55s/it] 13%|█▎        | 1710/12825 [6:05:48<38:43:38, 12.54s/it] 13%|█▎        | 1711/12825 [6:06:01<38:40:54, 12.53s/it] 13%|█▎        | 1712/12825 [6:06:13<38:40:41, 12.53s/it] 13%|█▎        | 1713/12825 [6:06:26<38:38:49, 12.52s/it] 13%|█▎        | 1714/12825 [6:06:39<38:40:04, 12.53s/it] 13%|█▎        | 1715/12825 [6:07:00<46:47:32, 15.16s/it] 13%|█▎        | 1716/12825 [6:07:12<44:21:24, 14.37s/it] 13%|█▎        | 1717/12825 [6:07:25<42:37:33, 13.81s/it] 13%|█▎        | 1718/12825 [6:07:37<41:26:28, 13.43s/it] 13%|█▎        | 1719/12825 [6:07:50<40:37:04, 13.17s/it] 13%|█▎        | 1720/12825 [6:08:03<40:04:11, 12.99s/it] 13%|█▎        | 1721/12825 [6:08:15<39:38:27, 12.85s/it] 13%|█▎        | 1722/12825 [6:08:28<39:18:45, 12.75s/it] 13%|█▎        | 1723/12825 [6:08:40<39:07:52, 12.69s/it] 13%|█▎        | 1724/12825 [6:08:53<38:57:18, 12.63s/it] 13%|█▎        | 1725/12825 [6:09:05<38:50:32, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120499.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103750.07lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1725
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1725/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1725/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1675] due to args.save_total_limit
 13%|█▎        | 1726/12825 [6:09:18<39:08:45, 12.70s/it] 13%|█▎        | 1727/12825 [6:09:31<38:59:46, 12.65s/it] 13%|█▎        | 1728/12825 [6:09:43<38:51:30, 12.61s/it] 13%|█▎        | 1729/12825 [6:09:56<38:46:39, 12.58s/it] 13%|█▎        | 1730/12825 [6:10:08<38:42:19, 12.56s/it] 13%|█▎        | 1731/12825 [6:10:21<38:42:21, 12.56s/it] 14%|█▎        | 1732/12825 [6:10:33<38:38:54, 12.54s/it] 14%|█▎        | 1733/12825 [6:10:46<38:38:07, 12.54s/it] 14%|█▎        | 1734/12825 [6:10:58<38:37:53, 12.54s/it] 14%|█▎        | 1735/12825 [6:11:11<38:38:00, 12.54s/it] 14%|█▎        | 1736/12825 [6:11:23<38:36:23, 12.53s/it] 14%|█▎        | 1737/12825 [6:11:36<38:34:39, 12.53s/it] 14%|█▎        | 1738/12825 [6:11:48<38:32:06, 12.51s/it] 14%|█▎        | 1739/12825 [6:12:01<38:33:54, 12.52s/it] 14%|█▎        | 1740/12825 [6:12:13<38:34:52, 12.53s/it] 14%|█▎        | 1741/12825 [6:12:26<38:36:08, 12.54s/it] 14%|█▎        | 1742/12825 [6:12:39<38:35:00, 12.53s/it] 14%|█▎        | 1743/12825 [6:12:51<38:46:16, 12.59s/it] 14%|█▎        | 1744/12825 [6:13:04<38:43:28, 12.58s/it] 14%|█▎        | 1745/12825 [6:13:16<38:41:42, 12.57s/it] 14%|█▎        | 1746/12825 [6:13:29<38:40:04, 12.56s/it] 14%|█▎        | 1747/12825 [6:13:49<45:54:54, 14.92s/it] 14%|█▎        | 1748/12825 [6:14:02<43:43:29, 14.21s/it] 14%|█▎        | 1749/12825 [6:14:14<42:11:48, 13.72s/it] 14%|█▎        | 1750/12825 [6:14:27<41:06:05, 13.36s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120266.78lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103498.98lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1750
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1750/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1750/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1700] due to args.save_total_limit
 14%|█▎        | 1751/12825 [6:14:40<40:35:28, 13.20s/it] 14%|█▎        | 1752/12825 [6:14:52<40:00:36, 13.01s/it] 14%|█▎        | 1753/12825 [6:15:05<39:30:42, 12.85s/it] 14%|█▎        | 1754/12825 [6:15:17<39:11:54, 12.75s/it] 14%|█▎        | 1755/12825 [6:15:30<39:01:43, 12.69s/it] 14%|█▎        | 1756/12825 [6:15:42<38:53:35, 12.65s/it] 14%|█▎        | 1757/12825 [6:15:55<38:49:11, 12.63s/it] 14%|█▎        | 1758/12825 [6:16:08<38:43:49, 12.60s/it] 14%|█▎        | 1759/12825 [6:16:20<38:40:08, 12.58s/it] 14%|█▎        | 1760/12825 [6:16:33<38:37:22, 12.57s/it] 14%|█▎        | 1761/12825 [6:16:45<38:36:42, 12.56s/it] 14%|█▎        | 1762/12825 [6:16:58<38:35:03, 12.56s/it] 14%|█▎        | 1763/12825 [6:17:10<38:34:22, 12.55s/it] 14%|█▍        | 1764/12825 [6:17:23<38:31:34, 12.54s/it] 14%|█▍        | 1765/12825 [6:17:35<38:30:29, 12.53s/it] 14%|█▍        | 1766/12825 [6:17:48<38:31:50, 12.54s/it] 14%|█▍        | 1767/12825 [6:18:00<38:30:24, 12.54s/it] 14%|█▍        | 1768/12825 [6:18:13<38:29:27, 12.53s/it] 14%|█▍        | 1769/12825 [6:18:25<38:30:14, 12.54s/it] 14%|█▍        | 1770/12825 [6:18:38<38:28:50, 12.53s/it] 14%|█▍        | 1771/12825 [6:18:51<38:30:23, 12.54s/it] 14%|█▍        | 1772/12825 [6:19:03<38:29:00, 12.53s/it] 14%|█▍        | 1773/12825 [6:19:16<38:26:59, 12.52s/it] 14%|█▍        | 1774/12825 [6:19:28<38:25:56, 12.52s/it] 14%|█▍        | 1775/12825 [6:19:41<38:26:48, 12.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120211.76lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103375.60lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1775
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1775/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1775/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1725] due to args.save_total_limit
 14%|█▍        | 1776/12825 [6:19:53<38:47:05, 12.64s/it] 14%|█▍        | 1777/12825 [6:20:06<38:40:09, 12.60s/it] 14%|█▍        | 1778/12825 [6:20:19<38:37:30, 12.59s/it] 14%|█▍        | 1779/12825 [6:20:31<38:33:50, 12.57s/it] 14%|█▍        | 1780/12825 [6:20:51<45:19:46, 14.77s/it] 14%|█▍        | 1781/12825 [6:21:04<43:15:27, 14.10s/it] 14%|█▍        | 1782/12825 [6:21:16<41:47:42, 13.63s/it] 14%|█▍        | 1783/12825 [6:21:29<40:47:02, 13.30s/it] 14%|█▍        | 1784/12825 [6:21:41<40:03:56, 13.06s/it] 14%|█▍        | 1785/12825 [6:21:54<39:34:43, 12.91s/it] 14%|█▍        | 1786/12825 [6:22:06<39:12:16, 12.79s/it] 14%|█▍        | 1787/12825 [6:22:19<39:00:34, 12.72s/it] 14%|█▍        | 1788/12825 [6:22:31<38:48:02, 12.66s/it] 14%|█▍        | 1789/12825 [6:22:44<38:42:39, 12.63s/it] 14%|█▍        | 1790/12825 [6:22:56<38:39:39, 12.61s/it] 14%|█▍        | 1791/12825 [6:23:09<38:36:52, 12.60s/it] 14%|█▍        | 1792/12825 [6:23:21<38:34:09, 12.58s/it] 14%|█▍        | 1793/12825 [6:23:34<38:30:59, 12.57s/it] 14%|█▍        | 1794/12825 [6:23:47<38:29:56, 12.56s/it] 14%|█▍        | 1795/12825 [6:23:59<38:26:48, 12.55s/it] 14%|█▍        | 1796/12825 [6:24:12<38:22:53, 12.53s/it] 14%|█▍        | 1797/12825 [6:24:24<38:23:15, 12.53s/it] 14%|█▍        | 1798/12825 [6:24:37<38:22:59, 12.53s/it] 14%|█▍        | 1799/12825 [6:24:49<38:20:32, 12.52s/it] 14%|█▍        | 1800/12825 [6:25:02<38:21:50, 12.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120278.53lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103489.81lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1800
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1800/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1800/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1750] due to args.save_total_limit
 14%|█▍        | 1801/12825 [6:25:15<38:39:51, 12.63s/it] 14%|█▍        | 1802/12825 [6:25:27<38:32:03, 12.58s/it] 14%|█▍        | 1803/12825 [6:25:40<38:28:05, 12.56s/it] 14%|█▍        | 1804/12825 [6:25:52<38:23:46, 12.54s/it] 14%|█▍        | 1805/12825 [6:26:05<38:24:16, 12.55s/it] 14%|█▍        | 1806/12825 [6:26:17<38:23:12, 12.54s/it] 14%|█▍        | 1807/12825 [6:26:30<38:22:55, 12.54s/it] 14%|█▍        | 1808/12825 [6:26:42<38:23:47, 12.55s/it] 14%|█▍        | 1809/12825 [6:26:55<38:22:45, 12.54s/it] 14%|█▍        | 1810/12825 [6:27:07<38:21:44, 12.54s/it] 14%|█▍        | 1811/12825 [6:27:20<38:24:04, 12.55s/it] 14%|█▍        | 1812/12825 [6:27:41<46:23:58, 15.17s/it] 14%|█▍        | 1813/12825 [6:27:54<43:58:48, 14.38s/it] 14%|█▍        | 1814/12825 [6:28:06<42:16:22, 13.82s/it] 14%|█▍        | 1815/12825 [6:28:19<41:05:03, 13.43s/it] 14%|█▍        | 1816/12825 [6:28:31<40:15:31, 13.16s/it] 14%|█▍        | 1817/12825 [6:28:44<39:41:38, 12.98s/it] 14%|█▍        | 1818/12825 [6:28:56<39:14:11, 12.83s/it] 14%|█▍        | 1819/12825 [6:29:09<38:58:32, 12.75s/it] 14%|█▍        | 1820/12825 [6:29:21<38:48:15, 12.69s/it] 14%|█▍        | 1821/12825 [6:29:34<38:39:43, 12.65s/it] 14%|█▍        | 1822/12825 [6:29:46<38:33:58, 12.62s/it] 14%|█▍        | 1823/12825 [6:29:59<38:31:40, 12.61s/it] 14%|█▍        | 1824/12825 [6:30:12<38:28:30, 12.59s/it] 14%|█▍        | 1825/12825 [6:30:24<38:25:23, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 117119.95lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101192.47lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1825
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1825/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1825/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1775] due to args.save_total_limit
 14%|█▍        | 1826/12825 [6:30:37<38:42:27, 12.67s/it] 14%|█▍        | 1827/12825 [6:30:50<38:35:48, 12.63s/it] 14%|█▍        | 1828/12825 [6:31:02<38:29:56, 12.60s/it] 14%|█▍        | 1829/12825 [6:31:15<38:24:48, 12.58s/it] 14%|█▍        | 1830/12825 [6:31:27<38:24:06, 12.57s/it] 14%|█▍        | 1831/12825 [6:31:40<38:20:50, 12.56s/it] 14%|█▍        | 1832/12825 [6:31:52<38:17:24, 12.54s/it] 14%|█▍        | 1833/12825 [6:32:05<38:17:22, 12.54s/it] 14%|█▍        | 1834/12825 [6:32:17<38:15:40, 12.53s/it] 14%|█▍        | 1835/12825 [6:32:30<38:17:31, 12.54s/it] 14%|█▍        | 1836/12825 [6:32:42<38:17:00, 12.54s/it] 14%|█▍        | 1837/12825 [6:32:55<38:17:02, 12.54s/it] 14%|█▍        | 1838/12825 [6:33:07<38:15:06, 12.53s/it] 14%|█▍        | 1839/12825 [6:33:20<38:15:20, 12.54s/it] 14%|█▍        | 1840/12825 [6:33:33<38:15:55, 12.54s/it] 14%|█▍        | 1841/12825 [6:33:45<38:14:09, 12.53s/it] 14%|█▍        | 1842/12825 [6:33:58<38:14:22, 12.53s/it] 14%|█▍        | 1843/12825 [6:34:10<38:13:41, 12.53s/it] 14%|█▍        | 1844/12825 [6:34:23<38:12:30, 12.53s/it] 14%|█▍        | 1845/12825 [6:34:43<45:16:50, 14.85s/it] 14%|█▍        | 1846/12825 [6:34:55<43:08:56, 14.15s/it] 14%|█▍        | 1847/12825 [6:35:08<41:40:56, 13.67s/it] 14%|█▍        | 1848/12825 [6:35:20<40:38:19, 13.33s/it] 14%|█▍        | 1849/12825 [6:35:33<39:56:57, 13.10s/it] 14%|█▍        | 1850/12825 [6:35:46<39:24:50, 12.93s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120043.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103344.46lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1850
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1850/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1850/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1825] due to args.save_total_limit
 14%|█▍        | 1851/12825 [6:35:58<39:22:39, 12.92s/it] 14%|█▍        | 1852/12825 [6:36:11<39:02:18, 12.81s/it] 14%|█▍        | 1853/12825 [6:36:24<38:47:54, 12.73s/it] 14%|█▍        | 1854/12825 [6:36:36<38:38:14, 12.68s/it] 14%|█▍        | 1855/12825 [6:36:49<38:28:58, 12.63s/it] 14%|█▍        | 1856/12825 [6:37:01<38:25:03, 12.61s/it] 14%|█▍        | 1857/12825 [6:37:14<38:21:27, 12.59s/it] 14%|█▍        | 1858/12825 [6:37:26<38:20:46, 12.59s/it] 14%|█▍        | 1859/12825 [6:37:39<38:17:57, 12.57s/it] 15%|█▍        | 1860/12825 [6:37:51<38:17:45, 12.57s/it] 15%|█▍        | 1861/12825 [6:38:04<38:14:00, 12.55s/it] 15%|█▍        | 1862/12825 [6:38:17<38:13:59, 12.55s/it] 15%|█▍        | 1863/12825 [6:38:29<38:15:42, 12.57s/it] 15%|█▍        | 1864/12825 [6:38:42<38:13:05, 12.55s/it] 15%|█▍        | 1865/12825 [6:38:54<38:11:16, 12.54s/it] 15%|█▍        | 1866/12825 [6:39:07<38:10:18, 12.54s/it] 15%|█▍        | 1867/12825 [6:39:19<38:10:39, 12.54s/it] 15%|█▍        | 1868/12825 [6:39:32<38:08:37, 12.53s/it] 15%|█▍        | 1869/12825 [6:39:44<38:07:05, 12.53s/it] 15%|█▍        | 1870/12825 [6:39:57<38:08:34, 12.53s/it] 15%|█▍        | 1871/12825 [6:40:09<38:08:29, 12.54s/it] 15%|█▍        | 1872/12825 [6:40:22<38:10:20, 12.55s/it] 15%|█▍        | 1873/12825 [6:40:34<38:10:42, 12.55s/it] 15%|█▍        | 1874/12825 [6:40:47<38:11:00, 12.55s/it] 15%|█▍        | 1875/12825 [6:41:00<38:11:06, 12.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120330.55lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103399.29lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1875
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1875/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1875/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1800] due to args.save_total_limit
 15%|█▍        | 1876/12825 [6:41:13<38:30:05, 12.66s/it] 15%|█▍        | 1877/12825 [6:41:33<45:47:59, 15.06s/it] 15%|█▍        | 1878/12825 [6:41:46<43:33:08, 14.32s/it] 15%|█▍        | 1879/12825 [6:41:58<41:57:45, 13.80s/it] 15%|█▍        | 1880/12825 [6:42:11<40:47:35, 13.42s/it] 15%|█▍        | 1881/12825 [6:42:23<39:57:47, 13.15s/it] 15%|█▍        | 1882/12825 [6:42:36<39:25:07, 12.97s/it] 15%|█▍        | 1883/12825 [6:42:48<39:01:05, 12.84s/it] 15%|█▍        | 1884/12825 [6:43:01<38:44:04, 12.75s/it] 15%|█▍        | 1885/12825 [6:43:14<38:31:27, 12.68s/it] 15%|█▍        | 1886/12825 [6:43:26<38:23:21, 12.63s/it] 15%|█▍        | 1887/12825 [6:43:39<38:18:03, 12.61s/it] 15%|█▍        | 1888/12825 [6:43:51<38:14:24, 12.59s/it] 15%|█▍        | 1889/12825 [6:44:04<38:12:20, 12.58s/it] 15%|█▍        | 1890/12825 [6:44:16<38:09:54, 12.56s/it] 15%|█▍        | 1891/12825 [6:44:29<38:10:23, 12.57s/it] 15%|█▍        | 1892/12825 [6:44:41<38:06:37, 12.55s/it] 15%|█▍        | 1893/12825 [6:44:54<38:07:02, 12.55s/it] 15%|█▍        | 1894/12825 [6:45:06<38:06:19, 12.55s/it] 15%|█▍        | 1895/12825 [6:45:19<38:04:47, 12.54s/it] 15%|█▍        | 1896/12825 [6:45:31<38:02:03, 12.53s/it] 15%|█▍        | 1897/12825 [6:45:44<38:00:27, 12.52s/it] 15%|█▍        | 1898/12825 [6:45:56<38:02:05, 12.53s/it] 15%|█▍        | 1899/12825 [6:46:09<38:02:19, 12.53s/it] 15%|█▍        | 1900/12825 [6:46:22<38:01:27, 12.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120246.99lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103510.53lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1900
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1900/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1900/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1850] due to args.save_total_limit
 15%|█▍        | 1901/12825 [6:46:34<38:19:16, 12.63s/it] 15%|█▍        | 1902/12825 [6:46:47<38:11:39, 12.59s/it] 15%|█▍        | 1903/12825 [6:46:59<38:09:55, 12.58s/it] 15%|█▍        | 1904/12825 [6:47:12<38:07:14, 12.57s/it] 15%|█▍        | 1905/12825 [6:47:24<38:03:41, 12.55s/it] 15%|█▍        | 1906/12825 [6:47:37<38:03:19, 12.55s/it] 15%|█▍        | 1907/12825 [6:47:50<38:02:41, 12.54s/it] 15%|█▍        | 1908/12825 [6:48:02<38:00:35, 12.53s/it] 15%|█▍        | 1909/12825 [6:48:23<45:30:11, 15.01s/it] 15%|█▍        | 1910/12825 [6:48:35<43:12:40, 14.25s/it] 15%|█▍        | 1911/12825 [6:48:48<41:39:44, 13.74s/it] 15%|█▍        | 1912/12825 [6:49:00<40:32:47, 13.38s/it] 15%|█▍        | 1913/12825 [6:49:13<39:46:54, 13.12s/it] 15%|█▍        | 1914/12825 [6:49:25<39:13:59, 12.94s/it] 15%|█▍        | 1915/12825 [6:49:38<38:53:03, 12.83s/it] 15%|█▍        | 1916/12825 [6:49:51<38:36:47, 12.74s/it] 15%|█▍        | 1917/12825 [6:50:03<38:27:09, 12.69s/it] 15%|█▍        | 1918/12825 [6:50:16<38:19:31, 12.65s/it] 15%|█▍        | 1919/12825 [6:50:28<38:14:56, 12.63s/it] 15%|█▍        | 1920/12825 [6:50:41<38:11:07, 12.61s/it] 15%|█▍        | 1921/12825 [6:50:53<38:07:19, 12.59s/it] 15%|█▍        | 1922/12825 [6:51:06<38:04:29, 12.57s/it] 15%|█▍        | 1923/12825 [6:51:18<38:02:56, 12.56s/it] 15%|█▌        | 1924/12825 [6:51:31<38:01:38, 12.56s/it] 15%|█▌        | 1925/12825 [6:51:44<38:00:53, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120310.99lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 98861.64lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1925
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1925/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1925/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1900] due to args.save_total_limit
 15%|█▌        | 1926/12825 [6:51:57<38:28:58, 12.71s/it] 15%|█▌        | 1927/12825 [6:52:09<38:17:04, 12.65s/it] 15%|█▌        | 1928/12825 [6:52:22<38:11:26, 12.62s/it] 15%|█▌        | 1929/12825 [6:52:34<38:07:07, 12.59s/it] 15%|█▌        | 1930/12825 [6:52:47<38:03:41, 12.58s/it] 15%|█▌        | 1931/12825 [6:52:59<38:00:33, 12.56s/it] 15%|█▌        | 1932/12825 [6:53:12<37:58:22, 12.55s/it] 15%|█▌        | 1933/12825 [6:53:24<37:56:10, 12.54s/it] 15%|█▌        | 1934/12825 [6:53:37<37:54:55, 12.53s/it] 15%|█▌        | 1935/12825 [6:53:49<37:54:06, 12.53s/it] 15%|█▌        | 1936/12825 [6:54:02<37:52:04, 12.52s/it] 15%|█▌        | 1937/12825 [6:54:14<37:55:03, 12.54s/it] 15%|█▌        | 1938/12825 [6:54:27<37:54:43, 12.54s/it] 15%|█▌        | 1939/12825 [6:54:39<37:53:44, 12.53s/it] 15%|█▌        | 1940/12825 [6:54:52<37:53:18, 12.53s/it] 15%|█▌        | 1941/12825 [6:55:05<37:54:20, 12.54s/it] 15%|█▌        | 1942/12825 [6:55:25<44:57:34, 14.87s/it] 15%|█▌        | 1943/12825 [6:55:37<42:48:44, 14.16s/it] 15%|█▌        | 1944/12825 [6:55:50<41:22:07, 13.69s/it] 15%|█▌        | 1945/12825 [6:56:03<40:20:35, 13.35s/it] 15%|█▌        | 1946/12825 [6:56:15<39:36:04, 13.10s/it] 15%|█▌        | 1947/12825 [6:56:28<39:05:06, 12.93s/it] 15%|█▌        | 1948/12825 [6:56:40<38:42:33, 12.81s/it] 15%|█▌        | 1949/12825 [6:56:53<38:26:01, 12.72s/it] 15%|█▌        | 1950/12825 [6:57:05<38:14:49, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120247.75lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103505.04lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1950
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1950/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1950/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1925] due to args.save_total_limit
 15%|█▌        | 1951/12825 [6:57:18<38:26:33, 12.73s/it] 15%|█▌        | 1952/12825 [6:57:31<38:15:44, 12.67s/it] 15%|█▌        | 1953/12825 [6:57:43<38:06:46, 12.62s/it] 15%|█▌        | 1954/12825 [6:57:56<38:00:12, 12.59s/it] 15%|█▌        | 1955/12825 [6:58:08<37:57:37, 12.57s/it] 15%|█▌        | 1956/12825 [6:58:21<37:56:33, 12.57s/it] 15%|█▌        | 1957/12825 [6:58:33<37:54:13, 12.56s/it] 15%|█▌        | 1958/12825 [6:58:46<37:52:00, 12.54s/it] 15%|█▌        | 1959/12825 [6:58:58<37:52:33, 12.55s/it] 15%|█▌        | 1960/12825 [6:59:11<37:49:47, 12.53s/it] 15%|█▌        | 1961/12825 [6:59:23<37:49:13, 12.53s/it] 15%|█▌        | 1962/12825 [6:59:36<37:49:17, 12.53s/it] 15%|█▌        | 1963/12825 [6:59:48<37:49:04, 12.53s/it] 15%|█▌        | 1964/12825 [7:00:01<37:49:23, 12.54s/it] 15%|█▌        | 1965/12825 [7:00:13<37:47:46, 12.53s/it] 15%|█▌        | 1966/12825 [7:00:26<37:49:10, 12.54s/it] 15%|█▌        | 1967/12825 [7:00:39<37:47:56, 12.53s/it] 15%|█▌        | 1968/12825 [7:00:51<37:45:48, 12.52s/it] 15%|█▌        | 1969/12825 [7:01:04<37:47:00, 12.53s/it] 15%|█▌        | 1970/12825 [7:01:16<37:47:21, 12.53s/it] 15%|█▌        | 1971/12825 [7:01:29<37:49:41, 12.55s/it] 15%|█▌        | 1972/12825 [7:01:41<37:48:39, 12.54s/it] 15%|█▌        | 1973/12825 [7:01:54<37:48:14, 12.54s/it] 15%|█▌        | 1974/12825 [7:02:14<44:56:09, 14.91s/it] 15%|█▌        | 1975/12825 [7:02:27<42:44:46, 14.18s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120315.85lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103533.81lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1975
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1975/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1975/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-1975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1950] due to args.save_total_limit
 15%|█▌        | 1976/12825 [7:02:40<41:33:05, 13.79s/it] 15%|█▌        | 1977/12825 [7:02:52<40:23:12, 13.40s/it] 15%|█▌        | 1978/12825 [7:03:05<39:36:35, 13.15s/it] 15%|█▌        | 1979/12825 [7:03:17<39:02:02, 12.96s/it] 15%|█▌        | 1980/12825 [7:03:30<38:39:05, 12.83s/it] 15%|█▌        | 1981/12825 [7:03:42<38:22:35, 12.74s/it] 15%|█▌        | 1982/12825 [7:03:55<38:10:12, 12.67s/it] 15%|█▌        | 1983/12825 [7:04:07<38:00:08, 12.62s/it] 15%|█▌        | 1984/12825 [7:04:20<37:56:05, 12.60s/it] 15%|█▌        | 1985/12825 [7:04:32<37:52:52, 12.58s/it] 15%|█▌        | 1986/12825 [7:04:45<37:48:44, 12.56s/it] 15%|█▌        | 1987/12825 [7:04:57<37:46:11, 12.55s/it] 16%|█▌        | 1988/12825 [7:05:10<37:44:17, 12.54s/it] 16%|█▌        | 1989/12825 [7:05:22<37:43:39, 12.53s/it] 16%|█▌        | 1990/12825 [7:05:35<37:44:45, 12.54s/it] 16%|█▌        | 1991/12825 [7:05:47<37:44:49, 12.54s/it] 16%|█▌        | 1992/12825 [7:06:00<37:44:49, 12.54s/it] 16%|█▌        | 1993/12825 [7:06:13<37:45:13, 12.55s/it] 16%|█▌        | 1994/12825 [7:06:25<37:42:52, 12.54s/it] 16%|█▌        | 1995/12825 [7:06:38<37:43:26, 12.54s/it] 16%|█▌        | 1996/12825 [7:06:50<37:43:30, 12.54s/it] 16%|█▌        | 1997/12825 [7:07:03<37:42:39, 12.54s/it] 16%|█▌        | 1998/12825 [7:07:15<37:42:02, 12.54s/it] 16%|█▌        | 1999/12825 [7:07:28<37:41:07, 12.53s/it] 16%|█▌        | 2000/12825 [7:07:40<37:42:54, 12.54s/it]                                                          16%|█▌        | 2000/12825 [7:07:40<37:42:54, 12.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120291.69lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103567.04lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2000
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2000/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2000/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1875] due to args.save_total_limit
 16%|█▌        | 2001/12825 [7:07:53<37:59:38, 12.64s/it] 16%|█▌        | 2002/12825 [7:08:06<37:52:34, 12.60s/it] 16%|█▌        | 2003/12825 [7:08:18<37:50:08, 12.59s/it] 16%|█▌        | 2004/12825 [7:08:31<37:46:16, 12.57s/it] 16%|█▌        | 2005/12825 [7:08:43<37:44:39, 12.56s/it] 16%|█▌        | 2006/12825 [7:09:04<45:01:45, 14.98s/it] 16%|█▌        | 2007/12825 [7:09:16<42:49:22, 14.25s/it] 16%|█▌        | 2008/12825 [7:09:29<41:18:34, 13.75s/it] 16%|█▌        | 2009/12825 [7:09:42<40:14:39, 13.39s/it] 16%|█▌        | 2010/12825 [7:09:54<39:31:48, 13.16s/it] 16%|█▌        | 2011/12825 [7:10:07<38:58:07, 12.97s/it] 16%|█▌        | 2012/12825 [7:10:19<38:35:58, 12.85s/it] 16%|█▌        | 2013/12825 [7:10:32<38:22:16, 12.78s/it] 16%|█▌        | 2014/12825 [7:10:45<38:12:06, 12.72s/it] 16%|█▌        | 2015/12825 [7:10:57<38:04:56, 12.68s/it] 16%|█▌        | 2016/12825 [7:11:10<37:59:45, 12.65s/it] 16%|█▌        | 2017/12825 [7:11:22<37:58:19, 12.65s/it] 16%|█▌        | 2018/12825 [7:11:35<37:54:45, 12.63s/it] 16%|█▌        | 2019/12825 [7:11:48<37:53:21, 12.62s/it] 16%|█▌        | 2020/12825 [7:12:00<37:48:50, 12.60s/it] 16%|█▌        | 2021/12825 [7:12:13<37:47:08, 12.59s/it] 16%|█▌        | 2022/12825 [7:12:25<37:47:22, 12.59s/it] 16%|█▌        | 2023/12825 [7:12:38<37:46:37, 12.59s/it] 16%|█▌        | 2024/12825 [7:12:50<37:45:18, 12.58s/it] 16%|█▌        | 2025/12825 [7:13:03<37:43:26, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120292.20lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103530.97lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2025
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2025/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2025/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-1975] due to args.save_total_limit
 16%|█▌        | 2026/12825 [7:13:16<38:02:40, 12.68s/it] 16%|█▌        | 2027/12825 [7:13:28<37:58:31, 12.66s/it] 16%|█▌        | 2028/12825 [7:13:41<37:57:45, 12.66s/it] 16%|█▌        | 2029/12825 [7:13:54<37:53:45, 12.64s/it] 16%|█▌        | 2030/12825 [7:14:06<37:52:14, 12.63s/it] 16%|█▌        | 2031/12825 [7:14:19<37:50:23, 12.62s/it] 16%|█▌        | 2032/12825 [7:14:32<37:51:46, 12.63s/it] 16%|█▌        | 2033/12825 [7:14:44<37:48:24, 12.61s/it] 16%|█▌        | 2034/12825 [7:14:57<37:48:37, 12.61s/it] 16%|█▌        | 2035/12825 [7:15:09<37:49:01, 12.62s/it] 16%|█▌        | 2036/12825 [7:15:22<37:49:14, 12.62s/it] 16%|█▌        | 2037/12825 [7:15:35<37:47:56, 12.61s/it] 16%|█▌        | 2038/12825 [7:15:47<37:52:38, 12.64s/it] 16%|█▌        | 2039/12825 [7:16:08<44:47:47, 14.95s/it] 16%|█▌        | 2040/12825 [7:16:20<42:40:33, 14.25s/it] 16%|█▌        | 2041/12825 [7:16:33<41:16:21, 13.78s/it] 16%|█▌        | 2042/12825 [7:16:46<40:13:38, 13.43s/it] 16%|█▌        | 2043/12825 [7:16:58<39:28:04, 13.18s/it] 16%|█▌        | 2044/12825 [7:17:11<38:56:34, 13.00s/it] 16%|█▌        | 2045/12825 [7:17:23<38:33:55, 12.88s/it] 16%|█▌        | 2046/12825 [7:17:36<38:17:47, 12.79s/it] 16%|█▌        | 2047/12825 [7:17:49<38:10:50, 12.75s/it] 16%|█▌        | 2048/12825 [7:18:01<38:02:59, 12.71s/it] 16%|█▌        | 2049/12825 [7:18:14<37:58:05, 12.68s/it] 16%|█▌        | 2050/12825 [7:18:26<37:54:13, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120307.54lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103548.29lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2050
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2050/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2050/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2025] due to args.save_total_limit
 16%|█▌        | 2051/12825 [7:18:35<33:55:40, 11.34s/it] 16%|█▌        | 2052/12825 [7:18:36<24:29:10,  8.18s/it] 16%|█▌        | 2053/12825 [7:19:01<40:06:39, 13.41s/it] 16%|█▌        | 2054/12825 [7:19:14<39:23:51, 13.17s/it] 16%|█▌        | 2055/12825 [7:19:26<38:52:29, 12.99s/it] 16%|█▌        | 2056/12825 [7:19:39<38:30:53, 12.88s/it] 16%|█▌        | 2057/12825 [7:19:52<38:16:47, 12.80s/it] 16%|█▌        | 2058/12825 [7:20:04<38:06:33, 12.74s/it] 16%|█▌        | 2059/12825 [7:20:17<38:00:05, 12.71s/it] 16%|█▌        | 2060/12825 [7:20:29<37:54:35, 12.68s/it] 16%|█▌        | 2061/12825 [7:20:42<37:50:22, 12.66s/it] 16%|█▌        | 2062/12825 [7:20:55<37:46:44, 12.64s/it] 16%|█▌        | 2063/12825 [7:21:07<37:45:27, 12.63s/it] 16%|█▌        | 2064/12825 [7:21:20<37:42:45, 12.62s/it] 16%|█▌        | 2065/12825 [7:21:32<37:43:14, 12.62s/it] 16%|█▌        | 2066/12825 [7:21:45<37:42:22, 12.62s/it] 16%|█▌        | 2067/12825 [7:21:58<37:41:14, 12.61s/it] 16%|█▌        | 2068/12825 [7:22:10<37:38:20, 12.60s/it] 16%|█▌        | 2069/12825 [7:22:23<37:38:37, 12.60s/it] 16%|█▌        | 2070/12825 [7:22:35<37:38:55, 12.60s/it] 16%|█▌        | 2071/12825 [7:22:48<37:37:00, 12.59s/it] 16%|█▌        | 2072/12825 [7:23:08<44:40:35, 14.96s/it] 16%|█▌        | 2073/12825 [7:23:21<42:35:13, 14.26s/it] 16%|█▌        | 2074/12825 [7:23:34<41:06:21, 13.76s/it] 16%|█▌        | 2075/12825 [7:23:46<40:11:46, 13.46s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120241.63lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103187.21lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2075
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2075/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2075/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2050] due to args.save_total_limit
 16%|█▌        | 2076/12825 [7:23:59<39:46:39, 13.32s/it] 16%|█▌        | 2077/12825 [7:24:12<39:08:09, 13.11s/it] 16%|█▌        | 2078/12825 [7:24:25<38:41:12, 12.96s/it] 16%|█▌        | 2079/12825 [7:24:37<38:21:05, 12.85s/it] 16%|█▌        | 2080/12825 [7:24:50<38:05:50, 12.76s/it] 16%|█▌        | 2081/12825 [7:25:02<37:55:19, 12.71s/it] 16%|█▌        | 2082/12825 [7:25:15<37:51:21, 12.69s/it] 16%|█▌        | 2083/12825 [7:25:28<37:46:29, 12.66s/it] 16%|█▌        | 2084/12825 [7:25:40<37:43:41, 12.65s/it] 16%|█▋        | 2085/12825 [7:25:53<37:40:00, 12.63s/it] 16%|█▋        | 2086/12825 [7:26:05<37:38:07, 12.62s/it] 16%|█▋        | 2087/12825 [7:26:18<37:36:44, 12.61s/it] 16%|█▋        | 2088/12825 [7:26:31<37:33:58, 12.60s/it] 16%|█▋        | 2089/12825 [7:26:43<37:33:30, 12.59s/it] 16%|█▋        | 2090/12825 [7:26:56<37:35:00, 12.60s/it] 16%|█▋        | 2091/12825 [7:27:08<37:34:13, 12.60s/it] 16%|█▋        | 2092/12825 [7:27:21<37:34:16, 12.60s/it] 16%|█▋        | 2093/12825 [7:27:34<37:31:57, 12.59s/it] 16%|█▋        | 2094/12825 [7:27:46<37:30:52, 12.59s/it] 16%|█▋        | 2095/12825 [7:27:59<37:30:34, 12.58s/it] 16%|█▋        | 2096/12825 [7:28:11<37:29:28, 12.58s/it] 16%|█▋        | 2097/12825 [7:28:24<37:30:40, 12.59s/it] 16%|█▋        | 2098/12825 [7:28:36<37:32:29, 12.60s/it] 16%|█▋        | 2099/12825 [7:28:49<37:33:11, 12.60s/it] 16%|█▋        | 2100/12825 [7:29:02<37:33:37, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120240.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103471.28lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2075] due to args.save_total_limit
 16%|█▋        | 2101/12825 [7:29:15<37:51:44, 12.71s/it] 16%|█▋        | 2102/12825 [7:29:27<37:44:17, 12.67s/it] 16%|█▋        | 2103/12825 [7:29:40<37:42:07, 12.66s/it] 16%|█▋        | 2104/12825 [7:30:01<44:53:56, 15.08s/it] 16%|█▋        | 2105/12825 [7:30:13<42:43:33, 14.35s/it] 16%|█▋        | 2106/12825 [7:30:26<41:10:25, 13.83s/it] 16%|█▋        | 2107/12825 [7:30:38<40:02:06, 13.45s/it] 16%|█▋        | 2108/12825 [7:30:51<39:16:03, 13.19s/it] 16%|█▋        | 2109/12825 [7:31:04<38:45:25, 13.02s/it] 16%|█▋        | 2110/12825 [7:31:16<38:23:31, 12.90s/it] 16%|█▋        | 2111/12825 [7:31:29<38:05:34, 12.80s/it] 16%|█▋        | 2112/12825 [7:31:41<37:54:30, 12.74s/it] 16%|█▋        | 2113/12825 [7:31:54<37:48:08, 12.70s/it] 16%|█▋        | 2114/12825 [7:32:07<37:42:14, 12.67s/it] 16%|█▋        | 2115/12825 [7:32:19<37:37:51, 12.65s/it] 16%|█▋        | 2116/12825 [7:32:32<37:45:35, 12.69s/it] 17%|█▋        | 2117/12825 [7:32:45<37:37:43, 12.65s/it] 17%|█▋        | 2118/12825 [7:32:57<37:32:07, 12.62s/it] 17%|█▋        | 2119/12825 [7:33:10<37:28:27, 12.60s/it] 17%|█▋        | 2120/12825 [7:33:22<37:25:42, 12.59s/it] 17%|█▋        | 2121/12825 [7:33:35<37:24:32, 12.58s/it] 17%|█▋        | 2122/12825 [7:33:47<37:25:13, 12.59s/it] 17%|█▋        | 2123/12825 [7:34:00<37:24:37, 12.58s/it] 17%|█▋        | 2124/12825 [7:34:13<37:26:51, 12.60s/it] 17%|█▋        | 2125/12825 [7:34:25<37:27:17, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120169.41lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103438.39lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2000] due to args.save_total_limit
 17%|█▋        | 2126/12825 [7:34:38<37:45:02, 12.70s/it] 17%|█▋        | 2127/12825 [7:34:51<37:37:32, 12.66s/it] 17%|█▋        | 2128/12825 [7:35:03<37:32:16, 12.63s/it] 17%|█▋        | 2129/12825 [7:35:16<37:29:15, 12.62s/it] 17%|█▋        | 2130/12825 [7:35:28<37:27:26, 12.61s/it] 17%|█▋        | 2131/12825 [7:35:41<37:25:38, 12.60s/it] 17%|█▋        | 2132/12825 [7:35:54<37:27:08, 12.61s/it] 17%|█▋        | 2133/12825 [7:36:06<37:26:22, 12.61s/it] 17%|█▋        | 2134/12825 [7:36:19<37:28:44, 12.62s/it] 17%|█▋        | 2135/12825 [7:36:32<37:28:46, 12.62s/it] 17%|█▋        | 2136/12825 [7:36:53<45:20:20, 15.27s/it] 17%|█▋        | 2137/12825 [7:37:06<42:57:47, 14.47s/it] 17%|█▋        | 2138/12825 [7:37:18<41:18:46, 13.92s/it] 17%|█▋        | 2139/12825 [7:37:31<40:09:10, 13.53s/it] 17%|█▋        | 2140/12825 [7:37:43<39:17:53, 13.24s/it] 17%|█▋        | 2141/12825 [7:37:56<38:43:42, 13.05s/it] 17%|█▋        | 2142/12825 [7:38:09<38:20:24, 12.92s/it] 17%|█▋        | 2143/12825 [7:38:21<38:03:46, 12.83s/it] 17%|█▋        | 2144/12825 [7:38:34<37:51:23, 12.76s/it] 17%|█▋        | 2145/12825 [7:38:46<37:43:53, 12.72s/it] 17%|█▋        | 2146/12825 [7:38:59<37:39:18, 12.69s/it] 17%|█▋        | 2147/12825 [7:39:12<37:34:19, 12.67s/it] 17%|█▋        | 2148/12825 [7:39:24<37:30:42, 12.65s/it] 17%|█▋        | 2149/12825 [7:39:37<37:29:31, 12.64s/it] 17%|█▋        | 2150/12825 [7:39:50<37:26:42, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120267.42lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103470.61lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2100] due to args.save_total_limit
 17%|█▋        | 2151/12825 [7:40:03<37:45:33, 12.74s/it] 17%|█▋        | 2152/12825 [7:40:15<37:36:15, 12.68s/it] 17%|█▋        | 2153/12825 [7:40:28<37:31:42, 12.66s/it] 17%|█▋        | 2154/12825 [7:40:40<37:27:24, 12.64s/it] 17%|█▋        | 2155/12825 [7:40:53<37:24:41, 12.62s/it] 17%|█▋        | 2156/12825 [7:41:05<37:22:47, 12.61s/it] 17%|█▋        | 2157/12825 [7:41:18<37:22:25, 12.61s/it] 17%|█▋        | 2158/12825 [7:41:31<37:22:11, 12.61s/it] 17%|█▋        | 2159/12825 [7:41:43<37:19:53, 12.60s/it] 17%|█▋        | 2160/12825 [7:41:56<37:19:18, 12.60s/it] 17%|█▋        | 2161/12825 [7:42:08<37:19:59, 12.60s/it] 17%|█▋        | 2162/12825 [7:42:21<37:18:13, 12.59s/it] 17%|█▋        | 2163/12825 [7:42:34<37:16:45, 12.59s/it] 17%|█▋        | 2164/12825 [7:42:46<37:17:15, 12.59s/it] 17%|█▋        | 2165/12825 [7:42:59<37:18:01, 12.60s/it] 17%|█▋        | 2166/12825 [7:43:11<37:18:01, 12.60s/it] 17%|█▋        | 2167/12825 [7:43:24<37:17:39, 12.60s/it] 17%|█▋        | 2168/12825 [7:43:37<37:18:10, 12.60s/it] 17%|█▋        | 2169/12825 [7:43:57<44:28:31, 15.03s/it] 17%|█▋        | 2170/12825 [7:44:10<42:19:49, 14.30s/it] 17%|█▋        | 2171/12825 [7:44:23<40:48:27, 13.79s/it] 17%|█▋        | 2172/12825 [7:44:35<39:44:45, 13.43s/it] 17%|█▋        | 2173/12825 [7:44:48<39:01:37, 13.19s/it] 17%|█▋        | 2174/12825 [7:45:00<38:27:49, 13.00s/it] 17%|█▋        | 2175/12825 [7:45:13<38:07:12, 12.89s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120298.21lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103495.20lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2125] due to args.save_total_limit
 17%|█▋        | 2176/12825 [7:45:26<38:11:04, 12.91s/it] 17%|█▋        | 2177/12825 [7:45:38<37:54:51, 12.82s/it] 17%|█▋        | 2178/12825 [7:45:51<37:44:15, 12.76s/it] 17%|█▋        | 2179/12825 [7:46:04<37:36:58, 12.72s/it] 17%|█▋        | 2180/12825 [7:46:16<37:36:44, 12.72s/it] 17%|█▋        | 2181/12825 [7:46:29<37:30:24, 12.69s/it] 17%|█▋        | 2182/12825 [7:46:42<37:27:41, 12.67s/it] 17%|█▋        | 2183/12825 [7:46:54<37:25:49, 12.66s/it] 17%|█▋        | 2184/12825 [7:47:07<37:23:17, 12.65s/it] 17%|█▋        | 2185/12825 [7:47:20<37:20:28, 12.63s/it] 17%|█▋        | 2186/12825 [7:47:32<37:16:44, 12.61s/it] 17%|█▋        | 2187/12825 [7:47:45<37:14:31, 12.60s/it] 17%|█▋        | 2188/12825 [7:47:57<37:12:54, 12.60s/it] 17%|█▋        | 2189/12825 [7:48:10<37:11:55, 12.59s/it] 17%|█▋        | 2190/12825 [7:48:23<37:15:56, 12.61s/it] 17%|█▋        | 2191/12825 [7:48:35<37:21:25, 12.65s/it] 17%|█▋        | 2192/12825 [7:48:48<37:18:41, 12.63s/it] 17%|█▋        | 2193/12825 [7:49:00<37:18:10, 12.63s/it] 17%|█▋        | 2194/12825 [7:49:13<37:17:37, 12.63s/it] 17%|█▋        | 2195/12825 [7:49:26<37:18:54, 12.64s/it] 17%|█▋        | 2196/12825 [7:49:38<37:16:28, 12.62s/it] 17%|█▋        | 2197/12825 [7:49:51<37:14:41, 12.62s/it] 17%|█▋        | 2198/12825 [7:50:04<37:16:03, 12.62s/it] 17%|█▋        | 2199/12825 [7:50:16<37:19:59, 12.65s/it] 17%|█▋        | 2200/12825 [7:50:29<37:16:30, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120325.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103578.31lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2150] due to args.save_total_limit
 17%|█▋        | 2201/12825 [7:50:50<44:42:24, 15.15s/it] 17%|█▋        | 2202/12825 [7:51:02<42:25:31, 14.38s/it] 17%|█▋        | 2203/12825 [7:51:15<40:50:27, 13.84s/it] 17%|█▋        | 2204/12825 [7:51:28<39:44:19, 13.47s/it] 17%|█▋        | 2205/12825 [7:51:40<38:57:06, 13.20s/it] 17%|█▋        | 2206/12825 [7:51:53<38:25:46, 13.03s/it] 17%|█▋        | 2207/12825 [7:52:05<38:02:09, 12.90s/it] 17%|█▋        | 2208/12825 [7:52:18<37:48:39, 12.82s/it] 17%|█▋        | 2209/12825 [7:52:31<37:35:53, 12.75s/it] 17%|█▋        | 2210/12825 [7:52:43<37:27:45, 12.71s/it] 17%|█▋        | 2211/12825 [7:52:56<37:22:28, 12.68s/it] 17%|█▋        | 2212/12825 [7:53:09<37:17:53, 12.65s/it] 17%|█▋        | 2213/12825 [7:53:21<37:16:00, 12.64s/it] 17%|█▋        | 2214/12825 [7:53:34<37:12:33, 12.62s/it] 17%|█▋        | 2215/12825 [7:53:46<37:11:26, 12.62s/it] 17%|█▋        | 2216/12825 [7:53:59<37:11:53, 12.62s/it] 17%|█▋        | 2217/12825 [7:54:12<37:10:49, 12.62s/it] 17%|█▋        | 2218/12825 [7:54:24<37:08:07, 12.60s/it] 17%|█▋        | 2219/12825 [7:54:37<37:07:25, 12.60s/it] 17%|█▋        | 2220/12825 [7:54:49<37:06:48, 12.60s/it] 17%|█▋        | 2221/12825 [7:55:02<37:06:04, 12.60s/it] 17%|█▋        | 2222/12825 [7:55:14<37:05:45, 12.60s/it] 17%|█▋        | 2223/12825 [7:55:27<37:07:13, 12.60s/it] 17%|█▋        | 2224/12825 [7:55:40<37:07:36, 12.61s/it] 17%|█▋        | 2225/12825 [7:55:52<37:06:41, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120226.82lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103472.88lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2175] due to args.save_total_limit
 17%|█▋        | 2226/12825 [7:56:05<37:25:30, 12.71s/it] 17%|█▋        | 2227/12825 [7:56:18<37:16:31, 12.66s/it] 17%|█▋        | 2228/12825 [7:56:30<37:13:36, 12.65s/it] 17%|█▋        | 2229/12825 [7:56:43<37:12:14, 12.64s/it] 17%|█▋        | 2230/12825 [7:56:56<37:10:39, 12.63s/it] 17%|█▋        | 2231/12825 [7:57:08<37:06:42, 12.61s/it] 17%|█▋        | 2232/12825 [7:57:21<37:06:49, 12.61s/it] 17%|█▋        | 2233/12825 [7:57:34<37:07:41, 12.62s/it] 17%|█▋        | 2234/12825 [7:57:54<44:05:38, 14.99s/it] 17%|█▋        | 2235/12825 [7:58:07<42:00:10, 14.28s/it] 17%|█▋        | 2236/12825 [7:58:19<40:31:30, 13.78s/it] 17%|█▋        | 2237/12825 [7:58:32<39:29:08, 13.43s/it] 17%|█▋        | 2238/12825 [7:58:44<38:46:22, 13.18s/it] 17%|█▋        | 2239/12825 [7:58:57<38:16:50, 13.02s/it] 17%|█▋        | 2240/12825 [7:59:10<37:56:20, 12.90s/it] 17%|█▋        | 2241/12825 [7:59:22<37:42:47, 12.83s/it] 17%|█▋        | 2242/12825 [7:59:35<37:30:55, 12.76s/it] 17%|█▋        | 2243/12825 [7:59:48<37:24:41, 12.73s/it] 17%|█▋        | 2244/12825 [8:00:00<37:18:07, 12.69s/it] 18%|█▊        | 2245/12825 [8:00:13<37:13:44, 12.67s/it] 18%|█▊        | 2246/12825 [8:00:26<37:11:56, 12.66s/it] 18%|█▊        | 2247/12825 [8:00:38<37:11:21, 12.66s/it] 18%|█▊        | 2248/12825 [8:00:51<37:08:11, 12.64s/it] 18%|█▊        | 2249/12825 [8:01:03<37:07:26, 12.64s/it] 18%|█▊        | 2250/12825 [8:01:16<37:05:38, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120225.16lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103497.38lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2200] due to args.save_total_limit
 18%|█▊        | 2251/12825 [8:01:29<37:20:58, 12.72s/it] 18%|█▊        | 2252/12825 [8:01:42<37:14:40, 12.68s/it] 18%|█▊        | 2253/12825 [8:01:54<37:13:19, 12.67s/it] 18%|█▊        | 2254/12825 [8:02:07<37:08:40, 12.65s/it] 18%|█▊        | 2255/12825 [8:02:19<37:09:17, 12.65s/it] 18%|█▊        | 2256/12825 [8:02:32<37:08:04, 12.65s/it] 18%|█▊        | 2257/12825 [8:02:45<37:07:04, 12.64s/it] 18%|█▊        | 2258/12825 [8:02:57<37:03:50, 12.63s/it] 18%|█▊        | 2259/12825 [8:03:10<37:03:23, 12.63s/it] 18%|█▊        | 2260/12825 [8:03:23<37:02:23, 12.62s/it] 18%|█▊        | 2261/12825 [8:03:35<37:00:38, 12.61s/it] 18%|█▊        | 2262/12825 [8:03:48<37:01:38, 12.62s/it] 18%|█▊        | 2263/12825 [8:04:00<37:00:22, 12.61s/it] 18%|█▊        | 2264/12825 [8:04:13<37:00:43, 12.62s/it] 18%|█▊        | 2265/12825 [8:04:26<36:59:07, 12.61s/it] 18%|█▊        | 2266/12825 [8:04:46<43:48:40, 14.94s/it] 18%|█▊        | 2267/12825 [8:04:59<41:46:42, 14.25s/it] 18%|█▊        | 2268/12825 [8:05:11<40:20:44, 13.76s/it] 18%|█▊        | 2269/12825 [8:05:24<39:20:34, 13.42s/it] 18%|█▊        | 2270/12825 [8:05:36<38:36:57, 13.17s/it] 18%|█▊        | 2271/12825 [8:05:49<38:08:13, 13.01s/it] 18%|█▊        | 2272/12825 [8:06:02<37:44:35, 12.88s/it] 18%|█▊        | 2273/12825 [8:06:14<37:32:51, 12.81s/it] 18%|█▊        | 2274/12825 [8:06:27<37:22:15, 12.75s/it] 18%|█▊        | 2275/12825 [8:06:39<37:15:25, 12.71s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120374.68lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103658.05lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2225] due to args.save_total_limit
 18%|█▊        | 2276/12825 [8:06:52<37:28:35, 12.79s/it] 18%|█▊        | 2277/12825 [8:07:05<37:19:38, 12.74s/it] 18%|█▊        | 2278/12825 [8:07:18<37:15:03, 12.71s/it] 18%|█▊        | 2279/12825 [8:07:30<37:10:39, 12.69s/it] 18%|█▊        | 2280/12825 [8:07:43<37:06:29, 12.67s/it] 18%|█▊        | 2281/12825 [8:07:56<37:04:26, 12.66s/it] 18%|█▊        | 2282/12825 [8:08:08<37:02:29, 12.65s/it] 18%|█▊        | 2283/12825 [8:08:21<37:00:16, 12.64s/it] 18%|█▊        | 2284/12825 [8:08:33<36:58:37, 12.63s/it] 18%|█▊        | 2285/12825 [8:08:46<36:56:17, 12.62s/it] 18%|█▊        | 2286/12825 [8:08:59<36:56:09, 12.62s/it] 18%|█▊        | 2287/12825 [8:09:11<36:56:50, 12.62s/it] 18%|█▊        | 2288/12825 [8:09:24<36:58:11, 12.63s/it] 18%|█▊        | 2289/12825 [8:09:37<36:55:59, 12.62s/it] 18%|█▊        | 2290/12825 [8:09:49<36:54:16, 12.61s/it] 18%|█▊        | 2291/12825 [8:10:02<36:54:26, 12.61s/it] 18%|█▊        | 2292/12825 [8:10:14<36:52:57, 12.61s/it] 18%|█▊        | 2293/12825 [8:10:27<36:54:17, 12.61s/it] 18%|█▊        | 2294/12825 [8:10:40<36:53:26, 12.61s/it] 18%|█▊        | 2295/12825 [8:10:52<36:54:23, 12.62s/it] 18%|█▊        | 2296/12825 [8:11:05<36:54:41, 12.62s/it] 18%|█▊        | 2297/12825 [8:11:17<36:52:50, 12.61s/it] 18%|█▊        | 2298/12825 [8:11:38<43:53:27, 15.01s/it] 18%|█▊        | 2299/12825 [8:11:51<41:45:07, 14.28s/it] 18%|█▊        | 2300/12825 [8:12:03<40:15:35, 13.77s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120206.78lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103494.07lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2250] due to args.save_total_limit
 18%|█▊        | 2301/12825 [8:12:16<39:32:28, 13.53s/it] 18%|█▊        | 2302/12825 [8:12:29<38:42:22, 13.24s/it] 18%|█▊        | 2303/12825 [8:12:41<38:06:51, 13.04s/it] 18%|█▊        | 2304/12825 [8:12:54<37:45:04, 12.92s/it] 18%|█▊        | 2305/12825 [8:13:07<37:30:31, 12.84s/it] 18%|█▊        | 2306/12825 [8:13:19<37:17:52, 12.76s/it] 18%|█▊        | 2307/12825 [8:13:32<37:06:40, 12.70s/it] 18%|█▊        | 2308/12825 [8:13:44<37:04:25, 12.69s/it] 18%|█▊        | 2309/12825 [8:13:57<36:57:07, 12.65s/it] 18%|█▊        | 2310/12825 [8:14:10<36:51:17, 12.62s/it] 18%|█▊        | 2311/12825 [8:14:22<36:57:21, 12.65s/it] 18%|█▊        | 2312/12825 [8:14:35<37:02:32, 12.68s/it] 18%|█▊        | 2313/12825 [8:14:48<36:59:03, 12.67s/it] 18%|█▊        | 2314/12825 [8:15:00<36:56:24, 12.65s/it] 18%|█▊        | 2315/12825 [8:15:13<36:52:26, 12.63s/it] 18%|█▊        | 2316/12825 [8:15:25<36:51:07, 12.62s/it] 18%|█▊        | 2317/12825 [8:15:38<36:46:49, 12.60s/it] 18%|█▊        | 2318/12825 [8:15:51<36:44:24, 12.59s/it] 18%|█▊        | 2319/12825 [8:16:03<36:44:09, 12.59s/it] 18%|█▊        | 2320/12825 [8:16:16<36:42:44, 12.58s/it] 18%|█▊        | 2321/12825 [8:16:28<36:42:09, 12.58s/it] 18%|█▊        | 2322/12825 [8:16:41<36:41:52, 12.58s/it] 18%|█▊        | 2323/12825 [8:16:53<36:41:28, 12.58s/it] 18%|█▊        | 2324/12825 [8:17:06<36:40:48, 12.57s/it] 18%|█▊        | 2325/12825 [8:17:19<36:39:19, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 46208.99lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 43497.56lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2275] due to args.save_total_limit
 18%|█▊        | 2326/12825 [8:17:32<37:19:14, 12.80s/it] 18%|█▊        | 2327/12825 [8:17:44<37:09:01, 12.74s/it] 18%|█▊        | 2328/12825 [8:17:57<36:59:08, 12.68s/it] 18%|█▊        | 2329/12825 [8:18:10<36:52:13, 12.65s/it] 18%|█▊        | 2330/12825 [8:18:31<44:07:03, 15.13s/it] 18%|█▊        | 2331/12825 [8:18:43<41:53:30, 14.37s/it] 18%|█▊        | 2332/12825 [8:18:56<40:19:38, 13.84s/it] 18%|█▊        | 2333/12825 [8:19:08<39:12:00, 13.45s/it] 18%|█▊        | 2334/12825 [8:19:21<38:27:54, 13.20s/it] 18%|█▊        | 2335/12825 [8:19:33<37:55:34, 13.02s/it] 18%|█▊        | 2336/12825 [8:19:46<37:32:57, 12.89s/it] 18%|█▊        | 2337/12825 [8:19:59<37:16:48, 12.80s/it] 18%|█▊        | 2338/12825 [8:20:11<37:04:13, 12.73s/it] 18%|█▊        | 2339/12825 [8:20:24<36:55:21, 12.68s/it] 18%|█▊        | 2340/12825 [8:20:36<36:49:39, 12.64s/it] 18%|█▊        | 2341/12825 [8:20:49<36:44:38, 12.62s/it] 18%|█▊        | 2342/12825 [8:21:01<36:41:29, 12.60s/it] 18%|█▊        | 2343/12825 [8:21:14<36:41:05, 12.60s/it] 18%|█▊        | 2344/12825 [8:21:27<36:39:37, 12.59s/it] 18%|█▊        | 2345/12825 [8:21:39<36:37:35, 12.58s/it] 18%|█▊        | 2346/12825 [8:21:52<36:36:27, 12.58s/it] 18%|█▊        | 2347/12825 [8:22:04<36:36:35, 12.58s/it] 18%|█▊        | 2348/12825 [8:22:17<36:36:28, 12.58s/it] 18%|█▊        | 2349/12825 [8:22:29<36:34:35, 12.57s/it] 18%|█▊        | 2350/12825 [8:22:42<36:35:14, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120168.52lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103422.99lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2325] due to args.save_total_limit
 18%|█▊        | 2351/12825 [8:22:55<36:52:19, 12.67s/it] 18%|█▊        | 2352/12825 [8:23:08<36:48:04, 12.65s/it] 18%|█▊        | 2353/12825 [8:23:20<36:45:17, 12.64s/it] 18%|█▊        | 2354/12825 [8:23:33<36:39:48, 12.61s/it] 18%|█▊        | 2355/12825 [8:23:45<36:38:58, 12.60s/it] 18%|█▊        | 2356/12825 [8:23:58<36:37:59, 12.60s/it] 18%|█▊        | 2357/12825 [8:24:10<36:37:52, 12.60s/it] 18%|█▊        | 2358/12825 [8:24:23<36:36:29, 12.59s/it] 18%|█▊        | 2359/12825 [8:24:36<36:35:29, 12.59s/it] 18%|█▊        | 2360/12825 [8:24:48<36:33:53, 12.58s/it] 18%|█▊        | 2361/12825 [8:25:01<36:32:55, 12.57s/it] 18%|█▊        | 2362/12825 [8:25:13<36:32:16, 12.57s/it] 18%|█▊        | 2363/12825 [8:25:34<43:39:08, 15.02s/it] 18%|█▊        | 2364/12825 [8:25:47<41:29:43, 14.28s/it] 18%|█▊        | 2365/12825 [8:25:59<39:59:28, 13.76s/it] 18%|█▊        | 2366/12825 [8:26:12<38:58:11, 13.41s/it] 18%|█▊        | 2367/12825 [8:26:24<38:13:05, 13.16s/it] 18%|█▊        | 2368/12825 [8:26:37<37:44:34, 12.99s/it] 18%|█▊        | 2369/12825 [8:26:49<37:21:49, 12.86s/it] 18%|█▊        | 2370/12825 [8:27:02<37:06:08, 12.78s/it] 18%|█▊        | 2371/12825 [8:27:15<36:54:17, 12.71s/it] 18%|█▊        | 2372/12825 [8:27:27<36:48:35, 12.68s/it] 19%|█▊        | 2373/12825 [8:27:40<36:44:30, 12.66s/it] 19%|█▊        | 2374/12825 [8:27:52<36:40:07, 12.63s/it] 19%|█▊        | 2375/12825 [8:28:05<36:38:35, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120196.32lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103444.06lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2300] due to args.save_total_limit
 19%|█▊        | 2376/12825 [8:28:18<36:55:59, 12.72s/it] 19%|█▊        | 2377/12825 [8:28:30<36:47:51, 12.68s/it] 19%|█▊        | 2378/12825 [8:28:43<36:43:13, 12.65s/it] 19%|█▊        | 2379/12825 [8:28:56<36:41:50, 12.65s/it] 19%|█▊        | 2380/12825 [8:29:08<36:36:59, 12.62s/it] 19%|█▊        | 2381/12825 [8:29:21<36:33:28, 12.60s/it] 19%|█▊        | 2382/12825 [8:29:33<36:29:31, 12.58s/it] 19%|█▊        | 2383/12825 [8:29:46<36:29:03, 12.58s/it] 19%|█▊        | 2384/12825 [8:29:59<36:27:59, 12.57s/it] 19%|█▊        | 2385/12825 [8:30:11<36:27:37, 12.57s/it] 19%|█▊        | 2386/12825 [8:30:24<36:27:09, 12.57s/it] 19%|█▊        | 2387/12825 [8:30:36<36:25:14, 12.56s/it] 19%|█▊        | 2388/12825 [8:30:49<36:26:31, 12.57s/it] 19%|█▊        | 2389/12825 [8:31:01<36:25:07, 12.56s/it] 19%|█▊        | 2390/12825 [8:31:14<36:24:52, 12.56s/it] 19%|█▊        | 2391/12825 [8:31:26<36:23:53, 12.56s/it] 19%|█▊        | 2392/12825 [8:31:39<36:25:12, 12.57s/it] 19%|█▊        | 2393/12825 [8:31:52<36:24:29, 12.56s/it] 19%|█▊        | 2394/12825 [8:32:04<36:24:46, 12.57s/it] 19%|█▊        | 2395/12825 [8:32:25<43:16:52, 14.94s/it] 19%|█▊        | 2396/12825 [8:32:37<41:13:57, 14.23s/it] 19%|█▊        | 2397/12825 [8:32:50<39:47:02, 13.73s/it] 19%|█▊        | 2398/12825 [8:33:02<38:45:51, 13.38s/it] 19%|█▊        | 2399/12825 [8:33:15<38:03:20, 13.14s/it] 19%|█▊        | 2400/12825 [8:33:27<37:34:06, 12.97s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120117.15lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103493.50lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2350] due to args.save_total_limit
 19%|█▊        | 2401/12825 [8:33:40<37:27:31, 12.94s/it] 19%|█▊        | 2402/12825 [8:33:53<37:05:48, 12.81s/it] 19%|█▊        | 2403/12825 [8:34:05<36:53:06, 12.74s/it] 19%|█▊        | 2404/12825 [8:34:18<36:44:25, 12.69s/it] 19%|█▉        | 2405/12825 [8:34:31<36:37:39, 12.65s/it] 19%|█▉        | 2406/12825 [8:34:43<36:32:44, 12.63s/it] 19%|█▉        | 2407/12825 [8:34:56<36:29:34, 12.61s/it] 19%|█▉        | 2408/12825 [8:35:08<36:25:30, 12.59s/it] 19%|█▉        | 2409/12825 [8:35:21<36:24:25, 12.58s/it] 19%|█▉        | 2410/12825 [8:35:33<36:22:24, 12.57s/it] 19%|█▉        | 2411/12825 [8:35:46<36:21:38, 12.57s/it] 19%|█▉        | 2412/12825 [8:35:58<36:19:55, 12.56s/it] 19%|█▉        | 2413/12825 [8:36:11<36:17:43, 12.55s/it] 19%|█▉        | 2414/12825 [8:36:24<36:17:18, 12.55s/it] 19%|█▉        | 2415/12825 [8:36:36<36:17:53, 12.55s/it] 19%|█▉        | 2416/12825 [8:36:49<36:19:58, 12.57s/it] 19%|█▉        | 2417/12825 [8:37:01<36:17:46, 12.55s/it] 19%|█▉        | 2418/12825 [8:37:14<36:17:48, 12.56s/it] 19%|█▉        | 2419/12825 [8:37:26<36:19:45, 12.57s/it] 19%|█▉        | 2420/12825 [8:37:39<36:20:24, 12.57s/it] 19%|█▉        | 2421/12825 [8:37:52<36:19:39, 12.57s/it] 19%|█▉        | 2422/12825 [8:38:04<36:20:56, 12.58s/it] 19%|█▉        | 2423/12825 [8:38:17<36:18:15, 12.56s/it] 19%|█▉        | 2424/12825 [8:38:29<36:17:47, 12.56s/it] 19%|█▉        | 2425/12825 [8:38:42<36:16:56, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120190.58lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103534.66lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2400] due to args.save_total_limit
 19%|█▉        | 2426/12825 [8:38:55<36:32:28, 12.65s/it] 19%|█▉        | 2427/12825 [8:39:07<36:27:54, 12.62s/it] 19%|█▉        | 2428/12825 [8:39:29<44:33:32, 15.43s/it] 19%|█▉        | 2429/12825 [8:39:42<42:05:42, 14.58s/it] 19%|█▉        | 2430/12825 [8:39:54<40:21:24, 13.98s/it] 19%|█▉        | 2431/12825 [8:40:07<39:08:50, 13.56s/it] 19%|█▉        | 2432/12825 [8:40:19<38:14:48, 13.25s/it] 19%|█▉        | 2433/12825 [8:40:32<37:40:29, 13.05s/it] 19%|█▉        | 2434/12825 [8:40:45<37:16:22, 12.91s/it] 19%|█▉        | 2435/12825 [8:40:57<36:57:07, 12.80s/it] 19%|█▉        | 2436/12825 [8:41:10<36:45:02, 12.73s/it] 19%|█▉        | 2437/12825 [8:41:22<36:36:05, 12.68s/it] 19%|█▉        | 2438/12825 [8:41:35<36:29:53, 12.65s/it] 19%|█▉        | 2439/12825 [8:41:47<36:24:42, 12.62s/it] 19%|█▉        | 2440/12825 [8:42:00<36:21:57, 12.61s/it] 19%|█▉        | 2441/12825 [8:42:13<36:20:31, 12.60s/it] 19%|█▉        | 2442/12825 [8:42:25<36:19:44, 12.60s/it] 19%|█▉        | 2443/12825 [8:42:38<36:17:29, 12.58s/it] 19%|█▉        | 2444/12825 [8:42:50<36:15:05, 12.57s/it] 19%|█▉        | 2445/12825 [8:43:03<36:14:41, 12.57s/it] 19%|█▉        | 2446/12825 [8:43:15<36:13:09, 12.56s/it] 19%|█▉        | 2447/12825 [8:43:28<36:13:52, 12.57s/it] 19%|█▉        | 2448/12825 [8:43:41<36:14:40, 12.57s/it] 19%|█▉        | 2449/12825 [8:43:53<36:14:15, 12.57s/it] 19%|█▉        | 2450/12825 [8:44:06<36:15:01, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120304.60lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103545.45lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2425] due to args.save_total_limit
 19%|█▉        | 2451/12825 [8:44:19<36:31:51, 12.68s/it] 19%|█▉        | 2452/12825 [8:44:31<36:24:24, 12.64s/it] 19%|█▉        | 2453/12825 [8:44:44<36:19:49, 12.61s/it] 19%|█▉        | 2454/12825 [8:44:56<36:18:22, 12.60s/it] 19%|█▉        | 2455/12825 [8:45:09<36:16:39, 12.59s/it] 19%|█▉        | 2456/12825 [8:45:21<36:14:30, 12.58s/it] 19%|█▉        | 2457/12825 [8:45:34<36:12:18, 12.57s/it] 19%|█▉        | 2458/12825 [8:45:47<36:11:13, 12.57s/it] 19%|█▉        | 2459/12825 [8:45:59<36:11:46, 12.57s/it] 19%|█▉        | 2460/12825 [8:46:20<43:27:30, 15.09s/it] 19%|█▉        | 2461/12825 [8:46:33<41:17:17, 14.34s/it] 19%|█▉        | 2462/12825 [8:46:45<39:44:50, 13.81s/it] 19%|█▉        | 2463/12825 [8:46:58<38:42:45, 13.45s/it] 19%|█▉        | 2464/12825 [8:47:10<37:56:02, 13.18s/it] 19%|█▉        | 2465/12825 [8:47:23<37:24:00, 13.00s/it] 19%|█▉        | 2466/12825 [8:47:36<37:00:55, 12.86s/it] 19%|█▉        | 2467/12825 [8:47:48<36:43:59, 12.77s/it] 19%|█▉        | 2468/12825 [8:48:01<36:33:37, 12.71s/it] 19%|█▉        | 2469/12825 [8:48:13<36:24:38, 12.66s/it] 19%|█▉        | 2470/12825 [8:48:26<36:19:40, 12.63s/it] 19%|█▉        | 2471/12825 [8:48:38<36:15:36, 12.61s/it] 19%|█▉        | 2472/12825 [8:48:51<36:12:02, 12.59s/it] 19%|█▉        | 2473/12825 [8:49:03<36:10:24, 12.58s/it] 19%|█▉        | 2474/12825 [8:49:16<36:09:01, 12.57s/it] 19%|█▉        | 2475/12825 [8:49:29<36:08:11, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120269.34lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103547.72lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2375] due to args.save_total_limit
 19%|█▉        | 2476/12825 [8:49:42<36:29:38, 12.69s/it] 19%|█▉        | 2477/12825 [8:49:54<36:24:01, 12.66s/it] 19%|█▉        | 2478/12825 [8:50:07<36:18:07, 12.63s/it] 19%|█▉        | 2479/12825 [8:50:19<36:15:54, 12.62s/it] 19%|█▉        | 2480/12825 [8:50:32<36:13:25, 12.61s/it] 19%|█▉        | 2481/12825 [8:50:44<36:12:10, 12.60s/it] 19%|█▉        | 2482/12825 [8:50:57<36:11:23, 12.60s/it] 19%|█▉        | 2483/12825 [8:51:10<36:10:12, 12.59s/it] 19%|█▉        | 2484/12825 [8:51:22<36:08:32, 12.58s/it] 19%|█▉        | 2485/12825 [8:51:35<36:07:38, 12.58s/it] 19%|█▉        | 2486/12825 [8:51:47<36:08:05, 12.58s/it] 19%|█▉        | 2487/12825 [8:52:00<36:08:12, 12.58s/it] 19%|█▉        | 2488/12825 [8:52:12<36:07:51, 12.58s/it] 19%|█▉        | 2489/12825 [8:52:25<36:07:51, 12.58s/it] 19%|█▉        | 2490/12825 [8:52:38<36:07:33, 12.58s/it] 19%|█▉        | 2491/12825 [8:52:50<36:04:34, 12.57s/it] 19%|█▉        | 2492/12825 [8:53:11<42:49:32, 14.92s/it] 19%|█▉        | 2493/12825 [8:53:23<40:46:45, 14.21s/it] 19%|█▉        | 2494/12825 [8:53:36<39:23:45, 13.73s/it] 19%|█▉        | 2495/12825 [8:53:48<38:23:58, 13.38s/it] 19%|█▉        | 2496/12825 [8:54:01<37:42:46, 13.14s/it] 19%|█▉        | 2497/12825 [8:54:13<37:11:09, 12.96s/it] 19%|█▉        | 2498/12825 [8:54:26<36:51:30, 12.85s/it] 19%|█▉        | 2499/12825 [8:54:39<36:35:07, 12.75s/it] 19%|█▉        | 2500/12825 [8:54:51<36:27:11, 12.71s/it]                                                          19%|█▉        | 2500/12825 [8:54:51<36:27:11, 12.71s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120192.49lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103455.59lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2450] due to args.save_total_limit
 20%|█▉        | 2501/12825 [8:55:04<36:36:49, 12.77s/it] 20%|█▉        | 2502/12825 [8:55:17<36:24:59, 12.70s/it] 20%|█▉        | 2503/12825 [8:55:29<36:17:19, 12.66s/it] 20%|█▉        | 2504/12825 [8:55:42<36:10:51, 12.62s/it] 20%|█▉        | 2505/12825 [8:55:54<36:07:30, 12.60s/it] 20%|█▉        | 2506/12825 [8:56:07<36:04:44, 12.59s/it] 20%|█▉        | 2507/12825 [8:56:19<36:02:12, 12.57s/it] 20%|█▉        | 2508/12825 [8:56:32<36:03:37, 12.58s/it] 20%|█▉        | 2509/12825 [8:56:45<36:03:27, 12.58s/it] 20%|█▉        | 2510/12825 [8:56:57<36:02:19, 12.58s/it] 20%|█▉        | 2511/12825 [8:57:10<36:03:20, 12.58s/it] 20%|█▉        | 2512/12825 [8:57:22<36:03:45, 12.59s/it] 20%|█▉        | 2513/12825 [8:57:35<36:03:40, 12.59s/it] 20%|█▉        | 2514/12825 [8:57:47<36:01:44, 12.58s/it] 20%|█▉        | 2515/12825 [8:58:00<36:00:59, 12.58s/it] 20%|█▉        | 2516/12825 [8:58:13<36:01:52, 12.58s/it] 20%|█▉        | 2517/12825 [8:58:25<36:13:44, 12.65s/it] 20%|█▉        | 2518/12825 [8:58:38<36:09:30, 12.63s/it] 20%|█▉        | 2519/12825 [8:58:51<36:06:58, 12.62s/it] 20%|█▉        | 2520/12825 [8:59:03<36:03:41, 12.60s/it] 20%|█▉        | 2521/12825 [8:59:16<35:59:59, 12.58s/it] 20%|█▉        | 2522/12825 [8:59:28<35:59:06, 12.57s/it] 20%|█▉        | 2523/12825 [8:59:41<35:59:34, 12.58s/it] 20%|█▉        | 2524/12825 [8:59:53<35:58:45, 12.57s/it] 20%|█▉        | 2525/12825 [9:00:13<42:22:22, 14.81s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120187.26lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103438.76lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2475] due to args.save_total_limit
 20%|█▉        | 2526/12825 [9:00:26<40:43:31, 14.24s/it] 20%|█▉        | 2527/12825 [9:00:39<39:17:30, 13.74s/it] 20%|█▉        | 2528/12825 [9:00:51<38:18:39, 13.39s/it] 20%|█▉        | 2529/12825 [9:01:04<37:35:39, 13.14s/it] 20%|█▉        | 2530/12825 [9:01:17<37:06:07, 12.97s/it] 20%|█▉        | 2531/12825 [9:01:29<36:46:11, 12.86s/it] 20%|█▉        | 2532/12825 [9:01:42<36:34:28, 12.79s/it] 20%|█▉        | 2533/12825 [9:01:54<36:23:39, 12.73s/it] 20%|█▉        | 2534/12825 [9:02:07<36:17:04, 12.69s/it] 20%|█▉        | 2535/12825 [9:02:20<36:09:28, 12.65s/it] 20%|█▉        | 2536/12825 [9:02:32<36:05:03, 12.63s/it] 20%|█▉        | 2537/12825 [9:02:45<36:02:08, 12.61s/it] 20%|█▉        | 2538/12825 [9:02:57<36:02:19, 12.61s/it] 20%|█▉        | 2539/12825 [9:03:10<36:01:42, 12.61s/it] 20%|█▉        | 2540/12825 [9:03:23<36:00:31, 12.60s/it] 20%|█▉        | 2541/12825 [9:03:35<35:58:52, 12.60s/it] 20%|█▉        | 2542/12825 [9:03:48<35:59:32, 12.60s/it] 20%|█▉        | 2543/12825 [9:04:00<35:58:13, 12.59s/it] 20%|█▉        | 2544/12825 [9:04:13<35:57:34, 12.59s/it] 20%|█▉        | 2545/12825 [9:04:25<35:55:58, 12.58s/it] 20%|█▉        | 2546/12825 [9:04:38<35:54:44, 12.58s/it] 20%|█▉        | 2547/12825 [9:04:51<35:52:18, 12.56s/it] 20%|█▉        | 2548/12825 [9:05:03<35:52:12, 12.57s/it] 20%|█▉        | 2549/12825 [9:05:16<35:49:57, 12.55s/it] 20%|█▉        | 2550/12825 [9:05:28<35:51:07, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120269.08lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103520.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2525] due to args.save_total_limit
 20%|█▉        | 2551/12825 [9:05:41<36:16:48, 12.71s/it] 20%|█▉        | 2552/12825 [9:05:54<36:10:21, 12.68s/it] 20%|█▉        | 2553/12825 [9:06:06<36:04:52, 12.65s/it] 20%|█▉        | 2554/12825 [9:06:19<36:00:02, 12.62s/it] 20%|█▉        | 2555/12825 [9:06:32<35:56:44, 12.60s/it] 20%|█▉        | 2556/12825 [9:06:44<35:53:49, 12.58s/it] 20%|█▉        | 2557/12825 [9:07:05<42:45:54, 14.99s/it] 20%|█▉        | 2558/12825 [9:07:17<40:39:50, 14.26s/it] 20%|█▉        | 2559/12825 [9:07:30<39:11:29, 13.74s/it] 20%|█▉        | 2560/12825 [9:07:42<38:11:02, 13.39s/it] 20%|█▉        | 2561/12825 [9:07:55<37:28:35, 13.14s/it] 20%|█▉        | 2562/12825 [9:08:08<36:58:15, 12.97s/it] 20%|█▉        | 2563/12825 [9:08:20<36:38:16, 12.85s/it] 20%|█▉        | 2564/12825 [9:08:28<32:21:17, 11.35s/it] 20%|██        | 2565/12825 [9:08:29<23:21:00,  8.19s/it] 20%|██        | 2566/12825 [9:08:54<38:09:06, 13.39s/it] 20%|██        | 2567/12825 [9:09:07<37:26:27, 13.14s/it] 20%|██        | 2568/12825 [9:09:19<36:58:41, 12.98s/it] 20%|██        | 2569/12825 [9:09:32<36:38:47, 12.86s/it] 20%|██        | 2570/12825 [9:09:45<36:26:37, 12.79s/it] 20%|██        | 2571/12825 [9:09:57<36:21:44, 12.77s/it] 20%|██        | 2572/12825 [9:10:10<36:22:27, 12.77s/it] 20%|██        | 2573/12825 [9:10:23<36:21:24, 12.77s/it] 20%|██        | 2574/12825 [9:10:36<36:21:17, 12.77s/it] 20%|██        | 2575/12825 [9:10:48<36:22:03, 12.77s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120211.76lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103465.79lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2500] due to args.save_total_limit
 20%|██        | 2576/12825 [9:11:01<36:31:08, 12.83s/it] 20%|██        | 2577/12825 [9:11:14<36:19:08, 12.76s/it] 20%|██        | 2578/12825 [9:11:27<36:12:06, 12.72s/it] 20%|██        | 2579/12825 [9:11:39<36:03:19, 12.67s/it] 20%|██        | 2580/12825 [9:11:52<35:58:29, 12.64s/it] 20%|██        | 2581/12825 [9:12:04<35:55:39, 12.63s/it] 20%|██        | 2582/12825 [9:12:17<35:53:40, 12.62s/it] 20%|██        | 2583/12825 [9:12:30<35:52:38, 12.61s/it] 20%|██        | 2584/12825 [9:12:42<35:51:21, 12.60s/it] 20%|██        | 2585/12825 [9:12:55<35:48:51, 12.59s/it] 20%|██        | 2586/12825 [9:13:07<35:47:10, 12.58s/it] 20%|██        | 2587/12825 [9:13:20<35:47:41, 12.59s/it] 20%|██        | 2588/12825 [9:13:32<35:47:15, 12.59s/it] 20%|██        | 2589/12825 [9:13:45<35:46:08, 12.58s/it] 20%|██        | 2590/12825 [9:14:06<42:33:47, 14.97s/it] 20%|██        | 2591/12825 [9:14:18<40:31:52, 14.26s/it] 20%|██        | 2592/12825 [9:14:31<39:05:51, 13.75s/it] 20%|██        | 2593/12825 [9:14:43<38:04:35, 13.40s/it] 20%|██        | 2594/12825 [9:14:56<37:23:02, 13.15s/it] 20%|██        | 2595/12825 [9:15:08<36:54:54, 12.99s/it] 20%|██        | 2596/12825 [9:15:21<36:35:58, 12.88s/it] 20%|██        | 2597/12825 [9:15:34<36:20:36, 12.79s/it] 20%|██        | 2598/12825 [9:15:46<36:09:22, 12.73s/it] 20%|██        | 2599/12825 [9:15:59<36:02:37, 12.69s/it] 20%|██        | 2600/12825 [9:16:11<35:56:26, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120242.01lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103469.10lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2550] due to args.save_total_limit
 20%|██        | 2601/12825 [9:16:24<36:14:48, 12.76s/it] 20%|██        | 2602/12825 [9:16:37<36:07:31, 12.72s/it] 20%|██        | 2603/12825 [9:16:50<36:02:08, 12.69s/it] 20%|██        | 2604/12825 [9:17:02<35:57:51, 12.67s/it] 20%|██        | 2605/12825 [9:17:15<35:53:48, 12.64s/it] 20%|██        | 2606/12825 [9:17:28<35:50:54, 12.63s/it] 20%|██        | 2607/12825 [9:17:40<35:48:23, 12.62s/it] 20%|██        | 2608/12825 [9:17:53<35:46:22, 12.60s/it] 20%|██        | 2609/12825 [9:18:05<35:44:42, 12.60s/it] 20%|██        | 2610/12825 [9:18:18<35:43:10, 12.59s/it] 20%|██        | 2611/12825 [9:18:30<35:43:07, 12.59s/it] 20%|██        | 2612/12825 [9:18:43<35:42:26, 12.59s/it] 20%|██        | 2613/12825 [9:18:56<35:40:45, 12.58s/it] 20%|██        | 2614/12825 [9:19:08<35:42:16, 12.59s/it] 20%|██        | 2615/12825 [9:19:21<35:55:12, 12.67s/it] 20%|██        | 2616/12825 [9:19:34<35:50:53, 12.64s/it] 20%|██        | 2617/12825 [9:19:46<35:47:43, 12.62s/it] 20%|██        | 2618/12825 [9:19:59<35:44:24, 12.61s/it] 20%|██        | 2619/12825 [9:20:11<35:41:22, 12.59s/it] 20%|██        | 2620/12825 [9:20:24<35:38:39, 12.57s/it] 20%|██        | 2621/12825 [9:20:36<35:41:16, 12.59s/it] 20%|██        | 2622/12825 [9:20:56<41:59:08, 14.81s/it] 20%|██        | 2623/12825 [9:21:09<40:05:28, 14.15s/it] 20%|██        | 2624/12825 [9:21:22<38:45:20, 13.68s/it] 20%|██        | 2625/12825 [9:21:34<37:49:43, 13.35s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120126.58lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103396.17lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2575] due to args.save_total_limit
 20%|██        | 2626/12825 [9:21:47<37:31:07, 13.24s/it] 20%|██        | 2627/12825 [9:22:00<36:58:37, 13.05s/it] 20%|██        | 2628/12825 [9:22:12<36:34:05, 12.91s/it] 20%|██        | 2629/12825 [9:22:25<36:17:54, 12.82s/it] 21%|██        | 2630/12825 [9:22:38<36:05:54, 12.75s/it] 21%|██        | 2631/12825 [9:22:50<35:58:43, 12.71s/it] 21%|██        | 2632/12825 [9:23:03<35:52:52, 12.67s/it] 21%|██        | 2633/12825 [9:23:15<35:48:00, 12.65s/it] 21%|██        | 2634/12825 [9:23:28<35:45:38, 12.63s/it] 21%|██        | 2635/12825 [9:23:41<35:45:51, 12.64s/it] 21%|██        | 2636/12825 [9:23:53<35:45:02, 12.63s/it] 21%|██        | 2637/12825 [9:24:06<35:42:45, 12.62s/it] 21%|██        | 2638/12825 [9:24:18<35:42:50, 12.62s/it] 21%|██        | 2639/12825 [9:24:31<35:41:59, 12.62s/it] 21%|██        | 2640/12825 [9:24:44<35:40:23, 12.61s/it] 21%|██        | 2641/12825 [9:24:56<35:37:49, 12.60s/it] 21%|██        | 2642/12825 [9:25:09<35:38:33, 12.60s/it] 21%|██        | 2643/12825 [9:25:21<35:38:00, 12.60s/it] 21%|██        | 2644/12825 [9:25:34<35:38:40, 12.60s/it] 21%|██        | 2645/12825 [9:25:47<35:38:29, 12.60s/it] 21%|██        | 2646/12825 [9:25:59<35:36:55, 12.60s/it] 21%|██        | 2647/12825 [9:26:12<35:36:22, 12.59s/it] 21%|██        | 2648/12825 [9:26:24<35:37:37, 12.60s/it] 21%|██        | 2649/12825 [9:26:37<35:35:49, 12.59s/it] 21%|██        | 2650/12825 [9:26:50<35:37:05, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120240.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103492.65lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2600] due to args.save_total_limit
 21%|██        | 2651/12825 [9:27:03<35:54:50, 12.71s/it] 21%|██        | 2652/12825 [9:27:15<35:47:51, 12.67s/it] 21%|██        | 2653/12825 [9:27:28<35:43:02, 12.64s/it] 21%|██        | 2654/12825 [9:27:48<42:09:06, 14.92s/it] 21%|██        | 2655/12825 [9:28:01<40:10:49, 14.22s/it] 21%|██        | 2656/12825 [9:28:13<38:47:43, 13.73s/it] 21%|██        | 2657/12825 [9:28:26<37:49:38, 13.39s/it] 21%|██        | 2658/12825 [9:28:38<37:11:01, 13.17s/it] 21%|██        | 2659/12825 [9:28:51<36:40:37, 12.99s/it] 21%|██        | 2660/12825 [9:29:04<36:18:14, 12.86s/it] 21%|██        | 2661/12825 [9:29:16<36:04:39, 12.78s/it] 21%|██        | 2662/12825 [9:29:29<35:53:33, 12.71s/it] 21%|██        | 2663/12825 [9:29:41<35:47:59, 12.68s/it] 21%|██        | 2664/12825 [9:29:54<35:43:13, 12.66s/it] 21%|██        | 2665/12825 [9:30:07<35:41:31, 12.65s/it] 21%|██        | 2666/12825 [9:30:19<35:39:42, 12.64s/it] 21%|██        | 2667/12825 [9:30:32<35:35:03, 12.61s/it] 21%|██        | 2668/12825 [9:30:44<35:34:09, 12.61s/it] 21%|██        | 2669/12825 [9:30:57<35:32:57, 12.60s/it] 21%|██        | 2670/12825 [9:31:09<35:31:14, 12.59s/it] 21%|██        | 2671/12825 [9:31:22<35:33:03, 12.60s/it] 21%|██        | 2672/12825 [9:31:35<35:32:47, 12.60s/it] 21%|██        | 2673/12825 [9:31:47<35:29:55, 12.59s/it] 21%|██        | 2674/12825 [9:32:00<35:30:02, 12.59s/it] 21%|██        | 2675/12825 [9:32:12<35:29:26, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120190.20lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103459.65lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2625] due to args.save_total_limit
 21%|██        | 2676/12825 [9:32:25<35:48:12, 12.70s/it] 21%|██        | 2677/12825 [9:32:38<35:41:13, 12.66s/it] 21%|██        | 2678/12825 [9:32:50<35:36:12, 12.63s/it] 21%|██        | 2679/12825 [9:33:03<35:34:13, 12.62s/it] 21%|██        | 2680/12825 [9:33:16<35:33:02, 12.62s/it] 21%|██        | 2681/12825 [9:33:28<35:38:25, 12.65s/it] 21%|██        | 2682/12825 [9:33:41<35:36:51, 12.64s/it] 21%|██        | 2683/12825 [9:33:54<35:35:14, 12.63s/it] 21%|██        | 2684/12825 [9:34:06<35:32:34, 12.62s/it] 21%|██        | 2685/12825 [9:34:19<35:31:25, 12.61s/it] 21%|██        | 2686/12825 [9:34:31<35:28:19, 12.59s/it] 21%|██        | 2687/12825 [9:34:51<41:45:39, 14.83s/it] 21%|██        | 2688/12825 [9:35:04<39:51:23, 14.15s/it] 21%|██        | 2689/12825 [9:35:17<38:30:39, 13.68s/it] 21%|██        | 2690/12825 [9:35:29<37:35:31, 13.35s/it] 21%|██        | 2691/12825 [9:35:42<36:55:42, 13.12s/it] 21%|██        | 2692/12825 [9:35:54<36:28:58, 12.96s/it] 21%|██        | 2693/12825 [9:36:07<36:09:45, 12.85s/it] 21%|██        | 2694/12825 [9:36:20<35:58:23, 12.78s/it] 21%|██        | 2695/12825 [9:36:32<35:47:53, 12.72s/it] 21%|██        | 2696/12825 [9:36:45<35:40:25, 12.68s/it] 21%|██        | 2697/12825 [9:36:57<35:33:53, 12.64s/it] 21%|██        | 2698/12825 [9:37:10<35:31:28, 12.63s/it] 21%|██        | 2699/12825 [9:37:22<35:29:45, 12.62s/it] 21%|██        | 2700/12825 [9:37:35<35:26:51, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120064.81lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103386.07lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2650] due to args.save_total_limit
 21%|██        | 2701/12825 [9:37:48<35:42:27, 12.70s/it] 21%|██        | 2702/12825 [9:38:01<35:36:07, 12.66s/it] 21%|██        | 2703/12825 [9:38:13<35:33:36, 12.65s/it] 21%|██        | 2704/12825 [9:38:26<35:31:34, 12.64s/it] 21%|██        | 2705/12825 [9:38:38<35:29:18, 12.62s/it] 21%|██        | 2706/12825 [9:38:51<35:30:26, 12.63s/it] 21%|██        | 2707/12825 [9:39:04<35:31:35, 12.64s/it] 21%|██        | 2708/12825 [9:39:16<35:29:23, 12.63s/it] 21%|██        | 2709/12825 [9:39:29<35:29:16, 12.63s/it] 21%|██        | 2710/12825 [9:39:42<35:37:42, 12.68s/it] 21%|██        | 2711/12825 [9:39:54<35:34:04, 12.66s/it] 21%|██        | 2712/12825 [9:40:07<35:31:15, 12.64s/it] 21%|██        | 2713/12825 [9:40:20<35:30:27, 12.64s/it] 21%|██        | 2714/12825 [9:40:32<35:29:11, 12.63s/it] 21%|██        | 2715/12825 [9:40:45<35:27:14, 12.62s/it] 21%|██        | 2716/12825 [9:40:57<35:26:05, 12.62s/it] 21%|██        | 2717/12825 [9:41:10<35:26:56, 12.63s/it] 21%|██        | 2718/12825 [9:41:23<35:25:53, 12.62s/it] 21%|██        | 2719/12825 [9:41:43<41:55:57, 14.94s/it] 21%|██        | 2720/12825 [9:41:56<39:58:39, 14.24s/it] 21%|██        | 2721/12825 [9:42:08<38:35:32, 13.75s/it] 21%|██        | 2722/12825 [9:42:21<37:38:08, 13.41s/it] 21%|██        | 2723/12825 [9:42:33<36:56:57, 13.17s/it] 21%|██        | 2724/12825 [9:42:46<36:28:05, 13.00s/it] 21%|██        | 2725/12825 [9:42:59<36:08:39, 12.88s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120139.32lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103501.63lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2725
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2725/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2725/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2700] due to args.save_total_limit
 21%|██▏       | 2726/12825 [9:43:12<36:08:53, 12.89s/it] 21%|██▏       | 2727/12825 [9:43:24<35:53:47, 12.80s/it] 21%|██▏       | 2728/12825 [9:43:37<35:42:43, 12.73s/it] 21%|██▏       | 2729/12825 [9:43:49<35:36:47, 12.70s/it] 21%|██▏       | 2730/12825 [9:44:02<35:32:55, 12.68s/it] 21%|██▏       | 2731/12825 [9:44:15<35:31:41, 12.67s/it] 21%|██▏       | 2732/12825 [9:44:27<35:27:03, 12.64s/it] 21%|██▏       | 2733/12825 [9:44:40<35:22:59, 12.62s/it] 21%|██▏       | 2734/12825 [9:44:52<35:22:23, 12.62s/it] 21%|██▏       | 2735/12825 [9:45:05<35:22:42, 12.62s/it] 21%|██▏       | 2736/12825 [9:45:18<35:19:48, 12.61s/it] 21%|██▏       | 2737/12825 [9:45:30<35:18:16, 12.60s/it] 21%|██▏       | 2738/12825 [9:45:43<35:20:25, 12.61s/it] 21%|██▏       | 2739/12825 [9:45:55<35:18:34, 12.60s/it] 21%|██▏       | 2740/12825 [9:46:08<35:18:39, 12.60s/it] 21%|██▏       | 2741/12825 [9:46:21<35:17:28, 12.60s/it] 21%|██▏       | 2742/12825 [9:46:33<35:18:11, 12.60s/it] 21%|██▏       | 2743/12825 [9:46:46<35:16:22, 12.59s/it] 21%|██▏       | 2744/12825 [9:46:58<35:18:12, 12.61s/it] 21%|██▏       | 2745/12825 [9:47:11<35:17:50, 12.61s/it] 21%|██▏       | 2746/12825 [9:47:24<35:18:00, 12.61s/it] 21%|██▏       | 2747/12825 [9:47:36<35:17:37, 12.61s/it] 21%|██▏       | 2748/12825 [9:47:49<35:16:32, 12.60s/it] 21%|██▏       | 2749/12825 [9:48:01<35:15:34, 12.60s/it] 21%|██▏       | 2750/12825 [9:48:14<35:15:51, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120180.25lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103435.08lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2750
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2750/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2750/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2725] due to args.save_total_limit
 21%|██▏       | 2751/12825 [9:48:35<42:08:40, 15.06s/it] 21%|██▏       | 2752/12825 [9:48:47<40:04:43, 14.32s/it] 21%|██▏       | 2753/12825 [9:49:00<38:37:36, 13.81s/it] 21%|██▏       | 2754/12825 [9:49:13<37:36:20, 13.44s/it] 21%|██▏       | 2755/12825 [9:49:25<36:55:43, 13.20s/it] 21%|██▏       | 2756/12825 [9:49:38<36:26:03, 13.03s/it] 21%|██▏       | 2757/12825 [9:49:50<36:06:43, 12.91s/it] 22%|██▏       | 2758/12825 [9:50:03<35:50:42, 12.82s/it] 22%|██▏       | 2759/12825 [9:50:16<35:42:20, 12.77s/it] 22%|██▏       | 2760/12825 [9:50:28<35:33:19, 12.72s/it] 22%|██▏       | 2761/12825 [9:50:41<35:27:58, 12.69s/it] 22%|██▏       | 2762/12825 [9:50:54<35:24:56, 12.67s/it] 22%|██▏       | 2763/12825 [9:51:06<35:20:17, 12.64s/it] 22%|██▏       | 2764/12825 [9:51:19<35:18:20, 12.63s/it] 22%|██▏       | 2765/12825 [9:51:31<35:14:40, 12.61s/it] 22%|██▏       | 2766/12825 [9:51:44<35:13:37, 12.61s/it] 22%|██▏       | 2767/12825 [9:51:57<35:12:13, 12.60s/it] 22%|██▏       | 2768/12825 [9:52:09<35:11:36, 12.60s/it] 22%|██▏       | 2769/12825 [9:52:22<35:11:00, 12.60s/it] 22%|██▏       | 2770/12825 [9:52:34<35:09:53, 12.59s/it] 22%|██▏       | 2771/12825 [9:52:47<35:10:14, 12.59s/it] 22%|██▏       | 2772/12825 [9:52:59<35:10:10, 12.59s/it] 22%|██▏       | 2773/12825 [9:53:12<35:09:16, 12.59s/it] 22%|██▏       | 2774/12825 [9:53:25<35:07:18, 12.58s/it] 22%|██▏       | 2775/12825 [9:53:37<35:07:48, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120221.97lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103457.76lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2775
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2775/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2775/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2750] due to args.save_total_limit
 22%|██▏       | 2776/12825 [9:53:50<35:23:14, 12.68s/it] 22%|██▏       | 2777/12825 [9:54:03<35:17:26, 12.64s/it] 22%|██▏       | 2778/12825 [9:54:15<35:13:35, 12.62s/it] 22%|██▏       | 2779/12825 [9:54:28<35:11:22, 12.61s/it] 22%|██▏       | 2780/12825 [9:54:40<35:10:53, 12.61s/it] 22%|██▏       | 2781/12825 [9:54:53<35:09:23, 12.60s/it] 22%|██▏       | 2782/12825 [9:55:06<35:09:13, 12.60s/it] 22%|██▏       | 2783/12825 [9:55:18<35:06:33, 12.59s/it] 22%|██▏       | 2784/12825 [9:55:39<42:03:04, 15.08s/it] 22%|██▏       | 2785/12825 [9:55:52<39:56:49, 14.32s/it] 22%|██▏       | 2786/12825 [9:56:04<38:29:38, 13.80s/it] 22%|██▏       | 2787/12825 [9:56:17<37:30:38, 13.45s/it] 22%|██▏       | 2788/12825 [9:56:29<36:48:04, 13.20s/it] 22%|██▏       | 2789/12825 [9:56:42<36:16:32, 13.01s/it] 22%|██▏       | 2790/12825 [9:56:55<35:57:03, 12.90s/it] 22%|██▏       | 2791/12825 [9:57:07<35:43:31, 12.82s/it] 22%|██▏       | 2792/12825 [9:57:20<35:30:50, 12.74s/it] 22%|██▏       | 2793/12825 [9:57:32<35:23:26, 12.70s/it] 22%|██▏       | 2794/12825 [9:57:45<35:18:18, 12.67s/it] 22%|██▏       | 2795/12825 [9:57:58<35:13:36, 12.64s/it] 22%|██▏       | 2796/12825 [9:58:10<35:12:01, 12.64s/it] 22%|██▏       | 2797/12825 [9:58:23<35:09:07, 12.62s/it] 22%|██▏       | 2798/12825 [9:58:35<35:08:03, 12.61s/it] 22%|██▏       | 2799/12825 [9:58:48<35:06:59, 12.61s/it] 22%|██▏       | 2800/12825 [9:59:01<35:04:36, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120274.19lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103616.88lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2800
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2800/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2800/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2775] due to args.save_total_limit
 22%|██▏       | 2801/12825 [9:59:14<35:22:22, 12.70s/it] 22%|██▏       | 2802/12825 [9:59:26<35:15:38, 12.66s/it] 22%|██▏       | 2803/12825 [9:59:39<35:12:24, 12.65s/it] 22%|██▏       | 2804/12825 [9:59:51<35:08:46, 12.63s/it] 22%|██▏       | 2805/12825 [10:00:04<35:08:09, 12.62s/it] 22%|██▏       | 2806/12825 [10:00:17<35:07:48, 12.62s/it] 22%|██▏       | 2807/12825 [10:00:29<35:06:12, 12.61s/it] 22%|██▏       | 2808/12825 [10:00:42<35:03:55, 12.60s/it] 22%|██▏       | 2809/12825 [10:00:54<35:01:44, 12.59s/it] 22%|██▏       | 2810/12825 [10:01:07<35:01:08, 12.59s/it] 22%|██▏       | 2811/12825 [10:01:19<35:01:02, 12.59s/it] 22%|██▏       | 2812/12825 [10:01:32<34:59:56, 12.58s/it] 22%|██▏       | 2813/12825 [10:01:45<34:59:33, 12.58s/it] 22%|██▏       | 2814/12825 [10:01:57<34:58:16, 12.58s/it] 22%|██▏       | 2815/12825 [10:02:10<34:57:02, 12.57s/it] 22%|██▏       | 2816/12825 [10:02:30<41:24:10, 14.89s/it] 22%|██▏       | 2817/12825 [10:02:43<39:27:19, 14.19s/it] 22%|██▏       | 2818/12825 [10:02:55<38:05:43, 13.70s/it] 22%|██▏       | 2819/12825 [10:03:08<37:10:08, 13.37s/it] 22%|██▏       | 2820/12825 [10:03:20<36:31:06, 13.14s/it] 22%|██▏       | 2821/12825 [10:03:33<36:02:11, 12.97s/it] 22%|██▏       | 2822/12825 [10:03:46<35:43:03, 12.85s/it] 22%|██▏       | 2823/12825 [10:03:58<35:29:27, 12.77s/it] 22%|██▏       | 2824/12825 [10:04:11<35:20:21, 12.72s/it] 22%|██▏       | 2825/12825 [10:04:23<35:14:54, 12.69s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120065.32lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103430.17lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2825
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2825/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2825/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2675] due to args.save_total_limit
 22%|██▏       | 2826/12825 [10:04:36<35:25:42, 12.76s/it] 22%|██▏       | 2827/12825 [10:04:49<35:18:24, 12.71s/it] 22%|██▏       | 2828/12825 [10:05:01<35:11:27, 12.67s/it] 22%|██▏       | 2829/12825 [10:05:14<35:05:45, 12.64s/it] 22%|██▏       | 2830/12825 [10:05:27<35:03:02, 12.62s/it] 22%|██▏       | 2831/12825 [10:05:39<35:01:06, 12.61s/it] 22%|██▏       | 2832/12825 [10:05:52<35:01:08, 12.62s/it] 22%|██▏       | 2833/12825 [10:06:04<34:58:15, 12.60s/it] 22%|██▏       | 2834/12825 [10:06:17<34:57:00, 12.59s/it] 22%|██▏       | 2835/12825 [10:06:29<34:53:57, 12.58s/it] 22%|██▏       | 2836/12825 [10:06:42<34:52:50, 12.57s/it] 22%|██▏       | 2837/12825 [10:06:55<34:54:09, 12.58s/it] 22%|██▏       | 2838/12825 [10:07:07<34:56:27, 12.60s/it] 22%|██▏       | 2839/12825 [10:07:20<34:56:56, 12.60s/it] 22%|██▏       | 2840/12825 [10:07:32<34:56:50, 12.60s/it] 22%|██▏       | 2841/12825 [10:07:45<34:56:13, 12.60s/it] 22%|██▏       | 2842/12825 [10:07:58<34:56:05, 12.60s/it] 22%|██▏       | 2843/12825 [10:08:10<34:56:46, 12.60s/it] 22%|██▏       | 2844/12825 [10:08:23<34:57:13, 12.61s/it] 22%|██▏       | 2845/12825 [10:08:35<34:54:49, 12.59s/it] 22%|██▏       | 2846/12825 [10:08:48<34:52:30, 12.58s/it] 22%|██▏       | 2847/12825 [10:09:01<34:53:34, 12.59s/it] 22%|██▏       | 2848/12825 [10:09:13<34:53:21, 12.59s/it] 22%|██▏       | 2849/12825 [10:09:34<41:22:05, 14.93s/it] 22%|██▏       | 2850/12825 [10:09:46<39:26:14, 14.23s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120255.93lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103496.52lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2850
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2850/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2850/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2800] due to args.save_total_limit
 22%|██▏       | 2851/12825 [10:09:59<38:19:58, 13.84s/it] 22%|██▏       | 2852/12825 [10:10:12<37:18:03, 13.46s/it] 22%|██▏       | 2853/12825 [10:10:24<36:35:21, 13.21s/it] 22%|██▏       | 2854/12825 [10:10:37<36:04:42, 13.03s/it] 22%|██▏       | 2855/12825 [10:10:49<35:41:29, 12.89s/it] 22%|██▏       | 2856/12825 [10:11:02<35:27:07, 12.80s/it] 22%|██▏       | 2857/12825 [10:11:15<35:15:52, 12.74s/it] 22%|██▏       | 2858/12825 [10:11:27<35:10:35, 12.71s/it] 22%|██▏       | 2859/12825 [10:11:40<35:03:07, 12.66s/it] 22%|██▏       | 2860/12825 [10:11:52<35:00:49, 12.65s/it] 22%|██▏       | 2861/12825 [10:12:05<35:00:47, 12.65s/it] 22%|██▏       | 2862/12825 [10:12:18<34:59:30, 12.64s/it] 22%|██▏       | 2863/12825 [10:12:30<34:58:25, 12.64s/it] 22%|██▏       | 2864/12825 [10:12:43<34:56:25, 12.63s/it] 22%|██▏       | 2865/12825 [10:12:56<34:54:32, 12.62s/it] 22%|██▏       | 2866/12825 [10:13:08<34:53:39, 12.61s/it] 22%|██▏       | 2867/12825 [10:13:21<34:50:50, 12.60s/it] 22%|██▏       | 2868/12825 [10:13:33<34:50:56, 12.60s/it] 22%|██▏       | 2869/12825 [10:13:46<34:50:12, 12.60s/it] 22%|██▏       | 2870/12825 [10:13:59<34:52:31, 12.61s/it] 22%|██▏       | 2871/12825 [10:14:11<34:52:23, 12.61s/it] 22%|██▏       | 2872/12825 [10:14:24<34:50:11, 12.60s/it] 22%|██▏       | 2873/12825 [10:14:36<34:49:04, 12.59s/it] 22%|██▏       | 2874/12825 [10:14:49<34:49:41, 12.60s/it] 22%|██▏       | 2875/12825 [10:15:02<34:50:40, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120157.17lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103404.01lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2875
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2875/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2875/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2825] due to args.save_total_limit
 22%|██▏       | 2876/12825 [10:15:14<35:05:47, 12.70s/it] 22%|██▏       | 2877/12825 [10:15:27<34:58:16, 12.66s/it] 22%|██▏       | 2878/12825 [10:15:40<34:51:45, 12.62s/it] 22%|██▏       | 2879/12825 [10:15:52<34:48:14, 12.60s/it] 22%|██▏       | 2880/12825 [10:16:05<34:47:21, 12.59s/it] 22%|██▏       | 2881/12825 [10:16:26<41:52:40, 15.16s/it] 22%|██▏       | 2882/12825 [10:16:38<39:45:00, 14.39s/it] 22%|██▏       | 2883/12825 [10:16:51<38:16:03, 13.86s/it] 22%|██▏       | 2884/12825 [10:17:04<37:10:50, 13.46s/it] 22%|██▏       | 2885/12825 [10:17:16<36:25:29, 13.19s/it] 23%|██▎       | 2886/12825 [10:17:29<35:54:45, 13.01s/it] 23%|██▎       | 2887/12825 [10:17:41<35:33:53, 12.88s/it] 23%|██▎       | 2888/12825 [10:17:54<35:18:51, 12.79s/it] 23%|██▎       | 2889/12825 [10:18:07<35:09:16, 12.74s/it] 23%|██▎       | 2890/12825 [10:18:19<35:02:29, 12.70s/it] 23%|██▎       | 2891/12825 [10:18:32<34:58:29, 12.67s/it] 23%|██▎       | 2892/12825 [10:18:44<34:55:53, 12.66s/it] 23%|██▎       | 2893/12825 [10:18:57<34:52:10, 12.64s/it] 23%|██▎       | 2894/12825 [10:19:10<34:49:01, 12.62s/it] 23%|██▎       | 2895/12825 [10:19:22<34:49:05, 12.62s/it] 23%|██▎       | 2896/12825 [10:19:35<34:45:14, 12.60s/it] 23%|██▎       | 2897/12825 [10:19:47<34:44:44, 12.60s/it] 23%|██▎       | 2898/12825 [10:20:00<34:44:00, 12.60s/it] 23%|██▎       | 2899/12825 [10:20:13<34:43:35, 12.59s/it] 23%|██▎       | 2900/12825 [10:20:25<34:43:27, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120132.06lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 99809.99lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2900
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2900/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2900/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2850] due to args.save_total_limit
 23%|██▎       | 2901/12825 [10:20:38<35:10:33, 12.76s/it] 23%|██▎       | 2902/12825 [10:20:51<35:01:43, 12.71s/it] 23%|██▎       | 2903/12825 [10:21:03<34:55:13, 12.67s/it] 23%|██▎       | 2904/12825 [10:21:16<34:49:32, 12.64s/it] 23%|██▎       | 2905/12825 [10:21:29<34:46:02, 12.62s/it] 23%|██▎       | 2906/12825 [10:21:41<34:42:31, 12.60s/it] 23%|██▎       | 2907/12825 [10:21:54<34:42:58, 12.60s/it] 23%|██▎       | 2908/12825 [10:22:06<34:41:15, 12.59s/it] 23%|██▎       | 2909/12825 [10:22:19<34:39:38, 12.58s/it] 23%|██▎       | 2910/12825 [10:22:33<36:01:28, 13.08s/it] 23%|██▎       | 2911/12825 [10:22:46<35:35:26, 12.92s/it] 23%|██▎       | 2912/12825 [10:22:58<35:17:32, 12.82s/it] 23%|██▎       | 2913/12825 [10:23:19<42:10:15, 15.32s/it] 23%|██▎       | 2914/12825 [10:23:32<39:54:07, 14.49s/it] 23%|██▎       | 2915/12825 [10:23:44<38:18:39, 13.92s/it] 23%|██▎       | 2916/12825 [10:23:57<37:12:15, 13.52s/it] 23%|██▎       | 2917/12825 [10:24:10<36:26:38, 13.24s/it] 23%|██▎       | 2918/12825 [10:24:22<35:53:56, 13.04s/it] 23%|██▎       | 2919/12825 [10:24:35<35:28:32, 12.89s/it] 23%|██▎       | 2920/12825 [10:24:47<35:12:43, 12.80s/it] 23%|██▎       | 2921/12825 [10:25:00<35:17:35, 12.83s/it] 23%|██▎       | 2922/12825 [10:25:13<35:03:55, 12.75s/it] 23%|██▎       | 2923/12825 [10:25:25<34:56:17, 12.70s/it] 23%|██▎       | 2924/12825 [10:25:38<34:49:19, 12.66s/it] 23%|██▎       | 2925/12825 [10:25:51<34:45:57, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120263.97lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103486.78lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2925
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2925/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2925/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2900] due to args.save_total_limit
 23%|██▎       | 2926/12825 [10:26:04<35:10:43, 12.79s/it] 23%|██▎       | 2927/12825 [10:26:16<34:57:55, 12.72s/it] 23%|██▎       | 2928/12825 [10:26:29<34:48:57, 12.66s/it] 23%|██▎       | 2929/12825 [10:26:41<34:43:37, 12.63s/it] 23%|██▎       | 2930/12825 [10:26:54<34:37:58, 12.60s/it] 23%|██▎       | 2931/12825 [10:27:06<34:35:40, 12.59s/it] 23%|██▎       | 2932/12825 [10:27:19<34:33:32, 12.58s/it] 23%|██▎       | 2933/12825 [10:27:32<34:33:32, 12.58s/it] 23%|██▎       | 2934/12825 [10:27:44<34:34:19, 12.58s/it] 23%|██▎       | 2935/12825 [10:27:57<34:34:00, 12.58s/it] 23%|██▎       | 2936/12825 [10:28:09<34:34:05, 12.58s/it] 23%|██▎       | 2937/12825 [10:28:22<34:34:17, 12.59s/it] 23%|██▎       | 2938/12825 [10:28:35<34:32:37, 12.58s/it] 23%|██▎       | 2939/12825 [10:28:47<34:31:40, 12.57s/it] 23%|██▎       | 2940/12825 [10:29:00<34:30:31, 12.57s/it] 23%|██▎       | 2941/12825 [10:29:12<34:29:19, 12.56s/it] 23%|██▎       | 2942/12825 [10:29:25<34:29:46, 12.57s/it] 23%|██▎       | 2943/12825 [10:29:37<34:28:33, 12.56s/it] 23%|██▎       | 2944/12825 [10:29:50<34:29:02, 12.56s/it] 23%|██▎       | 2945/12825 [10:30:02<34:28:02, 12.56s/it] 23%|██▎       | 2946/12825 [10:30:23<41:23:54, 15.09s/it] 23%|██▎       | 2947/12825 [10:30:36<39:19:11, 14.33s/it] 23%|██▎       | 2948/12825 [10:30:48<37:49:25, 13.79s/it] 23%|██▎       | 2949/12825 [10:31:01<36:50:50, 13.43s/it] 23%|██▎       | 2950/12825 [10:31:14<36:09:08, 13.18s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 119976.15lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103283.67lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2950
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2950/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2950/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2925] due to args.save_total_limit
 23%|██▎       | 2951/12825 [10:31:27<35:53:28, 13.09s/it] 23%|██▎       | 2952/12825 [10:31:39<35:25:59, 12.92s/it] 23%|██▎       | 2953/12825 [10:31:52<35:07:19, 12.81s/it] 23%|██▎       | 2954/12825 [10:32:04<34:54:59, 12.73s/it] 23%|██▎       | 2955/12825 [10:32:17<34:46:22, 12.68s/it] 23%|██▎       | 2956/12825 [10:32:29<34:40:46, 12.65s/it] 23%|██▎       | 2957/12825 [10:32:42<34:36:33, 12.63s/it] 23%|██▎       | 2958/12825 [10:32:54<34:34:41, 12.62s/it] 23%|██▎       | 2959/12825 [10:33:07<34:30:20, 12.59s/it] 23%|██▎       | 2960/12825 [10:33:20<34:27:25, 12.57s/it] 23%|██▎       | 2961/12825 [10:33:32<34:27:08, 12.57s/it] 23%|██▎       | 2962/12825 [10:33:45<34:27:03, 12.57s/it] 23%|██▎       | 2963/12825 [10:33:57<34:24:09, 12.56s/it] 23%|██▎       | 2964/12825 [10:34:10<34:25:25, 12.57s/it] 23%|██▎       | 2965/12825 [10:34:22<34:25:33, 12.57s/it] 23%|██▎       | 2966/12825 [10:34:35<34:24:40, 12.57s/it] 23%|██▎       | 2967/12825 [10:34:47<34:23:38, 12.56s/it] 23%|██▎       | 2968/12825 [10:35:00<34:22:57, 12.56s/it] 23%|██▎       | 2969/12825 [10:35:13<34:24:27, 12.57s/it] 23%|██▎       | 2970/12825 [10:35:25<34:26:45, 12.58s/it] 23%|██▎       | 2971/12825 [10:35:38<34:26:20, 12.58s/it] 23%|██▎       | 2972/12825 [10:35:50<34:25:01, 12.58s/it] 23%|██▎       | 2973/12825 [10:36:03<34:23:44, 12.57s/it] 23%|██▎       | 2974/12825 [10:36:16<34:26:16, 12.59s/it] 23%|██▎       | 2975/12825 [10:36:28<34:26:09, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120203.59lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103555.77lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2975
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2975/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2975/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-2975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2875] due to args.save_total_limit
 23%|██▎       | 2976/12825 [10:36:41<34:42:51, 12.69s/it] 23%|██▎       | 2977/12825 [10:36:54<34:38:29, 12.66s/it] 23%|██▎       | 2978/12825 [10:37:14<40:51:35, 14.94s/it] 23%|██▎       | 2979/12825 [10:37:27<38:54:55, 14.23s/it] 23%|██▎       | 2980/12825 [10:37:39<37:32:02, 13.72s/it] 23%|██▎       | 2981/12825 [10:37:52<36:34:22, 13.37s/it] 23%|██▎       | 2982/12825 [10:38:04<35:53:27, 13.13s/it] 23%|██▎       | 2983/12825 [10:38:17<35:26:23, 12.96s/it] 23%|██▎       | 2984/12825 [10:38:29<35:12:27, 12.88s/it] 23%|██▎       | 2985/12825 [10:38:42<34:55:45, 12.78s/it] 23%|██▎       | 2986/12825 [10:38:55<34:43:50, 12.71s/it] 23%|██▎       | 2987/12825 [10:39:07<34:37:35, 12.67s/it] 23%|██▎       | 2988/12825 [10:39:20<34:33:16, 12.65s/it] 23%|██▎       | 2989/12825 [10:39:32<34:28:52, 12.62s/it] 23%|██▎       | 2990/12825 [10:39:45<34:25:40, 12.60s/it] 23%|██▎       | 2991/12825 [10:39:57<34:24:22, 12.60s/it] 23%|██▎       | 2992/12825 [10:40:10<34:20:58, 12.58s/it] 23%|██▎       | 2993/12825 [10:40:22<34:20:37, 12.58s/it] 23%|██▎       | 2994/12825 [10:40:35<34:20:39, 12.58s/it] 23%|██▎       | 2995/12825 [10:40:48<34:18:43, 12.57s/it] 23%|██▎       | 2996/12825 [10:41:00<34:16:43, 12.56s/it] 23%|██▎       | 2997/12825 [10:41:13<34:16:07, 12.55s/it] 23%|██▎       | 2998/12825 [10:41:25<34:16:40, 12.56s/it] 23%|██▎       | 2999/12825 [10:41:38<34:16:06, 12.56s/it] 23%|██▎       | 3000/12825 [10:41:50<34:16:15, 12.56s/it]                                                           23%|██▎       | 3000/12825 [10:41:50<34:16:15, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120229.63lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103520.37lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3000
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3000/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3000/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2950] due to args.save_total_limit
 23%|██▎       | 3001/12825 [10:42:03<34:34:22, 12.67s/it] 23%|██▎       | 3002/12825 [10:42:16<34:29:43, 12.64s/it] 23%|██▎       | 3003/12825 [10:42:28<34:25:36, 12.62s/it] 23%|██▎       | 3004/12825 [10:42:41<34:21:50, 12.60s/it] 23%|██▎       | 3005/12825 [10:42:54<34:19:47, 12.59s/it] 23%|██▎       | 3006/12825 [10:43:06<34:18:52, 12.58s/it] 23%|██▎       | 3007/12825 [10:43:19<34:19:00, 12.58s/it] 23%|██▎       | 3008/12825 [10:43:31<34:17:37, 12.58s/it] 23%|██▎       | 3009/12825 [10:43:44<34:17:07, 12.57s/it] 23%|██▎       | 3010/12825 [10:44:04<40:21:37, 14.80s/it] 23%|██▎       | 3011/12825 [10:44:16<38:27:56, 14.11s/it] 23%|██▎       | 3012/12825 [10:44:29<37:11:30, 13.64s/it] 23%|██▎       | 3013/12825 [10:44:41<36:17:44, 13.32s/it] 24%|██▎       | 3014/12825 [10:44:54<35:43:08, 13.11s/it] 24%|██▎       | 3015/12825 [10:45:07<35:16:02, 12.94s/it] 24%|██▎       | 3016/12825 [10:45:19<34:57:18, 12.83s/it] 24%|██▎       | 3017/12825 [10:45:32<34:42:50, 12.74s/it] 24%|██▎       | 3018/12825 [10:45:44<34:33:35, 12.69s/it] 24%|██▎       | 3019/12825 [10:45:57<34:29:10, 12.66s/it] 24%|██▎       | 3020/12825 [10:46:09<34:24:00, 12.63s/it] 24%|██▎       | 3021/12825 [10:46:22<34:19:58, 12.61s/it] 24%|██▎       | 3022/12825 [10:46:35<34:18:27, 12.60s/it] 24%|██▎       | 3023/12825 [10:46:47<34:15:21, 12.58s/it] 24%|██▎       | 3024/12825 [10:47:00<34:16:37, 12.59s/it] 24%|██▎       | 3025/12825 [10:47:12<34:15:01, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120101.74lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103366.63lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3025
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3025/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3025/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3000] due to args.save_total_limit
 24%|██▎       | 3026/12825 [10:47:25<34:31:39, 12.68s/it] 24%|██▎       | 3027/12825 [10:47:38<34:26:35, 12.66s/it] 24%|██▎       | 3028/12825 [10:47:50<34:23:38, 12.64s/it] 24%|██▎       | 3029/12825 [10:48:03<34:22:17, 12.63s/it] 24%|██▎       | 3030/12825 [10:48:16<34:19:40, 12.62s/it] 24%|██▎       | 3031/12825 [10:48:28<34:18:22, 12.61s/it] 24%|██▎       | 3032/12825 [10:48:41<34:15:59, 12.60s/it] 24%|██▎       | 3033/12825 [10:48:53<34:15:37, 12.60s/it] 24%|██▎       | 3034/12825 [10:49:06<34:15:15, 12.59s/it] 24%|██▎       | 3035/12825 [10:49:19<34:14:10, 12.59s/it] 24%|██▎       | 3036/12825 [10:49:31<34:14:05, 12.59s/it] 24%|██▎       | 3037/12825 [10:49:44<34:14:37, 12.59s/it] 24%|██▎       | 3038/12825 [10:49:56<34:14:24, 12.59s/it] 24%|██▎       | 3039/12825 [10:50:09<34:13:39, 12.59s/it] 24%|██▎       | 3040/12825 [10:50:21<34:13:28, 12.59s/it] 24%|██▎       | 3041/12825 [10:50:34<34:13:53, 12.60s/it] 24%|██▎       | 3042/12825 [10:50:47<34:13:41, 12.60s/it] 24%|██▎       | 3043/12825 [10:51:07<40:41:29, 14.98s/it] 24%|██▎       | 3044/12825 [10:51:20<38:43:20, 14.25s/it] 24%|██▎       | 3045/12825 [10:51:32<37:21:28, 13.75s/it] 24%|██▍       | 3046/12825 [10:51:45<36:23:05, 13.39s/it] 24%|██▍       | 3047/12825 [10:51:58<35:43:13, 13.15s/it] 24%|██▍       | 3048/12825 [10:52:10<35:14:37, 12.98s/it] 24%|██▍       | 3049/12825 [10:52:23<34:55:02, 12.86s/it] 24%|██▍       | 3050/12825 [10:52:35<34:41:16, 12.78s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120175.91lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103465.04lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3050
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3050/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3050/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-2975] due to args.save_total_limit
 24%|██▍       | 3051/12825 [10:52:48<34:45:02, 12.80s/it] 24%|██▍       | 3052/12825 [10:53:01<34:30:34, 12.71s/it] 24%|██▍       | 3053/12825 [10:53:13<34:23:10, 12.67s/it] 24%|██▍       | 3054/12825 [10:53:26<34:18:27, 12.64s/it] 24%|██▍       | 3055/12825 [10:53:38<34:16:19, 12.63s/it] 24%|██▍       | 3056/12825 [10:53:51<34:13:08, 12.61s/it] 24%|██▍       | 3057/12825 [10:54:03<34:08:54, 12.59s/it] 24%|██▍       | 3058/12825 [10:54:16<34:10:24, 12.60s/it] 24%|██▍       | 3059/12825 [10:54:29<34:08:06, 12.58s/it] 24%|██▍       | 3060/12825 [10:54:41<34:05:14, 12.57s/it] 24%|██▍       | 3061/12825 [10:54:54<34:06:03, 12.57s/it] 24%|██▍       | 3062/12825 [10:55:06<34:05:29, 12.57s/it] 24%|██▍       | 3063/12825 [10:55:19<34:06:38, 12.58s/it] 24%|██▍       | 3064/12825 [10:55:31<34:06:32, 12.58s/it] 24%|██▍       | 3065/12825 [10:55:44<34:04:47, 12.57s/it] 24%|██▍       | 3066/12825 [10:55:57<34:03:19, 12.56s/it] 24%|██▍       | 3067/12825 [10:56:09<34:05:25, 12.58s/it] 24%|██▍       | 3068/12825 [10:56:22<34:02:32, 12.56s/it] 24%|██▍       | 3069/12825 [10:56:34<34:02:12, 12.56s/it] 24%|██▍       | 3070/12825 [10:56:47<34:01:24, 12.56s/it] 24%|██▍       | 3071/12825 [10:56:59<34:03:20, 12.57s/it] 24%|██▍       | 3072/12825 [10:57:12<34:04:32, 12.58s/it] 24%|██▍       | 3073/12825 [10:57:25<34:04:57, 12.58s/it] 24%|██▍       | 3074/12825 [10:57:37<34:04:34, 12.58s/it] 24%|██▍       | 3075/12825 [10:57:57<40:03:13, 14.79s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120188.79lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103467.59lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3075
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3075/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3075/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3025] due to args.save_total_limit
 24%|██▍       | 3076/12825 [10:58:10<38:33:53, 14.24s/it] 24%|██▍       | 3077/12825 [10:58:18<33:24:54, 12.34s/it] 24%|██▍       | 3078/12825 [10:58:19<24:03:24,  8.89s/it] 24%|██▍       | 3079/12825 [10:58:44<37:33:13, 13.87s/it] 24%|██▍       | 3080/12825 [10:58:57<36:29:52, 13.48s/it] 24%|██▍       | 3081/12825 [10:59:09<35:46:37, 13.22s/it] 24%|██▍       | 3082/12825 [10:59:22<35:15:56, 13.03s/it] 24%|██▍       | 3083/12825 [10:59:35<34:55:33, 12.91s/it] 24%|██▍       | 3084/12825 [10:59:47<34:39:04, 12.81s/it] 24%|██▍       | 3085/12825 [11:00:00<34:29:24, 12.75s/it] 24%|██▍       | 3086/12825 [11:00:12<34:20:05, 12.69s/it] 24%|██▍       | 3087/12825 [11:00:25<34:14:14, 12.66s/it] 24%|██▍       | 3088/12825 [11:00:38<34:12:00, 12.64s/it] 24%|██▍       | 3089/12825 [11:00:50<34:15:14, 12.67s/it] 24%|██▍       | 3090/12825 [11:01:03<34:10:19, 12.64s/it] 24%|██▍       | 3091/12825 [11:01:15<34:06:35, 12.62s/it] 24%|██▍       | 3092/12825 [11:01:28<34:06:57, 12.62s/it] 24%|██▍       | 3093/12825 [11:01:41<34:06:44, 12.62s/it] 24%|██▍       | 3094/12825 [11:01:53<34:04:53, 12.61s/it] 24%|██▍       | 3095/12825 [11:02:06<34:03:03, 12.60s/it] 24%|██▍       | 3096/12825 [11:02:18<34:01:26, 12.59s/it] 24%|██▍       | 3097/12825 [11:02:31<34:02:12, 12.60s/it] 24%|██▍       | 3098/12825 [11:02:44<34:04:10, 12.61s/it] 24%|██▍       | 3099/12825 [11:02:56<34:00:44, 12.59s/it] 24%|██▍       | 3100/12825 [11:03:09<33:59:38, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120170.68lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103485.84lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3075] due to args.save_total_limit
 24%|██▍       | 3101/12825 [11:03:22<34:13:36, 12.67s/it] 24%|██▍       | 3102/12825 [11:03:34<34:09:03, 12.64s/it] 24%|██▍       | 3103/12825 [11:03:47<34:07:01, 12.63s/it] 24%|██▍       | 3104/12825 [11:03:59<34:02:14, 12.61s/it] 24%|██▍       | 3105/12825 [11:04:12<34:01:06, 12.60s/it] 24%|██▍       | 3106/12825 [11:04:25<34:01:13, 12.60s/it] 24%|██▍       | 3107/12825 [11:04:37<33:59:42, 12.59s/it] 24%|██▍       | 3108/12825 [11:04:58<40:51:26, 15.14s/it] 24%|██▍       | 3109/12825 [11:05:11<38:48:24, 14.38s/it] 24%|██▍       | 3110/12825 [11:05:23<37:19:40, 13.83s/it] 24%|██▍       | 3111/12825 [11:05:36<36:19:07, 13.46s/it] 24%|██▍       | 3112/12825 [11:05:49<35:36:20, 13.20s/it] 24%|██▍       | 3113/12825 [11:06:01<35:05:53, 13.01s/it] 24%|██▍       | 3114/12825 [11:06:14<34:46:13, 12.89s/it] 24%|██▍       | 3115/12825 [11:06:26<34:28:47, 12.78s/it] 24%|██▍       | 3116/12825 [11:06:39<34:19:15, 12.73s/it] 24%|██▍       | 3117/12825 [11:06:51<34:10:04, 12.67s/it] 24%|██▍       | 3118/12825 [11:07:04<34:05:31, 12.64s/it] 24%|██▍       | 3119/12825 [11:07:17<34:04:01, 12.64s/it] 24%|██▍       | 3120/12825 [11:07:29<34:00:25, 12.61s/it] 24%|██▍       | 3121/12825 [11:07:42<33:59:03, 12.61s/it] 24%|██▍       | 3122/12825 [11:07:54<33:59:01, 12.61s/it] 24%|██▍       | 3123/12825 [11:08:07<33:56:03, 12.59s/it] 24%|██▍       | 3124/12825 [11:08:20<33:53:52, 12.58s/it] 24%|██▍       | 3125/12825 [11:08:32<33:52:50, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120192.37lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103450.10lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3050] due to args.save_total_limit
 24%|██▍       | 3126/12825 [11:08:45<34:09:19, 12.68s/it] 24%|██▍       | 3127/12825 [11:08:58<34:05:24, 12.65s/it] 24%|██▍       | 3128/12825 [11:09:10<34:01:53, 12.63s/it] 24%|██▍       | 3129/12825 [11:09:23<33:59:13, 12.62s/it] 24%|██▍       | 3130/12825 [11:09:35<33:58:15, 12.61s/it] 24%|██▍       | 3131/12825 [11:09:48<33:58:19, 12.62s/it] 24%|██▍       | 3132/12825 [11:10:01<33:54:29, 12.59s/it] 24%|██▍       | 3133/12825 [11:10:13<33:54:23, 12.59s/it] 24%|██▍       | 3134/12825 [11:10:26<33:53:11, 12.59s/it] 24%|██▍       | 3135/12825 [11:10:38<33:52:10, 12.58s/it] 24%|██▍       | 3136/12825 [11:10:51<33:50:25, 12.57s/it] 24%|██▍       | 3137/12825 [11:11:03<33:49:58, 12.57s/it] 24%|██▍       | 3138/12825 [11:11:16<33:50:47, 12.58s/it] 24%|██▍       | 3139/12825 [11:11:29<33:51:25, 12.58s/it] 24%|██▍       | 3140/12825 [11:11:41<33:49:45, 12.57s/it] 24%|██▍       | 3141/12825 [11:12:02<40:42:11, 15.13s/it] 24%|██▍       | 3142/12825 [11:12:15<38:38:57, 14.37s/it] 25%|██▍       | 3143/12825 [11:12:27<37:12:25, 13.83s/it] 25%|██▍       | 3144/12825 [11:12:40<36:11:42, 13.46s/it] 25%|██▍       | 3145/12825 [11:12:53<35:28:27, 13.19s/it] 25%|██▍       | 3146/12825 [11:13:05<34:59:11, 13.01s/it] 25%|██▍       | 3147/12825 [11:13:18<34:39:16, 12.89s/it] 25%|██▍       | 3148/12825 [11:13:30<34:24:04, 12.80s/it] 25%|██▍       | 3149/12825 [11:13:43<34:14:23, 12.74s/it] 25%|██▍       | 3150/12825 [11:13:56<34:07:40, 12.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120203.59lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103487.35lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3100] due to args.save_total_limit
 25%|██▍       | 3151/12825 [11:14:08<34:17:03, 12.76s/it] 25%|██▍       | 3152/12825 [11:14:21<34:06:50, 12.70s/it] 25%|██▍       | 3153/12825 [11:14:34<34:01:17, 12.66s/it] 25%|██▍       | 3154/12825 [11:14:46<33:56:51, 12.64s/it] 25%|██▍       | 3155/12825 [11:14:59<33:54:53, 12.63s/it] 25%|██▍       | 3156/12825 [11:15:11<33:54:02, 12.62s/it] 25%|██▍       | 3157/12825 [11:15:24<33:54:13, 12.62s/it] 25%|██▍       | 3158/12825 [11:15:37<33:53:42, 12.62s/it] 25%|██▍       | 3159/12825 [11:15:49<33:51:25, 12.61s/it] 25%|██▍       | 3160/12825 [11:16:02<33:51:02, 12.61s/it] 25%|██▍       | 3161/12825 [11:16:14<33:50:16, 12.61s/it] 25%|██▍       | 3162/12825 [11:16:27<33:50:22, 12.61s/it] 25%|██▍       | 3163/12825 [11:16:40<33:50:35, 12.61s/it] 25%|██▍       | 3164/12825 [11:16:52<33:49:52, 12.61s/it] 25%|██▍       | 3165/12825 [11:17:05<33:50:11, 12.61s/it] 25%|██▍       | 3166/12825 [11:17:17<33:48:51, 12.60s/it] 25%|██▍       | 3167/12825 [11:17:30<33:48:58, 12.60s/it] 25%|██▍       | 3168/12825 [11:17:43<33:47:42, 12.60s/it] 25%|██▍       | 3169/12825 [11:17:55<33:47:36, 12.60s/it] 25%|██▍       | 3170/12825 [11:18:08<33:47:02, 12.60s/it] 25%|██▍       | 3171/12825 [11:18:20<33:48:05, 12.60s/it] 25%|██▍       | 3172/12825 [11:18:33<33:48:18, 12.61s/it] 25%|██▍       | 3173/12825 [11:18:54<40:09:35, 14.98s/it] 25%|██▍       | 3174/12825 [11:19:06<38:15:49, 14.27s/it] 25%|██▍       | 3175/12825 [11:19:19<36:54:58, 13.77s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120203.21lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103462.86lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3150] due to args.save_total_limit
 25%|██▍       | 3176/12825 [11:19:32<36:13:58, 13.52s/it] 25%|██▍       | 3177/12825 [11:19:44<35:28:46, 13.24s/it] 25%|██▍       | 3178/12825 [11:19:57<34:56:46, 13.04s/it] 25%|██▍       | 3179/12825 [11:20:09<34:32:36, 12.89s/it] 25%|██▍       | 3180/12825 [11:20:22<34:17:37, 12.80s/it] 25%|██▍       | 3181/12825 [11:20:35<34:06:43, 12.73s/it] 25%|██▍       | 3182/12825 [11:20:47<33:59:23, 12.69s/it] 25%|██▍       | 3183/12825 [11:21:00<33:54:35, 12.66s/it] 25%|██▍       | 3184/12825 [11:21:12<33:52:49, 12.65s/it] 25%|██▍       | 3185/12825 [11:21:25<33:49:06, 12.63s/it] 25%|██▍       | 3186/12825 [11:21:38<33:45:38, 12.61s/it] 25%|██▍       | 3187/12825 [11:21:50<33:44:21, 12.60s/it] 25%|██▍       | 3188/12825 [11:22:03<33:44:39, 12.61s/it] 25%|██▍       | 3189/12825 [11:22:15<33:41:19, 12.59s/it] 25%|██▍       | 3190/12825 [11:22:28<33:42:54, 12.60s/it] 25%|██▍       | 3191/12825 [11:22:41<33:42:33, 12.60s/it] 25%|██▍       | 3192/12825 [11:22:53<33:42:30, 12.60s/it] 25%|██▍       | 3193/12825 [11:23:06<33:41:38, 12.59s/it] 25%|██▍       | 3194/12825 [11:23:18<33:40:18, 12.59s/it] 25%|██▍       | 3195/12825 [11:23:31<33:40:10, 12.59s/it] 25%|██▍       | 3196/12825 [11:23:43<33:38:23, 12.58s/it] 25%|██▍       | 3197/12825 [11:23:56<33:38:01, 12.58s/it] 25%|██▍       | 3198/12825 [11:24:09<33:38:13, 12.58s/it] 25%|██▍       | 3199/12825 [11:24:21<33:36:52, 12.57s/it] 25%|██▍       | 3200/12825 [11:24:34<33:36:45, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120193.77lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103476.38lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3175] due to args.save_total_limit
 25%|██▍       | 3201/12825 [11:24:47<33:52:01, 12.67s/it] 25%|██▍       | 3202/12825 [11:24:59<33:48:08, 12.65s/it] 25%|██▍       | 3203/12825 [11:25:12<33:43:31, 12.62s/it] 25%|██▍       | 3204/12825 [11:25:24<33:42:19, 12.61s/it] 25%|██▍       | 3205/12825 [11:25:45<40:09:18, 15.03s/it] 25%|██▍       | 3206/12825 [11:25:58<38:10:38, 14.29s/it] 25%|██▌       | 3207/12825 [11:26:10<36:47:52, 13.77s/it] 25%|██▌       | 3208/12825 [11:26:23<35:49:49, 13.41s/it] 25%|██▌       | 3209/12825 [11:26:35<35:06:51, 13.15s/it] 25%|██▌       | 3210/12825 [11:26:48<34:37:02, 12.96s/it] 25%|██▌       | 3211/12825 [11:27:00<34:18:26, 12.85s/it] 25%|██▌       | 3212/12825 [11:27:13<34:05:44, 12.77s/it] 25%|██▌       | 3213/12825 [11:27:25<33:55:36, 12.71s/it] 25%|██▌       | 3214/12825 [11:27:38<33:49:10, 12.67s/it] 25%|██▌       | 3215/12825 [11:27:51<33:43:43, 12.64s/it] 25%|██▌       | 3216/12825 [11:28:03<33:41:19, 12.62s/it] 25%|██▌       | 3217/12825 [11:28:16<33:39:07, 12.61s/it] 25%|██▌       | 3218/12825 [11:28:28<33:39:06, 12.61s/it] 25%|██▌       | 3219/12825 [11:28:41<33:36:18, 12.59s/it] 25%|██▌       | 3220/12825 [11:28:54<33:34:23, 12.58s/it] 25%|██▌       | 3221/12825 [11:29:06<33:33:12, 12.58s/it] 25%|██▌       | 3222/12825 [11:29:19<33:31:48, 12.57s/it] 25%|██▌       | 3223/12825 [11:29:31<33:32:56, 12.58s/it] 25%|██▌       | 3224/12825 [11:29:44<33:30:54, 12.57s/it] 25%|██▌       | 3225/12825 [11:29:56<33:30:42, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120173.87lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103429.98lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3200] due to args.save_total_limit
 25%|██▌       | 3226/12825 [11:30:09<33:47:51, 12.68s/it] 25%|██▌       | 3227/12825 [11:30:22<33:41:23, 12.64s/it] 25%|██▌       | 3228/12825 [11:30:34<33:37:40, 12.61s/it] 25%|██▌       | 3229/12825 [11:30:47<33:34:31, 12.60s/it] 25%|██▌       | 3230/12825 [11:31:00<33:33:40, 12.59s/it] 25%|██▌       | 3231/12825 [11:31:12<33:32:13, 12.58s/it] 25%|██▌       | 3232/12825 [11:31:25<33:31:07, 12.58s/it] 25%|██▌       | 3233/12825 [11:31:37<33:29:28, 12.57s/it] 25%|██▌       | 3234/12825 [11:31:50<33:28:45, 12.57s/it] 25%|██▌       | 3235/12825 [11:32:02<33:29:43, 12.57s/it] 25%|██▌       | 3236/12825 [11:32:15<33:29:58, 12.58s/it] 25%|██▌       | 3237/12825 [11:32:27<33:29:11, 12.57s/it] 25%|██▌       | 3238/12825 [11:32:48<40:01:09, 15.03s/it] 25%|██▌       | 3239/12825 [11:33:01<38:03:05, 14.29s/it] 25%|██▌       | 3240/12825 [11:33:13<36:39:30, 13.77s/it] 25%|██▌       | 3241/12825 [11:33:26<35:40:31, 13.40s/it] 25%|██▌       | 3242/12825 [11:33:39<35:02:15, 13.16s/it] 25%|██▌       | 3243/12825 [11:33:51<34:35:01, 12.99s/it] 25%|██▌       | 3244/12825 [11:34:04<34:15:22, 12.87s/it] 25%|██▌       | 3245/12825 [11:34:16<34:00:00, 12.78s/it] 25%|██▌       | 3246/12825 [11:34:29<33:50:39, 12.72s/it] 25%|██▌       | 3247/12825 [11:34:41<33:43:51, 12.68s/it] 25%|██▌       | 3248/12825 [11:34:54<33:39:42, 12.65s/it] 25%|██▌       | 3249/12825 [11:35:07<33:37:06, 12.64s/it] 25%|██▌       | 3250/12825 [11:35:19<33:33:23, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120182.54lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103459.46lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3225] due to args.save_total_limit
 25%|██▌       | 3251/12825 [11:35:32<33:47:34, 12.71s/it] 25%|██▌       | 3252/12825 [11:35:45<33:40:10, 12.66s/it] 25%|██▌       | 3253/12825 [11:35:57<33:36:48, 12.64s/it] 25%|██▌       | 3254/12825 [11:36:10<33:34:15, 12.63s/it] 25%|██▌       | 3255/12825 [11:36:22<33:32:57, 12.62s/it] 25%|██▌       | 3256/12825 [11:36:35<33:32:02, 12.62s/it] 25%|██▌       | 3257/12825 [11:36:48<33:30:14, 12.61s/it] 25%|██▌       | 3258/12825 [11:37:00<33:28:14, 12.59s/it] 25%|██▌       | 3259/12825 [11:37:13<33:26:05, 12.58s/it] 25%|██▌       | 3260/12825 [11:37:25<33:27:11, 12.59s/it] 25%|██▌       | 3261/12825 [11:37:38<33:26:50, 12.59s/it] 25%|██▌       | 3262/12825 [11:37:51<33:27:28, 12.60s/it] 25%|██▌       | 3263/12825 [11:38:03<33:25:11, 12.58s/it] 25%|██▌       | 3264/12825 [11:38:16<33:26:05, 12.59s/it] 25%|██▌       | 3265/12825 [11:38:28<33:23:22, 12.57s/it] 25%|██▌       | 3266/12825 [11:38:41<33:22:22, 12.57s/it] 25%|██▌       | 3267/12825 [11:38:53<33:23:25, 12.58s/it] 25%|██▌       | 3268/12825 [11:39:06<33:22:59, 12.58s/it] 25%|██▌       | 3269/12825 [11:39:19<33:24:17, 12.58s/it] 25%|██▌       | 3270/12825 [11:39:41<41:21:40, 15.58s/it] 26%|██▌       | 3271/12825 [11:39:54<38:57:15, 14.68s/it] 26%|██▌       | 3272/12825 [11:40:06<37:16:48, 14.05s/it] 26%|██▌       | 3273/12825 [11:40:19<36:06:20, 13.61s/it] 26%|██▌       | 3274/12825 [11:40:31<35:15:17, 13.29s/it] 26%|██▌       | 3275/12825 [11:40:44<34:41:07, 13.08s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120146.20lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103447.74lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3250] due to args.save_total_limit
 26%|██▌       | 3276/12825 [11:40:57<34:32:20, 13.02s/it] 26%|██▌       | 3277/12825 [11:41:09<34:09:46, 12.88s/it] 26%|██▌       | 3278/12825 [11:41:22<33:54:28, 12.79s/it] 26%|██▌       | 3279/12825 [11:41:35<33:43:49, 12.72s/it] 26%|██▌       | 3280/12825 [11:41:47<33:37:17, 12.68s/it] 26%|██▌       | 3281/12825 [11:42:00<33:31:18, 12.64s/it] 26%|██▌       | 3282/12825 [11:42:12<33:33:39, 12.66s/it] 26%|██▌       | 3283/12825 [11:42:25<33:27:46, 12.62s/it] 26%|██▌       | 3284/12825 [11:42:38<33:24:57, 12.61s/it] 26%|██▌       | 3285/12825 [11:42:50<33:24:05, 12.60s/it] 26%|██▌       | 3286/12825 [11:43:03<33:22:43, 12.60s/it] 26%|██▌       | 3287/12825 [11:43:15<33:22:23, 12.60s/it] 26%|██▌       | 3288/12825 [11:43:28<33:19:32, 12.58s/it] 26%|██▌       | 3289/12825 [11:43:40<33:20:40, 12.59s/it] 26%|██▌       | 3290/12825 [11:43:53<33:19:58, 12.59s/it] 26%|██▌       | 3291/12825 [11:44:06<33:18:59, 12.58s/it] 26%|██▌       | 3292/12825 [11:44:18<33:17:57, 12.57s/it] 26%|██▌       | 3293/12825 [11:44:31<33:17:33, 12.57s/it] 26%|██▌       | 3294/12825 [11:44:43<33:16:06, 12.57s/it] 26%|██▌       | 3295/12825 [11:44:56<33:16:58, 12.57s/it] 26%|██▌       | 3296/12825 [11:45:08<33:16:54, 12.57s/it] 26%|██▌       | 3297/12825 [11:45:21<33:14:10, 12.56s/it] 26%|██▌       | 3298/12825 [11:45:34<33:15:03, 12.56s/it] 26%|██▌       | 3299/12825 [11:45:46<33:14:16, 12.56s/it] 26%|██▌       | 3300/12825 [11:45:59<33:13:23, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120195.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103471.94lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3125] due to args.save_total_limit
 26%|██▌       | 3301/12825 [11:46:12<33:31:06, 12.67s/it] 26%|██▌       | 3302/12825 [11:46:32<39:20:53, 14.87s/it] 26%|██▌       | 3303/12825 [11:46:44<37:30:13, 14.18s/it] 26%|██▌       | 3304/12825 [11:46:57<36:14:27, 13.70s/it] 26%|██▌       | 3305/12825 [11:47:09<35:20:48, 13.37s/it] 26%|██▌       | 3306/12825 [11:47:22<34:42:36, 13.13s/it] 26%|██▌       | 3307/12825 [11:47:35<34:16:55, 12.97s/it] 26%|██▌       | 3308/12825 [11:47:47<33:56:41, 12.84s/it] 26%|██▌       | 3309/12825 [11:48:00<33:42:47, 12.75s/it] 26%|██▌       | 3310/12825 [11:48:12<33:34:49, 12.71s/it] 26%|██▌       | 3311/12825 [11:48:25<33:29:22, 12.67s/it] 26%|██▌       | 3312/12825 [11:48:37<33:25:19, 12.65s/it] 26%|██▌       | 3313/12825 [11:48:50<33:21:41, 12.63s/it] 26%|██▌       | 3314/12825 [11:49:03<33:18:36, 12.61s/it] 26%|██▌       | 3315/12825 [11:49:15<33:16:29, 12.60s/it] 26%|██▌       | 3316/12825 [11:49:28<33:15:53, 12.59s/it] 26%|██▌       | 3317/12825 [11:49:40<33:14:30, 12.59s/it] 26%|██▌       | 3318/12825 [11:49:53<33:15:41, 12.60s/it] 26%|██▌       | 3319/12825 [11:50:05<33:15:22, 12.59s/it] 26%|██▌       | 3320/12825 [11:50:18<33:11:38, 12.57s/it] 26%|██▌       | 3321/12825 [11:50:31<33:09:44, 12.56s/it] 26%|██▌       | 3322/12825 [11:50:43<33:06:57, 12.55s/it] 26%|██▌       | 3323/12825 [11:50:56<33:08:40, 12.56s/it] 26%|██▌       | 3324/12825 [11:51:08<33:08:34, 12.56s/it] 26%|██▌       | 3325/12825 [11:51:21<33:10:06, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120151.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103421.10lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3275] due to args.save_total_limit
 26%|██▌       | 3326/12825 [11:51:34<33:24:16, 12.66s/it] 26%|██▌       | 3327/12825 [11:51:46<33:17:31, 12.62s/it] 26%|██▌       | 3328/12825 [11:51:59<33:16:38, 12.61s/it] 26%|██▌       | 3329/12825 [11:52:11<33:11:59, 12.59s/it] 26%|██▌       | 3330/12825 [11:52:24<33:07:22, 12.56s/it] 26%|██▌       | 3331/12825 [11:52:36<33:05:11, 12.55s/it] 26%|██▌       | 3332/12825 [11:52:49<33:06:38, 12.56s/it] 26%|██▌       | 3333/12825 [11:53:01<33:05:27, 12.55s/it] 26%|██▌       | 3334/12825 [11:53:22<39:28:57, 14.98s/it] 26%|██▌       | 3335/12825 [11:53:35<37:34:17, 14.25s/it] 26%|██▌       | 3336/12825 [11:53:47<36:13:05, 13.74s/it] 26%|██▌       | 3337/12825 [11:54:00<35:14:58, 13.37s/it] 26%|██▌       | 3338/12825 [11:54:12<34:35:27, 13.13s/it] 26%|██▌       | 3339/12825 [11:54:25<34:07:13, 12.95s/it] 26%|██▌       | 3340/12825 [11:54:37<33:49:23, 12.84s/it] 26%|██▌       | 3341/12825 [11:54:50<33:34:59, 12.75s/it] 26%|██▌       | 3342/12825 [11:55:02<33:26:10, 12.69s/it] 26%|██▌       | 3343/12825 [11:55:15<33:20:36, 12.66s/it] 26%|██▌       | 3344/12825 [11:55:28<33:14:11, 12.62s/it] 26%|██▌       | 3345/12825 [11:55:40<33:13:53, 12.62s/it] 26%|██▌       | 3346/12825 [11:55:53<33:11:05, 12.60s/it] 26%|██▌       | 3347/12825 [11:56:05<33:08:58, 12.59s/it] 26%|██▌       | 3348/12825 [11:56:18<33:05:49, 12.57s/it] 26%|██▌       | 3349/12825 [11:56:30<33:05:52, 12.57s/it] 26%|██▌       | 3350/12825 [11:56:43<33:03:48, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120316.10lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103536.64lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3325] due to args.save_total_limit
 26%|██▌       | 3351/12825 [11:56:56<33:17:35, 12.65s/it] 26%|██▌       | 3352/12825 [11:57:08<33:11:00, 12.61s/it] 26%|██▌       | 3353/12825 [11:57:21<33:08:28, 12.60s/it] 26%|██▌       | 3354/12825 [11:57:33<33:07:07, 12.59s/it] 26%|██▌       | 3355/12825 [11:57:46<33:07:29, 12.59s/it] 26%|██▌       | 3356/12825 [11:57:59<33:06:40, 12.59s/it] 26%|██▌       | 3357/12825 [11:58:11<33:03:54, 12.57s/it] 26%|██▌       | 3358/12825 [11:58:24<33:01:19, 12.56s/it] 26%|██▌       | 3359/12825 [11:58:36<33:02:02, 12.56s/it] 26%|██▌       | 3360/12825 [11:58:49<33:00:52, 12.56s/it] 26%|██▌       | 3361/12825 [11:59:01<33:00:23, 12.56s/it] 26%|██▌       | 3362/12825 [11:59:14<32:58:40, 12.55s/it] 26%|██▌       | 3363/12825 [11:59:26<32:59:52, 12.55s/it] 26%|██▌       | 3364/12825 [11:59:39<33:00:41, 12.56s/it] 26%|██▌       | 3365/12825 [11:59:52<33:00:04, 12.56s/it] 26%|██▌       | 3366/12825 [12:00:04<33:00:42, 12.56s/it] 26%|██▋       | 3367/12825 [12:00:25<39:38:42, 15.09s/it] 26%|██▋       | 3368/12825 [12:00:38<37:37:44, 14.32s/it] 26%|██▋       | 3369/12825 [12:00:50<36:14:29, 13.80s/it] 26%|██▋       | 3370/12825 [12:01:03<35:15:35, 13.43s/it] 26%|██▋       | 3371/12825 [12:01:15<34:32:26, 13.15s/it] 26%|██▋       | 3372/12825 [12:01:28<34:03:43, 12.97s/it] 26%|██▋       | 3373/12825 [12:01:40<33:45:18, 12.86s/it] 26%|██▋       | 3374/12825 [12:01:53<33:29:40, 12.76s/it] 26%|██▋       | 3375/12825 [12:02:06<33:18:10, 12.69s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120289.14lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103505.89lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3350] due to args.save_total_limit
 26%|██▋       | 3376/12825 [12:02:18<33:29:01, 12.76s/it] 26%|██▋       | 3377/12825 [12:02:31<33:17:23, 12.68s/it] 26%|██▋       | 3378/12825 [12:02:43<33:09:41, 12.64s/it] 26%|██▋       | 3379/12825 [12:02:56<33:04:41, 12.61s/it] 26%|██▋       | 3380/12825 [12:03:09<33:03:01, 12.60s/it] 26%|██▋       | 3381/12825 [12:03:21<33:02:12, 12.59s/it] 26%|██▋       | 3382/12825 [12:03:34<33:01:22, 12.59s/it] 26%|██▋       | 3383/12825 [12:03:46<32:59:56, 12.58s/it] 26%|██▋       | 3384/12825 [12:03:59<32:57:44, 12.57s/it] 26%|██▋       | 3385/12825 [12:04:11<32:56:12, 12.56s/it] 26%|██▋       | 3386/12825 [12:04:24<32:54:36, 12.55s/it] 26%|██▋       | 3387/12825 [12:04:36<32:54:45, 12.55s/it] 26%|██▋       | 3388/12825 [12:04:49<32:54:47, 12.56s/it] 26%|██▋       | 3389/12825 [12:05:02<32:55:10, 12.56s/it] 26%|██▋       | 3390/12825 [12:05:14<32:53:46, 12.55s/it] 26%|██▋       | 3391/12825 [12:05:27<32:55:32, 12.56s/it] 26%|██▋       | 3392/12825 [12:05:39<32:55:44, 12.57s/it] 26%|██▋       | 3393/12825 [12:05:52<32:53:46, 12.56s/it] 26%|██▋       | 3394/12825 [12:06:04<32:54:09, 12.56s/it] 26%|██▋       | 3395/12825 [12:06:17<32:52:18, 12.55s/it] 26%|██▋       | 3396/12825 [12:06:30<32:54:04, 12.56s/it] 26%|██▋       | 3397/12825 [12:06:42<32:53:20, 12.56s/it] 26%|██▋       | 3398/12825 [12:06:55<32:53:18, 12.56s/it] 27%|██▋       | 3399/12825 [12:07:15<39:04:56, 14.93s/it] 27%|██▋       | 3400/12825 [12:07:28<37:13:01, 14.22s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120231.67lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103481.58lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3300] due to args.save_total_limit
 27%|██▋       | 3401/12825 [12:07:41<36:11:54, 13.83s/it] 27%|██▋       | 3402/12825 [12:07:53<35:12:10, 13.45s/it] 27%|██▋       | 3403/12825 [12:08:06<34:28:18, 13.17s/it] 27%|██▋       | 3404/12825 [12:08:18<33:57:56, 12.98s/it] 27%|██▋       | 3405/12825 [12:08:31<33:36:34, 12.84s/it] 27%|██▋       | 3406/12825 [12:08:43<33:22:09, 12.75s/it] 27%|██▋       | 3407/12825 [12:08:56<33:10:34, 12.68s/it] 27%|██▋       | 3408/12825 [12:09:08<33:02:37, 12.63s/it] 27%|██▋       | 3409/12825 [12:09:21<32:59:30, 12.61s/it] 27%|██▋       | 3410/12825 [12:09:33<32:55:51, 12.59s/it] 27%|██▋       | 3411/12825 [12:09:46<32:53:41, 12.58s/it] 27%|██▋       | 3412/12825 [12:09:59<32:52:24, 12.57s/it] 27%|██▋       | 3413/12825 [12:10:11<32:51:37, 12.57s/it] 27%|██▋       | 3414/12825 [12:10:24<32:48:51, 12.55s/it] 27%|██▋       | 3415/12825 [12:10:36<32:48:58, 12.55s/it] 27%|██▋       | 3416/12825 [12:10:49<32:48:50, 12.56s/it] 27%|██▋       | 3417/12825 [12:11:01<32:49:49, 12.56s/it] 27%|██▋       | 3418/12825 [12:11:14<32:51:09, 12.57s/it] 27%|██▋       | 3419/12825 [12:11:26<32:50:35, 12.57s/it] 27%|██▋       | 3420/12825 [12:11:39<32:49:26, 12.56s/it] 27%|██▋       | 3421/12825 [12:11:51<32:46:10, 12.54s/it] 27%|██▋       | 3422/12825 [12:12:04<32:48:01, 12.56s/it] 27%|██▋       | 3423/12825 [12:12:17<32:46:45, 12.55s/it] 27%|██▋       | 3424/12825 [12:12:29<32:47:02, 12.55s/it] 27%|██▋       | 3425/12825 [12:12:42<32:48:03, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120244.31lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103522.73lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3375] due to args.save_total_limit
 27%|██▋       | 3426/12825 [12:12:55<33:02:51, 12.66s/it] 27%|██▋       | 3427/12825 [12:13:07<32:55:54, 12.61s/it] 27%|██▋       | 3428/12825 [12:13:20<32:52:56, 12.60s/it] 27%|██▋       | 3429/12825 [12:13:32<32:48:54, 12.57s/it] 27%|██▋       | 3430/12825 [12:13:45<32:46:00, 12.56s/it] 27%|██▋       | 3431/12825 [12:13:57<32:46:18, 12.56s/it] 27%|██▋       | 3432/12825 [12:14:18<39:05:07, 14.98s/it] 27%|██▋       | 3433/12825 [12:14:31<37:12:15, 14.26s/it] 27%|██▋       | 3434/12825 [12:14:43<35:51:16, 13.74s/it] 27%|██▋       | 3435/12825 [12:14:56<34:53:46, 13.38s/it] 27%|██▋       | 3436/12825 [12:15:08<34:14:13, 13.13s/it] 27%|██▋       | 3437/12825 [12:15:21<33:47:28, 12.96s/it] 27%|██▋       | 3438/12825 [12:15:33<33:28:40, 12.84s/it] 27%|██▋       | 3439/12825 [12:15:46<33:15:35, 12.76s/it] 27%|██▋       | 3440/12825 [12:15:58<33:07:20, 12.71s/it] 27%|██▋       | 3441/12825 [12:16:11<32:59:37, 12.66s/it] 27%|██▋       | 3442/12825 [12:16:24<32:56:14, 12.64s/it] 27%|██▋       | 3443/12825 [12:16:36<32:49:56, 12.60s/it] 27%|██▋       | 3444/12825 [12:16:49<32:48:41, 12.59s/it] 27%|██▋       | 3445/12825 [12:17:01<32:46:19, 12.58s/it] 27%|██▋       | 3446/12825 [12:17:14<32:45:18, 12.57s/it] 27%|██▋       | 3447/12825 [12:17:26<32:45:20, 12.57s/it] 27%|██▋       | 3448/12825 [12:17:39<32:42:27, 12.56s/it] 27%|██▋       | 3449/12825 [12:17:51<32:43:55, 12.57s/it] 27%|██▋       | 3450/12825 [12:18:04<32:43:16, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120170.30lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103469.67lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3425] due to args.save_total_limit
 27%|██▋       | 3451/12825 [12:18:17<33:03:44, 12.70s/it] 27%|██▋       | 3452/12825 [12:18:30<32:58:12, 12.66s/it] 27%|██▋       | 3453/12825 [12:18:42<32:55:07, 12.64s/it] 27%|██▋       | 3454/12825 [12:18:55<32:52:10, 12.63s/it] 27%|██▋       | 3455/12825 [12:19:07<32:49:47, 12.61s/it] 27%|██▋       | 3456/12825 [12:19:20<32:46:17, 12.59s/it] 27%|██▋       | 3457/12825 [12:19:32<32:45:11, 12.59s/it] 27%|██▋       | 3458/12825 [12:19:45<32:42:12, 12.57s/it] 27%|██▋       | 3459/12825 [12:19:58<32:43:59, 12.58s/it] 27%|██▋       | 3460/12825 [12:20:10<32:43:15, 12.58s/it] 27%|██▋       | 3461/12825 [12:20:23<32:41:36, 12.57s/it] 27%|██▋       | 3462/12825 [12:20:35<32:42:33, 12.58s/it] 27%|██▋       | 3463/12825 [12:20:48<32:41:22, 12.57s/it] 27%|██▋       | 3464/12825 [12:21:09<39:14:56, 15.09s/it] 27%|██▋       | 3465/12825 [12:21:21<37:17:40, 14.34s/it] 27%|██▋       | 3466/12825 [12:21:34<35:53:18, 13.80s/it] 27%|██▋       | 3467/12825 [12:21:47<34:55:37, 13.44s/it] 27%|██▋       | 3468/12825 [12:21:59<34:15:40, 13.18s/it] 27%|██▋       | 3469/12825 [12:22:12<33:45:20, 12.99s/it] 27%|██▋       | 3470/12825 [12:22:24<33:25:35, 12.86s/it] 27%|██▋       | 3471/12825 [12:22:37<33:11:32, 12.77s/it] 27%|██▋       | 3472/12825 [12:22:49<33:02:03, 12.72s/it] 27%|██▋       | 3473/12825 [12:23:02<32:54:42, 12.67s/it] 27%|██▋       | 3474/12825 [12:23:14<32:48:19, 12.63s/it] 27%|██▋       | 3475/12825 [12:23:27<32:45:49, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120244.94lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103518.19lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3450] due to args.save_total_limit
 27%|██▋       | 3476/12825 [12:23:40<33:00:59, 12.71s/it] 27%|██▋       | 3477/12825 [12:23:53<32:56:30, 12.69s/it] 27%|██▋       | 3478/12825 [12:24:05<32:50:05, 12.65s/it] 27%|██▋       | 3479/12825 [12:24:18<32:48:16, 12.64s/it] 27%|██▋       | 3480/12825 [12:24:30<32:45:28, 12.62s/it] 27%|██▋       | 3481/12825 [12:24:43<32:41:40, 12.60s/it] 27%|██▋       | 3482/12825 [12:24:56<32:51:48, 12.66s/it] 27%|██▋       | 3483/12825 [12:25:08<32:46:11, 12.63s/it] 27%|██▋       | 3484/12825 [12:25:21<32:42:29, 12.61s/it] 27%|██▋       | 3485/12825 [12:25:33<32:40:24, 12.59s/it] 27%|██▋       | 3486/12825 [12:25:46<32:42:06, 12.61s/it] 27%|██▋       | 3487/12825 [12:25:59<32:40:55, 12.60s/it] 27%|██▋       | 3488/12825 [12:26:11<32:38:00, 12.58s/it] 27%|██▋       | 3489/12825 [12:26:24<32:37:00, 12.58s/it] 27%|██▋       | 3490/12825 [12:26:36<32:35:27, 12.57s/it] 27%|██▋       | 3491/12825 [12:26:49<32:35:40, 12.57s/it] 27%|██▋       | 3492/12825 [12:27:01<32:37:24, 12.58s/it] 27%|██▋       | 3493/12825 [12:27:14<32:36:18, 12.58s/it] 27%|██▋       | 3494/12825 [12:27:27<32:34:04, 12.57s/it] 27%|██▋       | 3495/12825 [12:27:39<32:34:13, 12.57s/it] 27%|██▋       | 3496/12825 [12:27:59<38:36:27, 14.90s/it] 27%|██▋       | 3497/12825 [12:28:12<36:48:09, 14.20s/it] 27%|██▋       | 3498/12825 [12:28:25<35:30:25, 13.70s/it] 27%|██▋       | 3499/12825 [12:28:37<34:36:17, 13.36s/it] 27%|██▋       | 3500/12825 [12:28:50<33:58:24, 13.12s/it]                                                           27%|██▋       | 3500/12825 [12:28:50<33:58:24, 13.12s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120126.58lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103378.24lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3400] due to args.save_total_limit
 27%|██▋       | 3501/12825 [12:29:03<33:52:58, 13.08s/it] 27%|██▋       | 3502/12825 [12:29:15<33:27:28, 12.92s/it] 27%|██▋       | 3503/12825 [12:29:28<33:08:34, 12.80s/it] 27%|██▋       | 3504/12825 [12:29:40<32:55:51, 12.72s/it] 27%|██▋       | 3505/12825 [12:29:53<32:45:57, 12.66s/it] 27%|██▋       | 3506/12825 [12:30:05<32:40:40, 12.62s/it] 27%|██▋       | 3507/12825 [12:30:18<32:37:34, 12.61s/it] 27%|██▋       | 3508/12825 [12:30:30<32:33:51, 12.58s/it] 27%|██▋       | 3509/12825 [12:30:43<32:32:58, 12.58s/it] 27%|██▋       | 3510/12825 [12:30:56<32:30:33, 12.56s/it] 27%|██▋       | 3511/12825 [12:31:08<32:27:01, 12.54s/it] 27%|██▋       | 3512/12825 [12:31:21<32:25:29, 12.53s/it] 27%|██▋       | 3513/12825 [12:31:33<32:25:40, 12.54s/it] 27%|██▋       | 3514/12825 [12:31:46<32:25:46, 12.54s/it] 27%|██▋       | 3515/12825 [12:31:58<32:26:08, 12.54s/it] 27%|██▋       | 3516/12825 [12:32:11<32:25:53, 12.54s/it] 27%|██▋       | 3517/12825 [12:32:23<32:26:52, 12.55s/it] 27%|██▋       | 3518/12825 [12:32:36<32:26:40, 12.55s/it] 27%|██▋       | 3519/12825 [12:32:48<32:27:23, 12.56s/it] 27%|██▋       | 3520/12825 [12:33:01<32:27:34, 12.56s/it] 27%|██▋       | 3521/12825 [12:33:14<32:26:53, 12.56s/it] 27%|██▋       | 3522/12825 [12:33:26<32:26:48, 12.56s/it] 27%|██▋       | 3523/12825 [12:33:39<32:28:37, 12.57s/it] 27%|██▋       | 3524/12825 [12:33:51<32:29:13, 12.57s/it] 27%|██▋       | 3525/12825 [12:34:04<32:28:57, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120256.95lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103560.50lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3475] due to args.save_total_limit
 27%|██▋       | 3526/12825 [12:34:17<32:45:46, 12.68s/it] 28%|██▊       | 3527/12825 [12:34:30<32:56:56, 12.76s/it] 28%|██▊       | 3528/12825 [12:34:42<32:47:14, 12.70s/it] 28%|██▊       | 3529/12825 [12:35:03<38:56:53, 15.08s/it] 28%|██▊       | 3530/12825 [12:35:16<37:03:10, 14.35s/it] 28%|██▊       | 3531/12825 [12:35:28<35:38:48, 13.81s/it] 28%|██▊       | 3532/12825 [12:35:41<34:40:25, 13.43s/it] 28%|██▊       | 3533/12825 [12:35:53<33:59:13, 13.17s/it] 28%|██▊       | 3534/12825 [12:36:06<33:29:50, 12.98s/it] 28%|██▊       | 3535/12825 [12:36:18<33:09:54, 12.85s/it] 28%|██▊       | 3536/12825 [12:36:31<32:57:57, 12.78s/it] 28%|██▊       | 3537/12825 [12:36:44<32:50:13, 12.73s/it] 28%|██▊       | 3538/12825 [12:36:56<32:44:19, 12.69s/it] 28%|██▊       | 3539/12825 [12:37:09<32:40:22, 12.67s/it] 28%|██▊       | 3540/12825 [12:37:21<32:36:06, 12.64s/it] 28%|██▊       | 3541/12825 [12:37:34<32:35:23, 12.64s/it] 28%|██▊       | 3542/12825 [12:37:47<32:33:39, 12.63s/it] 28%|██▊       | 3543/12825 [12:37:59<32:32:22, 12.62s/it] 28%|██▊       | 3544/12825 [12:38:12<32:31:02, 12.61s/it] 28%|██▊       | 3545/12825 [12:38:24<32:31:31, 12.62s/it] 28%|██▊       | 3546/12825 [12:38:37<32:30:18, 12.61s/it] 28%|██▊       | 3547/12825 [12:38:50<32:30:33, 12.61s/it] 28%|██▊       | 3548/12825 [12:39:02<32:29:45, 12.61s/it] 28%|██▊       | 3549/12825 [12:39:15<32:27:26, 12.60s/it] 28%|██▊       | 3550/12825 [12:39:27<32:26:52, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120174.38lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103465.04lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3500] due to args.save_total_limit
 28%|██▊       | 3551/12825 [12:39:40<32:38:33, 12.67s/it] 28%|██▊       | 3552/12825 [12:39:53<32:32:52, 12.64s/it] 28%|██▊       | 3553/12825 [12:40:05<32:29:10, 12.61s/it] 28%|██▊       | 3554/12825 [12:40:18<32:27:51, 12.61s/it] 28%|██▊       | 3555/12825 [12:40:31<32:27:06, 12.60s/it] 28%|██▊       | 3556/12825 [12:40:43<32:26:40, 12.60s/it] 28%|██▊       | 3557/12825 [12:40:56<32:27:25, 12.61s/it] 28%|██▊       | 3558/12825 [12:41:08<32:27:36, 12.61s/it] 28%|██▊       | 3559/12825 [12:41:21<32:27:21, 12.61s/it] 28%|██▊       | 3560/12825 [12:41:34<32:27:40, 12.61s/it] 28%|██▊       | 3561/12825 [12:41:54<38:37:11, 15.01s/it] 28%|██▊       | 3562/12825 [12:42:07<36:44:06, 14.28s/it] 28%|██▊       | 3563/12825 [12:42:19<35:23:33, 13.76s/it] 28%|██▊       | 3564/12825 [12:42:32<34:26:02, 13.39s/it] 28%|██▊       | 3565/12825 [12:42:44<33:47:13, 13.14s/it] 28%|██▊       | 3566/12825 [12:42:57<33:21:00, 12.97s/it] 28%|██▊       | 3567/12825 [12:43:09<33:01:21, 12.84s/it] 28%|██▊       | 3568/12825 [12:43:22<32:46:46, 12.75s/it] 28%|██▊       | 3569/12825 [12:43:35<32:38:01, 12.69s/it] 28%|██▊       | 3570/12825 [12:43:47<32:32:09, 12.66s/it] 28%|██▊       | 3571/12825 [12:44:00<32:28:11, 12.63s/it] 28%|██▊       | 3572/12825 [12:44:12<32:23:47, 12.60s/it] 28%|██▊       | 3573/12825 [12:44:25<32:21:35, 12.59s/it] 28%|██▊       | 3574/12825 [12:44:37<32:19:58, 12.58s/it] 28%|██▊       | 3575/12825 [12:44:50<32:18:36, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120267.68lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103398.34lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3550] due to args.save_total_limit
 28%|██▊       | 3576/12825 [12:45:03<32:32:46, 12.67s/it] 28%|██▊       | 3577/12825 [12:45:15<32:27:03, 12.63s/it] 28%|██▊       | 3578/12825 [12:45:28<32:24:27, 12.62s/it] 28%|██▊       | 3579/12825 [12:45:41<32:21:25, 12.60s/it] 28%|██▊       | 3580/12825 [12:45:53<32:20:53, 12.60s/it] 28%|██▊       | 3581/12825 [12:46:06<32:22:10, 12.61s/it] 28%|██▊       | 3582/12825 [12:46:18<32:19:34, 12.59s/it] 28%|██▊       | 3583/12825 [12:46:31<32:18:38, 12.59s/it] 28%|██▊       | 3584/12825 [12:46:43<32:18:17, 12.58s/it] 28%|██▊       | 3585/12825 [12:46:56<32:17:29, 12.58s/it] 28%|██▊       | 3586/12825 [12:47:09<32:18:26, 12.59s/it] 28%|██▊       | 3587/12825 [12:47:21<32:16:47, 12.58s/it] 28%|██▊       | 3588/12825 [12:47:34<32:17:14, 12.58s/it] 28%|██▊       | 3589/12825 [12:47:46<32:17:33, 12.59s/it] 28%|██▊       | 3590/12825 [12:47:54<28:39:11, 11.17s/it] 28%|██▊       | 3591/12825 [12:47:55<20:41:17,  8.07s/it] 28%|██▊       | 3592/12825 [12:48:21<34:06:38, 13.30s/it] 28%|██▊       | 3593/12825 [12:48:33<33:36:07, 13.10s/it] 28%|██▊       | 3594/12825 [12:48:54<39:30:50, 15.41s/it] 28%|██▊       | 3595/12825 [12:49:07<37:20:28, 14.56s/it] 28%|██▊       | 3596/12825 [12:49:19<35:48:32, 13.97s/it] 28%|██▊       | 3597/12825 [12:49:32<34:45:55, 13.56s/it] 28%|██▊       | 3598/12825 [12:49:44<34:00:01, 13.27s/it] 28%|██▊       | 3599/12825 [12:49:57<33:29:57, 13.07s/it] 28%|██▊       | 3600/12825 [12:50:10<33:07:40, 12.93s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120150.79lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103471.37lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3575] due to args.save_total_limit
 28%|██▊       | 3601/12825 [12:50:23<33:09:14, 12.94s/it] 28%|██▊       | 3602/12825 [12:50:35<32:53:20, 12.84s/it] 28%|██▊       | 3603/12825 [12:50:48<32:42:49, 12.77s/it] 28%|██▊       | 3604/12825 [12:51:00<32:34:16, 12.72s/it] 28%|██▊       | 3605/12825 [12:51:13<32:29:07, 12.68s/it] 28%|██▊       | 3606/12825 [12:51:26<32:27:07, 12.67s/it] 28%|██▊       | 3607/12825 [12:51:38<32:25:17, 12.66s/it] 28%|██▊       | 3608/12825 [12:51:51<32:25:31, 12.66s/it] 28%|██▊       | 3609/12825 [12:52:04<32:23:29, 12.65s/it] 28%|██▊       | 3610/12825 [12:52:16<32:21:30, 12.64s/it] 28%|██▊       | 3611/12825 [12:52:29<32:20:03, 12.63s/it] 28%|██▊       | 3612/12825 [12:52:41<32:18:39, 12.63s/it] 28%|██▊       | 3613/12825 [12:52:54<32:19:19, 12.63s/it] 28%|██▊       | 3614/12825 [12:53:07<32:16:53, 12.62s/it] 28%|██▊       | 3615/12825 [12:53:19<32:16:59, 12.62s/it] 28%|██▊       | 3616/12825 [12:53:32<32:18:30, 12.63s/it] 28%|██▊       | 3617/12825 [12:53:45<32:18:24, 12.63s/it] 28%|██▊       | 3618/12825 [12:53:57<32:17:13, 12.62s/it] 28%|██▊       | 3619/12825 [12:54:10<32:15:15, 12.61s/it] 28%|██▊       | 3620/12825 [12:54:22<32:16:46, 12.62s/it] 28%|██▊       | 3621/12825 [12:54:35<32:16:31, 12.62s/it] 28%|██▊       | 3622/12825 [12:54:48<32:16:15, 12.62s/it] 28%|██▊       | 3623/12825 [12:55:00<32:15:29, 12.62s/it] 28%|██▊       | 3624/12825 [12:55:13<32:15:33, 12.62s/it] 28%|██▊       | 3625/12825 [12:55:25<32:15:32, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120128.49lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103390.51lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3600] due to args.save_total_limit
 28%|██▊       | 3626/12825 [12:55:46<38:30:17, 15.07s/it] 28%|██▊       | 3627/12825 [12:55:59<36:35:19, 14.32s/it] 28%|██▊       | 3628/12825 [12:56:11<35:14:45, 13.80s/it] 28%|██▊       | 3629/12825 [12:56:24<34:19:02, 13.43s/it] 28%|██▊       | 3630/12825 [12:56:37<33:39:58, 13.18s/it] 28%|██▊       | 3631/12825 [12:56:49<33:12:26, 13.00s/it] 28%|██▊       | 3632/12825 [12:57:02<32:51:21, 12.87s/it] 28%|██▊       | 3633/12825 [12:57:14<32:37:52, 12.78s/it] 28%|██▊       | 3634/12825 [12:57:27<32:29:37, 12.73s/it] 28%|██▊       | 3635/12825 [12:57:39<32:22:28, 12.68s/it] 28%|██▊       | 3636/12825 [12:57:52<32:16:31, 12.64s/it] 28%|██▊       | 3637/12825 [12:58:05<32:13:55, 12.63s/it] 28%|██▊       | 3638/12825 [12:58:17<32:11:49, 12.62s/it] 28%|██▊       | 3639/12825 [12:58:30<32:09:54, 12.61s/it] 28%|██▊       | 3640/12825 [12:58:42<32:07:34, 12.59s/it] 28%|██▊       | 3641/12825 [12:58:55<32:08:24, 12.60s/it] 28%|██▊       | 3642/12825 [12:59:08<32:08:33, 12.60s/it] 28%|██▊       | 3643/12825 [12:59:20<32:08:27, 12.60s/it] 28%|██▊       | 3644/12825 [12:59:33<32:07:09, 12.59s/it] 28%|██▊       | 3645/12825 [12:59:45<32:06:21, 12.59s/it] 28%|██▊       | 3646/12825 [12:59:58<32:04:36, 12.58s/it] 28%|██▊       | 3647/12825 [13:00:10<32:05:07, 12.59s/it] 28%|██▊       | 3648/12825 [13:00:23<32:04:54, 12.59s/it] 28%|██▊       | 3649/12825 [13:00:36<32:02:53, 12.57s/it] 28%|██▊       | 3650/12825 [13:00:48<32:00:48, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120231.92lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103389.75lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3525] due to args.save_total_limit
 28%|██▊       | 3651/12825 [13:01:01<32:18:33, 12.68s/it] 28%|██▊       | 3652/12825 [13:01:14<32:13:29, 12.65s/it] 28%|██▊       | 3653/12825 [13:01:26<32:10:53, 12.63s/it] 28%|██▊       | 3654/12825 [13:01:39<32:08:52, 12.62s/it] 28%|██▊       | 3655/12825 [13:01:51<32:08:19, 12.62s/it] 29%|██▊       | 3656/12825 [13:02:04<32:07:36, 12.61s/it] 29%|██▊       | 3657/12825 [13:02:17<32:05:57, 12.60s/it] 29%|██▊       | 3658/12825 [13:02:29<32:05:59, 12.61s/it] 29%|██▊       | 3659/12825 [13:02:51<38:53:57, 15.28s/it] 29%|██▊       | 3660/12825 [13:03:03<36:50:33, 14.47s/it] 29%|██▊       | 3661/12825 [13:03:16<35:25:15, 13.91s/it] 29%|██▊       | 3662/12825 [13:03:29<34:24:43, 13.52s/it] 29%|██▊       | 3663/12825 [13:03:41<33:40:21, 13.23s/it] 29%|██▊       | 3664/12825 [13:03:54<33:10:01, 13.03s/it] 29%|██▊       | 3665/12825 [13:04:06<32:51:12, 12.91s/it] 29%|██▊       | 3666/12825 [13:04:19<32:34:54, 12.81s/it] 29%|██▊       | 3667/12825 [13:04:31<32:24:12, 12.74s/it] 29%|██▊       | 3668/12825 [13:04:44<32:17:20, 12.69s/it] 29%|██▊       | 3669/12825 [13:04:57<32:10:42, 12.65s/it] 29%|██▊       | 3670/12825 [13:05:09<32:07:40, 12.63s/it] 29%|██▊       | 3671/12825 [13:05:22<32:12:51, 12.67s/it] 29%|██▊       | 3672/12825 [13:05:34<32:06:38, 12.63s/it] 29%|██▊       | 3673/12825 [13:05:47<32:04:12, 12.61s/it] 29%|██▊       | 3674/12825 [13:06:00<32:02:14, 12.60s/it] 29%|██▊       | 3675/12825 [13:06:12<31:59:26, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120176.68lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103435.55lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3625] due to args.save_total_limit
 29%|██▊       | 3676/12825 [13:06:25<32:14:05, 12.68s/it] 29%|██▊       | 3677/12825 [13:06:38<32:09:12, 12.65s/it] 29%|██▊       | 3678/12825 [13:06:50<32:04:47, 12.63s/it] 29%|██▊       | 3679/12825 [13:07:03<32:02:49, 12.61s/it] 29%|██▊       | 3680/12825 [13:07:15<31:59:17, 12.59s/it] 29%|██▊       | 3681/12825 [13:07:28<31:58:37, 12.59s/it] 29%|██▊       | 3682/12825 [13:07:41<31:57:05, 12.58s/it] 29%|██▊       | 3683/12825 [13:07:53<31:57:47, 12.59s/it] 29%|██▊       | 3684/12825 [13:08:06<31:57:46, 12.59s/it] 29%|██▊       | 3685/12825 [13:08:18<31:56:32, 12.58s/it] 29%|██▊       | 3686/12825 [13:08:31<31:56:00, 12.58s/it] 29%|██▊       | 3687/12825 [13:08:43<31:55:21, 12.58s/it] 29%|██▉       | 3688/12825 [13:08:56<31:54:39, 12.57s/it] 29%|██▉       | 3689/12825 [13:09:09<31:54:58, 12.58s/it] 29%|██▉       | 3690/12825 [13:09:21<31:54:01, 12.57s/it] 29%|██▉       | 3691/12825 [13:09:42<38:17:04, 15.09s/it] 29%|██▉       | 3692/12825 [13:09:55<36:21:31, 14.33s/it] 29%|██▉       | 3693/12825 [13:10:07<35:02:24, 13.81s/it] 29%|██▉       | 3694/12825 [13:10:20<34:05:54, 13.44s/it] 29%|██▉       | 3695/12825 [13:10:32<33:26:12, 13.18s/it] 29%|██▉       | 3696/12825 [13:10:45<32:58:53, 13.01s/it] 29%|██▉       | 3697/12825 [13:10:58<32:38:37, 12.87s/it] 29%|██▉       | 3698/12825 [13:11:10<32:24:35, 12.78s/it] 29%|██▉       | 3699/12825 [13:11:23<32:15:02, 12.72s/it] 29%|██▉       | 3700/12825 [13:11:35<32:08:33, 12.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120289.78lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103526.80lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3675] due to args.save_total_limit
 29%|██▉       | 3701/12825 [13:11:48<32:21:05, 12.76s/it] 29%|██▉       | 3702/12825 [13:12:01<32:11:49, 12.71s/it] 29%|██▉       | 3703/12825 [13:12:13<32:05:32, 12.67s/it] 29%|██▉       | 3704/12825 [13:12:26<32:00:40, 12.63s/it] 29%|██▉       | 3705/12825 [13:12:39<31:59:22, 12.63s/it] 29%|██▉       | 3706/12825 [13:12:51<31:57:07, 12.61s/it] 29%|██▉       | 3707/12825 [13:13:04<31:55:57, 12.61s/it] 29%|██▉       | 3708/12825 [13:13:16<31:54:31, 12.60s/it] 29%|██▉       | 3709/12825 [13:13:29<31:52:50, 12.59s/it] 29%|██▉       | 3710/12825 [13:13:41<31:51:28, 12.58s/it] 29%|██▉       | 3711/12825 [13:13:54<31:49:56, 12.57s/it] 29%|██▉       | 3712/12825 [13:14:07<31:48:25, 12.57s/it] 29%|██▉       | 3713/12825 [13:14:19<31:48:55, 12.57s/it] 29%|██▉       | 3714/12825 [13:14:32<31:50:42, 12.58s/it] 29%|██▉       | 3715/12825 [13:14:44<31:50:14, 12.58s/it] 29%|██▉       | 3716/12825 [13:14:57<31:47:02, 12.56s/it] 29%|██▉       | 3717/12825 [13:15:09<31:47:43, 12.57s/it] 29%|██▉       | 3718/12825 [13:15:22<31:47:55, 12.57s/it] 29%|██▉       | 3719/12825 [13:15:35<31:49:55, 12.58s/it] 29%|██▉       | 3720/12825 [13:15:47<31:48:44, 12.58s/it] 29%|██▉       | 3721/12825 [13:16:00<31:50:05, 12.59s/it] 29%|██▉       | 3722/12825 [13:16:12<31:49:41, 12.59s/it] 29%|██▉       | 3723/12825 [13:16:25<31:50:37, 12.59s/it] 29%|██▉       | 3724/12825 [13:16:46<37:51:36, 14.98s/it] 29%|██▉       | 3725/12825 [13:16:58<36:04:22, 14.27s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120259.12lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103523.77lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3725
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3725/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3725/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3700] due to args.save_total_limit
 29%|██▉       | 3726/12825 [13:17:11<35:01:43, 13.86s/it] 29%|██▉       | 3727/12825 [13:17:24<34:04:37, 13.48s/it] 29%|██▉       | 3728/12825 [13:17:36<33:24:08, 13.22s/it] 29%|██▉       | 3729/12825 [13:17:49<32:56:46, 13.04s/it] 29%|██▉       | 3730/12825 [13:18:02<32:38:40, 12.92s/it] 29%|██▉       | 3731/12825 [13:18:14<32:23:15, 12.82s/it] 29%|██▉       | 3732/12825 [13:18:27<32:13:12, 12.76s/it] 29%|██▉       | 3733/12825 [13:18:39<32:06:24, 12.71s/it] 29%|██▉       | 3734/12825 [13:18:52<32:02:02, 12.69s/it] 29%|██▉       | 3735/12825 [13:19:05<31:57:09, 12.65s/it] 29%|██▉       | 3736/12825 [13:19:17<31:54:21, 12.64s/it] 29%|██▉       | 3737/12825 [13:19:30<31:52:50, 12.63s/it] 29%|██▉       | 3738/12825 [13:19:42<31:51:12, 12.62s/it] 29%|██▉       | 3739/12825 [13:19:55<31:50:40, 12.62s/it] 29%|██▉       | 3740/12825 [13:20:08<31:51:03, 12.62s/it] 29%|██▉       | 3741/12825 [13:20:20<31:49:44, 12.61s/it] 29%|██▉       | 3742/12825 [13:20:33<31:49:38, 12.61s/it] 29%|██▉       | 3743/12825 [13:20:45<31:47:58, 12.60s/it] 29%|██▉       | 3744/12825 [13:20:58<31:47:30, 12.60s/it] 29%|██▉       | 3745/12825 [13:21:11<31:47:11, 12.60s/it] 29%|██▉       | 3746/12825 [13:21:23<31:44:33, 12.59s/it] 29%|██▉       | 3747/12825 [13:21:36<31:43:39, 12.58s/it] 29%|██▉       | 3748/12825 [13:21:48<31:41:21, 12.57s/it] 29%|██▉       | 3749/12825 [13:22:01<31:40:57, 12.57s/it] 29%|██▉       | 3750/12825 [13:22:13<31:40:26, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120340.01lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103474.49lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3750
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3750/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3750/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3725] due to args.save_total_limit
 29%|██▉       | 3751/12825 [13:22:26<31:55:50, 12.67s/it] 29%|██▉       | 3752/12825 [13:22:39<31:51:35, 12.64s/it] 29%|██▉       | 3753/12825 [13:22:51<31:48:55, 12.63s/it] 29%|██▉       | 3754/12825 [13:23:04<31:47:49, 12.62s/it] 29%|██▉       | 3755/12825 [13:23:17<31:46:01, 12.61s/it] 29%|██▉       | 3756/12825 [13:23:37<37:51:07, 15.03s/it] 29%|██▉       | 3757/12825 [13:23:50<35:59:41, 14.29s/it] 29%|██▉       | 3758/12825 [13:24:02<34:41:18, 13.77s/it] 29%|██▉       | 3759/12825 [13:24:15<33:46:49, 13.41s/it] 29%|██▉       | 3760/12825 [13:24:28<33:08:56, 13.16s/it] 29%|██▉       | 3761/12825 [13:24:40<32:42:21, 12.99s/it] 29%|██▉       | 3762/12825 [13:24:53<32:22:33, 12.86s/it] 29%|██▉       | 3763/12825 [13:25:05<32:11:07, 12.79s/it] 29%|██▉       | 3764/12825 [13:25:18<32:02:09, 12.73s/it] 29%|██▉       | 3765/12825 [13:25:31<31:56:43, 12.69s/it] 29%|██▉       | 3766/12825 [13:25:43<31:51:54, 12.66s/it] 29%|██▉       | 3767/12825 [13:25:56<31:46:51, 12.63s/it] 29%|██▉       | 3768/12825 [13:26:08<31:45:30, 12.62s/it] 29%|██▉       | 3769/12825 [13:26:21<31:44:18, 12.62s/it] 29%|██▉       | 3770/12825 [13:26:34<31:43:23, 12.61s/it] 29%|██▉       | 3771/12825 [13:26:46<31:43:08, 12.61s/it] 29%|██▉       | 3772/12825 [13:26:59<31:41:46, 12.60s/it] 29%|██▉       | 3773/12825 [13:27:11<31:40:50, 12.60s/it] 29%|██▉       | 3774/12825 [13:27:24<31:40:30, 12.60s/it] 29%|██▉       | 3775/12825 [13:27:37<31:40:38, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120219.80lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103501.82lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3775
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3775/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3775/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3650] due to args.save_total_limit
 29%|██▉       | 3776/12825 [13:27:49<31:54:12, 12.69s/it] 29%|██▉       | 3777/12825 [13:28:02<31:48:53, 12.66s/it] 29%|██▉       | 3778/12825 [13:28:15<31:45:11, 12.64s/it] 29%|██▉       | 3779/12825 [13:28:27<31:42:45, 12.62s/it] 29%|██▉       | 3780/12825 [13:28:40<31:40:48, 12.61s/it] 29%|██▉       | 3781/12825 [13:28:52<31:40:45, 12.61s/it] 29%|██▉       | 3782/12825 [13:29:05<31:39:37, 12.60s/it] 29%|██▉       | 3783/12825 [13:29:18<31:37:56, 12.59s/it] 30%|██▉       | 3784/12825 [13:29:30<31:37:44, 12.59s/it] 30%|██▉       | 3785/12825 [13:29:43<31:37:34, 12.59s/it] 30%|██▉       | 3786/12825 [13:29:55<31:36:15, 12.59s/it] 30%|██▉       | 3787/12825 [13:30:08<31:34:48, 12.58s/it] 30%|██▉       | 3788/12825 [13:30:28<37:27:38, 14.92s/it] 30%|██▉       | 3789/12825 [13:30:41<35:43:07, 14.23s/it] 30%|██▉       | 3790/12825 [13:30:53<34:29:25, 13.74s/it] 30%|██▉       | 3791/12825 [13:31:06<33:37:08, 13.40s/it] 30%|██▉       | 3792/12825 [13:31:19<33:01:05, 13.16s/it] 30%|██▉       | 3793/12825 [13:31:31<32:34:57, 12.99s/it] 30%|██▉       | 3794/12825 [13:31:44<32:17:07, 12.87s/it] 30%|██▉       | 3795/12825 [13:31:56<32:01:44, 12.77s/it] 30%|██▉       | 3796/12825 [13:32:09<31:55:03, 12.73s/it] 30%|██▉       | 3797/12825 [13:32:22<31:48:57, 12.69s/it] 30%|██▉       | 3798/12825 [13:32:34<31:43:51, 12.65s/it] 30%|██▉       | 3799/12825 [13:32:47<31:39:38, 12.63s/it] 30%|██▉       | 3800/12825 [13:32:59<31:36:47, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120200.79lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103497.47lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3800
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3800/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3800/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3750] due to args.save_total_limit
 30%|██▉       | 3801/12825 [13:33:12<31:59:13, 12.76s/it] 30%|██▉       | 3802/12825 [13:33:25<31:50:28, 12.70s/it] 30%|██▉       | 3803/12825 [13:33:38<31:45:16, 12.67s/it] 30%|██▉       | 3804/12825 [13:33:50<31:40:32, 12.64s/it] 30%|██▉       | 3805/12825 [13:34:03<31:38:52, 12.63s/it] 30%|██▉       | 3806/12825 [13:34:15<31:36:25, 12.62s/it] 30%|██▉       | 3807/12825 [13:34:28<31:34:50, 12.61s/it] 30%|██▉       | 3808/12825 [13:34:41<31:34:39, 12.61s/it] 30%|██▉       | 3809/12825 [13:34:53<31:33:22, 12.60s/it] 30%|██▉       | 3810/12825 [13:35:06<31:33:23, 12.60s/it] 30%|██▉       | 3811/12825 [13:35:18<31:32:51, 12.60s/it] 30%|██▉       | 3812/12825 [13:35:31<31:33:37, 12.61s/it] 30%|██▉       | 3813/12825 [13:35:43<31:31:44, 12.59s/it] 30%|██▉       | 3814/12825 [13:35:56<31:30:57, 12.59s/it] 30%|██▉       | 3815/12825 [13:36:09<31:30:10, 12.59s/it] 30%|██▉       | 3816/12825 [13:36:21<31:32:27, 12.60s/it] 30%|██▉       | 3817/12825 [13:36:34<31:29:56, 12.59s/it] 30%|██▉       | 3818/12825 [13:36:46<31:29:45, 12.59s/it] 30%|██▉       | 3819/12825 [13:36:59<31:27:49, 12.58s/it] 30%|██▉       | 3820/12825 [13:37:12<31:28:11, 12.58s/it] 30%|██▉       | 3821/12825 [13:37:32<37:41:38, 15.07s/it] 30%|██▉       | 3822/12825 [13:37:45<35:50:28, 14.33s/it] 30%|██▉       | 3823/12825 [13:37:58<34:32:27, 13.81s/it] 30%|██▉       | 3824/12825 [13:38:10<33:35:39, 13.44s/it] 30%|██▉       | 3825/12825 [13:38:23<32:57:47, 13.19s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120150.16lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103421.67lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3825
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3825/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3825/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3775] due to args.save_total_limit
 30%|██▉       | 3826/12825 [13:38:36<32:45:41, 13.11s/it] 30%|██▉       | 3827/12825 [13:38:48<32:21:12, 12.94s/it] 30%|██▉       | 3828/12825 [13:39:01<32:05:11, 12.84s/it] 30%|██▉       | 3829/12825 [13:39:14<31:53:47, 12.76s/it] 30%|██▉       | 3830/12825 [13:39:26<31:49:37, 12.74s/it] 30%|██▉       | 3831/12825 [13:39:39<31:44:00, 12.70s/it] 30%|██▉       | 3832/12825 [13:39:51<31:37:51, 12.66s/it] 30%|██▉       | 3833/12825 [13:40:04<31:34:20, 12.64s/it] 30%|██▉       | 3834/12825 [13:40:17<31:31:04, 12.62s/it] 30%|██▉       | 3835/12825 [13:40:29<31:31:14, 12.62s/it] 30%|██▉       | 3836/12825 [13:40:42<31:29:52, 12.61s/it] 30%|██▉       | 3837/12825 [13:40:54<31:28:39, 12.61s/it] 30%|██▉       | 3838/12825 [13:41:07<31:27:16, 12.60s/it] 30%|██▉       | 3839/12825 [13:41:20<31:26:32, 12.60s/it] 30%|██▉       | 3840/12825 [13:41:32<31:26:00, 12.59s/it] 30%|██▉       | 3841/12825 [13:41:45<31:24:42, 12.59s/it] 30%|██▉       | 3842/12825 [13:41:57<31:23:06, 12.58s/it] 30%|██▉       | 3843/12825 [13:42:10<31:24:38, 12.59s/it] 30%|██▉       | 3844/12825 [13:42:22<31:24:44, 12.59s/it] 30%|██▉       | 3845/12825 [13:42:35<31:24:36, 12.59s/it] 30%|██▉       | 3846/12825 [13:42:48<31:35:15, 12.66s/it] 30%|██▉       | 3847/12825 [13:43:00<31:29:25, 12.63s/it] 30%|███       | 3848/12825 [13:43:13<31:26:18, 12.61s/it] 30%|███       | 3849/12825 [13:43:26<31:25:45, 12.61s/it] 30%|███       | 3850/12825 [13:43:38<31:23:34, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120151.56lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103431.58lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3850
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3850/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3850/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3825] due to args.save_total_limit
 30%|███       | 3851/12825 [13:43:51<31:41:34, 12.71s/it] 30%|███       | 3852/12825 [13:44:04<31:34:47, 12.67s/it] 30%|███       | 3853/12825 [13:44:24<37:13:25, 14.94s/it] 30%|███       | 3854/12825 [13:44:36<35:26:14, 14.22s/it] 30%|███       | 3855/12825 [13:44:49<34:12:50, 13.73s/it] 30%|███       | 3856/12825 [13:45:02<33:20:09, 13.38s/it] 30%|███       | 3857/12825 [13:45:14<32:44:21, 13.14s/it] 30%|███       | 3858/12825 [13:45:27<32:17:52, 12.97s/it] 30%|███       | 3859/12825 [13:45:39<31:59:32, 12.85s/it] 30%|███       | 3860/12825 [13:45:52<31:47:45, 12.77s/it] 30%|███       | 3861/12825 [13:46:04<31:39:12, 12.71s/it] 30%|███       | 3862/12825 [13:46:17<31:31:30, 12.66s/it] 30%|███       | 3863/12825 [13:46:30<31:27:02, 12.63s/it] 30%|███       | 3864/12825 [13:46:42<31:25:00, 12.62s/it] 30%|███       | 3865/12825 [13:46:55<31:22:21, 12.61s/it] 30%|███       | 3866/12825 [13:47:07<31:20:41, 12.60s/it] 30%|███       | 3867/12825 [13:47:20<31:20:31, 12.60s/it] 30%|███       | 3868/12825 [13:47:33<31:20:56, 12.60s/it] 30%|███       | 3869/12825 [13:47:45<31:18:16, 12.58s/it] 30%|███       | 3870/12825 [13:47:58<31:19:25, 12.59s/it] 30%|███       | 3871/12825 [13:48:10<31:20:43, 12.60s/it] 30%|███       | 3872/12825 [13:48:23<31:19:21, 12.59s/it] 30%|███       | 3873/12825 [13:48:35<31:17:05, 12.58s/it] 30%|███       | 3874/12825 [13:48:48<31:16:32, 12.58s/it] 30%|███       | 3875/12825 [13:49:01<31:16:09, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120187.77lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103424.97lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3875
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3875/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3875/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3850] due to args.save_total_limit
 30%|███       | 3876/12825 [13:49:14<31:41:24, 12.75s/it] 30%|███       | 3877/12825 [13:49:26<31:32:27, 12.69s/it] 30%|███       | 3878/12825 [13:49:39<31:27:20, 12.66s/it] 30%|███       | 3879/12825 [13:49:51<31:22:09, 12.62s/it] 30%|███       | 3880/12825 [13:50:04<31:17:57, 12.60s/it] 30%|███       | 3881/12825 [13:50:17<31:17:17, 12.59s/it] 30%|███       | 3882/12825 [13:50:29<31:15:21, 12.58s/it] 30%|███       | 3883/12825 [13:50:42<31:14:04, 12.57s/it] 30%|███       | 3884/12825 [13:50:54<31:14:50, 12.58s/it] 30%|███       | 3885/12825 [13:51:14<36:49:50, 14.83s/it] 30%|███       | 3886/12825 [13:51:27<35:08:41, 14.15s/it] 30%|███       | 3887/12825 [13:51:39<33:56:48, 13.67s/it] 30%|███       | 3888/12825 [13:51:52<33:06:38, 13.34s/it] 30%|███       | 3889/12825 [13:52:05<32:29:03, 13.09s/it] 30%|███       | 3890/12825 [13:52:17<32:04:18, 12.92s/it] 30%|███       | 3891/12825 [13:52:30<31:47:51, 12.81s/it] 30%|███       | 3892/12825 [13:52:42<31:35:41, 12.73s/it] 30%|███       | 3893/12825 [13:52:55<31:28:35, 12.69s/it] 30%|███       | 3894/12825 [13:53:07<31:24:05, 12.66s/it] 30%|███       | 3895/12825 [13:53:20<31:19:17, 12.63s/it] 30%|███       | 3896/12825 [13:53:32<31:15:31, 12.60s/it] 30%|███       | 3897/12825 [13:53:45<31:14:01, 12.59s/it] 30%|███       | 3898/12825 [13:53:58<31:16:33, 12.61s/it] 30%|███       | 3899/12825 [13:54:10<31:16:54, 12.62s/it] 30%|███       | 3900/12825 [13:54:23<31:14:33, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120125.94lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103446.51lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3900
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3900/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3900/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3875] due to args.save_total_limit
 30%|███       | 3901/12825 [13:54:36<31:32:43, 12.73s/it] 30%|███       | 3902/12825 [13:54:48<31:24:43, 12.67s/it] 30%|███       | 3903/12825 [13:55:01<31:19:21, 12.64s/it] 30%|███       | 3904/12825 [13:55:14<31:15:46, 12.62s/it] 30%|███       | 3905/12825 [13:55:26<31:14:05, 12.61s/it] 30%|███       | 3906/12825 [13:55:39<31:11:25, 12.59s/it] 30%|███       | 3907/12825 [13:55:51<31:09:22, 12.58s/it] 30%|███       | 3908/12825 [13:56:04<31:07:35, 12.57s/it] 30%|███       | 3909/12825 [13:56:16<31:06:24, 12.56s/it] 30%|███       | 3910/12825 [13:56:29<31:06:16, 12.56s/it] 30%|███       | 3911/12825 [13:56:41<31:06:46, 12.57s/it] 31%|███       | 3912/12825 [13:56:54<31:06:14, 12.56s/it] 31%|███       | 3913/12825 [13:57:07<31:05:19, 12.56s/it] 31%|███       | 3914/12825 [13:57:19<31:04:58, 12.56s/it] 31%|███       | 3915/12825 [13:57:32<31:06:21, 12.57s/it] 31%|███       | 3916/12825 [13:57:44<31:04:22, 12.56s/it] 31%|███       | 3917/12825 [13:57:57<31:05:39, 12.57s/it] 31%|███       | 3918/12825 [13:58:17<37:04:20, 14.98s/it] 31%|███       | 3919/12825 [13:58:30<35:16:59, 14.26s/it] 31%|███       | 3920/12825 [13:58:43<34:00:32, 13.75s/it] 31%|███       | 3921/12825 [13:58:55<33:06:02, 13.38s/it] 31%|███       | 3922/12825 [13:59:08<32:27:56, 13.13s/it] 31%|███       | 3923/12825 [13:59:20<32:01:57, 12.95s/it] 31%|███       | 3924/12825 [13:59:33<31:44:23, 12.84s/it] 31%|███       | 3925/12825 [13:59:45<31:30:00, 12.74s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120161.12lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 102711.13lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3925
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3925/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3925/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3900] due to args.save_total_limit
 31%|███       | 3926/12825 [13:59:58<31:38:02, 12.80s/it] 31%|███       | 3927/12825 [14:00:11<31:26:46, 12.72s/it] 31%|███       | 3928/12825 [14:00:23<31:21:42, 12.69s/it] 31%|███       | 3929/12825 [14:00:36<31:17:12, 12.66s/it] 31%|███       | 3930/12825 [14:00:48<31:11:20, 12.62s/it] 31%|███       | 3931/12825 [14:01:01<31:07:53, 12.60s/it] 31%|███       | 3932/12825 [14:01:14<31:05:30, 12.59s/it] 31%|███       | 3933/12825 [14:01:26<31:03:34, 12.57s/it] 31%|███       | 3934/12825 [14:01:39<31:02:48, 12.57s/it] 31%|███       | 3935/12825 [14:01:51<31:03:15, 12.58s/it] 31%|███       | 3936/12825 [14:02:04<31:02:32, 12.57s/it] 31%|███       | 3937/12825 [14:02:16<31:02:06, 12.57s/it] 31%|███       | 3938/12825 [14:02:29<31:02:56, 12.58s/it] 31%|███       | 3939/12825 [14:02:42<31:03:14, 12.58s/it] 31%|███       | 3940/12825 [14:02:54<31:04:30, 12.59s/it] 31%|███       | 3941/12825 [14:03:07<31:04:15, 12.59s/it] 31%|███       | 3942/12825 [14:03:19<31:03:18, 12.59s/it] 31%|███       | 3943/12825 [14:03:32<31:01:25, 12.57s/it] 31%|███       | 3944/12825 [14:03:44<31:00:35, 12.57s/it] 31%|███       | 3945/12825 [14:03:57<30:59:55, 12.57s/it] 31%|███       | 3946/12825 [14:04:10<30:59:56, 12.57s/it] 31%|███       | 3947/12825 [14:04:22<30:59:27, 12.57s/it] 31%|███       | 3948/12825 [14:04:35<30:59:31, 12.57s/it] 31%|███       | 3949/12825 [14:04:47<31:00:16, 12.58s/it] 31%|███       | 3950/12825 [14:05:08<36:57:42, 14.99s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120298.21lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103487.63lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3950
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3950/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3950/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3925] due to args.save_total_limit
 31%|███       | 3951/12825 [14:05:21<35:24:49, 14.37s/it] 31%|███       | 3952/12825 [14:05:33<34:04:50, 13.83s/it] 31%|███       | 3953/12825 [14:05:46<33:09:31, 13.45s/it] 31%|███       | 3954/12825 [14:05:59<32:31:46, 13.20s/it] 31%|███       | 3955/12825 [14:06:11<32:04:43, 13.02s/it] 31%|███       | 3956/12825 [14:06:24<31:43:56, 12.88s/it] 31%|███       | 3957/12825 [14:06:36<31:30:10, 12.79s/it] 31%|███       | 3958/12825 [14:06:49<31:21:58, 12.73s/it] 31%|███       | 3959/12825 [14:07:02<31:17:24, 12.71s/it] 31%|███       | 3960/12825 [14:07:14<31:10:51, 12.66s/it] 31%|███       | 3961/12825 [14:07:27<31:07:43, 12.64s/it] 31%|███       | 3962/12825 [14:07:39<31:07:52, 12.65s/it] 31%|███       | 3963/12825 [14:07:52<31:05:50, 12.63s/it] 31%|███       | 3964/12825 [14:08:05<31:04:44, 12.63s/it] 31%|███       | 3965/12825 [14:08:17<31:04:09, 12.62s/it] 31%|███       | 3966/12825 [14:08:30<31:02:46, 12.62s/it] 31%|███       | 3967/12825 [14:08:42<31:00:53, 12.60s/it] 31%|███       | 3968/12825 [14:08:55<31:01:19, 12.61s/it] 31%|███       | 3969/12825 [14:09:08<30:59:44, 12.60s/it] 31%|███       | 3970/12825 [14:09:20<30:58:20, 12.59s/it] 31%|███       | 3971/12825 [14:09:33<30:59:54, 12.60s/it] 31%|███       | 3972/12825 [14:09:45<30:59:16, 12.60s/it] 31%|███       | 3973/12825 [14:09:58<30:58:26, 12.60s/it] 31%|███       | 3974/12825 [14:10:11<31:00:03, 12.61s/it] 31%|███       | 3975/12825 [14:10:23<30:58:39, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120253.12lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103538.25lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3975
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3975/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3975/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-3975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3950] due to args.save_total_limit
 31%|███       | 3976/12825 [14:10:36<31:11:38, 12.69s/it] 31%|███       | 3977/12825 [14:10:49<31:07:51, 12.67s/it] 31%|███       | 3978/12825 [14:11:01<31:03:44, 12.64s/it] 31%|███       | 3979/12825 [14:11:14<30:59:45, 12.61s/it] 31%|███       | 3980/12825 [14:11:26<30:58:41, 12.61s/it] 31%|███       | 3981/12825 [14:11:39<30:58:10, 12.61s/it] 31%|███       | 3982/12825 [14:11:52<30:56:49, 12.60s/it] 31%|███       | 3983/12825 [14:12:12<36:47:47, 14.98s/it] 31%|███       | 3984/12825 [14:12:25<35:00:25, 14.25s/it] 31%|███       | 3985/12825 [14:12:37<33:44:36, 13.74s/it] 31%|███       | 3986/12825 [14:12:50<32:52:39, 13.39s/it] 31%|███       | 3987/12825 [14:13:02<32:17:26, 13.15s/it] 31%|███       | 3988/12825 [14:13:15<31:52:43, 12.99s/it] 31%|███       | 3989/12825 [14:13:28<31:35:57, 12.87s/it] 31%|███       | 3990/12825 [14:13:40<31:22:32, 12.78s/it] 31%|███       | 3991/12825 [14:13:53<31:12:06, 12.72s/it] 31%|███       | 3992/12825 [14:14:05<31:05:09, 12.67s/it] 31%|███       | 3993/12825 [14:14:18<31:02:41, 12.65s/it] 31%|███       | 3994/12825 [14:14:31<30:58:36, 12.63s/it] 31%|███       | 3995/12825 [14:14:43<30:56:42, 12.62s/it] 31%|███       | 3996/12825 [14:14:56<30:55:24, 12.61s/it] 31%|███       | 3997/12825 [14:15:08<30:55:39, 12.61s/it] 31%|███       | 3998/12825 [14:15:21<30:52:57, 12.60s/it] 31%|███       | 3999/12825 [14:15:34<30:53:38, 12.60s/it] 31%|███       | 4000/12825 [14:15:46<30:52:08, 12.59s/it]                                                           31%|███       | 4000/12825 [14:15:46<30:52:08, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120091.67lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103494.73lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4000
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4000/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4000/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3975] due to args.save_total_limit
 31%|███       | 4001/12825 [14:15:59<31:05:22, 12.68s/it] 31%|███       | 4002/12825 [14:16:12<30:59:49, 12.65s/it] 31%|███       | 4003/12825 [14:16:24<30:56:13, 12.62s/it] 31%|███       | 4004/12825 [14:16:37<30:51:49, 12.60s/it] 31%|███       | 4005/12825 [14:16:49<30:50:23, 12.59s/it] 31%|███       | 4006/12825 [14:17:02<30:48:50, 12.58s/it] 31%|███       | 4007/12825 [14:17:14<30:47:54, 12.57s/it] 31%|███▏      | 4008/12825 [14:17:27<30:49:44, 12.59s/it] 31%|███▏      | 4009/12825 [14:17:40<30:48:05, 12.58s/it] 31%|███▏      | 4010/12825 [14:17:52<30:47:42, 12.58s/it] 31%|███▏      | 4011/12825 [14:18:05<30:46:44, 12.57s/it] 31%|███▏      | 4012/12825 [14:18:17<30:46:25, 12.57s/it] 31%|███▏      | 4013/12825 [14:18:30<30:48:31, 12.59s/it] 31%|███▏      | 4014/12825 [14:18:42<30:48:28, 12.59s/it] 31%|███▏      | 4015/12825 [14:19:03<36:28:08, 14.90s/it] 31%|███▏      | 4016/12825 [14:19:15<34:45:09, 14.20s/it] 31%|███▏      | 4017/12825 [14:19:28<33:33:08, 13.71s/it] 31%|███▏      | 4018/12825 [14:19:40<32:42:50, 13.37s/it] 31%|███▏      | 4019/12825 [14:19:53<32:06:27, 13.13s/it] 31%|███▏      | 4020/12825 [14:20:06<31:43:31, 12.97s/it] 31%|███▏      | 4021/12825 [14:20:18<31:27:24, 12.86s/it] 31%|███▏      | 4022/12825 [14:20:31<31:14:56, 12.78s/it] 31%|███▏      | 4023/12825 [14:20:43<31:04:00, 12.71s/it] 31%|███▏      | 4024/12825 [14:20:56<30:59:55, 12.68s/it] 31%|███▏      | 4025/12825 [14:21:09<30:54:45, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120276.74lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103542.89lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4025
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4025/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4025/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-3800] due to args.save_total_limit
 31%|███▏      | 4026/12825 [14:21:22<31:09:20, 12.75s/it] 31%|███▏      | 4027/12825 [14:21:34<31:01:50, 12.70s/it] 31%|███▏      | 4028/12825 [14:21:47<30:57:06, 12.67s/it] 31%|███▏      | 4029/12825 [14:21:59<30:51:42, 12.63s/it] 31%|███▏      | 4030/12825 [14:22:12<30:46:22, 12.60s/it] 31%|███▏      | 4031/12825 [14:22:24<30:44:13, 12.58s/it] 31%|███▏      | 4032/12825 [14:22:37<30:43:42, 12.58s/it] 31%|███▏      | 4033/12825 [14:22:49<30:43:46, 12.58s/it] 31%|███▏      | 4034/12825 [14:23:02<30:43:59, 12.59s/it] 31%|███▏      | 4035/12825 [14:23:15<30:43:18, 12.58s/it] 31%|███▏      | 4036/12825 [14:23:27<30:43:28, 12.58s/it] 31%|███▏      | 4037/12825 [14:23:40<30:41:24, 12.57s/it] 31%|███▏      | 4038/12825 [14:23:52<30:40:40, 12.57s/it] 31%|███▏      | 4039/12825 [14:24:05<30:42:11, 12.58s/it] 32%|███▏      | 4040/12825 [14:24:18<30:43:12, 12.59s/it] 32%|███▏      | 4041/12825 [14:24:30<30:43:50, 12.59s/it] 32%|███▏      | 4042/12825 [14:24:43<30:43:30, 12.59s/it] 32%|███▏      | 4043/12825 [14:24:55<30:44:16, 12.60s/it] 32%|███▏      | 4044/12825 [14:25:08<30:42:23, 12.59s/it] 32%|███▏      | 4045/12825 [14:25:20<30:39:55, 12.57s/it] 32%|███▏      | 4046/12825 [14:25:33<30:41:32, 12.59s/it] 32%|███▏      | 4047/12825 [14:25:54<36:53:52, 15.13s/it] 32%|███▏      | 4048/12825 [14:26:07<35:00:56, 14.36s/it] 32%|███▏      | 4049/12825 [14:26:19<33:41:57, 13.82s/it] 32%|███▏      | 4050/12825 [14:26:32<32:46:11, 13.44s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120071.05lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103366.82lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4050
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4050/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4050/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4000] due to args.save_total_limit
 32%|███▏      | 4051/12825 [14:26:45<32:22:36, 13.28s/it] 32%|███▏      | 4052/12825 [14:26:57<31:50:23, 13.07s/it] 32%|███▏      | 4053/12825 [14:27:10<31:28:18, 12.92s/it] 32%|███▏      | 4054/12825 [14:27:22<31:13:41, 12.82s/it] 32%|███▏      | 4055/12825 [14:27:35<31:02:15, 12.74s/it] 32%|███▏      | 4056/12825 [14:27:48<30:55:14, 12.69s/it] 32%|███▏      | 4057/12825 [14:28:00<30:49:57, 12.66s/it] 32%|███▏      | 4058/12825 [14:28:13<30:45:34, 12.63s/it] 32%|███▏      | 4059/12825 [14:28:25<30:43:50, 12.62s/it] 32%|███▏      | 4060/12825 [14:28:38<30:41:42, 12.61s/it] 32%|███▏      | 4061/12825 [14:28:50<30:37:48, 12.58s/it] 32%|███▏      | 4062/12825 [14:29:03<30:36:34, 12.57s/it] 32%|███▏      | 4063/12825 [14:29:16<30:35:22, 12.57s/it] 32%|███▏      | 4064/12825 [14:29:28<30:34:57, 12.57s/it] 32%|███▏      | 4065/12825 [14:29:41<30:34:15, 12.56s/it] 32%|███▏      | 4066/12825 [14:29:53<30:42:29, 12.62s/it] 32%|███▏      | 4067/12825 [14:30:06<30:39:53, 12.60s/it] 32%|███▏      | 4068/12825 [14:30:19<30:38:31, 12.60s/it] 32%|███▏      | 4069/12825 [14:30:31<30:36:28, 12.58s/it] 32%|███▏      | 4070/12825 [14:30:44<30:35:55, 12.58s/it] 32%|███▏      | 4071/12825 [14:30:56<30:34:12, 12.57s/it] 32%|███▏      | 4072/12825 [14:31:09<30:33:31, 12.57s/it] 32%|███▏      | 4073/12825 [14:31:21<30:34:32, 12.58s/it] 32%|███▏      | 4074/12825 [14:31:34<30:32:49, 12.57s/it] 32%|███▏      | 4075/12825 [14:31:47<30:32:50, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120263.84lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103529.83lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4075
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4075/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4075/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4050] due to args.save_total_limit
 32%|███▏      | 4076/12825 [14:31:59<30:48:21, 12.68s/it] 32%|███▏      | 4077/12825 [14:32:12<30:42:42, 12.64s/it] 32%|███▏      | 4078/12825 [14:32:25<30:38:37, 12.61s/it] 32%|███▏      | 4079/12825 [14:32:37<30:35:25, 12.59s/it] 32%|███▏      | 4080/12825 [14:32:57<36:00:25, 14.82s/it] 32%|███▏      | 4081/12825 [14:33:10<34:21:24, 14.15s/it] 32%|███▏      | 4082/12825 [14:33:22<33:13:26, 13.68s/it] 32%|███▏      | 4083/12825 [14:33:35<32:23:22, 13.34s/it] 32%|███▏      | 4084/12825 [14:33:47<31:49:06, 13.10s/it] 32%|███▏      | 4085/12825 [14:34:00<31:22:38, 12.92s/it] 32%|███▏      | 4086/12825 [14:34:12<31:06:31, 12.82s/it] 32%|███▏      | 4087/12825 [14:34:25<30:54:22, 12.73s/it] 32%|███▏      | 4088/12825 [14:34:38<30:46:50, 12.68s/it] 32%|███▏      | 4089/12825 [14:34:50<30:41:25, 12.65s/it] 32%|███▏      | 4090/12825 [14:35:03<30:38:16, 12.63s/it] 32%|███▏      | 4091/12825 [14:35:15<30:34:54, 12.61s/it] 32%|███▏      | 4092/12825 [14:35:28<30:31:16, 12.58s/it] 32%|███▏      | 4093/12825 [14:35:40<30:30:52, 12.58s/it] 32%|███▏      | 4094/12825 [14:35:53<30:30:59, 12.58s/it] 32%|███▏      | 4095/12825 [14:36:06<30:30:12, 12.58s/it] 32%|███▏      | 4096/12825 [14:36:18<30:29:07, 12.57s/it] 32%|███▏      | 4097/12825 [14:36:31<30:25:53, 12.55s/it] 32%|███▏      | 4098/12825 [14:36:43<30:25:01, 12.55s/it] 32%|███▏      | 4099/12825 [14:36:56<30:25:39, 12.55s/it] 32%|███▏      | 4100/12825 [14:37:08<30:25:14, 12.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120116.26lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103383.62lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4075] due to args.save_total_limit
 32%|███▏      | 4101/12825 [14:37:21<30:42:03, 12.67s/it] 32%|███▏      | 4102/12825 [14:37:34<30:35:40, 12.63s/it] 32%|███▏      | 4103/12825 [14:37:42<27:07:59, 11.20s/it] 32%|███▏      | 4104/12825 [14:37:42<19:35:19,  8.09s/it] 32%|███▏      | 4105/12825 [14:38:08<32:18:19, 13.34s/it] 32%|███▏      | 4106/12825 [14:38:21<31:45:00, 13.11s/it] 32%|███▏      | 4107/12825 [14:38:33<31:22:24, 12.96s/it] 32%|███▏      | 4108/12825 [14:38:46<31:07:01, 12.85s/it] 32%|███▏      | 4109/12825 [14:38:58<30:55:52, 12.78s/it] 32%|███▏      | 4110/12825 [14:39:11<30:48:32, 12.73s/it] 32%|███▏      | 4111/12825 [14:39:24<30:42:20, 12.69s/it] 32%|███▏      | 4112/12825 [14:39:44<36:20:15, 15.01s/it] 32%|███▏      | 4113/12825 [14:39:57<34:35:17, 14.29s/it] 32%|███▏      | 4114/12825 [14:40:09<33:18:48, 13.77s/it] 32%|███▏      | 4115/12825 [14:40:22<32:26:28, 13.41s/it] 32%|███▏      | 4116/12825 [14:40:34<31:49:23, 13.15s/it] 32%|███▏      | 4117/12825 [14:40:47<31:23:06, 12.98s/it] 32%|███▏      | 4118/12825 [14:40:59<31:06:32, 12.86s/it] 32%|███▏      | 4119/12825 [14:41:12<30:52:33, 12.77s/it] 32%|███▏      | 4120/12825 [14:41:25<30:44:34, 12.71s/it] 32%|███▏      | 4121/12825 [14:41:37<30:39:08, 12.68s/it] 32%|███▏      | 4122/12825 [14:41:50<30:32:52, 12.64s/it] 32%|███▏      | 4123/12825 [14:42:02<30:30:22, 12.62s/it] 32%|███▏      | 4124/12825 [14:42:15<30:28:21, 12.61s/it] 32%|███▏      | 4125/12825 [14:42:27<30:26:52, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120156.66lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103425.26lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4100] due to args.save_total_limit
 32%|███▏      | 4126/12825 [14:42:40<30:42:11, 12.71s/it] 32%|███▏      | 4127/12825 [14:42:53<30:38:54, 12.69s/it] 32%|███▏      | 4128/12825 [14:43:06<30:35:59, 12.67s/it] 32%|███▏      | 4129/12825 [14:43:18<30:32:12, 12.64s/it] 32%|███▏      | 4130/12825 [14:43:31<30:30:33, 12.63s/it] 32%|███▏      | 4131/12825 [14:43:44<30:31:03, 12.64s/it] 32%|███▏      | 4132/12825 [14:43:56<30:31:58, 12.64s/it] 32%|███▏      | 4133/12825 [14:44:09<30:30:00, 12.63s/it] 32%|███▏      | 4134/12825 [14:44:21<30:29:47, 12.63s/it] 32%|███▏      | 4135/12825 [14:44:34<30:36:22, 12.68s/it] 32%|███▏      | 4136/12825 [14:44:47<30:34:21, 12.67s/it] 32%|███▏      | 4137/12825 [14:44:59<30:30:29, 12.64s/it] 32%|███▏      | 4138/12825 [14:45:12<30:28:44, 12.63s/it] 32%|███▏      | 4139/12825 [14:45:25<30:27:29, 12.62s/it] 32%|███▏      | 4140/12825 [14:45:37<30:28:40, 12.63s/it] 32%|███▏      | 4141/12825 [14:45:50<30:29:47, 12.64s/it] 32%|███▏      | 4142/12825 [14:46:03<30:27:03, 12.63s/it] 32%|███▏      | 4143/12825 [14:46:15<30:24:05, 12.61s/it] 32%|███▏      | 4144/12825 [14:46:28<30:22:10, 12.59s/it] 32%|███▏      | 4145/12825 [14:46:48<36:02:28, 14.95s/it] 32%|███▏      | 4146/12825 [14:47:01<34:22:27, 14.26s/it] 32%|███▏      | 4147/12825 [14:47:13<33:10:54, 13.77s/it] 32%|███▏      | 4148/12825 [14:47:26<32:19:03, 13.41s/it] 32%|███▏      | 4149/12825 [14:47:39<31:41:54, 13.15s/it] 32%|███▏      | 4150/12825 [14:47:51<31:19:47, 13.00s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120169.92lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103538.73lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4025] due to args.save_total_limit
 32%|███▏      | 4151/12825 [14:48:04<31:18:38, 13.00s/it] 32%|███▏      | 4152/12825 [14:48:17<31:01:48, 12.88s/it] 32%|███▏      | 4153/12825 [14:48:29<30:50:46, 12.81s/it] 32%|███▏      | 4154/12825 [14:48:42<30:48:13, 12.79s/it] 32%|███▏      | 4155/12825 [14:48:55<30:39:56, 12.73s/it] 32%|███▏      | 4156/12825 [14:49:07<30:34:31, 12.70s/it] 32%|███▏      | 4157/12825 [14:49:20<30:29:49, 12.67s/it] 32%|███▏      | 4158/12825 [14:49:33<30:26:38, 12.65s/it] 32%|███▏      | 4159/12825 [14:49:45<30:25:36, 12.64s/it] 32%|███▏      | 4160/12825 [14:49:58<30:22:32, 12.62s/it] 32%|███▏      | 4161/12825 [14:50:10<30:19:54, 12.60s/it] 32%|███▏      | 4162/12825 [14:50:23<30:17:58, 12.59s/it] 32%|███▏      | 4163/12825 [14:50:35<30:18:15, 12.59s/it] 32%|███▏      | 4164/12825 [14:50:48<30:19:14, 12.60s/it] 32%|███▏      | 4165/12825 [14:51:01<30:18:12, 12.60s/it] 32%|███▏      | 4166/12825 [14:51:13<30:17:17, 12.59s/it] 32%|███▏      | 4167/12825 [14:51:26<30:14:50, 12.58s/it] 32%|███▏      | 4168/12825 [14:51:38<30:13:43, 12.57s/it] 33%|███▎      | 4169/12825 [14:51:51<30:15:22, 12.58s/it] 33%|███▎      | 4170/12825 [14:52:04<30:16:28, 12.59s/it] 33%|███▎      | 4171/12825 [14:52:16<30:14:56, 12.58s/it] 33%|███▎      | 4172/12825 [14:52:29<30:15:37, 12.59s/it] 33%|███▎      | 4173/12825 [14:52:41<30:17:27, 12.60s/it] 33%|███▎      | 4174/12825 [14:52:54<30:15:38, 12.59s/it] 33%|███▎      | 4175/12825 [14:53:07<30:14:13, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120291.95lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103553.02lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4125] due to args.save_total_limit
 33%|███▎      | 4176/12825 [14:53:19<30:30:42, 12.70s/it] 33%|███▎      | 4177/12825 [14:53:40<36:09:44, 15.05s/it] 33%|███▎      | 4178/12825 [14:53:53<34:24:25, 14.32s/it] 33%|███▎      | 4179/12825 [14:54:05<33:08:12, 13.80s/it] 33%|███▎      | 4180/12825 [14:54:18<32:14:59, 13.43s/it] 33%|███▎      | 4181/12825 [14:54:30<31:37:57, 13.17s/it] 33%|███▎      | 4182/12825 [14:54:43<31:12:25, 13.00s/it] 33%|███▎      | 4183/12825 [14:54:56<30:53:19, 12.87s/it] 33%|███▎      | 4184/12825 [14:55:08<30:41:53, 12.79s/it] 33%|███▎      | 4185/12825 [14:55:21<30:31:10, 12.72s/it] 33%|███▎      | 4186/12825 [14:55:33<30:25:21, 12.68s/it] 33%|███▎      | 4187/12825 [14:55:46<30:21:32, 12.65s/it] 33%|███▎      | 4188/12825 [14:55:59<30:20:55, 12.65s/it] 33%|███▎      | 4189/12825 [14:56:11<30:18:26, 12.63s/it] 33%|███▎      | 4190/12825 [14:56:24<30:16:38, 12.62s/it] 33%|███▎      | 4191/12825 [14:56:36<30:14:53, 12.61s/it] 33%|███▎      | 4192/12825 [14:56:49<30:13:50, 12.61s/it] 33%|███▎      | 4193/12825 [14:57:01<30:12:27, 12.60s/it] 33%|███▎      | 4194/12825 [14:57:14<30:10:56, 12.59s/it] 33%|███▎      | 4195/12825 [14:57:27<30:10:23, 12.59s/it] 33%|███▎      | 4196/12825 [14:57:39<30:10:52, 12.59s/it] 33%|███▎      | 4197/12825 [14:57:52<30:10:39, 12.59s/it] 33%|███▎      | 4198/12825 [14:58:04<30:10:31, 12.59s/it] 33%|███▎      | 4199/12825 [14:58:17<30:09:39, 12.59s/it] 33%|███▎      | 4200/12825 [14:58:30<30:10:29, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120179.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103431.30lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4150] due to args.save_total_limit
 33%|███▎      | 4201/12825 [14:58:43<30:23:54, 12.69s/it] 33%|███▎      | 4202/12825 [14:58:55<30:18:45, 12.66s/it] 33%|███▎      | 4203/12825 [14:59:08<30:14:47, 12.63s/it] 33%|███▎      | 4204/12825 [14:59:20<30:12:55, 12.62s/it] 33%|███▎      | 4205/12825 [14:59:33<30:10:02, 12.60s/it] 33%|███▎      | 4206/12825 [14:59:45<30:09:41, 12.60s/it] 33%|███▎      | 4207/12825 [14:59:58<30:10:05, 12.60s/it] 33%|███▎      | 4208/12825 [15:00:11<30:09:18, 12.60s/it] 33%|███▎      | 4209/12825 [15:00:23<30:07:57, 12.59s/it] 33%|███▎      | 4210/12825 [15:00:44<35:42:15, 14.92s/it] 33%|███▎      | 4211/12825 [15:00:56<34:02:15, 14.23s/it] 33%|███▎      | 4212/12825 [15:01:09<32:51:28, 13.73s/it] 33%|███▎      | 4213/12825 [15:01:21<32:01:09, 13.38s/it] 33%|███▎      | 4214/12825 [15:01:34<31:27:12, 13.15s/it] 33%|███▎      | 4215/12825 [15:01:46<31:04:13, 12.99s/it] 33%|███▎      | 4216/12825 [15:01:59<30:47:04, 12.87s/it] 33%|███▎      | 4217/12825 [15:02:12<30:35:02, 12.79s/it] 33%|███▎      | 4218/12825 [15:02:24<30:27:28, 12.74s/it] 33%|███▎      | 4219/12825 [15:02:37<30:21:27, 12.70s/it] 33%|███▎      | 4220/12825 [15:02:50<30:19:06, 12.68s/it] 33%|███▎      | 4221/12825 [15:03:02<30:15:23, 12.66s/it] 33%|███▎      | 4222/12825 [15:03:15<30:12:50, 12.64s/it] 33%|███▎      | 4223/12825 [15:03:27<30:10:50, 12.63s/it] 33%|███▎      | 4224/12825 [15:03:40<30:08:08, 12.61s/it] 33%|███▎      | 4225/12825 [15:03:53<30:07:19, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120271.38lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103460.59lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4175] due to args.save_total_limit
 33%|███▎      | 4226/12825 [15:04:06<30:21:57, 12.71s/it] 33%|███▎      | 4227/12825 [15:04:18<30:16:58, 12.68s/it] 33%|███▎      | 4228/12825 [15:04:31<30:13:42, 12.66s/it] 33%|███▎      | 4229/12825 [15:04:43<30:12:24, 12.65s/it] 33%|███▎      | 4230/12825 [15:04:56<30:10:43, 12.64s/it] 33%|███▎      | 4231/12825 [15:05:09<30:08:32, 12.63s/it] 33%|███▎      | 4232/12825 [15:05:21<30:06:59, 12.62s/it] 33%|███▎      | 4233/12825 [15:05:34<30:06:07, 12.61s/it] 33%|███▎      | 4234/12825 [15:05:46<30:04:31, 12.60s/it] 33%|███▎      | 4235/12825 [15:05:59<30:03:26, 12.60s/it] 33%|███▎      | 4236/12825 [15:06:11<30:01:30, 12.58s/it] 33%|███▎      | 4237/12825 [15:06:24<29:59:47, 12.57s/it] 33%|███▎      | 4238/12825 [15:06:37<29:58:35, 12.57s/it] 33%|███▎      | 4239/12825 [15:06:49<29:57:43, 12.56s/it] 33%|███▎      | 4240/12825 [15:07:02<29:57:42, 12.56s/it] 33%|███▎      | 4241/12825 [15:07:14<29:59:29, 12.58s/it] 33%|███▎      | 4242/12825 [15:07:35<36:08:57, 15.16s/it] 33%|███▎      | 4243/12825 [15:07:48<34:17:34, 14.39s/it] 33%|███▎      | 4244/12825 [15:08:01<33:00:40, 13.85s/it] 33%|███▎      | 4245/12825 [15:08:13<32:04:55, 13.46s/it] 33%|███▎      | 4246/12825 [15:08:26<31:27:32, 13.20s/it] 33%|███▎      | 4247/12825 [15:08:38<30:58:45, 13.00s/it] 33%|███▎      | 4248/12825 [15:08:51<30:39:48, 12.87s/it] 33%|███▎      | 4249/12825 [15:09:03<30:26:18, 12.78s/it] 33%|███▎      | 4250/12825 [15:09:16<30:16:52, 12.71s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120240.73lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103434.51lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4225] due to args.save_total_limit
 33%|███▎      | 4251/12825 [15:09:29<30:25:08, 12.77s/it] 33%|███▎      | 4252/12825 [15:09:41<30:15:00, 12.70s/it] 33%|███▎      | 4253/12825 [15:09:54<30:08:48, 12.66s/it] 33%|███▎      | 4254/12825 [15:10:07<30:05:15, 12.64s/it] 33%|███▎      | 4255/12825 [15:10:19<30:03:46, 12.63s/it] 33%|███▎      | 4256/12825 [15:10:32<30:00:43, 12.61s/it] 33%|███▎      | 4257/12825 [15:10:44<29:58:49, 12.60s/it] 33%|███▎      | 4258/12825 [15:10:57<29:58:53, 12.60s/it] 33%|███▎      | 4259/12825 [15:11:10<29:58:42, 12.60s/it] 33%|███▎      | 4260/12825 [15:11:22<29:57:34, 12.59s/it] 33%|███▎      | 4261/12825 [15:11:35<29:56:03, 12.58s/it] 33%|███▎      | 4262/12825 [15:11:47<29:55:41, 12.58s/it] 33%|███▎      | 4263/12825 [15:12:00<29:54:55, 12.58s/it] 33%|███▎      | 4264/12825 [15:12:12<29:54:13, 12.57s/it] 33%|███▎      | 4265/12825 [15:12:25<29:53:48, 12.57s/it] 33%|███▎      | 4266/12825 [15:12:38<29:55:13, 12.58s/it] 33%|███▎      | 4267/12825 [15:12:50<29:54:58, 12.58s/it] 33%|███▎      | 4268/12825 [15:13:03<29:57:14, 12.60s/it] 33%|███▎      | 4269/12825 [15:13:15<29:55:19, 12.59s/it] 33%|███▎      | 4270/12825 [15:13:28<29:55:32, 12.59s/it] 33%|███▎      | 4271/12825 [15:13:41<29:54:31, 12.59s/it] 33%|███▎      | 4272/12825 [15:13:53<29:54:33, 12.59s/it] 33%|███▎      | 4273/12825 [15:14:06<29:53:45, 12.58s/it] 33%|███▎      | 4274/12825 [15:14:27<35:54:12, 15.12s/it] 33%|███▎      | 4275/12825 [15:14:39<34:04:19, 14.35s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120337.84lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103528.79lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4200] due to args.save_total_limit
 33%|███▎      | 4276/12825 [15:14:52<33:03:48, 13.92s/it] 33%|███▎      | 4277/12825 [15:15:05<32:05:46, 13.52s/it] 33%|███▎      | 4278/12825 [15:15:17<31:24:28, 13.23s/it] 33%|███▎      | 4279/12825 [15:15:30<30:55:35, 13.03s/it] 33%|███▎      | 4280/12825 [15:15:43<30:36:02, 12.89s/it] 33%|███▎      | 4281/12825 [15:15:55<30:22:44, 12.80s/it] 33%|███▎      | 4282/12825 [15:16:08<30:12:42, 12.73s/it] 33%|███▎      | 4283/12825 [15:16:20<30:05:21, 12.68s/it] 33%|███▎      | 4284/12825 [15:16:33<30:00:49, 12.65s/it] 33%|███▎      | 4285/12825 [15:16:45<29:54:57, 12.61s/it] 33%|███▎      | 4286/12825 [15:16:58<29:53:10, 12.60s/it] 33%|███▎      | 4287/12825 [15:17:10<29:51:20, 12.59s/it] 33%|███▎      | 4288/12825 [15:17:23<29:52:11, 12.60s/it] 33%|███▎      | 4289/12825 [15:17:36<29:52:20, 12.60s/it] 33%|███▎      | 4290/12825 [15:17:48<29:52:52, 12.60s/it] 33%|███▎      | 4291/12825 [15:18:01<29:50:19, 12.59s/it] 33%|███▎      | 4292/12825 [15:18:13<29:47:57, 12.57s/it] 33%|███▎      | 4293/12825 [15:18:26<29:46:50, 12.57s/it] 33%|███▎      | 4294/12825 [15:18:39<29:47:52, 12.57s/it] 33%|███▎      | 4295/12825 [15:18:51<29:48:13, 12.58s/it] 33%|███▎      | 4296/12825 [15:19:04<29:48:44, 12.58s/it] 34%|███▎      | 4297/12825 [15:19:16<29:47:23, 12.58s/it] 34%|███▎      | 4298/12825 [15:19:29<29:45:54, 12.57s/it] 34%|███▎      | 4299/12825 [15:19:41<29:47:19, 12.58s/it] 34%|███▎      | 4300/12825 [15:19:54<29:47:31, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120233.97lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103407.03lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4250] due to args.save_total_limit
 34%|███▎      | 4301/12825 [15:20:07<30:01:43, 12.68s/it] 34%|███▎      | 4302/12825 [15:20:20<29:59:00, 12.66s/it] 34%|███▎      | 4303/12825 [15:20:32<29:55:35, 12.64s/it] 34%|███▎      | 4304/12825 [15:20:45<29:50:37, 12.61s/it] 34%|███▎      | 4305/12825 [15:20:59<30:45:48, 13.00s/it] 34%|███▎      | 4306/12825 [15:21:11<30:27:38, 12.87s/it] 34%|███▎      | 4307/12825 [15:21:31<35:34:34, 15.04s/it] 34%|███▎      | 4308/12825 [15:21:44<33:49:39, 14.30s/it] 34%|███▎      | 4309/12825 [15:21:56<32:35:49, 13.78s/it] 34%|███▎      | 4310/12825 [15:22:09<31:45:10, 13.42s/it] 34%|███▎      | 4311/12825 [15:22:22<31:08:42, 13.17s/it] 34%|███▎      | 4312/12825 [15:22:34<30:43:48, 13.00s/it] 34%|███▎      | 4313/12825 [15:22:47<30:26:41, 12.88s/it] 34%|███▎      | 4314/12825 [15:22:59<30:13:04, 12.78s/it] 34%|███▎      | 4315/12825 [15:23:12<30:03:05, 12.71s/it] 34%|███▎      | 4316/12825 [15:23:24<29:57:56, 12.68s/it] 34%|███▎      | 4317/12825 [15:23:37<29:54:03, 12.65s/it] 34%|███▎      | 4318/12825 [15:23:50<29:50:59, 12.63s/it] 34%|███▎      | 4319/12825 [15:24:02<29:48:50, 12.62s/it] 34%|███▎      | 4320/12825 [15:24:15<29:45:24, 12.60s/it] 34%|███▎      | 4321/12825 [15:24:27<29:45:30, 12.60s/it] 34%|███▎      | 4322/12825 [15:24:40<29:45:08, 12.60s/it] 34%|███▎      | 4323/12825 [15:24:53<29:43:47, 12.59s/it] 34%|███▎      | 4324/12825 [15:25:05<29:41:56, 12.58s/it] 34%|███▎      | 4325/12825 [15:25:18<29:41:53, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120278.79lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103556.81lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4300] due to args.save_total_limit
 34%|███▎      | 4326/12825 [15:25:31<29:55:59, 12.68s/it] 34%|███▎      | 4327/12825 [15:25:43<29:53:56, 12.67s/it] 34%|███▎      | 4328/12825 [15:25:56<29:48:41, 12.63s/it] 34%|███▍      | 4329/12825 [15:26:08<29:45:22, 12.61s/it] 34%|███▍      | 4330/12825 [15:26:21<29:44:43, 12.61s/it] 34%|███▍      | 4331/12825 [15:26:33<29:42:50, 12.59s/it] 34%|███▍      | 4332/12825 [15:26:46<29:42:17, 12.59s/it] 34%|███▍      | 4333/12825 [15:26:59<29:42:32, 12.59s/it] 34%|███▍      | 4334/12825 [15:27:11<29:42:45, 12.60s/it] 34%|███▍      | 4335/12825 [15:27:24<29:41:23, 12.59s/it] 34%|███▍      | 4336/12825 [15:27:36<29:41:00, 12.59s/it] 34%|███▍      | 4337/12825 [15:27:49<29:41:11, 12.59s/it] 34%|███▍      | 4338/12825 [15:28:02<29:41:30, 12.59s/it] 34%|███▍      | 4339/12825 [15:28:22<35:14:47, 14.95s/it] 34%|███▍      | 4340/12825 [15:28:35<33:34:13, 14.24s/it] 34%|███▍      | 4341/12825 [15:28:47<32:23:33, 13.75s/it] 34%|███▍      | 4342/12825 [15:29:00<31:32:03, 13.38s/it] 34%|███▍      | 4343/12825 [15:29:12<30:57:07, 13.14s/it] 34%|███▍      | 4344/12825 [15:29:25<30:32:25, 12.96s/it] 34%|███▍      | 4345/12825 [15:29:37<30:14:57, 12.84s/it] 34%|███▍      | 4346/12825 [15:29:50<30:03:40, 12.76s/it] 34%|███▍      | 4347/12825 [15:30:03<29:54:36, 12.70s/it] 34%|███▍      | 4348/12825 [15:30:15<29:48:51, 12.66s/it] 34%|███▍      | 4349/12825 [15:30:28<29:45:00, 12.64s/it] 34%|███▍      | 4350/12825 [15:30:40<29:43:58, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120255.29lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103538.44lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4325] due to args.save_total_limit
 34%|███▍      | 4351/12825 [15:30:53<29:59:37, 12.74s/it] 34%|███▍      | 4352/12825 [15:31:06<29:52:03, 12.69s/it] 34%|███▍      | 4353/12825 [15:31:19<29:48:37, 12.67s/it] 34%|███▍      | 4354/12825 [15:31:31<29:44:11, 12.64s/it] 34%|███▍      | 4355/12825 [15:31:44<29:41:50, 12.62s/it] 34%|███▍      | 4356/12825 [15:31:56<29:40:58, 12.62s/it] 34%|███▍      | 4357/12825 [15:32:09<29:38:57, 12.60s/it] 34%|███▍      | 4358/12825 [15:32:21<29:38:09, 12.60s/it] 34%|███▍      | 4359/12825 [15:32:34<29:36:03, 12.59s/it] 34%|███▍      | 4360/12825 [15:32:47<29:34:33, 12.58s/it] 34%|███▍      | 4361/12825 [15:32:59<29:35:52, 12.59s/it] 34%|███▍      | 4362/12825 [15:33:12<29:35:08, 12.59s/it] 34%|███▍      | 4363/12825 [15:33:24<29:33:22, 12.57s/it] 34%|███▍      | 4364/12825 [15:33:37<29:31:36, 12.56s/it] 34%|███▍      | 4365/12825 [15:33:50<29:34:26, 12.58s/it] 34%|███▍      | 4366/12825 [15:34:02<29:34:33, 12.59s/it] 34%|███▍      | 4367/12825 [15:34:15<29:33:06, 12.58s/it] 34%|███▍      | 4368/12825 [15:34:27<29:31:38, 12.57s/it] 34%|███▍      | 4369/12825 [15:34:40<29:29:25, 12.56s/it] 34%|███▍      | 4370/12825 [15:34:52<29:30:04, 12.56s/it] 34%|███▍      | 4371/12825 [15:35:05<29:29:17, 12.56s/it] 34%|███▍      | 4372/12825 [15:35:26<35:22:14, 15.06s/it] 34%|███▍      | 4373/12825 [15:35:38<33:36:30, 14.31s/it] 34%|███▍      | 4374/12825 [15:35:51<32:24:39, 13.81s/it] 34%|███▍      | 4375/12825 [15:36:04<31:34:53, 13.45s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120284.79lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103520.37lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4350] due to args.save_total_limit
 34%|███▍      | 4376/12825 [15:36:17<31:12:13, 13.30s/it] 34%|███▍      | 4377/12825 [15:36:29<30:41:49, 13.08s/it] 34%|███▍      | 4378/12825 [15:36:42<30:20:00, 12.93s/it] 34%|███▍      | 4379/12825 [15:36:54<30:06:14, 12.83s/it] 34%|███▍      | 4380/12825 [15:37:07<29:54:43, 12.75s/it] 34%|███▍      | 4381/12825 [15:37:19<29:47:19, 12.70s/it] 34%|███▍      | 4382/12825 [15:37:32<29:42:10, 12.66s/it] 34%|███▍      | 4383/12825 [15:37:45<29:38:51, 12.64s/it] 34%|███▍      | 4384/12825 [15:37:57<29:34:50, 12.62s/it] 34%|███▍      | 4385/12825 [15:38:10<29:31:44, 12.60s/it] 34%|███▍      | 4386/12825 [15:38:22<29:30:27, 12.59s/it] 34%|███▍      | 4387/12825 [15:38:35<29:32:01, 12.60s/it] 34%|███▍      | 4388/12825 [15:38:47<29:30:48, 12.59s/it] 34%|███▍      | 4389/12825 [15:39:00<29:31:14, 12.60s/it] 34%|███▍      | 4390/12825 [15:39:13<29:29:35, 12.59s/it] 34%|███▍      | 4391/12825 [15:39:25<29:30:49, 12.60s/it] 34%|███▍      | 4392/12825 [15:39:38<29:28:15, 12.58s/it] 34%|███▍      | 4393/12825 [15:39:50<29:29:09, 12.59s/it] 34%|███▍      | 4394/12825 [15:40:03<29:29:42, 12.59s/it] 34%|███▍      | 4395/12825 [15:40:16<29:31:24, 12.61s/it] 34%|███▍      | 4396/12825 [15:40:28<29:31:28, 12.61s/it] 34%|███▍      | 4397/12825 [15:40:41<29:32:06, 12.62s/it] 34%|███▍      | 4398/12825 [15:40:54<29:32:10, 12.62s/it] 34%|███▍      | 4399/12825 [15:41:06<29:32:21, 12.62s/it] 34%|███▍      | 4400/12825 [15:41:19<29:31:56, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120315.46lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103537.50lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4375] due to args.save_total_limit
 34%|███▍      | 4401/12825 [15:41:32<29:46:21, 12.72s/it] 34%|███▍      | 4402/12825 [15:41:44<29:39:27, 12.68s/it] 34%|███▍      | 4403/12825 [15:41:57<29:32:33, 12.63s/it] 34%|███▍      | 4404/12825 [15:42:17<34:53:42, 14.92s/it] 34%|███▍      | 4405/12825 [15:42:30<33:15:53, 14.22s/it] 34%|███▍      | 4406/12825 [15:42:42<32:06:40, 13.73s/it] 34%|███▍      | 4407/12825 [15:42:55<31:38:01, 13.53s/it] 34%|███▍      | 4408/12825 [15:43:08<30:57:17, 13.24s/it] 34%|███▍      | 4409/12825 [15:43:20<30:29:12, 13.04s/it] 34%|███▍      | 4410/12825 [15:43:33<30:08:47, 12.90s/it] 34%|███▍      | 4411/12825 [15:43:46<29:56:19, 12.81s/it] 34%|███▍      | 4412/12825 [15:43:58<29:46:20, 12.74s/it] 34%|███▍      | 4413/12825 [15:44:11<29:39:55, 12.70s/it] 34%|███▍      | 4414/12825 [15:44:23<29:34:54, 12.66s/it] 34%|███▍      | 4415/12825 [15:44:36<29:31:21, 12.64s/it] 34%|███▍      | 4416/12825 [15:44:49<29:27:54, 12.61s/it] 34%|███▍      | 4417/12825 [15:45:01<29:25:22, 12.60s/it] 34%|███▍      | 4418/12825 [15:45:14<29:23:25, 12.59s/it] 34%|███▍      | 4419/12825 [15:45:26<29:21:38, 12.57s/it] 34%|███▍      | 4420/12825 [15:45:39<29:20:20, 12.57s/it] 34%|███▍      | 4421/12825 [15:45:51<29:21:24, 12.58s/it] 34%|███▍      | 4422/12825 [15:46:04<29:23:53, 12.59s/it] 34%|███▍      | 4423/12825 [15:46:17<29:24:04, 12.60s/it] 34%|███▍      | 4424/12825 [15:46:29<29:23:38, 12.60s/it] 35%|███▍      | 4425/12825 [15:46:42<29:22:27, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120232.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103512.23lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4400] due to args.save_total_limit
 35%|███▍      | 4426/12825 [15:46:55<29:35:33, 12.68s/it] 35%|███▍      | 4427/12825 [15:47:07<29:30:02, 12.65s/it] 35%|███▍      | 4428/12825 [15:47:20<29:26:14, 12.62s/it] 35%|███▍      | 4429/12825 [15:47:32<29:22:21, 12.59s/it] 35%|███▍      | 4430/12825 [15:47:45<29:19:35, 12.58s/it] 35%|███▍      | 4431/12825 [15:47:57<29:18:24, 12.57s/it] 35%|███▍      | 4432/12825 [15:48:10<29:19:01, 12.57s/it] 35%|███▍      | 4433/12825 [15:48:23<29:18:02, 12.57s/it] 35%|███▍      | 4434/12825 [15:48:35<29:18:12, 12.57s/it] 35%|███▍      | 4435/12825 [15:48:48<29:18:45, 12.58s/it] 35%|███▍      | 4436/12825 [15:49:08<34:53:21, 14.97s/it] 35%|███▍      | 4437/12825 [15:49:21<33:11:49, 14.25s/it] 35%|███▍      | 4438/12825 [15:49:33<32:02:18, 13.75s/it] 35%|███▍      | 4439/12825 [15:49:46<31:12:37, 13.40s/it] 35%|███▍      | 4440/12825 [15:49:59<30:38:40, 13.16s/it] 35%|███▍      | 4441/12825 [15:50:11<30:14:59, 12.99s/it] 35%|███▍      | 4442/12825 [15:50:24<29:57:52, 12.87s/it] 35%|███▍      | 4443/12825 [15:50:36<29:45:18, 12.78s/it] 35%|███▍      | 4444/12825 [15:50:49<29:37:10, 12.72s/it] 35%|███▍      | 4445/12825 [15:51:02<29:31:24, 12.68s/it] 35%|███▍      | 4446/12825 [15:51:14<29:26:37, 12.65s/it] 35%|███▍      | 4447/12825 [15:51:27<29:22:49, 12.62s/it] 35%|███▍      | 4448/12825 [15:51:39<29:20:15, 12.61s/it] 35%|███▍      | 4449/12825 [15:51:52<29:16:44, 12.58s/it] 35%|███▍      | 4450/12825 [15:52:04<29:16:28, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120244.69lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 99786.68lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4425] due to args.save_total_limit
 35%|███▍      | 4451/12825 [15:52:17<29:40:06, 12.75s/it] 35%|███▍      | 4452/12825 [15:52:30<29:32:29, 12.70s/it] 35%|███▍      | 4453/12825 [15:52:43<29:26:16, 12.66s/it] 35%|███▍      | 4454/12825 [15:52:55<29:23:29, 12.64s/it] 35%|███▍      | 4455/12825 [15:53:08<29:20:14, 12.62s/it] 35%|███▍      | 4456/12825 [15:53:20<29:16:29, 12.59s/it] 35%|███▍      | 4457/12825 [15:53:33<29:14:10, 12.58s/it] 35%|███▍      | 4458/12825 [15:53:46<29:38:34, 12.75s/it] 35%|███▍      | 4459/12825 [15:53:59<29:31:32, 12.71s/it] 35%|███▍      | 4460/12825 [15:54:11<29:24:35, 12.66s/it] 35%|███▍      | 4461/12825 [15:54:24<29:21:42, 12.64s/it] 35%|███▍      | 4462/12825 [15:54:36<29:19:18, 12.62s/it] 35%|███▍      | 4463/12825 [15:54:49<29:17:43, 12.61s/it] 35%|███▍      | 4464/12825 [15:55:02<29:16:35, 12.61s/it] 35%|███▍      | 4465/12825 [15:55:14<29:16:10, 12.60s/it] 35%|███▍      | 4466/12825 [15:55:27<29:14:15, 12.59s/it] 35%|███▍      | 4467/12825 [15:55:39<29:14:28, 12.59s/it] 35%|███▍      | 4468/12825 [15:56:00<34:38:19, 14.92s/it] 35%|███▍      | 4469/12825 [15:56:12<32:59:10, 14.21s/it] 35%|███▍      | 4470/12825 [15:56:25<31:50:30, 13.72s/it] 35%|███▍      | 4471/12825 [15:56:37<31:03:52, 13.39s/it] 35%|███▍      | 4472/12825 [15:56:50<30:29:48, 13.14s/it] 35%|███▍      | 4473/12825 [15:57:02<30:05:09, 12.97s/it] 35%|███▍      | 4474/12825 [15:57:15<29:47:06, 12.84s/it] 35%|███▍      | 4475/12825 [15:57:28<29:35:53, 12.76s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120325.18lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103557.47lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4450] due to args.save_total_limit
 35%|███▍      | 4476/12825 [15:57:42<30:29:18, 13.15s/it] 35%|███▍      | 4477/12825 [15:57:54<30:06:54, 12.99s/it] 35%|███▍      | 4478/12825 [15:58:07<29:48:58, 12.86s/it] 35%|███▍      | 4479/12825 [15:58:19<29:37:41, 12.78s/it] 35%|███▍      | 4480/12825 [15:58:32<29:30:13, 12.73s/it] 35%|███▍      | 4481/12825 [15:58:45<29:23:31, 12.68s/it] 35%|███▍      | 4482/12825 [15:58:57<29:19:12, 12.65s/it] 35%|███▍      | 4483/12825 [15:59:10<29:17:06, 12.64s/it] 35%|███▍      | 4484/12825 [15:59:22<29:14:39, 12.62s/it] 35%|███▍      | 4485/12825 [15:59:35<29:12:48, 12.61s/it] 35%|███▍      | 4486/12825 [15:59:48<29:10:15, 12.59s/it] 35%|███▍      | 4487/12825 [16:00:00<29:09:50, 12.59s/it] 35%|███▍      | 4488/12825 [16:00:13<29:10:28, 12.60s/it] 35%|███▌      | 4489/12825 [16:00:25<29:10:03, 12.60s/it] 35%|███▌      | 4490/12825 [16:00:38<29:09:40, 12.60s/it] 35%|███▌      | 4491/12825 [16:00:51<29:09:37, 12.60s/it] 35%|███▌      | 4492/12825 [16:01:03<29:09:27, 12.60s/it] 35%|███▌      | 4493/12825 [16:01:16<29:09:02, 12.60s/it] 35%|███▌      | 4494/12825 [16:01:28<29:08:38, 12.59s/it] 35%|███▌      | 4495/12825 [16:01:41<29:07:00, 12.58s/it] 35%|███▌      | 4496/12825 [16:01:53<29:05:14, 12.57s/it] 35%|███▌      | 4497/12825 [16:02:06<29:05:04, 12.57s/it] 35%|███▌      | 4498/12825 [16:02:19<29:06:07, 12.58s/it] 35%|███▌      | 4499/12825 [16:02:31<29:06:01, 12.58s/it] 35%|███▌      | 4500/12825 [16:02:44<29:06:25, 12.59s/it]                                                           35%|███▌      | 4500/12825 [16:02:44<29:06:25, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120247.63lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103500.88lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4475] due to args.save_total_limit
 35%|███▌      | 4501/12825 [16:03:05<34:58:31, 15.13s/it] 35%|███▌      | 4502/12825 [16:03:17<33:11:57, 14.36s/it] 35%|███▌      | 4503/12825 [16:03:30<31:57:25, 13.82s/it] 35%|███▌      | 4504/12825 [16:03:42<31:02:48, 13.43s/it] 35%|███▌      | 4505/12825 [16:03:55<30:26:23, 13.17s/it] 35%|███▌      | 4506/12825 [16:04:08<30:01:59, 13.00s/it] 35%|███▌      | 4507/12825 [16:04:20<29:43:28, 12.86s/it] 35%|███▌      | 4508/12825 [16:04:33<29:30:24, 12.77s/it] 35%|███▌      | 4509/12825 [16:04:45<29:21:25, 12.71s/it] 35%|███▌      | 4510/12825 [16:04:58<29:15:29, 12.67s/it] 35%|███▌      | 4511/12825 [16:05:10<29:12:01, 12.64s/it] 35%|███▌      | 4512/12825 [16:05:23<29:09:24, 12.63s/it] 35%|███▌      | 4513/12825 [16:05:36<29:08:43, 12.62s/it] 35%|███▌      | 4514/12825 [16:05:48<29:06:13, 12.61s/it] 35%|███▌      | 4515/12825 [16:06:01<29:04:40, 12.60s/it] 35%|███▌      | 4516/12825 [16:06:13<29:03:44, 12.59s/it] 35%|███▌      | 4517/12825 [16:06:26<29:03:15, 12.59s/it] 35%|███▌      | 4518/12825 [16:06:39<29:02:58, 12.59s/it] 35%|███▌      | 4519/12825 [16:06:51<29:04:01, 12.60s/it] 35%|███▌      | 4520/12825 [16:07:04<29:03:28, 12.60s/it] 35%|███▌      | 4521/12825 [16:07:16<29:02:00, 12.59s/it] 35%|███▌      | 4522/12825 [16:07:29<28:59:37, 12.57s/it] 35%|███▌      | 4523/12825 [16:07:41<29:01:16, 12.58s/it] 35%|███▌      | 4524/12825 [16:07:54<29:01:30, 12.59s/it] 35%|███▌      | 4525/12825 [16:08:07<29:01:29, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120252.99lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103512.04lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4275] due to args.save_total_limit
 35%|███▌      | 4526/12825 [16:08:20<29:14:42, 12.69s/it] 35%|███▌      | 4527/12825 [16:08:32<29:09:51, 12.65s/it] 35%|███▌      | 4528/12825 [16:08:45<29:05:45, 12.62s/it] 35%|███▌      | 4529/12825 [16:08:57<29:03:16, 12.61s/it] 35%|███▌      | 4530/12825 [16:09:10<29:01:55, 12.60s/it] 35%|███▌      | 4531/12825 [16:09:22<29:00:08, 12.59s/it] 35%|███▌      | 4532/12825 [16:09:35<29:00:45, 12.59s/it] 35%|███▌      | 4533/12825 [16:09:54<33:42:36, 14.64s/it] 35%|███▌      | 4534/12825 [16:10:07<32:16:49, 14.02s/it] 35%|███▌      | 4535/12825 [16:10:20<31:16:46, 13.58s/it] 35%|███▌      | 4536/12825 [16:10:32<30:33:41, 13.27s/it] 35%|███▌      | 4537/12825 [16:10:45<30:03:43, 13.06s/it] 35%|███▌      | 4538/12825 [16:10:57<29:42:50, 12.91s/it] 35%|███▌      | 4539/12825 [16:11:10<29:28:18, 12.80s/it] 35%|███▌      | 4540/12825 [16:11:22<29:18:36, 12.74s/it] 35%|███▌      | 4541/12825 [16:11:35<29:10:53, 12.68s/it] 35%|███▌      | 4542/12825 [16:11:47<29:05:30, 12.64s/it] 35%|███▌      | 4543/12825 [16:12:00<29:01:22, 12.62s/it] 35%|███▌      | 4544/12825 [16:12:13<28:59:43, 12.61s/it] 35%|███▌      | 4545/12825 [16:12:25<28:58:44, 12.60s/it] 35%|███▌      | 4546/12825 [16:12:38<28:57:30, 12.59s/it] 35%|███▌      | 4547/12825 [16:12:50<28:55:42, 12.58s/it] 35%|███▌      | 4548/12825 [16:13:03<28:55:44, 12.58s/it] 35%|███▌      | 4549/12825 [16:13:15<28:55:28, 12.58s/it] 35%|███▌      | 4550/12825 [16:13:28<28:54:40, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120217.50lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103288.00lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4500] due to args.save_total_limit
 35%|███▌      | 4551/12825 [16:13:41<29:12:08, 12.71s/it] 35%|███▌      | 4552/12825 [16:13:54<29:07:12, 12.67s/it] 36%|███▌      | 4553/12825 [16:14:06<29:03:57, 12.65s/it] 36%|███▌      | 4554/12825 [16:14:19<29:00:31, 12.63s/it] 36%|███▌      | 4555/12825 [16:14:31<28:58:50, 12.62s/it] 36%|███▌      | 4556/12825 [16:14:44<28:57:12, 12.61s/it] 36%|███▌      | 4557/12825 [16:14:57<28:55:04, 12.59s/it] 36%|███▌      | 4558/12825 [16:15:09<28:53:51, 12.58s/it] 36%|███▌      | 4559/12825 [16:15:22<28:53:23, 12.58s/it] 36%|███▌      | 4560/12825 [16:15:34<28:53:58, 12.59s/it] 36%|███▌      | 4561/12825 [16:15:47<28:53:56, 12.59s/it] 36%|███▌      | 4562/12825 [16:15:59<28:54:05, 12.59s/it] 36%|███▌      | 4563/12825 [16:16:12<28:55:28, 12.60s/it] 36%|███▌      | 4564/12825 [16:16:25<28:53:22, 12.59s/it] 36%|███▌      | 4565/12825 [16:16:37<28:51:24, 12.58s/it] 36%|███▌      | 4566/12825 [16:16:57<33:32:36, 14.62s/it] 36%|███▌      | 4567/12825 [16:17:09<32:09:40, 14.02s/it] 36%|███▌      | 4568/12825 [16:17:22<31:09:32, 13.59s/it] 36%|███▌      | 4569/12825 [16:17:34<30:26:24, 13.27s/it] 36%|███▌      | 4570/12825 [16:17:47<29:58:38, 13.07s/it] 36%|███▌      | 4571/12825 [16:18:00<29:36:53, 12.92s/it] 36%|███▌      | 4572/12825 [16:18:12<29:22:00, 12.81s/it] 36%|███▌      | 4573/12825 [16:18:25<29:11:38, 12.74s/it] 36%|███▌      | 4574/12825 [16:18:37<29:03:23, 12.68s/it] 36%|███▌      | 4575/12825 [16:18:50<28:57:31, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120293.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103554.44lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4525] due to args.save_total_limit
 36%|███▌      | 4576/12825 [16:19:03<29:07:35, 12.71s/it] 36%|███▌      | 4577/12825 [16:19:15<29:04:20, 12.69s/it] 36%|███▌      | 4578/12825 [16:19:28<29:04:05, 12.69s/it] 36%|███▌      | 4579/12825 [16:19:41<28:59:05, 12.65s/it] 36%|███▌      | 4580/12825 [16:19:53<28:55:40, 12.63s/it] 36%|███▌      | 4581/12825 [16:20:06<28:52:04, 12.61s/it] 36%|███▌      | 4582/12825 [16:20:18<28:49:24, 12.59s/it] 36%|███▌      | 4583/12825 [16:20:31<28:46:29, 12.57s/it] 36%|███▌      | 4584/12825 [16:20:43<28:47:40, 12.58s/it] 36%|███▌      | 4585/12825 [16:20:56<28:47:31, 12.58s/it] 36%|███▌      | 4586/12825 [16:21:08<28:47:31, 12.58s/it] 36%|███▌      | 4587/12825 [16:21:21<28:48:00, 12.59s/it] 36%|███▌      | 4588/12825 [16:21:34<28:47:14, 12.58s/it] 36%|███▌      | 4589/12825 [16:21:46<28:46:41, 12.58s/it] 36%|███▌      | 4590/12825 [16:21:59<28:47:10, 12.58s/it] 36%|███▌      | 4591/12825 [16:22:11<28:45:44, 12.58s/it] 36%|███▌      | 4592/12825 [16:22:24<28:46:03, 12.58s/it] 36%|███▌      | 4593/12825 [16:22:37<28:46:39, 12.59s/it] 36%|███▌      | 4594/12825 [16:22:49<28:47:18, 12.59s/it] 36%|███▌      | 4595/12825 [16:23:02<28:48:35, 12.60s/it] 36%|███▌      | 4596/12825 [16:23:14<28:47:28, 12.60s/it] 36%|███▌      | 4597/12825 [16:23:27<28:46:29, 12.59s/it] 36%|███▌      | 4598/12825 [16:23:47<34:08:54, 14.94s/it] 36%|███▌      | 4599/12825 [16:24:00<32:30:42, 14.23s/it] 36%|███▌      | 4600/12825 [16:24:12<31:21:54, 13.73s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120136.90lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103417.61lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4550] due to args.save_total_limit
 36%|███▌      | 4601/12825 [16:24:25<30:51:32, 13.51s/it] 36%|███▌      | 4602/12825 [16:24:38<30:12:04, 13.22s/it] 36%|███▌      | 4603/12825 [16:24:51<29:46:09, 13.03s/it] 36%|███▌      | 4604/12825 [16:25:03<29:26:51, 12.90s/it] 36%|███▌      | 4605/12825 [16:25:16<29:14:28, 12.81s/it] 36%|███▌      | 4606/12825 [16:25:28<29:04:15, 12.73s/it] 36%|███▌      | 4607/12825 [16:25:41<28:58:43, 12.69s/it] 36%|███▌      | 4608/12825 [16:25:54<28:54:17, 12.66s/it] 36%|███▌      | 4609/12825 [16:26:06<28:51:37, 12.65s/it] 36%|███▌      | 4610/12825 [16:26:19<28:47:55, 12.62s/it] 36%|███▌      | 4611/12825 [16:26:31<28:45:11, 12.60s/it] 36%|███▌      | 4612/12825 [16:26:44<28:44:56, 12.60s/it] 36%|███▌      | 4613/12825 [16:26:56<28:44:53, 12.60s/it] 36%|███▌      | 4614/12825 [16:27:09<28:43:29, 12.59s/it] 36%|███▌      | 4615/12825 [16:27:22<28:44:08, 12.60s/it] 36%|███▌      | 4616/12825 [16:27:30<25:29:07, 11.18s/it] 36%|███▌      | 4617/12825 [16:27:30<18:24:00,  8.07s/it] 36%|███▌      | 4618/12825 [16:27:56<30:21:00, 13.31s/it] 36%|███▌      | 4619/12825 [16:28:09<29:53:04, 13.11s/it] 36%|███▌      | 4620/12825 [16:28:21<29:32:35, 12.96s/it] 36%|███▌      | 4621/12825 [16:28:34<29:17:40, 12.85s/it] 36%|███▌      | 4622/12825 [16:28:46<29:05:09, 12.76s/it] 36%|███▌      | 4623/12825 [16:28:59<28:58:14, 12.72s/it] 36%|███▌      | 4624/12825 [16:29:12<28:53:41, 12.68s/it] 36%|███▌      | 4625/12825 [16:29:24<28:50:16, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120169.03lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103414.21lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4600] due to args.save_total_limit
 36%|███▌      | 4626/12825 [16:29:37<29:03:20, 12.76s/it] 36%|███▌      | 4627/12825 [16:29:50<28:58:14, 12.72s/it] 36%|███▌      | 4628/12825 [16:30:02<28:53:42, 12.69s/it] 36%|███▌      | 4629/12825 [16:30:15<28:50:19, 12.67s/it] 36%|███▌      | 4630/12825 [16:30:28<28:49:00, 12.66s/it] 36%|███▌      | 4631/12825 [16:30:48<34:02:48, 14.96s/it] 36%|███▌      | 4632/12825 [16:31:01<32:24:51, 14.24s/it] 36%|███▌      | 4633/12825 [16:31:13<31:15:44, 13.74s/it] 36%|███▌      | 4634/12825 [16:31:26<30:29:20, 13.40s/it] 36%|███▌      | 4635/12825 [16:31:38<29:56:48, 13.16s/it] 36%|███▌      | 4636/12825 [16:31:51<29:33:45, 13.00s/it] 36%|███▌      | 4637/12825 [16:32:04<29:18:07, 12.88s/it] 36%|███▌      | 4638/12825 [16:32:16<29:05:12, 12.79s/it] 36%|███▌      | 4639/12825 [16:32:29<28:56:21, 12.73s/it] 36%|███▌      | 4640/12825 [16:32:41<28:49:56, 12.68s/it] 36%|███▌      | 4641/12825 [16:32:54<28:47:15, 12.66s/it] 36%|███▌      | 4642/12825 [16:33:07<28:53:23, 12.71s/it] 36%|███▌      | 4643/12825 [16:33:19<28:48:42, 12.68s/it] 36%|███▌      | 4644/12825 [16:33:32<28:46:21, 12.66s/it] 36%|███▌      | 4645/12825 [16:33:45<28:44:30, 12.65s/it] 36%|███▌      | 4646/12825 [16:33:57<28:41:15, 12.63s/it] 36%|███▌      | 4647/12825 [16:34:10<28:40:10, 12.62s/it] 36%|███▌      | 4648/12825 [16:34:22<28:36:58, 12.60s/it] 36%|███▌      | 4649/12825 [16:34:35<28:37:18, 12.60s/it] 36%|███▋      | 4650/12825 [16:34:47<28:36:21, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120243.80lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103514.69lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4625] due to args.save_total_limit
 36%|███▋      | 4651/12825 [16:35:00<28:49:09, 12.69s/it] 36%|███▋      | 4652/12825 [16:35:13<28:45:47, 12.67s/it] 36%|███▋      | 4653/12825 [16:35:26<28:41:34, 12.64s/it] 36%|███▋      | 4654/12825 [16:35:38<28:38:09, 12.62s/it] 36%|███▋      | 4655/12825 [16:35:51<28:35:47, 12.60s/it] 36%|███▋      | 4656/12825 [16:36:03<28:35:09, 12.60s/it] 36%|███▋      | 4657/12825 [16:36:16<28:36:10, 12.61s/it] 36%|███▋      | 4658/12825 [16:36:29<28:35:23, 12.60s/it] 36%|███▋      | 4659/12825 [16:36:41<28:34:24, 12.60s/it] 36%|███▋      | 4660/12825 [16:36:54<28:35:46, 12.61s/it] 36%|███▋      | 4661/12825 [16:37:06<28:35:53, 12.61s/it] 36%|███▋      | 4662/12825 [16:37:19<28:34:48, 12.60s/it] 36%|███▋      | 4663/12825 [16:37:39<33:51:24, 14.93s/it] 36%|███▋      | 4664/12825 [16:37:52<32:13:49, 14.22s/it] 36%|███▋      | 4665/12825 [16:38:04<31:06:45, 13.73s/it] 36%|███▋      | 4666/12825 [16:38:17<30:18:17, 13.37s/it] 36%|███▋      | 4667/12825 [16:38:30<29:45:47, 13.13s/it] 36%|███▋      | 4668/12825 [16:38:42<29:22:52, 12.97s/it] 36%|███▋      | 4669/12825 [16:38:55<29:06:56, 12.85s/it] 36%|███▋      | 4670/12825 [16:39:07<28:56:43, 12.78s/it] 36%|███▋      | 4671/12825 [16:39:20<28:48:03, 12.72s/it] 36%|███▋      | 4672/12825 [16:39:32<28:41:42, 12.67s/it] 36%|███▋      | 4673/12825 [16:39:45<28:37:19, 12.64s/it] 36%|███▋      | 4674/12825 [16:39:58<28:35:55, 12.63s/it] 36%|███▋      | 4675/12825 [16:40:10<28:35:40, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120247.63lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103509.67lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4650] due to args.save_total_limit
 36%|███▋      | 4676/12825 [16:40:23<28:51:07, 12.75s/it] 36%|███▋      | 4677/12825 [16:40:36<28:43:48, 12.69s/it] 36%|███▋      | 4678/12825 [16:40:48<28:38:30, 12.66s/it] 36%|███▋      | 4679/12825 [16:41:01<28:34:36, 12.63s/it] 36%|███▋      | 4680/12825 [16:41:14<28:34:34, 12.63s/it] 36%|███▋      | 4681/12825 [16:41:26<28:32:21, 12.62s/it] 37%|███▋      | 4682/12825 [16:41:39<28:34:33, 12.63s/it] 37%|███▋      | 4683/12825 [16:41:51<28:32:45, 12.62s/it] 37%|███▋      | 4684/12825 [16:42:04<28:30:55, 12.61s/it] 37%|███▋      | 4685/12825 [16:42:17<28:29:18, 12.60s/it] 37%|███▋      | 4686/12825 [16:42:29<28:28:57, 12.60s/it] 37%|███▋      | 4687/12825 [16:42:42<28:28:58, 12.60s/it] 37%|███▋      | 4688/12825 [16:42:54<28:27:52, 12.59s/it] 37%|███▋      | 4689/12825 [16:43:07<28:27:00, 12.59s/it] 37%|███▋      | 4690/12825 [16:43:20<28:27:11, 12.59s/it] 37%|███▋      | 4691/12825 [16:43:32<28:27:20, 12.59s/it] 37%|███▋      | 4692/12825 [16:43:45<28:27:53, 12.60s/it] 37%|███▋      | 4693/12825 [16:43:57<28:28:14, 12.60s/it] 37%|███▋      | 4694/12825 [16:44:10<28:28:14, 12.61s/it] 37%|███▋      | 4695/12825 [16:44:23<28:28:06, 12.61s/it] 37%|███▋      | 4696/12825 [16:44:43<33:50:14, 14.99s/it] 37%|███▋      | 4697/12825 [16:44:56<32:13:30, 14.27s/it] 37%|███▋      | 4698/12825 [16:45:08<31:05:51, 13.78s/it] 37%|███▋      | 4699/12825 [16:45:21<30:16:37, 13.41s/it] 37%|███▋      | 4700/12825 [16:45:34<29:44:33, 13.18s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120177.19lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103482.81lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4575] due to args.save_total_limit
 37%|███▋      | 4701/12825 [16:45:47<29:36:49, 13.12s/it] 37%|███▋      | 4702/12825 [16:45:59<29:16:00, 12.97s/it] 37%|███▋      | 4703/12825 [16:46:12<29:01:01, 12.86s/it] 37%|███▋      | 4704/12825 [16:46:24<28:49:30, 12.78s/it] 37%|███▋      | 4705/12825 [16:46:37<28:42:40, 12.73s/it] 37%|███▋      | 4706/12825 [16:46:50<28:37:26, 12.69s/it] 37%|███▋      | 4707/12825 [16:47:02<28:35:01, 12.68s/it] 37%|███▋      | 4708/12825 [16:47:15<28:33:36, 12.67s/it] 37%|███▋      | 4709/12825 [16:47:27<28:30:31, 12.65s/it] 37%|███▋      | 4710/12825 [16:47:40<28:29:09, 12.64s/it] 37%|███▋      | 4711/12825 [16:47:53<28:28:05, 12.63s/it] 37%|███▋      | 4712/12825 [16:48:05<28:26:53, 12.62s/it] 37%|███▋      | 4713/12825 [16:48:18<28:26:00, 12.62s/it] 37%|███▋      | 4714/12825 [16:48:31<28:25:13, 12.61s/it] 37%|███▋      | 4715/12825 [16:48:43<28:24:55, 12.61s/it] 37%|███▋      | 4716/12825 [16:48:56<28:23:25, 12.60s/it] 37%|███▋      | 4717/12825 [16:49:08<28:24:00, 12.61s/it] 37%|███▋      | 4718/12825 [16:49:21<28:24:27, 12.61s/it] 37%|███▋      | 4719/12825 [16:49:34<28:22:31, 12.60s/it] 37%|███▋      | 4720/12825 [16:49:46<28:21:53, 12.60s/it] 37%|███▋      | 4721/12825 [16:49:59<28:21:12, 12.60s/it] 37%|███▋      | 4722/12825 [16:50:11<28:22:41, 12.61s/it] 37%|███▋      | 4723/12825 [16:50:24<28:24:12, 12.62s/it] 37%|███▋      | 4724/12825 [16:50:37<28:23:02, 12.61s/it] 37%|███▋      | 4725/12825 [16:50:49<28:22:38, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120277.26lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103541.38lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4725
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4725/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4725/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4675] due to args.save_total_limit
 37%|███▋      | 4726/12825 [16:51:02<28:36:27, 12.72s/it] 37%|███▋      | 4727/12825 [16:51:15<28:32:33, 12.69s/it] 37%|███▋      | 4728/12825 [16:51:36<34:02:44, 15.14s/it] 37%|███▋      | 4729/12825 [16:51:48<32:19:49, 14.38s/it] 37%|███▋      | 4730/12825 [16:52:01<31:06:42, 13.84s/it] 37%|███▋      | 4731/12825 [16:52:13<30:16:21, 13.46s/it] 37%|███▋      | 4732/12825 [16:52:26<29:42:16, 13.21s/it] 37%|███▋      | 4733/12825 [16:52:39<29:17:37, 13.03s/it] 37%|███▋      | 4734/12825 [16:52:51<28:59:59, 12.90s/it] 37%|███▋      | 4735/12825 [16:53:04<28:46:44, 12.81s/it] 37%|███▋      | 4736/12825 [16:53:16<28:40:22, 12.76s/it] 37%|███▋      | 4737/12825 [16:53:29<28:34:25, 12.72s/it] 37%|███▋      | 4738/12825 [16:53:42<28:28:45, 12.68s/it] 37%|███▋      | 4739/12825 [16:53:54<28:24:36, 12.65s/it] 37%|███▋      | 4740/12825 [16:54:07<28:22:37, 12.64s/it] 37%|███▋      | 4741/12825 [16:54:19<28:20:42, 12.62s/it] 37%|███▋      | 4742/12825 [16:54:32<28:24:16, 12.65s/it] 37%|███▋      | 4743/12825 [16:54:45<28:21:28, 12.63s/it] 37%|███▋      | 4744/12825 [16:54:57<28:19:03, 12.62s/it] 37%|███▋      | 4745/12825 [16:55:10<28:17:46, 12.61s/it] 37%|███▋      | 4746/12825 [16:55:23<28:17:41, 12.61s/it] 37%|███▋      | 4747/12825 [16:55:35<28:16:16, 12.60s/it] 37%|███▋      | 4748/12825 [16:55:48<28:15:21, 12.59s/it] 37%|███▋      | 4749/12825 [16:56:00<28:16:22, 12.60s/it] 37%|███▋      | 4750/12825 [16:56:13<28:15:51, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120259.88lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103521.60lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4750
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4750/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4750/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4725] due to args.save_total_limit
 37%|███▋      | 4751/12825 [16:56:26<28:30:25, 12.71s/it] 37%|███▋      | 4752/12825 [16:56:38<28:24:50, 12.67s/it] 37%|███▋      | 4753/12825 [16:56:51<28:20:26, 12.64s/it] 37%|███▋      | 4754/12825 [16:57:04<28:17:51, 12.62s/it] 37%|███▋      | 4755/12825 [16:57:16<28:16:19, 12.61s/it] 37%|███▋      | 4756/12825 [16:57:29<28:14:24, 12.60s/it] 37%|███▋      | 4757/12825 [16:57:41<28:14:27, 12.60s/it] 37%|███▋      | 4758/12825 [16:57:54<28:14:47, 12.61s/it] 37%|███▋      | 4759/12825 [16:58:07<28:14:53, 12.61s/it] 37%|███▋      | 4760/12825 [16:58:28<34:20:11, 15.33s/it] 37%|███▋      | 4761/12825 [16:58:41<32:29:13, 14.50s/it] 37%|███▋      | 4762/12825 [16:58:54<31:27:32, 14.05s/it] 37%|███▋      | 4763/12825 [16:59:06<30:26:55, 13.60s/it] 37%|███▋      | 4764/12825 [16:59:19<29:44:46, 13.28s/it] 37%|███▋      | 4765/12825 [16:59:32<29:16:02, 13.07s/it] 37%|███▋      | 4766/12825 [16:59:44<28:55:44, 12.92s/it] 37%|███▋      | 4767/12825 [16:59:57<28:40:13, 12.81s/it] 37%|███▋      | 4768/12825 [17:00:09<28:29:27, 12.73s/it] 37%|███▋      | 4769/12825 [17:00:22<28:23:54, 12.69s/it] 37%|███▋      | 4770/12825 [17:00:34<28:18:43, 12.65s/it] 37%|███▋      | 4771/12825 [17:00:47<28:16:11, 12.64s/it] 37%|███▋      | 4772/12825 [17:01:00<28:13:17, 12.62s/it] 37%|███▋      | 4773/12825 [17:01:12<28:11:46, 12.61s/it] 37%|███▋      | 4774/12825 [17:01:25<28:10:36, 12.60s/it] 37%|███▋      | 4775/12825 [17:01:37<28:09:10, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120133.33lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103420.16lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4775
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4775/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4775/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4750] due to args.save_total_limit
 37%|███▋      | 4776/12825 [17:01:50<28:22:15, 12.69s/it] 37%|███▋      | 4777/12825 [17:02:03<28:19:31, 12.67s/it] 37%|███▋      | 4778/12825 [17:02:15<28:16:01, 12.65s/it] 37%|███▋      | 4779/12825 [17:02:28<28:14:04, 12.63s/it] 37%|███▋      | 4780/12825 [17:02:41<28:12:36, 12.62s/it] 37%|███▋      | 4781/12825 [17:02:53<28:10:14, 12.61s/it] 37%|███▋      | 4782/12825 [17:03:06<28:09:58, 12.61s/it] 37%|███▋      | 4783/12825 [17:03:18<28:09:30, 12.61s/it] 37%|███▋      | 4784/12825 [17:03:31<28:09:17, 12.61s/it] 37%|███▋      | 4785/12825 [17:03:44<28:09:57, 12.61s/it] 37%|███▋      | 4786/12825 [17:03:56<28:07:56, 12.60s/it] 37%|███▋      | 4787/12825 [17:04:09<28:06:48, 12.59s/it] 37%|███▋      | 4788/12825 [17:04:21<28:05:21, 12.58s/it] 37%|███▋      | 4789/12825 [17:04:34<28:05:26, 12.58s/it] 37%|███▋      | 4790/12825 [17:04:46<28:05:05, 12.58s/it] 37%|███▋      | 4791/12825 [17:04:59<28:06:20, 12.59s/it] 37%|███▋      | 4792/12825 [17:05:19<33:11:00, 14.87s/it] 37%|███▋      | 4793/12825 [17:05:32<31:38:11, 14.18s/it] 37%|███▋      | 4794/12825 [17:05:44<30:33:13, 13.70s/it] 37%|███▋      | 4795/12825 [17:05:57<29:46:13, 13.35s/it] 37%|███▋      | 4796/12825 [17:06:10<29:15:26, 13.12s/it] 37%|███▋      | 4797/12825 [17:06:22<28:52:43, 12.95s/it] 37%|███▋      | 4798/12825 [17:06:35<28:34:04, 12.81s/it] 37%|███▋      | 4799/12825 [17:06:47<28:23:47, 12.74s/it] 37%|███▋      | 4800/12825 [17:07:00<28:15:52, 12.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120337.96lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103591.86lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4800
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4800/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4800/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4775] due to args.save_total_limit
 37%|███▋      | 4801/12825 [17:07:13<28:22:45, 12.73s/it] 37%|███▋      | 4802/12825 [17:07:25<28:15:41, 12.68s/it] 37%|███▋      | 4803/12825 [17:07:38<28:10:25, 12.64s/it] 37%|███▋      | 4804/12825 [17:07:51<28:40:10, 12.87s/it] 37%|███▋      | 4805/12825 [17:08:04<28:27:57, 12.78s/it] 37%|███▋      | 4806/12825 [17:08:16<28:17:42, 12.70s/it] 37%|███▋      | 4807/12825 [17:08:29<28:10:36, 12.65s/it] 37%|███▋      | 4808/12825 [17:08:41<28:04:57, 12.61s/it] 37%|███▋      | 4809/12825 [17:08:54<28:02:56, 12.60s/it] 38%|███▊      | 4810/12825 [17:09:06<28:02:38, 12.60s/it] 38%|███▊      | 4811/12825 [17:09:19<27:59:38, 12.58s/it] 38%|███▊      | 4812/12825 [17:09:31<27:59:02, 12.57s/it] 38%|███▊      | 4813/12825 [17:09:44<27:58:44, 12.57s/it] 38%|███▊      | 4814/12825 [17:09:57<27:57:18, 12.56s/it] 38%|███▊      | 4815/12825 [17:10:09<27:57:39, 12.57s/it] 38%|███▊      | 4816/12825 [17:10:22<27:56:21, 12.56s/it] 38%|███▊      | 4817/12825 [17:10:34<27:56:19, 12.56s/it] 38%|███▊      | 4818/12825 [17:10:47<27:56:48, 12.57s/it] 38%|███▊      | 4819/12825 [17:10:59<27:58:35, 12.58s/it] 38%|███▊      | 4820/12825 [17:11:12<28:01:34, 12.60s/it] 38%|███▊      | 4821/12825 [17:11:25<27:59:05, 12.59s/it] 38%|███▊      | 4822/12825 [17:11:37<27:56:29, 12.57s/it] 38%|███▊      | 4823/12825 [17:11:50<27:57:29, 12.58s/it] 38%|███▊      | 4824/12825 [17:12:02<27:56:22, 12.57s/it] 38%|███▊      | 4825/12825 [17:12:23<33:09:13, 14.92s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 111929.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 96674.22lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4825
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4825/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4825/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4800] due to args.save_total_limit
 38%|███▊      | 4826/12825 [17:12:36<31:57:04, 14.38s/it] 38%|███▊      | 4827/12825 [17:12:48<30:42:34, 13.82s/it] 38%|███▊      | 4828/12825 [17:13:01<29:52:37, 13.45s/it] 38%|███▊      | 4829/12825 [17:13:13<29:16:09, 13.18s/it] 38%|███▊      | 4830/12825 [17:13:26<28:50:02, 12.98s/it] 38%|███▊      | 4831/12825 [17:13:39<28:34:02, 12.86s/it] 38%|███▊      | 4832/12825 [17:13:51<28:20:39, 12.77s/it] 38%|███▊      | 4833/12825 [17:14:04<28:12:06, 12.70s/it] 38%|███▊      | 4834/12825 [17:14:16<28:07:07, 12.67s/it] 38%|███▊      | 4835/12825 [17:14:29<28:00:21, 12.62s/it] 38%|███▊      | 4836/12825 [17:14:41<27:56:50, 12.59s/it] 38%|███▊      | 4837/12825 [17:14:54<27:54:07, 12.57s/it] 38%|███▊      | 4838/12825 [17:15:06<27:53:34, 12.57s/it] 38%|███▊      | 4839/12825 [17:15:19<27:52:03, 12.56s/it] 38%|███▊      | 4840/12825 [17:15:32<27:51:08, 12.56s/it] 38%|███▊      | 4841/12825 [17:15:44<27:51:09, 12.56s/it] 38%|███▊      | 4842/12825 [17:15:57<27:49:19, 12.55s/it] 38%|███▊      | 4843/12825 [17:16:09<27:49:28, 12.55s/it] 38%|███▊      | 4844/12825 [17:16:22<27:49:36, 12.55s/it] 38%|███▊      | 4845/12825 [17:16:34<27:49:29, 12.55s/it] 38%|███▊      | 4846/12825 [17:16:47<27:48:46, 12.55s/it] 38%|███▊      | 4847/12825 [17:16:59<27:49:12, 12.55s/it] 38%|███▊      | 4848/12825 [17:17:12<27:46:36, 12.54s/it] 38%|███▊      | 4849/12825 [17:17:24<27:47:55, 12.55s/it] 38%|███▊      | 4850/12825 [17:17:37<27:47:37, 12.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120209.08lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 102795.97lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4850
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4850/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4850/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4825] due to args.save_total_limit
 38%|███▊      | 4851/12825 [17:17:50<28:02:00, 12.66s/it] 38%|███▊      | 4852/12825 [17:18:02<27:57:57, 12.63s/it] 38%|███▊      | 4853/12825 [17:18:15<27:53:24, 12.59s/it] 38%|███▊      | 4854/12825 [17:18:27<27:50:39, 12.58s/it] 38%|███▊      | 4855/12825 [17:18:40<27:48:57, 12.56s/it] 38%|███▊      | 4856/12825 [17:18:53<27:47:51, 12.56s/it] 38%|███▊      | 4857/12825 [17:19:13<33:04:19, 14.94s/it] 38%|███▊      | 4858/12825 [17:19:26<31:28:02, 14.22s/it] 38%|███▊      | 4859/12825 [17:19:38<30:20:01, 13.71s/it] 38%|███▊      | 4860/12825 [17:19:51<29:33:47, 13.36s/it] 38%|███▊      | 4861/12825 [17:20:03<28:59:35, 13.11s/it] 38%|███▊      | 4862/12825 [17:20:16<28:35:33, 12.93s/it] 38%|███▊      | 4863/12825 [17:20:28<28:19:13, 12.80s/it] 38%|███▊      | 4864/12825 [17:20:41<28:08:51, 12.73s/it] 38%|███▊      | 4865/12825 [17:20:53<28:01:58, 12.68s/it] 38%|███▊      | 4866/12825 [17:21:06<27:55:41, 12.63s/it] 38%|███▊      | 4867/12825 [17:21:18<27:52:01, 12.61s/it] 38%|███▊      | 4868/12825 [17:21:31<27:48:21, 12.58s/it] 38%|███▊      | 4869/12825 [17:21:43<27:46:50, 12.57s/it] 38%|███▊      | 4870/12825 [17:21:56<27:45:45, 12.56s/it] 38%|███▊      | 4871/12825 [17:22:09<27:45:12, 12.56s/it] 38%|███▊      | 4872/12825 [17:22:21<27:44:50, 12.56s/it] 38%|███▊      | 4873/12825 [17:22:34<27:42:33, 12.54s/it] 38%|███▊      | 4874/12825 [17:22:46<27:41:55, 12.54s/it] 38%|███▊      | 4875/12825 [17:22:59<27:41:34, 12.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120245.71lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103532.20lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4875
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4875/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4875/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4850] due to args.save_total_limit
 38%|███▊      | 4876/12825 [17:23:12<27:53:51, 12.63s/it] 38%|███▊      | 4877/12825 [17:23:24<27:49:52, 12.61s/it] 38%|███▊      | 4878/12825 [17:23:37<27:45:39, 12.58s/it] 38%|███▊      | 4879/12825 [17:23:49<27:42:22, 12.55s/it] 38%|███▊      | 4880/12825 [17:24:02<27:41:16, 12.55s/it] 38%|███▊      | 4881/12825 [17:24:14<27:40:10, 12.54s/it] 38%|███▊      | 4882/12825 [17:24:27<27:41:05, 12.55s/it] 38%|███▊      | 4883/12825 [17:24:39<27:40:44, 12.55s/it] 38%|███▊      | 4884/12825 [17:24:52<27:39:21, 12.54s/it] 38%|███▊      | 4885/12825 [17:25:04<27:39:19, 12.54s/it] 38%|███▊      | 4886/12825 [17:25:17<27:39:38, 12.54s/it] 38%|███▊      | 4887/12825 [17:25:29<27:38:18, 12.53s/it] 38%|███▊      | 4888/12825 [17:25:42<27:36:32, 12.52s/it] 38%|███▊      | 4889/12825 [17:25:54<27:37:02, 12.53s/it] 38%|███▊      | 4890/12825 [17:26:15<32:54:09, 14.93s/it] 38%|███▊      | 4891/12825 [17:26:28<31:19:20, 14.21s/it] 38%|███▊      | 4892/12825 [17:26:40<30:13:44, 13.72s/it] 38%|███▊      | 4893/12825 [17:26:53<29:25:41, 13.36s/it] 38%|███▊      | 4894/12825 [17:27:05<28:52:32, 13.11s/it] 38%|███▊      | 4895/12825 [17:27:18<28:28:43, 12.93s/it] 38%|███▊      | 4896/12825 [17:27:30<28:12:15, 12.81s/it] 38%|███▊      | 4897/12825 [17:27:43<28:01:00, 12.72s/it] 38%|███▊      | 4898/12825 [17:27:55<27:53:59, 12.67s/it] 38%|███▊      | 4899/12825 [17:28:08<27:49:32, 12.64s/it] 38%|███▊      | 4900/12825 [17:28:20<27:45:53, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120196.57lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103427.15lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4900
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4900/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4900/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4875] due to args.save_total_limit
 38%|███▊      | 4901/12825 [17:28:33<27:57:54, 12.70s/it] 38%|███▊      | 4902/12825 [17:28:46<27:51:49, 12.66s/it] 38%|███▊      | 4903/12825 [17:28:58<27:46:05, 12.62s/it] 38%|███▊      | 4904/12825 [17:29:11<27:42:03, 12.59s/it] 38%|███▊      | 4905/12825 [17:29:23<27:41:55, 12.59s/it] 38%|███▊      | 4906/12825 [17:29:36<27:40:15, 12.58s/it] 38%|███▊      | 4907/12825 [17:29:49<27:38:06, 12.56s/it] 38%|███▊      | 4908/12825 [17:30:01<27:36:27, 12.55s/it] 38%|███▊      | 4909/12825 [17:30:14<27:35:48, 12.55s/it] 38%|███▊      | 4910/12825 [17:30:26<27:35:22, 12.55s/it] 38%|███▊      | 4911/12825 [17:30:39<27:35:41, 12.55s/it] 38%|███▊      | 4912/12825 [17:30:51<27:34:35, 12.55s/it] 38%|███▊      | 4913/12825 [17:31:04<27:34:09, 12.54s/it] 38%|███▊      | 4914/12825 [17:31:16<27:35:02, 12.55s/it] 38%|███▊      | 4915/12825 [17:31:29<27:34:05, 12.55s/it] 38%|███▊      | 4916/12825 [17:31:41<27:32:39, 12.54s/it] 38%|███▊      | 4917/12825 [17:31:54<27:31:58, 12.53s/it] 38%|███▊      | 4918/12825 [17:32:06<27:32:26, 12.54s/it] 38%|███▊      | 4919/12825 [17:32:19<27:31:41, 12.53s/it] 38%|███▊      | 4920/12825 [17:32:32<27:33:01, 12.55s/it] 38%|███▊      | 4921/12825 [17:32:44<27:30:56, 12.53s/it] 38%|███▊      | 4922/12825 [17:33:04<32:30:40, 14.81s/it] 38%|███▊      | 4923/12825 [17:33:17<31:00:55, 14.13s/it] 38%|███▊      | 4924/12825 [17:33:29<29:57:11, 13.65s/it] 38%|███▊      | 4925/12825 [17:33:42<29:13:01, 13.31s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 88018.24lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 78704.36lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4925
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4925/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4925/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4900] due to args.save_total_limit
 38%|███▊      | 4926/12825 [17:33:55<28:59:11, 13.21s/it] 38%|███▊      | 4927/12825 [17:34:07<28:32:09, 13.01s/it] 38%|███▊      | 4928/12825 [17:34:20<28:12:54, 12.86s/it] 38%|███▊      | 4929/12825 [17:34:32<28:01:35, 12.78s/it] 38%|███▊      | 4930/12825 [17:34:45<27:52:08, 12.71s/it] 38%|███▊      | 4931/12825 [17:34:57<27:44:42, 12.65s/it] 38%|███▊      | 4932/12825 [17:35:10<27:39:23, 12.61s/it] 38%|███▊      | 4933/12825 [17:35:23<27:36:29, 12.59s/it] 38%|███▊      | 4934/12825 [17:35:35<27:33:39, 12.57s/it] 38%|███▊      | 4935/12825 [17:35:48<27:31:00, 12.56s/it] 38%|███▊      | 4936/12825 [17:36:00<27:28:59, 12.54s/it] 38%|███▊      | 4937/12825 [17:36:13<27:27:51, 12.53s/it] 39%|███▊      | 4938/12825 [17:36:25<27:26:32, 12.53s/it] 39%|███▊      | 4939/12825 [17:36:38<27:25:35, 12.52s/it] 39%|███▊      | 4940/12825 [17:36:50<27:26:46, 12.53s/it] 39%|███▊      | 4941/12825 [17:37:03<27:26:56, 12.53s/it] 39%|███▊      | 4942/12825 [17:37:15<27:25:45, 12.53s/it] 39%|███▊      | 4943/12825 [17:37:28<27:26:58, 12.54s/it] 39%|███▊      | 4944/12825 [17:37:40<27:26:33, 12.54s/it] 39%|███▊      | 4945/12825 [17:37:53<27:25:25, 12.53s/it] 39%|███▊      | 4946/12825 [17:38:05<27:24:42, 12.52s/it] 39%|███▊      | 4947/12825 [17:38:18<27:25:14, 12.53s/it] 39%|███▊      | 4948/12825 [17:38:30<27:23:24, 12.52s/it] 39%|███▊      | 4949/12825 [17:38:43<27:23:47, 12.52s/it] 39%|███▊      | 4950/12825 [17:38:55<27:21:30, 12.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120289.01lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103366.82lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4950
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4950/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4950/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4925] due to args.save_total_limit
 39%|███▊      | 4951/12825 [17:39:08<27:34:48, 12.61s/it] 39%|███▊      | 4952/12825 [17:39:21<27:30:57, 12.58s/it] 39%|███▊      | 4953/12825 [17:39:33<27:28:28, 12.56s/it] 39%|███▊      | 4954/12825 [17:39:54<33:02:08, 15.11s/it] 39%|███▊      | 4955/12825 [17:40:07<31:18:48, 14.32s/it] 39%|███▊      | 4956/12825 [17:40:19<30:08:04, 13.79s/it] 39%|███▊      | 4957/12825 [17:40:32<29:20:03, 13.42s/it] 39%|███▊      | 4958/12825 [17:40:44<28:43:56, 13.15s/it] 39%|███▊      | 4959/12825 [17:40:57<28:17:47, 12.95s/it] 39%|███▊      | 4960/12825 [17:41:09<28:00:21, 12.82s/it] 39%|███▊      | 4961/12825 [17:41:22<27:49:21, 12.74s/it] 39%|███▊      | 4962/12825 [17:41:35<27:41:09, 12.68s/it] 39%|███▊      | 4963/12825 [17:41:47<27:34:23, 12.63s/it] 39%|███▊      | 4964/12825 [17:42:00<27:30:50, 12.60s/it] 39%|███▊      | 4965/12825 [17:42:12<27:27:25, 12.58s/it] 39%|███▊      | 4966/12825 [17:42:25<27:25:54, 12.57s/it] 39%|███▊      | 4967/12825 [17:42:37<27:24:14, 12.55s/it] 39%|███▊      | 4968/12825 [17:42:50<27:21:27, 12.54s/it] 39%|███▊      | 4969/12825 [17:43:02<27:21:12, 12.53s/it] 39%|███▉      | 4970/12825 [17:43:15<27:20:20, 12.53s/it] 39%|███▉      | 4971/12825 [17:43:27<27:19:42, 12.53s/it] 39%|███▉      | 4972/12825 [17:43:40<27:19:05, 12.52s/it] 39%|███▉      | 4973/12825 [17:43:52<27:18:39, 12.52s/it] 39%|███▉      | 4974/12825 [17:44:05<27:18:11, 12.52s/it] 39%|███▉      | 4975/12825 [17:44:17<27:19:47, 12.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120264.61lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103356.82lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4975
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4975/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4975/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-4975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4950] due to args.save_total_limit
 39%|███▉      | 4976/12825 [17:44:30<27:32:52, 12.64s/it] 39%|███▉      | 4977/12825 [17:44:43<27:28:04, 12.60s/it] 39%|███▉      | 4978/12825 [17:44:55<27:25:21, 12.58s/it] 39%|███▉      | 4979/12825 [17:45:08<27:23:54, 12.57s/it] 39%|███▉      | 4980/12825 [17:45:20<27:22:15, 12.56s/it] 39%|███▉      | 4981/12825 [17:45:33<27:20:43, 12.55s/it] 39%|███▉      | 4982/12825 [17:45:45<27:19:35, 12.54s/it] 39%|███▉      | 4983/12825 [17:45:58<27:19:50, 12.55s/it] 39%|███▉      | 4984/12825 [17:46:10<27:17:55, 12.53s/it] 39%|███▉      | 4985/12825 [17:46:23<27:17:25, 12.53s/it] 39%|███▉      | 4986/12825 [17:46:36<27:17:42, 12.54s/it] 39%|███▉      | 4987/12825 [17:46:56<32:23:27, 14.88s/it] 39%|███▉      | 4988/12825 [17:47:08<30:50:15, 14.17s/it] 39%|███▉      | 4989/12825 [17:47:21<29:45:38, 13.67s/it] 39%|███▉      | 4990/12825 [17:47:33<28:59:57, 13.32s/it] 39%|███▉      | 4991/12825 [17:47:46<28:27:36, 13.08s/it] 39%|███▉      | 4992/12825 [17:47:58<28:05:23, 12.91s/it] 39%|███▉      | 4993/12825 [17:48:11<27:50:11, 12.80s/it] 39%|███▉      | 4994/12825 [17:48:23<27:37:24, 12.70s/it] 39%|███▉      | 4995/12825 [17:48:36<27:29:19, 12.64s/it] 39%|███▉      | 4996/12825 [17:48:48<27:25:14, 12.61s/it] 39%|███▉      | 4997/12825 [17:49:01<27:20:52, 12.58s/it] 39%|███▉      | 4998/12825 [17:49:13<27:18:18, 12.56s/it] 39%|███▉      | 4999/12825 [17:49:26<27:17:11, 12.55s/it] 39%|███▉      | 5000/12825 [17:49:39<27:14:50, 12.54s/it]                                                           39%|███▉      | 5000/12825 [17:49:39<27:14:50, 12.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120256.18lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 98960.39lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5000
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5000/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5000/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4975] due to args.save_total_limit
 39%|███▉      | 5001/12825 [17:49:52<27:37:18, 12.71s/it] 39%|███▉      | 5002/12825 [17:50:04<27:30:26, 12.66s/it] 39%|███▉      | 5003/12825 [17:50:17<27:23:53, 12.61s/it] 39%|███▉      | 5004/12825 [17:50:29<27:19:41, 12.58s/it] 39%|███▉      | 5005/12825 [17:50:42<27:14:59, 12.54s/it] 39%|███▉      | 5006/12825 [17:50:54<27:15:13, 12.55s/it] 39%|███▉      | 5007/12825 [17:51:07<27:13:59, 12.54s/it] 39%|███▉      | 5008/12825 [17:51:19<27:13:47, 12.54s/it] 39%|███▉      | 5009/12825 [17:51:32<27:12:12, 12.53s/it] 39%|███▉      | 5010/12825 [17:51:44<27:12:55, 12.54s/it] 39%|███▉      | 5011/12825 [17:51:57<27:13:29, 12.54s/it] 39%|███▉      | 5012/12825 [17:52:09<27:13:08, 12.54s/it] 39%|███▉      | 5013/12825 [17:52:22<27:13:13, 12.54s/it] 39%|███▉      | 5014/12825 [17:52:34<27:12:29, 12.54s/it] 39%|███▉      | 5015/12825 [17:52:47<27:12:33, 12.54s/it] 39%|███▉      | 5016/12825 [17:53:00<27:09:47, 12.52s/it] 39%|███▉      | 5017/12825 [17:53:12<27:10:27, 12.53s/it] 39%|███▉      | 5018/12825 [17:53:25<27:11:12, 12.54s/it] 39%|███▉      | 5019/12825 [17:53:45<32:07:08, 14.81s/it] 39%|███▉      | 5020/12825 [17:53:57<30:38:58, 14.14s/it] 39%|███▉      | 5021/12825 [17:54:10<29:35:27, 13.65s/it] 39%|███▉      | 5022/12825 [17:54:22<28:50:54, 13.31s/it] 39%|███▉      | 5023/12825 [17:54:35<28:21:17, 13.08s/it] 39%|███▉      | 5024/12825 [17:54:47<27:58:22, 12.91s/it] 39%|███▉      | 5025/12825 [17:55:00<27:41:53, 12.78s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120083.65lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103321.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5025
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5025/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5025/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5000] due to args.save_total_limit
 39%|███▉      | 5026/12825 [17:55:13<27:44:26, 12.81s/it] 39%|███▉      | 5027/12825 [17:55:25<27:31:44, 12.71s/it] 39%|███▉      | 5028/12825 [17:55:38<27:21:10, 12.63s/it] 39%|███▉      | 5029/12825 [17:55:50<27:15:05, 12.58s/it] 39%|███▉      | 5030/12825 [17:56:03<27:12:51, 12.57s/it] 39%|███▉      | 5031/12825 [17:56:15<27:10:55, 12.56s/it] 39%|███▉      | 5032/12825 [17:56:28<27:09:40, 12.55s/it] 39%|███▉      | 5033/12825 [17:56:40<27:09:18, 12.55s/it] 39%|███▉      | 5034/12825 [17:56:53<27:08:04, 12.54s/it] 39%|███▉      | 5035/12825 [17:57:05<27:07:12, 12.53s/it] 39%|███▉      | 5036/12825 [17:57:18<27:06:06, 12.53s/it] 39%|███▉      | 5037/12825 [17:57:30<27:05:35, 12.52s/it] 39%|███▉      | 5038/12825 [17:57:43<27:04:08, 12.51s/it] 39%|███▉      | 5039/12825 [17:57:55<27:03:33, 12.51s/it] 39%|███▉      | 5040/12825 [17:58:08<27:03:45, 12.51s/it] 39%|███▉      | 5041/12825 [17:58:20<27:02:39, 12.51s/it] 39%|███▉      | 5042/12825 [17:58:33<27:01:16, 12.50s/it] 39%|███▉      | 5043/12825 [17:58:45<27:01:05, 12.50s/it] 39%|███▉      | 5044/12825 [17:58:58<27:00:25, 12.50s/it] 39%|███▉      | 5045/12825 [17:59:10<27:02:02, 12.51s/it] 39%|███▉      | 5046/12825 [17:59:23<27:02:42, 12.52s/it] 39%|███▉      | 5047/12825 [17:59:35<27:03:00, 12.52s/it] 39%|███▉      | 5048/12825 [17:59:48<27:02:01, 12.51s/it] 39%|███▉      | 5049/12825 [18:00:00<27:03:10, 12.52s/it] 39%|███▉      | 5050/12825 [18:00:13<27:02:46, 12.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120141.11lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103452.66lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5050
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5050/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5050/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5025] due to args.save_total_limit
 39%|███▉      | 5051/12825 [18:00:33<32:03:33, 14.85s/it] 39%|███▉      | 5052/12825 [18:00:46<30:32:35, 14.15s/it] 39%|███▉      | 5053/12825 [18:00:58<29:28:20, 13.65s/it] 39%|███▉      | 5054/12825 [18:01:11<28:43:55, 13.31s/it] 39%|███▉      | 5055/12825 [18:01:23<28:13:51, 13.08s/it] 39%|███▉      | 5056/12825 [18:01:36<27:52:17, 12.92s/it] 39%|███▉      | 5057/12825 [18:01:48<27:37:48, 12.80s/it] 39%|███▉      | 5058/12825 [18:02:01<27:27:30, 12.73s/it] 39%|███▉      | 5059/12825 [18:02:14<27:21:30, 12.68s/it] 39%|███▉      | 5060/12825 [18:02:26<27:14:26, 12.63s/it] 39%|███▉      | 5061/12825 [18:02:39<27:10:05, 12.60s/it] 39%|███▉      | 5062/12825 [18:02:51<27:07:09, 12.58s/it] 39%|███▉      | 5063/12825 [18:03:04<27:04:49, 12.56s/it] 39%|███▉      | 5064/12825 [18:03:16<27:04:07, 12.56s/it] 39%|███▉      | 5065/12825 [18:03:29<27:03:03, 12.55s/it] 40%|███▉      | 5066/12825 [18:03:41<27:01:07, 12.54s/it] 40%|███▉      | 5067/12825 [18:03:54<27:00:34, 12.53s/it] 40%|███▉      | 5068/12825 [18:04:06<26:59:06, 12.52s/it] 40%|███▉      | 5069/12825 [18:04:19<26:56:05, 12.50s/it] 40%|███▉      | 5070/12825 [18:04:31<26:53:05, 12.48s/it] 40%|███▉      | 5071/12825 [18:04:44<26:54:16, 12.49s/it] 40%|███▉      | 5072/12825 [18:04:56<26:53:53, 12.49s/it] 40%|███▉      | 5073/12825 [18:05:09<26:54:23, 12.50s/it] 40%|███▉      | 5074/12825 [18:05:21<26:53:42, 12.49s/it] 40%|███▉      | 5075/12825 [18:05:34<26:53:40, 12.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120340.14lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103591.48lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5075
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5075/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5075/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5050] due to args.save_total_limit
 40%|███▉      | 5076/12825 [18:05:46<27:06:40, 12.60s/it] 40%|███▉      | 5077/12825 [18:05:59<27:02:38, 12.57s/it] 40%|███▉      | 5078/12825 [18:06:11<27:00:00, 12.55s/it] 40%|███▉      | 5079/12825 [18:06:24<26:57:26, 12.53s/it] 40%|███▉      | 5080/12825 [18:06:36<26:57:04, 12.53s/it] 40%|███▉      | 5081/12825 [18:06:49<26:56:28, 12.52s/it] 40%|███▉      | 5082/12825 [18:07:01<26:54:53, 12.51s/it] 40%|███▉      | 5083/12825 [18:07:14<26:53:48, 12.51s/it] 40%|███▉      | 5084/12825 [18:07:35<32:18:51, 15.03s/it] 40%|███▉      | 5085/12825 [18:07:47<30:41:26, 14.27s/it] 40%|███▉      | 5086/12825 [18:08:00<29:34:10, 13.76s/it] 40%|███▉      | 5087/12825 [18:08:12<28:44:59, 13.38s/it] 40%|███▉      | 5088/12825 [18:08:25<28:11:49, 13.12s/it] 40%|███▉      | 5089/12825 [18:08:37<27:48:05, 12.94s/it] 40%|███▉      | 5090/12825 [18:08:50<27:31:45, 12.81s/it] 40%|███▉      | 5091/12825 [18:09:02<27:19:37, 12.72s/it] 40%|███▉      | 5092/12825 [18:09:15<27:11:22, 12.66s/it] 40%|███▉      | 5093/12825 [18:09:27<27:04:44, 12.61s/it] 40%|███▉      | 5094/12825 [18:09:40<26:59:53, 12.57s/it] 40%|███▉      | 5095/12825 [18:09:52<26:58:31, 12.56s/it] 40%|███▉      | 5096/12825 [18:10:05<26:57:10, 12.55s/it] 40%|███▉      | 5097/12825 [18:10:17<26:54:15, 12.53s/it] 40%|███▉      | 5098/12825 [18:10:30<26:50:14, 12.50s/it] 40%|███▉      | 5099/12825 [18:10:42<26:50:17, 12.51s/it] 40%|███▉      | 5100/12825 [18:10:55<26:49:02, 12.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120164.56lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103417.98lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5075] due to args.save_total_limit
 40%|███▉      | 5101/12825 [18:11:08<27:03:14, 12.61s/it] 40%|███▉      | 5102/12825 [18:11:20<26:59:37, 12.58s/it] 40%|███▉      | 5103/12825 [18:11:33<26:55:12, 12.55s/it] 40%|███▉      | 5104/12825 [18:11:45<26:52:33, 12.53s/it] 40%|███▉      | 5105/12825 [18:11:58<26:50:19, 12.52s/it] 40%|███▉      | 5106/12825 [18:12:10<26:51:06, 12.52s/it] 40%|███▉      | 5107/12825 [18:12:23<26:50:36, 12.52s/it] 40%|███▉      | 5108/12825 [18:12:35<26:48:33, 12.51s/it] 40%|███▉      | 5109/12825 [18:12:48<26:48:04, 12.50s/it] 40%|███▉      | 5110/12825 [18:13:00<26:47:00, 12.50s/it] 40%|███▉      | 5111/12825 [18:13:13<26:45:06, 12.48s/it] 40%|███▉      | 5112/12825 [18:13:25<26:44:39, 12.48s/it] 40%|███▉      | 5113/12825 [18:13:38<26:45:03, 12.49s/it] 40%|███▉      | 5114/12825 [18:13:50<26:45:11, 12.49s/it] 40%|███▉      | 5115/12825 [18:14:03<26:45:40, 12.50s/it] 40%|███▉      | 5116/12825 [18:14:23<31:37:36, 14.77s/it] 40%|███▉      | 5117/12825 [18:14:35<30:09:29, 14.09s/it] 40%|███▉      | 5118/12825 [18:14:48<29:07:37, 13.61s/it] 40%|███▉      | 5119/12825 [18:15:00<28:23:52, 13.27s/it] 40%|███▉      | 5120/12825 [18:15:13<27:53:22, 13.03s/it] 40%|███▉      | 5121/12825 [18:15:25<27:32:38, 12.87s/it] 40%|███▉      | 5122/12825 [18:15:38<27:17:28, 12.75s/it] 40%|███▉      | 5123/12825 [18:15:50<27:07:22, 12.68s/it] 40%|███▉      | 5124/12825 [18:16:03<26:59:01, 12.61s/it] 40%|███▉      | 5125/12825 [18:16:15<26:54:29, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120225.03lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103500.12lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5100] due to args.save_total_limit
 40%|███▉      | 5126/12825 [18:16:28<27:04:52, 12.66s/it] 40%|███▉      | 5127/12825 [18:16:40<26:56:56, 12.60s/it] 40%|███▉      | 5128/12825 [18:16:53<26:52:32, 12.57s/it] 40%|███▉      | 5129/12825 [18:17:01<23:50:23, 11.15s/it] 40%|████      | 5130/12825 [18:17:02<17:12:47,  8.05s/it] 40%|████      | 5131/12825 [18:17:27<28:17:12, 13.24s/it] 40%|████      | 5132/12825 [18:17:39<27:50:24, 13.03s/it] 40%|████      | 5133/12825 [18:17:52<27:30:44, 12.88s/it] 40%|████      | 5134/12825 [18:18:05<27:16:42, 12.77s/it] 40%|████      | 5135/12825 [18:18:17<27:06:56, 12.69s/it] 40%|████      | 5136/12825 [18:18:30<26:59:43, 12.64s/it] 40%|████      | 5137/12825 [18:18:42<26:56:06, 12.61s/it] 40%|████      | 5138/12825 [18:18:55<26:51:44, 12.58s/it] 40%|████      | 5139/12825 [18:19:07<26:49:49, 12.57s/it] 40%|████      | 5140/12825 [18:19:20<26:48:48, 12.56s/it] 40%|████      | 5141/12825 [18:19:32<26:48:20, 12.56s/it] 40%|████      | 5142/12825 [18:19:45<26:45:42, 12.54s/it] 40%|████      | 5143/12825 [18:19:57<26:44:25, 12.53s/it] 40%|████      | 5144/12825 [18:20:10<26:43:25, 12.53s/it] 40%|████      | 5145/12825 [18:20:22<26:43:23, 12.53s/it] 40%|████      | 5146/12825 [18:20:35<26:43:02, 12.53s/it] 40%|████      | 5147/12825 [18:20:47<26:42:37, 12.52s/it] 40%|████      | 5148/12825 [18:21:00<26:42:05, 12.52s/it] 40%|████      | 5149/12825 [18:21:21<32:19:28, 15.16s/it] 40%|████      | 5150/12825 [18:21:34<30:38:13, 14.37s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120237.80lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103461.45lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-4700] due to args.save_total_limit
 40%|████      | 5151/12825 [18:21:47<29:38:10, 13.90s/it] 40%|████      | 5152/12825 [18:21:59<28:45:10, 13.49s/it] 40%|████      | 5153/12825 [18:22:12<28:07:15, 13.20s/it] 40%|████      | 5154/12825 [18:22:24<27:40:24, 12.99s/it] 40%|████      | 5155/12825 [18:22:37<27:22:30, 12.85s/it] 40%|████      | 5156/12825 [18:22:49<27:08:40, 12.74s/it] 40%|████      | 5157/12825 [18:23:02<26:58:28, 12.66s/it] 40%|████      | 5158/12825 [18:23:14<26:52:44, 12.62s/it] 40%|████      | 5159/12825 [18:23:27<26:47:48, 12.58s/it] 40%|████      | 5160/12825 [18:23:39<26:44:49, 12.56s/it] 40%|████      | 5161/12825 [18:23:52<26:42:24, 12.54s/it] 40%|████      | 5162/12825 [18:24:04<26:40:32, 12.53s/it] 40%|████      | 5163/12825 [18:24:17<26:40:30, 12.53s/it] 40%|████      | 5164/12825 [18:24:29<26:39:54, 12.53s/it] 40%|████      | 5165/12825 [18:24:42<26:38:27, 12.52s/it] 40%|████      | 5166/12825 [18:24:54<26:38:59, 12.53s/it] 40%|████      | 5167/12825 [18:25:07<26:38:09, 12.52s/it] 40%|████      | 5168/12825 [18:25:19<26:37:47, 12.52s/it] 40%|████      | 5169/12825 [18:25:32<26:37:26, 12.52s/it] 40%|████      | 5170/12825 [18:25:44<26:36:35, 12.51s/it] 40%|████      | 5171/12825 [18:25:57<26:36:06, 12.51s/it] 40%|████      | 5172/12825 [18:26:09<26:37:18, 12.52s/it] 40%|████      | 5173/12825 [18:26:22<26:38:14, 12.53s/it] 40%|████      | 5174/12825 [18:26:34<26:36:43, 12.52s/it] 40%|████      | 5175/12825 [18:26:47<26:34:29, 12.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120262.18lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103507.12lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5125] due to args.save_total_limit
 40%|████      | 5176/12825 [18:27:00<26:47:03, 12.61s/it] 40%|████      | 5177/12825 [18:27:12<26:43:22, 12.58s/it] 40%|████      | 5178/12825 [18:27:25<26:39:35, 12.55s/it] 40%|████      | 5179/12825 [18:27:37<26:37:17, 12.53s/it] 40%|████      | 5180/12825 [18:27:50<26:35:19, 12.52s/it] 40%|████      | 5181/12825 [18:28:10<31:36:12, 14.88s/it] 40%|████      | 5182/12825 [18:28:23<30:05:20, 14.17s/it] 40%|████      | 5183/12825 [18:28:35<28:59:55, 13.66s/it] 40%|████      | 5184/12825 [18:28:48<28:16:47, 13.32s/it] 40%|████      | 5185/12825 [18:29:00<27:44:11, 13.07s/it] 40%|████      | 5186/12825 [18:29:13<27:22:39, 12.90s/it] 40%|████      | 5187/12825 [18:29:25<27:06:25, 12.78s/it] 40%|████      | 5188/12825 [18:29:38<26:56:11, 12.70s/it] 40%|████      | 5189/12825 [18:29:50<26:47:34, 12.63s/it] 40%|████      | 5190/12825 [18:30:03<26:49:20, 12.65s/it] 40%|████      | 5191/12825 [18:30:15<26:46:59, 12.63s/it] 40%|████      | 5192/12825 [18:30:28<26:42:19, 12.60s/it] 40%|████      | 5193/12825 [18:30:40<26:41:51, 12.59s/it] 40%|████      | 5194/12825 [18:30:53<26:37:29, 12.56s/it] 41%|████      | 5195/12825 [18:31:05<26:34:54, 12.54s/it] 41%|████      | 5196/12825 [18:31:18<26:32:44, 12.53s/it] 41%|████      | 5197/12825 [18:31:30<26:30:58, 12.51s/it] 41%|████      | 5198/12825 [18:31:43<26:27:07, 12.49s/it] 41%|████      | 5199/12825 [18:31:55<26:25:51, 12.48s/it] 41%|████      | 5200/12825 [18:32:08<26:26:10, 12.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120164.05lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103442.17lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5150] due to args.save_total_limit
 41%|████      | 5201/12825 [18:32:21<26:39:45, 12.59s/it] 41%|████      | 5202/12825 [18:32:33<26:33:58, 12.55s/it] 41%|████      | 5203/12825 [18:32:46<26:32:35, 12.54s/it] 41%|████      | 5204/12825 [18:32:58<26:29:40, 12.52s/it] 41%|████      | 5205/12825 [18:33:10<26:27:47, 12.50s/it] 41%|████      | 5206/12825 [18:33:23<26:26:52, 12.50s/it] 41%|████      | 5207/12825 [18:33:35<26:27:27, 12.50s/it] 41%|████      | 5208/12825 [18:33:48<26:28:05, 12.51s/it] 41%|████      | 5209/12825 [18:34:01<26:28:59, 12.52s/it] 41%|████      | 5210/12825 [18:34:13<26:26:38, 12.50s/it] 41%|████      | 5211/12825 [18:34:25<26:26:31, 12.50s/it] 41%|████      | 5212/12825 [18:34:38<26:25:46, 12.50s/it] 41%|████      | 5213/12825 [18:34:50<26:25:08, 12.49s/it] 41%|████      | 5214/12825 [18:35:11<31:24:12, 14.85s/it] 41%|████      | 5215/12825 [18:35:23<29:55:44, 14.16s/it] 41%|████      | 5216/12825 [18:35:36<28:53:23, 13.67s/it] 41%|████      | 5217/12825 [18:35:48<28:09:32, 13.32s/it] 41%|████      | 5218/12825 [18:36:01<27:37:20, 13.07s/it] 41%|████      | 5219/12825 [18:36:13<27:15:53, 12.90s/it] 41%|████      | 5220/12825 [18:36:26<27:00:31, 12.79s/it] 41%|████      | 5221/12825 [18:36:38<26:49:20, 12.70s/it] 41%|████      | 5222/12825 [18:36:51<26:41:48, 12.64s/it] 41%|████      | 5223/12825 [18:37:03<26:35:10, 12.59s/it] 41%|████      | 5224/12825 [18:37:16<26:32:27, 12.57s/it] 41%|████      | 5225/12825 [18:37:28<26:30:58, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120269.21lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103553.97lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5175] due to args.save_total_limit
 41%|████      | 5226/12825 [18:37:41<26:42:15, 12.65s/it] 41%|████      | 5227/12825 [18:37:54<26:37:02, 12.61s/it] 41%|████      | 5228/12825 [18:38:06<26:32:00, 12.57s/it] 41%|████      | 5229/12825 [18:38:19<26:27:58, 12.54s/it] 41%|████      | 5230/12825 [18:38:31<26:26:17, 12.53s/it] 41%|████      | 5231/12825 [18:38:44<26:25:05, 12.52s/it] 41%|████      | 5232/12825 [18:38:56<26:24:33, 12.52s/it] 41%|████      | 5233/12825 [18:39:09<26:23:10, 12.51s/it] 41%|████      | 5234/12825 [18:39:21<26:22:26, 12.51s/it] 41%|████      | 5235/12825 [18:39:34<26:20:57, 12.50s/it] 41%|████      | 5236/12825 [18:39:46<26:23:21, 12.52s/it] 41%|████      | 5237/12825 [18:39:59<26:23:26, 12.52s/it] 41%|████      | 5238/12825 [18:40:11<26:23:42, 12.52s/it] 41%|████      | 5239/12825 [18:40:24<26:23:47, 12.53s/it] 41%|████      | 5240/12825 [18:40:36<26:22:42, 12.52s/it] 41%|████      | 5241/12825 [18:40:49<26:21:54, 12.52s/it] 41%|████      | 5242/12825 [18:41:01<26:22:06, 12.52s/it] 41%|████      | 5243/12825 [18:41:14<26:22:47, 12.53s/it] 41%|████      | 5244/12825 [18:41:27<26:22:12, 12.52s/it] 41%|████      | 5245/12825 [18:41:39<26:21:12, 12.52s/it] 41%|████      | 5246/12825 [18:41:59<31:13:45, 14.83s/it] 41%|████      | 5247/12825 [18:42:12<29:45:46, 14.14s/it] 41%|████      | 5248/12825 [18:42:24<28:44:04, 13.65s/it] 41%|████      | 5249/12825 [18:42:37<28:00:35, 13.31s/it] 41%|████      | 5250/12825 [18:42:49<27:30:14, 13.07s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120006.54lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103344.94lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5225] due to args.save_total_limit
 41%|████      | 5251/12825 [18:43:02<27:21:58, 13.01s/it] 41%|████      | 5252/12825 [18:43:15<27:05:20, 12.88s/it] 41%|████      | 5253/12825 [18:43:27<26:50:21, 12.76s/it] 41%|████      | 5254/12825 [18:43:40<26:41:29, 12.69s/it] 41%|████      | 5255/12825 [18:43:52<26:39:37, 12.68s/it] 41%|████      | 5256/12825 [18:44:05<26:35:08, 12.64s/it] 41%|████      | 5257/12825 [18:44:17<26:29:20, 12.60s/it] 41%|████      | 5258/12825 [18:44:30<26:26:53, 12.58s/it] 41%|████      | 5259/12825 [18:44:43<26:25:56, 12.58s/it] 41%|████      | 5260/12825 [18:44:55<26:24:07, 12.56s/it] 41%|████      | 5261/12825 [18:45:08<26:22:28, 12.55s/it] 41%|████      | 5262/12825 [18:45:20<26:21:54, 12.55s/it] 41%|████      | 5263/12825 [18:45:33<26:19:31, 12.53s/it] 41%|████      | 5264/12825 [18:45:45<26:18:30, 12.53s/it] 41%|████      | 5265/12825 [18:45:58<26:20:10, 12.54s/it] 41%|████      | 5266/12825 [18:46:10<26:20:57, 12.55s/it] 41%|████      | 5267/12825 [18:46:23<26:18:53, 12.53s/it] 41%|████      | 5268/12825 [18:46:35<26:19:22, 12.54s/it] 41%|████      | 5269/12825 [18:46:48<26:19:24, 12.54s/it] 41%|████      | 5270/12825 [18:47:00<26:19:22, 12.54s/it] 41%|████      | 5271/12825 [18:47:13<26:19:15, 12.54s/it] 41%|████      | 5272/12825 [18:47:26<26:17:32, 12.53s/it] 41%|████      | 5273/12825 [18:47:38<26:17:18, 12.53s/it] 41%|████      | 5274/12825 [18:47:51<26:17:05, 12.53s/it] 41%|████      | 5275/12825 [18:48:03<26:16:14, 12.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120175.02lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103508.07lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5200] due to args.save_total_limit
 41%|████      | 5276/12825 [18:48:16<26:26:37, 12.61s/it] 41%|████      | 5277/12825 [18:48:28<26:21:15, 12.57s/it] 41%|████      | 5278/12825 [18:48:49<31:06:23, 14.84s/it] 41%|████      | 5279/12825 [18:49:01<29:38:23, 14.14s/it] 41%|████      | 5280/12825 [18:49:14<28:36:47, 13.65s/it] 41%|████      | 5281/12825 [18:49:26<27:51:46, 13.30s/it] 41%|████      | 5282/12825 [18:49:38<27:20:43, 13.05s/it] 41%|████      | 5283/12825 [18:49:51<26:59:56, 12.89s/it] 41%|████      | 5284/12825 [18:50:03<26:45:31, 12.77s/it] 41%|████      | 5285/12825 [18:50:16<26:35:58, 12.70s/it] 41%|████      | 5286/12825 [18:50:29<26:30:17, 12.66s/it] 41%|████      | 5287/12825 [18:50:41<26:24:43, 12.61s/it] 41%|████      | 5288/12825 [18:50:54<26:21:54, 12.59s/it] 41%|████      | 5289/12825 [18:51:06<26:17:23, 12.56s/it] 41%|████      | 5290/12825 [18:51:19<26:16:30, 12.55s/it] 41%|████▏     | 5291/12825 [18:51:31<26:15:21, 12.55s/it] 41%|████▏     | 5292/12825 [18:51:44<26:14:19, 12.54s/it] 41%|████▏     | 5293/12825 [18:51:56<26:13:12, 12.53s/it] 41%|████▏     | 5294/12825 [18:52:09<26:13:45, 12.54s/it] 41%|████▏     | 5295/12825 [18:52:21<26:12:27, 12.53s/it] 41%|████▏     | 5296/12825 [18:52:34<26:12:51, 12.53s/it] 41%|████▏     | 5297/12825 [18:52:46<26:11:30, 12.53s/it] 41%|████▏     | 5298/12825 [18:52:59<26:11:10, 12.52s/it] 41%|████▏     | 5299/12825 [18:53:11<26:11:05, 12.53s/it] 41%|████▏     | 5300/12825 [18:53:24<26:11:00, 12.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120219.16lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103495.77lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5250] due to args.save_total_limit
 41%|████▏     | 5301/12825 [18:53:37<26:22:46, 12.62s/it] 41%|████▏     | 5302/12825 [18:53:49<26:17:18, 12.58s/it] 41%|████▏     | 5303/12825 [18:54:02<26:15:13, 12.56s/it] 41%|████▏     | 5304/12825 [18:54:14<26:12:24, 12.54s/it] 41%|████▏     | 5305/12825 [18:54:27<26:11:02, 12.53s/it] 41%|████▏     | 5306/12825 [18:54:39<26:10:08, 12.53s/it] 41%|████▏     | 5307/12825 [18:54:53<26:53:55, 12.88s/it] 41%|████▏     | 5308/12825 [18:55:05<26:39:11, 12.76s/it] 41%|████▏     | 5309/12825 [18:55:18<26:28:59, 12.68s/it] 41%|████▏     | 5310/12825 [18:55:31<26:22:46, 12.64s/it] 41%|████▏     | 5311/12825 [18:55:51<31:07:24, 14.91s/it] 41%|████▏     | 5312/12825 [18:56:03<29:38:40, 14.20s/it] 41%|████▏     | 5313/12825 [18:56:16<28:35:45, 13.70s/it] 41%|████▏     | 5314/12825 [18:56:28<27:50:46, 13.35s/it] 41%|████▏     | 5315/12825 [18:56:41<27:20:26, 13.11s/it] 41%|████▏     | 5316/12825 [18:56:53<26:59:30, 12.94s/it] 41%|████▏     | 5317/12825 [18:57:06<26:45:14, 12.83s/it] 41%|████▏     | 5318/12825 [18:57:19<26:33:18, 12.73s/it] 41%|████▏     | 5319/12825 [18:57:31<26:26:03, 12.68s/it] 41%|████▏     | 5320/12825 [18:57:44<26:21:25, 12.64s/it] 41%|████▏     | 5321/12825 [18:57:56<26:17:04, 12.61s/it] 41%|████▏     | 5322/12825 [18:58:09<26:14:26, 12.59s/it] 42%|████▏     | 5323/12825 [18:58:21<26:12:28, 12.58s/it] 42%|████▏     | 5324/12825 [18:58:34<26:11:14, 12.57s/it] 42%|████▏     | 5325/12825 [18:58:46<26:10:07, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 51773.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 48400.66lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5275] due to args.save_total_limit
 42%|████▏     | 5326/12825 [18:59:00<26:35:03, 12.76s/it] 42%|████▏     | 5327/12825 [18:59:12<26:23:26, 12.67s/it] 42%|████▏     | 5328/12825 [18:59:25<26:17:12, 12.62s/it] 42%|████▏     | 5329/12825 [18:59:37<26:14:04, 12.60s/it] 42%|████▏     | 5330/12825 [18:59:50<26:10:47, 12.57s/it] 42%|████▏     | 5331/12825 [19:00:02<26:09:09, 12.56s/it] 42%|████▏     | 5332/12825 [19:00:15<26:06:32, 12.54s/it] 42%|████▏     | 5333/12825 [19:00:27<26:04:52, 12.53s/it] 42%|████▏     | 5334/12825 [19:00:40<26:04:59, 12.53s/it] 42%|████▏     | 5335/12825 [19:00:52<26:04:22, 12.53s/it] 42%|████▏     | 5336/12825 [19:01:05<26:04:18, 12.53s/it] 42%|████▏     | 5337/12825 [19:01:17<26:05:31, 12.54s/it] 42%|████▏     | 5338/12825 [19:01:30<26:04:27, 12.54s/it] 42%|████▏     | 5339/12825 [19:01:42<26:03:38, 12.53s/it] 42%|████▏     | 5340/12825 [19:01:55<26:03:21, 12.53s/it] 42%|████▏     | 5341/12825 [19:02:07<26:03:33, 12.54s/it] 42%|████▏     | 5342/12825 [19:02:20<26:02:23, 12.53s/it] 42%|████▏     | 5343/12825 [19:02:40<30:58:18, 14.90s/it] 42%|████▏     | 5344/12825 [19:02:53<29:29:18, 14.19s/it] 42%|████▏     | 5345/12825 [19:03:05<28:26:01, 13.68s/it] 42%|████▏     | 5346/12825 [19:03:18<27:42:52, 13.34s/it] 42%|████▏     | 5347/12825 [19:03:31<27:13:04, 13.10s/it] 42%|████▏     | 5348/12825 [19:03:43<26:49:59, 12.92s/it] 42%|████▏     | 5349/12825 [19:03:56<26:34:19, 12.80s/it] 42%|████▏     | 5350/12825 [19:04:08<26:25:08, 12.72s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120090.91lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103408.26lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5325] due to args.save_total_limit
 42%|████▏     | 5351/12825 [19:04:21<26:30:05, 12.77s/it] 42%|████▏     | 5352/12825 [19:04:33<26:22:35, 12.71s/it] 42%|████▏     | 5353/12825 [19:04:46<26:15:50, 12.65s/it] 42%|████▏     | 5354/12825 [19:04:59<26:12:01, 12.62s/it] 42%|████▏     | 5355/12825 [19:05:11<26:08:44, 12.60s/it] 42%|████▏     | 5356/12825 [19:05:24<26:07:06, 12.59s/it] 42%|████▏     | 5357/12825 [19:05:36<26:04:51, 12.57s/it] 42%|████▏     | 5358/12825 [19:05:49<26:03:49, 12.57s/it] 42%|████▏     | 5359/12825 [19:06:01<26:03:52, 12.57s/it] 42%|████▏     | 5360/12825 [19:06:14<26:03:32, 12.57s/it] 42%|████▏     | 5361/12825 [19:06:26<26:02:38, 12.56s/it] 42%|████▏     | 5362/12825 [19:06:39<26:01:20, 12.55s/it] 42%|████▏     | 5363/12825 [19:06:52<26:00:27, 12.55s/it] 42%|████▏     | 5364/12825 [19:07:04<26:00:26, 12.55s/it] 42%|████▏     | 5365/12825 [19:07:17<25:58:35, 12.54s/it] 42%|████▏     | 5366/12825 [19:07:29<25:57:41, 12.53s/it] 42%|████▏     | 5367/12825 [19:07:42<25:57:23, 12.53s/it] 42%|████▏     | 5368/12825 [19:07:54<25:57:12, 12.53s/it] 42%|████▏     | 5369/12825 [19:08:07<25:57:42, 12.54s/it] 42%|████▏     | 5370/12825 [19:08:19<25:57:41, 12.54s/it] 42%|████▏     | 5371/12825 [19:08:32<25:57:29, 12.54s/it] 42%|████▏     | 5372/12825 [19:08:44<25:56:29, 12.53s/it] 42%|████▏     | 5373/12825 [19:08:57<25:59:55, 12.56s/it] 42%|████▏     | 5374/12825 [19:09:09<25:59:55, 12.56s/it] 42%|████▏     | 5375/12825 [19:09:30<30:58:51, 14.97s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120315.08lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103623.62lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5350] due to args.save_total_limit
 42%|████▏     | 5376/12825 [19:09:43<29:42:33, 14.36s/it] 42%|████▏     | 5377/12825 [19:09:56<28:35:51, 13.82s/it] 42%|████▏     | 5378/12825 [19:10:08<27:47:28, 13.43s/it] 42%|████▏     | 5379/12825 [19:10:21<27:14:23, 13.17s/it] 42%|████▏     | 5380/12825 [19:10:33<26:50:17, 12.98s/it] 42%|████▏     | 5381/12825 [19:10:46<26:34:28, 12.85s/it] 42%|████▏     | 5382/12825 [19:10:58<26:22:41, 12.76s/it] 42%|████▏     | 5383/12825 [19:11:11<26:15:01, 12.70s/it] 42%|████▏     | 5384/12825 [19:11:23<26:08:56, 12.65s/it] 42%|████▏     | 5385/12825 [19:11:36<26:04:24, 12.62s/it] 42%|████▏     | 5386/12825 [19:11:48<26:02:21, 12.60s/it] 42%|████▏     | 5387/12825 [19:12:01<25:59:36, 12.58s/it] 42%|████▏     | 5388/12825 [19:12:14<25:58:55, 12.58s/it] 42%|████▏     | 5389/12825 [19:12:26<25:59:01, 12.58s/it] 42%|████▏     | 5390/12825 [19:12:39<25:59:47, 12.59s/it] 42%|████▏     | 5391/12825 [19:12:51<25:57:42, 12.57s/it] 42%|████▏     | 5392/12825 [19:13:04<25:56:55, 12.57s/it] 42%|████▏     | 5393/12825 [19:13:16<25:57:28, 12.57s/it] 42%|████▏     | 5394/12825 [19:13:29<25:56:59, 12.57s/it] 42%|████▏     | 5395/12825 [19:13:42<25:56:14, 12.57s/it] 42%|████▏     | 5396/12825 [19:13:54<25:56:30, 12.57s/it] 42%|████▏     | 5397/12825 [19:14:07<25:55:17, 12.56s/it] 42%|████▏     | 5398/12825 [19:14:19<25:54:05, 12.55s/it] 42%|████▏     | 5399/12825 [19:14:32<25:53:43, 12.55s/it] 42%|████▏     | 5400/12825 [19:14:45<26:02:15, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120216.10lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103268.32lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5375] due to args.save_total_limit
 42%|████▏     | 5401/12825 [19:14:57<26:11:26, 12.70s/it] 42%|████▏     | 5402/12825 [19:15:10<26:04:20, 12.64s/it] 42%|████▏     | 5403/12825 [19:15:23<26:02:10, 12.63s/it] 42%|████▏     | 5404/12825 [19:15:35<25:59:11, 12.61s/it] 42%|████▏     | 5405/12825 [19:15:48<25:57:04, 12.59s/it] 42%|████▏     | 5406/12825 [19:16:00<25:54:33, 12.57s/it] 42%|████▏     | 5407/12825 [19:16:21<30:53:06, 14.99s/it] 42%|████▏     | 5408/12825 [19:16:33<29:23:56, 14.27s/it] 42%|████▏     | 5409/12825 [19:16:46<28:18:57, 13.75s/it] 42%|████▏     | 5410/12825 [19:16:59<27:34:59, 13.39s/it] 42%|████▏     | 5411/12825 [19:17:11<27:02:37, 13.13s/it] 42%|████▏     | 5412/12825 [19:17:24<26:40:48, 12.96s/it] 42%|████▏     | 5413/12825 [19:17:36<26:23:23, 12.82s/it] 42%|████▏     | 5414/12825 [19:17:49<26:13:14, 12.74s/it] 42%|████▏     | 5415/12825 [19:18:01<26:07:37, 12.69s/it] 42%|████▏     | 5416/12825 [19:18:14<26:04:14, 12.67s/it] 42%|████▏     | 5417/12825 [19:18:26<26:00:48, 12.64s/it] 42%|████▏     | 5418/12825 [19:18:39<25:57:43, 12.62s/it] 42%|████▏     | 5419/12825 [19:18:52<25:56:02, 12.61s/it] 42%|████▏     | 5420/12825 [19:19:04<25:52:42, 12.58s/it] 42%|████▏     | 5421/12825 [19:19:17<25:49:46, 12.56s/it] 42%|████▏     | 5422/12825 [19:19:29<25:48:30, 12.55s/it] 42%|████▏     | 5423/12825 [19:19:42<25:49:03, 12.56s/it] 42%|████▏     | 5424/12825 [19:19:54<25:47:28, 12.55s/it] 42%|████▏     | 5425/12825 [19:20:07<25:46:59, 12.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120177.06lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103568.56lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5400] due to args.save_total_limit
 42%|████▏     | 5426/12825 [19:20:20<25:59:41, 12.65s/it] 42%|████▏     | 5427/12825 [19:20:32<25:54:05, 12.60s/it] 42%|████▏     | 5428/12825 [19:20:45<25:52:13, 12.59s/it] 42%|████▏     | 5429/12825 [19:20:57<25:49:53, 12.57s/it] 42%|████▏     | 5430/12825 [19:21:10<25:48:38, 12.56s/it] 42%|████▏     | 5431/12825 [19:21:22<25:46:39, 12.55s/it] 42%|████▏     | 5432/12825 [19:21:35<25:46:12, 12.55s/it] 42%|████▏     | 5433/12825 [19:21:47<25:45:30, 12.54s/it] 42%|████▏     | 5434/12825 [19:22:00<25:45:24, 12.55s/it] 42%|████▏     | 5435/12825 [19:22:12<25:45:02, 12.54s/it] 42%|████▏     | 5436/12825 [19:22:25<25:44:01, 12.54s/it] 42%|████▏     | 5437/12825 [19:22:38<25:43:18, 12.53s/it] 42%|████▏     | 5438/12825 [19:22:50<25:42:15, 12.53s/it] 42%|████▏     | 5439/12825 [19:23:03<25:42:28, 12.53s/it] 42%|████▏     | 5440/12825 [19:23:23<30:31:13, 14.88s/it] 42%|████▏     | 5441/12825 [19:23:35<29:05:50, 14.19s/it] 42%|████▏     | 5442/12825 [19:23:48<28:04:49, 13.69s/it] 42%|████▏     | 5443/12825 [19:24:01<27:22:17, 13.35s/it] 42%|████▏     | 5444/12825 [19:24:13<26:51:50, 13.10s/it] 42%|████▏     | 5445/12825 [19:24:26<26:31:59, 12.94s/it] 42%|████▏     | 5446/12825 [19:24:38<26:17:12, 12.82s/it] 42%|████▏     | 5447/12825 [19:24:51<26:07:48, 12.75s/it] 42%|████▏     | 5448/12825 [19:25:03<26:05:38, 12.73s/it] 42%|████▏     | 5449/12825 [19:25:16<26:02:41, 12.71s/it] 42%|████▏     | 5450/12825 [19:25:29<25:59:53, 12.69s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120216.73lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103457.10lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5425] due to args.save_total_limit
 43%|████▎     | 5451/12825 [19:25:42<26:13:00, 12.80s/it] 43%|████▎     | 5452/12825 [19:25:54<26:07:10, 12.75s/it] 43%|████▎     | 5453/12825 [19:26:07<26:02:59, 12.72s/it] 43%|████▎     | 5454/12825 [19:26:20<26:00:15, 12.70s/it] 43%|████▎     | 5455/12825 [19:26:32<25:59:42, 12.70s/it] 43%|████▎     | 5456/12825 [19:26:45<25:56:07, 12.67s/it] 43%|████▎     | 5457/12825 [19:26:58<25:50:01, 12.62s/it] 43%|████▎     | 5458/12825 [19:27:10<25:45:23, 12.59s/it] 43%|████▎     | 5459/12825 [19:27:23<25:43:27, 12.57s/it] 43%|████▎     | 5460/12825 [19:27:35<25:40:24, 12.55s/it] 43%|████▎     | 5461/12825 [19:27:48<25:38:05, 12.53s/it] 43%|████▎     | 5462/12825 [19:28:00<25:37:35, 12.53s/it] 43%|████▎     | 5463/12825 [19:28:13<25:37:29, 12.53s/it] 43%|████▎     | 5464/12825 [19:28:25<25:36:18, 12.52s/it] 43%|████▎     | 5465/12825 [19:28:38<25:35:09, 12.51s/it] 43%|████▎     | 5466/12825 [19:28:50<25:35:43, 12.52s/it] 43%|████▎     | 5467/12825 [19:29:03<25:36:14, 12.53s/it] 43%|████▎     | 5468/12825 [19:29:15<25:36:07, 12.53s/it] 43%|████▎     | 5469/12825 [19:29:28<25:37:20, 12.54s/it] 43%|████▎     | 5470/12825 [19:29:40<25:36:50, 12.54s/it] 43%|████▎     | 5471/12825 [19:29:53<25:35:50, 12.53s/it] 43%|████▎     | 5472/12825 [19:30:13<30:12:52, 14.79s/it] 43%|████▎     | 5473/12825 [19:30:26<28:49:43, 14.12s/it] 43%|████▎     | 5474/12825 [19:30:38<27:50:54, 13.64s/it] 43%|████▎     | 5475/12825 [19:30:51<27:09:42, 13.30s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120350.11lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103562.11lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5450] due to args.save_total_limit
 43%|████▎     | 5476/12825 [19:31:03<26:50:49, 13.15s/it] 43%|████▎     | 5477/12825 [19:31:16<26:27:25, 12.96s/it] 43%|████▎     | 5478/12825 [19:31:28<26:11:57, 12.84s/it] 43%|████▎     | 5479/12825 [19:31:41<25:59:48, 12.74s/it] 43%|████▎     | 5480/12825 [19:31:53<25:52:42, 12.68s/it] 43%|████▎     | 5481/12825 [19:32:06<25:46:26, 12.63s/it] 43%|████▎     | 5482/12825 [19:32:19<25:42:20, 12.60s/it] 43%|████▎     | 5483/12825 [19:32:31<25:38:38, 12.57s/it] 43%|████▎     | 5484/12825 [19:32:44<25:36:00, 12.55s/it] 43%|████▎     | 5485/12825 [19:32:56<25:37:09, 12.57s/it] 43%|████▎     | 5486/12825 [19:33:09<25:36:05, 12.56s/it] 43%|████▎     | 5487/12825 [19:33:21<25:35:05, 12.55s/it] 43%|████▎     | 5488/12825 [19:33:34<25:33:45, 12.54s/it] 43%|████▎     | 5489/12825 [19:33:46<25:31:57, 12.53s/it] 43%|████▎     | 5490/12825 [19:33:59<25:30:45, 12.52s/it] 43%|████▎     | 5491/12825 [19:34:11<25:30:21, 12.52s/it] 43%|████▎     | 5492/12825 [19:34:24<25:30:57, 12.53s/it] 43%|████▎     | 5493/12825 [19:34:36<25:29:03, 12.51s/it] 43%|████▎     | 5494/12825 [19:34:49<25:29:20, 12.52s/it] 43%|████▎     | 5495/12825 [19:35:01<25:29:07, 12.52s/it] 43%|████▎     | 5496/12825 [19:35:14<25:27:32, 12.51s/it] 43%|████▎     | 5497/12825 [19:35:26<25:28:04, 12.51s/it] 43%|████▎     | 5498/12825 [19:35:39<25:27:27, 12.51s/it] 43%|████▎     | 5499/12825 [19:35:51<25:28:14, 12.52s/it] 43%|████▎     | 5500/12825 [19:36:04<25:28:18, 12.52s/it]                                                           43%|████▎     | 5500/12825 [19:36:04<25:28:18, 12.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120332.85lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103521.79lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5475] due to args.save_total_limit
 43%|████▎     | 5501/12825 [19:36:17<25:42:09, 12.63s/it] 43%|████▎     | 5502/12825 [19:36:29<25:37:54, 12.60s/it] 43%|████▎     | 5503/12825 [19:36:42<25:34:25, 12.57s/it] 43%|████▎     | 5504/12825 [19:36:54<25:31:08, 12.55s/it] 43%|████▎     | 5505/12825 [19:37:15<30:27:45, 14.98s/it] 43%|████▎     | 5506/12825 [19:37:28<28:57:28, 14.24s/it] 43%|████▎     | 5507/12825 [19:37:40<27:53:27, 13.72s/it] 43%|████▎     | 5508/12825 [19:37:52<27:08:24, 13.35s/it] 43%|████▎     | 5509/12825 [19:38:05<26:38:01, 13.11s/it] 43%|████▎     | 5510/12825 [19:38:18<26:15:36, 12.92s/it] 43%|████▎     | 5511/12825 [19:38:30<26:00:53, 12.80s/it] 43%|████▎     | 5512/12825 [19:38:43<25:50:40, 12.72s/it] 43%|████▎     | 5513/12825 [19:38:55<25:44:09, 12.67s/it] 43%|████▎     | 5514/12825 [19:39:08<25:39:58, 12.64s/it] 43%|████▎     | 5515/12825 [19:39:20<25:34:49, 12.60s/it] 43%|████▎     | 5516/12825 [19:39:33<25:33:11, 12.59s/it] 43%|████▎     | 5517/12825 [19:39:45<25:31:45, 12.58s/it] 43%|████▎     | 5518/12825 [19:39:58<25:30:57, 12.57s/it] 43%|████▎     | 5519/12825 [19:40:10<25:29:03, 12.56s/it] 43%|████▎     | 5520/12825 [19:40:23<25:27:56, 12.55s/it] 43%|████▎     | 5521/12825 [19:40:35<25:26:48, 12.54s/it] 43%|████▎     | 5522/12825 [19:40:48<25:25:05, 12.53s/it] 43%|████▎     | 5523/12825 [19:41:00<25:25:14, 12.53s/it] 43%|████▎     | 5524/12825 [19:41:13<25:24:30, 12.53s/it] 43%|████▎     | 5525/12825 [19:41:26<25:25:19, 12.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120342.82lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103553.12lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5500] due to args.save_total_limit
 43%|████▎     | 5526/12825 [19:41:38<25:35:55, 12.63s/it] 43%|████▎     | 5527/12825 [19:41:51<25:32:58, 12.60s/it] 43%|████▎     | 5528/12825 [19:42:04<25:31:24, 12.59s/it] 43%|████▎     | 5529/12825 [19:42:16<25:27:55, 12.57s/it] 43%|████▎     | 5530/12825 [19:42:29<25:26:13, 12.55s/it] 43%|████▎     | 5531/12825 [19:42:41<25:25:41, 12.55s/it] 43%|████▎     | 5532/12825 [19:42:54<25:24:30, 12.54s/it] 43%|████▎     | 5533/12825 [19:43:06<25:25:51, 12.56s/it] 43%|████▎     | 5534/12825 [19:43:19<25:23:43, 12.54s/it] 43%|████▎     | 5535/12825 [19:43:31<25:24:06, 12.54s/it] 43%|████▎     | 5536/12825 [19:43:44<25:23:35, 12.54s/it] 43%|████▎     | 5537/12825 [19:44:05<30:24:50, 15.02s/it] 43%|████▎     | 5538/12825 [19:44:17<28:53:20, 14.27s/it] 43%|████▎     | 5539/12825 [19:44:30<27:48:47, 13.74s/it] 43%|████▎     | 5540/12825 [19:44:42<27:03:02, 13.37s/it] 43%|████▎     | 5541/12825 [19:44:55<26:31:48, 13.11s/it] 43%|████▎     | 5542/12825 [19:45:07<26:11:07, 12.94s/it] 43%|████▎     | 5543/12825 [19:45:20<25:56:07, 12.82s/it] 43%|████▎     | 5544/12825 [19:45:32<25:46:59, 12.75s/it] 43%|████▎     | 5545/12825 [19:45:45<25:38:49, 12.68s/it] 43%|████▎     | 5546/12825 [19:45:57<25:33:12, 12.64s/it] 43%|████▎     | 5547/12825 [19:46:10<25:28:40, 12.60s/it] 43%|████▎     | 5548/12825 [19:46:22<25:25:29, 12.58s/it] 43%|████▎     | 5549/12825 [19:46:35<25:23:46, 12.57s/it] 43%|████▎     | 5550/12825 [19:46:47<25:22:29, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120251.46lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103447.46lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5525] due to args.save_total_limit
 43%|████▎     | 5551/12825 [19:47:00<25:33:58, 12.65s/it] 43%|████▎     | 5552/12825 [19:47:13<25:28:33, 12.61s/it] 43%|████▎     | 5553/12825 [19:47:25<25:24:59, 12.58s/it] 43%|████▎     | 5554/12825 [19:47:38<25:22:03, 12.56s/it] 43%|████▎     | 5555/12825 [19:47:50<25:21:20, 12.56s/it] 43%|████▎     | 5556/12825 [19:48:03<25:19:35, 12.54s/it] 43%|████▎     | 5557/12825 [19:48:15<25:18:39, 12.54s/it] 43%|████▎     | 5558/12825 [19:48:28<25:16:42, 12.52s/it] 43%|████▎     | 5559/12825 [19:48:41<25:18:05, 12.54s/it] 43%|████▎     | 5560/12825 [19:48:53<25:17:12, 12.53s/it] 43%|████▎     | 5561/12825 [19:49:06<25:16:55, 12.53s/it] 43%|████▎     | 5562/12825 [19:49:18<25:15:22, 12.52s/it] 43%|████▎     | 5563/12825 [19:49:31<25:15:56, 12.52s/it] 43%|████▎     | 5564/12825 [19:49:43<25:15:39, 12.52s/it] 43%|████▎     | 5565/12825 [19:49:56<25:16:38, 12.53s/it] 43%|████▎     | 5566/12825 [19:50:08<25:16:03, 12.53s/it] 43%|████▎     | 5567/12825 [19:50:21<25:15:41, 12.53s/it] 43%|████▎     | 5568/12825 [19:50:33<25:15:37, 12.53s/it] 43%|████▎     | 5569/12825 [19:50:54<30:02:11, 14.90s/it] 43%|████▎     | 5570/12825 [19:51:06<28:34:46, 14.18s/it] 43%|████▎     | 5571/12825 [19:51:19<27:36:06, 13.70s/it] 43%|████▎     | 5572/12825 [19:51:31<26:54:18, 13.35s/it] 43%|████▎     | 5573/12825 [19:51:44<26:23:39, 13.10s/it] 43%|████▎     | 5574/12825 [19:51:56<26:02:32, 12.93s/it] 43%|████▎     | 5575/12825 [19:52:09<25:48:26, 12.81s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120236.77lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103523.49lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5550] due to args.save_total_limit
 43%|████▎     | 5576/12825 [19:52:22<25:49:31, 12.83s/it] 43%|████▎     | 5577/12825 [19:52:34<25:37:55, 12.73s/it] 43%|████▎     | 5578/12825 [19:52:47<25:29:50, 12.67s/it] 44%|████▎     | 5579/12825 [19:52:59<25:24:12, 12.62s/it] 44%|████▎     | 5580/12825 [19:53:12<25:20:31, 12.59s/it] 44%|████▎     | 5581/12825 [19:53:24<25:18:26, 12.58s/it] 44%|████▎     | 5582/12825 [19:53:37<25:15:58, 12.56s/it] 44%|████▎     | 5583/12825 [19:53:49<25:15:25, 12.56s/it] 44%|████▎     | 5584/12825 [19:54:02<25:13:49, 12.54s/it] 44%|████▎     | 5585/12825 [19:54:14<25:12:05, 12.53s/it] 44%|████▎     | 5586/12825 [19:54:27<25:11:09, 12.53s/it] 44%|████▎     | 5587/12825 [19:54:39<25:09:53, 12.52s/it] 44%|████▎     | 5588/12825 [19:54:52<25:11:23, 12.53s/it] 44%|████▎     | 5589/12825 [19:55:04<25:08:49, 12.51s/it] 44%|████▎     | 5590/12825 [19:55:17<25:11:27, 12.53s/it] 44%|████▎     | 5591/12825 [19:55:30<25:11:04, 12.53s/it] 44%|████▎     | 5592/12825 [19:55:42<25:11:52, 12.54s/it] 44%|████▎     | 5593/12825 [19:55:55<25:12:35, 12.55s/it] 44%|████▎     | 5594/12825 [19:56:07<25:12:32, 12.55s/it] 44%|████▎     | 5595/12825 [19:56:20<25:10:50, 12.54s/it] 44%|████▎     | 5596/12825 [19:56:32<25:09:11, 12.53s/it] 44%|████▎     | 5597/12825 [19:56:45<25:09:47, 12.53s/it] 44%|████▎     | 5598/12825 [19:56:57<25:08:43, 12.53s/it] 44%|████▎     | 5599/12825 [19:57:10<25:08:54, 12.53s/it] 44%|████▎     | 5600/12825 [19:57:22<25:07:54, 12.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120279.55lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 99886.23lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5300] due to args.save_total_limit
 44%|████▎     | 5601/12825 [19:57:35<25:28:15, 12.69s/it] 44%|████▎     | 5602/12825 [19:57:57<30:35:58, 15.25s/it] 44%|████▎     | 5603/12825 [19:58:09<28:57:05, 14.43s/it] 44%|████▎     | 5604/12825 [19:58:22<27:48:11, 13.86s/it] 44%|████▎     | 5605/12825 [19:58:34<26:59:33, 13.46s/it] 44%|████▎     | 5606/12825 [19:58:47<26:29:52, 13.21s/it] 44%|████▎     | 5607/12825 [19:58:59<26:06:18, 13.02s/it] 44%|████▎     | 5608/12825 [19:59:12<25:49:27, 12.88s/it] 44%|████▎     | 5609/12825 [19:59:25<25:36:10, 12.77s/it] 44%|████▎     | 5610/12825 [19:59:37<25:27:32, 12.70s/it] 44%|████▍     | 5611/12825 [19:59:50<25:24:15, 12.68s/it] 44%|████▍     | 5612/12825 [20:00:02<25:18:30, 12.63s/it] 44%|████▍     | 5613/12825 [20:00:15<25:15:22, 12.61s/it] 44%|████▍     | 5614/12825 [20:00:27<25:12:52, 12.59s/it] 44%|████▍     | 5615/12825 [20:00:40<25:09:59, 12.57s/it] 44%|████▍     | 5616/12825 [20:00:52<25:09:03, 12.56s/it] 44%|████▍     | 5617/12825 [20:01:05<25:09:14, 12.56s/it] 44%|████▍     | 5618/12825 [20:01:17<25:07:25, 12.55s/it] 44%|████▍     | 5619/12825 [20:01:30<25:08:04, 12.56s/it] 44%|████▍     | 5620/12825 [20:01:43<25:06:34, 12.55s/it] 44%|████▍     | 5621/12825 [20:01:55<25:08:16, 12.56s/it] 44%|████▍     | 5622/12825 [20:02:08<25:07:55, 12.56s/it] 44%|████▍     | 5623/12825 [20:02:20<25:06:56, 12.55s/it] 44%|████▍     | 5624/12825 [20:02:33<25:06:11, 12.55s/it] 44%|████▍     | 5625/12825 [20:02:45<25:05:23, 12.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120230.65lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103517.62lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5575] due to args.save_total_limit
 44%|████▍     | 5626/12825 [20:02:58<25:16:50, 12.64s/it] 44%|████▍     | 5627/12825 [20:03:11<25:12:26, 12.61s/it] 44%|████▍     | 5628/12825 [20:03:23<25:10:15, 12.59s/it] 44%|████▍     | 5629/12825 [20:03:36<25:07:07, 12.57s/it] 44%|████▍     | 5630/12825 [20:03:48<25:05:47, 12.56s/it] 44%|████▍     | 5631/12825 [20:04:01<25:03:13, 12.54s/it] 44%|████▍     | 5632/12825 [20:04:13<25:03:52, 12.54s/it] 44%|████▍     | 5633/12825 [20:04:26<25:04:09, 12.55s/it] 44%|████▍     | 5634/12825 [20:04:46<29:39:15, 14.85s/it] 44%|████▍     | 5635/12825 [20:04:59<28:15:50, 14.15s/it] 44%|████▍     | 5636/12825 [20:05:11<27:17:31, 13.67s/it] 44%|████▍     | 5637/12825 [20:05:24<26:35:46, 13.32s/it] 44%|████▍     | 5638/12825 [20:05:36<26:06:34, 13.08s/it] 44%|████▍     | 5639/12825 [20:05:49<25:46:33, 12.91s/it] 44%|████▍     | 5640/12825 [20:06:01<25:33:16, 12.80s/it] 44%|████▍     | 5641/12825 [20:06:14<25:21:56, 12.71s/it] 44%|████▍     | 5642/12825 [20:06:22<22:27:09, 11.25s/it] 44%|████▍     | 5643/12825 [20:06:23<16:12:25,  8.12s/it] 44%|████▍     | 5644/12825 [20:06:48<26:34:18, 13.32s/it] 44%|████▍     | 5645/12825 [20:07:01<26:07:16, 13.10s/it] 44%|████▍     | 5646/12825 [20:07:13<25:47:46, 12.94s/it] 44%|████▍     | 5647/12825 [20:07:26<25:34:36, 12.83s/it] 44%|████▍     | 5648/12825 [20:07:38<25:24:54, 12.75s/it] 44%|████▍     | 5649/12825 [20:07:51<25:18:18, 12.69s/it] 44%|████▍     | 5650/12825 [20:08:03<25:15:14, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120272.27lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103605.98lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5625] due to args.save_total_limit
 44%|████▍     | 5651/12825 [20:08:16<25:23:18, 12.74s/it] 44%|████▍     | 5652/12825 [20:08:29<25:16:40, 12.69s/it] 44%|████▍     | 5653/12825 [20:08:41<25:12:52, 12.66s/it] 44%|████▍     | 5654/12825 [20:08:54<25:09:56, 12.63s/it] 44%|████▍     | 5655/12825 [20:09:07<25:07:23, 12.61s/it] 44%|████▍     | 5656/12825 [20:09:19<25:05:26, 12.60s/it] 44%|████▍     | 5657/12825 [20:09:32<25:05:25, 12.60s/it] 44%|████▍     | 5658/12825 [20:09:44<25:04:33, 12.60s/it] 44%|████▍     | 5659/12825 [20:09:57<25:02:25, 12.58s/it] 44%|████▍     | 5660/12825 [20:10:09<25:01:18, 12.57s/it] 44%|████▍     | 5661/12825 [20:10:22<25:01:08, 12.57s/it] 44%|████▍     | 5662/12825 [20:10:35<24:59:23, 12.56s/it] 44%|████▍     | 5663/12825 [20:10:47<24:59:35, 12.56s/it] 44%|████▍     | 5664/12825 [20:11:00<24:59:07, 12.56s/it] 44%|████▍     | 5665/12825 [20:11:12<24:57:08, 12.55s/it] 44%|████▍     | 5666/12825 [20:11:25<24:57:05, 12.55s/it] 44%|████▍     | 5667/12825 [20:11:46<29:51:00, 15.01s/it] 44%|████▍     | 5668/12825 [20:11:58<28:22:33, 14.27s/it] 44%|████▍     | 5669/12825 [20:12:11<27:21:32, 13.76s/it] 44%|████▍     | 5670/12825 [20:12:23<26:37:43, 13.40s/it] 44%|████▍     | 5671/12825 [20:12:36<26:07:15, 13.14s/it] 44%|████▍     | 5672/12825 [20:12:48<25:48:35, 12.99s/it] 44%|████▍     | 5673/12825 [20:13:01<25:32:18, 12.85s/it] 44%|████▍     | 5674/12825 [20:13:13<25:20:48, 12.76s/it] 44%|████▍     | 5675/12825 [20:13:26<25:14:46, 12.71s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120231.03lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103433.19lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5650] due to args.save_total_limit
 44%|████▍     | 5676/12825 [20:13:39<25:20:16, 12.76s/it] 44%|████▍     | 5677/12825 [20:13:51<25:13:49, 12.71s/it] 44%|████▍     | 5678/12825 [20:14:04<25:08:06, 12.66s/it] 44%|████▍     | 5679/12825 [20:14:17<25:02:23, 12.61s/it] 44%|████▍     | 5680/12825 [20:14:29<24:59:14, 12.59s/it] 44%|████▍     | 5681/12825 [20:14:42<24:57:22, 12.58s/it] 44%|████▍     | 5682/12825 [20:14:54<24:54:29, 12.55s/it] 44%|████▍     | 5683/12825 [20:15:07<24:52:57, 12.54s/it] 44%|████▍     | 5684/12825 [20:15:19<24:57:20, 12.58s/it] 44%|████▍     | 5685/12825 [20:15:32<25:02:16, 12.62s/it] 44%|████▍     | 5686/12825 [20:15:45<24:59:26, 12.60s/it] 44%|████▍     | 5687/12825 [20:15:57<24:57:14, 12.59s/it] 44%|████▍     | 5688/12825 [20:16:10<24:58:53, 12.60s/it] 44%|████▍     | 5689/12825 [20:16:22<24:57:55, 12.59s/it] 44%|████▍     | 5690/12825 [20:16:35<24:56:21, 12.58s/it] 44%|████▍     | 5691/12825 [20:16:48<24:57:08, 12.59s/it] 44%|████▍     | 5692/12825 [20:17:00<24:54:30, 12.57s/it] 44%|████▍     | 5693/12825 [20:17:13<24:52:37, 12.56s/it] 44%|████▍     | 5694/12825 [20:17:25<24:53:46, 12.57s/it] 44%|████▍     | 5695/12825 [20:17:38<24:50:56, 12.55s/it] 44%|████▍     | 5696/12825 [20:17:50<24:50:51, 12.55s/it] 44%|████▍     | 5697/12825 [20:18:03<24:50:08, 12.54s/it] 44%|████▍     | 5698/12825 [20:18:15<24:50:08, 12.55s/it] 44%|████▍     | 5699/12825 [20:18:36<29:51:44, 15.09s/it] 44%|████▍     | 5700/12825 [20:18:49<28:19:53, 14.31s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120250.18lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103459.08lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5675] due to args.save_total_limit
 44%|████▍     | 5701/12825 [20:19:02<27:33:00, 13.92s/it] 44%|████▍     | 5702/12825 [20:19:14<26:43:43, 13.51s/it] 44%|████▍     | 5703/12825 [20:19:27<26:09:20, 13.22s/it] 44%|████▍     | 5704/12825 [20:19:40<25:49:30, 13.06s/it] 44%|████▍     | 5705/12825 [20:19:52<25:32:17, 12.91s/it] 44%|████▍     | 5706/12825 [20:20:05<25:19:33, 12.81s/it] 44%|████▍     | 5707/12825 [20:20:17<25:10:56, 12.74s/it] 45%|████▍     | 5708/12825 [20:20:30<25:05:44, 12.69s/it] 45%|████▍     | 5709/12825 [20:20:42<24:59:05, 12.64s/it] 45%|████▍     | 5710/12825 [20:20:55<24:55:41, 12.61s/it] 45%|████▍     | 5711/12825 [20:21:07<24:52:12, 12.59s/it] 45%|████▍     | 5712/12825 [20:21:20<24:51:08, 12.58s/it] 45%|████▍     | 5713/12825 [20:21:33<24:50:07, 12.57s/it] 45%|████▍     | 5714/12825 [20:21:45<24:47:56, 12.55s/it] 45%|████▍     | 5715/12825 [20:21:58<24:47:56, 12.56s/it] 45%|████▍     | 5716/12825 [20:22:10<24:49:13, 12.57s/it] 45%|████▍     | 5717/12825 [20:22:23<24:48:09, 12.56s/it] 45%|████▍     | 5718/12825 [20:22:36<24:52:42, 12.60s/it] 45%|████▍     | 5719/12825 [20:22:48<24:52:02, 12.60s/it] 45%|████▍     | 5720/12825 [20:23:01<24:55:49, 12.63s/it] 45%|████▍     | 5721/12825 [20:23:13<24:51:47, 12.60s/it] 45%|████▍     | 5722/12825 [20:23:26<24:50:10, 12.59s/it] 45%|████▍     | 5723/12825 [20:23:39<24:50:11, 12.59s/it] 45%|████▍     | 5724/12825 [20:23:51<24:54:26, 12.63s/it] 45%|████▍     | 5725/12825 [20:24:04<24:51:06, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120259.76lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103293.94lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5725
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5725/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5725/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5700] due to args.save_total_limit
 45%|████▍     | 5726/12825 [20:24:17<25:01:39, 12.69s/it] 45%|████▍     | 5727/12825 [20:24:29<24:59:58, 12.68s/it] 45%|████▍     | 5728/12825 [20:24:42<24:58:23, 12.67s/it] 45%|████▍     | 5729/12825 [20:24:54<24:52:28, 12.62s/it] 45%|████▍     | 5730/12825 [20:25:07<24:51:03, 12.61s/it] 45%|████▍     | 5731/12825 [20:25:20<24:48:24, 12.59s/it] 45%|████▍     | 5732/12825 [20:25:40<29:41:33, 15.07s/it] 45%|████▍     | 5733/12825 [20:25:53<28:14:48, 14.34s/it] 45%|████▍     | 5734/12825 [20:26:06<27:16:04, 13.84s/it] 45%|████▍     | 5735/12825 [20:26:18<26:34:46, 13.50s/it] 45%|████▍     | 5736/12825 [20:26:31<26:00:15, 13.21s/it] 45%|████▍     | 5737/12825 [20:26:44<25:37:59, 13.02s/it] 45%|████▍     | 5738/12825 [20:26:56<25:19:33, 12.86s/it] 45%|████▍     | 5739/12825 [20:27:09<25:06:45, 12.76s/it] 45%|████▍     | 5740/12825 [20:27:21<25:02:30, 12.72s/it] 45%|████▍     | 5741/12825 [20:27:34<24:56:45, 12.68s/it] 45%|████▍     | 5742/12825 [20:27:46<24:51:25, 12.63s/it] 45%|████▍     | 5743/12825 [20:27:59<24:49:46, 12.62s/it] 45%|████▍     | 5744/12825 [20:28:12<24:48:52, 12.62s/it] 45%|████▍     | 5745/12825 [20:28:24<24:45:16, 12.59s/it] 45%|████▍     | 5746/12825 [20:28:37<24:42:35, 12.57s/it] 45%|████▍     | 5747/12825 [20:28:49<24:41:58, 12.56s/it] 45%|████▍     | 5748/12825 [20:29:02<24:45:20, 12.59s/it] 45%|████▍     | 5749/12825 [20:29:14<24:49:40, 12.63s/it] 45%|████▍     | 5750/12825 [20:29:27<24:51:40, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120302.04lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103375.97lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5750
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5750/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5750/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5725] due to args.save_total_limit
 45%|████▍     | 5751/12825 [20:29:40<25:04:11, 12.76s/it] 45%|████▍     | 5752/12825 [20:29:53<24:54:32, 12.68s/it] 45%|████▍     | 5753/12825 [20:30:05<24:50:59, 12.65s/it] 45%|████▍     | 5754/12825 [20:30:18<24:47:31, 12.62s/it] 45%|████▍     | 5755/12825 [20:30:30<24:43:02, 12.59s/it] 45%|████▍     | 5756/12825 [20:30:43<24:40:24, 12.57s/it] 45%|████▍     | 5757/12825 [20:30:56<24:43:33, 12.59s/it] 45%|████▍     | 5758/12825 [20:31:08<24:44:09, 12.60s/it] 45%|████▍     | 5759/12825 [20:31:21<24:43:08, 12.59s/it] 45%|████▍     | 5760/12825 [20:31:33<24:43:42, 12.60s/it] 45%|████▍     | 5761/12825 [20:31:46<24:42:33, 12.59s/it] 45%|████▍     | 5762/12825 [20:31:59<24:44:24, 12.61s/it] 45%|████▍     | 5763/12825 [20:32:11<24:42:57, 12.60s/it] 45%|████▍     | 5764/12825 [20:32:32<29:24:15, 14.99s/it] 45%|████▍     | 5765/12825 [20:32:44<28:01:18, 14.29s/it] 45%|████▍     | 5766/12825 [20:32:57<27:03:55, 13.80s/it] 45%|████▍     | 5767/12825 [20:33:10<26:17:44, 13.41s/it] 45%|████▍     | 5768/12825 [20:33:22<25:46:12, 13.15s/it] 45%|████▍     | 5769/12825 [20:33:35<25:26:20, 12.98s/it] 45%|████▍     | 5770/12825 [20:33:47<25:11:20, 12.85s/it] 45%|████▍     | 5771/12825 [20:34:00<24:58:44, 12.75s/it] 45%|████▌     | 5772/12825 [20:34:12<24:54:14, 12.71s/it] 45%|████▌     | 5773/12825 [20:34:25<24:47:57, 12.66s/it] 45%|████▌     | 5774/12825 [20:34:37<24:41:49, 12.61s/it] 45%|████▌     | 5775/12825 [20:34:50<24:40:02, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120242.14lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103545.35lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5775
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5775/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5775/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5750] due to args.save_total_limit
 45%|████▌     | 5776/12825 [20:35:03<24:51:16, 12.69s/it] 45%|████▌     | 5777/12825 [20:35:16<24:52:07, 12.70s/it] 45%|████▌     | 5778/12825 [20:35:28<24:51:55, 12.70s/it] 45%|████▌     | 5779/12825 [20:35:41<24:50:41, 12.69s/it] 45%|████▌     | 5780/12825 [20:35:54<24:50:11, 12.69s/it] 45%|████▌     | 5781/12825 [20:36:06<24:44:30, 12.64s/it] 45%|████▌     | 5782/12825 [20:36:19<24:41:06, 12.62s/it] 45%|████▌     | 5783/12825 [20:36:31<24:42:03, 12.63s/it] 45%|████▌     | 5784/12825 [20:36:44<24:43:58, 12.65s/it] 45%|████▌     | 5785/12825 [20:36:57<24:43:18, 12.64s/it] 45%|████▌     | 5786/12825 [20:37:09<24:44:54, 12.66s/it] 45%|████▌     | 5787/12825 [20:37:22<24:42:19, 12.64s/it] 45%|████▌     | 5788/12825 [20:37:35<24:39:02, 12.61s/it] 45%|████▌     | 5789/12825 [20:37:47<24:40:06, 12.62s/it] 45%|████▌     | 5790/12825 [20:38:00<24:40:32, 12.63s/it] 45%|████▌     | 5791/12825 [20:38:12<24:41:30, 12.64s/it] 45%|████▌     | 5792/12825 [20:38:25<24:37:18, 12.60s/it] 45%|████▌     | 5793/12825 [20:38:38<24:39:07, 12.62s/it] 45%|████▌     | 5794/12825 [20:38:50<24:41:39, 12.64s/it] 45%|████▌     | 5795/12825 [20:39:03<24:42:23, 12.65s/it] 45%|████▌     | 5796/12825 [20:39:24<29:24:58, 15.07s/it] 45%|████▌     | 5797/12825 [20:39:36<27:56:12, 14.31s/it] 45%|████▌     | 5798/12825 [20:39:49<26:55:58, 13.80s/it] 45%|████▌     | 5799/12825 [20:40:01<26:11:46, 13.42s/it] 45%|████▌     | 5800/12825 [20:40:14<25:39:06, 13.15s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120401.42lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 99931.80lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5800
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5800/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5800/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5775] due to args.save_total_limit
 45%|████▌     | 5801/12825 [20:40:27<25:37:53, 13.14s/it] 45%|████▌     | 5802/12825 [20:40:40<25:15:55, 12.95s/it] 45%|████▌     | 5803/12825 [20:40:52<24:59:49, 12.82s/it] 45%|████▌     | 5804/12825 [20:41:05<24:51:02, 12.74s/it] 45%|████▌     | 5805/12825 [20:41:17<24:50:30, 12.74s/it] 45%|████▌     | 5806/12825 [20:41:30<24:42:12, 12.67s/it] 45%|████▌     | 5807/12825 [20:41:42<24:37:10, 12.63s/it] 45%|████▌     | 5808/12825 [20:41:55<24:34:50, 12.61s/it] 45%|████▌     | 5809/12825 [20:42:08<24:32:48, 12.60s/it] 45%|████▌     | 5810/12825 [20:42:20<24:31:30, 12.59s/it] 45%|████▌     | 5811/12825 [20:42:33<24:35:14, 12.62s/it] 45%|████▌     | 5812/12825 [20:42:45<24:35:12, 12.62s/it] 45%|████▌     | 5813/12825 [20:42:58<24:36:14, 12.63s/it] 45%|████▌     | 5814/12825 [20:43:11<24:35:24, 12.63s/it] 45%|████▌     | 5815/12825 [20:43:23<24:37:01, 12.64s/it] 45%|████▌     | 5816/12825 [20:43:36<24:33:38, 12.61s/it] 45%|████▌     | 5817/12825 [20:43:49<24:37:19, 12.65s/it] 45%|████▌     | 5818/12825 [20:44:01<24:37:01, 12.65s/it] 45%|████▌     | 5819/12825 [20:44:14<24:34:08, 12.62s/it] 45%|████▌     | 5820/12825 [20:44:26<24:31:06, 12.60s/it] 45%|████▌     | 5821/12825 [20:44:39<24:28:10, 12.58s/it] 45%|████▌     | 5822/12825 [20:44:51<24:26:28, 12.56s/it] 45%|████▌     | 5823/12825 [20:45:04<24:24:05, 12.55s/it] 45%|████▌     | 5824/12825 [20:45:16<24:23:00, 12.54s/it] 45%|████▌     | 5825/12825 [20:45:29<24:21:26, 12.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120096.26lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103385.51lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5825
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5825/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5825/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5800] due to args.save_total_limit
 45%|████▌     | 5826/12825 [20:45:42<24:32:32, 12.62s/it] 45%|████▌     | 5827/12825 [20:45:54<24:30:18, 12.61s/it] 45%|████▌     | 5828/12825 [20:46:07<24:24:57, 12.56s/it] 45%|████▌     | 5829/12825 [20:46:28<29:16:49, 15.07s/it] 45%|████▌     | 5830/12825 [20:46:40<27:47:38, 14.30s/it] 45%|████▌     | 5831/12825 [20:46:53<26:50:15, 13.81s/it] 45%|████▌     | 5832/12825 [20:47:05<26:05:39, 13.43s/it] 45%|████▌     | 5833/12825 [20:47:18<25:38:23, 13.20s/it] 45%|████▌     | 5834/12825 [20:47:31<25:18:24, 13.03s/it] 45%|████▌     | 5835/12825 [20:47:43<25:00:38, 12.88s/it] 46%|████▌     | 5836/12825 [20:47:56<24:52:35, 12.81s/it] 46%|████▌     | 5837/12825 [20:48:09<24:42:17, 12.73s/it] 46%|████▌     | 5838/12825 [20:48:21<24:41:15, 12.72s/it] 46%|████▌     | 5839/12825 [20:48:34<24:34:31, 12.66s/it] 46%|████▌     | 5840/12825 [20:48:46<24:36:07, 12.68s/it] 46%|████▌     | 5841/12825 [20:48:59<24:30:17, 12.63s/it] 46%|████▌     | 5842/12825 [20:49:12<24:26:27, 12.60s/it] 46%|████▌     | 5843/12825 [20:49:24<24:27:19, 12.61s/it] 46%|████▌     | 5844/12825 [20:49:37<24:24:21, 12.59s/it] 46%|████▌     | 5845/12825 [20:49:49<24:23:04, 12.58s/it] 46%|████▌     | 5846/12825 [20:50:02<24:21:40, 12.57s/it] 46%|████▌     | 5847/12825 [20:50:14<24:21:46, 12.57s/it] 46%|████▌     | 5848/12825 [20:50:27<24:26:42, 12.61s/it] 46%|████▌     | 5849/12825 [20:50:40<24:23:00, 12.58s/it] 46%|████▌     | 5850/12825 [20:50:52<24:19:48, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120261.80lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103524.53lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5850
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5850/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5850/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5600] due to args.save_total_limit
 46%|████▌     | 5851/12825 [20:51:05<24:32:31, 12.67s/it] 46%|████▌     | 5852/12825 [20:51:18<24:28:07, 12.63s/it] 46%|████▌     | 5853/12825 [20:51:30<24:28:13, 12.64s/it] 46%|████▌     | 5854/12825 [20:51:43<24:28:33, 12.64s/it] 46%|████▌     | 5855/12825 [20:51:55<24:24:05, 12.60s/it] 46%|████▌     | 5856/12825 [20:52:08<24:21:46, 12.59s/it] 46%|████▌     | 5857/12825 [20:52:20<24:17:22, 12.55s/it] 46%|████▌     | 5858/12825 [20:52:33<24:16:36, 12.54s/it] 46%|████▌     | 5859/12825 [20:52:45<24:18:29, 12.56s/it] 46%|████▌     | 5860/12825 [20:52:58<24:17:25, 12.56s/it] 46%|████▌     | 5861/12825 [20:53:19<29:04:43, 15.03s/it] 46%|████▌     | 5862/12825 [20:53:31<27:37:16, 14.28s/it] 46%|████▌     | 5863/12825 [20:53:44<26:33:51, 13.74s/it] 46%|████▌     | 5864/12825 [20:53:57<25:56:14, 13.41s/it] 46%|████▌     | 5865/12825 [20:54:09<25:24:16, 13.14s/it] 46%|████▌     | 5866/12825 [20:54:22<25:04:04, 12.97s/it] 46%|████▌     | 5867/12825 [20:54:34<24:49:08, 12.84s/it] 46%|████▌     | 5868/12825 [20:54:47<24:38:11, 12.75s/it] 46%|████▌     | 5869/12825 [20:54:59<24:31:35, 12.69s/it] 46%|████▌     | 5870/12825 [20:55:12<24:26:48, 12.65s/it] 46%|████▌     | 5871/12825 [20:55:24<24:23:01, 12.62s/it] 46%|████▌     | 5872/12825 [20:55:37<24:25:45, 12.65s/it] 46%|████▌     | 5873/12825 [20:55:50<24:22:27, 12.62s/it] 46%|████▌     | 5874/12825 [20:56:02<24:19:52, 12.60s/it] 46%|████▌     | 5875/12825 [20:56:15<24:23:06, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 119920.88lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103276.98lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5875
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5875/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5875/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5825] due to args.save_total_limit
 46%|████▌     | 5876/12825 [20:56:28<24:34:13, 12.73s/it] 46%|████▌     | 5877/12825 [20:56:40<24:30:52, 12.70s/it] 46%|████▌     | 5878/12825 [20:56:53<24:31:11, 12.71s/it] 46%|████▌     | 5879/12825 [20:57:06<24:25:47, 12.66s/it] 46%|████▌     | 5880/12825 [20:57:18<24:22:53, 12.64s/it] 46%|████▌     | 5881/12825 [20:57:31<24:20:59, 12.62s/it] 46%|████▌     | 5882/12825 [20:57:44<24:21:08, 12.63s/it] 46%|████▌     | 5883/12825 [20:57:56<24:19:11, 12.61s/it] 46%|████▌     | 5884/12825 [20:58:09<24:22:55, 12.65s/it] 46%|████▌     | 5885/12825 [20:58:21<24:19:28, 12.62s/it] 46%|████▌     | 5886/12825 [20:58:34<24:17:44, 12.60s/it] 46%|████▌     | 5887/12825 [20:58:47<24:17:00, 12.60s/it] 46%|████▌     | 5888/12825 [20:58:59<24:19:39, 12.63s/it] 46%|████▌     | 5889/12825 [20:59:12<24:16:48, 12.60s/it] 46%|████▌     | 5890/12825 [20:59:24<24:16:27, 12.60s/it] 46%|████▌     | 5891/12825 [20:59:37<24:13:44, 12.58s/it] 46%|████▌     | 5892/12825 [20:59:49<24:12:34, 12.57s/it] 46%|████▌     | 5893/12825 [21:00:02<24:10:12, 12.55s/it] 46%|████▌     | 5894/12825 [21:00:23<28:49:21, 14.97s/it] 46%|████▌     | 5895/12825 [21:00:35<27:25:49, 14.25s/it] 46%|████▌     | 5896/12825 [21:00:48<26:28:25, 13.75s/it] 46%|████▌     | 5897/12825 [21:01:00<25:49:11, 13.42s/it] 46%|████▌     | 5898/12825 [21:01:13<25:22:50, 13.19s/it] 46%|████▌     | 5899/12825 [21:01:26<25:02:10, 13.01s/it] 46%|████▌     | 5900/12825 [21:01:38<24:49:32, 12.91s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120133.33lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103229.25lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5900
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5900/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5900/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5850] due to args.save_total_limit
 46%|████▌     | 5901/12825 [21:01:51<24:50:14, 12.91s/it] 46%|████▌     | 5902/12825 [21:02:04<24:40:43, 12.83s/it] 46%|████▌     | 5903/12825 [21:02:16<24:29:39, 12.74s/it] 46%|████▌     | 5904/12825 [21:02:29<24:21:51, 12.67s/it] 46%|████▌     | 5905/12825 [21:02:42<24:21:27, 12.67s/it] 46%|████▌     | 5906/12825 [21:02:54<24:19:50, 12.66s/it] 46%|████▌     | 5907/12825 [21:03:07<24:18:49, 12.65s/it] 46%|████▌     | 5908/12825 [21:03:19<24:15:15, 12.62s/it] 46%|████▌     | 5909/12825 [21:03:32<24:13:51, 12.61s/it] 46%|████▌     | 5910/12825 [21:03:44<24:09:02, 12.57s/it] 46%|████▌     | 5911/12825 [21:03:57<24:07:52, 12.56s/it] 46%|████▌     | 5912/12825 [21:04:10<24:05:17, 12.54s/it] 46%|████▌     | 5913/12825 [21:04:22<24:05:11, 12.55s/it] 46%|████▌     | 5914/12825 [21:04:35<24:04:40, 12.54s/it] 46%|████▌     | 5915/12825 [21:04:47<24:04:40, 12.54s/it] 46%|████▌     | 5916/12825 [21:05:00<24:10:12, 12.59s/it] 46%|████▌     | 5917/12825 [21:05:13<24:12:04, 12.61s/it] 46%|████▌     | 5918/12825 [21:05:25<24:10:55, 12.60s/it] 46%|████▌     | 5919/12825 [21:05:38<24:09:57, 12.60s/it] 46%|████▌     | 5920/12825 [21:05:50<24:10:01, 12.60s/it] 46%|████▌     | 5921/12825 [21:06:03<24:11:05, 12.61s/it] 46%|████▌     | 5922/12825 [21:06:15<24:06:53, 12.58s/it] 46%|████▌     | 5923/12825 [21:06:28<24:04:39, 12.56s/it] 46%|████▌     | 5924/12825 [21:06:41<24:05:47, 12.57s/it] 46%|████▌     | 5925/12825 [21:06:53<24:03:44, 12.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120313.03lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103579.07lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5925
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5925/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5925/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5875] due to args.save_total_limit
 46%|████▌     | 5926/12825 [21:07:14<29:04:54, 15.18s/it] 46%|████▌     | 5927/12825 [21:07:27<27:35:03, 14.40s/it] 46%|████▌     | 5928/12825 [21:07:39<26:29:55, 13.83s/it] 46%|████▌     | 5929/12825 [21:07:52<25:44:42, 13.44s/it] 46%|████▌     | 5930/12825 [21:08:05<25:16:12, 13.19s/it] 46%|████▌     | 5931/12825 [21:08:17<24:56:37, 13.03s/it] 46%|████▋     | 5932/12825 [21:08:30<24:43:48, 12.92s/it] 46%|████▋     | 5933/12825 [21:08:42<24:31:18, 12.81s/it] 46%|████▋     | 5934/12825 [21:08:55<24:25:57, 12.76s/it] 46%|████▋     | 5935/12825 [21:09:08<24:21:25, 12.73s/it] 46%|████▋     | 5936/12825 [21:09:20<24:13:09, 12.66s/it] 46%|████▋     | 5937/12825 [21:09:33<24:13:42, 12.66s/it] 46%|████▋     | 5938/12825 [21:09:45<24:07:43, 12.61s/it] 46%|████▋     | 5939/12825 [21:09:58<24:05:10, 12.59s/it] 46%|████▋     | 5940/12825 [21:10:10<24:02:20, 12.57s/it] 46%|████▋     | 5941/12825 [21:10:23<24:00:40, 12.56s/it] 46%|████▋     | 5942/12825 [21:10:36<24:00:19, 12.56s/it] 46%|████▋     | 5943/12825 [21:10:48<23:59:03, 12.55s/it] 46%|████▋     | 5944/12825 [21:11:01<23:56:46, 12.53s/it] 46%|████▋     | 5945/12825 [21:11:13<23:58:08, 12.54s/it] 46%|████▋     | 5946/12825 [21:11:26<24:03:43, 12.59s/it] 46%|████▋     | 5947/12825 [21:11:38<24:03:07, 12.59s/it] 46%|████▋     | 5948/12825 [21:11:51<24:02:14, 12.58s/it] 46%|████▋     | 5949/12825 [21:12:04<24:01:13, 12.58s/it] 46%|████▋     | 5950/12825 [21:12:16<23:57:58, 12.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120177.06lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103339.84lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5950
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5950/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5950/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5900] due to args.save_total_limit
 46%|████▋     | 5951/12825 [21:12:29<24:09:19, 12.65s/it] 46%|████▋     | 5952/12825 [21:12:41<24:05:30, 12.62s/it] 46%|████▋     | 5953/12825 [21:12:54<24:01:52, 12.59s/it] 46%|████▋     | 5954/12825 [21:13:07<24:01:23, 12.59s/it] 46%|████▋     | 5955/12825 [21:13:19<23:58:24, 12.56s/it] 46%|████▋     | 5956/12825 [21:13:32<23:59:12, 12.57s/it] 46%|████▋     | 5957/12825 [21:13:44<23:58:49, 12.57s/it] 46%|████▋     | 5958/12825 [21:14:05<28:51:35, 15.13s/it] 46%|████▋     | 5959/12825 [21:14:18<27:26:57, 14.39s/it] 46%|████▋     | 5960/12825 [21:14:31<26:27:51, 13.88s/it] 46%|████▋     | 5961/12825 [21:14:43<25:46:46, 13.52s/it] 46%|████▋     | 5962/12825 [21:14:56<25:16:54, 13.26s/it] 46%|████▋     | 5963/12825 [21:15:09<24:55:38, 13.08s/it] 47%|████▋     | 5964/12825 [21:15:21<24:41:27, 12.96s/it] 47%|████▋     | 5965/12825 [21:15:34<24:30:43, 12.86s/it] 47%|████▋     | 5966/12825 [21:15:46<24:18:13, 12.76s/it] 47%|████▋     | 5967/12825 [21:15:59<24:12:30, 12.71s/it] 47%|████▋     | 5968/12825 [21:16:12<24:05:40, 12.65s/it] 47%|████▋     | 5969/12825 [21:16:24<24:01:35, 12.62s/it] 47%|████▋     | 5970/12825 [21:16:37<24:01:17, 12.62s/it] 47%|████▋     | 5971/12825 [21:16:49<24:02:37, 12.63s/it] 47%|████▋     | 5972/12825 [21:17:02<24:03:28, 12.64s/it] 47%|████▋     | 5973/12825 [21:17:15<24:04:31, 12.65s/it] 47%|████▋     | 5974/12825 [21:17:27<24:02:53, 12.64s/it] 47%|████▋     | 5975/12825 [21:17:40<23:57:50, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120153.98lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103438.29lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5975
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5975/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5975/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-5975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5925] due to args.save_total_limit
 47%|████▋     | 5976/12825 [21:17:53<24:08:45, 12.69s/it] 47%|████▋     | 5977/12825 [21:18:05<24:04:26, 12.66s/it] 47%|████▋     | 5978/12825 [21:18:18<24:00:47, 12.63s/it] 47%|████▋     | 5979/12825 [21:18:31<24:01:57, 12.64s/it] 47%|████▋     | 5980/12825 [21:18:43<23:57:38, 12.60s/it] 47%|████▋     | 5981/12825 [21:18:56<23:55:24, 12.58s/it] 47%|████▋     | 5982/12825 [21:19:08<23:52:59, 12.56s/it] 47%|████▋     | 5983/12825 [21:19:21<23:50:36, 12.55s/it] 47%|████▋     | 5984/12825 [21:19:33<23:51:32, 12.56s/it] 47%|████▋     | 5985/12825 [21:19:46<23:55:05, 12.59s/it] 47%|████▋     | 5986/12825 [21:19:59<23:56:45, 12.60s/it] 47%|████▋     | 5987/12825 [21:20:11<23:55:03, 12.59s/it] 47%|████▋     | 5988/12825 [21:20:24<23:54:29, 12.59s/it] 47%|████▋     | 5989/12825 [21:20:36<23:54:13, 12.59s/it] 47%|████▋     | 5990/12825 [21:20:49<23:55:25, 12.60s/it] 47%|████▋     | 5991/12825 [21:21:13<30:16:27, 15.95s/it] 47%|████▋     | 5992/12825 [21:21:25<28:19:47, 14.93s/it] 47%|████▋     | 5993/12825 [21:21:38<27:02:11, 14.25s/it] 47%|████▋     | 5994/12825 [21:21:50<26:04:38, 13.74s/it] 47%|████▋     | 5995/12825 [21:22:03<25:29:04, 13.43s/it] 47%|████▋     | 5996/12825 [21:22:16<25:06:07, 13.23s/it] 47%|████▋     | 5997/12825 [21:22:29<24:44:51, 13.05s/it] 47%|████▋     | 5998/12825 [21:22:41<24:27:04, 12.89s/it] 47%|████▋     | 5999/12825 [21:22:54<24:14:19, 12.78s/it] 47%|████▋     | 6000/12825 [21:23:06<24:14:42, 12.79s/it]                                                           47%|████▋     | 6000/12825 [21:23:06<24:14:42, 12.79s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120171.32lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103405.52lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6000
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6000/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6000/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5975] due to args.save_total_limit
 47%|████▋     | 6001/12825 [21:23:19<24:19:54, 12.84s/it] 47%|████▋     | 6002/12825 [21:23:32<24:11:18, 12.76s/it] 47%|████▋     | 6003/12825 [21:23:44<24:02:23, 12.69s/it] 47%|████▋     | 6004/12825 [21:23:57<23:57:42, 12.65s/it] 47%|████▋     | 6005/12825 [21:24:09<23:53:29, 12.61s/it] 47%|████▋     | 6006/12825 [21:24:22<23:51:07, 12.59s/it] 47%|████▋     | 6007/12825 [21:24:35<23:52:16, 12.60s/it] 47%|████▋     | 6008/12825 [21:24:47<23:55:22, 12.63s/it] 47%|████▋     | 6009/12825 [21:25:00<23:56:35, 12.65s/it] 47%|████▋     | 6010/12825 [21:25:13<23:56:41, 12.65s/it] 47%|████▋     | 6011/12825 [21:25:25<23:57:19, 12.66s/it] 47%|████▋     | 6012/12825 [21:25:38<23:56:12, 12.65s/it] 47%|████▋     | 6013/12825 [21:25:51<23:55:55, 12.65s/it] 47%|████▋     | 6014/12825 [21:26:03<23:55:19, 12.64s/it] 47%|████▋     | 6015/12825 [21:26:16<23:56:19, 12.65s/it] 47%|████▋     | 6016/12825 [21:26:29<23:52:45, 12.63s/it] 47%|████▋     | 6017/12825 [21:26:41<23:50:07, 12.60s/it] 47%|████▋     | 6018/12825 [21:26:54<23:52:15, 12.62s/it] 47%|████▋     | 6019/12825 [21:27:06<23:52:33, 12.63s/it] 47%|████▋     | 6020/12825 [21:27:19<23:49:43, 12.61s/it] 47%|████▋     | 6021/12825 [21:27:32<23:49:30, 12.61s/it] 47%|████▋     | 6022/12825 [21:27:44<23:51:31, 12.63s/it] 47%|████▋     | 6023/12825 [21:28:05<28:18:35, 14.98s/it] 47%|████▋     | 6024/12825 [21:28:17<26:59:12, 14.29s/it] 47%|████▋     | 6025/12825 [21:28:30<26:03:52, 13.80s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120289.90lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103526.23lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6025
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6025/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6025/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6000] due to args.save_total_limit
 47%|████▋     | 6026/12825 [21:28:43<25:44:55, 13.63s/it] 47%|████▋     | 6027/12825 [21:28:56<25:11:31, 13.34s/it] 47%|████▋     | 6028/12825 [21:29:09<24:47:13, 13.13s/it] 47%|████▋     | 6029/12825 [21:29:21<24:30:11, 12.98s/it] 47%|████▋     | 6030/12825 [21:29:34<24:19:33, 12.89s/it] 47%|████▋     | 6031/12825 [21:29:47<24:12:11, 12.82s/it] 47%|████▋     | 6032/12825 [21:29:59<24:03:50, 12.75s/it] 47%|████▋     | 6033/12825 [21:30:12<23:59:30, 12.72s/it] 47%|████▋     | 6034/12825 [21:30:24<23:54:50, 12.68s/it] 47%|████▋     | 6035/12825 [21:30:37<23:54:12, 12.67s/it] 47%|████▋     | 6036/12825 [21:30:50<23:54:17, 12.68s/it] 47%|████▋     | 6037/12825 [21:31:02<23:53:50, 12.67s/it] 47%|████▋     | 6038/12825 [21:31:15<23:54:17, 12.68s/it] 47%|████▋     | 6039/12825 [21:31:28<23:53:31, 12.67s/it] 47%|████▋     | 6040/12825 [21:31:40<23:51:12, 12.66s/it] 47%|████▋     | 6041/12825 [21:31:53<23:51:06, 12.66s/it] 47%|████▋     | 6042/12825 [21:32:06<23:48:24, 12.64s/it] 47%|████▋     | 6043/12825 [21:32:18<23:49:02, 12.64s/it] 47%|████▋     | 6044/12825 [21:32:31<23:50:02, 12.65s/it] 47%|████▋     | 6045/12825 [21:32:44<23:49:36, 12.65s/it] 47%|████▋     | 6046/12825 [21:32:56<23:47:27, 12.63s/it] 47%|████▋     | 6047/12825 [21:33:09<23:46:34, 12.63s/it] 47%|████▋     | 6048/12825 [21:33:21<23:47:44, 12.64s/it] 47%|████▋     | 6049/12825 [21:33:34<23:43:21, 12.60s/it] 47%|████▋     | 6050/12825 [21:33:47<23:44:44, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120272.02lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103551.70lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6050
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6050/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6050/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6025] due to args.save_total_limit
 47%|████▋     | 6051/12825 [21:33:59<23:52:44, 12.69s/it] 47%|████▋     | 6052/12825 [21:34:12<23:50:07, 12.67s/it] 47%|████▋     | 6053/12825 [21:34:25<23:48:43, 12.66s/it] 47%|████▋     | 6054/12825 [21:34:37<23:44:35, 12.62s/it] 47%|████▋     | 6055/12825 [21:34:50<23:42:48, 12.61s/it] 47%|████▋     | 6056/12825 [21:35:10<28:12:23, 15.00s/it] 47%|████▋     | 6057/12825 [21:35:23<26:49:43, 14.27s/it] 47%|████▋     | 6058/12825 [21:35:36<25:52:57, 13.77s/it] 47%|████▋     | 6059/12825 [21:35:48<25:10:26, 13.39s/it] 47%|████▋     | 6060/12825 [21:36:01<24:44:54, 13.17s/it] 47%|████▋     | 6061/12825 [21:36:13<24:21:09, 12.96s/it] 47%|████▋     | 6062/12825 [21:36:26<24:10:49, 12.87s/it] 47%|████▋     | 6063/12825 [21:36:39<24:01:41, 12.79s/it] 47%|████▋     | 6064/12825 [21:36:51<23:53:18, 12.72s/it] 47%|████▋     | 6065/12825 [21:37:04<23:46:35, 12.66s/it] 47%|████▋     | 6066/12825 [21:37:16<23:41:10, 12.62s/it] 47%|████▋     | 6067/12825 [21:37:29<23:37:01, 12.58s/it] 47%|████▋     | 6068/12825 [21:37:41<23:35:29, 12.57s/it] 47%|████▋     | 6069/12825 [21:37:54<23:33:48, 12.56s/it] 47%|████▋     | 6070/12825 [21:38:06<23:37:15, 12.59s/it] 47%|████▋     | 6071/12825 [21:38:19<23:35:00, 12.57s/it] 47%|████▋     | 6072/12825 [21:38:31<23:32:47, 12.55s/it] 47%|████▋     | 6073/12825 [21:38:44<23:36:27, 12.59s/it] 47%|████▋     | 6074/12825 [21:38:57<23:37:31, 12.60s/it] 47%|████▋     | 6075/12825 [21:39:09<23:36:39, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120296.55lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103500.88lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6075
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6075/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6075/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6050] due to args.save_total_limit
 47%|████▋     | 6076/12825 [21:39:22<23:45:15, 12.67s/it] 47%|████▋     | 6077/12825 [21:39:35<23:41:15, 12.64s/it] 47%|████▋     | 6078/12825 [21:39:47<23:38:48, 12.62s/it] 47%|████▋     | 6079/12825 [21:40:00<23:36:00, 12.59s/it] 47%|████▋     | 6080/12825 [21:40:12<23:31:56, 12.56s/it] 47%|████▋     | 6081/12825 [21:40:25<23:36:43, 12.60s/it] 47%|████▋     | 6082/12825 [21:40:38<23:39:31, 12.63s/it] 47%|████▋     | 6083/12825 [21:40:50<23:40:26, 12.64s/it] 47%|████▋     | 6084/12825 [21:41:03<23:39:50, 12.64s/it] 47%|████▋     | 6085/12825 [21:41:16<23:40:33, 12.65s/it] 47%|████▋     | 6086/12825 [21:41:28<23:39:34, 12.64s/it] 47%|████▋     | 6087/12825 [21:41:41<23:34:56, 12.60s/it] 47%|████▋     | 6088/12825 [21:42:01<27:56:05, 14.93s/it] 47%|████▋     | 6089/12825 [21:42:14<26:37:55, 14.23s/it] 47%|████▋     | 6090/12825 [21:42:26<25:39:05, 13.71s/it] 47%|████▋     | 6091/12825 [21:42:39<24:59:19, 13.36s/it] 48%|████▊     | 6092/12825 [21:42:51<24:31:45, 13.12s/it] 48%|████▊     | 6093/12825 [21:43:04<24:12:18, 12.94s/it] 48%|████▊     | 6094/12825 [21:43:16<23:58:03, 12.82s/it] 48%|████▊     | 6095/12825 [21:43:29<23:49:02, 12.74s/it] 48%|████▊     | 6096/12825 [21:43:41<23:43:29, 12.69s/it] 48%|████▊     | 6097/12825 [21:43:54<23:37:52, 12.64s/it] 48%|████▊     | 6098/12825 [21:44:07<23:32:25, 12.60s/it] 48%|████▊     | 6099/12825 [21:44:19<23:33:41, 12.61s/it] 48%|████▊     | 6100/12825 [21:44:32<23:31:27, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120219.41lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103486.03lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6075] due to args.save_total_limit
 48%|████▊     | 6101/12825 [21:44:45<23:41:52, 12.69s/it] 48%|████▊     | 6102/12825 [21:44:57<23:35:42, 12.63s/it] 48%|████▊     | 6103/12825 [21:45:10<23:34:37, 12.63s/it] 48%|████▊     | 6104/12825 [21:45:22<23:31:12, 12.60s/it] 48%|████▊     | 6105/12825 [21:45:35<23:29:44, 12.59s/it] 48%|████▊     | 6106/12825 [21:45:47<23:27:27, 12.57s/it] 48%|████▊     | 6107/12825 [21:46:00<23:25:10, 12.55s/it] 48%|████▊     | 6108/12825 [21:46:12<23:23:52, 12.54s/it] 48%|████▊     | 6109/12825 [21:46:25<23:21:55, 12.52s/it] 48%|████▊     | 6110/12825 [21:46:37<23:19:26, 12.50s/it] 48%|████▊     | 6111/12825 [21:46:50<23:22:51, 12.54s/it] 48%|████▊     | 6112/12825 [21:47:02<23:21:21, 12.53s/it] 48%|████▊     | 6113/12825 [21:47:15<23:21:54, 12.53s/it] 48%|████▊     | 6114/12825 [21:47:27<23:21:12, 12.53s/it] 48%|████▊     | 6115/12825 [21:47:40<23:21:34, 12.53s/it] 48%|████▊     | 6116/12825 [21:47:53<23:19:59, 12.52s/it] 48%|████▊     | 6117/12825 [21:48:05<23:18:56, 12.51s/it] 48%|████▊     | 6118/12825 [21:48:17<23:17:37, 12.50s/it] 48%|████▊     | 6119/12825 [21:48:30<23:18:38, 12.51s/it] 48%|████▊     | 6120/12825 [21:48:51<27:54:34, 14.99s/it] 48%|████▊     | 6121/12825 [21:49:03<26:34:52, 14.27s/it] 48%|████▊     | 6122/12825 [21:49:16<25:39:04, 13.78s/it] 48%|████▊     | 6123/12825 [21:49:29<24:56:32, 13.40s/it] 48%|████▊     | 6124/12825 [21:49:41<24:26:57, 13.13s/it] 48%|████▊     | 6125/12825 [21:49:54<24:03:55, 12.93s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120189.18lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103496.71lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6100] due to args.save_total_limit
 48%|████▊     | 6126/12825 [21:50:06<24:01:18, 12.91s/it] 48%|████▊     | 6127/12825 [21:50:19<23:49:06, 12.80s/it] 48%|████▊     | 6128/12825 [21:50:31<23:39:50, 12.72s/it] 48%|████▊     | 6129/12825 [21:50:44<23:36:39, 12.69s/it] 48%|████▊     | 6130/12825 [21:50:57<23:30:26, 12.64s/it] 48%|████▊     | 6131/12825 [21:51:09<23:25:11, 12.60s/it] 48%|████▊     | 6132/12825 [21:51:22<23:22:25, 12.57s/it] 48%|████▊     | 6133/12825 [21:51:34<23:21:13, 12.56s/it] 48%|████▊     | 6134/12825 [21:51:47<23:19:38, 12.55s/it] 48%|████▊     | 6135/12825 [21:51:59<23:19:09, 12.55s/it] 48%|████▊     | 6136/12825 [21:52:12<23:20:11, 12.56s/it] 48%|████▊     | 6137/12825 [21:52:24<23:22:51, 12.59s/it] 48%|████▊     | 6138/12825 [21:52:37<23:25:00, 12.61s/it] 48%|████▊     | 6139/12825 [21:52:50<23:27:00, 12.63s/it] 48%|████▊     | 6140/12825 [21:53:02<23:27:13, 12.63s/it] 48%|████▊     | 6141/12825 [21:53:15<23:22:17, 12.59s/it] 48%|████▊     | 6142/12825 [21:53:28<23:23:54, 12.60s/it] 48%|████▊     | 6143/12825 [21:53:40<23:21:43, 12.59s/it] 48%|████▊     | 6144/12825 [21:53:53<23:19:16, 12.57s/it] 48%|████▊     | 6145/12825 [21:54:05<23:17:08, 12.55s/it] 48%|████▊     | 6146/12825 [21:54:18<23:15:38, 12.54s/it] 48%|████▊     | 6147/12825 [21:54:30<23:14:50, 12.53s/it] 48%|████▊     | 6148/12825 [21:54:43<23:17:57, 12.56s/it] 48%|████▊     | 6149/12825 [21:54:55<23:20:06, 12.58s/it] 48%|████▊     | 6150/12825 [21:55:08<23:22:01, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120187.39lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103474.30lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6125] due to args.save_total_limit
 48%|████▊     | 6151/12825 [21:55:21<23:34:52, 12.72s/it] 48%|████▊     | 6152/12825 [21:55:34<23:30:51, 12.69s/it] 48%|████▊     | 6153/12825 [21:55:56<28:41:16, 15.48s/it] 48%|████▊     | 6154/12825 [21:56:08<27:07:11, 14.64s/it] 48%|████▊     | 6155/12825 [21:56:16<23:20:45, 12.60s/it] 48%|████▊     | 6156/12825 [21:56:17<16:47:49,  9.07s/it] 48%|████▊     | 6157/12825 [21:56:42<25:53:41, 13.98s/it] 48%|████▊     | 6158/12825 [21:56:55<25:05:34, 13.55s/it] 48%|████▊     | 6159/12825 [21:57:08<24:32:54, 13.26s/it] 48%|████▊     | 6160/12825 [21:57:20<24:10:43, 13.06s/it] 48%|████▊     | 6161/12825 [21:57:33<23:55:15, 12.92s/it] 48%|████▊     | 6162/12825 [21:57:45<23:44:21, 12.83s/it] 48%|████▊     | 6163/12825 [21:57:58<23:36:20, 12.76s/it] 48%|████▊     | 6164/12825 [21:58:11<23:29:39, 12.70s/it] 48%|████▊     | 6165/12825 [21:58:23<23:24:02, 12.65s/it] 48%|████▊     | 6166/12825 [21:58:36<23:20:37, 12.62s/it] 48%|████▊     | 6167/12825 [21:58:48<23:18:37, 12.60s/it] 48%|████▊     | 6168/12825 [21:59:01<23:17:29, 12.60s/it] 48%|████▊     | 6169/12825 [21:59:13<23:15:50, 12.58s/it] 48%|████▊     | 6170/12825 [21:59:26<23:15:38, 12.58s/it] 48%|████▊     | 6171/12825 [21:59:38<23:14:32, 12.57s/it] 48%|████▊     | 6172/12825 [21:59:51<23:13:44, 12.57s/it] 48%|████▊     | 6173/12825 [22:00:04<23:13:39, 12.57s/it] 48%|████▊     | 6174/12825 [22:00:16<23:11:53, 12.56s/it] 48%|████▊     | 6175/12825 [22:00:29<23:10:36, 12.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120281.22lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103326.36lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6150] due to args.save_total_limit
 48%|████▊     | 6176/12825 [22:00:42<23:21:36, 12.65s/it] 48%|████▊     | 6177/12825 [22:00:54<23:18:28, 12.62s/it] 48%|████▊     | 6178/12825 [22:01:07<23:16:26, 12.61s/it] 48%|████▊     | 6179/12825 [22:01:19<23:13:18, 12.58s/it] 48%|████▊     | 6180/12825 [22:01:32<23:10:58, 12.56s/it] 48%|████▊     | 6181/12825 [22:01:44<23:09:22, 12.55s/it] 48%|████▊     | 6182/12825 [22:01:57<23:06:56, 12.53s/it] 48%|████▊     | 6183/12825 [22:02:09<23:12:51, 12.58s/it] 48%|████▊     | 6184/12825 [22:02:22<23:10:46, 12.57s/it] 48%|████▊     | 6185/12825 [22:02:44<28:17:36, 15.34s/it] 48%|████▊     | 6186/12825 [22:02:56<26:45:03, 14.51s/it] 48%|████▊     | 6187/12825 [22:03:09<25:39:04, 13.91s/it] 48%|████▊     | 6188/12825 [22:03:21<24:55:39, 13.52s/it] 48%|████▊     | 6189/12825 [22:03:34<24:22:27, 13.22s/it] 48%|████▊     | 6190/12825 [22:03:46<23:59:07, 13.01s/it] 48%|████▊     | 6191/12825 [22:03:59<23:43:34, 12.88s/it] 48%|████▊     | 6192/12825 [22:04:12<23:32:11, 12.77s/it] 48%|████▊     | 6193/12825 [22:04:24<23:24:16, 12.70s/it] 48%|████▊     | 6194/12825 [22:04:37<23:18:37, 12.66s/it] 48%|████▊     | 6195/12825 [22:04:49<23:12:44, 12.60s/it] 48%|████▊     | 6196/12825 [22:05:02<23:12:42, 12.61s/it] 48%|████▊     | 6197/12825 [22:05:14<23:10:21, 12.59s/it] 48%|████▊     | 6198/12825 [22:05:27<23:07:50, 12.57s/it] 48%|████▊     | 6199/12825 [22:05:39<23:05:59, 12.55s/it] 48%|████▊     | 6200/12825 [22:05:52<23:07:12, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120122.63lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103205.92lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6175] due to args.save_total_limit
 48%|████▊     | 6201/12825 [22:06:05<23:17:21, 12.66s/it] 48%|████▊     | 6202/12825 [22:06:17<23:12:40, 12.62s/it] 48%|████▊     | 6203/12825 [22:06:30<23:09:37, 12.59s/it] 48%|████▊     | 6204/12825 [22:06:42<23:06:30, 12.56s/it] 48%|████▊     | 6205/12825 [22:06:55<23:05:28, 12.56s/it] 48%|████▊     | 6206/12825 [22:07:07<23:04:40, 12.55s/it] 48%|████▊     | 6207/12825 [22:07:20<23:03:52, 12.55s/it] 48%|████▊     | 6208/12825 [22:07:32<23:02:33, 12.54s/it] 48%|████▊     | 6209/12825 [22:07:45<23:02:48, 12.54s/it] 48%|████▊     | 6210/12825 [22:07:58<23:02:29, 12.54s/it] 48%|████▊     | 6211/12825 [22:08:10<23:00:49, 12.53s/it] 48%|████▊     | 6212/12825 [22:08:23<23:01:18, 12.53s/it] 48%|████▊     | 6213/12825 [22:08:35<23:00:16, 12.53s/it] 48%|████▊     | 6214/12825 [22:08:48<23:00:40, 12.53s/it] 48%|████▊     | 6215/12825 [22:09:00<22:59:44, 12.52s/it] 48%|████▊     | 6216/12825 [22:09:13<22:58:59, 12.52s/it] 48%|████▊     | 6217/12825 [22:09:25<22:58:33, 12.52s/it] 48%|████▊     | 6218/12825 [22:09:46<27:19:13, 14.89s/it] 48%|████▊     | 6219/12825 [22:09:58<26:03:31, 14.20s/it] 48%|████▊     | 6220/12825 [22:10:11<25:06:57, 13.69s/it] 49%|████▊     | 6221/12825 [22:10:23<24:28:07, 13.34s/it] 49%|████▊     | 6222/12825 [22:10:36<24:01:28, 13.10s/it] 49%|████▊     | 6223/12825 [22:10:48<23:42:53, 12.93s/it] 49%|████▊     | 6224/12825 [22:11:01<23:29:30, 12.81s/it] 49%|████▊     | 6225/12825 [22:11:13<23:18:49, 12.72s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120216.35lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 102957.56lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6200] due to args.save_total_limit
 49%|████▊     | 6226/12825 [22:11:26<23:26:37, 12.79s/it] 49%|████▊     | 6227/12825 [22:11:39<23:18:24, 12.72s/it] 49%|████▊     | 6228/12825 [22:11:51<23:11:13, 12.65s/it] 49%|████▊     | 6229/12825 [22:12:04<23:06:02, 12.61s/it] 49%|████▊     | 6230/12825 [22:12:16<23:05:43, 12.61s/it] 49%|████▊     | 6231/12825 [22:12:29<23:04:55, 12.60s/it] 49%|████▊     | 6232/12825 [22:12:42<23:03:47, 12.59s/it] 49%|████▊     | 6233/12825 [22:12:54<23:02:04, 12.58s/it] 49%|████▊     | 6234/12825 [22:13:07<22:59:05, 12.55s/it] 49%|████▊     | 6235/12825 [22:13:19<22:57:19, 12.54s/it] 49%|████▊     | 6236/12825 [22:13:32<22:55:40, 12.53s/it] 49%|████▊     | 6237/12825 [22:13:44<22:55:21, 12.53s/it] 49%|████▊     | 6238/12825 [22:13:57<22:54:33, 12.52s/it] 49%|████▊     | 6239/12825 [22:14:09<22:53:05, 12.51s/it] 49%|████▊     | 6240/12825 [22:14:22<22:54:08, 12.52s/it] 49%|████▊     | 6241/12825 [22:14:34<22:53:56, 12.52s/it] 49%|████▊     | 6242/12825 [22:14:47<22:57:44, 12.56s/it] 49%|████▊     | 6243/12825 [22:14:59<22:57:30, 12.56s/it] 49%|████▊     | 6244/12825 [22:15:12<22:56:16, 12.55s/it] 49%|████▊     | 6245/12825 [22:15:24<22:54:01, 12.53s/it] 49%|████▊     | 6246/12825 [22:15:37<22:53:36, 12.53s/it] 49%|████▊     | 6247/12825 [22:15:50<22:54:29, 12.54s/it] 49%|████▊     | 6248/12825 [22:16:02<22:53:08, 12.53s/it] 49%|████▊     | 6249/12825 [22:16:15<22:52:48, 12.53s/it] 49%|████▊     | 6250/12825 [22:16:35<27:10:21, 14.88s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120099.44lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103423.65lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6225] due to args.save_total_limit
 49%|████▊     | 6251/12825 [22:16:48<26:02:23, 14.26s/it] 49%|████▊     | 6252/12825 [22:17:00<25:05:39, 13.74s/it] 49%|████▉     | 6253/12825 [22:17:13<24:25:20, 13.38s/it] 49%|████▉     | 6254/12825 [22:17:25<23:57:10, 13.12s/it] 49%|████▉     | 6255/12825 [22:17:38<23:37:28, 12.95s/it] 49%|████▉     | 6256/12825 [22:17:50<23:22:54, 12.81s/it] 49%|████▉     | 6257/12825 [22:18:03<23:15:34, 12.75s/it] 49%|████▉     | 6258/12825 [22:18:16<23:09:13, 12.69s/it] 49%|████▉     | 6259/12825 [22:18:28<23:03:15, 12.64s/it] 49%|████▉     | 6260/12825 [22:18:41<22:59:16, 12.61s/it] 49%|████▉     | 6261/12825 [22:18:53<23:00:28, 12.62s/it] 49%|████▉     | 6262/12825 [22:19:06<22:57:57, 12.60s/it] 49%|████▉     | 6263/12825 [22:19:18<22:55:03, 12.57s/it] 49%|████▉     | 6264/12825 [22:19:31<22:57:28, 12.60s/it] 49%|████▉     | 6265/12825 [22:19:43<22:56:41, 12.59s/it] 49%|████▉     | 6266/12825 [22:19:56<22:54:25, 12.57s/it] 49%|████▉     | 6267/12825 [22:20:09<22:51:16, 12.55s/it] 49%|████▉     | 6268/12825 [22:20:21<22:50:14, 12.54s/it] 49%|████▉     | 6269/12825 [22:20:34<22:49:08, 12.53s/it] 49%|████▉     | 6270/12825 [22:20:46<22:49:50, 12.54s/it] 49%|████▉     | 6271/12825 [22:20:59<22:49:29, 12.54s/it] 49%|████▉     | 6272/12825 [22:21:11<22:47:29, 12.52s/it] 49%|████▉     | 6273/12825 [22:21:24<22:47:36, 12.52s/it] 49%|████▉     | 6274/12825 [22:21:36<22:48:39, 12.54s/it] 49%|████▉     | 6275/12825 [22:21:49<22:47:28, 12.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120192.11lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103502.01lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-5950] due to args.save_total_limit
 49%|████▉     | 6276/12825 [22:22:02<22:57:45, 12.62s/it] 49%|████▉     | 6277/12825 [22:22:14<22:55:20, 12.60s/it] 49%|████▉     | 6278/12825 [22:22:27<22:53:41, 12.59s/it] 49%|████▉     | 6279/12825 [22:22:39<22:51:09, 12.57s/it] 49%|████▉     | 6280/12825 [22:22:52<22:48:28, 12.55s/it] 49%|████▉     | 6281/12825 [22:23:04<22:47:45, 12.54s/it] 49%|████▉     | 6282/12825 [22:23:24<26:58:36, 14.84s/it] 49%|████▉     | 6283/12825 [22:23:37<25:42:02, 14.14s/it] 49%|████▉     | 6284/12825 [22:23:49<24:48:59, 13.66s/it] 49%|████▉     | 6285/12825 [22:24:02<24:13:06, 13.33s/it] 49%|████▉     | 6286/12825 [22:24:15<23:48:53, 13.11s/it] 49%|████▉     | 6287/12825 [22:24:27<23:29:00, 12.93s/it] 49%|████▉     | 6288/12825 [22:24:40<23:14:21, 12.80s/it] 49%|████▉     | 6289/12825 [22:24:52<23:05:02, 12.71s/it] 49%|████▉     | 6290/12825 [22:25:05<22:58:33, 12.66s/it] 49%|████▉     | 6291/12825 [22:25:17<22:54:23, 12.62s/it] 49%|████▉     | 6292/12825 [22:25:30<22:50:20, 12.59s/it] 49%|████▉     | 6293/12825 [22:25:42<22:47:56, 12.57s/it] 49%|████▉     | 6294/12825 [22:25:55<22:46:18, 12.55s/it] 49%|████▉     | 6295/12825 [22:26:07<22:44:25, 12.54s/it] 49%|████▉     | 6296/12825 [22:26:20<22:43:43, 12.53s/it] 49%|████▉     | 6297/12825 [22:26:32<22:42:15, 12.52s/it] 49%|████▉     | 6298/12825 [22:26:45<22:41:41, 12.52s/it] 49%|████▉     | 6299/12825 [22:26:57<22:40:42, 12.51s/it] 49%|████▉     | 6300/12825 [22:27:10<22:40:47, 12.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120210.74lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103499.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6250] due to args.save_total_limit
 49%|████▉     | 6301/12825 [22:27:23<22:52:20, 12.62s/it] 49%|████▉     | 6302/12825 [22:27:35<22:47:53, 12.58s/it] 49%|████▉     | 6303/12825 [22:27:48<22:46:06, 12.57s/it] 49%|████▉     | 6304/12825 [22:28:00<22:45:01, 12.56s/it] 49%|████▉     | 6305/12825 [22:28:13<22:43:34, 12.55s/it] 49%|████▉     | 6306/12825 [22:28:26<23:05:01, 12.75s/it] 49%|████▉     | 6307/12825 [22:28:39<22:58:31, 12.69s/it] 49%|████▉     | 6308/12825 [22:28:51<22:53:15, 12.64s/it] 49%|████▉     | 6309/12825 [22:29:04<22:49:05, 12.61s/it] 49%|████▉     | 6310/12825 [22:29:16<22:46:40, 12.59s/it] 49%|████▉     | 6311/12825 [22:29:29<22:43:42, 12.56s/it] 49%|████▉     | 6312/12825 [22:29:41<22:41:20, 12.54s/it] 49%|████▉     | 6313/12825 [22:29:54<22:41:21, 12.54s/it] 49%|████▉     | 6314/12825 [22:30:06<22:40:19, 12.54s/it] 49%|████▉     | 6315/12825 [22:30:27<26:57:26, 14.91s/it] 49%|████▉     | 6316/12825 [22:30:39<25:39:38, 14.19s/it] 49%|████▉     | 6317/12825 [22:30:52<24:45:38, 13.70s/it] 49%|████▉     | 6318/12825 [22:31:04<24:07:15, 13.34s/it] 49%|████▉     | 6319/12825 [22:31:17<23:40:03, 13.10s/it] 49%|████▉     | 6320/12825 [22:31:29<23:22:05, 12.93s/it] 49%|████▉     | 6321/12825 [22:31:42<23:07:50, 12.80s/it] 49%|████▉     | 6322/12825 [22:31:54<22:58:26, 12.72s/it] 49%|████▉     | 6323/12825 [22:32:07<22:53:14, 12.67s/it] 49%|████▉     | 6324/12825 [22:32:19<22:49:29, 12.64s/it] 49%|████▉     | 6325/12825 [22:32:32<22:45:41, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120157.93lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103398.15lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6300] due to args.save_total_limit
 49%|████▉     | 6326/12825 [22:32:45<22:52:39, 12.67s/it] 49%|████▉     | 6327/12825 [22:32:57<22:47:33, 12.63s/it] 49%|████▉     | 6328/12825 [22:33:10<22:43:59, 12.60s/it] 49%|████▉     | 6329/12825 [22:33:22<22:41:17, 12.57s/it] 49%|████▉     | 6330/12825 [22:33:35<22:37:16, 12.54s/it] 49%|████▉     | 6331/12825 [22:33:47<22:35:04, 12.52s/it] 49%|████▉     | 6332/12825 [22:34:00<22:34:39, 12.52s/it] 49%|████▉     | 6333/12825 [22:34:12<22:34:36, 12.52s/it] 49%|████▉     | 6334/12825 [22:34:25<22:34:50, 12.52s/it] 49%|████▉     | 6335/12825 [22:34:37<22:34:56, 12.53s/it] 49%|████▉     | 6336/12825 [22:34:50<22:33:35, 12.52s/it] 49%|████▉     | 6337/12825 [22:35:03<22:38:45, 12.57s/it] 49%|████▉     | 6338/12825 [22:35:15<22:43:09, 12.61s/it] 49%|████▉     | 6339/12825 [22:35:28<22:42:59, 12.61s/it] 49%|████▉     | 6340/12825 [22:35:41<22:44:09, 12.62s/it] 49%|████▉     | 6341/12825 [22:35:53<22:45:02, 12.63s/it] 49%|████▉     | 6342/12825 [22:36:06<22:46:04, 12.64s/it] 49%|████▉     | 6343/12825 [22:36:18<22:46:07, 12.65s/it] 49%|████▉     | 6344/12825 [22:36:31<22:45:54, 12.65s/it] 49%|████▉     | 6345/12825 [22:36:44<22:45:28, 12.64s/it] 49%|████▉     | 6346/12825 [22:36:56<22:45:31, 12.65s/it] 49%|████▉     | 6347/12825 [22:37:17<26:54:41, 14.96s/it] 49%|████▉     | 6348/12825 [22:37:29<25:39:49, 14.26s/it] 50%|████▉     | 6349/12825 [22:37:42<24:48:13, 13.79s/it] 50%|████▉     | 6350/12825 [22:37:55<24:11:33, 13.45s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120311.76lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103499.65lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6325] due to args.save_total_limit
 50%|████▉     | 6351/12825 [22:38:08<23:55:17, 13.30s/it] 50%|████▉     | 6352/12825 [22:38:20<23:34:09, 13.11s/it] 50%|████▉     | 6353/12825 [22:38:33<23:18:18, 12.96s/it] 50%|████▉     | 6354/12825 [22:38:46<23:08:24, 12.87s/it] 50%|████▉     | 6355/12825 [22:38:58<23:01:40, 12.81s/it] 50%|████▉     | 6356/12825 [22:39:11<22:55:05, 12.75s/it] 50%|████▉     | 6357/12825 [22:39:24<22:51:01, 12.72s/it] 50%|████▉     | 6358/12825 [22:39:36<22:47:47, 12.69s/it] 50%|████▉     | 6359/12825 [22:39:49<22:46:32, 12.68s/it] 50%|████▉     | 6360/12825 [22:40:01<22:44:31, 12.66s/it] 50%|████▉     | 6361/12825 [22:40:14<22:43:37, 12.66s/it] 50%|████▉     | 6362/12825 [22:40:27<22:42:36, 12.65s/it] 50%|████▉     | 6363/12825 [22:40:39<22:41:54, 12.65s/it] 50%|████▉     | 6364/12825 [22:40:52<22:41:11, 12.64s/it] 50%|████▉     | 6365/12825 [22:41:05<22:40:33, 12.64s/it] 50%|████▉     | 6366/12825 [22:41:17<22:38:54, 12.62s/it] 50%|████▉     | 6367/12825 [22:41:30<22:39:33, 12.63s/it] 50%|████▉     | 6368/12825 [22:41:43<22:38:52, 12.63s/it] 50%|████▉     | 6369/12825 [22:41:55<22:38:38, 12.63s/it] 50%|████▉     | 6370/12825 [22:42:08<22:39:29, 12.64s/it] 50%|████▉     | 6371/12825 [22:42:20<22:39:39, 12.64s/it] 50%|████▉     | 6372/12825 [22:42:33<22:38:26, 12.63s/it] 50%|████▉     | 6373/12825 [22:42:46<22:39:47, 12.65s/it] 50%|████▉     | 6374/12825 [22:42:58<22:39:21, 12.64s/it] 50%|████▉     | 6375/12825 [22:43:11<22:44:52, 12.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120395.79lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103589.68lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6350] due to args.save_total_limit
 50%|████▉     | 6376/12825 [22:43:24<22:53:25, 12.78s/it] 50%|████▉     | 6377/12825 [22:43:37<22:48:31, 12.73s/it] 50%|████▉     | 6378/12825 [22:43:49<22:45:23, 12.71s/it] 50%|████▉     | 6379/12825 [22:44:10<26:51:39, 15.00s/it] 50%|████▉     | 6380/12825 [22:44:22<25:34:52, 14.29s/it] 50%|████▉     | 6381/12825 [22:44:35<24:40:59, 13.79s/it] 50%|████▉     | 6382/12825 [22:44:48<24:02:59, 13.44s/it] 50%|████▉     | 6383/12825 [22:45:00<23:36:45, 13.20s/it] 50%|████▉     | 6384/12825 [22:45:13<23:18:13, 13.02s/it] 50%|████▉     | 6385/12825 [22:45:26<23:06:50, 12.92s/it] 50%|████▉     | 6386/12825 [22:45:38<22:57:48, 12.84s/it] 50%|████▉     | 6387/12825 [22:45:51<22:51:56, 12.79s/it] 50%|████▉     | 6388/12825 [22:46:04<22:47:24, 12.75s/it] 50%|████▉     | 6389/12825 [22:46:16<22:44:23, 12.72s/it] 50%|████▉     | 6390/12825 [22:46:29<22:42:15, 12.70s/it] 50%|████▉     | 6391/12825 [22:46:42<22:40:46, 12.69s/it] 50%|████▉     | 6392/12825 [22:46:54<22:38:29, 12.67s/it] 50%|████▉     | 6393/12825 [22:47:07<22:38:20, 12.67s/it] 50%|████▉     | 6394/12825 [22:47:19<22:36:14, 12.65s/it] 50%|████▉     | 6395/12825 [22:47:32<22:35:22, 12.65s/it] 50%|████▉     | 6396/12825 [22:47:45<22:35:09, 12.65s/it] 50%|████▉     | 6397/12825 [22:47:57<22:33:11, 12.63s/it] 50%|████▉     | 6398/12825 [22:48:10<22:33:13, 12.63s/it] 50%|████▉     | 6399/12825 [22:48:23<22:32:28, 12.63s/it] 50%|████▉     | 6400/12825 [22:48:35<22:33:30, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120406.29lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103622.86lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6375] due to args.save_total_limit
 50%|████▉     | 6401/12825 [22:48:48<22:43:57, 12.74s/it] 50%|████▉     | 6402/12825 [22:49:01<22:38:04, 12.69s/it] 50%|████▉     | 6403/12825 [22:49:13<22:34:44, 12.66s/it] 50%|████▉     | 6404/12825 [22:49:26<22:33:03, 12.64s/it] 50%|████▉     | 6405/12825 [22:49:39<22:31:36, 12.63s/it] 50%|████▉     | 6406/12825 [22:49:51<22:31:00, 12.63s/it] 50%|████▉     | 6407/12825 [22:50:04<22:31:19, 12.63s/it] 50%|████▉     | 6408/12825 [22:50:16<22:29:15, 12.62s/it] 50%|████▉     | 6409/12825 [22:50:29<22:28:30, 12.61s/it] 50%|████▉     | 6410/12825 [22:50:42<22:29:31, 12.62s/it] 50%|████▉     | 6411/12825 [22:50:54<22:29:38, 12.63s/it] 50%|████▉     | 6412/12825 [22:51:14<26:25:38, 14.84s/it] 50%|█████     | 6413/12825 [22:51:27<25:15:55, 14.19s/it] 50%|█████     | 6414/12825 [22:51:40<24:25:42, 13.72s/it] 50%|█████     | 6415/12825 [22:51:52<23:50:34, 13.39s/it] 50%|█████     | 6416/12825 [22:52:05<23:26:16, 13.17s/it] 50%|█████     | 6417/12825 [22:52:17<23:08:02, 13.00s/it] 50%|█████     | 6418/12825 [22:52:30<22:56:44, 12.89s/it] 50%|█████     | 6419/12825 [22:52:43<22:47:59, 12.81s/it] 50%|█████     | 6420/12825 [22:52:55<22:42:59, 12.77s/it] 50%|█████     | 6421/12825 [22:53:08<22:38:47, 12.73s/it] 50%|█████     | 6422/12825 [22:53:21<22:35:37, 12.70s/it] 50%|█████     | 6423/12825 [22:53:33<22:32:55, 12.68s/it] 50%|█████     | 6424/12825 [22:53:46<22:30:48, 12.66s/it] 50%|█████     | 6425/12825 [22:53:59<22:30:11, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120450.60lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103572.82lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6400] due to args.save_total_limit
 50%|█████     | 6426/12825 [22:54:12<22:40:39, 12.76s/it] 50%|█████     | 6427/12825 [22:54:24<22:36:02, 12.72s/it] 50%|█████     | 6428/12825 [22:54:37<22:33:13, 12.69s/it] 50%|█████     | 6429/12825 [22:54:49<22:30:18, 12.67s/it] 50%|█████     | 6430/12825 [22:55:02<22:29:22, 12.66s/it] 50%|█████     | 6431/12825 [22:55:15<22:29:05, 12.66s/it] 50%|█████     | 6432/12825 [22:55:27<22:28:14, 12.65s/it] 50%|█████     | 6433/12825 [22:55:40<22:26:28, 12.64s/it] 50%|█████     | 6434/12825 [22:55:53<22:24:56, 12.63s/it] 50%|█████     | 6435/12825 [22:56:05<22:26:04, 12.64s/it] 50%|█████     | 6436/12825 [22:56:18<22:24:41, 12.63s/it] 50%|█████     | 6437/12825 [22:56:30<22:24:20, 12.63s/it] 50%|█████     | 6438/12825 [22:56:43<22:23:41, 12.62s/it] 50%|█████     | 6439/12825 [22:56:56<22:24:52, 12.64s/it] 50%|█████     | 6440/12825 [22:57:08<22:25:25, 12.64s/it] 50%|█████     | 6441/12825 [22:57:21<22:25:26, 12.65s/it] 50%|█████     | 6442/12825 [22:57:34<22:24:36, 12.64s/it] 50%|█████     | 6443/12825 [22:57:46<22:24:06, 12.64s/it] 50%|█████     | 6444/12825 [22:58:06<26:22:05, 14.88s/it] 50%|█████     | 6445/12825 [22:58:19<25:10:30, 14.21s/it] 50%|█████     | 6446/12825 [22:58:32<24:19:32, 13.73s/it] 50%|█████     | 6447/12825 [22:58:44<23:45:06, 13.41s/it] 50%|█████     | 6448/12825 [22:58:57<23:19:14, 13.17s/it] 50%|█████     | 6449/12825 [22:59:10<23:00:42, 12.99s/it] 50%|█████     | 6450/12825 [22:59:22<22:48:01, 12.88s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120650.92lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103917.05lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6425] due to args.save_total_limit
 50%|█████     | 6451/12825 [22:59:35<22:49:13, 12.89s/it] 50%|█████     | 6452/12825 [22:59:48<22:40:45, 12.81s/it] 50%|█████     | 6453/12825 [23:00:00<22:33:45, 12.75s/it] 50%|█████     | 6454/12825 [23:00:13<22:29:03, 12.71s/it] 50%|█████     | 6455/12825 [23:00:26<22:26:36, 12.68s/it] 50%|█████     | 6456/12825 [23:00:38<22:24:06, 12.66s/it] 50%|█████     | 6457/12825 [23:00:51<22:22:40, 12.65s/it] 50%|█████     | 6458/12825 [23:01:03<22:21:08, 12.64s/it] 50%|█████     | 6459/12825 [23:01:16<22:19:43, 12.63s/it] 50%|█████     | 6460/12825 [23:01:29<22:19:49, 12.63s/it] 50%|█████     | 6461/12825 [23:01:41<22:19:22, 12.63s/it] 50%|█████     | 6462/12825 [23:01:54<22:19:09, 12.63s/it] 50%|█████     | 6463/12825 [23:02:06<22:19:04, 12.63s/it] 50%|█████     | 6464/12825 [23:02:19<22:18:13, 12.62s/it] 50%|█████     | 6465/12825 [23:02:32<22:17:42, 12.62s/it] 50%|█████     | 6466/12825 [23:02:44<22:18:45, 12.63s/it] 50%|█████     | 6467/12825 [23:02:57<22:17:54, 12.63s/it] 50%|█████     | 6468/12825 [23:03:10<22:17:00, 12.62s/it] 50%|█████     | 6469/12825 [23:03:22<22:15:43, 12.61s/it] 50%|█████     | 6470/12825 [23:03:35<22:16:12, 12.62s/it] 50%|█████     | 6471/12825 [23:03:47<22:16:49, 12.62s/it] 50%|█████     | 6472/12825 [23:04:00<22:17:20, 12.63s/it] 50%|█████     | 6473/12825 [23:04:13<22:16:42, 12.63s/it] 50%|█████     | 6474/12825 [23:04:25<22:17:56, 12.64s/it] 50%|█████     | 6475/12825 [23:04:38<22:17:31, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120462.26lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103670.00lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6450] due to args.save_total_limit
 50%|█████     | 6476/12825 [23:04:51<22:28:24, 12.74s/it] 51%|█████     | 6477/12825 [23:05:11<26:23:08, 14.96s/it] 51%|█████     | 6478/12825 [23:05:24<25:09:01, 14.27s/it] 51%|█████     | 6479/12825 [23:05:36<24:16:24, 13.77s/it] 51%|█████     | 6480/12825 [23:05:49<23:40:27, 13.43s/it] 51%|█████     | 6481/12825 [23:06:02<23:15:05, 13.19s/it] 51%|█████     | 6482/12825 [23:06:14<22:56:50, 13.02s/it] 51%|█████     | 6483/12825 [23:06:27<22:44:27, 12.91s/it] 51%|█████     | 6484/12825 [23:06:40<22:35:32, 12.83s/it] 51%|█████     | 6485/12825 [23:06:52<22:29:13, 12.77s/it] 51%|█████     | 6486/12825 [23:07:05<22:25:56, 12.74s/it] 51%|█████     | 6487/12825 [23:07:18<22:22:31, 12.71s/it] 51%|█████     | 6488/12825 [23:07:30<22:19:55, 12.69s/it] 51%|█████     | 6489/12825 [23:07:43<22:18:50, 12.68s/it] 51%|█████     | 6490/12825 [23:07:55<22:17:25, 12.67s/it] 51%|█████     | 6491/12825 [23:08:08<22:16:01, 12.66s/it] 51%|█████     | 6492/12825 [23:08:21<22:17:14, 12.67s/it] 51%|█████     | 6493/12825 [23:08:33<22:16:57, 12.67s/it] 51%|█████     | 6494/12825 [23:08:46<22:17:06, 12.67s/it] 51%|█████     | 6495/12825 [23:08:59<22:15:42, 12.66s/it] 51%|█████     | 6496/12825 [23:09:11<22:14:47, 12.65s/it] 51%|█████     | 6497/12825 [23:09:24<22:15:21, 12.66s/it] 51%|█████     | 6498/12825 [23:09:37<22:14:24, 12.65s/it] 51%|█████     | 6499/12825 [23:09:49<22:14:04, 12.65s/it] 51%|█████     | 6500/12825 [23:10:02<22:15:09, 12.67s/it]                                                           51%|█████     | 6500/12825 [23:10:02<22:15:09, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120254.01lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103403.06lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6475] due to args.save_total_limit
 51%|█████     | 6501/12825 [23:10:15<22:26:14, 12.77s/it] 51%|█████     | 6502/12825 [23:10:28<22:21:24, 12.73s/it] 51%|█████     | 6503/12825 [23:10:40<22:18:18, 12.70s/it] 51%|█████     | 6504/12825 [23:10:53<22:15:28, 12.68s/it] 51%|█████     | 6505/12825 [23:11:06<22:13:53, 12.66s/it] 51%|█████     | 6506/12825 [23:11:18<22:11:32, 12.64s/it] 51%|█████     | 6507/12825 [23:11:31<22:10:25, 12.63s/it] 51%|█████     | 6508/12825 [23:11:43<22:10:29, 12.64s/it] 51%|█████     | 6509/12825 [23:12:04<26:05:55, 14.88s/it] 51%|█████     | 6510/12825 [23:12:16<24:56:10, 14.22s/it] 51%|█████     | 6511/12825 [23:12:29<24:06:18, 13.74s/it] 51%|█████     | 6512/12825 [23:12:42<23:32:41, 13.43s/it] 51%|█████     | 6513/12825 [23:12:54<23:08:10, 13.20s/it] 51%|█████     | 6514/12825 [23:13:07<22:50:00, 13.03s/it] 51%|█████     | 6515/12825 [23:13:19<22:36:28, 12.90s/it] 51%|█████     | 6516/12825 [23:13:32<22:26:46, 12.81s/it] 51%|█████     | 6517/12825 [23:13:45<22:21:06, 12.76s/it] 51%|█████     | 6518/12825 [23:13:57<22:17:47, 12.73s/it] 51%|█████     | 6519/12825 [23:14:10<22:16:33, 12.72s/it] 51%|█████     | 6520/12825 [23:14:23<22:15:16, 12.71s/it] 51%|█████     | 6521/12825 [23:14:35<22:14:15, 12.70s/it] 51%|█████     | 6522/12825 [23:14:48<22:12:51, 12.69s/it] 51%|█████     | 6523/12825 [23:15:01<22:12:05, 12.68s/it] 51%|█████     | 6524/12825 [23:15:13<22:10:45, 12.67s/it] 51%|█████     | 6525/12825 [23:15:26<22:09:58, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120439.45lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103646.28lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6500] due to args.save_total_limit
 51%|█████     | 6526/12825 [23:15:39<22:18:02, 12.75s/it] 51%|█████     | 6527/12825 [23:15:52<22:16:05, 12.73s/it] 51%|█████     | 6528/12825 [23:16:04<22:13:28, 12.71s/it] 51%|█████     | 6529/12825 [23:16:17<22:12:07, 12.69s/it] 51%|█████     | 6530/12825 [23:16:30<22:11:32, 12.69s/it] 51%|█████     | 6531/12825 [23:16:42<22:10:38, 12.68s/it] 51%|█████     | 6532/12825 [23:16:55<22:08:09, 12.66s/it] 51%|█████     | 6533/12825 [23:17:08<22:08:55, 12.67s/it] 51%|█████     | 6534/12825 [23:17:20<22:08:20, 12.67s/it] 51%|█████     | 6535/12825 [23:17:33<22:07:13, 12.66s/it] 51%|█████     | 6536/12825 [23:17:46<22:06:44, 12.66s/it] 51%|█████     | 6537/12825 [23:17:58<22:08:14, 12.67s/it] 51%|█████     | 6538/12825 [23:18:11<22:08:02, 12.67s/it] 51%|█████     | 6539/12825 [23:18:24<22:06:34, 12.66s/it] 51%|█████     | 6540/12825 [23:18:36<22:04:52, 12.65s/it] 51%|█████     | 6541/12825 [23:18:57<26:08:24, 14.98s/it] 51%|█████     | 6542/12825 [23:19:09<24:56:14, 14.29s/it] 51%|█████     | 6543/12825 [23:19:22<24:04:53, 13.80s/it] 51%|█████     | 6544/12825 [23:19:35<23:29:35, 13.47s/it] 51%|█████     | 6545/12825 [23:19:47<23:03:58, 13.22s/it] 51%|█████     | 6546/12825 [23:20:00<22:45:24, 13.05s/it] 51%|█████     | 6547/12825 [23:20:13<22:33:23, 12.93s/it] 51%|█████     | 6548/12825 [23:20:25<22:25:18, 12.86s/it] 51%|█████     | 6549/12825 [23:20:38<22:17:46, 12.79s/it] 51%|█████     | 6550/12825 [23:20:51<22:12:13, 12.74s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120422.93lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 98879.08lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6525] due to args.save_total_limit
 51%|█████     | 6551/12825 [23:21:04<22:26:11, 12.87s/it] 51%|█████     | 6552/12825 [23:21:16<22:18:58, 12.81s/it] 51%|█████     | 6553/12825 [23:21:29<22:13:10, 12.75s/it] 51%|█████     | 6554/12825 [23:21:42<22:10:32, 12.73s/it] 51%|█████     | 6555/12825 [23:21:54<22:07:38, 12.70s/it] 51%|█████     | 6556/12825 [23:22:07<22:04:52, 12.68s/it] 51%|█████     | 6557/12825 [23:22:20<22:03:53, 12.67s/it] 51%|█████     | 6558/12825 [23:22:32<22:02:34, 12.66s/it] 51%|█████     | 6559/12825 [23:22:45<22:01:01, 12.65s/it] 51%|█████     | 6560/12825 [23:22:58<22:00:30, 12.65s/it] 51%|█████     | 6561/12825 [23:23:10<21:59:57, 12.64s/it] 51%|█████     | 6562/12825 [23:23:23<21:58:11, 12.63s/it] 51%|█████     | 6563/12825 [23:23:35<21:56:39, 12.62s/it] 51%|█████     | 6564/12825 [23:23:48<21:57:02, 12.62s/it] 51%|█████     | 6565/12825 [23:24:01<21:56:56, 12.62s/it] 51%|█████     | 6566/12825 [23:24:13<21:57:06, 12.63s/it] 51%|█████     | 6567/12825 [23:24:26<21:56:13, 12.62s/it] 51%|█████     | 6568/12825 [23:24:38<21:56:56, 12.63s/it] 51%|█████     | 6569/12825 [23:24:51<21:55:41, 12.62s/it] 51%|█████     | 6570/12825 [23:25:04<21:55:47, 12.62s/it] 51%|█████     | 6571/12825 [23:25:16<21:55:08, 12.62s/it] 51%|█████     | 6572/12825 [23:25:29<21:54:37, 12.61s/it] 51%|█████▏    | 6573/12825 [23:25:42<21:54:35, 12.62s/it] 51%|█████▏    | 6574/12825 [23:26:02<25:54:41, 14.92s/it] 51%|█████▏    | 6575/12825 [23:26:14<24:43:00, 14.24s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120361.63lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103575.66lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6550] due to args.save_total_limit
 51%|█████▏    | 6576/12825 [23:26:27<24:03:05, 13.86s/it] 51%|█████▏    | 6577/12825 [23:26:40<23:24:27, 13.49s/it] 51%|█████▏    | 6578/12825 [23:26:53<22:57:35, 13.23s/it] 51%|█████▏    | 6579/12825 [23:27:05<22:38:47, 13.05s/it] 51%|█████▏    | 6580/12825 [23:27:18<22:26:08, 12.93s/it] 51%|█████▏    | 6581/12825 [23:27:31<22:16:03, 12.84s/it] 51%|█████▏    | 6582/12825 [23:27:43<22:09:13, 12.77s/it] 51%|█████▏    | 6583/12825 [23:27:56<22:05:20, 12.74s/it] 51%|█████▏    | 6584/12825 [23:28:09<22:01:18, 12.70s/it] 51%|█████▏    | 6585/12825 [23:28:21<22:00:04, 12.69s/it] 51%|█████▏    | 6586/12825 [23:28:34<21:58:07, 12.68s/it] 51%|█████▏    | 6587/12825 [23:28:46<21:57:26, 12.67s/it] 51%|█████▏    | 6588/12825 [23:28:59<21:56:27, 12.66s/it] 51%|█████▏    | 6589/12825 [23:29:12<21:54:18, 12.65s/it] 51%|█████▏    | 6590/12825 [23:29:24<21:56:15, 12.67s/it] 51%|█████▏    | 6591/12825 [23:29:37<21:55:35, 12.66s/it] 51%|█████▏    | 6592/12825 [23:29:50<21:55:29, 12.66s/it] 51%|█████▏    | 6593/12825 [23:30:02<21:56:17, 12.67s/it] 51%|█████▏    | 6594/12825 [23:30:15<21:55:00, 12.66s/it] 51%|█████▏    | 6595/12825 [23:30:28<21:53:27, 12.65s/it] 51%|█████▏    | 6596/12825 [23:30:40<21:53:59, 12.66s/it] 51%|█████▏    | 6597/12825 [23:30:53<21:54:54, 12.67s/it] 51%|█████▏    | 6598/12825 [23:31:06<21:54:33, 12.67s/it] 51%|█████▏    | 6599/12825 [23:31:18<21:53:05, 12.65s/it] 51%|█████▏    | 6600/12825 [23:31:31<21:53:15, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120461.11lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103650.17lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6575] due to args.save_total_limit
 51%|█████▏    | 6601/12825 [23:31:44<22:06:05, 12.78s/it] 51%|█████▏    | 6602/12825 [23:31:57<22:00:45, 12.73s/it] 51%|█████▏    | 6603/12825 [23:32:09<21:57:30, 12.71s/it] 51%|█████▏    | 6604/12825 [23:32:22<21:55:03, 12.68s/it] 52%|█████▏    | 6605/12825 [23:32:35<21:52:17, 12.66s/it] 52%|█████▏    | 6606/12825 [23:32:55<25:52:01, 14.97s/it] 52%|█████▏    | 6607/12825 [23:33:08<24:49:09, 14.37s/it] 52%|█████▏    | 6608/12825 [23:33:21<23:58:54, 13.89s/it] 52%|█████▏    | 6609/12825 [23:33:33<23:20:29, 13.52s/it] 52%|█████▏    | 6610/12825 [23:33:46<22:58:45, 13.31s/it] 52%|█████▏    | 6611/12825 [23:33:59<22:42:16, 13.15s/it] 52%|█████▏    | 6612/12825 [23:34:12<22:30:07, 13.04s/it] 52%|█████▏    | 6613/12825 [23:34:25<22:21:08, 12.95s/it] 52%|█████▏    | 6614/12825 [23:34:37<22:15:08, 12.90s/it] 52%|█████▏    | 6615/12825 [23:34:50<22:11:49, 12.87s/it] 52%|█████▏    | 6616/12825 [23:35:03<22:10:01, 12.85s/it] 52%|█████▏    | 6617/12825 [23:35:16<22:08:32, 12.84s/it] 52%|█████▏    | 6618/12825 [23:35:28<22:04:04, 12.80s/it] 52%|█████▏    | 6619/12825 [23:35:41<22:03:30, 12.80s/it] 52%|█████▏    | 6620/12825 [23:35:54<22:02:17, 12.79s/it] 52%|█████▏    | 6621/12825 [23:36:07<22:00:25, 12.77s/it] 52%|█████▏    | 6622/12825 [23:36:19<21:59:35, 12.76s/it] 52%|█████▏    | 6623/12825 [23:36:32<22:00:33, 12.78s/it] 52%|█████▏    | 6624/12825 [23:36:45<21:55:58, 12.73s/it] 52%|█████▏    | 6625/12825 [23:36:58<21:57:19, 12.75s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120452.14lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103746.74lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6600] due to args.save_total_limit
 52%|█████▏    | 6626/12825 [23:37:11<22:08:58, 12.86s/it] 52%|█████▏    | 6627/12825 [23:37:24<22:04:52, 12.83s/it] 52%|█████▏    | 6628/12825 [23:37:36<22:02:25, 12.80s/it] 52%|█████▏    | 6629/12825 [23:37:49<22:02:00, 12.80s/it] 52%|█████▏    | 6630/12825 [23:38:02<22:01:05, 12.80s/it] 52%|█████▏    | 6631/12825 [23:38:15<21:59:37, 12.78s/it] 52%|█████▏    | 6632/12825 [23:38:27<22:00:26, 12.79s/it] 52%|█████▏    | 6633/12825 [23:38:40<22:00:26, 12.80s/it] 52%|█████▏    | 6634/12825 [23:38:53<21:58:01, 12.77s/it] 52%|█████▏    | 6635/12825 [23:39:06<21:54:02, 12.74s/it] 52%|█████▏    | 6636/12825 [23:39:18<21:50:53, 12.71s/it] 52%|█████▏    | 6637/12825 [23:39:31<21:49:15, 12.69s/it] 52%|█████▏    | 6638/12825 [23:39:51<25:48:31, 15.02s/it] 52%|█████▏    | 6639/12825 [23:40:04<24:33:12, 14.29s/it] 52%|█████▏    | 6640/12825 [23:40:17<23:42:13, 13.80s/it] 52%|█████▏    | 6641/12825 [23:40:29<23:05:58, 13.45s/it] 52%|█████▏    | 6642/12825 [23:40:42<22:39:50, 13.20s/it] 52%|█████▏    | 6643/12825 [23:40:54<22:22:57, 13.03s/it] 52%|█████▏    | 6644/12825 [23:41:07<22:10:11, 12.91s/it] 52%|█████▏    | 6645/12825 [23:41:20<22:03:57, 12.85s/it] 52%|█████▏    | 6646/12825 [23:41:33<21:58:17, 12.80s/it] 52%|█████▏    | 6647/12825 [23:41:45<21:54:56, 12.77s/it] 52%|█████▏    | 6648/12825 [23:41:58<21:51:36, 12.74s/it] 52%|█████▏    | 6649/12825 [23:42:11<21:50:27, 12.73s/it] 52%|█████▏    | 6650/12825 [23:42:23<21:51:17, 12.74s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120547.40lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103811.32lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6625] due to args.save_total_limit
 52%|█████▏    | 6651/12825 [23:42:36<22:01:26, 12.84s/it] 52%|█████▏    | 6652/12825 [23:42:49<21:57:57, 12.81s/it] 52%|█████▏    | 6653/12825 [23:43:02<21:53:47, 12.77s/it] 52%|█████▏    | 6654/12825 [23:43:15<21:50:20, 12.74s/it] 52%|█████▏    | 6655/12825 [23:43:27<21:50:04, 12.74s/it] 52%|█████▏    | 6656/12825 [23:43:40<21:51:15, 12.75s/it] 52%|█████▏    | 6657/12825 [23:43:53<21:52:22, 12.77s/it] 52%|█████▏    | 6658/12825 [23:44:05<21:48:49, 12.73s/it] 52%|█████▏    | 6659/12825 [23:44:18<21:46:24, 12.71s/it] 52%|█████▏    | 6660/12825 [23:44:31<21:43:49, 12.69s/it] 52%|█████▏    | 6661/12825 [23:44:43<21:43:03, 12.68s/it] 52%|█████▏    | 6662/12825 [23:44:56<21:43:54, 12.69s/it] 52%|█████▏    | 6663/12825 [23:45:09<21:46:42, 12.72s/it] 52%|█████▏    | 6664/12825 [23:45:22<21:47:27, 12.73s/it] 52%|█████▏    | 6665/12825 [23:45:34<21:46:34, 12.73s/it] 52%|█████▏    | 6666/12825 [23:45:47<21:45:23, 12.72s/it] 52%|█████▏    | 6667/12825 [23:46:00<21:47:06, 12.74s/it] 52%|█████▏    | 6668/12825 [23:46:08<19:21:05, 11.31s/it] 52%|█████▏    | 6669/12825 [23:46:09<13:57:57,  8.17s/it] 52%|█████▏    | 6670/12825 [23:46:35<23:07:08, 13.52s/it] 52%|█████▏    | 6671/12825 [23:46:55<26:43:11, 15.63s/it] 52%|█████▏    | 6672/12825 [23:47:08<25:10:59, 14.73s/it] 52%|█████▏    | 6673/12825 [23:47:21<24:10:46, 14.15s/it] 52%|█████▏    | 6674/12825 [23:47:34<23:29:18, 13.75s/it] 52%|█████▏    | 6675/12825 [23:47:46<22:58:41, 13.45s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120520.97lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103760.62lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6275] due to args.save_total_limit
 52%|█████▏    | 6676/12825 [23:47:59<22:50:13, 13.37s/it] 52%|█████▏    | 6677/12825 [23:48:12<22:32:35, 13.20s/it] 52%|█████▏    | 6678/12825 [23:48:25<22:22:36, 13.10s/it] 52%|█████▏    | 6679/12825 [23:48:38<22:13:39, 13.02s/it] 52%|█████▏    | 6680/12825 [23:48:51<22:08:15, 12.97s/it] 52%|█████▏    | 6681/12825 [23:49:04<22:04:11, 12.93s/it] 52%|█████▏    | 6682/12825 [23:49:16<22:00:19, 12.90s/it] 52%|█████▏    | 6683/12825 [23:49:29<21:59:21, 12.89s/it] 52%|█████▏    | 6684/12825 [23:49:42<21:57:55, 12.88s/it] 52%|█████▏    | 6685/12825 [23:49:55<21:56:04, 12.86s/it] 52%|█████▏    | 6686/12825 [23:50:08<21:56:30, 12.87s/it] 52%|█████▏    | 6687/12825 [23:50:21<21:56:05, 12.86s/it] 52%|█████▏    | 6688/12825 [23:50:34<21:53:51, 12.85s/it] 52%|█████▏    | 6689/12825 [23:50:46<21:52:48, 12.84s/it] 52%|█████▏    | 6690/12825 [23:50:59<21:52:06, 12.83s/it] 52%|█████▏    | 6691/12825 [23:51:12<21:51:27, 12.83s/it] 52%|█████▏    | 6692/12825 [23:51:25<21:51:27, 12.83s/it] 52%|█████▏    | 6693/12825 [23:51:38<21:50:50, 12.83s/it] 52%|█████▏    | 6694/12825 [23:51:51<21:50:36, 12.83s/it] 52%|█████▏    | 6695/12825 [23:52:03<21:51:35, 12.84s/it] 52%|█████▏    | 6696/12825 [23:52:16<21:52:17, 12.85s/it] 52%|█████▏    | 6697/12825 [23:52:29<21:52:47, 12.85s/it] 52%|█████▏    | 6698/12825 [23:52:42<21:52:41, 12.85s/it] 52%|█████▏    | 6699/12825 [23:52:55<21:51:18, 12.84s/it] 52%|█████▏    | 6700/12825 [23:53:08<21:50:02, 12.83s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120447.40lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103468.44lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6650] due to args.save_total_limit
 52%|█████▏    | 6701/12825 [23:53:21<21:59:55, 12.93s/it] 52%|█████▏    | 6702/12825 [23:53:33<21:52:01, 12.86s/it] 52%|█████▏    | 6703/12825 [23:53:54<25:42:20, 15.12s/it] 52%|█████▏    | 6704/12825 [23:54:07<24:32:18, 14.43s/it] 52%|█████▏    | 6705/12825 [23:54:20<23:43:32, 13.96s/it] 52%|█████▏    | 6706/12825 [23:54:32<23:08:01, 13.61s/it] 52%|█████▏    | 6707/12825 [23:54:45<22:42:46, 13.36s/it] 52%|█████▏    | 6708/12825 [23:54:58<22:24:43, 13.19s/it] 52%|█████▏    | 6709/12825 [23:55:11<22:18:26, 13.13s/it] 52%|█████▏    | 6710/12825 [23:55:24<22:10:14, 13.05s/it] 52%|█████▏    | 6711/12825 [23:55:37<22:02:48, 12.98s/it] 52%|█████▏    | 6712/12825 [23:55:49<21:57:46, 12.93s/it] 52%|█████▏    | 6713/12825 [23:56:02<21:54:58, 12.91s/it] 52%|█████▏    | 6714/12825 [23:56:15<21:52:39, 12.89s/it] 52%|█████▏    | 6715/12825 [23:56:28<21:51:01, 12.87s/it] 52%|█████▏    | 6716/12825 [23:56:41<21:48:50, 12.85s/it] 52%|█████▏    | 6717/12825 [23:56:54<21:47:54, 12.85s/it] 52%|█████▏    | 6718/12825 [23:57:06<21:47:03, 12.84s/it] 52%|█████▏    | 6719/12825 [23:57:19<21:44:22, 12.82s/it] 52%|█████▏    | 6720/12825 [23:57:32<21:44:36, 12.82s/it] 52%|█████▏    | 6721/12825 [23:57:45<21:45:27, 12.83s/it] 52%|█████▏    | 6722/12825 [23:57:58<21:44:57, 12.83s/it] 52%|█████▏    | 6723/12825 [23:58:10<21:43:43, 12.82s/it] 52%|█████▏    | 6724/12825 [23:58:23<21:44:28, 12.83s/it] 52%|█████▏    | 6725/12825 [23:58:36<21:44:41, 12.83s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120499.30lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103695.54lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6725
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6725/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6725/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6675] due to args.save_total_limit
 52%|█████▏    | 6726/12825 [23:58:49<21:54:12, 12.93s/it] 52%|█████▏    | 6727/12825 [23:59:02<21:47:23, 12.86s/it] 52%|█████▏    | 6728/12825 [23:59:15<21:45:20, 12.85s/it] 52%|█████▏    | 6729/12825 [23:59:28<21:44:22, 12.84s/it] 52%|█████▏    | 6730/12825 [23:59:40<21:42:41, 12.82s/it] 52%|█████▏    | 6731/12825 [23:59:53<21:42:01, 12.82s/it] 52%|█████▏    | 6732/12825 [24:00:06<21:42:05, 12.82s/it] 52%|█████▏    | 6733/12825 [24:00:19<21:43:52, 12.84s/it] 53%|█████▎    | 6734/12825 [24:00:32<21:43:14, 12.84s/it] 53%|█████▎    | 6735/12825 [24:00:45<21:42:29, 12.83s/it] 53%|█████▎    | 6736/12825 [24:01:05<25:28:20, 15.06s/it] 53%|█████▎    | 6737/12825 [24:01:18<24:19:16, 14.38s/it] 53%|█████▎    | 6738/12825 [24:01:30<23:31:44, 13.92s/it] 53%|█████▎    | 6739/12825 [24:01:43<22:58:01, 13.59s/it] 53%|█████▎    | 6740/12825 [24:01:56<22:34:46, 13.36s/it] 53%|█████▎    | 6741/12825 [24:02:09<22:18:02, 13.20s/it] 53%|█████▎    | 6742/12825 [24:02:22<22:07:04, 13.09s/it] 53%|█████▎    | 6743/12825 [24:02:35<21:58:20, 13.01s/it] 53%|█████▎    | 6744/12825 [24:02:47<21:52:43, 12.95s/it] 53%|█████▎    | 6745/12825 [24:03:00<21:46:38, 12.89s/it] 53%|█████▎    | 6746/12825 [24:03:13<21:39:58, 12.83s/it] 53%|█████▎    | 6747/12825 [24:03:26<21:41:38, 12.85s/it] 53%|█████▎    | 6748/12825 [24:03:39<21:41:07, 12.85s/it] 53%|█████▎    | 6749/12825 [24:03:52<21:48:01, 12.92s/it] 53%|█████▎    | 6750/12825 [24:04:04<21:43:38, 12.88s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120407.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103540.15lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6750
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6750/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6750/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6725] due to args.save_total_limit
 53%|█████▎    | 6751/12825 [24:04:18<21:51:54, 12.96s/it] 53%|█████▎    | 6752/12825 [24:04:30<21:47:03, 12.91s/it] 53%|█████▎    | 6753/12825 [24:04:43<21:44:24, 12.89s/it] 53%|█████▎    | 6754/12825 [24:04:56<21:41:58, 12.87s/it] 53%|█████▎    | 6755/12825 [24:05:09<21:40:09, 12.85s/it] 53%|█████▎    | 6756/12825 [24:05:22<21:39:33, 12.85s/it] 53%|█████▎    | 6757/12825 [24:05:35<21:38:31, 12.84s/it] 53%|█████▎    | 6758/12825 [24:05:47<21:39:15, 12.85s/it] 53%|█████▎    | 6759/12825 [24:06:00<21:37:23, 12.83s/it] 53%|█████▎    | 6760/12825 [24:06:13<21:37:15, 12.83s/it] 53%|█████▎    | 6761/12825 [24:06:26<21:38:16, 12.85s/it] 53%|█████▎    | 6762/12825 [24:06:39<21:38:57, 12.85s/it] 53%|█████▎    | 6763/12825 [24:06:52<21:38:32, 12.85s/it] 53%|█████▎    | 6764/12825 [24:07:04<21:37:13, 12.84s/it] 53%|█████▎    | 6765/12825 [24:07:17<21:37:49, 12.85s/it] 53%|█████▎    | 6766/12825 [24:07:30<21:38:26, 12.86s/it] 53%|█████▎    | 6767/12825 [24:07:43<21:37:56, 12.86s/it] 53%|█████▎    | 6768/12825 [24:08:03<25:18:58, 15.05s/it] 53%|█████▎    | 6769/12825 [24:08:16<24:11:31, 14.38s/it] 53%|█████▎    | 6770/12825 [24:08:29<23:23:58, 13.91s/it] 53%|█████▎    | 6771/12825 [24:08:42<22:51:16, 13.59s/it] 53%|█████▎    | 6772/12825 [24:08:55<22:27:24, 13.36s/it] 53%|█████▎    | 6773/12825 [24:09:07<22:11:10, 13.20s/it] 53%|█████▎    | 6774/12825 [24:09:20<21:59:38, 13.09s/it] 53%|█████▎    | 6775/12825 [24:09:33<21:51:44, 13.01s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120482.00lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103671.24lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6775
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6775/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6775/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6750] due to args.save_total_limit
 53%|█████▎    | 6776/12825 [24:09:46<21:56:46, 13.06s/it] 53%|█████▎    | 6777/12825 [24:09:59<21:50:12, 13.00s/it] 53%|█████▎    | 6778/12825 [24:10:12<21:45:39, 12.96s/it] 53%|█████▎    | 6779/12825 [24:10:25<21:36:39, 12.87s/it] 53%|█████▎    | 6780/12825 [24:10:37<21:34:32, 12.85s/it] 53%|█████▎    | 6781/12825 [24:10:50<21:34:46, 12.85s/it] 53%|█████▎    | 6782/12825 [24:11:03<21:34:26, 12.85s/it] 53%|█████▎    | 6783/12825 [24:11:16<21:34:07, 12.85s/it] 53%|█████▎    | 6784/12825 [24:11:29<21:32:16, 12.84s/it] 53%|█████▎    | 6785/12825 [24:11:42<21:32:24, 12.84s/it] 53%|█████▎    | 6786/12825 [24:11:54<21:30:43, 12.82s/it] 53%|█████▎    | 6787/12825 [24:12:07<21:30:01, 12.82s/it] 53%|█████▎    | 6788/12825 [24:12:20<21:29:29, 12.82s/it] 53%|█████▎    | 6789/12825 [24:12:33<21:28:49, 12.81s/it] 53%|█████▎    | 6790/12825 [24:12:46<21:27:00, 12.80s/it] 53%|█████▎    | 6791/12825 [24:12:58<21:27:33, 12.80s/it] 53%|█████▎    | 6792/12825 [24:13:11<21:26:03, 12.79s/it] 53%|█████▎    | 6793/12825 [24:13:24<21:26:15, 12.79s/it] 53%|█████▎    | 6794/12825 [24:13:37<21:26:36, 12.80s/it] 53%|█████▎    | 6795/12825 [24:13:50<21:26:47, 12.80s/it] 53%|█████▎    | 6796/12825 [24:14:02<21:26:48, 12.81s/it] 53%|█████▎    | 6797/12825 [24:14:15<21:26:57, 12.81s/it] 53%|█████▎    | 6798/12825 [24:14:28<21:27:16, 12.82s/it] 53%|█████▎    | 6799/12825 [24:14:41<21:27:41, 12.82s/it] 53%|█████▎    | 6800/12825 [24:15:01<25:18:53, 15.13s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120518.92lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103718.33lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6800
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6800/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6800/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6775] due to args.save_total_limit
 53%|█████▎    | 6801/12825 [24:15:14<24:19:09, 14.53s/it] 53%|█████▎    | 6802/12825 [24:15:27<23:26:21, 14.01s/it] 53%|█████▎    | 6803/12825 [24:15:40<22:49:55, 13.65s/it] 53%|█████▎    | 6804/12825 [24:15:53<22:22:37, 13.38s/it] 53%|█████▎    | 6805/12825 [24:16:06<22:06:55, 13.23s/it] 53%|█████▎    | 6806/12825 [24:16:19<21:54:58, 13.11s/it] 53%|█████▎    | 6807/12825 [24:16:31<21:46:25, 13.03s/it] 53%|█████▎    | 6808/12825 [24:16:44<21:36:09, 12.92s/it] 53%|█████▎    | 6809/12825 [24:16:57<21:33:24, 12.90s/it] 53%|█████▎    | 6810/12825 [24:17:10<21:31:13, 12.88s/it] 53%|█████▎    | 6811/12825 [24:17:23<21:28:56, 12.86s/it] 53%|█████▎    | 6812/12825 [24:17:35<21:27:05, 12.84s/it] 53%|█████▎    | 6813/12825 [24:17:48<21:24:22, 12.82s/it] 53%|█████▎    | 6814/12825 [24:18:01<21:23:45, 12.81s/it] 53%|█████▎    | 6815/12825 [24:18:14<21:24:15, 12.82s/it] 53%|█████▎    | 6816/12825 [24:18:27<21:23:50, 12.82s/it] 53%|█████▎    | 6817/12825 [24:18:39<21:23:07, 12.81s/it] 53%|█████▎    | 6818/12825 [24:18:52<21:22:03, 12.81s/it] 53%|█████▎    | 6819/12825 [24:19:05<21:22:39, 12.81s/it] 53%|█████▎    | 6820/12825 [24:19:18<21:23:12, 12.82s/it] 53%|█████▎    | 6821/12825 [24:19:31<21:22:49, 12.82s/it] 53%|█████▎    | 6822/12825 [24:19:43<21:21:26, 12.81s/it] 53%|█████▎    | 6823/12825 [24:19:56<21:20:35, 12.80s/it] 53%|█████▎    | 6824/12825 [24:20:09<21:19:46, 12.80s/it] 53%|█████▎    | 6825/12825 [24:20:22<21:17:59, 12.78s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120407.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103635.66lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6825
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6825/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6825/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6800] due to args.save_total_limit
 53%|█████▎    | 6826/12825 [24:20:35<21:29:37, 12.90s/it] 53%|█████▎    | 6827/12825 [24:20:48<21:23:38, 12.84s/it] 53%|█████▎    | 6828/12825 [24:21:00<21:23:15, 12.84s/it] 53%|█████▎    | 6829/12825 [24:21:13<21:22:14, 12.83s/it] 53%|█████▎    | 6830/12825 [24:21:26<21:21:49, 12.83s/it] 53%|█████▎    | 6831/12825 [24:21:39<21:20:30, 12.82s/it] 53%|█████▎    | 6832/12825 [24:21:52<21:20:01, 12.82s/it] 53%|█████▎    | 6833/12825 [24:22:12<25:09:37, 15.12s/it] 53%|█████▎    | 6834/12825 [24:22:25<24:01:13, 14.43s/it] 53%|█████▎    | 6835/12825 [24:22:38<23:13:38, 13.96s/it] 53%|█████▎    | 6836/12825 [24:22:51<22:39:09, 13.62s/it] 53%|█████▎    | 6837/12825 [24:23:03<22:15:02, 13.38s/it] 53%|█████▎    | 6838/12825 [24:23:16<21:59:31, 13.22s/it] 53%|█████▎    | 6839/12825 [24:23:29<21:47:30, 13.11s/it] 53%|█████▎    | 6840/12825 [24:23:42<21:36:07, 12.99s/it] 53%|█████▎    | 6841/12825 [24:23:55<21:30:17, 12.94s/it] 53%|█████▎    | 6842/12825 [24:24:08<21:25:27, 12.89s/it] 53%|█████▎    | 6843/12825 [24:24:20<21:23:16, 12.87s/it] 53%|█████▎    | 6844/12825 [24:24:33<21:18:50, 12.83s/it] 53%|█████▎    | 6845/12825 [24:24:46<21:16:01, 12.80s/it] 53%|█████▎    | 6846/12825 [24:24:59<21:14:55, 12.79s/it] 53%|█████▎    | 6847/12825 [24:25:11<21:14:49, 12.80s/it] 53%|█████▎    | 6848/12825 [24:25:24<21:15:00, 12.80s/it] 53%|█████▎    | 6849/12825 [24:25:37<21:15:22, 12.81s/it] 53%|█████▎    | 6850/12825 [24:25:50<21:16:05, 12.81s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120404.50lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103628.17lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6850
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6850/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6850/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6825] due to args.save_total_limit
 53%|█████▎    | 6851/12825 [24:26:03<21:25:11, 12.91s/it] 53%|█████▎    | 6852/12825 [24:26:16<21:21:16, 12.87s/it] 53%|█████▎    | 6853/12825 [24:26:29<21:19:44, 12.86s/it] 53%|█████▎    | 6854/12825 [24:26:41<21:18:34, 12.85s/it] 53%|█████▎    | 6855/12825 [24:26:54<21:14:58, 12.81s/it] 53%|█████▎    | 6856/12825 [24:27:07<21:14:22, 12.81s/it] 53%|█████▎    | 6857/12825 [24:27:20<21:14:01, 12.81s/it] 53%|█████▎    | 6858/12825 [24:27:33<21:12:42, 12.80s/it] 53%|█████▎    | 6859/12825 [24:27:45<21:11:13, 12.78s/it] 53%|█████▎    | 6860/12825 [24:27:58<21:12:27, 12.80s/it] 53%|█████▎    | 6861/12825 [24:28:11<21:12:53, 12.81s/it] 54%|█████▎    | 6862/12825 [24:28:24<21:14:21, 12.82s/it] 54%|█████▎    | 6863/12825 [24:28:37<21:13:38, 12.82s/it] 54%|█████▎    | 6864/12825 [24:28:49<21:12:32, 12.81s/it] 54%|█████▎    | 6865/12825 [24:29:10<24:59:27, 15.10s/it] 54%|█████▎    | 6866/12825 [24:29:23<23:52:55, 14.43s/it] 54%|█████▎    | 6867/12825 [24:29:36<23:04:58, 13.95s/it] 54%|█████▎    | 6868/12825 [24:29:48<22:32:45, 13.63s/it] 54%|█████▎    | 6869/12825 [24:30:01<22:09:28, 13.39s/it] 54%|█████▎    | 6870/12825 [24:30:14<21:51:44, 13.22s/it] 54%|█████▎    | 6871/12825 [24:30:27<21:38:58, 13.09s/it] 54%|█████▎    | 6872/12825 [24:30:40<21:31:17, 13.01s/it] 54%|█████▎    | 6873/12825 [24:30:53<21:26:09, 12.97s/it] 54%|█████▎    | 6874/12825 [24:31:05<21:21:31, 12.92s/it] 54%|█████▎    | 6875/12825 [24:31:18<21:19:18, 12.90s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120457.13lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103631.20lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6875
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6875/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6875/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6850] due to args.save_total_limit
 54%|█████▎    | 6876/12825 [24:31:31<21:27:54, 12.99s/it] 54%|█████▎    | 6877/12825 [24:31:44<21:23:56, 12.95s/it] 54%|█████▎    | 6878/12825 [24:31:57<21:19:00, 12.90s/it] 54%|█████▎    | 6879/12825 [24:32:10<21:16:06, 12.88s/it] 54%|█████▎    | 6880/12825 [24:32:23<21:15:37, 12.87s/it] 54%|█████▎    | 6881/12825 [24:32:36<21:14:49, 12.87s/it] 54%|█████▎    | 6882/12825 [24:32:48<21:13:42, 12.86s/it] 54%|█████▎    | 6883/12825 [24:33:01<21:13:36, 12.86s/it] 54%|█████▎    | 6884/12825 [24:33:14<21:11:59, 12.85s/it] 54%|█████▎    | 6885/12825 [24:33:27<21:11:14, 12.84s/it] 54%|█████▎    | 6886/12825 [24:33:40<21:11:12, 12.84s/it] 54%|█████▎    | 6887/12825 [24:33:53<21:10:45, 12.84s/it] 54%|█████▎    | 6888/12825 [24:34:05<21:09:49, 12.83s/it] 54%|█████▎    | 6889/12825 [24:34:18<21:10:17, 12.84s/it] 54%|█████▎    | 6890/12825 [24:34:31<21:10:29, 12.84s/it] 54%|█████▎    | 6891/12825 [24:34:44<21:10:35, 12.85s/it] 54%|█████▎    | 6892/12825 [24:34:57<21:09:28, 12.84s/it] 54%|█████▎    | 6893/12825 [24:35:10<21:08:35, 12.83s/it] 54%|█████▍    | 6894/12825 [24:35:22<21:08:24, 12.83s/it] 54%|█████▍    | 6895/12825 [24:35:35<21:07:27, 12.82s/it] 54%|█████▍    | 6896/12825 [24:35:48<21:09:04, 12.84s/it] 54%|█████▍    | 6897/12825 [24:36:08<24:46:03, 15.04s/it] 54%|█████▍    | 6898/12825 [24:36:21<23:40:41, 14.38s/it] 54%|█████▍    | 6899/12825 [24:36:34<22:53:49, 13.91s/it] 54%|█████▍    | 6900/12825 [24:36:47<22:21:41, 13.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120025.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103321.74lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6900
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6900/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6900/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6875] due to args.save_total_limit
 54%|█████▍    | 6901/12825 [24:37:00<22:08:45, 13.46s/it] 54%|█████▍    | 6902/12825 [24:37:13<21:49:05, 13.26s/it] 54%|█████▍    | 6903/12825 [24:37:26<21:35:14, 13.12s/it] 54%|█████▍    | 6904/12825 [24:37:38<21:26:05, 13.03s/it] 54%|█████▍    | 6905/12825 [24:37:51<21:20:25, 12.98s/it] 54%|█████▍    | 6906/12825 [24:38:04<21:15:57, 12.93s/it] 54%|█████▍    | 6907/12825 [24:38:17<21:11:36, 12.89s/it] 54%|█████▍    | 6908/12825 [24:38:30<21:09:31, 12.87s/it] 54%|█████▍    | 6909/12825 [24:38:42<21:07:08, 12.85s/it] 54%|█████▍    | 6910/12825 [24:38:55<21:06:13, 12.84s/it] 54%|█████▍    | 6911/12825 [24:39:08<21:05:23, 12.84s/it] 54%|█████▍    | 6912/12825 [24:39:21<21:05:05, 12.84s/it] 54%|█████▍    | 6913/12825 [24:39:34<21:04:58, 12.84s/it] 54%|█████▍    | 6914/12825 [24:39:47<21:03:34, 12.83s/it] 54%|█████▍    | 6915/12825 [24:39:59<21:04:01, 12.83s/it] 54%|█████▍    | 6916/12825 [24:40:12<21:03:41, 12.83s/it] 54%|█████▍    | 6917/12825 [24:40:25<21:00:20, 12.80s/it] 54%|█████▍    | 6918/12825 [24:40:38<21:00:50, 12.81s/it] 54%|█████▍    | 6919/12825 [24:40:51<21:01:14, 12.81s/it] 54%|█████▍    | 6920/12825 [24:41:03<21:01:09, 12.81s/it] 54%|█████▍    | 6921/12825 [24:41:16<21:00:57, 12.81s/it] 54%|█████▍    | 6922/12825 [24:41:29<21:00:59, 12.82s/it] 54%|█████▍    | 6923/12825 [24:41:42<20:59:38, 12.81s/it] 54%|█████▍    | 6924/12825 [24:41:55<20:58:11, 12.79s/it] 54%|█████▍    | 6925/12825 [24:42:07<20:58:05, 12.79s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120487.89lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 99190.60lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6925
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6925/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6925/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6900] due to args.save_total_limit
 54%|█████▍    | 6926/12825 [24:42:21<21:16:05, 12.98s/it] 54%|█████▍    | 6927/12825 [24:42:34<21:10:39, 12.93s/it] 54%|█████▍    | 6928/12825 [24:42:46<21:05:50, 12.88s/it] 54%|█████▍    | 6929/12825 [24:42:59<21:04:34, 12.87s/it] 54%|█████▍    | 6930/12825 [24:43:20<24:41:29, 15.08s/it] 54%|█████▍    | 6931/12825 [24:43:32<23:34:12, 14.40s/it] 54%|█████▍    | 6932/12825 [24:43:45<22:47:50, 13.93s/it] 54%|█████▍    | 6933/12825 [24:43:58<22:15:28, 13.60s/it] 54%|█████▍    | 6934/12825 [24:44:11<21:51:53, 13.36s/it] 54%|█████▍    | 6935/12825 [24:44:24<21:36:48, 13.21s/it] 54%|█████▍    | 6936/12825 [24:44:36<21:24:55, 13.09s/it] 54%|█████▍    | 6937/12825 [24:44:49<21:17:03, 13.01s/it] 54%|█████▍    | 6938/12825 [24:45:02<21:11:07, 12.96s/it] 54%|█████▍    | 6939/12825 [24:45:15<21:07:11, 12.92s/it] 54%|█████▍    | 6940/12825 [24:45:28<21:03:03, 12.88s/it] 54%|█████▍    | 6941/12825 [24:45:41<21:02:49, 12.88s/it] 54%|█████▍    | 6942/12825 [24:45:53<20:59:56, 12.85s/it] 54%|█████▍    | 6943/12825 [24:46:06<20:58:37, 12.84s/it] 54%|█████▍    | 6944/12825 [24:46:19<20:59:25, 12.85s/it] 54%|█████▍    | 6945/12825 [24:46:32<20:58:26, 12.84s/it] 54%|█████▍    | 6946/12825 [24:46:45<20:58:45, 12.85s/it] 54%|█████▍    | 6947/12825 [24:46:58<20:58:20, 12.84s/it] 54%|█████▍    | 6948/12825 [24:47:10<20:58:31, 12.85s/it] 54%|█████▍    | 6949/12825 [24:47:23<20:58:29, 12.85s/it] 54%|█████▍    | 6950/12825 [24:47:36<20:57:56, 12.85s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120487.38lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103703.23lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6950
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6950/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6950/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6925] due to args.save_total_limit
 54%|█████▍    | 6951/12825 [24:47:49<21:07:47, 12.95s/it] 54%|█████▍    | 6952/12825 [24:48:02<21:04:16, 12.92s/it] 54%|█████▍    | 6953/12825 [24:48:15<21:00:50, 12.88s/it] 54%|█████▍    | 6954/12825 [24:48:28<20:58:54, 12.87s/it] 54%|█████▍    | 6955/12825 [24:48:41<20:56:48, 12.85s/it] 54%|█████▍    | 6956/12825 [24:48:53<20:55:02, 12.83s/it] 54%|█████▍    | 6957/12825 [24:49:06<20:55:40, 12.84s/it] 54%|█████▍    | 6958/12825 [24:49:19<20:56:21, 12.85s/it] 54%|█████▍    | 6959/12825 [24:49:32<20:54:14, 12.83s/it] 54%|█████▍    | 6960/12825 [24:49:45<20:53:11, 12.82s/it] 54%|█████▍    | 6961/12825 [24:49:58<20:52:58, 12.82s/it] 54%|█████▍    | 6962/12825 [24:50:18<24:32:24, 15.07s/it] 54%|█████▍    | 6963/12825 [24:50:31<23:26:26, 14.40s/it] 54%|█████▍    | 6964/12825 [24:50:44<22:40:04, 13.92s/it] 54%|█████▍    | 6965/12825 [24:50:56<22:04:57, 13.57s/it] 54%|█████▍    | 6966/12825 [24:51:09<21:42:33, 13.34s/it] 54%|█████▍    | 6967/12825 [24:51:22<21:42:56, 13.35s/it] 54%|█████▍    | 6968/12825 [24:51:35<21:26:46, 13.18s/it] 54%|█████▍    | 6969/12825 [24:51:48<21:15:45, 13.07s/it] 54%|█████▍    | 6970/12825 [24:52:01<21:08:11, 13.00s/it] 54%|█████▍    | 6971/12825 [24:52:14<21:02:46, 12.94s/it] 54%|█████▍    | 6972/12825 [24:52:27<20:59:56, 12.92s/it] 54%|█████▍    | 6973/12825 [24:52:39<20:56:58, 12.89s/it] 54%|█████▍    | 6974/12825 [24:52:52<20:55:01, 12.87s/it] 54%|█████▍    | 6975/12825 [24:53:05<20:53:14, 12.85s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 83513.61lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 75054.35lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6975
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6975/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6975/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-6975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6950] due to args.save_total_limit
 54%|█████▍    | 6976/12825 [24:53:18<21:05:01, 12.98s/it] 54%|█████▍    | 6977/12825 [24:53:31<20:59:56, 12.93s/it] 54%|█████▍    | 6978/12825 [24:53:44<20:56:32, 12.89s/it] 54%|█████▍    | 6979/12825 [24:53:57<20:53:13, 12.86s/it] 54%|█████▍    | 6980/12825 [24:54:09<20:51:16, 12.84s/it] 54%|█████▍    | 6981/12825 [24:54:22<20:47:41, 12.81s/it] 54%|█████▍    | 6982/12825 [24:54:35<20:46:34, 12.80s/it] 54%|█████▍    | 6983/12825 [24:54:48<20:46:06, 12.80s/it] 54%|█████▍    | 6984/12825 [24:55:01<20:45:46, 12.80s/it] 54%|█████▍    | 6985/12825 [24:55:13<20:46:21, 12.81s/it] 54%|█████▍    | 6986/12825 [24:55:26<20:46:18, 12.81s/it] 54%|█████▍    | 6987/12825 [24:55:39<20:43:33, 12.78s/it] 54%|█████▍    | 6988/12825 [24:55:52<20:43:33, 12.78s/it] 54%|█████▍    | 6989/12825 [24:56:04<20:43:29, 12.78s/it] 55%|█████▍    | 6990/12825 [24:56:17<20:42:45, 12.78s/it] 55%|█████▍    | 6991/12825 [24:56:30<20:45:23, 12.81s/it] 55%|█████▍    | 6992/12825 [24:56:43<20:43:37, 12.79s/it] 55%|█████▍    | 6993/12825 [24:56:56<20:43:41, 12.80s/it] 55%|█████▍    | 6994/12825 [24:57:17<24:37:47, 15.21s/it] 55%|█████▍    | 6995/12825 [24:57:29<23:28:14, 14.49s/it] 55%|█████▍    | 6996/12825 [24:57:42<22:39:49, 14.00s/it] 55%|█████▍    | 6997/12825 [24:57:55<22:03:24, 13.62s/it] 55%|█████▍    | 6998/12825 [24:58:08<21:39:32, 13.38s/it] 55%|█████▍    | 6999/12825 [24:58:21<21:23:15, 13.22s/it] 55%|█████▍    | 7000/12825 [24:58:33<21:10:57, 13.09s/it]                                                           55%|█████▍    | 7000/12825 [24:58:33<21:10:57, 13.09s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120329.65lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103618.12lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7000
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7000/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7000/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6700] due to args.save_total_limit
 55%|█████▍    | 7001/12825 [24:58:47<21:11:32, 13.10s/it] 55%|█████▍    | 7002/12825 [24:58:59<20:58:15, 12.97s/it] 55%|█████▍    | 7003/12825 [24:59:12<20:54:04, 12.92s/it] 55%|█████▍    | 7004/12825 [24:59:25<20:52:06, 12.91s/it] 55%|█████▍    | 7005/12825 [24:59:38<20:48:51, 12.87s/it] 55%|█████▍    | 7006/12825 [24:59:50<20:46:07, 12.85s/it] 55%|█████▍    | 7007/12825 [25:00:03<20:44:41, 12.84s/it] 55%|█████▍    | 7008/12825 [25:00:16<20:43:16, 12.82s/it] 55%|█████▍    | 7009/12825 [25:00:29<20:42:52, 12.82s/it] 55%|█████▍    | 7010/12825 [25:00:42<20:43:15, 12.83s/it] 55%|█████▍    | 7011/12825 [25:00:55<20:43:28, 12.83s/it] 55%|█████▍    | 7012/12825 [25:01:07<20:42:56, 12.83s/it] 55%|█████▍    | 7013/12825 [25:01:20<20:38:44, 12.79s/it] 55%|█████▍    | 7014/12825 [25:01:33<20:39:46, 12.80s/it] 55%|█████▍    | 7015/12825 [25:01:46<20:40:48, 12.81s/it] 55%|█████▍    | 7016/12825 [25:01:58<20:38:20, 12.79s/it] 55%|█████▍    | 7017/12825 [25:02:11<20:37:49, 12.79s/it] 55%|█████▍    | 7018/12825 [25:02:24<20:37:28, 12.79s/it] 55%|█████▍    | 7019/12825 [25:02:37<20:37:31, 12.79s/it] 55%|█████▍    | 7020/12825 [25:02:50<20:39:20, 12.81s/it] 55%|█████▍    | 7021/12825 [25:03:03<20:40:49, 12.83s/it] 55%|█████▍    | 7022/12825 [25:03:15<20:40:01, 12.82s/it] 55%|█████▍    | 7023/12825 [25:03:28<20:40:47, 12.83s/it] 55%|█████▍    | 7024/12825 [25:03:41<20:38:55, 12.81s/it] 55%|█████▍    | 7025/12825 [25:03:54<20:38:34, 12.81s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120460.34lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103653.21lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7025
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7025/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7025/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-6975] due to args.save_total_limit
 55%|█████▍    | 7026/12825 [25:04:07<20:47:58, 12.91s/it] 55%|█████▍    | 7027/12825 [25:04:27<24:25:13, 15.16s/it] 55%|█████▍    | 7028/12825 [25:04:40<23:18:05, 14.47s/it] 55%|█████▍    | 7029/12825 [25:04:53<22:28:19, 13.96s/it] 55%|█████▍    | 7030/12825 [25:05:06<21:52:02, 13.58s/it] 55%|█████▍    | 7031/12825 [25:05:18<21:28:24, 13.34s/it] 55%|█████▍    | 7032/12825 [25:05:31<21:14:28, 13.20s/it] 55%|█████▍    | 7033/12825 [25:05:44<21:04:25, 13.10s/it] 55%|█████▍    | 7034/12825 [25:05:57<20:55:32, 13.01s/it] 55%|█████▍    | 7035/12825 [25:06:10<20:50:01, 12.95s/it] 55%|█████▍    | 7036/12825 [25:06:23<20:44:48, 12.90s/it] 55%|█████▍    | 7037/12825 [25:06:35<20:42:16, 12.88s/it] 55%|█████▍    | 7038/12825 [25:06:48<20:40:10, 12.86s/it] 55%|█████▍    | 7039/12825 [25:07:01<20:38:57, 12.85s/it] 55%|█████▍    | 7040/12825 [25:07:14<20:38:14, 12.84s/it] 55%|█████▍    | 7041/12825 [25:07:27<20:36:39, 12.83s/it] 55%|█████▍    | 7042/12825 [25:07:40<20:36:57, 12.83s/it] 55%|█████▍    | 7043/12825 [25:07:52<20:36:32, 12.83s/it] 55%|█████▍    | 7044/12825 [25:08:05<20:35:39, 12.82s/it] 55%|█████▍    | 7045/12825 [25:08:18<20:35:32, 12.83s/it] 55%|█████▍    | 7046/12825 [25:08:31<20:35:19, 12.83s/it] 55%|█████▍    | 7047/12825 [25:08:44<20:35:35, 12.83s/it] 55%|█████▍    | 7048/12825 [25:08:56<20:35:03, 12.83s/it] 55%|█████▍    | 7049/12825 [25:09:09<20:34:21, 12.82s/it] 55%|█████▍    | 7050/12825 [25:09:22<20:32:43, 12.81s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120575.25lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103781.92lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7050
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7050/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7050/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7025] due to args.save_total_limit
 55%|█████▍    | 7051/12825 [25:09:35<20:42:39, 12.91s/it] 55%|█████▍    | 7052/12825 [25:09:48<20:39:30, 12.88s/it] 55%|█████▍    | 7053/12825 [25:10:01<20:37:18, 12.86s/it] 55%|█████▌    | 7054/12825 [25:10:14<20:36:41, 12.86s/it] 55%|█████▌    | 7055/12825 [25:10:26<20:34:36, 12.84s/it] 55%|█████▌    | 7056/12825 [25:10:39<20:34:38, 12.84s/it] 55%|█████▌    | 7057/12825 [25:10:52<20:34:55, 12.85s/it] 55%|█████▌    | 7058/12825 [25:11:05<20:34:35, 12.84s/it] 55%|█████▌    | 7059/12825 [25:11:25<24:06:31, 15.05s/it] 55%|█████▌    | 7060/12825 [25:11:38<23:03:00, 14.39s/it] 55%|█████▌    | 7061/12825 [25:11:51<22:17:47, 13.93s/it] 55%|█████▌    | 7062/12825 [25:12:04<21:45:57, 13.60s/it] 55%|█████▌    | 7063/12825 [25:12:17<21:21:17, 13.34s/it] 55%|█████▌    | 7064/12825 [25:12:29<21:05:44, 13.18s/it] 55%|█████▌    | 7065/12825 [25:12:42<20:55:19, 13.08s/it] 55%|█████▌    | 7066/12825 [25:12:55<20:46:30, 12.99s/it] 55%|█████▌    | 7067/12825 [25:13:08<20:41:39, 12.94s/it] 55%|█████▌    | 7068/12825 [25:13:21<20:38:41, 12.91s/it] 55%|█████▌    | 7069/12825 [25:13:33<20:37:30, 12.90s/it] 55%|█████▌    | 7070/12825 [25:13:46<20:35:09, 12.88s/it] 55%|█████▌    | 7071/12825 [25:13:59<20:33:32, 12.86s/it] 55%|█████▌    | 7072/12825 [25:14:12<20:32:02, 12.85s/it] 55%|█████▌    | 7073/12825 [25:14:25<20:30:26, 12.83s/it] 55%|█████▌    | 7074/12825 [25:14:38<20:30:04, 12.83s/it] 55%|█████▌    | 7075/12825 [25:14:50<20:30:03, 12.84s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120411.41lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103681.87lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7075
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7075/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7075/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7050] due to args.save_total_limit
 55%|█████▌    | 7076/12825 [25:15:04<20:38:04, 12.92s/it] 55%|█████▌    | 7077/12825 [25:15:16<20:34:25, 12.89s/it] 55%|█████▌    | 7078/12825 [25:15:29<20:31:46, 12.86s/it] 55%|█████▌    | 7079/12825 [25:15:42<20:30:36, 12.85s/it] 55%|█████▌    | 7080/12825 [25:15:55<20:29:56, 12.85s/it] 55%|█████▌    | 7081/12825 [25:16:08<20:28:23, 12.83s/it] 55%|█████▌    | 7082/12825 [25:16:20<20:28:41, 12.84s/it] 55%|█████▌    | 7083/12825 [25:16:33<20:28:19, 12.84s/it] 55%|█████▌    | 7084/12825 [25:16:46<20:28:05, 12.84s/it] 55%|█████▌    | 7085/12825 [25:16:59<20:26:52, 12.82s/it] 55%|█████▌    | 7086/12825 [25:17:12<20:26:37, 12.82s/it] 55%|█████▌    | 7087/12825 [25:17:25<20:25:50, 12.82s/it] 55%|█████▌    | 7088/12825 [25:17:37<20:26:03, 12.82s/it] 55%|█████▌    | 7089/12825 [25:17:50<20:26:09, 12.83s/it] 55%|█████▌    | 7090/12825 [25:18:03<20:25:27, 12.82s/it] 55%|█████▌    | 7091/12825 [25:18:23<23:58:30, 15.05s/it] 55%|█████▌    | 7092/12825 [25:18:36<22:53:54, 14.38s/it] 55%|█████▌    | 7093/12825 [25:18:49<22:09:51, 13.92s/it] 55%|█████▌    | 7094/12825 [25:19:02<21:38:54, 13.60s/it] 55%|█████▌    | 7095/12825 [25:19:15<21:16:06, 13.36s/it] 55%|█████▌    | 7096/12825 [25:19:27<20:59:55, 13.20s/it] 55%|█████▌    | 7097/12825 [25:19:40<20:49:02, 13.08s/it] 55%|█████▌    | 7098/12825 [25:19:53<20:40:58, 13.00s/it] 55%|█████▌    | 7099/12825 [25:20:06<20:36:01, 12.95s/it] 55%|█████▌    | 7100/12825 [25:20:19<20:31:36, 12.91s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120360.60lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103580.59lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7075] due to args.save_total_limit
 55%|█████▌    | 7101/12825 [25:20:32<20:39:20, 12.99s/it] 55%|█████▌    | 7102/12825 [25:20:45<20:32:40, 12.92s/it] 55%|█████▌    | 7103/12825 [25:20:58<20:35:27, 12.95s/it] 55%|█████▌    | 7104/12825 [25:21:10<20:30:10, 12.90s/it] 55%|█████▌    | 7105/12825 [25:21:23<20:27:43, 12.88s/it] 55%|█████▌    | 7106/12825 [25:21:36<20:25:30, 12.86s/it] 55%|█████▌    | 7107/12825 [25:21:49<20:24:11, 12.85s/it] 55%|█████▌    | 7108/12825 [25:22:02<20:23:19, 12.84s/it] 55%|█████▌    | 7109/12825 [25:22:15<20:23:09, 12.84s/it] 55%|█████▌    | 7110/12825 [25:22:27<20:22:50, 12.84s/it] 55%|█████▌    | 7111/12825 [25:22:40<20:21:38, 12.83s/it] 55%|█████▌    | 7112/12825 [25:22:53<20:21:32, 12.83s/it] 55%|█████▌    | 7113/12825 [25:23:06<20:20:57, 12.83s/it] 55%|█████▌    | 7114/12825 [25:23:19<20:20:33, 12.82s/it] 55%|█████▌    | 7115/12825 [25:23:31<20:19:45, 12.82s/it] 55%|█████▌    | 7116/12825 [25:23:44<20:19:32, 12.82s/it] 55%|█████▌    | 7117/12825 [25:23:57<20:19:37, 12.82s/it] 56%|█████▌    | 7118/12825 [25:24:10<20:19:40, 12.82s/it] 56%|█████▌    | 7119/12825 [25:24:23<20:16:24, 12.79s/it] 56%|█████▌    | 7120/12825 [25:24:35<20:16:18, 12.79s/it] 56%|█████▌    | 7121/12825 [25:24:48<20:16:18, 12.79s/it] 56%|█████▌    | 7122/12825 [25:25:01<20:17:16, 12.81s/it] 56%|█████▌    | 7123/12825 [25:25:14<20:17:08, 12.81s/it] 56%|█████▌    | 7124/12825 [25:25:34<23:45:32, 15.00s/it] 56%|█████▌    | 7125/12825 [25:25:47<22:44:03, 14.36s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120431.00lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103630.25lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7100] due to args.save_total_limit
 56%|█████▌    | 7126/12825 [25:26:00<22:10:04, 14.00s/it] 56%|█████▌    | 7127/12825 [25:26:13<21:36:58, 13.66s/it] 56%|█████▌    | 7128/12825 [25:26:26<21:13:33, 13.41s/it] 56%|█████▌    | 7129/12825 [25:26:39<20:58:22, 13.26s/it] 56%|█████▌    | 7130/12825 [25:26:51<20:46:01, 13.13s/it] 56%|█████▌    | 7131/12825 [25:27:04<20:35:03, 13.01s/it] 56%|█████▌    | 7132/12825 [25:27:17<20:30:47, 12.97s/it] 56%|█████▌    | 7133/12825 [25:27:30<20:25:47, 12.92s/it] 56%|█████▌    | 7134/12825 [25:27:43<20:23:04, 12.89s/it] 56%|█████▌    | 7135/12825 [25:27:56<20:20:12, 12.87s/it] 56%|█████▌    | 7136/12825 [25:28:08<20:18:59, 12.86s/it] 56%|█████▌    | 7137/12825 [25:28:21<20:18:37, 12.85s/it] 56%|█████▌    | 7138/12825 [25:28:34<20:17:21, 12.84s/it] 56%|█████▌    | 7139/12825 [25:28:47<20:17:48, 12.85s/it] 56%|█████▌    | 7140/12825 [25:29:00<20:17:16, 12.85s/it] 56%|█████▌    | 7141/12825 [25:29:13<20:16:27, 12.84s/it] 56%|█████▌    | 7142/12825 [25:29:25<20:15:39, 12.83s/it] 56%|█████▌    | 7143/12825 [25:29:38<20:15:20, 12.83s/it] 56%|█████▌    | 7144/12825 [25:29:51<20:14:19, 12.83s/it] 56%|█████▌    | 7145/12825 [25:30:04<20:14:11, 12.83s/it] 56%|█████▌    | 7146/12825 [25:30:17<20:14:12, 12.83s/it] 56%|█████▌    | 7147/12825 [25:30:30<20:14:23, 12.83s/it] 56%|█████▌    | 7148/12825 [25:30:42<20:15:16, 12.84s/it] 56%|█████▌    | 7149/12825 [25:30:55<20:15:23, 12.85s/it] 56%|█████▌    | 7150/12825 [25:31:08<20:14:23, 12.84s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120446.50lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103647.04lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7125] due to args.save_total_limit
 56%|█████▌    | 7151/12825 [25:31:21<20:23:53, 12.94s/it] 56%|█████▌    | 7152/12825 [25:31:34<20:20:43, 12.91s/it] 56%|█████▌    | 7153/12825 [25:31:47<20:18:39, 12.89s/it] 56%|█████▌    | 7154/12825 [25:32:00<20:16:33, 12.87s/it] 56%|█████▌    | 7155/12825 [25:32:13<20:15:26, 12.86s/it] 56%|█████▌    | 7156/12825 [25:32:33<23:49:31, 15.13s/it] 56%|█████▌    | 7157/12825 [25:32:46<22:44:07, 14.44s/it] 56%|█████▌    | 7158/12825 [25:32:59<21:59:08, 13.97s/it] 56%|█████▌    | 7159/12825 [25:33:12<21:27:28, 13.63s/it] 56%|█████▌    | 7160/12825 [25:33:24<21:05:30, 13.40s/it] 56%|█████▌    | 7161/12825 [25:33:37<20:48:55, 13.23s/it] 56%|█████▌    | 7162/12825 [25:33:50<20:38:37, 13.12s/it] 56%|█████▌    | 7163/12825 [25:34:03<20:30:30, 13.04s/it] 56%|█████▌    | 7164/12825 [25:34:16<20:25:01, 12.98s/it] 56%|█████▌    | 7165/12825 [25:34:29<20:21:45, 12.95s/it] 56%|█████▌    | 7166/12825 [25:34:42<20:18:39, 12.92s/it] 56%|█████▌    | 7167/12825 [25:34:54<20:16:43, 12.90s/it] 56%|█████▌    | 7168/12825 [25:35:07<20:13:48, 12.87s/it] 56%|█████▌    | 7169/12825 [25:35:20<20:13:24, 12.87s/it] 56%|█████▌    | 7170/12825 [25:35:33<20:12:38, 12.87s/it] 56%|█████▌    | 7171/12825 [25:35:46<20:11:56, 12.86s/it] 56%|█████▌    | 7172/12825 [25:35:59<20:10:17, 12.85s/it] 56%|█████▌    | 7173/12825 [25:36:11<20:09:07, 12.84s/it] 56%|█████▌    | 7174/12825 [25:36:24<20:07:56, 12.83s/it] 56%|█████▌    | 7175/12825 [25:36:37<20:08:02, 12.83s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120196.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103481.11lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7150] due to args.save_total_limit
 56%|█████▌    | 7176/12825 [25:36:50<20:18:00, 12.94s/it] 56%|█████▌    | 7177/12825 [25:37:03<20:14:51, 12.91s/it] 56%|█████▌    | 7178/12825 [25:37:16<20:12:26, 12.88s/it] 56%|█████▌    | 7179/12825 [25:37:29<20:10:08, 12.86s/it] 56%|█████▌    | 7180/12825 [25:37:42<20:09:21, 12.85s/it] 56%|█████▌    | 7181/12825 [25:37:50<17:52:04, 11.40s/it] 56%|█████▌    | 7182/12825 [25:37:50<12:53:32,  8.22s/it] 56%|█████▌    | 7183/12825 [25:38:16<21:15:16, 13.56s/it] 56%|█████▌    | 7184/12825 [25:38:29<20:54:08, 13.34s/it] 56%|█████▌    | 7185/12825 [25:38:42<20:38:50, 13.18s/it] 56%|█████▌    | 7186/12825 [25:38:55<20:28:48, 13.07s/it] 56%|█████▌    | 7187/12825 [25:39:08<20:21:35, 13.00s/it] 56%|█████▌    | 7188/12825 [25:39:28<23:45:30, 15.17s/it] 56%|█████▌    | 7189/12825 [25:39:41<22:39:37, 14.47s/it] 56%|█████▌    | 7190/12825 [25:39:54<21:53:11, 13.98s/it] 56%|█████▌    | 7191/12825 [25:40:06<21:20:35, 13.64s/it] 56%|█████▌    | 7192/12825 [25:40:19<20:56:23, 13.38s/it] 56%|█████▌    | 7193/12825 [25:40:32<20:45:17, 13.27s/it] 56%|█████▌    | 7194/12825 [25:40:45<20:31:50, 13.13s/it] 56%|█████▌    | 7195/12825 [25:40:58<20:23:32, 13.04s/it] 56%|█████▌    | 7196/12825 [25:41:11<20:17:05, 12.97s/it] 56%|█████▌    | 7197/12825 [25:41:23<20:12:33, 12.93s/it] 56%|█████▌    | 7198/12825 [25:41:36<20:03:57, 12.84s/it] 56%|█████▌    | 7199/12825 [25:41:49<20:02:08, 12.82s/it] 56%|█████▌    | 7200/12825 [25:42:02<20:00:17, 12.80s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120471.61lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103452.28lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7175] due to args.save_total_limit
 56%|█████▌    | 7201/12825 [25:42:15<20:09:49, 12.91s/it] 56%|█████▌    | 7202/12825 [25:42:28<20:07:13, 12.88s/it] 56%|█████▌    | 7203/12825 [25:42:40<20:03:50, 12.85s/it] 56%|█████▌    | 7204/12825 [25:42:53<20:01:43, 12.83s/it] 56%|█████▌    | 7205/12825 [25:43:06<20:01:43, 12.83s/it] 56%|█████▌    | 7206/12825 [25:43:19<20:00:03, 12.81s/it] 56%|█████▌    | 7207/12825 [25:43:31<19:55:27, 12.77s/it] 56%|█████▌    | 7208/12825 [25:43:44<19:52:08, 12.73s/it] 56%|█████▌    | 7209/12825 [25:43:57<19:55:25, 12.77s/it] 56%|█████▌    | 7210/12825 [25:44:10<19:51:34, 12.73s/it] 56%|█████▌    | 7211/12825 [25:44:22<19:52:41, 12.75s/it] 56%|█████▌    | 7212/12825 [25:44:35<19:49:34, 12.72s/it] 56%|█████▌    | 7213/12825 [25:44:48<19:49:02, 12.71s/it] 56%|█████▌    | 7214/12825 [25:45:00<19:47:55, 12.70s/it] 56%|█████▋    | 7215/12825 [25:45:13<19:49:17, 12.72s/it] 56%|█████▋    | 7216/12825 [25:45:26<19:46:35, 12.69s/it] 56%|█████▋    | 7217/12825 [25:45:39<19:48:05, 12.71s/it] 56%|█████▋    | 7218/12825 [25:45:51<19:47:42, 12.71s/it] 56%|█████▋    | 7219/12825 [25:46:04<19:51:10, 12.75s/it] 56%|█████▋    | 7220/12825 [25:46:17<19:48:40, 12.72s/it] 56%|█████▋    | 7221/12825 [25:46:37<23:10:51, 14.89s/it] 56%|█████▋    | 7222/12825 [25:46:49<22:07:44, 14.22s/it] 56%|█████▋    | 7223/12825 [25:47:02<21:26:00, 13.77s/it] 56%|█████▋    | 7224/12825 [25:47:15<20:56:29, 13.46s/it] 56%|█████▋    | 7225/12825 [25:47:28<20:38:43, 13.27s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120202.32lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103447.46lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7200] due to args.save_total_limit
 56%|█████▋    | 7226/12825 [25:47:41<20:31:34, 13.20s/it] 56%|█████▋    | 7227/12825 [25:47:53<20:18:09, 13.06s/it] 56%|█████▋    | 7228/12825 [25:48:06<20:11:16, 12.98s/it] 56%|█████▋    | 7229/12825 [25:48:19<20:04:34, 12.92s/it] 56%|█████▋    | 7230/12825 [25:48:32<20:02:18, 12.89s/it] 56%|█████▋    | 7231/12825 [25:48:44<19:54:37, 12.81s/it] 56%|█████▋    | 7232/12825 [25:48:57<19:52:45, 12.80s/it] 56%|█████▋    | 7233/12825 [25:49:10<19:50:01, 12.77s/it] 56%|█████▋    | 7234/12825 [25:49:23<19:47:01, 12.74s/it] 56%|█████▋    | 7235/12825 [25:49:35<19:43:57, 12.71s/it] 56%|█████▋    | 7236/12825 [25:49:48<19:44:07, 12.71s/it] 56%|█████▋    | 7237/12825 [25:50:01<19:42:57, 12.70s/it] 56%|█████▋    | 7238/12825 [25:50:13<19:42:08, 12.70s/it] 56%|█████▋    | 7239/12825 [25:50:26<19:43:03, 12.71s/it] 56%|█████▋    | 7240/12825 [25:50:39<19:42:14, 12.70s/it] 56%|█████▋    | 7241/12825 [25:50:51<19:40:15, 12.68s/it] 56%|█████▋    | 7242/12825 [25:51:04<19:43:22, 12.72s/it] 56%|█████▋    | 7243/12825 [25:51:17<19:42:11, 12.71s/it] 56%|█████▋    | 7244/12825 [25:51:29<19:41:05, 12.70s/it] 56%|█████▋    | 7245/12825 [25:51:42<19:39:37, 12.68s/it] 56%|█████▋    | 7246/12825 [25:51:55<19:39:20, 12.68s/it] 57%|█████▋    | 7247/12825 [25:52:07<19:38:16, 12.67s/it] 57%|█████▋    | 7248/12825 [25:52:20<19:37:33, 12.67s/it] 57%|█████▋    | 7249/12825 [25:52:33<19:36:20, 12.66s/it] 57%|█████▋    | 7250/12825 [25:52:45<19:35:37, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120397.84lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103583.33lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7225] due to args.save_total_limit
 57%|█████▋    | 7251/12825 [25:52:58<19:44:27, 12.75s/it] 57%|█████▋    | 7252/12825 [25:53:11<19:41:27, 12.72s/it] 57%|█████▋    | 7253/12825 [25:53:31<23:12:16, 14.99s/it] 57%|█████▋    | 7254/12825 [25:53:44<22:06:56, 14.29s/it] 57%|█████▋    | 7255/12825 [25:53:57<21:21:52, 13.81s/it] 57%|█████▋    | 7256/12825 [25:54:09<20:50:06, 13.47s/it] 57%|█████▋    | 7257/12825 [25:54:22<20:28:09, 13.23s/it] 57%|█████▋    | 7258/12825 [25:54:35<20:16:32, 13.11s/it] 57%|█████▋    | 7259/12825 [25:54:48<20:04:30, 12.98s/it] 57%|█████▋    | 7260/12825 [25:55:00<19:59:49, 12.94s/it] 57%|█████▋    | 7261/12825 [25:55:13<19:53:18, 12.87s/it] 57%|█████▋    | 7262/12825 [25:55:26<19:48:22, 12.82s/it] 57%|█████▋    | 7263/12825 [25:55:38<19:42:07, 12.75s/it] 57%|█████▋    | 7264/12825 [25:55:51<19:37:57, 12.71s/it] 57%|█████▋    | 7265/12825 [25:56:04<19:34:54, 12.68s/it] 57%|█████▋    | 7266/12825 [25:56:16<19:32:46, 12.66s/it] 57%|█████▋    | 7267/12825 [25:56:29<19:30:30, 12.64s/it] 57%|█████▋    | 7268/12825 [25:56:41<19:30:48, 12.64s/it] 57%|█████▋    | 7269/12825 [25:56:54<19:29:47, 12.63s/it] 57%|█████▋    | 7270/12825 [25:57:07<19:29:04, 12.63s/it] 57%|█████▋    | 7271/12825 [25:57:19<19:29:20, 12.63s/it] 57%|█████▋    | 7272/12825 [25:57:32<19:30:04, 12.64s/it] 57%|█████▋    | 7273/12825 [25:57:45<19:30:19, 12.65s/it] 57%|█████▋    | 7274/12825 [25:57:57<19:29:50, 12.64s/it] 57%|█████▋    | 7275/12825 [25:58:10<19:32:09, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120462.90lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103654.44lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7250] due to args.save_total_limit
 57%|█████▋    | 7276/12825 [25:58:23<19:41:32, 12.78s/it] 57%|█████▋    | 7277/12825 [25:58:36<19:36:50, 12.73s/it] 57%|█████▋    | 7278/12825 [25:58:48<19:37:42, 12.74s/it] 57%|█████▋    | 7279/12825 [25:59:01<19:38:10, 12.75s/it] 57%|█████▋    | 7280/12825 [25:59:14<19:37:55, 12.75s/it] 57%|█████▋    | 7281/12825 [25:59:27<19:33:07, 12.70s/it] 57%|█████▋    | 7282/12825 [25:59:39<19:29:31, 12.66s/it] 57%|█████▋    | 7283/12825 [25:59:52<19:27:28, 12.64s/it] 57%|█████▋    | 7284/12825 [26:00:04<19:29:12, 12.66s/it] 57%|█████▋    | 7285/12825 [26:00:17<19:28:31, 12.66s/it] 57%|█████▋    | 7286/12825 [26:00:37<22:55:28, 14.90s/it] 57%|█████▋    | 7287/12825 [26:00:50<21:54:34, 14.24s/it] 57%|█████▋    | 7288/12825 [26:01:03<21:09:48, 13.76s/it] 57%|█████▋    | 7289/12825 [26:01:15<20:38:14, 13.42s/it] 57%|█████▋    | 7290/12825 [26:01:28<20:16:11, 13.18s/it] 57%|█████▋    | 7291/12825 [26:01:41<20:04:54, 13.06s/it] 57%|█████▋    | 7292/12825 [26:01:53<19:58:27, 13.00s/it] 57%|█████▋    | 7293/12825 [26:02:06<19:49:38, 12.90s/it] 57%|█████▋    | 7294/12825 [26:02:19<19:45:37, 12.86s/it] 57%|█████▋    | 7295/12825 [26:02:32<19:43:13, 12.84s/it] 57%|█████▋    | 7296/12825 [26:02:44<19:37:34, 12.78s/it] 57%|█████▋    | 7297/12825 [26:02:57<19:32:24, 12.73s/it] 57%|█████▋    | 7298/12825 [26:03:09<19:29:47, 12.70s/it] 57%|█████▋    | 7299/12825 [26:03:22<19:30:35, 12.71s/it] 57%|█████▋    | 7300/12825 [26:03:35<19:28:23, 12.69s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120558.95lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103481.30lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7275] due to args.save_total_limit
 57%|█████▋    | 7301/12825 [26:03:48<19:37:43, 12.79s/it] 57%|█████▋    | 7302/12825 [26:04:00<19:31:54, 12.73s/it] 57%|█████▋    | 7303/12825 [26:04:13<19:28:23, 12.70s/it] 57%|█████▋    | 7304/12825 [26:04:26<19:27:13, 12.68s/it] 57%|█████▋    | 7305/12825 [26:04:39<19:30:48, 12.73s/it] 57%|█████▋    | 7306/12825 [26:04:51<19:30:56, 12.73s/it] 57%|█████▋    | 7307/12825 [26:05:04<19:27:39, 12.70s/it] 57%|█████▋    | 7308/12825 [26:05:17<19:30:15, 12.73s/it] 57%|█████▋    | 7309/12825 [26:05:29<19:28:15, 12.71s/it] 57%|█████▋    | 7310/12825 [26:05:42<19:27:10, 12.70s/it] 57%|█████▋    | 7311/12825 [26:05:55<19:25:15, 12.68s/it] 57%|█████▋    | 7312/12825 [26:06:07<19:27:28, 12.71s/it] 57%|█████▋    | 7313/12825 [26:06:20<19:25:16, 12.68s/it] 57%|█████▋    | 7314/12825 [26:06:33<19:23:50, 12.67s/it] 57%|█████▋    | 7315/12825 [26:06:45<19:23:01, 12.66s/it] 57%|█████▋    | 7316/12825 [26:06:58<19:26:05, 12.70s/it] 57%|█████▋    | 7317/12825 [26:07:11<19:24:14, 12.68s/it] 57%|█████▋    | 7318/12825 [26:07:31<22:50:51, 14.94s/it] 57%|█████▋    | 7319/12825 [26:07:44<21:47:43, 14.25s/it] 57%|█████▋    | 7320/12825 [26:07:56<21:02:54, 13.76s/it] 57%|█████▋    | 7321/12825 [26:08:09<20:32:52, 13.44s/it] 57%|█████▋    | 7322/12825 [26:08:22<20:10:26, 13.20s/it] 57%|█████▋    | 7323/12825 [26:08:34<19:56:03, 13.04s/it] 57%|█████▋    | 7324/12825 [26:08:47<19:45:45, 12.93s/it] 57%|█████▋    | 7325/12825 [26:09:00<19:39:24, 12.87s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120384.02lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103561.83lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7300] due to args.save_total_limit
 57%|█████▋    | 7326/12825 [26:09:13<19:40:20, 12.88s/it] 57%|█████▋    | 7327/12825 [26:09:25<19:32:17, 12.79s/it] 57%|█████▋    | 7328/12825 [26:09:38<19:26:24, 12.73s/it] 57%|█████▋    | 7329/12825 [26:09:50<19:22:43, 12.69s/it] 57%|█████▋    | 7330/12825 [26:10:03<19:19:24, 12.66s/it] 57%|█████▋    | 7331/12825 [26:10:16<19:17:15, 12.64s/it] 57%|█████▋    | 7332/12825 [26:10:28<19:16:03, 12.63s/it] 57%|█████▋    | 7333/12825 [26:10:41<19:15:50, 12.63s/it] 57%|█████▋    | 7334/12825 [26:10:53<19:14:42, 12.62s/it] 57%|█████▋    | 7335/12825 [26:11:06<19:14:27, 12.62s/it] 57%|█████▋    | 7336/12825 [26:11:19<19:14:23, 12.62s/it] 57%|█████▋    | 7337/12825 [26:11:31<19:13:40, 12.61s/it] 57%|█████▋    | 7338/12825 [26:11:44<19:12:07, 12.60s/it] 57%|█████▋    | 7339/12825 [26:11:56<19:13:19, 12.61s/it] 57%|█████▋    | 7340/12825 [26:12:09<19:14:03, 12.62s/it] 57%|█████▋    | 7341/12825 [26:12:22<19:13:06, 12.62s/it] 57%|█████▋    | 7342/12825 [26:12:34<19:12:39, 12.61s/it] 57%|█████▋    | 7343/12825 [26:12:47<19:13:21, 12.62s/it] 57%|█████▋    | 7344/12825 [26:13:00<19:13:05, 12.62s/it] 57%|█████▋    | 7345/12825 [26:13:12<19:11:50, 12.61s/it] 57%|█████▋    | 7346/12825 [26:13:25<19:12:21, 12.62s/it] 57%|█████▋    | 7347/12825 [26:13:37<19:13:42, 12.64s/it] 57%|█████▋    | 7348/12825 [26:13:50<19:15:39, 12.66s/it] 57%|█████▋    | 7349/12825 [26:14:03<19:14:46, 12.65s/it] 57%|█████▋    | 7350/12825 [26:14:23<22:45:21, 14.96s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120481.61lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103650.84lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7000] due to args.save_total_limit
 57%|█████▋    | 7351/12825 [26:14:36<21:49:02, 14.35s/it] 57%|█████▋    | 7352/12825 [26:14:49<21:02:21, 13.84s/it] 57%|█████▋    | 7353/12825 [26:15:01<20:28:51, 13.47s/it] 57%|█████▋    | 7354/12825 [26:15:14<20:04:28, 13.21s/it] 57%|█████▋    | 7355/12825 [26:15:27<19:48:30, 13.04s/it] 57%|█████▋    | 7356/12825 [26:15:39<19:36:32, 12.91s/it] 57%|█████▋    | 7357/12825 [26:15:52<19:29:34, 12.83s/it] 57%|█████▋    | 7358/12825 [26:16:04<19:23:27, 12.77s/it] 57%|█████▋    | 7359/12825 [26:16:17<19:19:49, 12.73s/it] 57%|█████▋    | 7360/12825 [26:16:30<19:16:39, 12.70s/it] 57%|█████▋    | 7361/12825 [26:16:42<19:15:45, 12.69s/it] 57%|█████▋    | 7362/12825 [26:16:55<19:14:12, 12.68s/it] 57%|█████▋    | 7363/12825 [26:17:08<19:16:15, 12.70s/it] 57%|█████▋    | 7364/12825 [26:17:20<19:15:10, 12.69s/it] 57%|█████▋    | 7365/12825 [26:17:33<19:13:34, 12.68s/it] 57%|█████▋    | 7366/12825 [26:17:46<19:12:59, 12.67s/it] 57%|█████▋    | 7367/12825 [26:17:58<19:11:48, 12.66s/it] 57%|█████▋    | 7368/12825 [26:18:11<19:10:22, 12.65s/it] 57%|█████▋    | 7369/12825 [26:18:24<19:11:15, 12.66s/it] 57%|█████▋    | 7370/12825 [26:18:36<19:10:22, 12.65s/it] 57%|█████▋    | 7371/12825 [26:18:49<19:09:23, 12.64s/it] 57%|█████▋    | 7372/12825 [26:19:02<19:07:40, 12.63s/it] 57%|█████▋    | 7373/12825 [26:19:14<19:07:39, 12.63s/it] 57%|█████▋    | 7374/12825 [26:19:27<19:06:33, 12.62s/it] 58%|█████▊    | 7375/12825 [26:19:39<19:08:04, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120460.46lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103681.96lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7325] due to args.save_total_limit
 58%|█████▊    | 7376/12825 [26:19:52<19:14:59, 12.72s/it] 58%|█████▊    | 7377/12825 [26:20:05<19:12:33, 12.69s/it] 58%|█████▊    | 7378/12825 [26:20:18<19:09:22, 12.66s/it] 58%|█████▊    | 7379/12825 [26:20:30<19:08:11, 12.65s/it] 58%|█████▊    | 7380/12825 [26:20:43<19:06:08, 12.63s/it] 58%|█████▊    | 7381/12825 [26:20:55<19:04:56, 12.62s/it] 58%|█████▊    | 7382/12825 [26:21:08<19:06:13, 12.64s/it] 58%|█████▊    | 7383/12825 [26:21:28<22:25:36, 14.84s/it] 58%|█████▊    | 7384/12825 [26:21:41<21:24:04, 14.16s/it] 58%|█████▊    | 7385/12825 [26:21:53<20:42:45, 13.71s/it] 58%|█████▊    | 7386/12825 [26:22:06<20:13:11, 13.38s/it] 58%|█████▊    | 7387/12825 [26:22:18<19:51:03, 13.14s/it] 58%|█████▊    | 7388/12825 [26:22:31<19:38:17, 13.00s/it] 58%|█████▊    | 7389/12825 [26:22:44<19:27:03, 12.88s/it] 58%|█████▊    | 7390/12825 [26:22:56<19:20:45, 12.81s/it] 58%|█████▊    | 7391/12825 [26:23:09<19:14:04, 12.74s/it] 58%|█████▊    | 7392/12825 [26:23:22<19:13:42, 12.74s/it] 58%|█████▊    | 7393/12825 [26:23:34<19:09:51, 12.70s/it] 58%|█████▊    | 7394/12825 [26:23:47<19:10:11, 12.71s/it] 58%|█████▊    | 7395/12825 [26:24:00<19:08:07, 12.69s/it] 58%|█████▊    | 7396/12825 [26:24:12<19:05:17, 12.66s/it] 58%|█████▊    | 7397/12825 [26:24:25<19:05:07, 12.66s/it] 58%|█████▊    | 7398/12825 [26:24:38<19:05:00, 12.66s/it] 58%|█████▊    | 7399/12825 [26:24:50<19:05:00, 12.66s/it] 58%|█████▊    | 7400/12825 [26:25:03<19:02:48, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120452.01lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103645.81lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7375] due to args.save_total_limit
 58%|█████▊    | 7401/12825 [26:25:16<19:09:59, 12.72s/it] 58%|█████▊    | 7402/12825 [26:25:28<19:06:03, 12.68s/it] 58%|█████▊    | 7403/12825 [26:25:41<19:04:20, 12.66s/it] 58%|█████▊    | 7404/12825 [26:25:54<19:06:30, 12.69s/it] 58%|█████▊    | 7405/12825 [26:26:06<19:04:22, 12.67s/it] 58%|█████▊    | 7406/12825 [26:26:19<19:02:30, 12.65s/it] 58%|█████▊    | 7407/12825 [26:26:32<19:02:24, 12.65s/it] 58%|█████▊    | 7408/12825 [26:26:44<19:00:12, 12.63s/it] 58%|█████▊    | 7409/12825 [26:26:57<18:59:33, 12.62s/it] 58%|█████▊    | 7410/12825 [26:27:09<19:00:36, 12.64s/it] 58%|█████▊    | 7411/12825 [26:27:22<18:59:08, 12.62s/it] 58%|█████▊    | 7412/12825 [26:27:35<18:58:44, 12.62s/it] 58%|█████▊    | 7413/12825 [26:27:47<18:58:02, 12.62s/it] 58%|█████▊    | 7414/12825 [26:28:00<18:57:29, 12.61s/it] 58%|█████▊    | 7415/12825 [26:28:20<22:26:38, 14.93s/it] 58%|█████▊    | 7416/12825 [26:28:33<21:23:38, 14.24s/it] 58%|█████▊    | 7417/12825 [26:28:46<20:44:06, 13.80s/it] 58%|█████▊    | 7418/12825 [26:28:58<20:12:30, 13.45s/it] 58%|█████▊    | 7419/12825 [26:29:11<19:50:18, 13.21s/it] 58%|█████▊    | 7420/12825 [26:29:24<19:34:08, 13.03s/it] 58%|█████▊    | 7421/12825 [26:29:36<19:23:22, 12.92s/it] 58%|█████▊    | 7422/12825 [26:29:49<19:14:58, 12.83s/it] 58%|█████▊    | 7423/12825 [26:30:02<19:13:01, 12.81s/it] 58%|█████▊    | 7424/12825 [26:30:14<19:09:06, 12.77s/it] 58%|█████▊    | 7425/12825 [26:30:27<19:06:56, 12.74s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120349.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103564.96lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7350] due to args.save_total_limit
 58%|█████▊    | 7426/12825 [26:30:40<19:11:27, 12.80s/it] 58%|█████▊    | 7427/12825 [26:30:53<19:07:09, 12.75s/it] 58%|█████▊    | 7428/12825 [26:31:05<19:03:01, 12.71s/it] 58%|█████▊    | 7429/12825 [26:31:18<18:59:15, 12.67s/it] 58%|█████▊    | 7430/12825 [26:31:30<18:59:12, 12.67s/it] 58%|█████▊    | 7431/12825 [26:31:43<18:59:03, 12.67s/it] 58%|█████▊    | 7432/12825 [26:31:56<18:56:52, 12.65s/it] 58%|█████▊    | 7433/12825 [26:32:08<18:55:29, 12.64s/it] 58%|█████▊    | 7434/12825 [26:32:21<18:53:57, 12.62s/it] 58%|█████▊    | 7435/12825 [26:32:33<18:53:20, 12.62s/it] 58%|█████▊    | 7436/12825 [26:32:46<18:56:54, 12.66s/it] 58%|█████▊    | 7437/12825 [26:32:59<18:54:49, 12.64s/it] 58%|█████▊    | 7438/12825 [26:33:11<18:53:45, 12.63s/it] 58%|█████▊    | 7439/12825 [26:33:24<18:52:16, 12.61s/it] 58%|█████▊    | 7440/12825 [26:33:37<18:52:22, 12.62s/it] 58%|█████▊    | 7441/12825 [26:33:49<18:51:38, 12.61s/it] 58%|█████▊    | 7442/12825 [26:34:02<18:51:07, 12.61s/it] 58%|█████▊    | 7443/12825 [26:34:14<18:50:34, 12.60s/it] 58%|█████▊    | 7444/12825 [26:34:27<18:49:52, 12.60s/it] 58%|█████▊    | 7445/12825 [26:34:40<18:50:13, 12.60s/it] 58%|█████▊    | 7446/12825 [26:34:52<18:48:48, 12.59s/it] 58%|█████▊    | 7447/12825 [26:35:05<18:49:49, 12.60s/it] 58%|█████▊    | 7448/12825 [26:35:25<22:12:35, 14.87s/it] 58%|█████▊    | 7449/12825 [26:35:38<21:11:13, 14.19s/it] 58%|█████▊    | 7450/12825 [26:35:50<20:29:06, 13.72s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120347.30lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103533.43lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7400] due to args.save_total_limit
 58%|█████▊    | 7451/12825 [26:36:03<20:10:43, 13.52s/it] 58%|█████▊    | 7452/12825 [26:36:16<19:45:11, 13.23s/it] 58%|█████▊    | 7453/12825 [26:36:28<19:28:20, 13.05s/it] 58%|█████▊    | 7454/12825 [26:36:41<19:16:42, 12.92s/it] 58%|█████▊    | 7455/12825 [26:36:54<19:09:52, 12.85s/it] 58%|█████▊    | 7456/12825 [26:37:06<19:01:50, 12.76s/it] 58%|█████▊    | 7457/12825 [26:37:19<18:57:37, 12.72s/it] 58%|█████▊    | 7458/12825 [26:37:31<18:54:15, 12.68s/it] 58%|█████▊    | 7459/12825 [26:37:44<18:56:04, 12.70s/it] 58%|█████▊    | 7460/12825 [26:37:57<18:55:21, 12.70s/it] 58%|█████▊    | 7461/12825 [26:38:10<18:55:52, 12.71s/it] 58%|█████▊    | 7462/12825 [26:38:22<18:53:05, 12.68s/it] 58%|█████▊    | 7463/12825 [26:38:35<18:51:36, 12.66s/it] 58%|█████▊    | 7464/12825 [26:38:47<18:50:23, 12.65s/it] 58%|█████▊    | 7465/12825 [26:39:00<18:48:57, 12.64s/it] 58%|█████▊    | 7466/12825 [26:39:13<18:49:28, 12.65s/it] 58%|█████▊    | 7467/12825 [26:39:25<18:48:57, 12.64s/it] 58%|█████▊    | 7468/12825 [26:39:38<18:48:30, 12.64s/it] 58%|█████▊    | 7469/12825 [26:39:51<18:55:52, 12.72s/it] 58%|█████▊    | 7470/12825 [26:40:04<18:52:22, 12.69s/it] 58%|█████▊    | 7471/12825 [26:40:16<18:50:33, 12.67s/it] 58%|█████▊    | 7472/12825 [26:40:29<18:49:30, 12.66s/it] 58%|█████▊    | 7473/12825 [26:40:41<18:48:50, 12.66s/it] 58%|█████▊    | 7474/12825 [26:40:54<18:48:24, 12.65s/it] 58%|█████▊    | 7475/12825 [26:41:07<18:48:34, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120412.82lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103646.66lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7450] due to args.save_total_limit
 58%|█████▊    | 7476/12825 [26:41:20<19:03:17, 12.82s/it] 58%|█████▊    | 7477/12825 [26:41:33<18:57:11, 12.76s/it] 58%|█████▊    | 7478/12825 [26:41:45<18:54:40, 12.73s/it] 58%|█████▊    | 7479/12825 [26:41:58<18:51:42, 12.70s/it] 58%|█████▊    | 7480/12825 [26:42:19<22:36:45, 15.23s/it] 58%|█████▊    | 7481/12825 [26:42:32<21:27:27, 14.45s/it] 58%|█████▊    | 7482/12825 [26:42:44<20:37:46, 13.90s/it] 58%|█████▊    | 7483/12825 [26:42:57<20:17:57, 13.68s/it] 58%|█████▊    | 7484/12825 [26:43:10<19:50:17, 13.37s/it] 58%|█████▊    | 7485/12825 [26:43:23<19:30:15, 13.15s/it] 58%|█████▊    | 7486/12825 [26:43:35<19:16:00, 12.99s/it] 58%|█████▊    | 7487/12825 [26:43:48<19:06:43, 12.89s/it] 58%|█████▊    | 7488/12825 [26:44:01<18:59:31, 12.81s/it] 58%|█████▊    | 7489/12825 [26:44:13<18:53:44, 12.75s/it] 58%|█████▊    | 7490/12825 [26:44:26<18:50:18, 12.71s/it] 58%|█████▊    | 7491/12825 [26:44:38<18:46:39, 12.67s/it] 58%|█████▊    | 7492/12825 [26:44:51<18:47:22, 12.68s/it] 58%|█████▊    | 7493/12825 [26:45:04<18:45:36, 12.67s/it] 58%|█████▊    | 7494/12825 [26:45:16<18:45:05, 12.66s/it] 58%|█████▊    | 7495/12825 [26:45:29<18:42:54, 12.64s/it] 58%|█████▊    | 7496/12825 [26:45:42<18:42:36, 12.64s/it] 58%|█████▊    | 7497/12825 [26:45:54<18:41:42, 12.63s/it] 58%|█████▊    | 7498/12825 [26:46:07<18:41:25, 12.63s/it] 58%|█████▊    | 7499/12825 [26:46:20<18:40:58, 12.63s/it] 58%|█████▊    | 7500/12825 [26:46:32<18:41:09, 12.63s/it]                                                           58%|█████▊    | 7500/12825 [26:46:32<18:41:09, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120449.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103666.02lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7475] due to args.save_total_limit
 58%|█████▊    | 7501/12825 [26:46:45<18:49:31, 12.73s/it] 58%|█████▊    | 7502/12825 [26:46:58<18:46:37, 12.70s/it] 59%|█████▊    | 7503/12825 [26:47:10<18:44:13, 12.67s/it] 59%|█████▊    | 7504/12825 [26:47:23<18:43:37, 12.67s/it] 59%|█████▊    | 7505/12825 [26:47:36<18:43:04, 12.67s/it] 59%|█████▊    | 7506/12825 [26:47:48<18:42:46, 12.67s/it] 59%|█████▊    | 7507/12825 [26:48:01<18:41:13, 12.65s/it] 59%|█████▊    | 7508/12825 [26:48:14<18:42:06, 12.66s/it] 59%|█████▊    | 7509/12825 [26:48:26<18:41:27, 12.66s/it] 59%|█████▊    | 7510/12825 [26:48:39<18:40:29, 12.65s/it] 59%|█████▊    | 7511/12825 [26:48:52<18:40:00, 12.65s/it] 59%|█████▊    | 7512/12825 [26:49:12<21:56:05, 14.86s/it] 59%|█████▊    | 7513/12825 [26:49:24<20:56:20, 14.19s/it] 59%|█████▊    | 7514/12825 [26:49:37<20:13:55, 13.71s/it] 59%|█████▊    | 7515/12825 [26:49:49<19:44:41, 13.39s/it] 59%|█████▊    | 7516/12825 [26:50:02<19:24:12, 13.16s/it] 59%|█████▊    | 7517/12825 [26:50:15<19:10:15, 13.00s/it] 59%|█████▊    | 7518/12825 [26:50:27<18:59:31, 12.88s/it] 59%|█████▊    | 7519/12825 [26:50:40<18:52:39, 12.81s/it] 59%|█████▊    | 7520/12825 [26:50:53<18:46:48, 12.74s/it] 59%|█████▊    | 7521/12825 [26:51:05<18:43:44, 12.71s/it] 59%|█████▊    | 7522/12825 [26:51:18<18:43:40, 12.71s/it] 59%|█████▊    | 7523/12825 [26:51:31<18:41:33, 12.69s/it] 59%|█████▊    | 7524/12825 [26:51:43<18:39:43, 12.67s/it] 59%|█████▊    | 7525/12825 [26:51:56<18:39:09, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120382.10lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103618.31lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7500] due to args.save_total_limit
 59%|█████▊    | 7526/12825 [26:52:09<18:45:41, 12.75s/it] 59%|█████▊    | 7527/12825 [26:52:21<18:42:21, 12.71s/it] 59%|█████▊    | 7528/12825 [26:52:34<18:39:43, 12.68s/it] 59%|█████▊    | 7529/12825 [26:52:47<18:37:03, 12.66s/it] 59%|█████▊    | 7530/12825 [26:52:59<18:36:49, 12.66s/it] 59%|█████▊    | 7531/12825 [26:53:12<18:35:11, 12.64s/it] 59%|█████▊    | 7532/12825 [26:53:24<18:33:13, 12.62s/it] 59%|█████▊    | 7533/12825 [26:53:37<18:32:48, 12.62s/it] 59%|█████▊    | 7534/12825 [26:53:50<18:32:00, 12.61s/it] 59%|█████▉    | 7535/12825 [26:54:02<18:31:12, 12.60s/it] 59%|█████▉    | 7536/12825 [26:54:15<18:30:30, 12.60s/it] 59%|█████▉    | 7537/12825 [26:54:27<18:30:21, 12.60s/it] 59%|█████▉    | 7538/12825 [26:54:40<18:30:24, 12.60s/it] 59%|█████▉    | 7539/12825 [26:54:53<18:32:06, 12.62s/it] 59%|█████▉    | 7540/12825 [26:55:05<18:31:58, 12.62s/it] 59%|█████▉    | 7541/12825 [26:55:18<18:32:14, 12.63s/it] 59%|█████▉    | 7542/12825 [26:55:31<18:34:02, 12.65s/it] 59%|█████▉    | 7543/12825 [26:55:43<18:33:25, 12.65s/it] 59%|█████▉    | 7544/12825 [26:55:56<18:35:19, 12.67s/it] 59%|█████▉    | 7545/12825 [26:56:16<21:48:04, 14.86s/it] 59%|█████▉    | 7546/12825 [26:56:29<20:48:43, 14.19s/it] 59%|█████▉    | 7547/12825 [26:56:41<20:07:14, 13.72s/it] 59%|█████▉    | 7548/12825 [26:56:54<19:37:46, 13.39s/it] 59%|█████▉    | 7549/12825 [26:57:07<19:18:00, 13.17s/it] 59%|█████▉    | 7550/12825 [26:57:19<19:04:04, 13.01s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120393.74lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103624.94lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7525] due to args.save_total_limit
 59%|█████▉    | 7551/12825 [26:57:32<19:02:41, 13.00s/it] 59%|█████▉    | 7552/12825 [26:57:45<18:52:44, 12.89s/it] 59%|█████▉    | 7553/12825 [26:57:57<18:45:26, 12.81s/it] 59%|█████▉    | 7554/12825 [26:58:10<18:39:33, 12.74s/it] 59%|█████▉    | 7555/12825 [26:58:23<18:36:29, 12.71s/it] 59%|█████▉    | 7556/12825 [26:58:35<18:33:45, 12.68s/it] 59%|█████▉    | 7557/12825 [26:58:48<18:31:51, 12.66s/it] 59%|█████▉    | 7558/12825 [26:59:01<18:31:55, 12.67s/it] 59%|█████▉    | 7559/12825 [26:59:13<18:30:51, 12.66s/it] 59%|█████▉    | 7560/12825 [26:59:26<18:29:33, 12.64s/it] 59%|█████▉    | 7561/12825 [26:59:38<18:28:51, 12.64s/it] 59%|█████▉    | 7562/12825 [26:59:51<18:27:48, 12.63s/it] 59%|█████▉    | 7563/12825 [27:00:04<18:28:15, 12.64s/it] 59%|█████▉    | 7564/12825 [27:00:16<18:27:42, 12.63s/it] 59%|█████▉    | 7565/12825 [27:00:29<18:26:47, 12.62s/it] 59%|█████▉    | 7566/12825 [27:00:42<18:26:29, 12.62s/it] 59%|█████▉    | 7567/12825 [27:00:54<18:25:46, 12.62s/it] 59%|█████▉    | 7568/12825 [27:01:07<18:26:20, 12.63s/it] 59%|█████▉    | 7569/12825 [27:01:19<18:27:09, 12.64s/it] 59%|█████▉    | 7570/12825 [27:01:32<18:27:40, 12.65s/it] 59%|█████▉    | 7571/12825 [27:01:45<18:27:54, 12.65s/it] 59%|█████▉    | 7572/12825 [27:01:57<18:26:28, 12.64s/it] 59%|█████▉    | 7573/12825 [27:02:10<18:25:54, 12.63s/it] 59%|█████▉    | 7574/12825 [27:02:23<18:26:45, 12.65s/it] 59%|█████▉    | 7575/12825 [27:02:35<18:26:12, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120466.62lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103453.13lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7550] due to args.save_total_limit
 59%|█████▉    | 7576/12825 [27:02:48<18:34:51, 12.74s/it] 59%|█████▉    | 7577/12825 [27:03:08<21:46:28, 14.94s/it] 59%|█████▉    | 7578/12825 [27:03:21<20:45:11, 14.24s/it] 59%|█████▉    | 7579/12825 [27:03:34<20:02:57, 13.76s/it] 59%|█████▉    | 7580/12825 [27:03:46<19:32:38, 13.41s/it] 59%|█████▉    | 7581/12825 [27:03:59<19:12:31, 13.19s/it] 59%|█████▉    | 7582/12825 [27:04:11<18:57:21, 13.02s/it] 59%|█████▉    | 7583/12825 [27:04:24<18:46:37, 12.90s/it] 59%|█████▉    | 7584/12825 [27:04:37<18:39:33, 12.82s/it] 59%|█████▉    | 7585/12825 [27:04:49<18:35:25, 12.77s/it] 59%|█████▉    | 7586/12825 [27:05:02<18:31:25, 12.73s/it] 59%|█████▉    | 7587/12825 [27:05:15<18:28:37, 12.70s/it] 59%|█████▉    | 7588/12825 [27:05:27<18:28:13, 12.70s/it] 59%|█████▉    | 7589/12825 [27:05:40<18:28:31, 12.70s/it] 59%|█████▉    | 7590/12825 [27:05:53<18:26:55, 12.69s/it] 59%|█████▉    | 7591/12825 [27:06:05<18:25:07, 12.67s/it] 59%|█████▉    | 7592/12825 [27:06:18<18:25:15, 12.67s/it] 59%|█████▉    | 7593/12825 [27:06:31<18:22:53, 12.65s/it] 59%|█████▉    | 7594/12825 [27:06:43<18:23:29, 12.66s/it] 59%|█████▉    | 7595/12825 [27:06:56<18:22:30, 12.65s/it] 59%|█████▉    | 7596/12825 [27:07:09<18:21:40, 12.64s/it] 59%|█████▉    | 7597/12825 [27:07:21<18:21:45, 12.64s/it] 59%|█████▉    | 7598/12825 [27:07:34<18:21:18, 12.64s/it] 59%|█████▉    | 7599/12825 [27:07:46<18:22:15, 12.66s/it] 59%|█████▉    | 7600/12825 [27:07:59<18:21:52, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120457.65lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103439.71lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7575] due to args.save_total_limit
 59%|█████▉    | 7601/12825 [27:08:12<18:30:08, 12.75s/it] 59%|█████▉    | 7602/12825 [27:08:25<18:26:56, 12.72s/it] 59%|█████▉    | 7603/12825 [27:08:37<18:23:56, 12.68s/it] 59%|█████▉    | 7604/12825 [27:08:50<18:21:45, 12.66s/it] 59%|█████▉    | 7605/12825 [27:09:03<18:20:32, 12.65s/it] 59%|█████▉    | 7606/12825 [27:09:15<18:19:14, 12.64s/it] 59%|█████▉    | 7607/12825 [27:09:28<18:18:26, 12.63s/it] 59%|█████▉    | 7608/12825 [27:09:40<18:18:12, 12.63s/it] 59%|█████▉    | 7609/12825 [27:10:00<21:30:50, 14.85s/it] 59%|█████▉    | 7610/12825 [27:10:13<20:32:53, 14.18s/it] 59%|█████▉    | 7611/12825 [27:10:26<19:51:56, 13.72s/it] 59%|█████▉    | 7612/12825 [27:10:38<19:23:48, 13.40s/it] 59%|█████▉    | 7613/12825 [27:10:51<19:02:51, 13.16s/it] 59%|█████▉    | 7614/12825 [27:11:04<18:48:03, 12.99s/it] 59%|█████▉    | 7615/12825 [27:11:16<18:39:23, 12.89s/it] 59%|█████▉    | 7616/12825 [27:11:29<18:32:49, 12.82s/it] 59%|█████▉    | 7617/12825 [27:11:42<18:27:42, 12.76s/it] 59%|█████▉    | 7618/12825 [27:11:54<18:24:03, 12.72s/it] 59%|█████▉    | 7619/12825 [27:12:07<18:22:37, 12.71s/it] 59%|█████▉    | 7620/12825 [27:12:19<18:21:03, 12.69s/it] 59%|█████▉    | 7621/12825 [27:12:32<18:20:21, 12.69s/it] 59%|█████▉    | 7622/12825 [27:12:45<18:18:19, 12.67s/it] 59%|█████▉    | 7623/12825 [27:12:57<18:18:20, 12.67s/it] 59%|█████▉    | 7624/12825 [27:13:10<18:17:39, 12.66s/it] 59%|█████▉    | 7625/12825 [27:13:23<18:16:58, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120428.18lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103618.12lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7600] due to args.save_total_limit
 59%|█████▉    | 7626/12825 [27:13:36<18:23:32, 12.74s/it] 59%|█████▉    | 7627/12825 [27:13:48<18:19:54, 12.70s/it] 59%|█████▉    | 7628/12825 [27:14:01<18:17:30, 12.67s/it] 59%|█████▉    | 7629/12825 [27:14:14<18:16:11, 12.66s/it] 59%|█████▉    | 7630/12825 [27:14:26<18:15:06, 12.65s/it] 60%|█████▉    | 7631/12825 [27:14:39<18:14:40, 12.65s/it] 60%|█████▉    | 7632/12825 [27:14:51<18:13:48, 12.64s/it] 60%|█████▉    | 7633/12825 [27:15:04<18:12:49, 12.63s/it] 60%|█████▉    | 7634/12825 [27:15:17<18:12:33, 12.63s/it] 60%|█████▉    | 7635/12825 [27:15:29<18:12:53, 12.63s/it] 60%|█████▉    | 7636/12825 [27:15:42<18:13:30, 12.64s/it] 60%|█████▉    | 7637/12825 [27:15:55<18:13:37, 12.65s/it] 60%|█████▉    | 7638/12825 [27:16:07<18:13:29, 12.65s/it] 60%|█████▉    | 7639/12825 [27:16:20<18:13:18, 12.65s/it] 60%|█████▉    | 7640/12825 [27:16:33<18:12:02, 12.64s/it] 60%|█████▉    | 7641/12825 [27:16:45<18:12:47, 12.65s/it] 60%|█████▉    | 7642/12825 [27:17:06<21:31:29, 14.95s/it] 60%|█████▉    | 7643/12825 [27:17:18<20:31:30, 14.26s/it] 60%|█████▉    | 7644/12825 [27:17:31<19:48:47, 13.77s/it] 60%|█████▉    | 7645/12825 [27:17:43<19:18:03, 13.41s/it] 60%|█████▉    | 7646/12825 [27:17:56<18:56:16, 13.16s/it] 60%|█████▉    | 7647/12825 [27:18:09<18:42:00, 13.00s/it] 60%|█████▉    | 7648/12825 [27:18:21<18:33:30, 12.91s/it] 60%|█████▉    | 7649/12825 [27:18:34<18:25:09, 12.81s/it] 60%|█████▉    | 7650/12825 [27:18:46<18:20:13, 12.76s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120525.21lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103708.83lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7625] due to args.save_total_limit
 60%|█████▉    | 7651/12825 [27:18:59<18:24:07, 12.80s/it] 60%|█████▉    | 7652/12825 [27:19:12<18:20:49, 12.77s/it] 60%|█████▉    | 7653/12825 [27:19:25<18:16:36, 12.72s/it] 60%|█████▉    | 7654/12825 [27:19:37<18:13:51, 12.69s/it] 60%|█████▉    | 7655/12825 [27:19:50<18:13:42, 12.69s/it] 60%|█████▉    | 7656/12825 [27:20:03<18:12:50, 12.69s/it] 60%|█████▉    | 7657/12825 [27:20:15<18:10:45, 12.66s/it] 60%|█████▉    | 7658/12825 [27:20:28<18:09:40, 12.65s/it] 60%|█████▉    | 7659/12825 [27:20:41<18:09:40, 12.66s/it] 60%|█████▉    | 7660/12825 [27:20:53<18:09:48, 12.66s/it] 60%|█████▉    | 7661/12825 [27:21:06<18:10:10, 12.67s/it] 60%|█████▉    | 7662/12825 [27:21:19<18:08:54, 12.65s/it] 60%|█████▉    | 7663/12825 [27:21:31<18:07:37, 12.64s/it] 60%|█████▉    | 7664/12825 [27:21:44<18:07:05, 12.64s/it] 60%|█████▉    | 7665/12825 [27:21:56<18:06:58, 12.64s/it] 60%|█████▉    | 7666/12825 [27:22:09<18:11:12, 12.69s/it] 60%|█████▉    | 7667/12825 [27:22:22<18:09:06, 12.67s/it] 60%|█████▉    | 7668/12825 [27:22:34<18:07:58, 12.66s/it] 60%|█████▉    | 7669/12825 [27:22:47<18:06:17, 12.64s/it] 60%|█████▉    | 7670/12825 [27:23:00<18:08:26, 12.67s/it] 60%|█████▉    | 7671/12825 [27:23:13<18:08:34, 12.67s/it] 60%|█████▉    | 7672/12825 [27:23:25<18:07:54, 12.67s/it] 60%|█████▉    | 7673/12825 [27:23:38<18:06:46, 12.66s/it] 60%|█████▉    | 7674/12825 [27:23:57<21:06:20, 14.75s/it] 60%|█████▉    | 7675/12825 [27:24:10<20:11:56, 14.12s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120503.79lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 99086.63lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7650] due to args.save_total_limit
 60%|█████▉    | 7676/12825 [27:24:23<19:48:01, 13.84s/it] 60%|█████▉    | 7677/12825 [27:24:36<19:16:21, 13.48s/it] 60%|█████▉    | 7678/12825 [27:24:49<18:54:37, 13.23s/it] 60%|█████▉    | 7679/12825 [27:25:01<18:38:27, 13.04s/it] 60%|█████▉    | 7680/12825 [27:25:14<18:26:42, 12.91s/it] 60%|█████▉    | 7681/12825 [27:25:26<18:20:16, 12.83s/it] 60%|█████▉    | 7682/12825 [27:25:39<18:15:29, 12.78s/it] 60%|█████▉    | 7683/12825 [27:25:52<18:11:42, 12.74s/it] 60%|█████▉    | 7684/12825 [27:26:04<18:09:40, 12.72s/it] 60%|█████▉    | 7685/12825 [27:26:17<18:06:39, 12.68s/it] 60%|█████▉    | 7686/12825 [27:26:30<18:04:59, 12.67s/it] 60%|█████▉    | 7687/12825 [27:26:42<18:04:16, 12.66s/it] 60%|█████▉    | 7688/12825 [27:26:55<18:02:55, 12.65s/it] 60%|█████▉    | 7689/12825 [27:27:08<18:03:26, 12.66s/it] 60%|█████▉    | 7690/12825 [27:27:20<18:02:09, 12.64s/it] 60%|█████▉    | 7691/12825 [27:27:33<18:02:08, 12.65s/it] 60%|█████▉    | 7692/12825 [27:27:45<18:01:57, 12.65s/it] 60%|█████▉    | 7693/12825 [27:27:58<18:01:04, 12.64s/it] 60%|█████▉    | 7694/12825 [27:28:06<16:00:52, 11.24s/it] 60%|██████    | 7695/12825 [27:28:07<11:33:35,  8.11s/it] 60%|██████    | 7696/12825 [27:28:33<19:04:02, 13.38s/it] 60%|██████    | 7697/12825 [27:28:45<18:45:19, 13.17s/it] 60%|██████    | 7698/12825 [27:28:58<18:31:26, 13.01s/it] 60%|██████    | 7699/12825 [27:29:10<18:21:56, 12.90s/it] 60%|██████    | 7700/12825 [27:29:23<18:15:28, 12.83s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120523.41lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103660.51lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7675] due to args.save_total_limit
 60%|██████    | 7701/12825 [27:29:36<18:17:01, 12.85s/it] 60%|██████    | 7702/12825 [27:29:49<18:08:06, 12.74s/it] 60%|██████    | 7703/12825 [27:30:01<18:03:04, 12.69s/it] 60%|██████    | 7704/12825 [27:30:14<18:01:58, 12.68s/it] 60%|██████    | 7705/12825 [27:30:26<18:00:38, 12.66s/it] 60%|██████    | 7706/12825 [27:30:39<18:00:36, 12.67s/it] 60%|██████    | 7707/12825 [27:30:59<21:07:39, 14.86s/it] 60%|██████    | 7708/12825 [27:31:12<20:09:56, 14.19s/it] 60%|██████    | 7709/12825 [27:31:24<19:27:01, 13.69s/it] 60%|██████    | 7710/12825 [27:31:37<18:56:58, 13.34s/it] 60%|██████    | 7711/12825 [27:31:49<18:36:14, 13.10s/it] 60%|██████    | 7712/12825 [27:32:02<18:24:36, 12.96s/it] 60%|██████    | 7713/12825 [27:32:15<18:16:22, 12.87s/it] 60%|██████    | 7714/12825 [27:32:27<18:11:00, 12.81s/it] 60%|██████    | 7715/12825 [27:32:40<18:06:15, 12.75s/it] 60%|██████    | 7716/12825 [27:32:53<18:04:04, 12.73s/it] 60%|██████    | 7717/12825 [27:33:05<18:02:14, 12.71s/it] 60%|██████    | 7718/12825 [27:33:18<18:00:41, 12.70s/it] 60%|██████    | 7719/12825 [27:33:30<17:59:20, 12.68s/it] 60%|██████    | 7720/12825 [27:33:43<17:58:15, 12.67s/it] 60%|██████    | 7721/12825 [27:33:56<17:58:10, 12.67s/it] 60%|██████    | 7722/12825 [27:34:08<17:56:56, 12.66s/it] 60%|██████    | 7723/12825 [27:34:21<17:57:00, 12.67s/it] 60%|██████    | 7724/12825 [27:34:34<17:57:11, 12.67s/it] 60%|██████    | 7725/12825 [27:34:46<17:56:27, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120480.07lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103635.56lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7725
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7725/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7725/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7700] due to args.save_total_limit
 60%|██████    | 7726/12825 [27:34:59<18:03:31, 12.75s/it] 60%|██████    | 7727/12825 [27:35:12<18:00:20, 12.71s/it] 60%|██████    | 7728/12825 [27:35:25<17:57:07, 12.68s/it] 60%|██████    | 7729/12825 [27:35:37<17:54:47, 12.65s/it] 60%|██████    | 7730/12825 [27:35:50<17:55:21, 12.66s/it] 60%|██████    | 7731/12825 [27:36:03<17:55:17, 12.67s/it] 60%|██████    | 7732/12825 [27:36:15<17:54:38, 12.66s/it] 60%|██████    | 7733/12825 [27:36:28<17:54:35, 12.66s/it] 60%|██████    | 7734/12825 [27:36:40<17:52:56, 12.65s/it] 60%|██████    | 7735/12825 [27:36:53<17:53:02, 12.65s/it] 60%|██████    | 7736/12825 [27:37:06<17:52:33, 12.65s/it] 60%|██████    | 7737/12825 [27:37:18<17:52:40, 12.65s/it] 60%|██████    | 7738/12825 [27:37:31<17:52:26, 12.65s/it] 60%|██████    | 7739/12825 [27:37:51<21:00:15, 14.87s/it] 60%|██████    | 7740/12825 [27:38:04<20:03:01, 14.20s/it] 60%|██████    | 7741/12825 [27:38:16<19:24:12, 13.74s/it] 60%|██████    | 7742/12825 [27:38:29<18:56:49, 13.42s/it] 60%|██████    | 7743/12825 [27:38:42<18:36:46, 13.19s/it] 60%|██████    | 7744/12825 [27:38:54<18:23:25, 13.03s/it] 60%|██████    | 7745/12825 [27:39:07<18:14:05, 12.92s/it] 60%|██████    | 7746/12825 [27:39:20<18:06:48, 12.84s/it] 60%|██████    | 7747/12825 [27:39:32<18:02:08, 12.79s/it] 60%|██████    | 7748/12825 [27:39:45<17:58:52, 12.75s/it] 60%|██████    | 7749/12825 [27:39:58<17:56:37, 12.73s/it] 60%|██████    | 7750/12825 [27:40:10<17:53:58, 12.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120423.96lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103642.11lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7750
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7750/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7750/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7725] due to args.save_total_limit
 60%|██████    | 7751/12825 [27:40:23<18:01:06, 12.78s/it] 60%|██████    | 7752/12825 [27:40:36<17:56:38, 12.73s/it] 60%|██████    | 7753/12825 [27:40:49<17:54:35, 12.71s/it] 60%|██████    | 7754/12825 [27:41:01<17:52:14, 12.69s/it] 60%|██████    | 7755/12825 [27:41:14<17:50:48, 12.67s/it] 60%|██████    | 7756/12825 [27:41:27<17:49:09, 12.66s/it] 60%|██████    | 7757/12825 [27:41:39<17:48:58, 12.66s/it] 60%|██████    | 7758/12825 [27:41:52<17:48:23, 12.65s/it] 60%|██████    | 7759/12825 [27:42:04<17:47:32, 12.64s/it] 61%|██████    | 7760/12825 [27:42:17<17:47:43, 12.65s/it] 61%|██████    | 7761/12825 [27:42:30<17:48:18, 12.66s/it] 61%|██████    | 7762/12825 [27:42:42<17:47:07, 12.65s/it] 61%|██████    | 7763/12825 [27:42:55<17:46:23, 12.64s/it] 61%|██████    | 7764/12825 [27:43:08<17:46:02, 12.64s/it] 61%|██████    | 7765/12825 [27:43:20<17:45:28, 12.63s/it] 61%|██████    | 7766/12825 [27:43:33<17:44:56, 12.63s/it] 61%|██████    | 7767/12825 [27:43:46<17:44:31, 12.63s/it] 61%|██████    | 7768/12825 [27:43:58<17:44:53, 12.63s/it] 61%|██████    | 7769/12825 [27:44:11<17:45:02, 12.64s/it] 61%|██████    | 7770/12825 [27:44:23<17:44:08, 12.63s/it] 61%|██████    | 7771/12825 [27:44:36<17:46:18, 12.66s/it] 61%|██████    | 7772/12825 [27:44:56<20:50:16, 14.85s/it] 61%|██████    | 7773/12825 [27:45:09<19:54:25, 14.19s/it] 61%|██████    | 7774/12825 [27:45:21<19:15:00, 13.72s/it] 61%|██████    | 7775/12825 [27:45:34<18:47:19, 13.39s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120467.00lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103595.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7775
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7775/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7775/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7750] due to args.save_total_limit
 61%|██████    | 7776/12825 [27:45:47<18:35:48, 13.26s/it] 61%|██████    | 7777/12825 [27:46:00<18:20:25, 13.08s/it] 61%|██████    | 7778/12825 [27:46:12<18:08:49, 12.94s/it] 61%|██████    | 7779/12825 [27:46:25<18:01:18, 12.86s/it] 61%|██████    | 7780/12825 [27:46:38<17:54:57, 12.78s/it] 61%|██████    | 7781/12825 [27:46:50<17:51:42, 12.75s/it] 61%|██████    | 7782/12825 [27:47:03<17:49:47, 12.73s/it] 61%|██████    | 7783/12825 [27:47:16<17:47:51, 12.71s/it] 61%|██████    | 7784/12825 [27:47:28<17:46:03, 12.69s/it] 61%|██████    | 7785/12825 [27:47:41<17:44:09, 12.67s/it] 61%|██████    | 7786/12825 [27:47:53<17:44:09, 12.67s/it] 61%|██████    | 7787/12825 [27:48:06<17:43:50, 12.67s/it] 61%|██████    | 7788/12825 [27:48:19<17:43:04, 12.66s/it] 61%|██████    | 7789/12825 [27:48:31<17:41:47, 12.65s/it] 61%|██████    | 7790/12825 [27:48:44<17:41:26, 12.65s/it] 61%|██████    | 7791/12825 [27:48:57<17:40:40, 12.64s/it] 61%|██████    | 7792/12825 [27:49:09<17:40:25, 12.64s/it] 61%|██████    | 7793/12825 [27:49:22<17:40:42, 12.65s/it] 61%|██████    | 7794/12825 [27:49:35<17:40:43, 12.65s/it] 61%|██████    | 7795/12825 [27:49:47<17:40:23, 12.65s/it] 61%|██████    | 7796/12825 [27:50:00<17:40:21, 12.65s/it] 61%|██████    | 7797/12825 [27:50:13<17:40:53, 12.66s/it] 61%|██████    | 7798/12825 [27:50:25<17:39:52, 12.65s/it] 61%|██████    | 7799/12825 [27:50:38<17:44:40, 12.71s/it] 61%|██████    | 7800/12825 [27:50:51<17:42:10, 12.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120480.33lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103688.89lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7800
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7800/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7800/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7775] due to args.save_total_limit
 61%|██████    | 7801/12825 [27:51:04<17:49:38, 12.77s/it] 61%|██████    | 7802/12825 [27:51:16<17:46:34, 12.74s/it] 61%|██████    | 7803/12825 [27:51:29<17:43:42, 12.71s/it] 61%|██████    | 7804/12825 [27:51:49<20:51:16, 14.95s/it] 61%|██████    | 7805/12825 [27:52:02<19:52:46, 14.26s/it] 61%|██████    | 7806/12825 [27:52:14<19:11:44, 13.77s/it] 61%|██████    | 7807/12825 [27:52:27<18:42:31, 13.42s/it] 61%|██████    | 7808/12825 [27:52:40<18:22:27, 13.18s/it] 61%|██████    | 7809/12825 [27:52:52<18:08:36, 13.02s/it] 61%|██████    | 7810/12825 [27:53:05<18:03:21, 12.96s/it] 61%|██████    | 7811/12825 [27:53:18<17:54:55, 12.86s/it] 61%|██████    | 7812/12825 [27:53:30<17:49:17, 12.80s/it] 61%|██████    | 7813/12825 [27:53:43<17:45:28, 12.76s/it] 61%|██████    | 7814/12825 [27:53:56<17:42:31, 12.72s/it] 61%|██████    | 7815/12825 [27:54:08<17:40:35, 12.70s/it] 61%|██████    | 7816/12825 [27:54:21<17:39:21, 12.69s/it] 61%|██████    | 7817/12825 [27:54:34<17:38:51, 12.69s/it] 61%|██████    | 7818/12825 [27:54:46<17:36:52, 12.66s/it] 61%|██████    | 7819/12825 [27:54:59<17:36:05, 12.66s/it] 61%|██████    | 7820/12825 [27:55:12<17:35:25, 12.65s/it] 61%|██████    | 7821/12825 [27:55:24<17:35:33, 12.66s/it] 61%|██████    | 7822/12825 [27:55:37<17:35:21, 12.66s/it] 61%|██████    | 7823/12825 [27:55:50<17:35:58, 12.67s/it] 61%|██████    | 7824/12825 [27:56:02<17:35:23, 12.66s/it] 61%|██████    | 7825/12825 [27:56:15<17:33:54, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120314.06lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103547.25lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7825
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7825/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7825/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7800] due to args.save_total_limit
 61%|██████    | 7826/12825 [27:56:28<17:41:11, 12.74s/it] 61%|██████    | 7827/12825 [27:56:40<17:37:54, 12.70s/it] 61%|██████    | 7828/12825 [27:56:53<17:35:01, 12.67s/it] 61%|██████    | 7829/12825 [27:57:06<17:34:22, 12.66s/it] 61%|██████    | 7830/12825 [27:57:18<17:34:28, 12.67s/it] 61%|██████    | 7831/12825 [27:57:31<17:33:28, 12.66s/it] 61%|██████    | 7832/12825 [27:57:44<17:33:52, 12.66s/it] 61%|██████    | 7833/12825 [27:57:56<17:31:25, 12.64s/it] 61%|██████    | 7834/12825 [27:58:09<17:31:18, 12.64s/it] 61%|██████    | 7835/12825 [27:58:22<17:32:23, 12.65s/it] 61%|██████    | 7836/12825 [27:58:42<20:47:18, 15.00s/it] 61%|██████    | 7837/12825 [27:58:55<19:48:35, 14.30s/it] 61%|██████    | 7838/12825 [27:59:07<19:07:42, 13.81s/it] 61%|██████    | 7839/12825 [27:59:20<18:37:42, 13.45s/it] 61%|██████    | 7840/12825 [27:59:33<18:18:08, 13.22s/it] 61%|██████    | 7841/12825 [27:59:45<18:03:34, 13.04s/it] 61%|██████    | 7842/12825 [27:59:58<17:53:33, 12.93s/it] 61%|██████    | 7843/12825 [28:00:11<17:45:41, 12.83s/it] 61%|██████    | 7844/12825 [28:00:23<17:41:07, 12.78s/it] 61%|██████    | 7845/12825 [28:00:36<17:37:44, 12.74s/it] 61%|██████    | 7846/12825 [28:00:49<17:35:02, 12.71s/it] 61%|██████    | 7847/12825 [28:01:01<17:33:33, 12.70s/it] 61%|██████    | 7848/12825 [28:01:14<17:31:48, 12.68s/it] 61%|██████    | 7849/12825 [28:01:27<17:30:48, 12.67s/it] 61%|██████    | 7850/12825 [28:01:39<17:30:09, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120401.30lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103590.91lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7850
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7850/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7850/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7825] due to args.save_total_limit
 61%|██████    | 7851/12825 [28:01:52<17:40:57, 12.80s/it] 61%|██████    | 7852/12825 [28:02:05<17:36:09, 12.74s/it] 61%|██████    | 7853/12825 [28:02:18<17:33:25, 12.71s/it] 61%|██████    | 7854/12825 [28:02:30<17:30:47, 12.68s/it] 61%|██████    | 7855/12825 [28:02:43<17:29:21, 12.67s/it] 61%|██████▏   | 7856/12825 [28:02:55<17:27:47, 12.65s/it] 61%|██████▏   | 7857/12825 [28:03:08<17:27:09, 12.65s/it] 61%|██████▏   | 7858/12825 [28:03:21<17:30:47, 12.69s/it] 61%|██████▏   | 7859/12825 [28:03:33<17:28:39, 12.67s/it] 61%|██████▏   | 7860/12825 [28:03:46<17:27:58, 12.66s/it] 61%|██████▏   | 7861/12825 [28:03:59<17:27:47, 12.66s/it] 61%|██████▏   | 7862/12825 [28:04:11<17:27:02, 12.66s/it] 61%|██████▏   | 7863/12825 [28:04:24<17:25:29, 12.64s/it] 61%|██████▏   | 7864/12825 [28:04:37<17:26:07, 12.65s/it] 61%|██████▏   | 7865/12825 [28:04:49<17:25:54, 12.65s/it] 61%|██████▏   | 7866/12825 [28:05:02<17:25:31, 12.65s/it] 61%|██████▏   | 7867/12825 [28:05:15<17:25:10, 12.65s/it] 61%|██████▏   | 7868/12825 [28:05:27<17:26:09, 12.66s/it] 61%|██████▏   | 7869/12825 [28:05:47<20:30:09, 14.89s/it] 61%|██████▏   | 7870/12825 [28:06:00<19:34:11, 14.22s/it] 61%|██████▏   | 7871/12825 [28:06:13<18:54:18, 13.74s/it] 61%|██████▏   | 7872/12825 [28:06:25<18:25:59, 13.40s/it] 61%|██████▏   | 7873/12825 [28:06:38<18:07:09, 13.17s/it] 61%|██████▏   | 7874/12825 [28:06:51<17:53:26, 13.01s/it] 61%|██████▏   | 7875/12825 [28:07:03<17:44:19, 12.90s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120458.80lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103622.67lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7875
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7875/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7875/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7850] due to args.save_total_limit
 61%|██████▏   | 7876/12825 [28:07:16<17:45:57, 12.92s/it] 61%|██████▏   | 7877/12825 [28:07:29<17:38:16, 12.83s/it] 61%|██████▏   | 7878/12825 [28:07:41<17:33:23, 12.78s/it] 61%|██████▏   | 7879/12825 [28:07:54<17:30:18, 12.74s/it] 61%|██████▏   | 7880/12825 [28:08:07<17:28:27, 12.72s/it] 61%|██████▏   | 7881/12825 [28:08:19<17:27:15, 12.71s/it] 61%|██████▏   | 7882/12825 [28:08:32<17:26:06, 12.70s/it] 61%|██████▏   | 7883/12825 [28:08:45<17:25:16, 12.69s/it] 61%|██████▏   | 7884/12825 [28:08:57<17:23:51, 12.68s/it] 61%|██████▏   | 7885/12825 [28:09:10<17:21:29, 12.65s/it] 61%|██████▏   | 7886/12825 [28:09:23<17:18:52, 12.62s/it] 61%|██████▏   | 7887/12825 [28:09:35<17:16:39, 12.60s/it] 62%|██████▏   | 7888/12825 [28:09:48<17:15:24, 12.58s/it] 62%|██████▏   | 7889/12825 [28:10:00<17:14:17, 12.57s/it] 62%|██████▏   | 7890/12825 [28:10:13<17:12:24, 12.55s/it] 62%|██████▏   | 7891/12825 [28:10:25<17:11:48, 12.55s/it] 62%|██████▏   | 7892/12825 [28:10:38<17:19:10, 12.64s/it] 62%|██████▏   | 7893/12825 [28:10:51<17:21:36, 12.67s/it] 62%|██████▏   | 7894/12825 [28:11:04<17:21:39, 12.67s/it] 62%|██████▏   | 7895/12825 [28:11:16<17:21:01, 12.67s/it] 62%|██████▏   | 7896/12825 [28:11:29<17:20:25, 12.66s/it] 62%|██████▏   | 7897/12825 [28:11:42<17:19:39, 12.66s/it] 62%|██████▏   | 7898/12825 [28:11:54<17:19:35, 12.66s/it] 62%|██████▏   | 7899/12825 [28:12:07<17:18:49, 12.65s/it] 62%|██████▏   | 7900/12825 [28:12:19<17:17:56, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120398.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103613.00lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7900
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7900/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7900/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7875] due to args.save_total_limit
 62%|██████▏   | 7901/12825 [28:12:40<20:44:36, 15.17s/it] 62%|██████▏   | 7902/12825 [28:12:53<19:43:01, 14.42s/it] 62%|██████▏   | 7903/12825 [28:13:06<18:59:25, 13.89s/it] 62%|██████▏   | 7904/12825 [28:13:18<18:27:48, 13.51s/it] 62%|██████▏   | 7905/12825 [28:13:31<18:06:48, 13.25s/it] 62%|██████▏   | 7906/12825 [28:13:44<17:51:08, 13.07s/it] 62%|██████▏   | 7907/12825 [28:13:56<17:39:15, 12.92s/it] 62%|██████▏   | 7908/12825 [28:14:09<17:31:24, 12.83s/it] 62%|██████▏   | 7909/12825 [28:14:22<17:26:19, 12.77s/it] 62%|██████▏   | 7910/12825 [28:14:34<17:24:56, 12.76s/it] 62%|██████▏   | 7911/12825 [28:14:47<17:23:10, 12.74s/it] 62%|██████▏   | 7912/12825 [28:15:00<17:21:30, 12.72s/it] 62%|██████▏   | 7913/12825 [28:15:12<17:20:50, 12.71s/it] 62%|██████▏   | 7914/12825 [28:15:25<17:19:20, 12.70s/it] 62%|██████▏   | 7915/12825 [28:15:38<17:19:33, 12.70s/it] 62%|██████▏   | 7916/12825 [28:15:50<17:19:07, 12.70s/it] 62%|██████▏   | 7917/12825 [28:16:03<17:17:26, 12.68s/it] 62%|██████▏   | 7918/12825 [28:16:16<17:17:07, 12.68s/it] 62%|██████▏   | 7919/12825 [28:16:28<17:16:18, 12.67s/it] 62%|██████▏   | 7920/12825 [28:16:41<17:15:16, 12.66s/it] 62%|██████▏   | 7921/12825 [28:16:54<17:15:37, 12.67s/it] 62%|██████▏   | 7922/12825 [28:17:06<17:15:06, 12.67s/it] 62%|██████▏   | 7923/12825 [28:17:19<17:14:47, 12.67s/it] 62%|██████▏   | 7924/12825 [28:17:32<17:15:54, 12.68s/it] 62%|██████▏   | 7925/12825 [28:17:44<17:15:02, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120340.52lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103499.93lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7925
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7925/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7925/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7900] due to args.save_total_limit
 62%|██████▏   | 7926/12825 [28:17:57<17:24:07, 12.79s/it] 62%|██████▏   | 7927/12825 [28:18:10<17:20:27, 12.75s/it] 62%|██████▏   | 7928/12825 [28:18:23<17:18:28, 12.72s/it] 62%|██████▏   | 7929/12825 [28:18:35<17:16:50, 12.71s/it] 62%|██████▏   | 7930/12825 [28:18:48<17:15:53, 12.70s/it] 62%|██████▏   | 7931/12825 [28:19:01<17:18:59, 12.74s/it] 62%|██████▏   | 7932/12825 [28:19:14<17:17:22, 12.72s/it] 62%|██████▏   | 7933/12825 [28:19:34<20:23:39, 15.01s/it] 62%|██████▏   | 7934/12825 [28:19:47<19:25:50, 14.30s/it] 62%|██████▏   | 7935/12825 [28:19:59<18:46:56, 13.83s/it] 62%|██████▏   | 7936/12825 [28:20:12<18:18:45, 13.48s/it] 62%|██████▏   | 7937/12825 [28:20:25<17:59:16, 13.25s/it] 62%|██████▏   | 7938/12825 [28:20:37<17:46:33, 13.09s/it] 62%|██████▏   | 7939/12825 [28:20:50<17:36:17, 12.97s/it] 62%|██████▏   | 7940/12825 [28:21:03<17:28:46, 12.88s/it] 62%|██████▏   | 7941/12825 [28:21:16<17:24:23, 12.83s/it] 62%|██████▏   | 7942/12825 [28:21:28<17:19:46, 12.78s/it] 62%|██████▏   | 7943/12825 [28:21:41<17:18:04, 12.76s/it] 62%|██████▏   | 7944/12825 [28:21:54<17:16:05, 12.74s/it] 62%|██████▏   | 7945/12825 [28:22:06<17:15:47, 12.74s/it] 62%|██████▏   | 7946/12825 [28:22:19<17:14:43, 12.72s/it] 62%|██████▏   | 7947/12825 [28:22:32<17:13:02, 12.71s/it] 62%|██████▏   | 7948/12825 [28:22:44<17:11:59, 12.70s/it] 62%|██████▏   | 7949/12825 [28:22:57<17:12:29, 12.70s/it] 62%|██████▏   | 7950/12825 [28:23:10<17:12:02, 12.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120418.20lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103617.45lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7950
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7950/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7950/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7925] due to args.save_total_limit
 62%|██████▏   | 7951/12825 [28:23:23<17:19:55, 12.80s/it] 62%|██████▏   | 7952/12825 [28:23:35<17:15:46, 12.75s/it] 62%|██████▏   | 7953/12825 [28:23:48<17:12:23, 12.71s/it] 62%|██████▏   | 7954/12825 [28:24:01<17:11:28, 12.71s/it] 62%|██████▏   | 7955/12825 [28:24:13<17:11:07, 12.70s/it] 62%|██████▏   | 7956/12825 [28:24:26<17:10:49, 12.70s/it] 62%|██████▏   | 7957/12825 [28:24:39<17:09:22, 12.69s/it] 62%|██████▏   | 7958/12825 [28:24:51<17:08:40, 12.68s/it] 62%|██████▏   | 7959/12825 [28:25:04<17:08:02, 12.68s/it] 62%|██████▏   | 7960/12825 [28:25:17<17:07:40, 12.67s/it] 62%|██████▏   | 7961/12825 [28:25:30<17:07:33, 12.68s/it] 62%|██████▏   | 7962/12825 [28:25:42<17:06:35, 12.67s/it] 62%|██████▏   | 7963/12825 [28:25:55<17:06:52, 12.67s/it] 62%|██████▏   | 7964/12825 [28:26:08<17:07:14, 12.68s/it] 62%|██████▏   | 7965/12825 [28:26:20<17:06:17, 12.67s/it] 62%|██████▏   | 7966/12825 [28:26:41<20:20:41, 15.07s/it] 62%|██████▏   | 7967/12825 [28:26:54<19:21:29, 14.35s/it] 62%|██████▏   | 7968/12825 [28:27:06<18:41:36, 13.86s/it] 62%|██████▏   | 7969/12825 [28:27:19<18:13:18, 13.51s/it] 62%|██████▏   | 7970/12825 [28:27:32<17:53:25, 13.27s/it] 62%|██████▏   | 7971/12825 [28:27:44<17:39:06, 13.09s/it] 62%|██████▏   | 7972/12825 [28:27:57<17:27:59, 12.96s/it] 62%|██████▏   | 7973/12825 [28:28:10<17:21:15, 12.88s/it] 62%|██████▏   | 7974/12825 [28:28:22<17:16:37, 12.82s/it] 62%|██████▏   | 7975/12825 [28:28:35<17:13:11, 12.78s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120472.13lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103571.02lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7975
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7975/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7975/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-7975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7950] due to args.save_total_limit
 62%|██████▏   | 7976/12825 [28:28:48<17:19:22, 12.86s/it] 62%|██████▏   | 7977/12825 [28:29:01<17:13:43, 12.79s/it] 62%|██████▏   | 7978/12825 [28:29:13<17:09:56, 12.75s/it] 62%|██████▏   | 7979/12825 [28:29:26<17:06:30, 12.71s/it] 62%|██████▏   | 7980/12825 [28:29:39<17:06:03, 12.71s/it] 62%|██████▏   | 7981/12825 [28:29:51<17:04:49, 12.69s/it] 62%|██████▏   | 7982/12825 [28:30:04<17:03:14, 12.68s/it] 62%|██████▏   | 7983/12825 [28:30:17<17:02:21, 12.67s/it] 62%|██████▏   | 7984/12825 [28:30:29<17:01:45, 12.66s/it] 62%|██████▏   | 7985/12825 [28:30:42<17:01:24, 12.66s/it] 62%|██████▏   | 7986/12825 [28:30:55<17:01:31, 12.67s/it] 62%|██████▏   | 7987/12825 [28:31:07<17:01:16, 12.67s/it] 62%|██████▏   | 7988/12825 [28:31:20<17:01:10, 12.67s/it] 62%|██████▏   | 7989/12825 [28:31:33<17:00:18, 12.66s/it] 62%|██████▏   | 7990/12825 [28:31:45<17:01:10, 12.67s/it] 62%|██████▏   | 7991/12825 [28:31:58<17:00:50, 12.67s/it] 62%|██████▏   | 7992/12825 [28:32:11<17:01:03, 12.68s/it] 62%|██████▏   | 7993/12825 [28:32:23<16:59:43, 12.66s/it] 62%|██████▏   | 7994/12825 [28:32:36<16:59:40, 12.66s/it] 62%|██████▏   | 7995/12825 [28:32:49<16:59:36, 12.67s/it] 62%|██████▏   | 7996/12825 [28:33:01<16:59:55, 12.67s/it] 62%|██████▏   | 7997/12825 [28:33:14<16:59:51, 12.67s/it] 62%|██████▏   | 7998/12825 [28:33:34<20:08:16, 15.02s/it] 62%|██████▏   | 7999/12825 [28:33:47<19:12:57, 14.33s/it] 62%|██████▏   | 8000/12825 [28:34:00<18:32:12, 13.83s/it]                                                           62%|██████▏   | 8000/12825 [28:34:00<18:32:12, 13.83s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 84714.65lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 76032.59lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8000
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8000/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8000/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7975] due to args.save_total_limit
 62%|██████▏   | 8001/12825 [28:34:13<18:15:17, 13.62s/it] 62%|██████▏   | 8002/12825 [28:34:26<17:53:15, 13.35s/it] 62%|██████▏   | 8003/12825 [28:34:38<17:36:51, 13.15s/it] 62%|██████▏   | 8004/12825 [28:34:51<17:25:46, 13.02s/it] 62%|██████▏   | 8005/12825 [28:35:04<17:17:30, 12.91s/it] 62%|██████▏   | 8006/12825 [28:35:16<17:11:24, 12.84s/it] 62%|██████▏   | 8007/12825 [28:35:29<17:07:18, 12.79s/it] 62%|██████▏   | 8008/12825 [28:35:42<17:04:46, 12.76s/it] 62%|██████▏   | 8009/12825 [28:35:54<17:02:16, 12.74s/it] 62%|██████▏   | 8010/12825 [28:36:07<16:59:56, 12.71s/it] 62%|██████▏   | 8011/12825 [28:36:20<16:59:02, 12.70s/it] 62%|██████▏   | 8012/12825 [28:36:33<16:58:33, 12.70s/it] 62%|██████▏   | 8013/12825 [28:36:45<16:58:23, 12.70s/it] 62%|██████▏   | 8014/12825 [28:36:58<16:58:13, 12.70s/it] 62%|██████▏   | 8015/12825 [28:37:11<16:57:44, 12.70s/it] 63%|██████▎   | 8016/12825 [28:37:23<16:57:22, 12.69s/it] 63%|██████▎   | 8017/12825 [28:37:36<16:56:52, 12.69s/it] 63%|██████▎   | 8018/12825 [28:37:49<16:55:34, 12.68s/it] 63%|██████▎   | 8019/12825 [28:38:01<16:55:05, 12.67s/it] 63%|██████▎   | 8020/12825 [28:38:14<16:54:46, 12.67s/it] 63%|██████▎   | 8021/12825 [28:38:27<16:54:31, 12.67s/it] 63%|██████▎   | 8022/12825 [28:38:39<16:54:14, 12.67s/it] 63%|██████▎   | 8023/12825 [28:38:52<16:53:27, 12.66s/it] 63%|██████▎   | 8024/12825 [28:39:05<16:53:41, 12.67s/it] 63%|██████▎   | 8025/12825 [28:39:17<16:54:09, 12.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120320.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103523.02lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8025
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8025/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8025/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8000] due to args.save_total_limit
 63%|██████▎   | 8026/12825 [28:39:30<17:04:44, 12.81s/it] 63%|██████▎   | 8027/12825 [28:39:43<17:00:53, 12.77s/it] 63%|██████▎   | 8028/12825 [28:39:56<17:01:58, 12.78s/it] 63%|██████▎   | 8029/12825 [28:40:09<16:59:48, 12.76s/it] 63%|██████▎   | 8030/12825 [28:40:29<20:01:59, 15.04s/it] 63%|██████▎   | 8031/12825 [28:40:42<19:05:13, 14.33s/it] 63%|██████▎   | 8032/12825 [28:40:54<18:24:57, 13.83s/it] 63%|██████▎   | 8033/12825 [28:41:07<17:56:24, 13.48s/it] 63%|██████▎   | 8034/12825 [28:41:20<17:36:50, 13.24s/it] 63%|██████▎   | 8035/12825 [28:41:32<17:23:02, 13.07s/it] 63%|██████▎   | 8036/12825 [28:41:45<17:13:04, 12.94s/it] 63%|██████▎   | 8037/12825 [28:41:58<17:05:46, 12.85s/it] 63%|██████▎   | 8038/12825 [28:42:10<17:01:26, 12.80s/it] 63%|██████▎   | 8039/12825 [28:42:23<16:58:29, 12.77s/it] 63%|██████▎   | 8040/12825 [28:42:36<16:57:43, 12.76s/it] 63%|██████▎   | 8041/12825 [28:42:48<16:55:55, 12.74s/it] 63%|██████▎   | 8042/12825 [28:43:01<16:54:45, 12.73s/it] 63%|██████▎   | 8043/12825 [28:43:14<16:53:26, 12.72s/it] 63%|██████▎   | 8044/12825 [28:43:26<16:52:21, 12.70s/it] 63%|██████▎   | 8045/12825 [28:43:39<16:50:52, 12.69s/it] 63%|██████▎   | 8046/12825 [28:43:52<16:50:13, 12.68s/it] 63%|██████▎   | 8047/12825 [28:44:05<16:52:05, 12.71s/it] 63%|██████▎   | 8048/12825 [28:44:17<16:50:46, 12.70s/it] 63%|██████▎   | 8049/12825 [28:44:30<16:50:31, 12.70s/it] 63%|██████▎   | 8050/12825 [28:44:43<16:49:38, 12.69s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120372.63lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103588.92lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8050
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8050/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8050/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8025] due to args.save_total_limit
 63%|██████▎   | 8051/12825 [28:44:56<16:57:31, 12.79s/it] 63%|██████▎   | 8052/12825 [28:45:08<16:54:36, 12.75s/it] 63%|██████▎   | 8053/12825 [28:45:21<16:52:43, 12.73s/it] 63%|██████▎   | 8054/12825 [28:45:34<16:49:50, 12.70s/it] 63%|██████▎   | 8055/12825 [28:45:46<16:48:58, 12.69s/it] 63%|██████▎   | 8056/12825 [28:45:59<16:49:14, 12.70s/it] 63%|██████▎   | 8057/12825 [28:46:12<16:47:45, 12.68s/it] 63%|██████▎   | 8058/12825 [28:46:24<16:48:06, 12.69s/it] 63%|██████▎   | 8059/12825 [28:46:37<16:47:58, 12.69s/it] 63%|██████▎   | 8060/12825 [28:46:50<16:48:11, 12.69s/it] 63%|██████▎   | 8061/12825 [28:47:02<16:47:20, 12.69s/it] 63%|██████▎   | 8062/12825 [28:47:15<16:47:13, 12.69s/it] 63%|██████▎   | 8063/12825 [28:47:35<19:47:11, 14.96s/it] 63%|██████▎   | 8064/12825 [28:47:48<18:54:06, 14.29s/it] 63%|██████▎   | 8065/12825 [28:48:01<18:14:45, 13.80s/it] 63%|██████▎   | 8066/12825 [28:48:13<17:48:34, 13.47s/it] 63%|██████▎   | 8067/12825 [28:48:26<17:29:56, 13.24s/it] 63%|██████▎   | 8068/12825 [28:48:39<17:15:49, 13.06s/it] 63%|██████▎   | 8069/12825 [28:48:51<17:06:04, 12.94s/it] 63%|██████▎   | 8070/12825 [28:49:04<16:59:43, 12.87s/it] 63%|██████▎   | 8071/12825 [28:49:17<16:54:33, 12.80s/it] 63%|██████▎   | 8072/12825 [28:49:29<16:50:28, 12.76s/it] 63%|██████▎   | 8073/12825 [28:49:42<16:48:12, 12.73s/it] 63%|██████▎   | 8074/12825 [28:49:55<16:46:48, 12.71s/it] 63%|██████▎   | 8075/12825 [28:50:07<16:44:48, 12.69s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120039.74lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103322.02lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8075
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8075/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8075/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-7425] due to args.save_total_limit
 63%|██████▎   | 8076/12825 [28:50:20<16:52:46, 12.80s/it] 63%|██████▎   | 8077/12825 [28:50:33<16:49:45, 12.76s/it] 63%|██████▎   | 8078/12825 [28:50:46<16:46:34, 12.72s/it] 63%|██████▎   | 8079/12825 [28:50:58<16:44:18, 12.70s/it] 63%|██████▎   | 8080/12825 [28:51:11<16:42:20, 12.67s/it] 63%|██████▎   | 8081/12825 [28:51:24<16:40:53, 12.66s/it] 63%|██████▎   | 8082/12825 [28:51:36<16:40:15, 12.65s/it] 63%|██████▎   | 8083/12825 [28:51:49<16:38:53, 12.64s/it] 63%|██████▎   | 8084/12825 [28:52:01<16:36:24, 12.61s/it] 63%|██████▎   | 8085/12825 [28:52:14<16:34:40, 12.59s/it] 63%|██████▎   | 8086/12825 [28:52:27<16:34:59, 12.60s/it] 63%|██████▎   | 8087/12825 [28:52:39<16:34:44, 12.60s/it] 63%|██████▎   | 8088/12825 [28:52:52<16:34:39, 12.60s/it] 63%|██████▎   | 8089/12825 [28:53:04<16:34:19, 12.60s/it] 63%|██████▎   | 8090/12825 [28:53:17<16:33:46, 12.59s/it] 63%|██████▎   | 8091/12825 [28:53:30<16:33:28, 12.59s/it] 63%|██████▎   | 8092/12825 [28:53:42<16:32:07, 12.58s/it] 63%|██████▎   | 8093/12825 [28:53:55<16:31:02, 12.57s/it] 63%|██████▎   | 8094/12825 [28:54:07<16:30:42, 12.56s/it] 63%|██████▎   | 8095/12825 [28:54:28<19:42:58, 15.01s/it] 63%|██████▎   | 8096/12825 [28:54:40<18:44:31, 14.27s/it] 63%|██████▎   | 8097/12825 [28:54:53<18:02:45, 13.74s/it] 63%|██████▎   | 8098/12825 [28:55:06<17:34:53, 13.39s/it] 63%|██████▎   | 8099/12825 [28:55:18<17:15:10, 13.14s/it] 63%|██████▎   | 8100/12825 [28:55:31<17:01:12, 12.97s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120276.11lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103561.83lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8050] due to args.save_total_limit
 63%|██████▎   | 8101/12825 [28:55:44<16:58:53, 12.94s/it] 63%|██████▎   | 8102/12825 [28:55:56<16:52:18, 12.86s/it] 63%|██████▎   | 8103/12825 [28:56:09<16:43:34, 12.75s/it] 63%|██████▎   | 8104/12825 [28:56:21<16:38:36, 12.69s/it] 63%|██████▎   | 8105/12825 [28:56:34<16:35:19, 12.65s/it] 63%|██████▎   | 8106/12825 [28:56:46<16:33:36, 12.63s/it] 63%|██████▎   | 8107/12825 [28:56:59<16:30:16, 12.59s/it] 63%|██████▎   | 8108/12825 [28:57:11<16:28:44, 12.58s/it] 63%|██████▎   | 8109/12825 [28:57:24<16:27:15, 12.56s/it] 63%|██████▎   | 8110/12825 [28:57:37<16:26:23, 12.55s/it] 63%|██████▎   | 8111/12825 [28:57:49<16:25:44, 12.55s/it] 63%|██████▎   | 8112/12825 [28:58:02<16:25:36, 12.55s/it] 63%|██████▎   | 8113/12825 [28:58:14<16:24:28, 12.54s/it] 63%|██████▎   | 8114/12825 [28:58:27<16:24:46, 12.54s/it] 63%|██████▎   | 8115/12825 [28:58:39<16:22:58, 12.52s/it] 63%|██████▎   | 8116/12825 [28:58:52<16:25:28, 12.56s/it] 63%|██████▎   | 8117/12825 [28:59:04<16:24:48, 12.55s/it] 63%|██████▎   | 8118/12825 [28:59:17<16:23:41, 12.54s/it] 63%|██████▎   | 8119/12825 [28:59:29<16:25:06, 12.56s/it] 63%|██████▎   | 8120/12825 [28:59:42<16:26:16, 12.58s/it] 63%|██████▎   | 8121/12825 [28:59:55<16:25:30, 12.57s/it] 63%|██████▎   | 8122/12825 [29:00:07<16:27:01, 12.59s/it] 63%|██████▎   | 8123/12825 [29:00:20<16:24:47, 12.57s/it] 63%|██████▎   | 8124/12825 [29:00:32<16:24:21, 12.56s/it] 63%|██████▎   | 8125/12825 [29:00:45<16:22:47, 12.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120293.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103569.60lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8100] due to args.save_total_limit
 63%|██████▎   | 8126/12825 [29:00:58<16:30:27, 12.65s/it] 63%|██████▎   | 8127/12825 [29:01:18<19:35:19, 15.01s/it] 63%|██████▎   | 8128/12825 [29:01:31<18:36:50, 14.27s/it] 63%|██████▎   | 8129/12825 [29:01:43<17:55:10, 13.74s/it] 63%|██████▎   | 8130/12825 [29:01:56<17:29:49, 13.42s/it] 63%|██████▎   | 8131/12825 [29:02:08<17:08:51, 13.15s/it] 63%|██████▎   | 8132/12825 [29:02:21<16:55:30, 12.98s/it] 63%|██████▎   | 8133/12825 [29:02:34<16:47:54, 12.89s/it] 63%|██████▎   | 8134/12825 [29:02:46<16:40:40, 12.80s/it] 63%|██████▎   | 8135/12825 [29:02:59<16:34:03, 12.72s/it] 63%|██████▎   | 8136/12825 [29:03:11<16:29:10, 12.66s/it] 63%|██████▎   | 8137/12825 [29:03:24<16:27:32, 12.64s/it] 63%|██████▎   | 8138/12825 [29:03:37<16:24:51, 12.61s/it] 63%|██████▎   | 8139/12825 [29:03:49<16:24:35, 12.61s/it] 63%|██████▎   | 8140/12825 [29:04:02<16:22:47, 12.59s/it] 63%|██████▎   | 8141/12825 [29:04:14<16:21:18, 12.57s/it] 63%|██████▎   | 8142/12825 [29:04:27<16:20:18, 12.56s/it] 63%|██████▎   | 8143/12825 [29:04:39<16:19:07, 12.55s/it] 64%|██████▎   | 8144/12825 [29:04:52<16:18:32, 12.54s/it] 64%|██████▎   | 8145/12825 [29:05:04<16:19:31, 12.56s/it] 64%|██████▎   | 8146/12825 [29:05:17<16:17:58, 12.54s/it] 64%|██████▎   | 8147/12825 [29:05:29<16:16:53, 12.53s/it] 64%|██████▎   | 8148/12825 [29:05:42<16:16:55, 12.53s/it] 64%|██████▎   | 8149/12825 [29:05:54<16:17:19, 12.54s/it] 64%|██████▎   | 8150/12825 [29:06:07<16:16:55, 12.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120226.95lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103532.29lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8125] due to args.save_total_limit
 64%|██████▎   | 8151/12825 [29:06:20<16:25:55, 12.66s/it] 64%|██████▎   | 8152/12825 [29:06:32<16:21:36, 12.60s/it] 64%|██████▎   | 8153/12825 [29:06:45<16:18:37, 12.57s/it] 64%|██████▎   | 8154/12825 [29:06:57<16:16:46, 12.55s/it] 64%|██████▎   | 8155/12825 [29:07:10<16:16:35, 12.55s/it] 64%|██████▎   | 8156/12825 [29:07:22<16:14:27, 12.52s/it] 64%|██████▎   | 8157/12825 [29:07:35<16:14:35, 12.53s/it] 64%|██████▎   | 8158/12825 [29:07:47<16:13:43, 12.52s/it] 64%|██████▎   | 8159/12825 [29:08:00<16:12:56, 12.51s/it] 64%|██████▎   | 8160/12825 [29:08:20<19:10:23, 14.80s/it] 64%|██████▎   | 8161/12825 [29:08:33<18:16:40, 14.11s/it] 64%|██████▎   | 8162/12825 [29:08:45<17:39:43, 13.64s/it] 64%|██████▎   | 8163/12825 [29:08:58<17:12:41, 13.29s/it] 64%|██████▎   | 8164/12825 [29:09:10<16:56:17, 13.08s/it] 64%|██████▎   | 8165/12825 [29:09:23<16:45:24, 12.95s/it] 64%|██████▎   | 8166/12825 [29:09:35<16:37:31, 12.85s/it] 64%|██████▎   | 8167/12825 [29:09:48<16:31:39, 12.77s/it] 64%|██████▎   | 8168/12825 [29:10:01<16:27:12, 12.72s/it] 64%|██████▎   | 8169/12825 [29:10:13<16:24:04, 12.68s/it] 64%|██████▎   | 8170/12825 [29:10:26<16:25:21, 12.70s/it] 64%|██████▎   | 8171/12825 [29:10:39<16:23:07, 12.67s/it] 64%|██████▎   | 8172/12825 [29:10:51<16:24:42, 12.70s/it] 64%|██████▎   | 8173/12825 [29:11:04<16:24:39, 12.70s/it] 64%|██████▎   | 8174/12825 [29:11:17<16:25:50, 12.72s/it] 64%|██████▎   | 8175/12825 [29:11:29<16:23:52, 12.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120130.53lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 83958.66lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8150] due to args.save_total_limit
 64%|██████▍   | 8176/12825 [29:11:43<16:35:37, 12.85s/it] 64%|██████▍   | 8177/12825 [29:11:55<16:32:09, 12.81s/it] 64%|██████▍   | 8178/12825 [29:12:08<16:28:57, 12.77s/it] 64%|██████▍   | 8179/12825 [29:12:21<16:27:02, 12.75s/it] 64%|██████▍   | 8180/12825 [29:12:33<16:26:45, 12.75s/it] 64%|██████▍   | 8181/12825 [29:12:46<16:23:34, 12.71s/it] 64%|██████▍   | 8182/12825 [29:12:59<16:22:35, 12.70s/it] 64%|██████▍   | 8183/12825 [29:13:11<16:21:37, 12.69s/it] 64%|██████▍   | 8184/12825 [29:13:24<16:20:38, 12.68s/it] 64%|██████▍   | 8185/12825 [29:13:37<16:20:27, 12.68s/it] 64%|██████▍   | 8186/12825 [29:13:50<16:22:01, 12.70s/it] 64%|██████▍   | 8187/12825 [29:14:02<16:23:00, 12.72s/it] 64%|██████▍   | 8188/12825 [29:14:15<16:21:22, 12.70s/it] 64%|██████▍   | 8189/12825 [29:14:28<16:20:11, 12.69s/it] 64%|██████▍   | 8190/12825 [29:14:40<16:19:18, 12.68s/it] 64%|██████▍   | 8191/12825 [29:14:53<16:19:05, 12.68s/it] 64%|██████▍   | 8192/12825 [29:15:14<19:43:08, 15.32s/it] 64%|██████▍   | 8193/12825 [29:15:27<18:40:22, 14.51s/it] 64%|██████▍   | 8194/12825 [29:15:40<17:57:17, 13.96s/it] 64%|██████▍   | 8195/12825 [29:15:52<17:26:16, 13.56s/it] 64%|██████▍   | 8196/12825 [29:16:05<17:04:48, 13.28s/it] 64%|██████▍   | 8197/12825 [29:16:18<16:49:58, 13.09s/it] 64%|██████▍   | 8198/12825 [29:16:30<16:39:52, 12.97s/it] 64%|██████▍   | 8199/12825 [29:16:43<16:32:32, 12.87s/it] 64%|██████▍   | 8200/12825 [29:16:56<16:27:45, 12.81s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120256.82lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103518.19lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8175] due to args.save_total_limit
 64%|██████▍   | 8201/12825 [29:17:09<16:32:19, 12.88s/it] 64%|██████▍   | 8202/12825 [29:17:21<16:26:29, 12.80s/it] 64%|██████▍   | 8203/12825 [29:17:34<16:22:35, 12.76s/it] 64%|██████▍   | 8204/12825 [29:17:47<16:21:19, 12.74s/it] 64%|██████▍   | 8205/12825 [29:17:59<16:19:05, 12.72s/it] 64%|██████▍   | 8206/12825 [29:18:12<16:17:29, 12.70s/it] 64%|██████▍   | 8207/12825 [29:18:20<14:26:33, 11.26s/it] 64%|██████▍   | 8208/12825 [29:18:21<10:25:26,  8.13s/it] 64%|██████▍   | 8209/12825 [29:18:46<17:13:31, 13.43s/it] 64%|██████▍   | 8210/12825 [29:18:59<16:57:58, 13.23s/it] 64%|██████▍   | 8211/12825 [29:19:12<16:44:52, 13.07s/it] 64%|██████▍   | 8212/12825 [29:19:25<16:36:20, 12.96s/it] 64%|██████▍   | 8213/12825 [29:19:37<16:30:31, 12.89s/it] 64%|██████▍   | 8214/12825 [29:19:50<16:25:52, 12.83s/it] 64%|██████▍   | 8215/12825 [29:20:03<16:22:46, 12.79s/it] 64%|██████▍   | 8216/12825 [29:20:15<16:20:27, 12.76s/it] 64%|██████▍   | 8217/12825 [29:20:28<16:19:13, 12.75s/it] 64%|██████▍   | 8218/12825 [29:20:41<16:17:14, 12.73s/it] 64%|██████▍   | 8219/12825 [29:20:54<16:15:58, 12.71s/it] 64%|██████▍   | 8220/12825 [29:21:06<16:15:02, 12.70s/it] 64%|██████▍   | 8221/12825 [29:21:19<16:14:02, 12.69s/it] 64%|██████▍   | 8222/12825 [29:21:32<16:13:27, 12.69s/it] 64%|██████▍   | 8223/12825 [29:21:44<16:12:52, 12.68s/it] 64%|██████▍   | 8224/12825 [29:21:57<16:11:42, 12.67s/it] 64%|██████▍   | 8225/12825 [29:22:18<19:34:33, 15.32s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120282.62lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103343.52lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8200] due to args.save_total_limit
 64%|██████▍   | 8226/12825 [29:22:31<18:41:05, 14.63s/it] 64%|██████▍   | 8227/12825 [29:22:44<17:54:39, 14.02s/it] 64%|██████▍   | 8228/12825 [29:22:57<17:22:34, 13.61s/it] 64%|██████▍   | 8229/12825 [29:23:09<17:00:37, 13.32s/it] 64%|██████▍   | 8230/12825 [29:23:22<16:44:34, 13.12s/it] 64%|██████▍   | 8231/12825 [29:23:35<16:33:50, 12.98s/it] 64%|██████▍   | 8232/12825 [29:23:47<16:26:29, 12.89s/it] 64%|██████▍   | 8233/12825 [29:24:00<16:21:58, 12.83s/it] 64%|██████▍   | 8234/12825 [29:24:13<16:17:28, 12.77s/it] 64%|██████▍   | 8235/12825 [29:24:25<16:13:57, 12.73s/it] 64%|██████▍   | 8236/12825 [29:24:38<16:12:21, 12.71s/it] 64%|██████▍   | 8237/12825 [29:24:51<16:11:20, 12.70s/it] 64%|██████▍   | 8238/12825 [29:25:03<16:09:05, 12.68s/it] 64%|██████▍   | 8239/12825 [29:25:16<16:08:05, 12.67s/it] 64%|██████▍   | 8240/12825 [29:25:28<16:07:17, 12.66s/it] 64%|██████▍   | 8241/12825 [29:25:41<16:07:46, 12.67s/it] 64%|██████▍   | 8242/12825 [29:25:54<16:07:05, 12.66s/it] 64%|██████▍   | 8243/12825 [29:26:06<16:05:36, 12.64s/it] 64%|██████▍   | 8244/12825 [29:26:19<16:05:32, 12.65s/it] 64%|██████▍   | 8245/12825 [29:26:32<16:05:51, 12.65s/it] 64%|██████▍   | 8246/12825 [29:26:44<16:05:45, 12.65s/it] 64%|██████▍   | 8247/12825 [29:26:57<16:06:20, 12.66s/it] 64%|██████▍   | 8248/12825 [29:27:10<16:05:41, 12.66s/it] 64%|██████▍   | 8249/12825 [29:27:22<16:06:21, 12.67s/it] 64%|██████▍   | 8250/12825 [29:27:35<16:07:15, 12.69s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120289.39lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103548.48lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8225] due to args.save_total_limit
 64%|██████▍   | 8251/12825 [29:27:48<16:13:36, 12.77s/it] 64%|██████▍   | 8252/12825 [29:28:01<16:10:22, 12.73s/it] 64%|██████▍   | 8253/12825 [29:28:13<16:08:16, 12.71s/it] 64%|██████▍   | 8254/12825 [29:28:26<16:07:38, 12.70s/it] 64%|██████▍   | 8255/12825 [29:28:39<16:05:48, 12.68s/it] 64%|██████▍   | 8256/12825 [29:28:51<16:04:44, 12.67s/it] 64%|██████▍   | 8257/12825 [29:29:13<19:20:03, 15.24s/it] 64%|██████▍   | 8258/12825 [29:29:25<18:20:52, 14.46s/it] 64%|██████▍   | 8259/12825 [29:29:38<17:39:27, 13.92s/it] 64%|██████▍   | 8260/12825 [29:29:51<17:12:15, 13.57s/it] 64%|██████▍   | 8261/12825 [29:30:03<16:50:56, 13.29s/it] 64%|██████▍   | 8262/12825 [29:30:16<16:35:25, 13.09s/it] 64%|██████▍   | 8263/12825 [29:30:29<16:27:05, 12.98s/it] 64%|██████▍   | 8264/12825 [29:30:41<16:18:49, 12.88s/it] 64%|██████▍   | 8265/12825 [29:30:54<16:17:21, 12.86s/it] 64%|██████▍   | 8266/12825 [29:31:07<16:15:45, 12.84s/it] 64%|██████▍   | 8267/12825 [29:31:20<16:11:53, 12.79s/it] 64%|██████▍   | 8268/12825 [29:31:32<16:09:04, 12.76s/it] 64%|██████▍   | 8269/12825 [29:31:45<16:06:38, 12.73s/it] 64%|██████▍   | 8270/12825 [29:31:58<16:06:07, 12.73s/it] 64%|██████▍   | 8271/12825 [29:32:10<16:04:14, 12.70s/it] 64%|██████▍   | 8272/12825 [29:32:23<16:03:31, 12.70s/it] 65%|██████▍   | 8273/12825 [29:32:36<16:03:18, 12.70s/it] 65%|██████▍   | 8274/12825 [29:32:48<16:02:25, 12.69s/it] 65%|██████▍   | 8275/12825 [29:33:01<16:00:45, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120224.78lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103509.30lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8250] due to args.save_total_limit
 65%|██████▍   | 8276/12825 [29:33:14<16:08:34, 12.78s/it] 65%|██████▍   | 8277/12825 [29:33:27<16:05:09, 12.73s/it] 65%|██████▍   | 8278/12825 [29:33:39<16:02:53, 12.71s/it] 65%|██████▍   | 8279/12825 [29:33:52<16:00:59, 12.68s/it] 65%|██████▍   | 8280/12825 [29:34:05<15:59:53, 12.67s/it] 65%|██████▍   | 8281/12825 [29:34:17<15:59:19, 12.67s/it] 65%|██████▍   | 8282/12825 [29:34:30<15:59:40, 12.67s/it] 65%|██████▍   | 8283/12825 [29:34:43<16:00:16, 12.69s/it] 65%|██████▍   | 8284/12825 [29:34:55<15:59:49, 12.68s/it] 65%|██████▍   | 8285/12825 [29:35:08<15:58:47, 12.67s/it] 65%|██████▍   | 8286/12825 [29:35:21<15:59:48, 12.69s/it] 65%|██████▍   | 8287/12825 [29:35:33<15:58:11, 12.67s/it] 65%|██████▍   | 8288/12825 [29:35:46<15:59:46, 12.69s/it] 65%|██████▍   | 8289/12825 [29:35:59<15:59:31, 12.69s/it] 65%|██████▍   | 8290/12825 [29:36:20<19:09:39, 15.21s/it] 65%|██████▍   | 8291/12825 [29:36:32<18:12:31, 14.46s/it] 65%|██████▍   | 8292/12825 [29:36:45<17:32:15, 13.93s/it] 65%|██████▍   | 8293/12825 [29:36:58<17:04:06, 13.56s/it] 65%|██████▍   | 8294/12825 [29:37:10<16:42:49, 13.28s/it] 65%|██████▍   | 8295/12825 [29:37:23<16:28:41, 13.10s/it] 65%|██████▍   | 8296/12825 [29:37:36<16:19:39, 12.98s/it] 65%|██████▍   | 8297/12825 [29:37:49<16:12:42, 12.89s/it] 65%|██████▍   | 8298/12825 [29:38:01<16:07:18, 12.82s/it] 65%|██████▍   | 8299/12825 [29:38:14<16:04:24, 12.79s/it] 65%|██████▍   | 8300/12825 [29:38:27<16:05:10, 12.80s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 117120.56lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101194.82lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8275] due to args.save_total_limit
 65%|██████▍   | 8301/12825 [29:38:40<16:10:28, 12.87s/it] 65%|██████▍   | 8302/12825 [29:38:52<16:06:35, 12.82s/it] 65%|██████▍   | 8303/12825 [29:39:05<16:02:49, 12.78s/it] 65%|██████▍   | 8304/12825 [29:39:18<16:00:22, 12.75s/it] 65%|██████▍   | 8305/12825 [29:39:31<15:58:53, 12.73s/it] 65%|██████▍   | 8306/12825 [29:39:43<16:00:30, 12.75s/it] 65%|██████▍   | 8307/12825 [29:39:56<15:58:45, 12.73s/it] 65%|██████▍   | 8308/12825 [29:40:09<15:58:23, 12.73s/it] 65%|██████▍   | 8309/12825 [29:40:21<15:57:13, 12.72s/it] 65%|██████▍   | 8310/12825 [29:40:34<15:55:38, 12.70s/it] 65%|██████▍   | 8311/12825 [29:40:47<15:55:06, 12.70s/it] 65%|██████▍   | 8312/12825 [29:40:59<15:54:21, 12.69s/it] 65%|██████▍   | 8313/12825 [29:41:12<15:53:30, 12.68s/it] 65%|██████▍   | 8314/12825 [29:41:25<15:53:16, 12.68s/it] 65%|██████▍   | 8315/12825 [29:41:37<15:53:49, 12.69s/it] 65%|██████▍   | 8316/12825 [29:41:50<15:54:05, 12.70s/it] 65%|██████▍   | 8317/12825 [29:42:03<15:53:01, 12.68s/it] 65%|██████▍   | 8318/12825 [29:42:16<15:53:02, 12.69s/it] 65%|██████▍   | 8319/12825 [29:42:28<15:55:57, 12.73s/it] 65%|██████▍   | 8320/12825 [29:42:41<15:54:19, 12.71s/it] 65%|██████▍   | 8321/12825 [29:42:54<15:53:41, 12.70s/it] 65%|██████▍   | 8322/12825 [29:43:15<19:01:05, 15.20s/it] 65%|██████▍   | 8323/12825 [29:43:27<18:03:43, 14.44s/it] 65%|██████▍   | 8324/12825 [29:43:40<17:23:47, 13.91s/it] 65%|██████▍   | 8325/12825 [29:43:53<16:55:16, 13.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120323.64lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103570.45lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8300] due to args.save_total_limit
 65%|██████▍   | 8326/12825 [29:44:06<16:42:20, 13.37s/it] 65%|██████▍   | 8327/12825 [29:44:18<16:26:25, 13.16s/it] 65%|██████▍   | 8328/12825 [29:44:31<16:17:09, 13.04s/it] 65%|██████▍   | 8329/12825 [29:44:44<16:08:03, 12.92s/it] 65%|██████▍   | 8330/12825 [29:44:56<16:02:04, 12.84s/it] 65%|██████▍   | 8331/12825 [29:45:09<15:56:44, 12.77s/it] 65%|██████▍   | 8332/12825 [29:45:22<15:53:40, 12.74s/it] 65%|██████▍   | 8333/12825 [29:45:34<15:52:00, 12.72s/it] 65%|██████▍   | 8334/12825 [29:45:47<15:50:13, 12.70s/it] 65%|██████▍   | 8335/12825 [29:46:00<15:49:03, 12.68s/it] 65%|██████▍   | 8336/12825 [29:46:12<15:46:52, 12.66s/it] 65%|██████▌   | 8337/12825 [29:46:25<15:46:47, 12.66s/it] 65%|██████▌   | 8338/12825 [29:46:38<15:46:37, 12.66s/it] 65%|██████▌   | 8339/12825 [29:46:50<15:45:15, 12.64s/it] 65%|██████▌   | 8340/12825 [29:47:03<15:46:17, 12.66s/it] 65%|██████▌   | 8341/12825 [29:47:16<15:46:02, 12.66s/it] 65%|██████▌   | 8342/12825 [29:47:28<15:47:12, 12.68s/it] 65%|██████▌   | 8343/12825 [29:47:41<15:46:33, 12.67s/it] 65%|██████▌   | 8344/12825 [29:47:54<15:46:06, 12.67s/it] 65%|██████▌   | 8345/12825 [29:48:06<15:47:17, 12.69s/it] 65%|██████▌   | 8346/12825 [29:48:19<15:49:11, 12.72s/it] 65%|██████▌   | 8347/12825 [29:48:32<15:47:19, 12.69s/it] 65%|██████▌   | 8348/12825 [29:48:44<15:46:00, 12.68s/it] 65%|██████▌   | 8349/12825 [29:48:57<15:46:02, 12.68s/it] 65%|██████▌   | 8350/12825 [29:49:10<15:45:08, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120198.74lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103572.44lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8325] due to args.save_total_limit
 65%|██████▌   | 8351/12825 [29:49:23<15:51:14, 12.76s/it] 65%|██████▌   | 8352/12825 [29:49:36<15:51:43, 12.77s/it] 65%|██████▌   | 8353/12825 [29:49:48<15:49:22, 12.74s/it] 65%|██████▌   | 8354/12825 [29:50:09<18:48:23, 15.14s/it] 65%|██████▌   | 8355/12825 [29:50:22<17:55:33, 14.44s/it] 65%|██████▌   | 8356/12825 [29:50:34<17:14:47, 13.89s/it] 65%|██████▌   | 8357/12825 [29:50:47<16:46:44, 13.52s/it] 65%|██████▌   | 8358/12825 [29:51:00<16:26:44, 13.25s/it] 65%|██████▌   | 8359/12825 [29:51:12<16:14:31, 13.09s/it] 65%|██████▌   | 8360/12825 [29:51:25<16:06:35, 12.99s/it] 65%|██████▌   | 8361/12825 [29:51:38<15:58:20, 12.88s/it] 65%|██████▌   | 8362/12825 [29:51:50<15:55:35, 12.85s/it] 65%|██████▌   | 8363/12825 [29:52:03<15:52:30, 12.81s/it] 65%|██████▌   | 8364/12825 [29:52:16<15:49:04, 12.76s/it] 65%|██████▌   | 8365/12825 [29:52:29<15:49:06, 12.77s/it] 65%|██████▌   | 8366/12825 [29:52:41<15:49:32, 12.78s/it] 65%|██████▌   | 8367/12825 [29:52:54<15:48:41, 12.77s/it] 65%|██████▌   | 8368/12825 [29:53:07<15:45:44, 12.73s/it] 65%|██████▌   | 8369/12825 [29:53:20<15:45:20, 12.73s/it] 65%|██████▌   | 8370/12825 [29:53:32<15:44:42, 12.72s/it] 65%|██████▌   | 8371/12825 [29:53:45<15:42:56, 12.70s/it] 65%|██████▌   | 8372/12825 [29:53:58<15:42:26, 12.70s/it] 65%|██████▌   | 8373/12825 [29:54:10<15:43:45, 12.72s/it] 65%|██████▌   | 8374/12825 [29:54:23<15:42:07, 12.70s/it] 65%|██████▌   | 8375/12825 [29:54:36<15:43:42, 12.72s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120262.57lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103539.67lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8350] due to args.save_total_limit
 65%|██████▌   | 8376/12825 [29:54:49<15:50:30, 12.82s/it] 65%|██████▌   | 8377/12825 [29:55:02<15:48:55, 12.80s/it] 65%|██████▌   | 8378/12825 [29:55:14<15:49:16, 12.81s/it] 65%|██████▌   | 8379/12825 [29:55:27<15:48:30, 12.80s/it] 65%|██████▌   | 8380/12825 [29:55:40<15:48:35, 12.80s/it] 65%|██████▌   | 8381/12825 [29:55:53<15:48:17, 12.80s/it] 65%|██████▌   | 8382/12825 [29:56:06<15:48:26, 12.81s/it] 65%|██████▌   | 8383/12825 [29:56:18<15:48:39, 12.81s/it] 65%|██████▌   | 8384/12825 [29:56:31<15:48:35, 12.82s/it] 65%|██████▌   | 8385/12825 [29:56:44<15:47:47, 12.81s/it] 65%|██████▌   | 8386/12825 [29:57:05<18:43:56, 15.19s/it] 65%|██████▌   | 8387/12825 [29:57:18<17:48:54, 14.45s/it] 65%|██████▌   | 8388/12825 [29:57:30<17:11:29, 13.95s/it] 65%|██████▌   | 8389/12825 [29:57:43<16:43:16, 13.57s/it] 65%|██████▌   | 8390/12825 [29:57:56<16:22:52, 13.30s/it] 65%|██████▌   | 8391/12825 [29:58:08<16:09:16, 13.12s/it] 65%|██████▌   | 8392/12825 [29:58:21<15:59:14, 12.98s/it] 65%|██████▌   | 8393/12825 [29:58:34<15:53:57, 12.91s/it] 65%|██████▌   | 8394/12825 [29:58:47<15:50:26, 12.87s/it] 65%|██████▌   | 8395/12825 [29:58:59<15:45:30, 12.81s/it] 65%|██████▌   | 8396/12825 [29:59:12<15:42:04, 12.76s/it] 65%|██████▌   | 8397/12825 [29:59:25<15:42:49, 12.78s/it] 65%|██████▌   | 8398/12825 [29:59:37<15:40:36, 12.75s/it] 65%|██████▌   | 8399/12825 [29:59:50<15:38:30, 12.72s/it] 65%|██████▌   | 8400/12825 [30:00:03<15:39:36, 12.74s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120329.91lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103543.65lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8375] due to args.save_total_limit
 66%|██████▌   | 8401/12825 [30:00:16<15:44:29, 12.81s/it] 66%|██████▌   | 8402/12825 [30:00:29<15:42:50, 12.79s/it] 66%|██████▌   | 8403/12825 [30:00:41<15:40:04, 12.76s/it] 66%|██████▌   | 8404/12825 [30:00:54<15:37:26, 12.72s/it] 66%|██████▌   | 8405/12825 [30:01:07<15:39:17, 12.75s/it] 66%|██████▌   | 8406/12825 [30:01:19<15:37:45, 12.73s/it] 66%|██████▌   | 8407/12825 [30:01:32<15:38:19, 12.74s/it] 66%|██████▌   | 8408/12825 [30:01:45<15:38:31, 12.75s/it] 66%|██████▌   | 8409/12825 [30:01:58<15:38:26, 12.75s/it] 66%|██████▌   | 8410/12825 [30:02:10<15:35:30, 12.71s/it] 66%|██████▌   | 8411/12825 [30:02:23<15:35:13, 12.71s/it] 66%|██████▌   | 8412/12825 [30:02:36<15:36:34, 12.73s/it] 66%|██████▌   | 8413/12825 [30:02:49<15:36:34, 12.74s/it] 66%|██████▌   | 8414/12825 [30:03:01<15:35:43, 12.73s/it] 66%|██████▌   | 8415/12825 [30:03:14<15:42:04, 12.82s/it] 66%|██████▌   | 8416/12825 [30:03:27<15:38:10, 12.77s/it] 66%|██████▌   | 8417/12825 [30:03:40<15:35:57, 12.74s/it] 66%|██████▌   | 8418/12825 [30:03:52<15:32:59, 12.70s/it] 66%|██████▌   | 8419/12825 [30:04:14<18:57:20, 15.49s/it] 66%|██████▌   | 8420/12825 [30:04:27<17:54:09, 14.63s/it] 66%|██████▌   | 8421/12825 [30:04:39<17:09:50, 14.03s/it] 66%|██████▌   | 8422/12825 [30:04:52<16:39:55, 13.63s/it] 66%|██████▌   | 8423/12825 [30:05:05<16:17:31, 13.32s/it] 66%|██████▌   | 8424/12825 [30:05:17<16:01:42, 13.11s/it] 66%|██████▌   | 8425/12825 [30:05:30<15:51:45, 12.98s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120285.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103522.45lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8400] due to args.save_total_limit
 66%|██████▌   | 8426/12825 [30:05:43<15:53:31, 13.01s/it] 66%|██████▌   | 8427/12825 [30:05:56<15:46:40, 12.91s/it] 66%|██████▌   | 8428/12825 [30:06:08<15:39:36, 12.82s/it] 66%|██████▌   | 8429/12825 [30:06:21<15:34:17, 12.75s/it] 66%|██████▌   | 8430/12825 [30:06:34<15:29:19, 12.69s/it] 66%|██████▌   | 8431/12825 [30:06:46<15:27:42, 12.67s/it] 66%|██████▌   | 8432/12825 [30:06:59<15:24:40, 12.63s/it] 66%|██████▌   | 8433/12825 [30:07:11<15:22:55, 12.61s/it] 66%|██████▌   | 8434/12825 [30:07:24<15:21:01, 12.59s/it] 66%|██████▌   | 8435/12825 [30:07:36<15:19:22, 12.57s/it] 66%|██████▌   | 8436/12825 [30:07:49<15:18:54, 12.56s/it] 66%|██████▌   | 8437/12825 [30:08:01<15:17:53, 12.55s/it] 66%|██████▌   | 8438/12825 [30:08:14<15:16:28, 12.53s/it] 66%|██████▌   | 8439/12825 [30:08:26<15:16:18, 12.53s/it] 66%|██████▌   | 8440/12825 [30:08:39<15:15:00, 12.52s/it] 66%|██████▌   | 8441/12825 [30:08:51<15:14:27, 12.52s/it] 66%|██████▌   | 8442/12825 [30:09:04<15:15:10, 12.53s/it] 66%|██████▌   | 8443/12825 [30:09:17<15:16:49, 12.55s/it] 66%|██████▌   | 8444/12825 [30:09:29<15:16:04, 12.55s/it] 66%|██████▌   | 8445/12825 [30:09:42<15:15:54, 12.55s/it] 66%|██████▌   | 8446/12825 [30:09:54<15:15:25, 12.54s/it] 66%|██████▌   | 8447/12825 [30:10:07<15:15:12, 12.54s/it] 66%|██████▌   | 8448/12825 [30:10:19<15:14:57, 12.54s/it] 66%|██████▌   | 8449/12825 [30:10:32<15:15:44, 12.56s/it] 66%|██████▌   | 8450/12825 [30:10:44<15:15:29, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120282.49lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103537.50lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8425] due to args.save_total_limit
 66%|██████▌   | 8451/12825 [30:11:05<18:21:23, 15.11s/it] 66%|██████▌   | 8452/12825 [30:11:18<17:24:37, 14.33s/it] 66%|██████▌   | 8453/12825 [30:11:31<16:45:13, 13.80s/it] 66%|██████▌   | 8454/12825 [30:11:43<16:20:38, 13.46s/it] 66%|██████▌   | 8455/12825 [30:11:56<16:00:37, 13.19s/it] 66%|██████▌   | 8456/12825 [30:12:08<15:47:17, 13.01s/it] 66%|██████▌   | 8457/12825 [30:12:21<15:39:42, 12.91s/it] 66%|██████▌   | 8458/12825 [30:12:34<15:33:56, 12.83s/it] 66%|██████▌   | 8459/12825 [30:12:46<15:29:51, 12.78s/it] 66%|██████▌   | 8460/12825 [30:12:59<15:27:04, 12.74s/it] 66%|██████▌   | 8461/12825 [30:13:12<15:24:40, 12.71s/it] 66%|██████▌   | 8462/12825 [30:13:24<15:23:35, 12.70s/it] 66%|██████▌   | 8463/12825 [30:13:37<15:21:52, 12.68s/it] 66%|██████▌   | 8464/12825 [30:13:50<15:22:17, 12.69s/it] 66%|██████▌   | 8465/12825 [30:14:02<15:21:43, 12.68s/it] 66%|██████▌   | 8466/12825 [30:14:15<15:20:14, 12.67s/it] 66%|██████▌   | 8467/12825 [30:14:28<15:19:20, 12.66s/it] 66%|██████▌   | 8468/12825 [30:14:40<15:18:35, 12.65s/it] 66%|██████▌   | 8469/12825 [30:14:53<15:17:47, 12.64s/it] 66%|██████▌   | 8470/12825 [30:15:06<15:17:30, 12.64s/it] 66%|██████▌   | 8471/12825 [30:15:18<15:17:15, 12.64s/it] 66%|██████▌   | 8472/12825 [30:15:31<15:16:33, 12.63s/it] 66%|██████▌   | 8473/12825 [30:15:43<15:17:26, 12.65s/it] 66%|██████▌   | 8474/12825 [30:15:56<15:17:14, 12.65s/it] 66%|██████▌   | 8475/12825 [30:16:09<15:18:01, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120264.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103297.52lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8450] due to args.save_total_limit
 66%|██████▌   | 8476/12825 [30:16:22<15:24:43, 12.76s/it] 66%|██████▌   | 8477/12825 [30:16:34<15:22:37, 12.73s/it] 66%|██████▌   | 8478/12825 [30:16:47<15:19:42, 12.69s/it] 66%|██████▌   | 8479/12825 [30:17:00<15:17:43, 12.67s/it] 66%|██████▌   | 8480/12825 [30:17:12<15:17:13, 12.67s/it] 66%|██████▌   | 8481/12825 [30:17:25<15:16:29, 12.66s/it] 66%|██████▌   | 8482/12825 [30:17:38<15:15:59, 12.65s/it] 66%|██████▌   | 8483/12825 [30:17:50<15:14:38, 12.64s/it] 66%|██████▌   | 8484/12825 [30:18:11<18:18:13, 15.18s/it] 66%|██████▌   | 8485/12825 [30:18:24<17:22:47, 14.42s/it] 66%|██████▌   | 8486/12825 [30:18:37<16:44:07, 13.89s/it] 66%|██████▌   | 8487/12825 [30:18:49<16:17:27, 13.52s/it] 66%|██████▌   | 8488/12825 [30:19:02<15:58:13, 13.26s/it] 66%|██████▌   | 8489/12825 [30:19:15<15:45:19, 13.08s/it] 66%|██████▌   | 8490/12825 [30:19:27<15:35:43, 12.95s/it] 66%|██████▌   | 8491/12825 [30:19:40<15:29:01, 12.86s/it] 66%|██████▌   | 8492/12825 [30:19:53<15:24:06, 12.80s/it] 66%|██████▌   | 8493/12825 [30:20:05<15:22:01, 12.77s/it] 66%|██████▌   | 8494/12825 [30:20:18<15:19:39, 12.74s/it] 66%|██████▌   | 8495/12825 [30:20:31<15:18:11, 12.72s/it] 66%|██████▌   | 8496/12825 [30:20:43<15:16:27, 12.70s/it] 66%|██████▋   | 8497/12825 [30:20:56<15:14:46, 12.68s/it] 66%|██████▋   | 8498/12825 [30:21:09<15:13:42, 12.67s/it] 66%|██████▋   | 8499/12825 [30:21:21<15:13:31, 12.67s/it] 66%|██████▋   | 8500/12825 [30:21:34<15:13:05, 12.67s/it]                                                           66%|██████▋   | 8500/12825 [30:21:34<15:13:05, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120222.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103469.01lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8475] due to args.save_total_limit
 66%|██████▋   | 8501/12825 [30:21:47<15:19:42, 12.76s/it] 66%|██████▋   | 8502/12825 [30:21:59<15:17:05, 12.73s/it] 66%|██████▋   | 8503/12825 [30:22:12<15:13:00, 12.67s/it] 66%|██████▋   | 8504/12825 [30:22:25<15:10:15, 12.64s/it] 66%|██████▋   | 8505/12825 [30:22:37<15:07:47, 12.61s/it] 66%|██████▋   | 8506/12825 [30:22:50<15:06:47, 12.60s/it] 66%|██████▋   | 8507/12825 [30:23:02<15:04:53, 12.57s/it] 66%|██████▋   | 8508/12825 [30:23:15<15:03:55, 12.56s/it] 66%|██████▋   | 8509/12825 [30:23:27<15:02:51, 12.55s/it] 66%|██████▋   | 8510/12825 [30:23:40<15:02:33, 12.55s/it] 66%|██████▋   | 8511/12825 [30:23:52<15:01:58, 12.54s/it] 66%|██████▋   | 8512/12825 [30:24:05<15:01:31, 12.54s/it] 66%|██████▋   | 8513/12825 [30:24:17<15:01:24, 12.54s/it] 66%|██████▋   | 8514/12825 [30:24:30<15:01:24, 12.55s/it] 66%|██████▋   | 8515/12825 [30:24:42<15:00:29, 12.54s/it] 66%|██████▋   | 8516/12825 [30:25:03<17:47:24, 14.86s/it] 66%|██████▋   | 8517/12825 [30:25:15<16:57:37, 14.17s/it] 66%|██████▋   | 8518/12825 [30:25:28<16:22:23, 13.69s/it] 66%|██████▋   | 8519/12825 [30:25:40<15:57:26, 13.34s/it] 66%|██████▋   | 8520/12825 [30:25:53<15:40:37, 13.11s/it] 66%|██████▋   | 8521/12825 [30:26:06<15:28:05, 12.94s/it] 66%|██████▋   | 8522/12825 [30:26:18<15:19:36, 12.82s/it] 66%|██████▋   | 8523/12825 [30:26:31<15:13:17, 12.74s/it] 66%|██████▋   | 8524/12825 [30:26:43<15:08:48, 12.68s/it] 66%|██████▋   | 8525/12825 [30:26:56<15:05:10, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120149.01lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103411.66lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8500] due to args.save_total_limit
 66%|██████▋   | 8526/12825 [30:27:09<15:09:49, 12.70s/it] 66%|██████▋   | 8527/12825 [30:27:21<15:06:10, 12.65s/it] 66%|██████▋   | 8528/12825 [30:27:34<15:02:40, 12.60s/it] 67%|██████▋   | 8529/12825 [30:27:46<15:00:53, 12.58s/it] 67%|██████▋   | 8530/12825 [30:27:59<14:59:22, 12.56s/it] 67%|██████▋   | 8531/12825 [30:28:11<14:58:22, 12.55s/it] 67%|██████▋   | 8532/12825 [30:28:24<14:57:33, 12.54s/it] 67%|██████▋   | 8533/12825 [30:28:36<14:56:30, 12.53s/it] 67%|██████▋   | 8534/12825 [30:28:49<14:56:25, 12.53s/it] 67%|██████▋   | 8535/12825 [30:29:01<14:56:31, 12.54s/it] 67%|██████▋   | 8536/12825 [30:29:14<14:56:01, 12.53s/it] 67%|██████▋   | 8537/12825 [30:29:26<14:55:10, 12.53s/it] 67%|██████▋   | 8538/12825 [30:29:39<14:55:30, 12.53s/it] 67%|██████▋   | 8539/12825 [30:29:51<14:56:17, 12.55s/it] 67%|██████▋   | 8540/12825 [30:30:04<14:56:00, 12.55s/it] 67%|██████▋   | 8541/12825 [30:30:17<14:55:40, 12.54s/it] 67%|██████▋   | 8542/12825 [30:30:29<14:55:01, 12.54s/it] 67%|██████▋   | 8543/12825 [30:30:42<14:54:53, 12.54s/it] 67%|██████▋   | 8544/12825 [30:30:54<14:55:17, 12.55s/it] 67%|██████▋   | 8545/12825 [30:31:07<14:54:32, 12.54s/it] 67%|██████▋   | 8546/12825 [30:31:19<14:56:09, 12.57s/it] 67%|██████▋   | 8547/12825 [30:31:32<14:55:01, 12.55s/it] 67%|██████▋   | 8548/12825 [30:31:53<17:54:28, 15.07s/it] 67%|██████▋   | 8549/12825 [30:32:05<17:00:00, 14.31s/it] 67%|██████▋   | 8550/12825 [30:32:18<16:21:48, 13.78s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120264.61lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103522.35lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8525] due to args.save_total_limit
 67%|██████▋   | 8551/12825 [30:32:31<16:01:39, 13.50s/it] 67%|██████▋   | 8552/12825 [30:32:43<15:39:59, 13.20s/it] 67%|██████▋   | 8553/12825 [30:32:56<15:25:24, 13.00s/it] 67%|██████▋   | 8554/12825 [30:33:08<15:15:35, 12.86s/it] 67%|██████▋   | 8555/12825 [30:33:21<15:07:38, 12.75s/it] 67%|██████▋   | 8556/12825 [30:33:33<15:02:32, 12.68s/it] 67%|██████▋   | 8557/12825 [30:33:46<14:59:18, 12.64s/it] 67%|██████▋   | 8558/12825 [30:33:58<14:56:45, 12.61s/it] 67%|██████▋   | 8559/12825 [30:34:11<14:54:31, 12.58s/it] 67%|██████▋   | 8560/12825 [30:34:23<14:53:37, 12.57s/it] 67%|██████▋   | 8561/12825 [30:34:36<14:52:05, 12.55s/it] 67%|██████▋   | 8562/12825 [30:34:48<14:51:37, 12.55s/it] 67%|██████▋   | 8563/12825 [30:35:01<14:51:05, 12.54s/it] 67%|██████▋   | 8564/12825 [30:35:14<14:50:25, 12.54s/it] 67%|██████▋   | 8565/12825 [30:35:26<14:49:20, 12.53s/it] 67%|██████▋   | 8566/12825 [30:35:39<14:49:12, 12.53s/it] 67%|██████▋   | 8567/12825 [30:35:51<14:49:00, 12.53s/it] 67%|██████▋   | 8568/12825 [30:36:04<14:49:16, 12.53s/it] 67%|██████▋   | 8569/12825 [30:36:16<14:49:14, 12.54s/it] 67%|██████▋   | 8570/12825 [30:36:29<14:49:03, 12.54s/it] 67%|██████▋   | 8571/12825 [30:36:41<14:48:58, 12.54s/it] 67%|██████▋   | 8572/12825 [30:36:54<14:48:14, 12.53s/it] 67%|██████▋   | 8573/12825 [30:37:06<14:48:01, 12.53s/it] 67%|██████▋   | 8574/12825 [30:37:19<14:47:53, 12.53s/it] 67%|██████▋   | 8575/12825 [30:37:31<14:46:48, 12.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120306.26lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103589.97lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8550] due to args.save_total_limit
 67%|██████▋   | 8576/12825 [30:37:44<14:52:54, 12.61s/it] 67%|██████▋   | 8577/12825 [30:37:57<14:50:35, 12.58s/it] 67%|██████▋   | 8578/12825 [30:38:09<14:49:24, 12.57s/it] 67%|██████▋   | 8579/12825 [30:38:22<14:48:45, 12.56s/it] 67%|██████▋   | 8580/12825 [30:38:34<14:47:22, 12.54s/it] 67%|██████▋   | 8581/12825 [30:38:54<17:28:43, 14.83s/it] 67%|██████▋   | 8582/12825 [30:39:07<16:40:00, 14.14s/it] 67%|██████▋   | 8583/12825 [30:39:19<16:05:10, 13.65s/it] 67%|██████▋   | 8584/12825 [30:39:32<15:40:11, 13.30s/it] 67%|██████▋   | 8585/12825 [30:39:44<15:24:04, 13.08s/it] 67%|██████▋   | 8586/12825 [30:39:57<15:12:06, 12.91s/it] 67%|██████▋   | 8587/12825 [30:40:10<15:05:22, 12.82s/it] 67%|██████▋   | 8588/12825 [30:40:22<14:59:22, 12.74s/it] 67%|██████▋   | 8589/12825 [30:40:35<14:54:58, 12.68s/it] 67%|██████▋   | 8590/12825 [30:40:47<14:51:23, 12.63s/it] 67%|██████▋   | 8591/12825 [30:41:00<14:49:31, 12.61s/it] 67%|██████▋   | 8592/12825 [30:41:12<14:48:06, 12.59s/it] 67%|██████▋   | 8593/12825 [30:41:25<14:46:40, 12.57s/it] 67%|██████▋   | 8594/12825 [30:41:37<14:46:50, 12.58s/it] 67%|██████▋   | 8595/12825 [30:41:50<14:45:26, 12.56s/it] 67%|██████▋   | 8596/12825 [30:42:02<14:44:13, 12.55s/it] 67%|██████▋   | 8597/12825 [30:42:15<14:44:12, 12.55s/it] 67%|██████▋   | 8598/12825 [30:42:28<14:43:21, 12.54s/it] 67%|██████▋   | 8599/12825 [30:42:40<14:42:50, 12.53s/it] 67%|██████▋   | 8600/12825 [30:42:53<14:42:38, 12.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120205.00lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103503.81lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8575] due to args.save_total_limit
 67%|██████▋   | 8601/12825 [30:43:05<14:49:44, 12.64s/it] 67%|██████▋   | 8602/12825 [30:43:18<14:47:32, 12.61s/it] 67%|██████▋   | 8603/12825 [30:43:31<14:45:15, 12.58s/it] 67%|██████▋   | 8604/12825 [30:43:43<14:43:53, 12.56s/it] 67%|██████▋   | 8605/12825 [30:43:56<14:43:18, 12.56s/it] 67%|██████▋   | 8606/12825 [30:44:08<14:42:37, 12.55s/it] 67%|██████▋   | 8607/12825 [30:44:21<14:42:12, 12.55s/it] 67%|██████▋   | 8608/12825 [30:44:33<14:41:31, 12.54s/it] 67%|██████▋   | 8609/12825 [30:44:46<14:41:02, 12.54s/it] 67%|██████▋   | 8610/12825 [30:44:58<14:40:54, 12.54s/it] 67%|██████▋   | 8611/12825 [30:45:11<14:40:56, 12.54s/it] 67%|██████▋   | 8612/12825 [30:45:23<14:40:08, 12.53s/it] 67%|██████▋   | 8613/12825 [30:45:44<17:20:16, 14.82s/it] 67%|██████▋   | 8614/12825 [30:45:56<16:32:03, 14.14s/it] 67%|██████▋   | 8615/12825 [30:46:09<15:57:09, 13.64s/it] 67%|██████▋   | 8616/12825 [30:46:21<15:32:59, 13.30s/it] 67%|██████▋   | 8617/12825 [30:46:34<15:16:26, 13.07s/it] 67%|██████▋   | 8618/12825 [30:46:46<15:04:27, 12.90s/it] 67%|██████▋   | 8619/12825 [30:46:59<14:56:25, 12.79s/it] 67%|██████▋   | 8620/12825 [30:47:11<14:50:48, 12.71s/it] 67%|██████▋   | 8621/12825 [30:47:24<14:47:06, 12.66s/it] 67%|██████▋   | 8622/12825 [30:47:36<14:44:13, 12.62s/it] 67%|██████▋   | 8623/12825 [30:47:49<14:42:33, 12.60s/it] 67%|██████▋   | 8624/12825 [30:48:01<14:41:18, 12.59s/it] 67%|██████▋   | 8625/12825 [30:48:14<14:39:55, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120193.64lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103486.78lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8600] due to args.save_total_limit
 67%|██████▋   | 8626/12825 [30:48:27<14:46:10, 12.66s/it] 67%|██████▋   | 8627/12825 [30:48:39<14:43:06, 12.62s/it] 67%|██████▋   | 8628/12825 [30:48:52<14:40:35, 12.59s/it] 67%|██████▋   | 8629/12825 [30:49:04<14:38:18, 12.56s/it] 67%|██████▋   | 8630/12825 [30:49:17<14:37:37, 12.55s/it] 67%|██████▋   | 8631/12825 [30:49:29<14:36:29, 12.54s/it] 67%|██████▋   | 8632/12825 [30:49:42<14:35:59, 12.54s/it] 67%|██████▋   | 8633/12825 [30:49:54<14:36:08, 12.54s/it] 67%|██████▋   | 8634/12825 [30:50:07<14:34:50, 12.52s/it] 67%|██████▋   | 8635/12825 [30:50:19<14:34:48, 12.53s/it] 67%|██████▋   | 8636/12825 [30:50:32<14:34:20, 12.52s/it] 67%|██████▋   | 8637/12825 [30:50:44<14:33:10, 12.51s/it] 67%|██████▋   | 8638/12825 [30:50:57<14:32:39, 12.51s/it] 67%|██████▋   | 8639/12825 [30:51:09<14:32:48, 12.51s/it] 67%|██████▋   | 8640/12825 [30:51:22<14:32:42, 12.51s/it] 67%|██████▋   | 8641/12825 [30:51:34<14:32:19, 12.51s/it] 67%|██████▋   | 8642/12825 [30:51:47<14:32:20, 12.51s/it] 67%|██████▋   | 8643/12825 [30:52:00<14:33:31, 12.53s/it] 67%|██████▋   | 8644/12825 [30:52:12<14:33:48, 12.54s/it] 67%|██████▋   | 8645/12825 [30:52:32<17:11:18, 14.80s/it] 67%|██████▋   | 8646/12825 [30:52:45<16:23:32, 14.12s/it] 67%|██████▋   | 8647/12825 [30:52:57<15:50:36, 13.65s/it] 67%|██████▋   | 8648/12825 [30:53:10<15:26:58, 13.32s/it] 67%|██████▋   | 8649/12825 [30:53:22<15:10:36, 13.08s/it] 67%|██████▋   | 8650/12825 [30:53:35<14:59:12, 12.92s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120309.07lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103541.28lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8625] due to args.save_total_limit
 67%|██████▋   | 8651/12825 [30:53:48<14:57:34, 12.90s/it] 67%|██████▋   | 8652/12825 [30:54:00<14:54:22, 12.86s/it] 67%|██████▋   | 8653/12825 [30:54:13<14:47:17, 12.76s/it] 67%|██████▋   | 8654/12825 [30:54:26<14:41:30, 12.68s/it] 67%|██████▋   | 8655/12825 [30:54:38<14:38:47, 12.64s/it] 67%|██████▋   | 8656/12825 [30:54:51<14:35:33, 12.60s/it] 68%|██████▊   | 8657/12825 [30:55:03<14:34:10, 12.58s/it] 68%|██████▊   | 8658/12825 [30:55:16<14:32:36, 12.56s/it] 68%|██████▊   | 8659/12825 [30:55:28<14:32:47, 12.57s/it] 68%|██████▊   | 8660/12825 [30:55:41<14:31:29, 12.55s/it] 68%|██████▊   | 8661/12825 [30:55:53<14:30:03, 12.54s/it] 68%|██████▊   | 8662/12825 [30:56:06<14:29:19, 12.53s/it] 68%|██████▊   | 8663/12825 [30:56:18<14:29:06, 12.53s/it] 68%|██████▊   | 8664/12825 [30:56:31<14:28:23, 12.52s/it] 68%|██████▊   | 8665/12825 [30:56:43<14:28:45, 12.53s/it] 68%|██████▊   | 8666/12825 [30:56:56<14:27:52, 12.52s/it] 68%|██████▊   | 8667/12825 [30:57:08<14:28:36, 12.53s/it] 68%|██████▊   | 8668/12825 [30:57:21<14:28:45, 12.54s/it] 68%|██████▊   | 8669/12825 [30:57:33<14:28:56, 12.54s/it] 68%|██████▊   | 8670/12825 [30:57:46<14:28:42, 12.54s/it] 68%|██████▊   | 8671/12825 [30:57:59<14:28:01, 12.54s/it] 68%|██████▊   | 8672/12825 [30:58:11<14:27:42, 12.54s/it] 68%|██████▊   | 8673/12825 [30:58:24<14:27:04, 12.53s/it] 68%|██████▊   | 8674/12825 [30:58:36<14:26:25, 12.52s/it] 68%|██████▊   | 8675/12825 [30:58:49<14:25:52, 12.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120295.53lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103571.59lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8650] due to args.save_total_limit
 68%|██████▊   | 8676/12825 [30:59:01<14:32:55, 12.62s/it] 68%|██████▊   | 8677/12825 [30:59:14<14:29:57, 12.58s/it] 68%|██████▊   | 8678/12825 [30:59:34<17:06:42, 14.85s/it] 68%|██████▊   | 8679/12825 [30:59:47<16:18:42, 14.16s/it] 68%|██████▊   | 8680/12825 [30:59:59<15:43:54, 13.66s/it] 68%|██████▊   | 8681/12825 [31:00:12<15:20:37, 13.33s/it] 68%|██████▊   | 8682/12825 [31:00:24<15:04:26, 13.10s/it] 68%|██████▊   | 8683/12825 [31:00:37<14:52:16, 12.93s/it] 68%|██████▊   | 8684/12825 [31:00:49<14:44:12, 12.81s/it] 68%|██████▊   | 8685/12825 [31:01:02<14:38:21, 12.73s/it] 68%|██████▊   | 8686/12825 [31:01:14<14:33:21, 12.66s/it] 68%|██████▊   | 8687/12825 [31:01:27<14:31:30, 12.64s/it] 68%|██████▊   | 8688/12825 [31:01:40<14:29:06, 12.60s/it] 68%|██████▊   | 8689/12825 [31:01:52<14:27:14, 12.58s/it] 68%|██████▊   | 8690/12825 [31:02:05<14:26:07, 12.57s/it] 68%|██████▊   | 8691/12825 [31:02:17<14:24:49, 12.55s/it] 68%|██████▊   | 8692/12825 [31:02:30<14:23:55, 12.54s/it] 68%|██████▊   | 8693/12825 [31:02:42<14:23:05, 12.53s/it] 68%|██████▊   | 8694/12825 [31:02:55<14:22:55, 12.53s/it] 68%|██████▊   | 8695/12825 [31:03:07<14:25:29, 12.57s/it] 68%|██████▊   | 8696/12825 [31:03:20<14:24:07, 12.56s/it] 68%|██████▊   | 8697/12825 [31:03:32<14:24:08, 12.56s/it] 68%|██████▊   | 8698/12825 [31:03:45<14:23:18, 12.55s/it] 68%|██████▊   | 8699/12825 [31:03:57<14:22:37, 12.54s/it] 68%|██████▊   | 8700/12825 [31:04:10<14:22:36, 12.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120058.95lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103344.94lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8675] due to args.save_total_limit
 68%|██████▊   | 8701/12825 [31:04:23<14:29:25, 12.65s/it] 68%|██████▊   | 8702/12825 [31:04:35<14:27:10, 12.62s/it] 68%|██████▊   | 8703/12825 [31:04:48<14:26:24, 12.61s/it] 68%|██████▊   | 8704/12825 [31:05:01<14:25:12, 12.60s/it] 68%|██████▊   | 8705/12825 [31:05:13<14:24:00, 12.58s/it] 68%|██████▊   | 8706/12825 [31:05:26<14:22:58, 12.57s/it] 68%|██████▊   | 8707/12825 [31:05:38<14:22:20, 12.56s/it] 68%|██████▊   | 8708/12825 [31:05:51<14:21:44, 12.56s/it] 68%|██████▊   | 8709/12825 [31:06:03<14:21:54, 12.56s/it] 68%|██████▊   | 8710/12825 [31:06:25<17:22:40, 15.20s/it] 68%|██████▊   | 8711/12825 [31:06:37<16:30:39, 14.45s/it] 68%|██████▊   | 8712/12825 [31:06:50<15:52:47, 13.90s/it] 68%|██████▊   | 8713/12825 [31:07:03<15:24:29, 13.49s/it] 68%|██████▊   | 8714/12825 [31:07:15<15:04:25, 13.20s/it] 68%|██████▊   | 8715/12825 [31:07:28<14:54:29, 13.06s/it] 68%|██████▊   | 8716/12825 [31:07:40<14:43:15, 12.90s/it] 68%|██████▊   | 8717/12825 [31:07:53<14:36:08, 12.80s/it] 68%|██████▊   | 8718/12825 [31:08:05<14:30:37, 12.72s/it] 68%|██████▊   | 8719/12825 [31:08:18<14:27:01, 12.67s/it] 68%|██████▊   | 8720/12825 [31:08:26<12:48:05, 11.23s/it] 68%|██████▊   | 8721/12825 [31:08:27<9:14:25,  8.11s/it]  68%|██████▊   | 8722/12825 [31:08:52<15:09:01, 13.29s/it] 68%|██████▊   | 8723/12825 [31:09:05<14:55:07, 13.09s/it] 68%|██████▊   | 8724/12825 [31:09:17<14:44:13, 12.94s/it] 68%|██████▊   | 8725/12825 [31:09:30<14:36:46, 12.83s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120241.75lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103476.67lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8725
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8725/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8725/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8700] due to args.save_total_limit
 68%|██████▊   | 8726/12825 [31:09:43<14:38:15, 12.86s/it] 68%|██████▊   | 8727/12825 [31:09:55<14:32:46, 12.78s/it] 68%|██████▊   | 8728/12825 [31:10:08<14:27:56, 12.71s/it] 68%|██████▊   | 8729/12825 [31:10:21<14:25:22, 12.68s/it] 68%|██████▊   | 8730/12825 [31:10:33<14:22:44, 12.64s/it] 68%|██████▊   | 8731/12825 [31:10:46<14:20:28, 12.61s/it] 68%|██████▊   | 8732/12825 [31:10:58<14:19:42, 12.60s/it] 68%|██████▊   | 8733/12825 [31:11:11<14:17:42, 12.58s/it] 68%|██████▊   | 8734/12825 [31:11:23<14:18:05, 12.59s/it] 68%|██████▊   | 8735/12825 [31:11:36<14:17:07, 12.57s/it] 68%|██████▊   | 8736/12825 [31:11:48<14:16:20, 12.57s/it] 68%|██████▊   | 8737/12825 [31:12:01<14:16:32, 12.57s/it] 68%|██████▊   | 8738/12825 [31:12:14<14:15:41, 12.56s/it] 68%|██████▊   | 8739/12825 [31:12:26<14:15:21, 12.56s/it] 68%|██████▊   | 8740/12825 [31:12:39<14:15:04, 12.56s/it] 68%|██████▊   | 8741/12825 [31:12:51<14:16:50, 12.59s/it] 68%|██████▊   | 8742/12825 [31:13:04<14:17:50, 12.61s/it] 68%|██████▊   | 8743/12825 [31:13:24<16:46:10, 14.79s/it] 68%|██████▊   | 8744/12825 [31:13:37<16:03:04, 14.16s/it] 68%|██████▊   | 8745/12825 [31:13:49<15:32:34, 13.71s/it] 68%|██████▊   | 8746/12825 [31:14:02<15:10:34, 13.39s/it] 68%|██████▊   | 8747/12825 [31:14:15<14:56:30, 13.19s/it] 68%|██████▊   | 8748/12825 [31:14:27<14:45:11, 13.03s/it] 68%|██████▊   | 8749/12825 [31:14:40<14:37:44, 12.92s/it] 68%|██████▊   | 8750/12825 [31:14:53<14:32:07, 12.84s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120129.76lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103439.05lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8750
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8750/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8750/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8725] due to args.save_total_limit
 68%|██████▊   | 8751/12825 [31:15:06<14:35:05, 12.89s/it] 68%|██████▊   | 8752/12825 [31:15:18<14:30:34, 12.82s/it] 68%|██████▊   | 8753/12825 [31:15:31<14:27:08, 12.78s/it] 68%|██████▊   | 8754/12825 [31:15:44<14:24:40, 12.74s/it] 68%|██████▊   | 8755/12825 [31:15:56<14:23:15, 12.73s/it] 68%|██████▊   | 8756/12825 [31:16:09<14:22:26, 12.72s/it] 68%|██████▊   | 8757/12825 [31:16:22<14:21:15, 12.70s/it] 68%|██████▊   | 8758/12825 [31:16:34<14:20:04, 12.69s/it] 68%|██████▊   | 8759/12825 [31:16:47<14:19:26, 12.68s/it] 68%|██████▊   | 8760/12825 [31:17:00<14:18:24, 12.67s/it] 68%|██████▊   | 8761/12825 [31:17:12<14:17:36, 12.66s/it] 68%|██████▊   | 8762/12825 [31:17:25<14:18:03, 12.67s/it] 68%|██████▊   | 8763/12825 [31:17:38<14:17:39, 12.67s/it] 68%|██████▊   | 8764/12825 [31:17:50<14:17:35, 12.67s/it] 68%|██████▊   | 8765/12825 [31:18:03<14:17:04, 12.67s/it] 68%|██████▊   | 8766/12825 [31:18:16<14:16:48, 12.67s/it] 68%|██████▊   | 8767/12825 [31:18:28<14:15:59, 12.66s/it] 68%|██████▊   | 8768/12825 [31:18:41<14:16:03, 12.66s/it] 68%|██████▊   | 8769/12825 [31:18:54<14:15:42, 12.66s/it] 68%|██████▊   | 8770/12825 [31:19:06<14:16:14, 12.67s/it] 68%|██████▊   | 8771/12825 [31:19:19<14:17:04, 12.68s/it] 68%|██████▊   | 8772/12825 [31:19:32<14:16:42, 12.68s/it] 68%|██████▊   | 8773/12825 [31:19:44<14:16:34, 12.68s/it] 68%|██████▊   | 8774/12825 [31:19:57<14:16:30, 12.69s/it] 68%|██████▊   | 8775/12825 [31:20:18<17:01:15, 15.13s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120218.90lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103487.16lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8775
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8775/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8775/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8750] due to args.save_total_limit
 68%|██████▊   | 8776/12825 [31:20:31<16:18:24, 14.50s/it] 68%|██████▊   | 8777/12825 [31:20:44<15:42:22, 13.97s/it] 68%|██████▊   | 8778/12825 [31:20:56<15:15:34, 13.57s/it] 68%|██████▊   | 8779/12825 [31:21:09<14:57:09, 13.30s/it] 68%|██████▊   | 8780/12825 [31:21:22<14:43:58, 13.11s/it] 68%|██████▊   | 8781/12825 [31:21:34<14:34:23, 12.97s/it] 68%|██████▊   | 8782/12825 [31:21:47<14:27:30, 12.87s/it] 68%|██████▊   | 8783/12825 [31:22:00<14:22:50, 12.81s/it] 68%|██████▊   | 8784/12825 [31:22:12<14:19:52, 12.77s/it] 68%|██████▊   | 8785/12825 [31:22:25<14:18:28, 12.75s/it] 69%|██████▊   | 8786/12825 [31:22:38<14:15:28, 12.71s/it] 69%|██████▊   | 8787/12825 [31:22:50<14:14:18, 12.69s/it] 69%|██████▊   | 8788/12825 [31:23:03<14:11:32, 12.66s/it] 69%|██████▊   | 8789/12825 [31:23:15<14:09:05, 12.62s/it] 69%|██████▊   | 8790/12825 [31:23:28<14:07:12, 12.60s/it] 69%|██████▊   | 8791/12825 [31:23:40<14:05:19, 12.57s/it] 69%|██████▊   | 8792/12825 [31:23:53<14:04:41, 12.57s/it] 69%|██████▊   | 8793/12825 [31:24:05<14:04:18, 12.56s/it] 69%|██████▊   | 8794/12825 [31:24:18<14:04:47, 12.57s/it] 69%|██████▊   | 8795/12825 [31:24:31<14:04:44, 12.58s/it] 69%|██████▊   | 8796/12825 [31:24:43<14:04:16, 12.57s/it] 69%|██████▊   | 8797/12825 [31:24:56<14:03:39, 12.57s/it] 69%|██████▊   | 8798/12825 [31:25:08<14:02:41, 12.56s/it] 69%|██████▊   | 8799/12825 [31:25:21<14:03:04, 12.56s/it] 69%|██████▊   | 8800/12825 [31:25:33<14:02:59, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 54473.52lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 49178.70lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8800
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8800/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8800/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8775] due to args.save_total_limit
 69%|██████▊   | 8801/12825 [31:25:47<14:15:52, 12.76s/it] 69%|██████▊   | 8802/12825 [31:25:59<14:11:39, 12.70s/it] 69%|██████▊   | 8803/12825 [31:26:12<14:08:46, 12.66s/it] 69%|██████▊   | 8804/12825 [31:26:24<14:05:52, 12.62s/it] 69%|██████▊   | 8805/12825 [31:26:37<14:05:06, 12.61s/it] 69%|██████▊   | 8806/12825 [31:26:49<14:02:58, 12.58s/it] 69%|██████▊   | 8807/12825 [31:27:10<16:33:29, 14.84s/it] 69%|██████▊   | 8808/12825 [31:27:22<15:48:14, 14.16s/it] 69%|██████▊   | 8809/12825 [31:27:35<15:15:37, 13.68s/it] 69%|██████▊   | 8810/12825 [31:27:47<14:53:16, 13.35s/it] 69%|██████▊   | 8811/12825 [31:28:00<14:36:49, 13.11s/it] 69%|██████▊   | 8812/12825 [31:28:12<14:25:22, 12.94s/it] 69%|██████▊   | 8813/12825 [31:28:25<14:17:40, 12.83s/it] 69%|██████▊   | 8814/12825 [31:28:37<14:12:28, 12.75s/it] 69%|██████▊   | 8815/12825 [31:28:50<14:09:46, 12.71s/it] 69%|██████▊   | 8816/12825 [31:29:03<14:06:34, 12.67s/it] 69%|██████▊   | 8817/12825 [31:29:15<14:05:02, 12.65s/it] 69%|██████▉   | 8818/12825 [31:29:28<14:03:09, 12.63s/it] 69%|██████▉   | 8819/12825 [31:29:40<14:00:53, 12.59s/it] 69%|██████▉   | 8820/12825 [31:29:53<14:00:47, 12.60s/it] 69%|██████▉   | 8821/12825 [31:30:05<13:59:17, 12.58s/it] 69%|██████▉   | 8822/12825 [31:30:18<14:01:21, 12.61s/it] 69%|██████▉   | 8823/12825 [31:30:31<13:59:37, 12.59s/it] 69%|██████▉   | 8824/12825 [31:30:43<13:58:24, 12.57s/it] 69%|██████▉   | 8825/12825 [31:30:56<13:58:02, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120299.49lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103569.12lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8825
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8825/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8825/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8800] due to args.save_total_limit
 69%|██████▉   | 8826/12825 [31:31:09<14:03:31, 12.66s/it] 69%|██████▉   | 8827/12825 [31:31:21<14:00:49, 12.62s/it] 69%|██████▉   | 8828/12825 [31:31:34<13:58:55, 12.59s/it] 69%|██████▉   | 8829/12825 [31:31:46<13:58:00, 12.58s/it] 69%|██████▉   | 8830/12825 [31:31:59<13:57:26, 12.58s/it] 69%|██████▉   | 8831/12825 [31:32:11<13:56:40, 12.57s/it] 69%|██████▉   | 8832/12825 [31:32:24<13:56:54, 12.58s/it] 69%|██████▉   | 8833/12825 [31:32:37<13:56:31, 12.57s/it] 69%|██████▉   | 8834/12825 [31:32:49<13:56:36, 12.58s/it] 69%|██████▉   | 8835/12825 [31:33:02<13:56:07, 12.57s/it] 69%|██████▉   | 8836/12825 [31:33:14<13:54:53, 12.56s/it] 69%|██████▉   | 8837/12825 [31:33:27<13:54:40, 12.56s/it] 69%|██████▉   | 8838/12825 [31:33:39<13:55:34, 12.57s/it] 69%|██████▉   | 8839/12825 [31:33:52<13:54:43, 12.56s/it] 69%|██████▉   | 8840/12825 [31:34:12<16:24:12, 14.82s/it] 69%|██████▉   | 8841/12825 [31:34:25<15:39:06, 14.14s/it] 69%|██████▉   | 8842/12825 [31:34:37<15:07:55, 13.68s/it] 69%|██████▉   | 8843/12825 [31:34:50<14:45:05, 13.34s/it] 69%|██████▉   | 8844/12825 [31:35:02<14:29:30, 13.10s/it] 69%|██████▉   | 8845/12825 [31:35:15<14:18:44, 12.95s/it] 69%|██████▉   | 8846/12825 [31:35:27<14:11:39, 12.84s/it] 69%|██████▉   | 8847/12825 [31:35:40<14:05:19, 12.75s/it] 69%|██████▉   | 8848/12825 [31:35:53<14:01:10, 12.69s/it] 69%|██████▉   | 8849/12825 [31:36:05<13:58:55, 12.66s/it] 69%|██████▉   | 8850/12825 [31:36:18<13:59:38, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120242.52lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103540.05lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8850
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8850/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8850/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8825] due to args.save_total_limit
 69%|██████▉   | 8851/12825 [31:36:31<14:03:36, 12.74s/it] 69%|██████▉   | 8852/12825 [31:36:43<14:00:12, 12.69s/it] 69%|██████▉   | 8853/12825 [31:36:56<13:57:10, 12.65s/it] 69%|██████▉   | 8854/12825 [31:37:08<13:55:22, 12.62s/it] 69%|██████▉   | 8855/12825 [31:37:21<13:54:07, 12.61s/it] 69%|██████▉   | 8856/12825 [31:37:34<13:52:48, 12.59s/it] 69%|██████▉   | 8857/12825 [31:37:46<13:51:40, 12.58s/it] 69%|██████▉   | 8858/12825 [31:37:59<13:51:06, 12.57s/it] 69%|██████▉   | 8859/12825 [31:38:11<13:50:58, 12.57s/it] 69%|██████▉   | 8860/12825 [31:38:24<13:51:48, 12.59s/it] 69%|██████▉   | 8861/12825 [31:38:36<13:50:37, 12.57s/it] 69%|██████▉   | 8862/12825 [31:38:49<13:50:24, 12.57s/it] 69%|██████▉   | 8863/12825 [31:39:01<13:49:06, 12.56s/it] 69%|██████▉   | 8864/12825 [31:39:14<13:49:35, 12.57s/it] 69%|██████▉   | 8865/12825 [31:39:27<13:49:37, 12.57s/it] 69%|██████▉   | 8866/12825 [31:39:39<13:48:45, 12.56s/it] 69%|██████▉   | 8867/12825 [31:39:52<13:47:39, 12.55s/it] 69%|██████▉   | 8868/12825 [31:40:04<13:48:17, 12.56s/it] 69%|██████▉   | 8869/12825 [31:40:17<13:47:24, 12.55s/it] 69%|██████▉   | 8870/12825 [31:40:29<13:46:56, 12.55s/it] 69%|██████▉   | 8871/12825 [31:40:42<13:46:50, 12.55s/it] 69%|██████▉   | 8872/12825 [31:41:02<16:18:47, 14.86s/it] 69%|██████▉   | 8873/12825 [31:41:15<15:33:04, 14.17s/it] 69%|██████▉   | 8874/12825 [31:41:27<15:00:45, 13.68s/it] 69%|██████▉   | 8875/12825 [31:41:40<14:38:10, 13.34s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120264.87lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103564.01lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8875
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8875/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8875/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8850] due to args.save_total_limit
 69%|██████▉   | 8876/12825 [31:41:53<14:29:25, 13.21s/it] 69%|██████▉   | 8877/12825 [31:42:05<14:15:16, 13.00s/it] 69%|██████▉   | 8878/12825 [31:42:18<14:06:22, 12.87s/it] 69%|██████▉   | 8879/12825 [31:42:30<13:59:59, 12.77s/it] 69%|██████▉   | 8880/12825 [31:42:43<13:55:40, 12.71s/it] 69%|██████▉   | 8881/12825 [31:42:55<13:52:59, 12.67s/it] 69%|██████▉   | 8882/12825 [31:43:08<13:50:12, 12.63s/it] 69%|██████▉   | 8883/12825 [31:43:21<13:48:48, 12.62s/it] 69%|██████▉   | 8884/12825 [31:43:33<13:47:33, 12.60s/it] 69%|██████▉   | 8885/12825 [31:43:46<13:46:57, 12.59s/it] 69%|██████▉   | 8886/12825 [31:43:58<13:45:34, 12.58s/it] 69%|██████▉   | 8887/12825 [31:44:11<13:44:17, 12.56s/it] 69%|██████▉   | 8888/12825 [31:44:23<13:44:27, 12.56s/it] 69%|██████▉   | 8889/12825 [31:44:36<13:43:43, 12.56s/it] 69%|██████▉   | 8890/12825 [31:44:48<13:43:07, 12.55s/it] 69%|██████▉   | 8891/12825 [31:45:01<13:42:11, 12.54s/it] 69%|██████▉   | 8892/12825 [31:45:13<13:42:13, 12.54s/it] 69%|██████▉   | 8893/12825 [31:45:26<13:42:17, 12.55s/it] 69%|██████▉   | 8894/12825 [31:45:39<13:42:47, 12.56s/it] 69%|██████▉   | 8895/12825 [31:45:51<13:42:51, 12.56s/it] 69%|██████▉   | 8896/12825 [31:46:04<13:42:03, 12.55s/it] 69%|██████▉   | 8897/12825 [31:46:16<13:42:18, 12.56s/it] 69%|██████▉   | 8898/12825 [31:46:29<13:42:00, 12.56s/it] 69%|██████▉   | 8899/12825 [31:46:41<13:42:42, 12.57s/it] 69%|██████▉   | 8900/12825 [31:46:54<13:41:49, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120335.28lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103542.23lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8900
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8900/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8900/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8875] due to args.save_total_limit
 69%|██████▉   | 8901/12825 [31:47:07<13:46:59, 12.65s/it] 69%|██████▉   | 8902/12825 [31:47:19<13:44:24, 12.61s/it] 69%|██████▉   | 8903/12825 [31:47:32<13:42:25, 12.58s/it] 69%|██████▉   | 8904/12825 [31:47:52<16:11:41, 14.87s/it] 69%|██████▉   | 8905/12825 [31:48:05<15:26:33, 14.18s/it] 69%|██████▉   | 8906/12825 [31:48:17<14:54:38, 13.70s/it] 69%|██████▉   | 8907/12825 [31:48:30<14:32:04, 13.36s/it] 69%|██████▉   | 8908/12825 [31:48:42<14:16:32, 13.12s/it] 69%|██████▉   | 8909/12825 [31:48:55<14:06:44, 12.97s/it] 69%|██████▉   | 8910/12825 [31:49:08<14:00:06, 12.88s/it] 69%|██████▉   | 8911/12825 [31:49:20<13:55:46, 12.81s/it] 69%|██████▉   | 8912/12825 [31:49:33<13:51:44, 12.75s/it] 69%|██████▉   | 8913/12825 [31:49:46<13:49:39, 12.72s/it] 70%|██████▉   | 8914/12825 [31:49:58<13:47:49, 12.70s/it] 70%|██████▉   | 8915/12825 [31:50:11<13:46:30, 12.68s/it] 70%|██████▉   | 8916/12825 [31:50:24<13:46:26, 12.69s/it] 70%|██████▉   | 8917/12825 [31:50:36<13:45:38, 12.68s/it] 70%|██████▉   | 8918/12825 [31:50:49<13:45:30, 12.68s/it] 70%|██████▉   | 8919/12825 [31:51:02<13:44:57, 12.67s/it] 70%|██████▉   | 8920/12825 [31:51:14<13:43:48, 12.66s/it] 70%|██████▉   | 8921/12825 [31:51:27<13:43:01, 12.65s/it] 70%|██████▉   | 8922/12825 [31:51:39<13:41:56, 12.64s/it] 70%|██████▉   | 8923/12825 [31:51:52<13:41:29, 12.63s/it] 70%|██████▉   | 8924/12825 [31:52:05<13:38:42, 12.59s/it] 70%|██████▉   | 8925/12825 [31:52:17<13:37:44, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120269.08lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103620.01lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8925
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8925/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8925/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8900] due to args.save_total_limit
 70%|██████▉   | 8926/12825 [31:52:30<13:43:32, 12.67s/it] 70%|██████▉   | 8927/12825 [31:52:43<13:41:09, 12.64s/it] 70%|██████▉   | 8928/12825 [31:52:55<13:40:01, 12.63s/it] 70%|██████▉   | 8929/12825 [31:53:08<13:38:04, 12.60s/it] 70%|██████▉   | 8930/12825 [31:53:20<13:37:45, 12.60s/it] 70%|██████▉   | 8931/12825 [31:53:33<13:37:07, 12.59s/it] 70%|██████▉   | 8932/12825 [31:53:45<13:36:02, 12.58s/it] 70%|██████▉   | 8933/12825 [31:53:58<13:35:40, 12.57s/it] 70%|██████▉   | 8934/12825 [31:54:11<13:35:21, 12.57s/it] 70%|██████▉   | 8935/12825 [31:54:23<13:34:21, 12.56s/it] 70%|██████▉   | 8936/12825 [31:54:36<13:34:18, 12.56s/it] 70%|██████▉   | 8937/12825 [31:54:56<16:03:43, 14.87s/it] 70%|██████▉   | 8938/12825 [31:55:08<15:18:34, 14.18s/it] 70%|██████▉   | 8939/12825 [31:55:21<14:45:54, 13.68s/it] 70%|██████▉   | 8940/12825 [31:55:34<14:24:25, 13.35s/it] 70%|██████▉   | 8941/12825 [31:55:46<14:07:23, 13.09s/it] 70%|██████▉   | 8942/12825 [31:55:59<13:56:15, 12.92s/it] 70%|██████▉   | 8943/12825 [31:56:11<13:49:17, 12.82s/it] 70%|██████▉   | 8944/12825 [31:56:24<13:44:08, 12.74s/it] 70%|██████▉   | 8945/12825 [31:56:36<13:39:45, 12.68s/it] 70%|██████▉   | 8946/12825 [31:56:49<13:37:12, 12.64s/it] 70%|██████▉   | 8947/12825 [31:57:01<13:35:28, 12.62s/it] 70%|██████▉   | 8948/12825 [31:57:14<13:34:33, 12.61s/it] 70%|██████▉   | 8949/12825 [31:57:26<13:32:56, 12.58s/it] 70%|██████▉   | 8950/12825 [31:57:39<13:32:17, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120355.87lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103680.54lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8950
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8950/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8950/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8925] due to args.save_total_limit
 70%|██████▉   | 8951/12825 [31:57:52<13:37:39, 12.66s/it] 70%|██████▉   | 8952/12825 [31:58:04<13:35:09, 12.63s/it] 70%|██████▉   | 8953/12825 [31:58:17<13:33:09, 12.60s/it] 70%|██████▉   | 8954/12825 [31:58:30<13:32:27, 12.59s/it] 70%|██████▉   | 8955/12825 [31:58:42<13:30:26, 12.56s/it] 70%|██████▉   | 8956/12825 [31:58:55<13:30:31, 12.57s/it] 70%|██████▉   | 8957/12825 [31:59:07<13:30:00, 12.56s/it] 70%|██████▉   | 8958/12825 [31:59:20<13:29:11, 12.56s/it] 70%|██████▉   | 8959/12825 [31:59:32<13:28:59, 12.56s/it] 70%|██████▉   | 8960/12825 [31:59:45<13:29:09, 12.56s/it] 70%|██████▉   | 8961/12825 [31:59:57<13:30:40, 12.59s/it] 70%|██████▉   | 8962/12825 [32:00:10<13:32:36, 12.62s/it] 70%|██████▉   | 8963/12825 [32:00:23<13:32:58, 12.63s/it] 70%|██████▉   | 8964/12825 [32:00:35<13:32:49, 12.63s/it] 70%|██████▉   | 8965/12825 [32:00:48<13:32:41, 12.63s/it] 70%|██████▉   | 8966/12825 [32:01:01<13:32:39, 12.64s/it] 70%|██████▉   | 8967/12825 [32:01:13<13:33:02, 12.64s/it] 70%|██████▉   | 8968/12825 [32:01:26<13:33:16, 12.65s/it] 70%|██████▉   | 8969/12825 [32:01:47<16:18:35, 15.23s/it] 70%|██████▉   | 8970/12825 [32:02:00<15:29:07, 14.46s/it] 70%|██████▉   | 8971/12825 [32:02:13<14:54:57, 13.93s/it] 70%|██████▉   | 8972/12825 [32:02:25<14:30:27, 13.56s/it] 70%|██████▉   | 8973/12825 [32:02:38<14:12:57, 13.29s/it] 70%|██████▉   | 8974/12825 [32:02:51<13:59:55, 13.09s/it] 70%|██████▉   | 8975/12825 [32:03:03<13:51:37, 12.96s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120289.01lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103558.14lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8975
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8975/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8975/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-8975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8950] due to args.save_total_limit
 70%|██████▉   | 8976/12825 [32:03:16<13:51:57, 12.97s/it] 70%|██████▉   | 8977/12825 [32:03:29<13:45:37, 12.87s/it] 70%|███████   | 8978/12825 [32:03:42<13:41:45, 12.82s/it] 70%|███████   | 8979/12825 [32:03:54<13:38:01, 12.76s/it] 70%|███████   | 8980/12825 [32:04:07<13:36:04, 12.73s/it] 70%|███████   | 8981/12825 [32:04:20<13:34:44, 12.72s/it] 70%|███████   | 8982/12825 [32:04:32<13:33:00, 12.69s/it] 70%|███████   | 8983/12825 [32:04:45<13:31:48, 12.68s/it] 70%|███████   | 8984/12825 [32:04:58<13:30:41, 12.66s/it] 70%|███████   | 8985/12825 [32:05:10<13:30:42, 12.67s/it] 70%|███████   | 8986/12825 [32:05:23<13:30:20, 12.66s/it] 70%|███████   | 8987/12825 [32:05:35<13:29:25, 12.65s/it] 70%|███████   | 8988/12825 [32:05:48<13:28:58, 12.65s/it] 70%|███████   | 8989/12825 [32:06:01<13:28:18, 12.64s/it] 70%|███████   | 8990/12825 [32:06:13<13:28:25, 12.65s/it] 70%|███████   | 8991/12825 [32:06:26<13:28:53, 12.66s/it] 70%|███████   | 8992/12825 [32:06:39<13:28:34, 12.66s/it] 70%|███████   | 8993/12825 [32:06:51<13:28:47, 12.66s/it] 70%|███████   | 8994/12825 [32:07:04<13:28:16, 12.66s/it] 70%|███████   | 8995/12825 [32:07:17<13:27:41, 12.65s/it] 70%|███████   | 8996/12825 [32:07:29<13:27:04, 12.65s/it] 70%|███████   | 8997/12825 [32:07:42<13:27:33, 12.66s/it] 70%|███████   | 8998/12825 [32:07:55<13:27:30, 12.66s/it] 70%|███████   | 8999/12825 [32:08:07<13:27:29, 12.66s/it] 70%|███████   | 9000/12825 [32:08:20<13:26:45, 12.65s/it]                                                           70%|███████   | 9000/12825 [32:08:20<13:26:45, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120323.64lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103411.47lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9000
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9000/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9000/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8975] due to args.save_total_limit
 70%|███████   | 9001/12825 [32:08:33<13:32:25, 12.75s/it] 70%|███████   | 9002/12825 [32:08:54<16:14:50, 15.30s/it] 70%|███████   | 9003/12825 [32:09:07<15:24:11, 14.51s/it] 70%|███████   | 9004/12825 [32:09:20<14:48:15, 13.95s/it] 70%|███████   | 9005/12825 [32:09:32<14:23:37, 13.56s/it] 70%|███████   | 9006/12825 [32:09:45<14:05:47, 13.29s/it] 70%|███████   | 9007/12825 [32:09:57<13:52:31, 13.08s/it] 70%|███████   | 9008/12825 [32:10:10<13:44:11, 12.96s/it] 70%|███████   | 9009/12825 [32:10:23<13:38:34, 12.87s/it] 70%|███████   | 9010/12825 [32:10:35<13:34:04, 12.80s/it] 70%|███████   | 9011/12825 [32:10:48<13:28:50, 12.72s/it] 70%|███████   | 9012/12825 [32:11:00<13:24:48, 12.66s/it] 70%|███████   | 9013/12825 [32:11:13<13:22:05, 12.62s/it] 70%|███████   | 9014/12825 [32:11:26<13:22:42, 12.64s/it] 70%|███████   | 9015/12825 [32:11:38<13:20:38, 12.61s/it] 70%|███████   | 9016/12825 [32:11:51<13:18:47, 12.58s/it] 70%|███████   | 9017/12825 [32:12:03<13:17:04, 12.56s/it] 70%|███████   | 9018/12825 [32:12:16<13:16:09, 12.55s/it] 70%|███████   | 9019/12825 [32:12:28<13:15:16, 12.54s/it] 70%|███████   | 9020/12825 [32:12:41<13:14:57, 12.54s/it] 70%|███████   | 9021/12825 [32:12:53<13:14:16, 12.53s/it] 70%|███████   | 9022/12825 [32:13:06<13:13:59, 12.53s/it] 70%|███████   | 9023/12825 [32:13:18<13:13:40, 12.53s/it] 70%|███████   | 9024/12825 [32:13:31<13:14:04, 12.53s/it] 70%|███████   | 9025/12825 [32:13:43<13:13:47, 12.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120417.68lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103732.77lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9025
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9025/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9025/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-8075] due to args.save_total_limit
 70%|███████   | 9026/12825 [32:13:56<13:20:31, 12.64s/it] 70%|███████   | 9027/12825 [32:14:09<13:18:00, 12.61s/it] 70%|███████   | 9028/12825 [32:14:21<13:17:08, 12.60s/it] 70%|███████   | 9029/12825 [32:14:34<13:16:04, 12.58s/it] 70%|███████   | 9030/12825 [32:14:47<13:14:58, 12.57s/it] 70%|███████   | 9031/12825 [32:14:59<13:13:32, 12.55s/it] 70%|███████   | 9032/12825 [32:15:12<13:13:56, 12.56s/it] 70%|███████   | 9033/12825 [32:15:24<13:13:58, 12.56s/it] 70%|███████   | 9034/12825 [32:15:45<15:40:56, 14.89s/it] 70%|███████   | 9035/12825 [32:15:57<14:56:43, 14.20s/it] 70%|███████   | 9036/12825 [32:16:10<14:25:02, 13.70s/it] 70%|███████   | 9037/12825 [32:16:22<14:02:33, 13.35s/it] 70%|███████   | 9038/12825 [32:16:35<13:46:47, 13.10s/it] 70%|███████   | 9039/12825 [32:16:47<13:36:24, 12.94s/it] 70%|███████   | 9040/12825 [32:17:00<13:29:46, 12.84s/it] 70%|███████   | 9041/12825 [32:17:12<13:23:15, 12.74s/it] 71%|███████   | 9042/12825 [32:17:25<13:20:20, 12.69s/it] 71%|███████   | 9043/12825 [32:17:37<13:17:32, 12.65s/it] 71%|███████   | 9044/12825 [32:17:50<13:15:37, 12.63s/it] 71%|███████   | 9045/12825 [32:18:03<13:14:01, 12.60s/it] 71%|███████   | 9046/12825 [32:18:15<13:13:52, 12.60s/it] 71%|███████   | 9047/12825 [32:18:28<13:12:34, 12.59s/it] 71%|███████   | 9048/12825 [32:18:40<13:12:02, 12.58s/it] 71%|███████   | 9049/12825 [32:18:53<13:11:10, 12.57s/it] 71%|███████   | 9050/12825 [32:19:05<13:10:35, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120345.89lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103621.43lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9050
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9050/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9050/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9000] due to args.save_total_limit
 71%|███████   | 9051/12825 [32:19:18<13:19:14, 12.71s/it] 71%|███████   | 9052/12825 [32:19:31<13:16:01, 12.66s/it] 71%|███████   | 9053/12825 [32:19:44<13:12:51, 12.61s/it] 71%|███████   | 9054/12825 [32:19:56<13:11:56, 12.60s/it] 71%|███████   | 9055/12825 [32:20:09<13:10:18, 12.58s/it] 71%|███████   | 9056/12825 [32:20:21<13:09:43, 12.57s/it] 71%|███████   | 9057/12825 [32:20:34<13:08:34, 12.56s/it] 71%|███████   | 9058/12825 [32:20:46<13:08:15, 12.56s/it] 71%|███████   | 9059/12825 [32:20:59<13:07:38, 12.55s/it] 71%|███████   | 9060/12825 [32:21:11<13:07:47, 12.55s/it] 71%|███████   | 9061/12825 [32:21:24<13:06:45, 12.54s/it] 71%|███████   | 9062/12825 [32:21:36<13:04:55, 12.52s/it] 71%|███████   | 9063/12825 [32:21:49<13:04:43, 12.52s/it] 71%|███████   | 9064/12825 [32:22:01<13:04:45, 12.52s/it] 71%|███████   | 9065/12825 [32:22:14<13:04:49, 12.52s/it] 71%|███████   | 9066/12825 [32:22:33<15:16:13, 14.62s/it] 71%|███████   | 9067/12825 [32:22:46<14:37:13, 14.01s/it] 71%|███████   | 9068/12825 [32:22:59<14:09:18, 13.56s/it] 71%|███████   | 9069/12825 [32:23:11<13:50:23, 13.27s/it] 71%|███████   | 9070/12825 [32:23:24<13:36:27, 13.05s/it] 71%|███████   | 9071/12825 [32:23:36<13:26:58, 12.90s/it] 71%|███████   | 9072/12825 [32:23:49<13:20:05, 12.79s/it] 71%|███████   | 9073/12825 [32:24:01<13:14:49, 12.71s/it] 71%|███████   | 9074/12825 [32:24:14<13:12:57, 12.68s/it] 71%|███████   | 9075/12825 [32:24:27<13:12:41, 12.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120240.22lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103485.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9075
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9075/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9075/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9050] due to args.save_total_limit
 71%|███████   | 9076/12825 [32:24:40<13:18:26, 12.78s/it] 71%|███████   | 9077/12825 [32:24:52<13:15:57, 12.74s/it] 71%|███████   | 9078/12825 [32:25:05<13:13:55, 12.71s/it] 71%|███████   | 9079/12825 [32:25:17<13:11:44, 12.68s/it] 71%|███████   | 9080/12825 [32:25:30<13:10:01, 12.66s/it] 71%|███████   | 9081/12825 [32:25:43<13:08:55, 12.64s/it] 71%|███████   | 9082/12825 [32:25:55<13:11:06, 12.68s/it] 71%|███████   | 9083/12825 [32:26:08<13:09:59, 12.67s/it] 71%|███████   | 9084/12825 [32:26:21<13:08:37, 12.65s/it] 71%|███████   | 9085/12825 [32:26:33<13:07:10, 12.63s/it] 71%|███████   | 9086/12825 [32:26:46<13:07:10, 12.63s/it] 71%|███████   | 9087/12825 [32:26:59<13:07:55, 12.65s/it] 71%|███████   | 9088/12825 [32:27:11<13:07:36, 12.65s/it] 71%|███████   | 9089/12825 [32:27:24<13:06:11, 12.63s/it] 71%|███████   | 9090/12825 [32:27:36<13:06:13, 12.63s/it] 71%|███████   | 9091/12825 [32:27:49<13:05:51, 12.63s/it] 71%|███████   | 9092/12825 [32:28:02<13:05:49, 12.63s/it] 71%|███████   | 9093/12825 [32:28:14<13:05:45, 12.63s/it] 71%|███████   | 9094/12825 [32:28:27<13:05:56, 12.64s/it] 71%|███████   | 9095/12825 [32:28:40<13:05:22, 12.63s/it] 71%|███████   | 9096/12825 [32:28:52<13:05:00, 12.63s/it] 71%|███████   | 9097/12825 [32:29:05<13:04:25, 12.62s/it] 71%|███████   | 9098/12825 [32:29:17<13:04:03, 12.62s/it] 71%|███████   | 9099/12825 [32:29:38<15:29:51, 14.97s/it] 71%|███████   | 9100/12825 [32:29:51<14:45:22, 14.26s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120196.19lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103418.08lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9075] due to args.save_total_limit
 71%|███████   | 9101/12825 [32:30:03<14:20:54, 13.87s/it] 71%|███████   | 9102/12825 [32:30:16<13:56:57, 13.49s/it] 71%|███████   | 9103/12825 [32:30:29<13:40:55, 13.23s/it] 71%|███████   | 9104/12825 [32:30:41<13:29:20, 13.05s/it] 71%|███████   | 9105/12825 [32:30:54<13:21:09, 12.92s/it] 71%|███████   | 9106/12825 [32:31:07<13:16:10, 12.84s/it] 71%|███████   | 9107/12825 [32:31:19<13:12:07, 12.78s/it] 71%|███████   | 9108/12825 [32:31:32<13:08:43, 12.73s/it] 71%|███████   | 9109/12825 [32:31:44<13:05:07, 12.68s/it] 71%|███████   | 9110/12825 [32:31:57<13:02:05, 12.63s/it] 71%|███████   | 9111/12825 [32:32:10<13:00:29, 12.61s/it] 71%|███████   | 9112/12825 [32:32:22<12:59:11, 12.59s/it] 71%|███████   | 9113/12825 [32:32:35<12:57:54, 12.57s/it] 71%|███████   | 9114/12825 [32:32:47<12:57:01, 12.56s/it] 71%|███████   | 9115/12825 [32:33:00<12:57:21, 12.57s/it] 71%|███████   | 9116/12825 [32:33:12<12:57:45, 12.58s/it] 71%|███████   | 9117/12825 [32:33:25<12:56:25, 12.56s/it] 71%|███████   | 9118/12825 [32:33:37<12:56:42, 12.57s/it] 71%|███████   | 9119/12825 [32:33:50<12:56:14, 12.57s/it] 71%|███████   | 9120/12825 [32:34:03<12:56:01, 12.57s/it] 71%|███████   | 9121/12825 [32:34:15<12:55:23, 12.56s/it] 71%|███████   | 9122/12825 [32:34:28<12:55:21, 12.56s/it] 71%|███████   | 9123/12825 [32:34:40<12:55:12, 12.56s/it] 71%|███████   | 9124/12825 [32:34:53<12:54:54, 12.56s/it] 71%|███████   | 9125/12825 [32:35:05<12:55:12, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120384.91lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103576.61lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9100] due to args.save_total_limit
 71%|███████   | 9126/12825 [32:35:18<13:00:27, 12.66s/it] 71%|███████   | 9127/12825 [32:35:31<13:00:59, 12.67s/it] 71%|███████   | 9128/12825 [32:35:44<13:00:53, 12.67s/it] 71%|███████   | 9129/12825 [32:35:56<12:58:48, 12.64s/it] 71%|███████   | 9130/12825 [32:36:09<12:57:32, 12.63s/it] 71%|███████   | 9131/12825 [32:36:29<15:13:06, 14.83s/it] 71%|███████   | 9132/12825 [32:36:41<14:31:14, 14.16s/it] 71%|███████   | 9133/12825 [32:36:54<14:00:53, 13.67s/it] 71%|███████   | 9134/12825 [32:37:06<13:38:38, 13.31s/it] 71%|███████   | 9135/12825 [32:37:19<13:24:51, 13.09s/it] 71%|███████   | 9136/12825 [32:37:31<13:14:02, 12.91s/it] 71%|███████   | 9137/12825 [32:37:44<13:06:27, 12.79s/it] 71%|███████▏  | 9138/12825 [32:37:56<13:00:48, 12.71s/it] 71%|███████▏  | 9139/12825 [32:38:09<12:57:35, 12.66s/it] 71%|███████▏  | 9140/12825 [32:38:22<12:55:33, 12.63s/it] 71%|███████▏  | 9141/12825 [32:38:34<12:54:16, 12.61s/it] 71%|███████▏  | 9142/12825 [32:38:47<12:53:11, 12.60s/it] 71%|███████▏  | 9143/12825 [32:38:59<12:51:59, 12.58s/it] 71%|███████▏  | 9144/12825 [32:39:12<12:51:39, 12.58s/it] 71%|███████▏  | 9145/12825 [32:39:24<12:51:06, 12.57s/it] 71%|███████▏  | 9146/12825 [32:39:37<12:49:37, 12.55s/it] 71%|███████▏  | 9147/12825 [32:39:49<12:49:29, 12.55s/it] 71%|███████▏  | 9148/12825 [32:40:02<12:49:34, 12.56s/it] 71%|███████▏  | 9149/12825 [32:40:14<12:47:59, 12.54s/it] 71%|███████▏  | 9150/12825 [32:40:27<12:48:19, 12.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120349.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103529.83lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9125] due to args.save_total_limit
 71%|███████▏  | 9151/12825 [32:40:40<12:53:56, 12.64s/it] 71%|███████▏  | 9152/12825 [32:40:53<12:54:53, 12.66s/it] 71%|███████▏  | 9153/12825 [32:41:05<12:52:51, 12.63s/it] 71%|███████▏  | 9154/12825 [32:41:18<12:52:56, 12.63s/it] 71%|███████▏  | 9155/12825 [32:41:30<12:51:15, 12.61s/it] 71%|███████▏  | 9156/12825 [32:41:43<12:50:19, 12.60s/it] 71%|███████▏  | 9157/12825 [32:41:56<12:50:02, 12.60s/it] 71%|███████▏  | 9158/12825 [32:42:08<12:51:16, 12.62s/it] 71%|███████▏  | 9159/12825 [32:42:21<12:51:19, 12.62s/it] 71%|███████▏  | 9160/12825 [32:42:33<12:49:56, 12.60s/it] 71%|███████▏  | 9161/12825 [32:42:46<12:48:59, 12.59s/it] 71%|███████▏  | 9162/12825 [32:42:59<12:49:36, 12.61s/it] 71%|███████▏  | 9163/12825 [32:43:11<12:48:52, 12.60s/it] 71%|███████▏  | 9164/12825 [32:43:32<15:12:27, 14.95s/it] 71%|███████▏  | 9165/12825 [32:43:44<14:28:44, 14.24s/it] 71%|███████▏  | 9166/12825 [32:43:57<13:57:03, 13.73s/it] 71%|███████▏  | 9167/12825 [32:44:09<13:37:55, 13.42s/it] 71%|███████▏  | 9168/12825 [32:44:22<13:22:08, 13.16s/it] 71%|███████▏  | 9169/12825 [32:44:35<13:10:55, 12.98s/it] 72%|███████▏  | 9170/12825 [32:44:47<13:05:00, 12.89s/it] 72%|███████▏  | 9171/12825 [32:45:00<12:59:06, 12.79s/it] 72%|███████▏  | 9172/12825 [32:45:12<12:55:32, 12.74s/it] 72%|███████▏  | 9173/12825 [32:45:25<12:52:43, 12.70s/it] 72%|███████▏  | 9174/12825 [32:45:38<12:51:06, 12.67s/it] 72%|███████▏  | 9175/12825 [32:45:50<12:48:35, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120393.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103663.26lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9150] due to args.save_total_limit
 72%|███████▏  | 9176/12825 [32:46:03<12:54:00, 12.73s/it] 72%|███████▏  | 9177/12825 [32:46:16<12:51:40, 12.69s/it] 72%|███████▏  | 9178/12825 [32:46:28<12:49:25, 12.66s/it] 72%|███████▏  | 9179/12825 [32:46:41<12:47:18, 12.63s/it] 72%|███████▏  | 9180/12825 [32:46:53<12:46:28, 12.62s/it] 72%|███████▏  | 9181/12825 [32:47:06<12:45:21, 12.60s/it] 72%|███████▏  | 9182/12825 [32:47:19<12:44:52, 12.60s/it] 72%|███████▏  | 9183/12825 [32:47:31<12:44:55, 12.60s/it] 72%|███████▏  | 9184/12825 [32:47:44<12:44:14, 12.59s/it] 72%|███████▏  | 9185/12825 [32:47:56<12:46:26, 12.63s/it] 72%|███████▏  | 9186/12825 [32:48:09<12:45:42, 12.63s/it] 72%|███████▏  | 9187/12825 [32:48:22<12:45:34, 12.63s/it] 72%|███████▏  | 9188/12825 [32:48:34<12:45:03, 12.62s/it] 72%|███████▏  | 9189/12825 [32:48:47<12:43:51, 12.60s/it] 72%|███████▏  | 9190/12825 [32:49:00<12:43:46, 12.61s/it] 72%|███████▏  | 9191/12825 [32:49:12<12:43:53, 12.61s/it] 72%|███████▏  | 9192/12825 [32:49:25<12:43:48, 12.61s/it] 72%|███████▏  | 9193/12825 [32:49:37<12:43:03, 12.61s/it] 72%|███████▏  | 9194/12825 [32:49:50<12:42:47, 12.60s/it] 72%|███████▏  | 9195/12825 [32:50:03<12:42:33, 12.60s/it] 72%|███████▏  | 9196/12825 [32:50:23<14:58:08, 14.85s/it] 72%|███████▏  | 9197/12825 [32:50:35<14:16:32, 14.17s/it] 72%|███████▏  | 9198/12825 [32:50:48<13:46:32, 13.67s/it] 72%|███████▏  | 9199/12825 [32:51:00<13:26:14, 13.34s/it] 72%|███████▏  | 9200/12825 [32:51:13<13:12:10, 13.11s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120542.01lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103746.84lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9175] due to args.save_total_limit
 72%|███████▏  | 9201/12825 [32:51:26<13:07:38, 13.04s/it] 72%|███████▏  | 9202/12825 [32:51:38<12:58:37, 12.89s/it] 72%|███████▏  | 9203/12825 [32:51:51<12:52:42, 12.80s/it] 72%|███████▏  | 9204/12825 [32:52:04<12:50:18, 12.76s/it] 72%|███████▏  | 9205/12825 [32:52:16<12:46:48, 12.71s/it] 72%|███████▏  | 9206/12825 [32:52:29<12:44:06, 12.67s/it] 72%|███████▏  | 9207/12825 [32:52:41<12:43:36, 12.66s/it] 72%|███████▏  | 9208/12825 [32:52:54<12:42:20, 12.65s/it] 72%|███████▏  | 9209/12825 [32:53:07<12:41:04, 12.63s/it] 72%|███████▏  | 9210/12825 [32:53:19<12:39:44, 12.61s/it] 72%|███████▏  | 9211/12825 [32:53:32<12:38:39, 12.60s/it] 72%|███████▏  | 9212/12825 [32:53:44<12:38:27, 12.60s/it] 72%|███████▏  | 9213/12825 [32:53:57<12:37:17, 12.58s/it] 72%|███████▏  | 9214/12825 [32:54:09<12:38:16, 12.60s/it] 72%|███████▏  | 9215/12825 [32:54:22<12:37:26, 12.59s/it] 72%|███████▏  | 9216/12825 [32:54:35<12:37:18, 12.59s/it] 72%|███████▏  | 9217/12825 [32:54:47<12:36:14, 12.58s/it] 72%|███████▏  | 9218/12825 [32:55:00<12:36:01, 12.58s/it] 72%|███████▏  | 9219/12825 [32:55:12<12:34:59, 12.56s/it] 72%|███████▏  | 9220/12825 [32:55:25<12:34:34, 12.56s/it] 72%|███████▏  | 9221/12825 [32:55:37<12:34:15, 12.56s/it] 72%|███████▏  | 9222/12825 [32:55:50<12:34:27, 12.56s/it] 72%|███████▏  | 9223/12825 [32:56:03<12:34:29, 12.57s/it] 72%|███████▏  | 9224/12825 [32:56:15<12:33:55, 12.56s/it] 72%|███████▏  | 9225/12825 [32:56:28<12:33:34, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120344.74lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103642.30lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9200] due to args.save_total_limit
 72%|███████▏  | 9226/12825 [32:56:41<12:40:40, 12.68s/it] 72%|███████▏  | 9227/12825 [32:56:53<12:38:55, 12.66s/it] 72%|███████▏  | 9228/12825 [32:57:14<14:58:09, 14.98s/it] 72%|███████▏  | 9229/12825 [32:57:26<14:13:59, 14.25s/it] 72%|███████▏  | 9230/12825 [32:57:39<13:43:48, 13.75s/it] 72%|███████▏  | 9231/12825 [32:57:51<13:22:34, 13.40s/it] 72%|███████▏  | 9232/12825 [32:58:04<13:07:43, 13.15s/it] 72%|███████▏  | 9233/12825 [32:58:12<11:33:54, 11.59s/it] 72%|███████▏  | 9234/12825 [32:58:13<8:20:21,  8.36s/it]  72%|███████▏  | 9235/12825 [32:58:38<13:27:06, 13.49s/it] 72%|███████▏  | 9236/12825 [32:58:51<13:10:33, 13.22s/it] 72%|███████▏  | 9237/12825 [32:59:03<12:59:13, 13.03s/it] 72%|███████▏  | 9238/12825 [32:59:16<12:50:58, 12.90s/it] 72%|███████▏  | 9239/12825 [32:59:28<12:44:24, 12.79s/it] 72%|███████▏  | 9240/12825 [32:59:41<12:40:48, 12.73s/it] 72%|███████▏  | 9241/12825 [32:59:54<12:37:47, 12.69s/it] 72%|███████▏  | 9242/12825 [33:00:06<12:35:38, 12.65s/it] 72%|███████▏  | 9243/12825 [33:00:19<12:33:31, 12.62s/it] 72%|███████▏  | 9244/12825 [33:00:31<12:32:29, 12.61s/it] 72%|███████▏  | 9245/12825 [33:00:44<12:31:43, 12.60s/it] 72%|███████▏  | 9246/12825 [33:00:56<12:30:18, 12.58s/it] 72%|███████▏  | 9247/12825 [33:01:09<12:29:00, 12.56s/it] 72%|███████▏  | 9248/12825 [33:01:22<12:29:25, 12.57s/it] 72%|███████▏  | 9249/12825 [33:01:34<12:29:10, 12.57s/it] 72%|███████▏  | 9250/12825 [33:01:47<12:28:34, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120492.12lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103781.73lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9225] due to args.save_total_limit
 72%|███████▏  | 9251/12825 [33:02:00<12:34:18, 12.66s/it] 72%|███████▏  | 9252/12825 [33:02:12<12:33:49, 12.66s/it] 72%|███████▏  | 9253/12825 [33:02:25<12:31:36, 12.62s/it] 72%|███████▏  | 9254/12825 [33:02:37<12:30:59, 12.62s/it] 72%|███████▏  | 9255/12825 [33:02:50<12:29:45, 12.60s/it] 72%|███████▏  | 9256/12825 [33:03:03<12:29:45, 12.60s/it] 72%|███████▏  | 9257/12825 [33:03:15<12:29:36, 12.61s/it] 72%|███████▏  | 9258/12825 [33:03:28<12:29:21, 12.60s/it] 72%|███████▏  | 9259/12825 [33:03:40<12:28:37, 12.60s/it] 72%|███████▏  | 9260/12825 [33:03:53<12:27:47, 12.59s/it] 72%|███████▏  | 9261/12825 [33:04:13<14:48:50, 14.96s/it] 72%|███████▏  | 9262/12825 [33:04:26<14:06:06, 14.25s/it] 72%|███████▏  | 9263/12825 [33:04:39<13:36:40, 13.76s/it] 72%|███████▏  | 9264/12825 [33:04:51<13:15:38, 13.41s/it] 72%|███████▏  | 9265/12825 [33:05:04<13:00:21, 13.15s/it] 72%|███████▏  | 9266/12825 [33:05:16<12:49:43, 12.98s/it] 72%|███████▏  | 9267/12825 [33:05:29<12:42:15, 12.85s/it] 72%|███████▏  | 9268/12825 [33:05:41<12:37:47, 12.78s/it] 72%|███████▏  | 9269/12825 [33:05:54<12:33:40, 12.72s/it] 72%|███████▏  | 9270/12825 [33:06:07<12:30:26, 12.67s/it] 72%|███████▏  | 9271/12825 [33:06:19<12:28:30, 12.64s/it] 72%|███████▏  | 9272/12825 [33:06:32<12:26:32, 12.61s/it] 72%|███████▏  | 9273/12825 [33:06:44<12:25:17, 12.59s/it] 72%|███████▏  | 9274/12825 [33:06:57<12:25:23, 12.59s/it] 72%|███████▏  | 9275/12825 [33:07:09<12:25:04, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120568.84lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103818.74lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9250] due to args.save_total_limit
 72%|███████▏  | 9276/12825 [33:07:22<12:31:10, 12.70s/it] 72%|███████▏  | 9277/12825 [33:07:35<12:27:49, 12.65s/it] 72%|███████▏  | 9278/12825 [33:07:48<12:27:42, 12.65s/it] 72%|███████▏  | 9279/12825 [33:08:00<12:26:42, 12.63s/it] 72%|███████▏  | 9280/12825 [33:08:13<12:25:16, 12.61s/it] 72%|███████▏  | 9281/12825 [33:08:25<12:23:32, 12.59s/it] 72%|███████▏  | 9282/12825 [33:08:38<12:22:38, 12.58s/it] 72%|███████▏  | 9283/12825 [33:08:50<12:22:45, 12.58s/it] 72%|███████▏  | 9284/12825 [33:09:03<12:22:02, 12.57s/it] 72%|███████▏  | 9285/12825 [33:09:15<12:20:59, 12.56s/it] 72%|███████▏  | 9286/12825 [33:09:28<12:20:25, 12.55s/it] 72%|███████▏  | 9287/12825 [33:09:41<12:20:49, 12.56s/it] 72%|███████▏  | 9288/12825 [33:09:53<12:24:41, 12.63s/it] 72%|███████▏  | 9289/12825 [33:10:06<12:22:50, 12.60s/it] 72%|███████▏  | 9290/12825 [33:10:19<12:24:27, 12.64s/it] 72%|███████▏  | 9291/12825 [33:10:31<12:23:05, 12.62s/it] 72%|███████▏  | 9292/12825 [33:10:44<12:22:28, 12.61s/it] 72%|███████▏  | 9293/12825 [33:11:05<14:46:36, 15.06s/it] 72%|███████▏  | 9294/12825 [33:11:17<14:02:09, 14.31s/it] 72%|███████▏  | 9295/12825 [33:11:30<13:34:48, 13.85s/it] 72%|███████▏  | 9296/12825 [33:11:43<13:14:31, 13.51s/it] 72%|███████▏  | 9297/12825 [33:11:55<13:00:28, 13.27s/it] 72%|███████▏  | 9298/12825 [33:12:08<12:50:28, 13.11s/it] 73%|███████▎  | 9299/12825 [33:12:21<12:43:38, 12.99s/it] 73%|███████▎  | 9300/12825 [33:12:34<12:38:43, 12.91s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120262.18lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103568.08lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9275] due to args.save_total_limit
 73%|███████▎  | 9301/12825 [33:12:47<12:40:19, 12.95s/it] 73%|███████▎  | 9302/12825 [33:12:59<12:35:17, 12.86s/it] 73%|███████▎  | 9303/12825 [33:13:12<12:32:04, 12.81s/it] 73%|███████▎  | 9304/12825 [33:13:25<12:30:11, 12.78s/it] 73%|███████▎  | 9305/12825 [33:13:37<12:27:25, 12.74s/it] 73%|███████▎  | 9306/12825 [33:13:50<12:26:19, 12.73s/it] 73%|███████▎  | 9307/12825 [33:14:03<12:25:49, 12.72s/it] 73%|███████▎  | 9308/12825 [33:14:15<12:24:58, 12.71s/it] 73%|███████▎  | 9309/12825 [33:14:28<12:25:16, 12.72s/it] 73%|███████▎  | 9310/12825 [33:14:41<12:24:32, 12.71s/it] 73%|███████▎  | 9311/12825 [33:14:53<12:23:27, 12.69s/it] 73%|███████▎  | 9312/12825 [33:15:06<12:20:48, 12.65s/it] 73%|███████▎  | 9313/12825 [33:15:19<12:18:53, 12.62s/it] 73%|███████▎  | 9314/12825 [33:15:31<12:17:53, 12.61s/it] 73%|███████▎  | 9315/12825 [33:15:44<12:16:30, 12.59s/it] 73%|███████▎  | 9316/12825 [33:15:56<12:18:10, 12.62s/it] 73%|███████▎  | 9317/12825 [33:16:09<12:19:34, 12.65s/it] 73%|███████▎  | 9318/12825 [33:16:22<12:19:19, 12.65s/it] 73%|███████▎  | 9319/12825 [33:16:34<12:19:11, 12.65s/it] 73%|███████▎  | 9320/12825 [33:16:47<12:20:00, 12.67s/it] 73%|███████▎  | 9321/12825 [33:17:00<12:20:17, 12.68s/it] 73%|███████▎  | 9322/12825 [33:17:12<12:20:30, 12.68s/it] 73%|███████▎  | 9323/12825 [33:17:25<12:20:45, 12.69s/it] 73%|███████▎  | 9324/12825 [33:17:38<12:21:24, 12.71s/it] 73%|███████▎  | 9325/12825 [33:17:51<12:20:24, 12.69s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120213.54lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103436.88lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9300] due to args.save_total_limit
 73%|███████▎  | 9326/12825 [33:18:11<14:41:25, 15.11s/it] 73%|███████▎  | 9327/12825 [33:18:24<13:59:48, 14.41s/it] 73%|███████▎  | 9328/12825 [33:18:37<13:30:39, 13.91s/it] 73%|███████▎  | 9329/12825 [33:18:50<13:09:22, 13.55s/it] 73%|███████▎  | 9330/12825 [33:19:02<12:55:59, 13.32s/it] 73%|███████▎  | 9331/12825 [33:19:15<12:45:03, 13.14s/it] 73%|███████▎  | 9332/12825 [33:19:28<12:36:41, 13.00s/it] 73%|███████▎  | 9333/12825 [33:19:40<12:30:40, 12.90s/it] 73%|███████▎  | 9334/12825 [33:19:53<12:27:15, 12.84s/it] 73%|███████▎  | 9335/12825 [33:20:06<12:25:32, 12.82s/it] 73%|███████▎  | 9336/12825 [33:20:19<12:23:54, 12.79s/it] 73%|███████▎  | 9337/12825 [33:20:31<12:23:40, 12.79s/it] 73%|███████▎  | 9338/12825 [33:20:44<12:24:15, 12.81s/it] 73%|███████▎  | 9339/12825 [33:20:57<12:22:07, 12.77s/it] 73%|███████▎  | 9340/12825 [33:21:10<12:20:59, 12.76s/it] 73%|███████▎  | 9341/12825 [33:21:22<12:19:59, 12.74s/it] 73%|███████▎  | 9342/12825 [33:21:35<12:19:16, 12.74s/it] 73%|███████▎  | 9343/12825 [33:21:48<12:18:35, 12.73s/it] 73%|███████▎  | 9344/12825 [33:22:00<12:17:34, 12.71s/it] 73%|███████▎  | 9345/12825 [33:22:13<12:16:31, 12.70s/it] 73%|███████▎  | 9346/12825 [33:22:26<12:16:16, 12.70s/it] 73%|███████▎  | 9347/12825 [33:22:39<12:16:51, 12.71s/it] 73%|███████▎  | 9348/12825 [33:22:51<12:17:03, 12.72s/it] 73%|███████▎  | 9349/12825 [33:23:04<12:18:56, 12.76s/it] 73%|███████▎  | 9350/12825 [33:23:17<12:19:53, 12.78s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120324.03lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103508.35lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9325] due to args.save_total_limit
 73%|███████▎  | 9351/12825 [33:23:30<12:25:20, 12.87s/it] 73%|███████▎  | 9352/12825 [33:23:43<12:22:10, 12.82s/it] 73%|███████▎  | 9353/12825 [33:23:56<12:21:16, 12.81s/it] 73%|███████▎  | 9354/12825 [33:24:08<12:19:58, 12.79s/it] 73%|███████▎  | 9355/12825 [33:24:21<12:18:08, 12.76s/it] 73%|███████▎  | 9356/12825 [33:24:34<12:19:04, 12.78s/it] 73%|███████▎  | 9357/12825 [33:24:47<12:20:07, 12.80s/it] 73%|███████▎  | 9358/12825 [33:25:07<14:31:03, 15.07s/it] 73%|███████▎  | 9359/12825 [33:25:20<13:50:12, 14.37s/it] 73%|███████▎  | 9360/12825 [33:25:33<13:21:25, 13.88s/it] 73%|███████▎  | 9361/12825 [33:25:45<13:00:48, 13.52s/it] 73%|███████▎  | 9362/12825 [33:25:58<12:47:04, 13.29s/it] 73%|███████▎  | 9363/12825 [33:26:11<12:36:54, 13.12s/it] 73%|███████▎  | 9364/12825 [33:26:23<12:29:42, 13.00s/it] 73%|███████▎  | 9365/12825 [33:26:36<12:25:20, 12.92s/it] 73%|███████▎  | 9366/12825 [33:26:49<12:23:06, 12.89s/it] 73%|███████▎  | 9367/12825 [33:27:02<12:21:08, 12.86s/it] 73%|███████▎  | 9368/12825 [33:27:14<12:18:01, 12.81s/it] 73%|███████▎  | 9369/12825 [33:27:27<12:16:34, 12.79s/it] 73%|███████▎  | 9370/12825 [33:27:40<12:15:25, 12.77s/it] 73%|███████▎  | 9371/12825 [33:27:53<12:15:57, 12.78s/it] 73%|███████▎  | 9372/12825 [33:28:05<12:15:11, 12.77s/it] 73%|███████▎  | 9373/12825 [33:28:18<12:14:33, 12.77s/it] 73%|███████▎  | 9374/12825 [33:28:31<12:13:05, 12.75s/it] 73%|███████▎  | 9375/12825 [33:28:44<12:12:00, 12.73s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120141.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 102703.86lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9350] due to args.save_total_limit
 73%|███████▎  | 9376/12825 [33:28:57<12:21:15, 12.90s/it] 73%|███████▎  | 9377/12825 [33:29:10<12:17:32, 12.83s/it] 73%|███████▎  | 9378/12825 [33:29:22<12:14:37, 12.79s/it] 73%|███████▎  | 9379/12825 [33:29:35<12:12:52, 12.76s/it] 73%|███████▎  | 9380/12825 [33:29:48<12:12:02, 12.75s/it] 73%|███████▎  | 9381/12825 [33:30:00<12:10:47, 12.73s/it] 73%|███████▎  | 9382/12825 [33:30:13<12:09:54, 12.72s/it] 73%|███████▎  | 9383/12825 [33:30:26<12:08:57, 12.71s/it] 73%|███████▎  | 9384/12825 [33:30:38<12:08:15, 12.70s/it] 73%|███████▎  | 9385/12825 [33:30:51<12:07:00, 12.68s/it] 73%|███████▎  | 9386/12825 [33:31:04<12:06:23, 12.67s/it] 73%|███████▎  | 9387/12825 [33:31:16<12:06:07, 12.67s/it] 73%|███████▎  | 9388/12825 [33:31:29<12:06:08, 12.68s/it] 73%|███████▎  | 9389/12825 [33:31:42<12:06:20, 12.68s/it] 73%|███████▎  | 9390/12825 [33:32:04<14:45:13, 15.46s/it] 73%|███████▎  | 9391/12825 [33:32:16<13:57:20, 14.63s/it] 73%|███████▎  | 9392/12825 [33:32:29<13:24:17, 14.06s/it] 73%|███████▎  | 9393/12825 [33:32:42<13:00:19, 13.64s/it] 73%|███████▎  | 9394/12825 [33:32:55<12:44:05, 13.36s/it] 73%|███████▎  | 9395/12825 [33:33:07<12:32:35, 13.16s/it] 73%|███████▎  | 9396/12825 [33:33:20<12:24:12, 13.02s/it] 73%|███████▎  | 9397/12825 [33:33:33<12:18:11, 12.92s/it] 73%|███████▎  | 9398/12825 [33:33:45<12:14:24, 12.86s/it] 73%|███████▎  | 9399/12825 [33:33:58<12:11:32, 12.81s/it] 73%|███████▎  | 9400/12825 [33:34:11<12:09:24, 12.78s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120381.59lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103479.60lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9375] due to args.save_total_limit
 73%|███████▎  | 9401/12825 [33:34:24<12:13:58, 12.86s/it] 73%|███████▎  | 9402/12825 [33:34:36<12:10:27, 12.80s/it] 73%|███████▎  | 9403/12825 [33:34:49<12:08:39, 12.78s/it] 73%|███████▎  | 9404/12825 [33:35:02<12:07:27, 12.76s/it] 73%|███████▎  | 9405/12825 [33:35:15<12:05:49, 12.73s/it] 73%|███████▎  | 9406/12825 [33:35:27<12:06:15, 12.74s/it] 73%|███████▎  | 9407/12825 [33:35:40<12:04:54, 12.73s/it] 73%|███████▎  | 9408/12825 [33:35:53<12:03:48, 12.71s/it] 73%|███████▎  | 9409/12825 [33:36:05<12:04:14, 12.72s/it] 73%|███████▎  | 9410/12825 [33:36:18<12:03:27, 12.71s/it] 73%|███████▎  | 9411/12825 [33:36:31<12:04:07, 12.73s/it] 73%|███████▎  | 9412/12825 [33:36:44<12:02:39, 12.70s/it] 73%|███████▎  | 9413/12825 [33:36:56<12:02:25, 12.70s/it] 73%|███████▎  | 9414/12825 [33:37:09<12:02:50, 12.71s/it] 73%|███████▎  | 9415/12825 [33:37:22<12:03:30, 12.73s/it] 73%|███████▎  | 9416/12825 [33:37:34<12:03:00, 12.73s/it] 73%|███████▎  | 9417/12825 [33:37:47<12:02:07, 12.71s/it] 73%|███████▎  | 9418/12825 [33:38:00<12:02:41, 12.73s/it] 73%|███████▎  | 9419/12825 [33:38:13<12:02:14, 12.72s/it] 73%|███████▎  | 9420/12825 [33:38:25<12:03:06, 12.74s/it] 73%|███████▎  | 9421/12825 [33:38:38<12:01:37, 12.72s/it] 73%|███████▎  | 9422/12825 [33:38:51<12:00:56, 12.71s/it] 73%|███████▎  | 9423/12825 [33:39:13<14:37:09, 15.47s/it] 73%|███████▎  | 9424/12825 [33:39:25<13:50:03, 14.64s/it] 73%|███████▎  | 9425/12825 [33:39:38<13:17:59, 14.08s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120445.60lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103695.54lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9400] due to args.save_total_limit
 73%|███████▎  | 9426/12825 [33:39:51<13:00:12, 13.77s/it] 74%|███████▎  | 9427/12825 [33:40:04<12:42:48, 13.47s/it] 74%|███████▎  | 9428/12825 [33:40:17<12:29:25, 13.24s/it] 74%|███████▎  | 9429/12825 [33:40:29<12:20:11, 13.08s/it] 74%|███████▎  | 9430/12825 [33:40:42<12:13:43, 12.97s/it] 74%|███████▎  | 9431/12825 [33:40:55<12:11:10, 12.93s/it] 74%|███████▎  | 9432/12825 [33:41:08<12:07:19, 12.86s/it] 74%|███████▎  | 9433/12825 [33:41:20<12:07:21, 12.87s/it] 74%|███████▎  | 9434/12825 [33:41:33<12:04:20, 12.82s/it] 74%|███████▎  | 9435/12825 [33:41:46<12:04:05, 12.82s/it] 74%|███████▎  | 9436/12825 [33:41:59<12:03:49, 12.81s/it] 74%|███████▎  | 9437/12825 [33:42:12<12:04:08, 12.82s/it] 74%|███████▎  | 9438/12825 [33:42:24<12:04:00, 12.83s/it] 74%|███████▎  | 9439/12825 [33:42:37<12:04:04, 12.83s/it] 74%|███████▎  | 9440/12825 [33:42:50<12:01:39, 12.79s/it] 74%|███████▎  | 9441/12825 [33:43:03<12:01:50, 12.80s/it] 74%|███████▎  | 9442/12825 [33:43:16<12:01:35, 12.80s/it] 74%|███████▎  | 9443/12825 [33:43:28<12:01:35, 12.80s/it] 74%|███████▎  | 9444/12825 [33:43:41<12:00:07, 12.78s/it] 74%|███████▎  | 9445/12825 [33:43:54<12:00:41, 12.79s/it] 74%|███████▎  | 9446/12825 [33:44:07<11:59:40, 12.78s/it] 74%|███████▎  | 9447/12825 [33:44:20<12:00:51, 12.80s/it] 74%|███████▎  | 9448/12825 [33:44:32<11:58:43, 12.77s/it] 74%|███████▎  | 9449/12825 [33:44:45<11:58:22, 12.77s/it] 74%|███████▎  | 9450/12825 [33:44:58<11:57:09, 12.75s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120347.17lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103593.47lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9425] due to args.save_total_limit
 74%|███████▎  | 9451/12825 [33:45:11<12:02:27, 12.85s/it] 74%|███████▎  | 9452/12825 [33:45:24<12:01:28, 12.83s/it] 74%|███████▎  | 9453/12825 [33:45:36<12:00:08, 12.81s/it] 74%|███████▎  | 9454/12825 [33:45:49<12:00:14, 12.82s/it] 74%|███████▎  | 9455/12825 [33:46:11<14:32:00, 15.53s/it] 74%|███████▎  | 9456/12825 [33:46:24<13:45:52, 14.71s/it] 74%|███████▎  | 9457/12825 [33:46:37<13:13:49, 14.14s/it] 74%|███████▎  | 9458/12825 [33:46:50<12:51:17, 13.74s/it] 74%|███████▍  | 9459/12825 [33:47:02<12:33:19, 13.43s/it] 74%|███████▍  | 9460/12825 [33:47:15<12:22:41, 13.24s/it] 74%|███████▍  | 9461/12825 [33:47:28<12:15:57, 13.13s/it] 74%|███████▍  | 9462/12825 [33:47:41<12:09:55, 13.02s/it] 74%|███████▍  | 9463/12825 [33:47:54<12:07:01, 12.97s/it] 74%|███████▍  | 9464/12825 [33:48:06<12:03:08, 12.91s/it] 74%|███████▍  | 9465/12825 [33:48:19<12:01:54, 12.89s/it] 74%|███████▍  | 9466/12825 [33:48:32<11:59:04, 12.84s/it] 74%|███████▍  | 9467/12825 [33:48:45<11:58:28, 12.84s/it] 74%|███████▍  | 9468/12825 [33:48:57<11:55:59, 12.80s/it] 74%|███████▍  | 9469/12825 [33:49:10<11:56:24, 12.81s/it] 74%|███████▍  | 9470/12825 [33:49:23<11:55:58, 12.80s/it] 74%|███████▍  | 9471/12825 [33:49:36<11:56:20, 12.81s/it] 74%|███████▍  | 9472/12825 [33:49:49<11:56:08, 12.82s/it] 74%|███████▍  | 9473/12825 [33:50:01<11:55:21, 12.80s/it] 74%|███████▍  | 9474/12825 [33:50:14<11:55:07, 12.80s/it] 74%|███████▍  | 9475/12825 [33:50:27<11:54:16, 12.79s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120271.38lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103445.19lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9450] due to args.save_total_limit
 74%|███████▍  | 9476/12825 [33:50:40<11:59:45, 12.90s/it] 74%|███████▍  | 9477/12825 [33:50:53<11:58:25, 12.88s/it] 74%|███████▍  | 9478/12825 [33:51:06<11:57:49, 12.87s/it] 74%|███████▍  | 9479/12825 [33:51:19<11:55:21, 12.83s/it] 74%|███████▍  | 9480/12825 [33:51:31<11:55:36, 12.84s/it] 74%|███████▍  | 9481/12825 [33:51:44<11:53:24, 12.80s/it] 74%|███████▍  | 9482/12825 [33:51:57<11:52:23, 12.79s/it] 74%|███████▍  | 9483/12825 [33:52:10<11:50:45, 12.76s/it] 74%|███████▍  | 9484/12825 [33:52:22<11:49:50, 12.75s/it] 74%|███████▍  | 9485/12825 [33:52:35<11:48:53, 12.73s/it] 74%|███████▍  | 9486/12825 [33:52:48<11:50:24, 12.77s/it] 74%|███████▍  | 9487/12825 [33:53:01<11:49:32, 12.75s/it] 74%|███████▍  | 9488/12825 [33:53:24<14:43:14, 15.88s/it] 74%|███████▍  | 9489/12825 [33:53:37<13:51:32, 14.96s/it] 74%|███████▍  | 9490/12825 [33:53:49<13:14:02, 14.29s/it] 74%|███████▍  | 9491/12825 [33:54:02<12:48:18, 13.83s/it] 74%|███████▍  | 9492/12825 [33:54:15<12:29:37, 13.49s/it] 74%|███████▍  | 9493/12825 [33:54:28<12:18:20, 13.30s/it] 74%|███████▍  | 9494/12825 [33:54:40<12:11:06, 13.17s/it] 74%|███████▍  | 9495/12825 [33:54:53<12:03:30, 13.04s/it] 74%|███████▍  | 9496/12825 [33:55:06<12:00:07, 12.98s/it] 74%|███████▍  | 9497/12825 [33:55:19<11:55:05, 12.89s/it] 74%|███████▍  | 9498/12825 [33:55:31<11:52:15, 12.85s/it] 74%|███████▍  | 9499/12825 [33:55:44<11:50:02, 12.81s/it] 74%|███████▍  | 9500/12825 [33:55:57<11:47:17, 12.76s/it]                                                           74%|███████▍  | 9500/12825 [33:55:57<11:47:17, 12.76s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120326.97lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103536.36lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9475] due to args.save_total_limit
 74%|███████▍  | 9501/12825 [33:56:10<11:49:55, 12.81s/it] 74%|███████▍  | 9502/12825 [33:56:22<11:45:02, 12.73s/it] 74%|███████▍  | 9503/12825 [33:56:35<11:43:48, 12.71s/it] 74%|███████▍  | 9504/12825 [33:56:48<11:41:34, 12.68s/it] 74%|███████▍  | 9505/12825 [33:57:00<11:39:40, 12.64s/it] 74%|███████▍  | 9506/12825 [33:57:13<11:40:05, 12.66s/it] 74%|███████▍  | 9507/12825 [33:57:25<11:38:20, 12.63s/it] 74%|███████▍  | 9508/12825 [33:57:38<11:37:46, 12.62s/it] 74%|███████▍  | 9509/12825 [33:57:51<11:38:36, 12.64s/it] 74%|███████▍  | 9510/12825 [33:58:03<11:37:26, 12.62s/it] 74%|███████▍  | 9511/12825 [33:58:16<11:39:02, 12.66s/it] 74%|███████▍  | 9512/12825 [33:58:29<11:38:28, 12.65s/it] 74%|███████▍  | 9513/12825 [33:58:41<11:38:11, 12.65s/it] 74%|███████▍  | 9514/12825 [33:58:54<11:37:20, 12.64s/it] 74%|███████▍  | 9515/12825 [33:59:07<11:38:24, 12.66s/it] 74%|███████▍  | 9516/12825 [33:59:19<11:38:04, 12.66s/it] 74%|███████▍  | 9517/12825 [33:59:32<11:37:34, 12.65s/it] 74%|███████▍  | 9518/12825 [33:59:44<11:35:34, 12.62s/it] 74%|███████▍  | 9519/12825 [33:59:57<11:34:57, 12.61s/it] 74%|███████▍  | 9520/12825 [34:00:18<14:00:48, 15.26s/it] 74%|███████▍  | 9521/12825 [34:00:31<13:17:18, 14.48s/it] 74%|███████▍  | 9522/12825 [34:00:44<12:45:38, 13.91s/it] 74%|███████▍  | 9523/12825 [34:00:56<12:22:41, 13.50s/it] 74%|███████▍  | 9524/12825 [34:01:09<12:09:27, 13.26s/it] 74%|███████▍  | 9525/12825 [34:01:22<11:58:23, 13.06s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120340.52lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103653.97lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9500] due to args.save_total_limit
 74%|███████▍  | 9526/12825 [34:01:35<11:57:16, 13.05s/it] 74%|███████▍  | 9527/12825 [34:01:47<11:50:11, 12.92s/it] 74%|███████▍  | 9528/12825 [34:02:00<11:46:21, 12.85s/it] 74%|███████▍  | 9529/12825 [34:02:13<11:43:08, 12.80s/it] 74%|███████▍  | 9530/12825 [34:02:25<11:41:12, 12.77s/it] 74%|███████▍  | 9531/12825 [34:02:38<11:38:18, 12.72s/it] 74%|███████▍  | 9532/12825 [34:02:51<11:37:50, 12.72s/it] 74%|███████▍  | 9533/12825 [34:03:03<11:36:00, 12.69s/it] 74%|███████▍  | 9534/12825 [34:03:16<11:35:34, 12.68s/it] 74%|███████▍  | 9535/12825 [34:03:28<11:35:06, 12.68s/it] 74%|███████▍  | 9536/12825 [34:03:41<11:33:14, 12.65s/it] 74%|███████▍  | 9537/12825 [34:03:54<11:33:52, 12.66s/it] 74%|███████▍  | 9538/12825 [34:04:06<11:34:45, 12.68s/it] 74%|███████▍  | 9539/12825 [34:04:19<11:34:20, 12.68s/it] 74%|███████▍  | 9540/12825 [34:04:32<11:34:13, 12.68s/it] 74%|███████▍  | 9541/12825 [34:04:45<11:34:17, 12.68s/it] 74%|███████▍  | 9542/12825 [34:04:57<11:33:26, 12.67s/it] 74%|███████▍  | 9543/12825 [34:05:10<11:33:02, 12.67s/it] 74%|███████▍  | 9544/12825 [34:05:23<11:32:54, 12.67s/it] 74%|███████▍  | 9545/12825 [34:05:35<11:33:05, 12.68s/it] 74%|███████▍  | 9546/12825 [34:05:48<11:31:53, 12.66s/it] 74%|███████▍  | 9547/12825 [34:06:01<11:31:51, 12.66s/it] 74%|███████▍  | 9548/12825 [34:06:13<11:31:36, 12.66s/it] 74%|███████▍  | 9549/12825 [34:06:26<11:31:27, 12.66s/it] 74%|███████▍  | 9550/12825 [34:06:39<11:32:03, 12.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120535.85lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 99531.82lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9525] due to args.save_total_limit
 74%|███████▍  | 9551/12825 [34:06:52<11:40:11, 12.83s/it] 74%|███████▍  | 9552/12825 [34:07:13<14:01:23, 15.42s/it] 74%|███████▍  | 9553/12825 [34:07:26<13:13:43, 14.55s/it] 74%|███████▍  | 9554/12825 [34:07:38<12:43:39, 14.01s/it] 75%|███████▍  | 9555/12825 [34:07:51<12:22:41, 13.63s/it] 75%|███████▍  | 9556/12825 [34:08:04<12:07:42, 13.36s/it] 75%|███████▍  | 9557/12825 [34:08:17<11:57:45, 13.18s/it] 75%|███████▍  | 9558/12825 [34:08:29<11:48:33, 13.01s/it] 75%|███████▍  | 9559/12825 [34:08:42<11:43:00, 12.92s/it] 75%|███████▍  | 9560/12825 [34:08:55<11:37:55, 12.83s/it] 75%|███████▍  | 9561/12825 [34:09:07<11:36:12, 12.80s/it] 75%|███████▍  | 9562/12825 [34:09:20<11:34:44, 12.77s/it] 75%|███████▍  | 9563/12825 [34:09:33<11:32:13, 12.73s/it] 75%|███████▍  | 9564/12825 [34:09:45<11:32:15, 12.74s/it] 75%|███████▍  | 9565/12825 [34:09:58<11:30:57, 12.72s/it] 75%|███████▍  | 9566/12825 [34:10:11<11:29:35, 12.70s/it] 75%|███████▍  | 9567/12825 [34:10:24<11:29:48, 12.70s/it] 75%|███████▍  | 9568/12825 [34:10:36<11:28:17, 12.68s/it] 75%|███████▍  | 9569/12825 [34:10:49<11:28:41, 12.69s/it] 75%|███████▍  | 9570/12825 [34:11:02<11:28:44, 12.70s/it] 75%|███████▍  | 9571/12825 [34:11:14<11:27:54, 12.68s/it] 75%|███████▍  | 9572/12825 [34:11:27<11:26:30, 12.66s/it] 75%|███████▍  | 9573/12825 [34:11:39<11:25:36, 12.65s/it] 75%|███████▍  | 9574/12825 [34:11:52<11:26:46, 12.68s/it] 75%|███████▍  | 9575/12825 [34:12:05<11:27:41, 12.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120168.64lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103435.74lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9550] due to args.save_total_limit
 75%|███████▍  | 9576/12825 [34:12:18<11:32:32, 12.79s/it] 75%|███████▍  | 9577/12825 [34:12:31<11:29:36, 12.74s/it] 75%|███████▍  | 9578/12825 [34:12:43<11:28:01, 12.71s/it] 75%|███████▍  | 9579/12825 [34:12:56<11:25:38, 12.67s/it] 75%|███████▍  | 9580/12825 [34:13:08<11:26:01, 12.68s/it] 75%|███████▍  | 9581/12825 [34:13:21<11:24:03, 12.65s/it] 75%|███████▍  | 9582/12825 [34:13:34<11:23:13, 12.64s/it] 75%|███████▍  | 9583/12825 [34:13:46<11:21:40, 12.62s/it] 75%|███████▍  | 9584/12825 [34:13:59<11:22:19, 12.63s/it] 75%|███████▍  | 9585/12825 [34:14:20<13:45:00, 15.28s/it] 75%|███████▍  | 9586/12825 [34:14:33<13:01:38, 14.48s/it] 75%|███████▍  | 9587/12825 [34:14:46<12:30:21, 13.90s/it] 75%|███████▍  | 9588/12825 [34:14:58<12:10:29, 13.54s/it] 75%|███████▍  | 9589/12825 [34:15:11<11:55:31, 13.27s/it] 75%|███████▍  | 9590/12825 [34:15:23<11:44:24, 13.06s/it] 75%|███████▍  | 9591/12825 [34:15:36<11:37:00, 12.93s/it] 75%|███████▍  | 9592/12825 [34:15:49<11:32:16, 12.85s/it] 75%|███████▍  | 9593/12825 [34:16:01<11:28:25, 12.78s/it] 75%|███████▍  | 9594/12825 [34:16:14<11:26:42, 12.75s/it] 75%|███████▍  | 9595/12825 [34:16:27<11:24:36, 12.72s/it] 75%|███████▍  | 9596/12825 [34:16:39<11:23:25, 12.70s/it] 75%|███████▍  | 9597/12825 [34:16:52<11:22:00, 12.68s/it] 75%|███████▍  | 9598/12825 [34:17:05<11:21:07, 12.66s/it] 75%|███████▍  | 9599/12825 [34:17:17<11:22:16, 12.69s/it] 75%|███████▍  | 9600/12825 [34:17:30<11:22:53, 12.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120278.41lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103411.56lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9575] due to args.save_total_limit
 75%|███████▍  | 9601/12825 [34:17:43<11:28:33, 12.81s/it] 75%|███████▍  | 9602/12825 [34:17:56<11:27:21, 12.80s/it] 75%|███████▍  | 9603/12825 [34:18:09<11:24:30, 12.75s/it] 75%|███████▍  | 9604/12825 [34:18:21<11:23:16, 12.73s/it] 75%|███████▍  | 9605/12825 [34:18:34<11:21:12, 12.69s/it] 75%|███████▍  | 9606/12825 [34:18:47<11:21:34, 12.70s/it] 75%|███████▍  | 9607/12825 [34:18:59<11:21:18, 12.70s/it] 75%|███████▍  | 9608/12825 [34:19:12<11:20:57, 12.70s/it] 75%|███████▍  | 9609/12825 [34:19:25<11:20:05, 12.69s/it] 75%|███████▍  | 9610/12825 [34:19:37<11:19:56, 12.69s/it] 75%|███████▍  | 9611/12825 [34:19:50<11:20:24, 12.70s/it] 75%|███████▍  | 9612/12825 [34:20:03<11:20:41, 12.71s/it] 75%|███████▍  | 9613/12825 [34:20:15<11:20:40, 12.72s/it] 75%|███████▍  | 9614/12825 [34:20:28<11:21:43, 12.74s/it] 75%|███████▍  | 9615/12825 [34:20:41<11:19:51, 12.71s/it] 75%|███████▍  | 9616/12825 [34:20:54<11:20:51, 12.73s/it] 75%|███████▍  | 9617/12825 [34:21:15<13:41:48, 15.37s/it] 75%|███████▍  | 9618/12825 [34:21:28<12:57:48, 14.55s/it] 75%|███████▌  | 9619/12825 [34:21:41<12:27:01, 13.98s/it] 75%|███████▌  | 9620/12825 [34:21:53<12:07:46, 13.62s/it] 75%|███████▌  | 9621/12825 [34:22:06<11:53:47, 13.37s/it] 75%|███████▌  | 9622/12825 [34:22:19<11:42:09, 13.15s/it] 75%|███████▌  | 9623/12825 [34:22:31<11:33:19, 12.99s/it] 75%|███████▌  | 9624/12825 [34:22:44<11:28:36, 12.91s/it] 75%|███████▌  | 9625/12825 [34:22:57<11:24:25, 12.83s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120190.45lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103537.59lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9600] due to args.save_total_limit
 75%|███████▌  | 9626/12825 [34:23:10<11:26:35, 12.88s/it] 75%|███████▌  | 9627/12825 [34:23:22<11:22:57, 12.81s/it] 75%|███████▌  | 9628/12825 [34:23:35<11:19:53, 12.76s/it] 75%|███████▌  | 9629/12825 [34:23:48<11:17:43, 12.72s/it] 75%|███████▌  | 9630/12825 [34:24:00<11:16:29, 12.70s/it] 75%|███████▌  | 9631/12825 [34:24:13<11:14:55, 12.68s/it] 75%|███████▌  | 9632/12825 [34:24:26<11:15:07, 12.69s/it] 75%|███████▌  | 9633/12825 [34:24:38<11:14:05, 12.67s/it] 75%|███████▌  | 9634/12825 [34:24:51<11:13:14, 12.66s/it] 75%|███████▌  | 9635/12825 [34:25:04<11:14:34, 12.69s/it] 75%|███████▌  | 9636/12825 [34:25:16<11:13:05, 12.66s/it] 75%|███████▌  | 9637/12825 [34:25:29<11:12:19, 12.65s/it] 75%|███████▌  | 9638/12825 [34:25:42<11:12:32, 12.66s/it] 75%|███████▌  | 9639/12825 [34:25:54<11:11:36, 12.65s/it] 75%|███████▌  | 9640/12825 [34:26:07<11:10:46, 12.64s/it] 75%|███████▌  | 9641/12825 [34:26:19<11:09:58, 12.63s/it] 75%|███████▌  | 9642/12825 [34:26:32<11:12:16, 12.67s/it] 75%|███████▌  | 9643/12825 [34:26:45<11:11:52, 12.67s/it] 75%|███████▌  | 9644/12825 [34:26:57<11:10:13, 12.64s/it] 75%|███████▌  | 9645/12825 [34:27:10<11:09:49, 12.64s/it] 75%|███████▌  | 9646/12825 [34:27:23<11:09:34, 12.64s/it] 75%|███████▌  | 9647/12825 [34:27:35<11:08:46, 12.63s/it] 75%|███████▌  | 9648/12825 [34:27:48<11:09:18, 12.64s/it] 75%|███████▌  | 9649/12825 [34:28:09<13:16:30, 15.05s/it] 75%|███████▌  | 9650/12825 [34:28:21<12:38:31, 14.33s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120312.01lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 102804.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9625] due to args.save_total_limit
 75%|███████▌  | 9651/12825 [34:28:34<12:17:08, 13.93s/it] 75%|███████▌  | 9652/12825 [34:28:47<11:56:19, 13.55s/it] 75%|███████▌  | 9653/12825 [34:29:00<11:41:50, 13.28s/it] 75%|███████▌  | 9654/12825 [34:29:12<11:30:20, 13.06s/it] 75%|███████▌  | 9655/12825 [34:29:25<11:22:46, 12.92s/it] 75%|███████▌  | 9656/12825 [34:29:37<11:16:57, 12.82s/it] 75%|███████▌  | 9657/12825 [34:29:50<11:13:28, 12.76s/it] 75%|███████▌  | 9658/12825 [34:30:03<11:11:00, 12.71s/it] 75%|███████▌  | 9659/12825 [34:30:15<11:09:36, 12.69s/it] 75%|███████▌  | 9660/12825 [34:30:28<11:08:42, 12.68s/it] 75%|███████▌  | 9661/12825 [34:30:40<11:07:37, 12.66s/it] 75%|███████▌  | 9662/12825 [34:30:53<11:06:27, 12.64s/it] 75%|███████▌  | 9663/12825 [34:31:06<11:06:13, 12.64s/it] 75%|███████▌  | 9664/12825 [34:31:18<11:05:05, 12.62s/it] 75%|███████▌  | 9665/12825 [34:31:31<11:04:14, 12.61s/it] 75%|███████▌  | 9666/12825 [34:31:43<11:04:17, 12.62s/it] 75%|███████▌  | 9667/12825 [34:31:56<11:03:46, 12.61s/it] 75%|███████▌  | 9668/12825 [34:32:09<11:03:56, 12.62s/it] 75%|███████▌  | 9669/12825 [34:32:21<11:03:20, 12.61s/it] 75%|███████▌  | 9670/12825 [34:32:34<11:02:57, 12.61s/it] 75%|███████▌  | 9671/12825 [34:32:46<11:02:22, 12.60s/it] 75%|███████▌  | 9672/12825 [34:32:59<11:02:07, 12.60s/it] 75%|███████▌  | 9673/12825 [34:33:12<11:01:58, 12.60s/it] 75%|███████▌  | 9674/12825 [34:33:24<11:02:25, 12.61s/it] 75%|███████▌  | 9675/12825 [34:33:37<11:01:41, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120373.65lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103607.88lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9650] due to args.save_total_limit
 75%|███████▌  | 9676/12825 [34:33:50<11:06:19, 12.70s/it] 75%|███████▌  | 9677/12825 [34:34:02<11:04:18, 12.66s/it] 75%|███████▌  | 9678/12825 [34:34:15<11:04:01, 12.66s/it] 75%|███████▌  | 9679/12825 [34:34:28<11:03:09, 12.65s/it] 75%|███████▌  | 9680/12825 [34:34:40<11:02:55, 12.65s/it] 75%|███████▌  | 9681/12825 [34:34:53<11:02:03, 12.63s/it] 75%|███████▌  | 9682/12825 [34:35:14<13:07:02, 15.02s/it] 76%|███████▌  | 9683/12825 [34:35:26<12:29:04, 14.30s/it] 76%|███████▌  | 9684/12825 [34:35:39<12:02:20, 13.80s/it] 76%|███████▌  | 9685/12825 [34:35:51<11:43:53, 13.45s/it] 76%|███████▌  | 9686/12825 [34:36:04<11:31:41, 13.22s/it] 76%|███████▌  | 9687/12825 [34:36:17<11:24:38, 13.09s/it] 76%|███████▌  | 9688/12825 [34:36:30<11:17:39, 12.96s/it] 76%|███████▌  | 9689/12825 [34:36:42<11:12:39, 12.87s/it] 76%|███████▌  | 9690/12825 [34:36:55<11:10:11, 12.83s/it] 76%|███████▌  | 9691/12825 [34:37:08<11:10:38, 12.84s/it] 76%|███████▌  | 9692/12825 [34:37:21<11:10:30, 12.84s/it] 76%|███████▌  | 9693/12825 [34:37:33<11:09:14, 12.82s/it] 76%|███████▌  | 9694/12825 [34:37:46<11:07:05, 12.78s/it] 76%|███████▌  | 9695/12825 [34:37:59<11:05:32, 12.76s/it] 76%|███████▌  | 9696/12825 [34:38:12<11:05:51, 12.77s/it] 76%|███████▌  | 9697/12825 [34:38:24<11:04:47, 12.75s/it] 76%|███████▌  | 9698/12825 [34:38:37<11:05:42, 12.77s/it] 76%|███████▌  | 9699/12825 [34:38:50<11:06:31, 12.79s/it] 76%|███████▌  | 9700/12825 [34:39:03<11:05:11, 12.77s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120257.71lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103507.21lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9675] due to args.save_total_limit
 76%|███████▌  | 9701/12825 [34:39:16<11:09:03, 12.85s/it] 76%|███████▌  | 9702/12825 [34:39:28<11:06:48, 12.81s/it] 76%|███████▌  | 9703/12825 [34:39:41<11:04:43, 12.78s/it] 76%|███████▌  | 9704/12825 [34:39:54<11:03:46, 12.76s/it] 76%|███████▌  | 9705/12825 [34:40:06<11:00:59, 12.71s/it] 76%|███████▌  | 9706/12825 [34:40:19<10:59:15, 12.68s/it] 76%|███████▌  | 9707/12825 [34:40:32<10:58:00, 12.66s/it] 76%|███████▌  | 9708/12825 [34:40:44<10:57:12, 12.65s/it] 76%|███████▌  | 9709/12825 [34:40:57<10:56:09, 12.63s/it] 76%|███████▌  | 9710/12825 [34:41:10<10:55:53, 12.63s/it] 76%|███████▌  | 9711/12825 [34:41:22<10:55:22, 12.63s/it] 76%|███████▌  | 9712/12825 [34:41:35<10:55:07, 12.63s/it] 76%|███████▌  | 9713/12825 [34:41:47<10:54:19, 12.62s/it] 76%|███████▌  | 9714/12825 [34:42:08<12:57:27, 14.99s/it] 76%|███████▌  | 9715/12825 [34:42:21<12:21:03, 14.30s/it] 76%|███████▌  | 9716/12825 [34:42:33<11:54:35, 13.79s/it] 76%|███████▌  | 9717/12825 [34:42:46<11:35:52, 13.43s/it] 76%|███████▌  | 9718/12825 [34:42:58<11:22:07, 13.17s/it] 76%|███████▌  | 9719/12825 [34:43:11<11:14:00, 13.02s/it] 76%|███████▌  | 9720/12825 [34:43:24<11:08:26, 12.92s/it] 76%|███████▌  | 9721/12825 [34:43:36<11:03:20, 12.82s/it] 76%|███████▌  | 9722/12825 [34:43:49<11:00:57, 12.78s/it] 76%|███████▌  | 9723/12825 [34:44:02<10:58:19, 12.73s/it] 76%|███████▌  | 9724/12825 [34:44:14<10:56:39, 12.71s/it] 76%|███████▌  | 9725/12825 [34:44:27<10:55:10, 12.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120245.97lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103422.23lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9725
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9725/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9725/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/tmp-checkpoint-9725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-both-22-and-23-ast/checkpoint-9700] due to args.save_total_limit
 76%|███████▌  | 9726/12825 [34:44:40<10:58:00, 12.74s/it] 76%|███████▌  | 9727/12825 [34:44:52<10:57:21, 12.73s/it] 76%|███████▌  | 9728/12825 [34:45:05<10:55:22, 12.70s/it]slurmstepd: error: *** JOB 52507595 ON gpu-q-58 CANCELLED AT 2024-05-17T03:21:17 DUE TO TIME LIMIT ***
