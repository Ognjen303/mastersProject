Map (num_proc=32):   0%|          | 0/33590720 [00:00<?, ? examples/s]Map (num_proc=32):   0%|          | 4000/33590720 [00:04<10:15:15, 909.82 examples/s]Map (num_proc=32):   0%|          | 32000/33590720 [00:04<57:55, 9656.80 examples/s] Map (num_proc=32):   0%|          | 48000/33590720 [00:04<36:13, 15434.56 examples/s]Map (num_proc=32):   0%|          | 60000/33590720 [00:04<27:07, 20604.09 examples/s]Map (num_proc=32):   0%|          | 72000/33590720 [00:05<20:54, 26716.02 examples/s]Map (num_proc=32):   0%|          | 84000/33590720 [00:05<16:38, 33544.39 examples/s]Map (num_proc=32):   0%|          | 96000/33590720 [00:05<13:42, 40706.48 examples/s]Map (num_proc=32):   0%|          | 108000/33590720 [00:05<11:40, 47781.15 examples/s]Map (num_proc=32):   0%|          | 120000/33590720 [00:05<10:20, 53915.93 examples/s]Map (num_proc=32):   0%|          | 132000/33590720 [00:05<09:21, 59638.83 examples/s]Map (num_proc=32):   0%|          | 144000/33590720 [00:05<08:39, 64408.97 examples/s]Map (num_proc=32):   0%|          | 156000/33590720 [00:07<21:53, 25464.29 examples/s]Map (num_proc=32):   1%|          | 168000/33590720 [00:07<18:29, 30126.52 examples/s]Map (num_proc=32):   1%|          | 176000/33590720 [00:07<15:56, 34920.47 examples/s]Map (num_proc=32):   1%|          | 298000/33590720 [00:07<03:10, 175212.84 examples/s]Map (num_proc=32):   1%|          | 334000/33590720 [00:07<03:12, 172688.44 examples/s]Map (num_proc=32):   1%|          | 367000/33590720 [00:07<03:16, 169266.78 examples/s]Map (num_proc=32):   1%|          | 395000/33590720 [00:08<03:23, 163234.08 examples/s]Map (num_proc=32):   1%|▏         | 421000/33590720 [00:08<03:23, 162964.62 examples/s]Map (num_proc=32):   1%|▏         | 445000/33590720 [00:08<03:24, 161871.94 examples/s]Map (num_proc=32):   1%|▏         | 466000/33590720 [00:08<03:23, 162754.80 examples/s]Map (num_proc=32):   1%|▏         | 486000/33590720 [00:08<03:26, 160394.43 examples/s]Map (num_proc=32):   2%|▏         | 506000/33590720 [00:08<03:24, 161560.02 examples/s]Map (num_proc=32):   2%|▏         | 526000/33590720 [00:08<03:28, 158671.68 examples/s]Map (num_proc=32):   2%|▏         | 546000/33590720 [00:10<11:18, 48723.48 examples/s] Map (num_proc=32):   2%|▏         | 562000/33590720 [00:10<11:03, 49785.42 examples/s]Map (num_proc=32):   2%|▏         | 801000/33590720 [00:10<02:00, 272471.33 examples/s]Map (num_proc=32):   3%|▎         | 874000/33590720 [00:10<02:04, 263160.19 examples/s]Map (num_proc=32):   3%|▎         | 935000/33590720 [00:11<02:06, 257733.14 examples/s]Map (num_proc=32):   3%|▎         | 984000/33590720 [00:11<02:08, 253977.38 examples/s]Map (num_proc=32):   3%|▎         | 1028000/33590720 [00:11<02:09, 250554.19 examples/s]Map (num_proc=32):   3%|▎         | 1064000/33590720 [00:11<02:11, 247534.68 examples/s]Map (num_proc=32):   3%|▎         | 1101000/33590720 [00:11<02:13, 242785.03 examples/s]Map (num_proc=32):   3%|▎         | 1133000/33590720 [00:11<02:16, 237171.05 examples/s]Map (num_proc=32):   3%|▎         | 1161000/33590720 [00:12<05:16, 102523.44 examples/s]Map (num_proc=32):   4%|▎         | 1181000/33590720 [00:13<07:33, 71538.93 examples/s] Map (num_proc=32):   5%|▍         | 1540000/33590720 [00:13<01:26, 368889.45 examples/s]Map (num_proc=32):   5%|▍         | 1658000/33590720 [00:13<01:30, 352569.52 examples/s]Map (num_proc=32):   5%|▌         | 1751000/33590720 [00:14<01:33, 340924.27 examples/s]Map (num_proc=32):   5%|▌         | 1825000/33590720 [00:14<01:33, 341054.24 examples/s]Map (num_proc=32):   6%|▌         | 1890000/33590720 [00:14<01:34, 334327.20 examples/s]Map (num_proc=32):   6%|▌         | 1943000/33590720 [00:14<01:34, 335819.85 examples/s]Map (num_proc=32):   6%|▌         | 1991000/33590720 [00:14<01:35, 332187.46 examples/s]Map (num_proc=32):   6%|▌         | 2035000/33590720 [00:16<04:22, 120280.35 examples/s]Map (num_proc=32):   6%|▌         | 2069000/33590720 [00:16<04:24, 119334.42 examples/s]Map (num_proc=32):   8%|▊         | 2527000/33590720 [00:16<01:01, 503670.01 examples/s]Map (num_proc=32):   8%|▊         | 2681000/33590720 [00:16<01:05, 468974.32 examples/s]Map (num_proc=32):   8%|▊         | 2802000/33590720 [00:17<01:08, 449583.57 examples/s]Map (num_proc=32):   9%|▊         | 2897710/33590720 [00:17<01:11, 426367.23 examples/s]Map (num_proc=32):   9%|▉         | 2977710/33590720 [00:17<01:17, 396497.10 examples/s]Map (num_proc=32):   9%|▉         | 3041710/33590720 [00:17<01:20, 378056.36 examples/s]Map (num_proc=32):   9%|▉         | 3097710/33590720 [00:19<03:44, 135713.03 examples/s]Map (num_proc=32):  10%|▉         | 3201710/33590720 [00:20<04:19, 116900.00 examples/s]Map (num_proc=32):  12%|█▏        | 3955710/33590720 [00:20<01:00, 492943.81 examples/s]Map (num_proc=32):  12%|█▏        | 4190420/33590720 [00:22<01:45, 279814.34 examples/s]Map (num_proc=32):  13%|█▎        | 4359420/33590720 [00:23<02:02, 238027.79 examples/s]Map (num_proc=32):  15%|█▍        | 4958420/33590720 [00:23<01:01, 468999.80 examples/s]Map (num_proc=32):  16%|█▌        | 5217130/33590720 [00:25<01:34, 300477.01 examples/s]Map (num_proc=32):  16%|█▌        | 5403130/33590720 [00:26<01:48, 260219.69 examples/s]Map (num_proc=32):  18%|█▊        | 5954130/33590720 [00:26<01:00, 459447.98 examples/s]Map (num_proc=32):  18%|█▊        | 6208840/33590720 [00:28<01:34, 290163.62 examples/s]Map (num_proc=32):  19%|█▉        | 6436840/33590720 [00:29<01:42, 265985.47 examples/s]Map (num_proc=32):  21%|██        | 7022840/33590720 [00:30<00:56, 469532.07 examples/s]Map (num_proc=32):  22%|██▏       | 7277550/33590720 [00:31<01:26, 305342.29 examples/s]Map (num_proc=32):  22%|██▏       | 7509550/33590720 [00:33<01:33, 278599.77 examples/s]Map (num_proc=32):  24%|██▍       | 8034550/33590720 [00:33<00:55, 459897.54 examples/s]Map (num_proc=32):  25%|██▍       | 8270550/33590720 [00:34<01:25, 296452.19 examples/s]Map (num_proc=32):  26%|██▌       | 8658260/33590720 [00:36<01:19, 313784.27 examples/s]Map (num_proc=32):  27%|██▋       | 9106260/33590720 [00:36<00:52, 466790.52 examples/s]Map (num_proc=32):  28%|██▊       | 9324970/33590720 [00:38<01:25, 283976.87 examples/s]Map (num_proc=32):  29%|██▊       | 9605970/33590720 [00:39<01:26, 276044.70 examples/s]Map (num_proc=32):  30%|███       | 10190970/33590720 [00:39<00:49, 473259.18 examples/s]Map (num_proc=32):  31%|███       | 10416680/33590720 [00:41<01:16, 302516.98 examples/s]Map (num_proc=32):  32%|███▏      | 10654680/33590720 [00:42<01:22, 278831.74 examples/s]Map (num_proc=32):  33%|███▎      | 11216680/33590720 [00:42<00:47, 472680.64 examples/s]Map (num_proc=32):  34%|███▍      | 11448390/33590720 [00:44<01:14, 296124.51 examples/s]Map (num_proc=32):  35%|███▍      | 11665390/33590720 [00:45<01:21, 267703.80 examples/s]Map (num_proc=32):  36%|███▋      | 12257390/33590720 [00:45<00:45, 472654.50 examples/s]Map (num_proc=32):  37%|███▋      | 12516100/33590720 [00:47<01:08, 309560.20 examples/s]Map (num_proc=32):  38%|███▊      | 12782100/33590720 [00:48<01:11, 290483.70 examples/s]Map (num_proc=32):  40%|███▉      | 13275100/33590720 [00:48<00:44, 461219.55 examples/s]Map (num_proc=32):  40%|████      | 13519100/33590720 [00:50<01:10, 283161.06 examples/s]Map (num_proc=32):  42%|████▏     | 13985810/33590720 [00:51<01:01, 316363.82 examples/s]Map (num_proc=32):  43%|████▎     | 14424810/33590720 [00:51<00:42, 456257.40 examples/s]Map (num_proc=32):  44%|████▎     | 14633520/33590720 [00:53<01:05, 290978.65 examples/s]Map (num_proc=32):  44%|████▍     | 14862520/33590720 [00:54<01:11, 262855.21 examples/s]Map (num_proc=32):  46%|████▌     | 15479520/33590720 [00:55<00:38, 469836.07 examples/s]Map (num_proc=32):  47%|████▋     | 15717230/33590720 [00:56<00:57, 309066.37 examples/s]Map (num_proc=32):  47%|████▋     | 15889230/33590720 [00:58<01:08, 259709.81 examples/s]Map (num_proc=32):  49%|████▉     | 16494230/33590720 [00:58<00:36, 468254.63 examples/s]Map (num_proc=32):  50%|████▉     | 16758940/33590720 [01:00<00:54, 310678.03 examples/s]Map (num_proc=32):  51%|█████     | 16974940/33590720 [01:01<01:00, 272700.16 examples/s]Map (num_proc=32):  52%|█████▏    | 17546940/33590720 [01:01<00:34, 463965.99 examples/s]Map (num_proc=32):  53%|█████▎    | 17772650/33590720 [01:03<00:51, 304387.24 examples/s]Map (num_proc=32):  54%|█████▎    | 17998650/33590720 [01:04<00:57, 270335.93 examples/s]Map (num_proc=32):  55%|█████▌    | 18582650/33590720 [01:04<00:32, 468635.47 examples/s]Map (num_proc=32):  56%|█████▌    | 18804360/33590720 [01:06<00:50, 292718.00 examples/s]Map (num_proc=32):  57%|█████▋    | 19072360/33590720 [01:07<00:52, 274297.70 examples/s]Map (num_proc=32):  59%|█████▊    | 19655360/33590720 [01:07<00:29, 472309.68 examples/s]Map (num_proc=32):  59%|█████▉    | 19913070/33590720 [01:09<00:44, 304518.74 examples/s]Map (num_proc=32):  60%|█████▉    | 20098070/33590720 [01:10<00:52, 259332.74 examples/s]Map (num_proc=32):  62%|██████▏   | 20731070/33590720 [01:10<00:27, 473152.19 examples/s]Map (num_proc=32):  63%|██████▎   | 21012780/33590720 [01:12<00:43, 290958.99 examples/s]Map (num_proc=32):  63%|██████▎   | 21214780/33590720 [01:14<00:48, 255758.54 examples/s]Map (num_proc=32):  65%|██████▌   | 21888490/33590720 [01:14<00:24, 469940.61 examples/s]Map (num_proc=32):  66%|██████▌   | 22167490/33590720 [01:17<00:45, 249459.44 examples/s]Map (num_proc=32):  68%|██████▊   | 22883200/33590720 [01:17<00:24, 438018.48 examples/s]Map (num_proc=32):  69%|██████▉   | 23236200/33590720 [01:20<00:39, 262366.59 examples/s]Map (num_proc=32):  71%|███████   | 23906910/33590720 [01:20<00:23, 420842.59 examples/s]Map (num_proc=32):  72%|███████▏  | 24262910/33590720 [01:23<00:34, 266748.30 examples/s]Map (num_proc=32):  74%|███████▍  | 24900620/33590720 [01:23<00:21, 412867.41 examples/s]Map (num_proc=32):  75%|███████▌  | 25260620/33590720 [01:26<00:31, 261928.94 examples/s]Map (num_proc=32):  77%|███████▋  | 25937620/33590720 [01:26<00:18, 413825.61 examples/s]Map (num_proc=32):  78%|███████▊  | 26319330/33590720 [01:28<00:22, 323895.56 examples/s]Map (num_proc=32):  79%|███████▉  | 26593330/33590720 [01:29<00:23, 301866.91 examples/s]Map (num_proc=32):  80%|████████  | 27040330/33590720 [01:30<00:15, 424390.14 examples/s]Map (num_proc=32):  81%|████████▏ | 27303040/33590720 [01:31<00:21, 297545.69 examples/s]Map (num_proc=32):  82%|████████▏ | 27490040/33590720 [01:33<00:23, 259329.11 examples/s]Map (num_proc=32):  84%|████████▎ | 28093040/33590720 [01:33<00:12, 448868.46 examples/s]Map (num_proc=32):  84%|████████▍ | 28341750/33590720 [01:35<00:18, 276455.27 examples/s]Map (num_proc=32):  85%|████████▍ | 28517750/33590720 [01:36<00:20, 243412.71 examples/s]Map (num_proc=32):  87%|████████▋ | 29212460/33590720 [01:36<00:09, 465310.27 examples/s]Map (num_proc=32):  88%|████████▊ | 29505460/33590720 [01:39<00:16, 249508.04 examples/s]Map (num_proc=32):  90%|████████▉ | 30224170/33590720 [01:39<00:07, 435211.59 examples/s]Map (num_proc=32):  91%|█████████ | 30545170/33590720 [01:41<00:09, 332149.23 examples/s]Map (num_proc=32):  92%|█████████▏| 30790170/33590720 [01:41<00:07, 398318.71 examples/s]Map (num_proc=32):  92%|█████████▏| 31022170/33590720 [01:42<00:06, 398011.31 examples/s]Map (num_proc=32):  93%|█████████▎| 31194170/33590720 [01:42<00:06, 396300.31 examples/s]Map (num_proc=32):  93%|█████████▎| 31326880/33590720 [01:43<00:05, 392415.11 examples/s]Map (num_proc=32):  94%|█████████▎| 31430880/33590720 [01:43<00:05, 379330.33 examples/s]Map (num_proc=32):  94%|█████████▍| 31514880/33590720 [01:43<00:05, 366935.45 examples/s]Map (num_proc=32):  94%|█████████▍| 31582880/33590720 [01:43<00:05, 356859.44 examples/s]Map (num_proc=32):  94%|█████████▍| 31639880/33590720 [01:45<00:10, 179687.76 examples/s]Map (num_proc=32):  95%|█████████▌| 31957880/33590720 [01:45<00:04, 371069.57 examples/s]Map (num_proc=32):  95%|█████████▌| 32078590/33590720 [01:45<00:04, 351628.51 examples/s]Map (num_proc=32):  96%|█████████▌| 32170590/33590720 [01:45<00:04, 321219.68 examples/s]Map (num_proc=32):  96%|█████████▌| 32242590/33590720 [01:46<00:04, 301671.15 examples/s]Map (num_proc=32):  96%|█████████▌| 32301590/33590720 [01:47<00:08, 148875.90 examples/s]Map (num_proc=32):  97%|█████████▋| 32547590/33590720 [01:47<00:03, 284453.47 examples/s]Map (num_proc=32):  97%|█████████▋| 32643590/33590720 [01:48<00:03, 272441.87 examples/s]Map (num_proc=32):  97%|█████████▋| 32719590/33590720 [01:48<00:03, 263891.12 examples/s]Map (num_proc=32):  98%|█████████▊| 32779590/33590720 [01:48<00:03, 258286.59 examples/s]Map (num_proc=32):  98%|█████████▊| 32827590/33590720 [01:48<00:03, 254192.58 examples/s]Map (num_proc=32):  98%|█████████▊| 32871590/33590720 [01:49<00:02, 253089.04 examples/s]Map (num_proc=32):  98%|█████████▊| 32908300/33590720 [01:49<00:02, 251276.14 examples/s]Map (num_proc=32):  98%|█████████▊| 32944300/33590720 [01:49<00:02, 224140.40 examples/s]Map (num_proc=32):  98%|█████████▊| 32972300/33590720 [01:49<00:02, 209111.47 examples/s]Map (num_proc=32):  98%|█████████▊| 32996300/33590720 [01:49<00:03, 197569.07 examples/s]Map (num_proc=32):  98%|█████████▊| 33020300/33590720 [01:49<00:03, 187881.34 examples/s]Map (num_proc=32):  98%|█████████▊| 33040300/33590720 [01:50<00:03, 178774.03 examples/s]Map (num_proc=32):  98%|█████████▊| 33060300/33590720 [01:50<00:03, 160021.61 examples/s]Map (num_proc=32):  98%|█████████▊| 33077300/33590720 [01:51<00:09, 53518.92 examples/s] Map (num_proc=32):  99%|█████████▉| 33236300/33590720 [01:51<00:01, 186709.67 examples/s]Map (num_proc=32):  99%|█████████▉| 33292300/33590720 [01:51<00:01, 177991.24 examples/s]Map (num_proc=32):  99%|█████████▉| 33336300/33590720 [01:52<00:01, 174111.66 examples/s]Map (num_proc=32):  99%|█████████▉| 33374010/33590720 [01:52<00:01, 162892.09 examples/s]Map (num_proc=32):  99%|█████████▉| 33406010/33590720 [01:52<00:01, 133058.33 examples/s]Map (num_proc=32): 100%|█████████▉| 33430010/33590720 [01:53<00:01, 118148.55 examples/s]Map (num_proc=32): 100%|█████████▉| 33452010/33590720 [01:54<00:02, 53861.61 examples/s] Map (num_proc=32): 100%|█████████▉| 33526010/33590720 [01:54<00:00, 95083.25 examples/s]Map (num_proc=32): 100%|█████████▉| 33554010/33590720 [01:54<00:00, 91277.33 examples/s]Map (num_proc=32): 100%|█████████▉| 33574010/33590720 [01:55<00:00, 88801.59 examples/s]Map (num_proc=32): 100%|██████████| 33590720/33590720 [01:55<00:00, 86844.61 examples/s]Map (num_proc=32): 100%|██████████| 33590720/33590720 [01:57<00:00, 285366.00 examples/s]
Map (num_proc=32):   0%|          | 0/27000 [00:00<?, ? examples/s]Map (num_proc=32):   3%|▎         | 844/27000 [00:00<00:05, 4966.30 examples/s]Map (num_proc=32):  47%|████▋     | 12660/27000 [00:00<00:00, 55147.25 examples/s]Map (num_proc=32): 100%|██████████| 27000/27000 [00:00<00:00, 87451.48 examples/s]Map (num_proc=32): 100%|██████████| 27000/27000 [00:00<00:00, 43310.07 examples/s]
wandb: Currently logged in as: os415. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /rds/user/os415/hpc-work/tspGPT/wandb/run-20240515_203648-ti4ti0lg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run final-anticlk-microGPT-200k-2223-eval-either-22-or-23
wandb: ⭐️ View project at https://wandb.ai/os415/Final-countdown
wandb: 🚀 View run at https://wandb.ai/os415/Final-countdown/runs/ti4ti0lg
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Using auto half precision backend
***** Running training *****
  Num examples = 33,590,720
  Num Epochs = 25
  Instantaneous batch size per device = 65,536
  Total train batch size (w. parallel, distributed & accumulation) = 65,536
  Gradient Accumulation steps = 1
  Total optimization steps = 12,825
  Number of trainable parameters = 926,080
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/12825 [00:00<?, ?it/s]  0%|          | 1/12825 [00:26<93:29:55, 26.25s/it]  0%|          | 2/12825 [00:38<65:06:58, 18.28s/it]  0%|          | 3/12825 [00:51<55:56:58, 15.71s/it]  0%|          | 4/12825 [01:04<51:38:25, 14.50s/it]  0%|          | 5/12825 [01:16<49:20:30, 13.86s/it]  0%|          | 6/12825 [01:29<47:59:45, 13.48s/it]  0%|          | 7/12825 [01:42<47:05:53, 13.23s/it]  0%|          | 8/12825 [01:55<46:26:18, 13.04s/it]  0%|          | 9/12825 [02:07<45:58:59, 12.92s/it]  0%|          | 10/12825 [02:20<45:41:53, 12.84s/it]  0%|          | 11/12825 [02:32<45:28:09, 12.77s/it]  0%|          | 12/12825 [02:45<45:20:14, 12.74s/it]  0%|          | 13/12825 [02:58<45:16:52, 12.72s/it]  0%|          | 14/12825 [03:10<45:11:58, 12.70s/it]  0%|          | 15/12825 [03:23<45:09:19, 12.69s/it]  0%|          | 16/12825 [03:36<45:06:23, 12.68s/it]  0%|          | 17/12825 [03:48<45:03:44, 12.67s/it]  0%|          | 18/12825 [04:01<45:01:53, 12.66s/it]  0%|          | 19/12825 [04:14<45:03:12, 12.67s/it]  0%|          | 20/12825 [04:26<45:04:47, 12.67s/it]  0%|          | 21/12825 [04:39<45:04:33, 12.67s/it]  0%|          | 22/12825 [04:52<45:01:55, 12.66s/it]  0%|          | 23/12825 [05:04<45:01:44, 12.66s/it]  0%|          | 24/12825 [05:17<45:00:33, 12.66s/it]  0%|          | 25/12825 [05:30<44:58:48, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120205.76lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103476.48lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-25
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-25/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-25/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-25/pytorch_model.bin
  0%|          | 26/12825 [05:43<45:22:22, 12.76s/it]  0%|          | 27/12825 [05:55<45:14:03, 12.72s/it]  0%|          | 28/12825 [06:08<45:08:44, 12.70s/it]  0%|          | 29/12825 [06:21<45:04:02, 12.68s/it]  0%|          | 30/12825 [06:33<45:01:04, 12.67s/it]  0%|          | 31/12825 [06:55<54:49:06, 15.42s/it]  0%|          | 32/12825 [07:08<51:50:51, 14.59s/it]  0%|          | 33/12825 [07:20<49:47:05, 14.01s/it]  0%|          | 34/12825 [07:33<48:22:26, 13.61s/it]  0%|          | 35/12825 [07:46<47:18:57, 13.32s/it]  0%|          | 36/12825 [07:58<46:36:27, 13.12s/it]  0%|          | 37/12825 [08:11<46:06:16, 12.98s/it]  0%|          | 38/12825 [08:24<45:44:01, 12.88s/it]  0%|          | 39/12825 [08:36<45:26:30, 12.79s/it]  0%|          | 40/12825 [08:49<45:19:50, 12.76s/it]  0%|          | 41/12825 [09:02<45:11:58, 12.73s/it]  0%|          | 42/12825 [09:14<45:06:30, 12.70s/it]  0%|          | 43/12825 [09:27<45:05:27, 12.70s/it]  0%|          | 44/12825 [09:40<45:01:04, 12.68s/it]  0%|          | 45/12825 [09:52<44:59:23, 12.67s/it]  0%|          | 46/12825 [10:05<44:55:13, 12.65s/it]  0%|          | 47/12825 [10:17<44:51:52, 12.64s/it]  0%|          | 48/12825 [10:30<44:52:36, 12.64s/it]  0%|          | 49/12825 [10:43<44:53:18, 12.65s/it]  0%|          | 50/12825 [10:55<44:53:17, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120513.54lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103712.82lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-50
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-50/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-50/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-50/pytorch_model.bin
  0%|          | 51/12825 [11:08<45:15:54, 12.76s/it]  0%|          | 52/12825 [11:21<45:11:18, 12.74s/it]  0%|          | 53/12825 [11:34<45:07:24, 12.72s/it]  0%|          | 54/12825 [11:46<45:03:48, 12.70s/it]  0%|          | 55/12825 [11:59<45:01:58, 12.70s/it]  0%|          | 56/12825 [12:12<44:58:22, 12.68s/it]  0%|          | 57/12825 [12:24<44:54:53, 12.66s/it]  0%|          | 58/12825 [12:37<44:53:57, 12.66s/it]  0%|          | 59/12825 [12:50<44:51:26, 12.65s/it]  0%|          | 60/12825 [13:02<44:52:26, 12.66s/it]  0%|          | 61/12825 [13:15<44:51:10, 12.65s/it]  0%|          | 62/12825 [13:28<44:49:07, 12.64s/it]  0%|          | 63/12825 [13:40<44:45:55, 12.63s/it]  0%|          | 64/12825 [14:02<54:00:36, 15.24s/it]  1%|          | 65/12825 [14:14<51:15:46, 14.46s/it]  1%|          | 66/12825 [14:27<49:20:06, 13.92s/it]  1%|          | 67/12825 [14:40<47:59:51, 13.54s/it]  1%|          | 68/12825 [14:52<47:02:39, 13.28s/it]  1%|          | 69/12825 [15:05<46:24:05, 13.10s/it]  1%|          | 70/12825 [15:18<45:55:36, 12.96s/it]  1%|          | 71/12825 [15:30<45:37:02, 12.88s/it]  1%|          | 72/12825 [15:43<45:24:03, 12.82s/it]  1%|          | 73/12825 [15:56<45:12:46, 12.76s/it]  1%|          | 74/12825 [16:08<45:05:08, 12.73s/it]  1%|          | 75/12825 [16:21<45:06:39, 12.74s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120447.78lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103662.32lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-75
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-75/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-75/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-75/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-50] due to args.save_total_limit
  1%|          | 76/12825 [16:34<45:23:35, 12.82s/it]  1%|          | 77/12825 [16:47<45:12:49, 12.77s/it]  1%|          | 78/12825 [16:59<45:06:49, 12.74s/it]  1%|          | 79/12825 [17:12<44:59:56, 12.71s/it]  1%|          | 80/12825 [17:25<44:55:19, 12.69s/it]  1%|          | 81/12825 [17:37<44:53:45, 12.68s/it]  1%|          | 82/12825 [17:50<44:52:55, 12.68s/it]  1%|          | 83/12825 [18:03<44:49:57, 12.67s/it]  1%|          | 84/12825 [18:15<44:47:55, 12.66s/it]  1%|          | 85/12825 [18:28<44:48:05, 12.66s/it]  1%|          | 86/12825 [18:40<44:48:53, 12.66s/it]  1%|          | 87/12825 [18:53<44:46:36, 12.65s/it]  1%|          | 88/12825 [19:06<44:45:36, 12.65s/it]  1%|          | 89/12825 [19:18<44:46:22, 12.66s/it]  1%|          | 90/12825 [19:31<44:45:33, 12.65s/it]  1%|          | 91/12825 [19:44<44:46:05, 12.66s/it]  1%|          | 92/12825 [19:56<44:46:51, 12.66s/it]  1%|          | 93/12825 [20:09<44:44:06, 12.65s/it]  1%|          | 94/12825 [20:22<44:46:54, 12.66s/it]  1%|          | 95/12825 [20:34<44:45:25, 12.66s/it]  1%|          | 96/12825 [20:56<54:20:39, 15.37s/it]  1%|          | 97/12825 [21:09<51:29:36, 14.56s/it]  1%|          | 98/12825 [21:21<49:33:19, 14.02s/it]  1%|          | 99/12825 [21:34<48:09:06, 13.62s/it]  1%|          | 100/12825 [21:47<47:07:52, 13.33s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120497.89lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103703.23lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-75] due to args.save_total_limit
  1%|          | 101/12825 [22:00<46:45:47, 13.23s/it]  1%|          | 102/12825 [22:13<46:11:38, 13.07s/it]  1%|          | 103/12825 [22:25<45:45:11, 12.95s/it]  1%|          | 104/12825 [22:38<45:27:21, 12.86s/it]  1%|          | 105/12825 [22:51<45:15:49, 12.81s/it]  1%|          | 106/12825 [23:03<45:04:41, 12.76s/it]  1%|          | 107/12825 [23:16<44:59:25, 12.74s/it]  1%|          | 108/12825 [23:29<44:56:16, 12.72s/it]  1%|          | 109/12825 [23:41<44:53:53, 12.71s/it]  1%|          | 110/12825 [23:54<44:54:44, 12.72s/it]  1%|          | 111/12825 [24:07<44:51:48, 12.70s/it]  1%|          | 112/12825 [24:19<44:48:43, 12.69s/it]  1%|          | 113/12825 [24:32<44:47:01, 12.68s/it]  1%|          | 114/12825 [24:45<44:46:34, 12.68s/it]  1%|          | 115/12825 [24:57<44:46:13, 12.68s/it]  1%|          | 116/12825 [25:10<44:44:40, 12.67s/it]  1%|          | 117/12825 [25:23<44:43:25, 12.67s/it]  1%|          | 118/12825 [25:35<44:41:50, 12.66s/it]  1%|          | 119/12825 [25:48<44:41:40, 12.66s/it]  1%|          | 120/12825 [26:01<44:44:06, 12.68s/it]  1%|          | 121/12825 [26:13<44:42:31, 12.67s/it]  1%|          | 122/12825 [26:26<44:43:25, 12.67s/it]  1%|          | 123/12825 [26:39<44:42:23, 12.67s/it]  1%|          | 124/12825 [26:51<44:42:13, 12.67s/it]  1%|          | 125/12825 [27:04<44:40:14, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120459.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103758.43lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-100] due to args.save_total_limit
  1%|          | 126/12825 [27:17<45:03:11, 12.77s/it]  1%|          | 127/12825 [27:30<44:56:16, 12.74s/it]  1%|          | 128/12825 [27:51<53:56:57, 15.30s/it]  1%|          | 129/12825 [28:04<51:07:10, 14.50s/it]  1%|          | 130/12825 [28:16<49:11:22, 13.95s/it]  1%|          | 131/12825 [28:29<47:48:12, 13.56s/it]  1%|          | 132/12825 [28:42<46:48:57, 13.28s/it]  1%|          | 133/12825 [28:54<46:07:47, 13.08s/it]  1%|          | 134/12825 [29:07<45:38:47, 12.95s/it]  1%|          | 135/12825 [29:19<45:19:53, 12.86s/it]  1%|          | 136/12825 [29:32<45:09:08, 12.81s/it]  1%|          | 137/12825 [29:45<44:59:48, 12.77s/it]  1%|          | 138/12825 [29:57<44:54:02, 12.74s/it]  1%|          | 139/12825 [30:10<44:48:21, 12.71s/it]  1%|          | 140/12825 [30:23<44:45:25, 12.70s/it]  1%|          | 141/12825 [30:35<44:41:06, 12.68s/it]  1%|          | 142/12825 [30:48<44:39:23, 12.68s/it]  1%|          | 143/12825 [31:01<44:38:02, 12.67s/it]  1%|          | 144/12825 [31:13<44:33:29, 12.65s/it]  1%|          | 145/12825 [31:26<44:32:40, 12.65s/it]  1%|          | 146/12825 [31:39<44:31:59, 12.64s/it]  1%|          | 147/12825 [31:51<44:33:47, 12.65s/it]  1%|          | 148/12825 [32:04<44:34:03, 12.66s/it]  1%|          | 149/12825 [32:17<44:33:02, 12.65s/it]  1%|          | 150/12825 [32:29<44:34:28, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120449.32lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 100539.25lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-125] due to args.save_total_limit
  1%|          | 151/12825 [32:43<45:09:34, 12.83s/it]  1%|          | 152/12825 [32:55<44:57:21, 12.77s/it]  1%|          | 153/12825 [33:08<44:47:33, 12.73s/it]  1%|          | 154/12825 [33:20<44:39:16, 12.69s/it]  1%|          | 155/12825 [33:33<44:38:02, 12.68s/it]  1%|          | 156/12825 [33:46<44:35:05, 12.67s/it]  1%|          | 157/12825 [33:58<44:32:39, 12.66s/it]  1%|          | 158/12825 [34:11<44:31:02, 12.65s/it]  1%|          | 159/12825 [34:24<44:30:03, 12.65s/it]  1%|          | 160/12825 [34:44<53:11:03, 15.12s/it]  1%|▏         | 161/12825 [34:57<50:33:48, 14.37s/it]  1%|▏         | 162/12825 [35:10<48:43:56, 13.85s/it]  1%|▏         | 163/12825 [35:22<47:29:59, 13.50s/it]  1%|▏         | 164/12825 [35:35<46:34:42, 13.24s/it]  1%|▏         | 165/12825 [35:48<45:58:01, 13.07s/it]  1%|▏         | 166/12825 [36:00<45:30:21, 12.94s/it]  1%|▏         | 167/12825 [36:13<45:13:50, 12.86s/it]  1%|▏         | 168/12825 [36:26<45:00:37, 12.80s/it]  1%|▏         | 169/12825 [36:38<44:50:13, 12.75s/it]  1%|▏         | 170/12825 [36:51<44:42:00, 12.72s/it]  1%|▏         | 171/12825 [37:04<44:40:52, 12.71s/it]  1%|▏         | 172/12825 [37:16<44:35:50, 12.69s/it]  1%|▏         | 173/12825 [37:29<44:32:48, 12.68s/it]  1%|▏         | 174/12825 [37:42<44:29:03, 12.66s/it]  1%|▏         | 175/12825 [37:54<44:27:34, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120470.33lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103680.25lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-150] due to args.save_total_limit
  1%|▏         | 176/12825 [38:07<44:45:36, 12.74s/it]  1%|▏         | 177/12825 [38:20<44:39:23, 12.71s/it]  1%|▏         | 178/12825 [38:32<44:35:21, 12.69s/it]  1%|▏         | 179/12825 [38:45<44:32:08, 12.68s/it]  1%|▏         | 180/12825 [38:58<44:29:39, 12.67s/it]  1%|▏         | 181/12825 [39:10<44:28:43, 12.66s/it]  1%|▏         | 182/12825 [39:23<44:26:46, 12.66s/it]  1%|▏         | 183/12825 [39:36<44:30:29, 12.67s/it]  1%|▏         | 184/12825 [39:48<44:27:45, 12.66s/it]  1%|▏         | 185/12825 [40:01<44:27:09, 12.66s/it]  1%|▏         | 186/12825 [40:14<44:25:52, 12.66s/it]  1%|▏         | 187/12825 [40:26<44:24:07, 12.65s/it]  1%|▏         | 188/12825 [40:39<44:22:35, 12.64s/it]  1%|▏         | 189/12825 [40:52<44:29:11, 12.67s/it]  1%|▏         | 190/12825 [41:04<44:28:58, 12.67s/it]  1%|▏         | 191/12825 [41:17<44:26:25, 12.66s/it]  1%|▏         | 192/12825 [41:30<44:27:07, 12.67s/it]  2%|▏         | 193/12825 [41:51<53:45:05, 15.32s/it]  2%|▏         | 194/12825 [42:04<50:54:53, 14.51s/it]  2%|▏         | 195/12825 [42:16<48:56:39, 13.95s/it]  2%|▏         | 196/12825 [42:29<47:32:09, 13.55s/it]  2%|▏         | 197/12825 [42:42<46:35:29, 13.28s/it]  2%|▏         | 198/12825 [42:54<45:53:17, 13.08s/it]  2%|▏         | 199/12825 [43:07<45:24:32, 12.95s/it]  2%|▏         | 200/12825 [43:20<45:06:33, 12.86s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120443.94lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103662.70lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-175] due to args.save_total_limit
  2%|▏         | 201/12825 [43:33<45:15:55, 12.91s/it]  2%|▏         | 202/12825 [43:45<44:59:30, 12.83s/it]  2%|▏         | 203/12825 [43:58<44:45:33, 12.77s/it]  2%|▏         | 204/12825 [44:11<44:36:54, 12.73s/it]  2%|▏         | 205/12825 [44:23<44:31:45, 12.70s/it]  2%|▏         | 206/12825 [44:36<44:30:26, 12.70s/it]  2%|▏         | 207/12825 [44:49<44:25:00, 12.67s/it]  2%|▏         | 208/12825 [45:01<44:22:52, 12.66s/it]  2%|▏         | 209/12825 [45:14<44:18:59, 12.65s/it]  2%|▏         | 210/12825 [45:26<44:17:41, 12.64s/it]  2%|▏         | 211/12825 [45:39<44:18:20, 12.64s/it]  2%|▏         | 212/12825 [45:52<44:15:41, 12.63s/it]  2%|▏         | 213/12825 [46:04<44:16:43, 12.64s/it]  2%|▏         | 214/12825 [46:17<44:17:15, 12.64s/it]  2%|▏         | 215/12825 [46:30<44:15:53, 12.64s/it]  2%|▏         | 216/12825 [46:42<44:15:14, 12.64s/it]  2%|▏         | 217/12825 [46:55<44:14:50, 12.63s/it]  2%|▏         | 218/12825 [47:08<44:18:09, 12.65s/it]  2%|▏         | 219/12825 [47:20<44:16:05, 12.64s/it]  2%|▏         | 220/12825 [47:33<44:13:15, 12.63s/it]  2%|▏         | 221/12825 [47:45<44:14:27, 12.64s/it]  2%|▏         | 222/12825 [47:58<44:13:15, 12.63s/it]  2%|▏         | 223/12825 [48:11<44:14:47, 12.64s/it]  2%|▏         | 224/12825 [48:23<44:16:09, 12.65s/it]  2%|▏         | 225/12825 [48:44<53:10:47, 15.19s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120602.73lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103850.44lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-200] due to args.save_total_limit
  2%|▏         | 226/12825 [48:58<50:53:51, 14.54s/it]  2%|▏         | 227/12825 [49:10<48:49:55, 13.95s/it]  2%|▏         | 228/12825 [49:23<47:24:23, 13.55s/it]  2%|▏         | 229/12825 [49:35<46:26:31, 13.27s/it]  2%|▏         | 230/12825 [49:48<45:46:14, 13.08s/it]  2%|▏         | 231/12825 [50:01<45:17:51, 12.95s/it]  2%|▏         | 232/12825 [50:13<44:57:26, 12.85s/it]  2%|▏         | 233/12825 [50:26<44:51:03, 12.82s/it]  2%|▏         | 234/12825 [50:39<44:38:59, 12.77s/it]  2%|▏         | 235/12825 [50:51<44:29:47, 12.72s/it]  2%|▏         | 236/12825 [51:04<44:21:12, 12.68s/it]  2%|▏         | 237/12825 [51:17<45:03:25, 12.89s/it]  2%|▏         | 238/12825 [51:30<44:46:59, 12.81s/it]  2%|▏         | 239/12825 [51:42<44:34:04, 12.75s/it]  2%|▏         | 240/12825 [51:55<44:26:23, 12.71s/it]  2%|▏         | 241/12825 [52:08<44:18:32, 12.68s/it]  2%|▏         | 242/12825 [52:20<44:14:40, 12.66s/it]  2%|▏         | 243/12825 [52:33<44:12:38, 12.65s/it]  2%|▏         | 244/12825 [52:45<44:10:41, 12.64s/it]  2%|▏         | 245/12825 [52:58<44:11:08, 12.64s/it]  2%|▏         | 246/12825 [53:11<44:09:55, 12.64s/it]  2%|▏         | 247/12825 [53:23<44:09:54, 12.64s/it]  2%|▏         | 248/12825 [53:36<44:09:09, 12.64s/it]  2%|▏         | 249/12825 [53:49<44:08:03, 12.63s/it]  2%|▏         | 250/12825 [54:01<44:06:23, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 118102.83lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101699.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-225] due to args.save_total_limit
  2%|▏         | 251/12825 [54:14<44:28:47, 12.73s/it]  2%|▏         | 252/12825 [54:27<44:21:14, 12.70s/it]  2%|▏         | 253/12825 [54:39<44:13:45, 12.67s/it]  2%|▏         | 254/12825 [54:52<44:15:59, 12.68s/it]  2%|▏         | 255/12825 [55:05<44:10:57, 12.65s/it]  2%|▏         | 256/12825 [55:17<44:09:02, 12.65s/it]  2%|▏         | 257/12825 [55:30<44:09:42, 12.65s/it]  2%|▏         | 258/12825 [55:50<52:05:21, 14.92s/it]  2%|▏         | 259/12825 [56:03<49:40:12, 14.23s/it]  2%|▏         | 260/12825 [56:15<47:56:43, 13.74s/it]  2%|▏         | 261/12825 [56:28<46:46:38, 13.40s/it]  2%|▏         | 262/12825 [56:41<45:57:03, 13.17s/it]  2%|▏         | 263/12825 [56:53<45:20:53, 13.00s/it]  2%|▏         | 264/12825 [57:06<44:55:40, 12.88s/it]  2%|▏         | 265/12825 [57:19<44:39:17, 12.80s/it]  2%|▏         | 266/12825 [57:31<44:24:53, 12.73s/it]  2%|▏         | 267/12825 [57:44<44:15:05, 12.69s/it]  2%|▏         | 268/12825 [57:56<44:08:30, 12.66s/it]  2%|▏         | 269/12825 [58:09<44:06:48, 12.65s/it]  2%|▏         | 270/12825 [58:21<44:01:43, 12.62s/it]  2%|▏         | 271/12825 [58:34<43:58:26, 12.61s/it]  2%|▏         | 272/12825 [58:47<43:58:57, 12.61s/it]  2%|▏         | 273/12825 [58:59<43:58:16, 12.61s/it]  2%|▏         | 274/12825 [59:12<43:55:59, 12.60s/it]  2%|▏         | 275/12825 [59:25<43:58:19, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120416.27lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103658.05lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-250] due to args.save_total_limit
  2%|▏         | 276/12825 [59:37<44:21:18, 12.72s/it]  2%|▏         | 277/12825 [59:50<44:16:13, 12.70s/it]  2%|▏         | 278/12825 [1:00:03<44:09:02, 12.67s/it]  2%|▏         | 279/12825 [1:00:15<44:07:54, 12.66s/it]  2%|▏         | 280/12825 [1:00:28<44:04:04, 12.65s/it]  2%|▏         | 281/12825 [1:00:41<44:02:59, 12.64s/it]  2%|▏         | 282/12825 [1:00:53<44:00:11, 12.63s/it]  2%|▏         | 283/12825 [1:01:06<44:00:23, 12.63s/it]  2%|▏         | 284/12825 [1:01:18<43:57:12, 12.62s/it]  2%|▏         | 285/12825 [1:01:31<43:56:17, 12.61s/it]  2%|▏         | 286/12825 [1:01:44<43:57:51, 12.62s/it]  2%|▏         | 287/12825 [1:01:56<44:00:01, 12.63s/it]  2%|▏         | 288/12825 [1:02:09<43:58:48, 12.63s/it]  2%|▏         | 289/12825 [1:02:22<43:58:26, 12.63s/it]  2%|▏         | 290/12825 [1:02:43<52:50:20, 15.18s/it]  2%|▏         | 291/12825 [1:02:55<50:07:01, 14.39s/it]  2%|▏         | 292/12825 [1:03:08<48:14:32, 13.86s/it]  2%|▏         | 293/12825 [1:03:21<47:00:59, 13.51s/it]  2%|▏         | 294/12825 [1:03:33<46:03:16, 13.23s/it]  2%|▏         | 295/12825 [1:03:46<45:25:41, 13.05s/it]  2%|▏         | 296/12825 [1:03:58<44:59:18, 12.93s/it]  2%|▏         | 297/12825 [1:04:11<44:44:46, 12.86s/it]  2%|▏         | 298/12825 [1:04:24<44:28:55, 12.78s/it]  2%|▏         | 299/12825 [1:04:36<44:19:27, 12.74s/it]  2%|▏         | 300/12825 [1:04:49<44:10:25, 12.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120500.84lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103690.89lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-275] due to args.save_total_limit
  2%|▏         | 301/12825 [1:05:02<44:26:09, 12.77s/it]  2%|▏         | 302/12825 [1:05:15<44:16:17, 12.73s/it]  2%|▏         | 303/12825 [1:05:27<44:09:41, 12.70s/it]  2%|▏         | 304/12825 [1:05:40<44:04:56, 12.67s/it]  2%|▏         | 305/12825 [1:05:52<44:00:04, 12.65s/it]  2%|▏         | 306/12825 [1:06:05<43:55:22, 12.63s/it]  2%|▏         | 307/12825 [1:06:18<43:59:08, 12.65s/it]  2%|▏         | 308/12825 [1:06:30<43:56:54, 12.64s/it]  2%|▏         | 309/12825 [1:06:43<43:53:33, 12.62s/it]  2%|▏         | 310/12825 [1:06:55<43:49:24, 12.61s/it]  2%|▏         | 311/12825 [1:07:08<43:50:26, 12.61s/it]  2%|▏         | 312/12825 [1:07:21<43:50:42, 12.61s/it]  2%|▏         | 313/12825 [1:07:33<43:52:40, 12.62s/it]  2%|▏         | 314/12825 [1:07:46<43:50:16, 12.61s/it]  2%|▏         | 315/12825 [1:07:59<43:50:27, 12.62s/it]  2%|▏         | 316/12825 [1:08:11<43:51:01, 12.62s/it]  2%|▏         | 317/12825 [1:08:24<43:56:16, 12.65s/it]  2%|▏         | 318/12825 [1:08:36<43:54:22, 12.64s/it]  2%|▏         | 319/12825 [1:08:49<43:52:08, 12.63s/it]  2%|▏         | 320/12825 [1:09:02<43:51:33, 12.63s/it]  3%|▎         | 321/12825 [1:09:14<43:49:55, 12.62s/it]  3%|▎         | 322/12825 [1:09:36<52:53:07, 15.23s/it]  3%|▎         | 323/12825 [1:09:48<50:07:39, 14.43s/it]  3%|▎         | 324/12825 [1:10:01<48:12:17, 13.88s/it]  3%|▎         | 325/12825 [1:10:13<46:51:23, 13.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120391.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103585.80lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-300] due to args.save_total_limit
  3%|▎         | 326/12825 [1:10:26<46:16:46, 13.33s/it]  3%|▎         | 327/12825 [1:10:39<45:30:40, 13.11s/it]  3%|▎         | 328/12825 [1:10:52<44:57:00, 12.95s/it]  3%|▎         | 329/12825 [1:11:04<44:34:53, 12.84s/it]  3%|▎         | 330/12825 [1:11:17<44:19:53, 12.77s/it]  3%|▎         | 331/12825 [1:11:29<44:14:59, 12.75s/it]  3%|▎         | 332/12825 [1:11:42<44:05:04, 12.70s/it]  3%|▎         | 333/12825 [1:11:55<43:58:14, 12.67s/it]  3%|▎         | 334/12825 [1:12:07<43:51:58, 12.64s/it]  3%|▎         | 335/12825 [1:12:20<43:49:11, 12.63s/it]  3%|▎         | 336/12825 [1:12:32<43:47:52, 12.62s/it]  3%|▎         | 337/12825 [1:12:45<43:46:41, 12.62s/it]  3%|▎         | 338/12825 [1:12:58<43:45:34, 12.62s/it]  3%|▎         | 339/12825 [1:13:10<43:44:26, 12.61s/it]  3%|▎         | 340/12825 [1:13:23<43:43:28, 12.61s/it]  3%|▎         | 341/12825 [1:13:36<43:48:41, 12.63s/it]  3%|▎         | 342/12825 [1:13:48<43:44:20, 12.61s/it]  3%|▎         | 343/12825 [1:14:01<43:48:13, 12.63s/it]  3%|▎         | 344/12825 [1:14:13<43:46:27, 12.63s/it]  3%|▎         | 345/12825 [1:14:26<43:44:23, 12.62s/it]  3%|▎         | 346/12825 [1:14:39<43:41:41, 12.61s/it]  3%|▎         | 347/12825 [1:14:51<43:39:13, 12.59s/it]  3%|▎         | 348/12825 [1:15:04<43:41:41, 12.61s/it]  3%|▎         | 349/12825 [1:15:16<43:41:24, 12.61s/it]  3%|▎         | 350/12825 [1:15:29<43:41:41, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120518.54lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 100200.68lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-325] due to args.save_total_limit
  3%|▎         | 351/12825 [1:15:42<44:16:14, 12.78s/it]  3%|▎         | 352/12825 [1:15:55<44:03:53, 12.72s/it]  3%|▎         | 353/12825 [1:16:07<43:57:28, 12.69s/it]  3%|▎         | 354/12825 [1:16:20<43:50:13, 12.65s/it]  3%|▎         | 355/12825 [1:16:42<54:04:59, 15.61s/it]  3%|▎         | 356/12825 [1:16:55<50:58:30, 14.72s/it]  3%|▎         | 357/12825 [1:17:08<48:45:10, 14.08s/it]  3%|▎         | 358/12825 [1:17:20<47:13:40, 13.64s/it]  3%|▎         | 359/12825 [1:17:33<46:10:43, 13.34s/it]  3%|▎         | 360/12825 [1:17:45<45:25:39, 13.12s/it]  3%|▎         | 361/12825 [1:17:58<44:51:11, 12.96s/it]  3%|▎         | 362/12825 [1:18:11<44:28:49, 12.85s/it]  3%|▎         | 363/12825 [1:18:23<44:13:39, 12.78s/it]  3%|▎         | 364/12825 [1:18:36<44:01:10, 12.72s/it]  3%|▎         | 365/12825 [1:18:48<43:53:20, 12.68s/it]  3%|▎         | 366/12825 [1:19:01<43:48:33, 12.66s/it]  3%|▎         | 367/12825 [1:19:14<43:44:58, 12.64s/it]  3%|▎         | 368/12825 [1:19:26<43:41:29, 12.63s/it]  3%|▎         | 369/12825 [1:19:39<43:39:50, 12.62s/it]  3%|▎         | 370/12825 [1:19:51<43:37:45, 12.61s/it]  3%|▎         | 371/12825 [1:20:04<43:34:23, 12.60s/it]  3%|▎         | 372/12825 [1:20:17<43:33:25, 12.59s/it]  3%|▎         | 373/12825 [1:20:29<43:33:38, 12.59s/it]  3%|▎         | 374/12825 [1:20:42<43:37:02, 12.61s/it]  3%|▎         | 375/12825 [1:20:54<43:34:18, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120331.57lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103654.25lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-350] due to args.save_total_limit
  3%|▎         | 376/12825 [1:21:07<43:55:10, 12.70s/it]  3%|▎         | 377/12825 [1:21:20<43:47:55, 12.67s/it]  3%|▎         | 378/12825 [1:21:33<43:43:09, 12.64s/it]  3%|▎         | 379/12825 [1:21:45<43:42:22, 12.64s/it]  3%|▎         | 380/12825 [1:21:58<43:42:08, 12.64s/it]  3%|▎         | 381/12825 [1:22:10<43:37:38, 12.62s/it]  3%|▎         | 382/12825 [1:22:23<43:37:04, 12.62s/it]  3%|▎         | 383/12825 [1:22:36<43:32:54, 12.60s/it]  3%|▎         | 384/12825 [1:22:48<43:32:53, 12.60s/it]  3%|▎         | 385/12825 [1:23:01<43:40:25, 12.64s/it]  3%|▎         | 386/12825 [1:23:14<43:39:06, 12.63s/it]  3%|▎         | 387/12825 [1:23:35<52:21:58, 15.16s/it]  3%|▎         | 388/12825 [1:23:47<49:44:30, 14.40s/it]  3%|▎         | 389/12825 [1:24:00<47:52:33, 13.86s/it]  3%|▎         | 390/12825 [1:24:12<46:32:33, 13.47s/it]  3%|▎         | 391/12825 [1:24:25<45:38:38, 13.22s/it]  3%|▎         | 392/12825 [1:24:38<45:01:04, 13.04s/it]  3%|▎         | 393/12825 [1:24:50<44:32:19, 12.90s/it]  3%|▎         | 394/12825 [1:25:03<44:12:10, 12.80s/it]  3%|▎         | 395/12825 [1:25:15<43:58:29, 12.74s/it]  3%|▎         | 396/12825 [1:25:28<43:47:46, 12.69s/it]  3%|▎         | 397/12825 [1:25:41<43:47:24, 12.68s/it]  3%|▎         | 398/12825 [1:25:53<43:41:55, 12.66s/it]  3%|▎         | 399/12825 [1:26:06<43:44:17, 12.67s/it]  3%|▎         | 400/12825 [1:26:18<43:37:58, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120546.76lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103746.46lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-375] due to args.save_total_limit
  3%|▎         | 401/12825 [1:26:31<43:55:38, 12.73s/it]  3%|▎         | 402/12825 [1:26:44<43:52:06, 12.71s/it]  3%|▎         | 403/12825 [1:26:57<43:45:09, 12.68s/it]  3%|▎         | 404/12825 [1:27:09<43:40:03, 12.66s/it]  3%|▎         | 405/12825 [1:27:22<43:34:26, 12.63s/it]  3%|▎         | 406/12825 [1:27:34<43:33:29, 12.63s/it]  3%|▎         | 407/12825 [1:27:47<43:32:58, 12.63s/it]  3%|▎         | 408/12825 [1:28:00<43:30:15, 12.61s/it]  3%|▎         | 409/12825 [1:28:12<43:33:49, 12.63s/it]  3%|▎         | 410/12825 [1:28:25<43:30:41, 12.62s/it]  3%|▎         | 411/12825 [1:28:38<43:30:40, 12.62s/it]  3%|▎         | 412/12825 [1:28:50<43:30:00, 12.62s/it]  3%|▎         | 413/12825 [1:29:03<43:30:45, 12.62s/it]  3%|▎         | 414/12825 [1:29:15<43:31:02, 12.62s/it]  3%|▎         | 415/12825 [1:29:28<43:28:29, 12.61s/it]  3%|▎         | 416/12825 [1:29:41<43:34:27, 12.64s/it]  3%|▎         | 417/12825 [1:29:53<43:32:55, 12.64s/it]  3%|▎         | 418/12825 [1:30:06<43:32:32, 12.63s/it]  3%|▎         | 419/12825 [1:30:28<53:26:29, 15.51s/it]  3%|▎         | 420/12825 [1:30:41<50:24:58, 14.63s/it]  3%|▎         | 421/12825 [1:30:53<48:16:46, 14.01s/it]  3%|▎         | 422/12825 [1:31:06<46:49:08, 13.59s/it]  3%|▎         | 423/12825 [1:31:19<45:47:11, 13.29s/it]  3%|▎         | 424/12825 [1:31:31<45:05:38, 13.09s/it]  3%|▎         | 425/12825 [1:31:44<44:32:41, 12.93s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120438.94lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103653.49lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-400] due to args.save_total_limit
  3%|▎         | 426/12825 [1:31:57<44:34:22, 12.94s/it]  3%|▎         | 427/12825 [1:32:09<44:12:16, 12.84s/it]  3%|▎         | 428/12825 [1:32:22<43:56:25, 12.76s/it]  3%|▎         | 429/12825 [1:32:34<43:45:57, 12.71s/it]  3%|▎         | 430/12825 [1:32:47<43:40:18, 12.68s/it]  3%|▎         | 431/12825 [1:33:00<43:35:18, 12.66s/it]  3%|▎         | 432/12825 [1:33:12<43:29:23, 12.63s/it]  3%|▎         | 433/12825 [1:33:25<43:25:43, 12.62s/it]  3%|▎         | 434/12825 [1:33:37<43:23:12, 12.61s/it]  3%|▎         | 435/12825 [1:33:50<43:20:52, 12.60s/it]  3%|▎         | 436/12825 [1:34:03<43:19:43, 12.59s/it]  3%|▎         | 437/12825 [1:34:15<43:22:37, 12.61s/it]  3%|▎         | 438/12825 [1:34:28<43:24:17, 12.61s/it]  3%|▎         | 439/12825 [1:34:40<43:24:55, 12.62s/it]  3%|▎         | 440/12825 [1:34:53<43:23:23, 12.61s/it]  3%|▎         | 441/12825 [1:35:06<43:22:12, 12.61s/it]  3%|▎         | 442/12825 [1:35:18<43:21:49, 12.61s/it]  3%|▎         | 443/12825 [1:35:31<43:23:23, 12.62s/it]  3%|▎         | 444/12825 [1:35:43<43:21:13, 12.61s/it]  3%|▎         | 445/12825 [1:35:56<43:20:06, 12.60s/it]  3%|▎         | 446/12825 [1:36:09<43:18:35, 12.60s/it]  3%|▎         | 447/12825 [1:36:21<43:18:44, 12.60s/it]  3%|▎         | 448/12825 [1:36:34<43:18:39, 12.60s/it]  4%|▎         | 449/12825 [1:36:46<43:17:24, 12.59s/it]  4%|▎         | 450/12825 [1:36:59<43:16:07, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120528.41lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103738.57lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-425] due to args.save_total_limit
  4%|▎         | 451/12825 [1:37:12<43:37:19, 12.69s/it]  4%|▎         | 452/12825 [1:37:33<52:24:16, 15.25s/it]  4%|▎         | 453/12825 [1:37:46<49:40:31, 14.45s/it]  4%|▎         | 454/12825 [1:37:58<47:45:00, 13.90s/it]  4%|▎         | 455/12825 [1:38:11<46:23:22, 13.50s/it]  4%|▎         | 456/12825 [1:38:23<45:23:37, 13.21s/it]  4%|▎         | 457/12825 [1:38:36<44:47:32, 13.04s/it]  4%|▎         | 458/12825 [1:38:49<44:18:30, 12.90s/it]  4%|▎         | 459/12825 [1:39:01<44:06:04, 12.84s/it]  4%|▎         | 460/12825 [1:39:14<43:57:33, 12.80s/it]  4%|▎         | 461/12825 [1:39:27<43:43:41, 12.73s/it]  4%|▎         | 462/12825 [1:39:39<43:34:58, 12.69s/it]  4%|▎         | 463/12825 [1:39:52<43:30:00, 12.67s/it]  4%|▎         | 464/12825 [1:40:04<43:26:55, 12.65s/it]  4%|▎         | 465/12825 [1:40:17<43:24:57, 12.65s/it]  4%|▎         | 466/12825 [1:40:30<43:22:20, 12.63s/it]  4%|▎         | 467/12825 [1:40:42<43:17:55, 12.61s/it]  4%|▎         | 468/12825 [1:40:55<43:16:47, 12.61s/it]  4%|▎         | 469/12825 [1:41:07<43:16:43, 12.61s/it]  4%|▎         | 470/12825 [1:41:20<43:17:48, 12.62s/it]  4%|▎         | 471/12825 [1:41:33<43:14:34, 12.60s/it]  4%|▎         | 472/12825 [1:41:45<43:12:11, 12.59s/it]  4%|▎         | 473/12825 [1:41:58<43:12:40, 12.59s/it]  4%|▎         | 474/12825 [1:42:10<43:11:12, 12.59s/it]  4%|▎         | 475/12825 [1:42:23<43:10:30, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120291.31lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103611.29lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-450] due to args.save_total_limit
  4%|▎         | 476/12825 [1:42:36<43:35:08, 12.71s/it]  4%|▎         | 477/12825 [1:42:49<43:33:37, 12.70s/it]  4%|▎         | 478/12825 [1:43:01<43:29:07, 12.68s/it]  4%|▎         | 479/12825 [1:43:14<43:26:04, 12.67s/it]  4%|▎         | 480/12825 [1:43:26<43:20:11, 12.64s/it]  4%|▍         | 481/12825 [1:43:39<43:18:56, 12.63s/it]  4%|▍         | 482/12825 [1:43:52<43:15:22, 12.62s/it]  4%|▍         | 483/12825 [1:44:04<43:17:07, 12.63s/it]  4%|▍         | 484/12825 [1:44:26<52:12:43, 15.23s/it]  4%|▍         | 485/12825 [1:44:38<49:29:23, 14.44s/it]  4%|▍         | 486/12825 [1:44:51<47:34:36, 13.88s/it]  4%|▍         | 487/12825 [1:45:03<46:14:52, 13.49s/it]  4%|▍         | 488/12825 [1:45:16<45:17:11, 13.21s/it]  4%|▍         | 489/12825 [1:45:29<44:38:22, 13.03s/it]  4%|▍         | 490/12825 [1:45:41<44:10:39, 12.89s/it]  4%|▍         | 491/12825 [1:45:54<43:52:22, 12.81s/it]  4%|▍         | 492/12825 [1:46:06<43:39:09, 12.74s/it]  4%|▍         | 493/12825 [1:46:19<43:28:08, 12.69s/it]  4%|▍         | 494/12825 [1:46:31<43:20:37, 12.65s/it]  4%|▍         | 495/12825 [1:46:44<43:14:01, 12.62s/it]  4%|▍         | 496/12825 [1:46:57<43:11:38, 12.61s/it]  4%|▍         | 497/12825 [1:47:09<43:08:22, 12.60s/it]  4%|▍         | 498/12825 [1:47:22<43:08:19, 12.60s/it]  4%|▍         | 499/12825 [1:47:34<43:13:15, 12.62s/it]  4%|▍         | 500/12825 [1:47:47<43:11:32, 12.62s/it]                                                          4%|▍         | 500/12825 [1:47:47<43:11:32, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120540.47lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103740.47lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-475] due to args.save_total_limit
  4%|▍         | 501/12825 [1:48:00<43:31:10, 12.71s/it]  4%|▍         | 502/12825 [1:48:13<43:22:30, 12.67s/it]  4%|▍         | 503/12825 [1:48:25<43:20:08, 12.66s/it]  4%|▍         | 504/12825 [1:48:38<43:16:22, 12.64s/it]  4%|▍         | 505/12825 [1:48:50<43:11:28, 12.62s/it]  4%|▍         | 506/12825 [1:49:03<43:07:57, 12.60s/it]  4%|▍         | 507/12825 [1:49:16<43:12:27, 12.63s/it]  4%|▍         | 508/12825 [1:49:28<43:11:16, 12.62s/it]  4%|▍         | 509/12825 [1:49:41<43:12:40, 12.63s/it]  4%|▍         | 510/12825 [1:49:53<43:10:58, 12.62s/it]  4%|▍         | 511/12825 [1:50:06<43:08:19, 12.61s/it]  4%|▍         | 512/12825 [1:50:14<38:17:07, 11.19s/it]  4%|▍         | 513/12825 [1:50:15<27:38:29,  8.08s/it]  4%|▍         | 514/12825 [1:50:40<45:33:48, 13.32s/it]  4%|▍         | 515/12825 [1:50:53<44:51:20, 13.12s/it]  4%|▍         | 516/12825 [1:51:06<44:20:07, 12.97s/it]  4%|▍         | 517/12825 [1:51:27<52:38:36, 15.40s/it]  4%|▍         | 518/12825 [1:51:39<49:46:13, 14.56s/it]  4%|▍         | 519/12825 [1:51:52<47:44:56, 13.97s/it]  4%|▍         | 520/12825 [1:52:04<46:23:41, 13.57s/it]  4%|▍         | 521/12825 [1:52:17<45:23:41, 13.28s/it]  4%|▍         | 522/12825 [1:52:30<44:42:31, 13.08s/it]  4%|▍         | 523/12825 [1:52:42<44:14:31, 12.95s/it]  4%|▍         | 524/12825 [1:52:55<43:52:06, 12.84s/it]  4%|▍         | 525/12825 [1:53:08<43:38:18, 12.77s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120351.27lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103607.40lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-500] due to args.save_total_limit
  4%|▍         | 526/12825 [1:53:21<43:57:10, 12.87s/it]  4%|▍         | 527/12825 [1:53:33<43:45:05, 12.81s/it]  4%|▍         | 528/12825 [1:53:46<43:33:36, 12.75s/it]  4%|▍         | 529/12825 [1:53:59<43:24:51, 12.71s/it]  4%|▍         | 530/12825 [1:54:11<43:21:54, 12.70s/it]  4%|▍         | 531/12825 [1:54:24<43:20:12, 12.69s/it]  4%|▍         | 532/12825 [1:54:36<43:14:56, 12.67s/it]  4%|▍         | 533/12825 [1:54:49<43:14:06, 12.66s/it]  4%|▍         | 534/12825 [1:55:02<43:13:04, 12.66s/it]  4%|▍         | 535/12825 [1:55:14<43:12:30, 12.66s/it]  4%|▍         | 536/12825 [1:55:27<43:10:40, 12.65s/it]  4%|▍         | 537/12825 [1:55:40<43:10:10, 12.65s/it]  4%|▍         | 538/12825 [1:55:52<43:11:14, 12.65s/it]  4%|▍         | 539/12825 [1:56:05<43:09:42, 12.65s/it]  4%|▍         | 540/12825 [1:56:18<43:07:53, 12.64s/it]  4%|▍         | 541/12825 [1:56:30<43:10:42, 12.65s/it]  4%|▍         | 542/12825 [1:56:43<43:09:50, 12.65s/it]  4%|▍         | 543/12825 [1:56:56<43:11:18, 12.66s/it]  4%|▍         | 544/12825 [1:57:08<43:09:15, 12.65s/it]  4%|▍         | 545/12825 [1:57:21<43:06:32, 12.64s/it]  4%|▍         | 546/12825 [1:57:34<43:06:06, 12.64s/it]  4%|▍         | 547/12825 [1:57:46<43:05:20, 12.63s/it]  4%|▍         | 548/12825 [1:57:59<43:06:23, 12.64s/it]  4%|▍         | 549/12825 [1:58:20<51:40:54, 15.16s/it]  4%|▍         | 550/12825 [1:58:33<49:11:55, 14.43s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120477.38lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103763.28lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-525] due to args.save_total_limit
  4%|▍         | 551/12825 [1:58:46<47:44:34, 14.00s/it]  4%|▍         | 552/12825 [1:58:58<46:19:43, 13.59s/it]  4%|▍         | 553/12825 [1:59:11<45:19:03, 13.29s/it]  4%|▍         | 554/12825 [1:59:23<44:41:12, 13.11s/it]  4%|▍         | 555/12825 [1:59:36<44:12:14, 12.97s/it]  4%|▍         | 556/12825 [1:59:49<43:51:10, 12.87s/it]  4%|▍         | 557/12825 [2:00:02<43:48:48, 12.86s/it]  4%|▍         | 558/12825 [2:00:14<43:34:27, 12.79s/it]  4%|▍         | 559/12825 [2:00:27<43:23:51, 12.74s/it]  4%|▍         | 560/12825 [2:00:39<43:13:35, 12.69s/it]  4%|▍         | 561/12825 [2:00:52<43:06:53, 12.66s/it]  4%|▍         | 562/12825 [2:01:05<43:06:15, 12.65s/it]  4%|▍         | 563/12825 [2:01:17<43:08:23, 12.67s/it]  4%|▍         | 564/12825 [2:01:30<43:06:40, 12.66s/it]  4%|▍         | 565/12825 [2:01:43<43:08:28, 12.67s/it]  4%|▍         | 566/12825 [2:01:55<43:12:03, 12.69s/it]  4%|▍         | 567/12825 [2:02:08<43:08:56, 12.67s/it]  4%|▍         | 568/12825 [2:02:21<43:05:10, 12.65s/it]  4%|▍         | 569/12825 [2:02:33<43:00:17, 12.63s/it]  4%|▍         | 570/12825 [2:02:46<43:00:04, 12.63s/it]  4%|▍         | 571/12825 [2:02:58<42:58:22, 12.62s/it]  4%|▍         | 572/12825 [2:03:11<42:57:41, 12.62s/it]  4%|▍         | 573/12825 [2:03:24<42:56:56, 12.62s/it]  4%|▍         | 574/12825 [2:03:36<42:56:08, 12.62s/it]  4%|▍         | 575/12825 [2:03:49<42:56:19, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120414.99lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103657.00lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-550] due to args.save_total_limit
  4%|▍         | 576/12825 [2:04:02<43:17:36, 12.72s/it]  4%|▍         | 577/12825 [2:04:15<43:14:44, 12.71s/it]  5%|▍         | 578/12825 [2:04:27<43:08:38, 12.68s/it]  5%|▍         | 579/12825 [2:04:40<43:05:52, 12.67s/it]  5%|▍         | 580/12825 [2:04:52<43:02:15, 12.65s/it]  5%|▍         | 581/12825 [2:05:13<50:45:44, 14.93s/it]  5%|▍         | 582/12825 [2:05:25<48:21:29, 14.22s/it]  5%|▍         | 583/12825 [2:05:38<46:44:13, 13.74s/it]  5%|▍         | 584/12825 [2:05:50<45:34:55, 13.41s/it]  5%|▍         | 585/12825 [2:06:03<44:44:49, 13.16s/it]  5%|▍         | 586/12825 [2:06:16<44:09:32, 12.99s/it]  5%|▍         | 587/12825 [2:06:28<43:45:21, 12.87s/it]  5%|▍         | 588/12825 [2:06:41<43:26:11, 12.78s/it]  5%|▍         | 589/12825 [2:06:53<43:13:55, 12.72s/it]  5%|▍         | 590/12825 [2:07:06<43:07:03, 12.69s/it]  5%|▍         | 591/12825 [2:07:19<43:03:30, 12.67s/it]  5%|▍         | 592/12825 [2:07:31<42:58:32, 12.65s/it]  5%|▍         | 593/12825 [2:07:44<42:55:50, 12.63s/it]  5%|▍         | 594/12825 [2:07:56<42:51:41, 12.62s/it]  5%|▍         | 595/12825 [2:08:09<42:51:46, 12.62s/it]  5%|▍         | 596/12825 [2:08:22<42:49:46, 12.61s/it]  5%|▍         | 597/12825 [2:08:34<42:49:47, 12.61s/it]  5%|▍         | 598/12825 [2:08:47<42:50:54, 12.62s/it]  5%|▍         | 599/12825 [2:09:00<42:52:11, 12.62s/it]  5%|▍         | 600/12825 [2:09:12<42:52:03, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120533.67lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103701.80lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-575] due to args.save_total_limit
  5%|▍         | 601/12825 [2:09:25<43:15:51, 12.74s/it]  5%|▍         | 602/12825 [2:09:38<43:07:50, 12.70s/it]  5%|▍         | 603/12825 [2:09:50<43:04:45, 12.69s/it]  5%|▍         | 604/12825 [2:10:03<42:58:53, 12.66s/it]  5%|▍         | 605/12825 [2:10:16<43:04:45, 12.69s/it]  5%|▍         | 606/12825 [2:10:29<43:07:40, 12.71s/it]  5%|▍         | 607/12825 [2:10:41<43:01:10, 12.68s/it]  5%|▍         | 608/12825 [2:10:54<42:58:43, 12.66s/it]  5%|▍         | 609/12825 [2:11:06<42:56:32, 12.65s/it]  5%|▍         | 610/12825 [2:11:19<42:55:34, 12.65s/it]  5%|▍         | 611/12825 [2:11:32<42:53:03, 12.64s/it]  5%|▍         | 612/12825 [2:11:44<42:50:13, 12.63s/it]  5%|▍         | 613/12825 [2:11:57<42:50:18, 12.63s/it]  5%|▍         | 614/12825 [2:12:18<51:14:51, 15.11s/it]  5%|▍         | 615/12825 [2:12:30<48:39:02, 14.34s/it]  5%|▍         | 616/12825 [2:12:43<46:49:31, 13.81s/it]  5%|▍         | 617/12825 [2:12:56<45:37:41, 13.46s/it]  5%|▍         | 618/12825 [2:13:08<44:44:18, 13.19s/it]  5%|▍         | 619/12825 [2:13:21<44:06:40, 13.01s/it]  5%|▍         | 620/12825 [2:13:33<43:40:51, 12.88s/it]  5%|▍         | 621/12825 [2:13:46<43:28:26, 12.82s/it]  5%|▍         | 622/12825 [2:13:59<43:13:52, 12.75s/it]  5%|▍         | 623/12825 [2:14:11<43:03:35, 12.70s/it]  5%|▍         | 624/12825 [2:14:24<42:54:00, 12.66s/it]  5%|▍         | 625/12825 [2:14:36<42:51:59, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120466.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103735.62lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-600] due to args.save_total_limit
  5%|▍         | 626/12825 [2:14:49<43:09:20, 12.74s/it]  5%|▍         | 627/12825 [2:15:02<43:01:00, 12.70s/it]  5%|▍         | 628/12825 [2:15:14<42:56:37, 12.68s/it]  5%|▍         | 629/12825 [2:15:27<42:52:56, 12.66s/it]  5%|▍         | 630/12825 [2:15:40<42:48:43, 12.64s/it]  5%|▍         | 631/12825 [2:15:52<42:49:05, 12.64s/it]  5%|▍         | 632/12825 [2:16:05<42:44:48, 12.62s/it]  5%|▍         | 633/12825 [2:16:18<42:45:06, 12.62s/it]  5%|▍         | 634/12825 [2:16:30<42:42:47, 12.61s/it]  5%|▍         | 635/12825 [2:16:43<42:41:53, 12.61s/it]  5%|▍         | 636/12825 [2:16:55<42:48:24, 12.64s/it]  5%|▍         | 637/12825 [2:17:08<42:44:50, 12.63s/it]  5%|▍         | 638/12825 [2:17:21<42:43:27, 12.62s/it]  5%|▍         | 639/12825 [2:17:33<42:44:23, 12.63s/it]  5%|▍         | 640/12825 [2:17:46<42:42:57, 12.62s/it]  5%|▍         | 641/12825 [2:17:59<42:40:57, 12.61s/it]  5%|▌         | 642/12825 [2:18:11<42:39:55, 12.61s/it]  5%|▌         | 643/12825 [2:18:24<42:38:46, 12.60s/it]  5%|▌         | 644/12825 [2:18:36<42:39:53, 12.61s/it]  5%|▌         | 645/12825 [2:18:49<42:36:22, 12.59s/it]  5%|▌         | 646/12825 [2:19:10<50:54:56, 15.05s/it]  5%|▌         | 647/12825 [2:19:22<48:24:59, 14.31s/it]  5%|▌         | 648/12825 [2:19:35<46:39:06, 13.79s/it]  5%|▌         | 649/12825 [2:19:47<45:26:43, 13.44s/it]  5%|▌         | 650/12825 [2:20:00<44:35:05, 13.18s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120483.41lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103780.30lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-625] due to args.save_total_limit
  5%|▌         | 651/12825 [2:20:13<44:17:49, 13.10s/it]  5%|▌         | 652/12825 [2:20:26<43:49:32, 12.96s/it]  5%|▌         | 653/12825 [2:20:38<43:29:02, 12.86s/it]  5%|▌         | 654/12825 [2:20:51<43:14:32, 12.79s/it]  5%|▌         | 655/12825 [2:21:03<43:02:17, 12.73s/it]  5%|▌         | 656/12825 [2:21:16<42:56:04, 12.70s/it]  5%|▌         | 657/12825 [2:21:29<42:50:15, 12.67s/it]  5%|▌         | 658/12825 [2:21:41<42:46:52, 12.66s/it]  5%|▌         | 659/12825 [2:21:54<42:43:30, 12.64s/it]  5%|▌         | 660/12825 [2:22:06<42:41:46, 12.64s/it]  5%|▌         | 661/12825 [2:22:19<42:41:12, 12.63s/it]  5%|▌         | 662/12825 [2:22:32<42:37:52, 12.62s/it]  5%|▌         | 663/12825 [2:22:44<42:37:23, 12.62s/it]  5%|▌         | 664/12825 [2:22:57<42:38:35, 12.62s/it]  5%|▌         | 665/12825 [2:23:10<42:38:59, 12.63s/it]  5%|▌         | 666/12825 [2:23:22<42:40:38, 12.64s/it]  5%|▌         | 667/12825 [2:23:35<42:41:41, 12.64s/it]  5%|▌         | 668/12825 [2:23:48<42:40:22, 12.64s/it]  5%|▌         | 669/12825 [2:24:00<42:39:48, 12.63s/it]  5%|▌         | 670/12825 [2:24:13<42:39:56, 12.64s/it]  5%|▌         | 671/12825 [2:24:25<42:38:44, 12.63s/it]  5%|▌         | 672/12825 [2:24:38<42:37:27, 12.63s/it]  5%|▌         | 673/12825 [2:24:51<42:35:22, 12.62s/it]  5%|▌         | 674/12825 [2:25:03<42:37:27, 12.63s/it]  5%|▌         | 675/12825 [2:25:16<42:41:11, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120495.97lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103717.29lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-650] due to args.save_total_limit
  5%|▌         | 676/12825 [2:25:29<42:59:48, 12.74s/it]  5%|▌         | 677/12825 [2:25:42<42:54:13, 12.71s/it]  5%|▌         | 678/12825 [2:25:54<42:48:43, 12.69s/it]  5%|▌         | 679/12825 [2:26:15<51:14:24, 15.19s/it]  5%|▌         | 680/12825 [2:26:28<48:34:15, 14.40s/it]  5%|▌         | 681/12825 [2:26:40<46:44:44, 13.86s/it]  5%|▌         | 682/12825 [2:26:53<45:28:36, 13.48s/it]  5%|▌         | 683/12825 [2:27:06<44:34:38, 13.22s/it]  5%|▌         | 684/12825 [2:27:18<44:03:46, 13.07s/it]  5%|▌         | 685/12825 [2:27:31<43:33:48, 12.92s/it]  5%|▌         | 686/12825 [2:27:44<43:15:40, 12.83s/it]  5%|▌         | 687/12825 [2:27:56<43:03:54, 12.77s/it]  5%|▌         | 688/12825 [2:28:09<42:52:56, 12.72s/it]  5%|▌         | 689/12825 [2:28:21<42:45:27, 12.68s/it]  5%|▌         | 690/12825 [2:28:34<42:40:51, 12.66s/it]  5%|▌         | 691/12825 [2:28:47<42:39:20, 12.66s/it]  5%|▌         | 692/12825 [2:28:59<42:35:11, 12.64s/it]  5%|▌         | 693/12825 [2:29:12<42:31:44, 12.62s/it]  5%|▌         | 694/12825 [2:29:24<42:29:23, 12.61s/it]  5%|▌         | 695/12825 [2:29:37<42:31:16, 12.62s/it]  5%|▌         | 696/12825 [2:29:50<42:35:39, 12.64s/it]  5%|▌         | 697/12825 [2:30:02<42:33:25, 12.63s/it]  5%|▌         | 698/12825 [2:30:15<42:29:00, 12.61s/it]  5%|▌         | 699/12825 [2:30:27<42:28:12, 12.61s/it]  5%|▌         | 700/12825 [2:30:40<42:26:46, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120490.20lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103688.42lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-675] due to args.save_total_limit
  5%|▌         | 701/12825 [2:30:53<42:49:42, 12.72s/it]  5%|▌         | 702/12825 [2:31:06<42:43:24, 12.69s/it]  5%|▌         | 703/12825 [2:31:18<42:44:46, 12.69s/it]  5%|▌         | 704/12825 [2:31:31<42:44:23, 12.69s/it]  5%|▌         | 705/12825 [2:31:44<42:39:11, 12.67s/it]  6%|▌         | 706/12825 [2:31:56<42:34:37, 12.65s/it]  6%|▌         | 707/12825 [2:32:09<42:33:17, 12.64s/it]  6%|▌         | 708/12825 [2:32:22<42:34:22, 12.65s/it]  6%|▌         | 709/12825 [2:32:34<42:33:24, 12.64s/it]  6%|▌         | 710/12825 [2:32:47<42:31:14, 12.64s/it]  6%|▌         | 711/12825 [2:33:08<50:53:25, 15.12s/it]  6%|▌         | 712/12825 [2:33:20<48:18:50, 14.36s/it]  6%|▌         | 713/12825 [2:33:33<46:32:23, 13.83s/it]  6%|▌         | 714/12825 [2:33:46<45:17:13, 13.46s/it]  6%|▌         | 715/12825 [2:33:58<44:27:32, 13.22s/it]  6%|▌         | 716/12825 [2:34:11<43:51:23, 13.04s/it]  6%|▌         | 717/12825 [2:34:23<43:25:35, 12.91s/it]  6%|▌         | 718/12825 [2:34:36<43:07:06, 12.82s/it]  6%|▌         | 719/12825 [2:34:49<42:58:17, 12.78s/it]  6%|▌         | 720/12825 [2:35:01<42:48:53, 12.73s/it]  6%|▌         | 721/12825 [2:35:14<42:41:12, 12.70s/it]  6%|▌         | 722/12825 [2:35:27<42:35:56, 12.67s/it]  6%|▌         | 723/12825 [2:35:39<42:33:16, 12.66s/it]  6%|▌         | 724/12825 [2:35:52<42:29:14, 12.64s/it]  6%|▌         | 725/12825 [2:36:04<42:27:24, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120504.69lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103714.06lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-725
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-725/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-725/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-700] due to args.save_total_limit
  6%|▌         | 726/12825 [2:36:17<42:46:57, 12.73s/it]  6%|▌         | 727/12825 [2:36:30<42:40:34, 12.70s/it]  6%|▌         | 728/12825 [2:36:43<42:36:35, 12.68s/it]  6%|▌         | 729/12825 [2:36:55<42:30:44, 12.65s/it]  6%|▌         | 730/12825 [2:37:08<42:27:32, 12.64s/it]  6%|▌         | 731/12825 [2:37:20<42:26:05, 12.63s/it]  6%|▌         | 732/12825 [2:37:33<42:26:04, 12.63s/it]  6%|▌         | 733/12825 [2:37:46<42:24:12, 12.62s/it]  6%|▌         | 734/12825 [2:37:58<42:25:34, 12.63s/it]  6%|▌         | 735/12825 [2:38:11<42:25:44, 12.63s/it]  6%|▌         | 736/12825 [2:38:24<42:24:48, 12.63s/it]  6%|▌         | 737/12825 [2:38:36<42:25:04, 12.63s/it]  6%|▌         | 738/12825 [2:38:49<42:25:13, 12.63s/it]  6%|▌         | 739/12825 [2:39:02<42:27:46, 12.65s/it]  6%|▌         | 740/12825 [2:39:14<42:25:59, 12.64s/it]  6%|▌         | 741/12825 [2:39:27<42:25:35, 12.64s/it]  6%|▌         | 742/12825 [2:39:40<42:33:13, 12.68s/it]  6%|▌         | 743/12825 [2:40:01<51:01:24, 15.20s/it]  6%|▌         | 744/12825 [2:40:13<48:23:57, 14.42s/it]  6%|▌         | 745/12825 [2:40:26<46:33:45, 13.88s/it]  6%|▌         | 746/12825 [2:40:38<45:20:05, 13.51s/it]  6%|▌         | 747/12825 [2:40:51<44:27:39, 13.25s/it]  6%|▌         | 748/12825 [2:41:04<43:49:46, 13.07s/it]  6%|▌         | 749/12825 [2:41:16<43:21:30, 12.93s/it]  6%|▌         | 750/12825 [2:41:29<43:03:52, 12.84s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120443.17lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103665.45lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-750
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-750/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-750/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-725] due to args.save_total_limit
  6%|▌         | 751/12825 [2:41:42<43:10:42, 12.87s/it]  6%|▌         | 752/12825 [2:41:55<42:57:38, 12.81s/it]  6%|▌         | 753/12825 [2:42:07<42:46:26, 12.76s/it]  6%|▌         | 754/12825 [2:42:20<42:38:15, 12.72s/it]  6%|▌         | 755/12825 [2:42:32<42:32:09, 12.69s/it]  6%|▌         | 756/12825 [2:42:45<42:27:01, 12.66s/it]  6%|▌         | 757/12825 [2:42:58<42:24:59, 12.65s/it]  6%|▌         | 758/12825 [2:43:10<42:24:55, 12.65s/it]  6%|▌         | 759/12825 [2:43:23<42:24:33, 12.65s/it]  6%|▌         | 760/12825 [2:43:36<42:25:25, 12.66s/it]  6%|▌         | 761/12825 [2:43:48<42:24:01, 12.65s/it]  6%|▌         | 762/12825 [2:44:01<42:21:25, 12.64s/it]  6%|▌         | 763/12825 [2:44:14<42:18:40, 12.63s/it]  6%|▌         | 764/12825 [2:44:26<42:17:28, 12.62s/it]  6%|▌         | 765/12825 [2:44:39<42:17:19, 12.62s/it]  6%|▌         | 766/12825 [2:44:52<42:22:27, 12.65s/it]  6%|▌         | 767/12825 [2:45:04<42:20:40, 12.64s/it]  6%|▌         | 768/12825 [2:45:17<42:19:59, 12.64s/it]  6%|▌         | 769/12825 [2:45:29<42:19:34, 12.64s/it]  6%|▌         | 770/12825 [2:45:42<42:20:27, 12.64s/it]  6%|▌         | 771/12825 [2:45:55<42:19:42, 12.64s/it]  6%|▌         | 772/12825 [2:46:07<42:19:00, 12.64s/it]  6%|▌         | 773/12825 [2:46:20<42:17:52, 12.63s/it]  6%|▌         | 774/12825 [2:46:33<42:17:25, 12.63s/it]  6%|▌         | 775/12825 [2:46:53<50:32:39, 15.10s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120455.21lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103500.31lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-775
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-775/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-775/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-750] due to args.save_total_limit
  6%|▌         | 776/12825 [2:47:06<48:25:01, 14.47s/it]  6%|▌         | 777/12825 [2:47:19<46:31:52, 13.90s/it]  6%|▌         | 778/12825 [2:47:32<45:14:25, 13.52s/it]  6%|▌         | 779/12825 [2:47:44<44:18:46, 13.24s/it]  6%|▌         | 780/12825 [2:47:57<43:42:15, 13.06s/it]  6%|▌         | 781/12825 [2:48:09<43:13:28, 12.92s/it]  6%|▌         | 782/12825 [2:48:22<42:55:29, 12.83s/it]  6%|▌         | 783/12825 [2:48:35<42:43:50, 12.77s/it]  6%|▌         | 784/12825 [2:48:47<42:35:37, 12.73s/it]  6%|▌         | 785/12825 [2:49:00<42:29:37, 12.71s/it]  6%|▌         | 786/12825 [2:49:13<42:25:59, 12.69s/it]  6%|▌         | 787/12825 [2:49:25<42:23:58, 12.68s/it]  6%|▌         | 788/12825 [2:49:38<42:19:44, 12.66s/it]  6%|▌         | 789/12825 [2:49:51<42:16:25, 12.64s/it]  6%|▌         | 790/12825 [2:50:03<42:14:57, 12.64s/it]  6%|▌         | 791/12825 [2:50:16<42:15:16, 12.64s/it]  6%|▌         | 792/12825 [2:50:29<42:19:11, 12.66s/it]  6%|▌         | 793/12825 [2:50:41<42:17:02, 12.65s/it]  6%|▌         | 794/12825 [2:50:54<42:14:52, 12.64s/it]  6%|▌         | 795/12825 [2:51:06<42:13:08, 12.63s/it]  6%|▌         | 796/12825 [2:51:19<42:12:36, 12.63s/it]  6%|▌         | 797/12825 [2:51:32<42:11:53, 12.63s/it]  6%|▌         | 798/12825 [2:51:44<42:10:44, 12.63s/it]  6%|▌         | 799/12825 [2:51:57<42:09:41, 12.62s/it]  6%|▌         | 800/12825 [2:52:09<42:08:41, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120490.84lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103689.08lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-800
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-800/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-800/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-775] due to args.save_total_limit
  6%|▌         | 801/12825 [2:52:22<42:28:07, 12.72s/it]  6%|▋         | 802/12825 [2:52:35<42:23:51, 12.69s/it]  6%|▋         | 803/12825 [2:52:48<42:20:20, 12.68s/it]  6%|▋         | 804/12825 [2:53:00<42:16:36, 12.66s/it]  6%|▋         | 805/12825 [2:53:13<42:19:43, 12.68s/it]  6%|▋         | 806/12825 [2:53:26<42:17:27, 12.67s/it]  6%|▋         | 807/12825 [2:53:38<42:12:58, 12.65s/it]  6%|▋         | 808/12825 [2:53:59<50:29:34, 15.13s/it]  6%|▋         | 809/12825 [2:54:12<47:57:25, 14.37s/it]  6%|▋         | 810/12825 [2:54:24<46:12:08, 13.84s/it]  6%|▋         | 811/12825 [2:54:37<44:56:28, 13.47s/it]  6%|▋         | 812/12825 [2:54:50<44:04:10, 13.21s/it]  6%|▋         | 813/12825 [2:55:02<43:26:35, 13.02s/it]  6%|▋         | 814/12825 [2:55:15<43:03:12, 12.90s/it]  6%|▋         | 815/12825 [2:55:27<42:46:15, 12.82s/it]  6%|▋         | 816/12825 [2:55:40<42:34:41, 12.76s/it]  6%|▋         | 817/12825 [2:55:53<42:29:35, 12.74s/it]  6%|▋         | 818/12825 [2:56:05<42:24:41, 12.72s/it]  6%|▋         | 819/12825 [2:56:18<42:21:34, 12.70s/it]  6%|▋         | 820/12825 [2:56:31<42:17:07, 12.68s/it]  6%|▋         | 821/12825 [2:56:43<42:13:29, 12.66s/it]  6%|▋         | 822/12825 [2:56:56<42:07:56, 12.64s/it]  6%|▋         | 823/12825 [2:57:09<42:06:50, 12.63s/it]  6%|▋         | 824/12825 [2:57:21<42:05:05, 12.62s/it]  6%|▋         | 825/12825 [2:57:34<42:01:54, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120416.15lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103726.03lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-825
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-825/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-825/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-800] due to args.save_total_limit
  6%|▋         | 826/12825 [2:57:47<42:24:01, 12.72s/it]  6%|▋         | 827/12825 [2:57:59<42:17:12, 12.69s/it]  6%|▋         | 828/12825 [2:58:12<42:19:41, 12.70s/it]  6%|▋         | 829/12825 [2:58:25<42:18:02, 12.69s/it]  6%|▋         | 830/12825 [2:58:37<42:18:11, 12.70s/it]  6%|▋         | 831/12825 [2:58:50<42:18:11, 12.70s/it]  6%|▋         | 832/12825 [2:59:03<42:21:26, 12.71s/it]  6%|▋         | 833/12825 [2:59:16<42:22:27, 12.72s/it]  7%|▋         | 834/12825 [2:59:28<42:22:36, 12.72s/it]  7%|▋         | 835/12825 [2:59:41<42:22:47, 12.72s/it]  7%|▋         | 836/12825 [2:59:54<42:22:09, 12.72s/it]  7%|▋         | 837/12825 [3:00:07<42:25:10, 12.74s/it]  7%|▋         | 838/12825 [3:00:19<42:24:32, 12.74s/it]  7%|▋         | 839/12825 [3:00:32<42:21:00, 12.72s/it]  7%|▋         | 840/12825 [3:00:53<50:48:22, 15.26s/it]  7%|▋         | 841/12825 [3:01:06<48:13:41, 14.49s/it]  7%|▋         | 842/12825 [3:01:19<46:26:43, 13.95s/it]  7%|▋         | 843/12825 [3:01:31<45:11:11, 13.58s/it]  7%|▋         | 844/12825 [3:01:44<44:20:14, 13.32s/it]  7%|▋         | 845/12825 [3:01:57<43:42:30, 13.13s/it]  7%|▋         | 846/12825 [3:02:09<43:16:58, 13.01s/it]  7%|▋         | 847/12825 [3:02:22<43:00:12, 12.92s/it]  7%|▋         | 848/12825 [3:02:35<42:49:46, 12.87s/it]  7%|▋         | 849/12825 [3:02:48<42:40:12, 12.83s/it]  7%|▋         | 850/12825 [3:03:00<42:36:57, 12.81s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120324.54lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103605.32lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-850
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-850/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-850/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-825] due to args.save_total_limit
  7%|▋         | 851/12825 [3:03:13<42:52:05, 12.89s/it]  7%|▋         | 852/12825 [3:03:26<42:45:10, 12.85s/it]  7%|▋         | 853/12825 [3:03:39<42:44:32, 12.85s/it]  7%|▋         | 854/12825 [3:03:52<42:35:47, 12.81s/it]  7%|▋         | 855/12825 [3:04:05<42:30:43, 12.79s/it]  7%|▋         | 856/12825 [3:04:17<42:28:30, 12.78s/it]  7%|▋         | 857/12825 [3:04:30<42:30:04, 12.78s/it]  7%|▋         | 858/12825 [3:04:43<42:25:59, 12.77s/it]  7%|▋         | 859/12825 [3:04:56<42:25:51, 12.77s/it]  7%|▋         | 860/12825 [3:05:08<42:21:53, 12.75s/it]  7%|▋         | 861/12825 [3:05:21<42:28:50, 12.78s/it]  7%|▋         | 862/12825 [3:05:34<42:25:33, 12.77s/it]  7%|▋         | 863/12825 [3:05:47<42:28:12, 12.78s/it]  7%|▋         | 864/12825 [3:05:59<42:25:47, 12.77s/it]  7%|▋         | 865/12825 [3:06:12<42:24:40, 12.77s/it]  7%|▋         | 866/12825 [3:06:25<42:19:42, 12.74s/it]  7%|▋         | 867/12825 [3:06:38<42:19:04, 12.74s/it]  7%|▋         | 868/12825 [3:06:50<42:18:30, 12.74s/it]  7%|▋         | 869/12825 [3:07:03<42:19:23, 12.74s/it]  7%|▋         | 870/12825 [3:07:16<42:19:09, 12.74s/it]  7%|▋         | 871/12825 [3:07:29<42:17:13, 12.73s/it]  7%|▋         | 872/12825 [3:07:41<42:14:33, 12.72s/it]  7%|▋         | 873/12825 [3:08:02<50:35:01, 15.24s/it]  7%|▋         | 874/12825 [3:08:15<48:05:51, 14.49s/it]  7%|▋         | 875/12825 [3:08:28<46:20:50, 13.96s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120317.76lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103561.74lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-875
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-875/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-875/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-850] due to args.save_total_limit
  7%|▋         | 876/12825 [3:08:41<45:29:31, 13.71s/it]  7%|▋         | 877/12825 [3:08:54<44:33:12, 13.42s/it]  7%|▋         | 878/12825 [3:09:07<43:59:49, 13.26s/it]  7%|▋         | 879/12825 [3:09:19<43:31:25, 13.12s/it]  7%|▋         | 880/12825 [3:09:32<43:13:04, 13.03s/it]  7%|▋         | 881/12825 [3:09:45<42:57:38, 12.95s/it]  7%|▋         | 882/12825 [3:09:58<42:47:52, 12.90s/it]  7%|▋         | 883/12825 [3:10:11<42:43:13, 12.88s/it]  7%|▋         | 884/12825 [3:10:23<42:43:25, 12.88s/it]  7%|▋         | 885/12825 [3:10:36<42:43:23, 12.88s/it]  7%|▋         | 886/12825 [3:10:49<42:38:31, 12.86s/it]  7%|▋         | 887/12825 [3:11:02<42:34:43, 12.84s/it]  7%|▋         | 888/12825 [3:11:15<42:31:10, 12.82s/it]  7%|▋         | 889/12825 [3:11:27<42:29:35, 12.82s/it]  7%|▋         | 890/12825 [3:11:40<42:28:22, 12.81s/it]  7%|▋         | 891/12825 [3:11:53<42:26:50, 12.80s/it]  7%|▋         | 892/12825 [3:12:06<42:28:14, 12.81s/it]  7%|▋         | 893/12825 [3:12:19<42:26:14, 12.80s/it]  7%|▋         | 894/12825 [3:12:31<42:25:34, 12.80s/it]  7%|▋         | 895/12825 [3:12:44<42:25:42, 12.80s/it]  7%|▋         | 896/12825 [3:12:57<42:28:04, 12.82s/it]  7%|▋         | 897/12825 [3:13:10<42:29:52, 12.83s/it]  7%|▋         | 898/12825 [3:13:23<42:25:36, 12.81s/it]  7%|▋         | 899/12825 [3:13:36<42:23:34, 12.80s/it]  7%|▋         | 900/12825 [3:13:48<42:21:50, 12.79s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120398.99lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103609.11lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-900
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-900/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-900/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-875] due to args.save_total_limit
  7%|▋         | 901/12825 [3:14:01<42:42:17, 12.89s/it]  7%|▋         | 902/12825 [3:14:14<42:36:30, 12.87s/it]  7%|▋         | 903/12825 [3:14:27<42:30:47, 12.84s/it]  7%|▋         | 904/12825 [3:14:40<42:28:03, 12.82s/it]  7%|▋         | 905/12825 [3:15:00<50:12:30, 15.16s/it]  7%|▋         | 906/12825 [3:15:13<47:48:19, 14.44s/it]  7%|▋         | 907/12825 [3:15:26<46:10:04, 13.95s/it]  7%|▋         | 908/12825 [3:15:39<45:01:51, 13.60s/it]  7%|▋         | 909/12825 [3:15:52<44:11:15, 13.35s/it]  7%|▋         | 910/12825 [3:16:04<43:43:00, 13.21s/it]  7%|▋         | 911/12825 [3:16:17<43:18:58, 13.09s/it]  7%|▋         | 912/12825 [3:16:30<42:59:26, 12.99s/it]  7%|▋         | 913/12825 [3:16:43<42:55:33, 12.97s/it]  7%|▋         | 914/12825 [3:16:56<42:49:25, 12.94s/it]  7%|▋         | 915/12825 [3:17:09<42:41:08, 12.90s/it]  7%|▋         | 916/12825 [3:17:21<42:38:37, 12.89s/it]  7%|▋         | 917/12825 [3:17:34<42:33:15, 12.86s/it]  7%|▋         | 918/12825 [3:17:47<42:30:20, 12.85s/it]  7%|▋         | 919/12825 [3:18:00<42:24:39, 12.82s/it]  7%|▋         | 920/12825 [3:18:13<42:22:54, 12.82s/it]  7%|▋         | 921/12825 [3:18:25<42:20:46, 12.81s/it]  7%|▋         | 922/12825 [3:18:38<42:19:50, 12.80s/it]  7%|▋         | 923/12825 [3:18:51<42:20:21, 12.81s/it]  7%|▋         | 924/12825 [3:19:04<42:18:57, 12.80s/it]  7%|▋         | 925/12825 [3:19:17<42:18:28, 12.80s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120429.08lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103687.56lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-925
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-925/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-925/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-900] due to args.save_total_limit
  7%|▋         | 926/12825 [3:19:30<42:37:42, 12.90s/it]  7%|▋         | 927/12825 [3:19:43<42:31:49, 12.87s/it]  7%|▋         | 928/12825 [3:19:55<42:28:17, 12.85s/it]  7%|▋         | 929/12825 [3:20:08<42:23:44, 12.83s/it]  7%|▋         | 930/12825 [3:20:21<42:22:17, 12.82s/it]  7%|▋         | 931/12825 [3:20:34<42:19:13, 12.81s/it]  7%|▋         | 932/12825 [3:20:47<42:17:54, 12.80s/it]  7%|▋         | 933/12825 [3:21:00<42:31:04, 12.87s/it]  7%|▋         | 934/12825 [3:21:12<42:25:46, 12.85s/it]  7%|▋         | 935/12825 [3:21:25<42:24:08, 12.84s/it]  7%|▋         | 936/12825 [3:21:38<42:29:00, 12.86s/it]  7%|▋         | 937/12825 [3:21:59<50:36:12, 15.32s/it]  7%|▋         | 938/12825 [3:22:12<48:10:32, 14.59s/it]  7%|▋         | 939/12825 [3:22:25<46:24:03, 14.05s/it]  7%|▋         | 940/12825 [3:22:38<45:09:59, 13.68s/it]  7%|▋         | 941/12825 [3:22:50<44:19:54, 13.43s/it]  7%|▋         | 942/12825 [3:23:03<43:42:57, 13.24s/it]  7%|▋         | 943/12825 [3:23:16<43:15:53, 13.11s/it]  7%|▋         | 944/12825 [3:23:29<42:56:09, 13.01s/it]  7%|▋         | 945/12825 [3:23:42<42:41:20, 12.94s/it]  7%|▋         | 946/12825 [3:23:54<42:36:12, 12.91s/it]  7%|▋         | 947/12825 [3:24:07<42:29:28, 12.88s/it]  7%|▋         | 948/12825 [3:24:20<42:25:36, 12.86s/it]  7%|▋         | 949/12825 [3:24:33<42:23:27, 12.85s/it]  7%|▋         | 950/12825 [3:24:46<42:18:33, 12.83s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120309.46lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103561.74lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-950
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-950/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-950/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-925] due to args.save_total_limit
  7%|▋         | 951/12825 [3:24:59<42:37:41, 12.92s/it]  7%|▋         | 952/12825 [3:25:12<42:31:02, 12.89s/it]  7%|▋         | 953/12825 [3:25:24<42:25:38, 12.87s/it]  7%|▋         | 954/12825 [3:25:37<42:20:26, 12.84s/it]  7%|▋         | 955/12825 [3:25:50<42:15:38, 12.82s/it]  7%|▋         | 956/12825 [3:26:03<42:12:50, 12.80s/it]  7%|▋         | 957/12825 [3:26:16<42:12:28, 12.80s/it]  7%|▋         | 958/12825 [3:26:28<42:10:45, 12.80s/it]  7%|▋         | 959/12825 [3:26:41<42:09:25, 12.79s/it]  7%|▋         | 960/12825 [3:26:54<42:09:50, 12.79s/it]  7%|▋         | 961/12825 [3:27:07<42:08:40, 12.79s/it]  8%|▊         | 962/12825 [3:27:20<42:10:28, 12.80s/it]  8%|▊         | 963/12825 [3:27:32<42:11:51, 12.81s/it]  8%|▊         | 964/12825 [3:27:45<42:18:54, 12.84s/it]  8%|▊         | 965/12825 [3:27:58<42:18:54, 12.84s/it]  8%|▊         | 966/12825 [3:28:11<42:16:02, 12.83s/it]  8%|▊         | 967/12825 [3:28:24<42:13:44, 12.82s/it]  8%|▊         | 968/12825 [3:28:37<42:12:57, 12.82s/it]  8%|▊         | 969/12825 [3:28:49<42:12:12, 12.81s/it]  8%|▊         | 970/12825 [3:29:10<49:35:45, 15.06s/it]  8%|▊         | 971/12825 [3:29:23<47:27:00, 14.41s/it]  8%|▊         | 972/12825 [3:29:35<45:52:49, 13.93s/it]  8%|▊         | 973/12825 [3:29:48<44:43:27, 13.58s/it]  8%|▊         | 974/12825 [3:30:01<43:55:19, 13.34s/it]  8%|▊         | 975/12825 [3:30:14<43:21:33, 13.17s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120295.78lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103536.93lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-975
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-975/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-975/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-950] due to args.save_total_limit
  8%|▊         | 976/12825 [3:30:27<43:18:32, 13.16s/it]  8%|▊         | 977/12825 [3:30:40<42:57:01, 13.05s/it]  8%|▊         | 978/12825 [3:30:52<42:43:35, 12.98s/it]  8%|▊         | 979/12825 [3:31:05<42:36:52, 12.95s/it]  8%|▊         | 980/12825 [3:31:18<42:27:19, 12.90s/it]  8%|▊         | 981/12825 [3:31:31<42:20:31, 12.87s/it]  8%|▊         | 982/12825 [3:31:44<42:16:22, 12.85s/it]  8%|▊         | 983/12825 [3:31:56<42:12:25, 12.83s/it]  8%|▊         | 984/12825 [3:32:09<42:11:04, 12.83s/it]  8%|▊         | 985/12825 [3:32:22<42:08:55, 12.82s/it]  8%|▊         | 986/12825 [3:32:35<42:07:14, 12.81s/it]  8%|▊         | 987/12825 [3:32:48<42:05:14, 12.80s/it]  8%|▊         | 988/12825 [3:33:01<42:11:04, 12.83s/it]  8%|▊         | 989/12825 [3:33:13<42:08:55, 12.82s/it]  8%|▊         | 990/12825 [3:33:26<42:07:48, 12.82s/it]  8%|▊         | 991/12825 [3:33:39<42:07:01, 12.81s/it]  8%|▊         | 992/12825 [3:33:52<42:04:35, 12.80s/it]  8%|▊         | 993/12825 [3:34:05<42:02:15, 12.79s/it]  8%|▊         | 994/12825 [3:34:17<42:02:49, 12.79s/it]  8%|▊         | 995/12825 [3:34:30<42:01:42, 12.79s/it]  8%|▊         | 996/12825 [3:34:43<42:05:51, 12.81s/it]  8%|▊         | 997/12825 [3:34:56<42:06:46, 12.82s/it]  8%|▊         | 998/12825 [3:35:09<42:06:55, 12.82s/it]  8%|▊         | 999/12825 [3:35:21<42:07:49, 12.83s/it]  8%|▊         | 1000/12825 [3:35:34<42:06:59, 12.82s/it]                                                           8%|▊         | 1000/12825 [3:35:34<42:06:59, 12.82s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120237.03lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103512.04lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1000
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1000/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1000/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-975] due to args.save_total_limit
  8%|▊         | 1001/12825 [3:35:47<42:23:46, 12.91s/it]  8%|▊         | 1002/12825 [3:36:08<50:27:37, 15.36s/it]  8%|▊         | 1003/12825 [3:36:21<47:56:31, 14.60s/it]  8%|▊         | 1004/12825 [3:36:34<46:08:59, 14.05s/it]  8%|▊         | 1005/12825 [3:36:47<44:53:27, 13.67s/it]  8%|▊         | 1006/12825 [3:37:00<44:02:17, 13.41s/it]  8%|▊         | 1007/12825 [3:37:12<43:23:16, 13.22s/it]  8%|▊         | 1008/12825 [3:37:25<42:57:24, 13.09s/it]  8%|▊         | 1009/12825 [3:37:38<42:39:21, 13.00s/it]  8%|▊         | 1010/12825 [3:37:51<42:26:14, 12.93s/it]  8%|▊         | 1011/12825 [3:38:04<42:18:15, 12.89s/it]  8%|▊         | 1012/12825 [3:38:16<42:12:08, 12.86s/it]  8%|▊         | 1013/12825 [3:38:29<42:07:16, 12.84s/it]  8%|▊         | 1014/12825 [3:38:42<42:05:36, 12.83s/it]  8%|▊         | 1015/12825 [3:38:55<42:03:59, 12.82s/it]  8%|▊         | 1016/12825 [3:39:08<42:02:35, 12.82s/it]  8%|▊         | 1017/12825 [3:39:20<42:01:19, 12.81s/it]  8%|▊         | 1018/12825 [3:39:33<41:58:42, 12.80s/it]  8%|▊         | 1019/12825 [3:39:46<41:58:58, 12.80s/it]  8%|▊         | 1020/12825 [3:39:59<41:57:37, 12.80s/it]  8%|▊         | 1021/12825 [3:40:11<41:56:32, 12.79s/it]  8%|▊         | 1022/12825 [3:40:24<41:51:23, 12.77s/it]  8%|▊         | 1023/12825 [3:40:37<41:48:48, 12.75s/it]  8%|▊         | 1024/12825 [3:40:50<41:44:00, 12.73s/it]  8%|▊         | 1025/12825 [3:40:58<37:03:36, 11.31s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120312.27lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103525.85lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1025
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1025/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1025/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1000] due to args.save_total_limit
  8%|▊         | 1026/12825 [3:40:59<27:05:04,  8.26s/it]  8%|▊         | 1027/12825 [3:41:25<44:22:26, 13.54s/it]  8%|▊         | 1028/12825 [3:41:37<43:35:57, 13.30s/it]  8%|▊         | 1029/12825 [3:41:50<43:06:37, 13.16s/it]  8%|▊         | 1030/12825 [3:42:03<42:44:08, 13.04s/it]  8%|▊         | 1031/12825 [3:42:16<42:28:22, 12.96s/it]  8%|▊         | 1032/12825 [3:42:28<42:17:00, 12.91s/it]  8%|▊         | 1033/12825 [3:42:41<42:11:26, 12.88s/it]  8%|▊         | 1034/12825 [3:42:54<42:02:59, 12.84s/it]  8%|▊         | 1035/12825 [3:43:15<50:09:03, 15.31s/it]  8%|▊         | 1036/12825 [3:43:28<47:36:45, 14.54s/it]  8%|▊         | 1037/12825 [3:43:41<45:51:46, 14.01s/it]  8%|▊         | 1038/12825 [3:43:53<44:41:30, 13.65s/it]  8%|▊         | 1039/12825 [3:44:06<43:51:13, 13.40s/it]  8%|▊         | 1040/12825 [3:44:19<43:14:52, 13.21s/it]  8%|▊         | 1041/12825 [3:44:32<42:49:52, 13.08s/it]  8%|▊         | 1042/12825 [3:44:45<42:31:05, 12.99s/it]  8%|▊         | 1043/12825 [3:44:57<42:17:59, 12.92s/it]  8%|▊         | 1044/12825 [3:45:10<42:10:55, 12.89s/it]  8%|▊         | 1045/12825 [3:45:23<42:04:37, 12.86s/it]  8%|▊         | 1046/12825 [3:45:36<41:59:32, 12.83s/it]  8%|▊         | 1047/12825 [3:45:49<41:56:34, 12.82s/it]  8%|▊         | 1048/12825 [3:46:01<41:53:55, 12.81s/it]  8%|▊         | 1049/12825 [3:46:14<41:52:20, 12.80s/it]  8%|▊         | 1050/12825 [3:46:27<41:51:14, 12.80s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120148.88lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103494.44lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1050
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1050/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1050/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1025] due to args.save_total_limit
  8%|▊         | 1051/12825 [3:46:40<42:08:52, 12.89s/it]  8%|▊         | 1052/12825 [3:46:53<42:01:09, 12.85s/it]  8%|▊         | 1053/12825 [3:47:06<41:56:37, 12.83s/it]  8%|▊         | 1054/12825 [3:47:18<41:55:14, 12.82s/it]  8%|▊         | 1055/12825 [3:47:31<41:53:02, 12.81s/it]  8%|▊         | 1056/12825 [3:47:44<41:49:21, 12.79s/it]  8%|▊         | 1057/12825 [3:47:57<41:53:13, 12.81s/it]  8%|▊         | 1058/12825 [3:48:09<41:50:46, 12.80s/it]  8%|▊         | 1059/12825 [3:48:22<41:49:27, 12.80s/it]  8%|▊         | 1060/12825 [3:48:35<41:47:21, 12.79s/it]  8%|▊         | 1061/12825 [3:48:48<41:45:44, 12.78s/it]  8%|▊         | 1062/12825 [3:49:01<41:46:22, 12.78s/it]  8%|▊         | 1063/12825 [3:49:13<41:48:37, 12.80s/it]  8%|▊         | 1064/12825 [3:49:26<41:48:39, 12.80s/it]  8%|▊         | 1065/12825 [3:49:39<41:47:07, 12.79s/it]  8%|▊         | 1066/12825 [3:49:52<41:47:10, 12.79s/it]  8%|▊         | 1067/12825 [3:50:15<51:37:10, 15.80s/it]  8%|▊         | 1068/12825 [3:50:27<48:38:05, 14.89s/it]  8%|▊         | 1069/12825 [3:50:40<46:30:54, 14.24s/it]  8%|▊         | 1070/12825 [3:50:53<44:59:56, 13.78s/it]  8%|▊         | 1071/12825 [3:51:06<44:02:55, 13.49s/it]  8%|▊         | 1072/12825 [3:51:18<43:16:05, 13.25s/it]  8%|▊         | 1073/12825 [3:51:31<42:45:36, 13.10s/it]  8%|▊         | 1074/12825 [3:51:44<42:22:58, 12.98s/it]  8%|▊         | 1075/12825 [3:51:57<42:08:11, 12.91s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120243.54lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103481.02lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1075
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1075/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1075/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1050] due to args.save_total_limit
  8%|▊         | 1076/12825 [3:52:10<42:20:40, 12.97s/it]  8%|▊         | 1077/12825 [3:52:22<42:06:28, 12.90s/it]  8%|▊         | 1078/12825 [3:52:35<41:54:14, 12.84s/it]  8%|▊         | 1079/12825 [3:52:48<41:51:10, 12.83s/it]  8%|▊         | 1080/12825 [3:53:01<41:43:53, 12.79s/it]  8%|▊         | 1081/12825 [3:53:13<41:40:44, 12.78s/it]  8%|▊         | 1082/12825 [3:53:26<41:35:48, 12.75s/it]  8%|▊         | 1083/12825 [3:53:39<41:32:26, 12.74s/it]  8%|▊         | 1084/12825 [3:53:51<41:32:26, 12.74s/it]  8%|▊         | 1085/12825 [3:54:04<41:39:09, 12.77s/it]  8%|▊         | 1086/12825 [3:54:17<41:36:58, 12.76s/it]  8%|▊         | 1087/12825 [3:54:30<41:33:34, 12.75s/it]  8%|▊         | 1088/12825 [3:54:43<41:32:53, 12.74s/it]  8%|▊         | 1089/12825 [3:54:55<41:33:06, 12.75s/it]  8%|▊         | 1090/12825 [3:55:08<41:32:23, 12.74s/it]  9%|▊         | 1091/12825 [3:55:21<41:34:45, 12.76s/it]  9%|▊         | 1092/12825 [3:55:34<41:32:00, 12.74s/it]  9%|▊         | 1093/12825 [3:55:46<41:29:27, 12.73s/it]  9%|▊         | 1094/12825 [3:55:59<41:29:56, 12.74s/it]  9%|▊         | 1095/12825 [3:56:12<41:28:28, 12.73s/it]  9%|▊         | 1096/12825 [3:56:24<41:27:40, 12.73s/it]  9%|▊         | 1097/12825 [3:56:37<41:27:03, 12.72s/it]  9%|▊         | 1098/12825 [3:56:50<41:27:33, 12.73s/it]  9%|▊         | 1099/12825 [3:57:11<49:13:30, 15.11s/it]  9%|▊         | 1100/12825 [3:57:23<46:53:35, 14.40s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120237.28lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103462.30lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1075] due to args.save_total_limit
  9%|▊         | 1101/12825 [3:57:36<45:34:25, 13.99s/it]  9%|▊         | 1102/12825 [3:57:49<44:19:10, 13.61s/it]  9%|▊         | 1103/12825 [3:58:02<43:28:17, 13.35s/it]  9%|▊         | 1104/12825 [3:58:15<42:59:05, 13.20s/it]  9%|▊         | 1105/12825 [3:58:27<42:32:44, 13.07s/it]  9%|▊         | 1106/12825 [3:58:40<42:14:13, 12.97s/it]  9%|▊         | 1107/12825 [3:58:53<42:03:19, 12.92s/it]  9%|▊         | 1108/12825 [3:59:06<41:51:36, 12.86s/it]  9%|▊         | 1109/12825 [3:59:18<41:42:30, 12.82s/it]  9%|▊         | 1110/12825 [3:59:31<41:37:27, 12.79s/it]  9%|▊         | 1111/12825 [3:59:44<41:32:23, 12.77s/it]  9%|▊         | 1112/12825 [3:59:57<41:30:36, 12.76s/it]  9%|▊         | 1113/12825 [4:00:09<41:27:28, 12.74s/it]  9%|▊         | 1114/12825 [4:00:22<41:25:49, 12.74s/it]  9%|▊         | 1115/12825 [4:00:35<41:23:47, 12.73s/it]  9%|▊         | 1116/12825 [4:00:47<41:24:09, 12.73s/it]  9%|▊         | 1117/12825 [4:01:00<41:21:43, 12.72s/it]  9%|▊         | 1118/12825 [4:01:13<41:21:01, 12.72s/it]  9%|▊         | 1119/12825 [4:01:26<41:20:37, 12.71s/it]  9%|▊         | 1120/12825 [4:01:38<41:22:28, 12.73s/it]  9%|▊         | 1121/12825 [4:01:51<41:22:30, 12.73s/it]  9%|▊         | 1122/12825 [4:02:04<41:24:13, 12.74s/it]  9%|▉         | 1123/12825 [4:02:16<41:23:49, 12.74s/it]  9%|▉         | 1124/12825 [4:02:29<41:30:23, 12.77s/it]  9%|▉         | 1125/12825 [4:02:42<41:27:13, 12.76s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120204.49lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 98884.86lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1100] due to args.save_total_limit
  9%|▉         | 1126/12825 [4:02:55<41:56:20, 12.91s/it]  9%|▉         | 1127/12825 [4:03:08<41:45:26, 12.85s/it]  9%|▉         | 1128/12825 [4:03:21<41:37:30, 12.81s/it]  9%|▉         | 1129/12825 [4:03:33<41:32:24, 12.79s/it]  9%|▉         | 1130/12825 [4:03:46<41:28:38, 12.77s/it]  9%|▉         | 1131/12825 [4:03:59<41:26:27, 12.76s/it]  9%|▉         | 1132/12825 [4:04:20<49:09:15, 15.13s/it]  9%|▉         | 1133/12825 [4:04:32<46:49:34, 14.42s/it]  9%|▉         | 1134/12825 [4:04:45<45:11:11, 13.91s/it]  9%|▉         | 1135/12825 [4:04:58<44:01:59, 13.56s/it]  9%|▉         | 1136/12825 [4:05:11<43:12:27, 13.31s/it]  9%|▉         | 1137/12825 [4:05:23<42:38:23, 13.13s/it]  9%|▉         | 1138/12825 [4:05:36<42:15:08, 13.02s/it]  9%|▉         | 1139/12825 [4:05:49<41:57:36, 12.93s/it]  9%|▉         | 1140/12825 [4:06:02<41:47:30, 12.88s/it]  9%|▉         | 1141/12825 [4:06:14<41:38:08, 12.83s/it]  9%|▉         | 1142/12825 [4:06:27<41:32:20, 12.80s/it]  9%|▉         | 1143/12825 [4:06:40<41:28:20, 12.78s/it]  9%|▉         | 1144/12825 [4:06:52<41:27:55, 12.78s/it]  9%|▉         | 1145/12825 [4:07:05<41:24:40, 12.76s/it]  9%|▉         | 1146/12825 [4:07:18<41:24:15, 12.76s/it]  9%|▉         | 1147/12825 [4:07:31<41:22:04, 12.75s/it]  9%|▉         | 1148/12825 [4:07:43<41:19:28, 12.74s/it]  9%|▉         | 1149/12825 [4:07:56<41:20:00, 12.74s/it]  9%|▉         | 1150/12825 [4:08:09<41:19:31, 12.74s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120002.59lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103399.66lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1125] due to args.save_total_limit
  9%|▉         | 1151/12825 [4:08:22<41:38:23, 12.84s/it]  9%|▉         | 1152/12825 [4:08:35<41:35:28, 12.83s/it]  9%|▉         | 1153/12825 [4:08:47<41:30:15, 12.80s/it]  9%|▉         | 1154/12825 [4:09:00<41:25:36, 12.78s/it]  9%|▉         | 1155/12825 [4:09:13<41:24:14, 12.77s/it]  9%|▉         | 1156/12825 [4:09:26<41:21:14, 12.76s/it]  9%|▉         | 1157/12825 [4:09:38<41:18:50, 12.75s/it]  9%|▉         | 1158/12825 [4:09:51<41:19:42, 12.75s/it]  9%|▉         | 1159/12825 [4:10:04<41:19:11, 12.75s/it]  9%|▉         | 1160/12825 [4:10:17<41:22:22, 12.77s/it]  9%|▉         | 1161/12825 [4:10:29<41:20:19, 12.76s/it]  9%|▉         | 1162/12825 [4:10:42<41:18:01, 12.75s/it]  9%|▉         | 1163/12825 [4:10:55<41:19:25, 12.76s/it]  9%|▉         | 1164/12825 [4:11:16<49:00:25, 15.13s/it]  9%|▉         | 1165/12825 [4:11:28<46:39:14, 14.40s/it]  9%|▉         | 1166/12825 [4:11:41<45:00:08, 13.90s/it]  9%|▉         | 1167/12825 [4:11:54<43:48:35, 13.53s/it]  9%|▉         | 1168/12825 [4:12:06<43:00:59, 13.28s/it]  9%|▉         | 1169/12825 [4:12:19<42:28:55, 13.12s/it]  9%|▉         | 1170/12825 [4:12:32<42:06:07, 13.00s/it]  9%|▉         | 1171/12825 [4:12:45<41:48:52, 12.92s/it]  9%|▉         | 1172/12825 [4:12:57<41:37:21, 12.86s/it]  9%|▉         | 1173/12825 [4:13:10<41:30:07, 12.82s/it]  9%|▉         | 1174/12825 [4:13:23<41:24:21, 12.79s/it]  9%|▉         | 1175/12825 [4:13:36<41:19:54, 12.77s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120129.89lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103498.61lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1150] due to args.save_total_limit
  9%|▉         | 1176/12825 [4:13:49<41:36:22, 12.86s/it]  9%|▉         | 1177/12825 [4:14:01<41:30:57, 12.83s/it]  9%|▉         | 1178/12825 [4:14:14<41:29:09, 12.82s/it]  9%|▉         | 1179/12825 [4:14:27<41:27:50, 12.82s/it]  9%|▉         | 1180/12825 [4:14:40<41:27:50, 12.82s/it]  9%|▉         | 1181/12825 [4:14:53<41:23:51, 12.80s/it]  9%|▉         | 1182/12825 [4:15:05<41:24:32, 12.80s/it]  9%|▉         | 1183/12825 [4:15:18<41:24:18, 12.80s/it]  9%|▉         | 1184/12825 [4:15:31<41:22:03, 12.79s/it]  9%|▉         | 1185/12825 [4:15:44<41:20:17, 12.78s/it]  9%|▉         | 1186/12825 [4:15:56<41:18:51, 12.78s/it]  9%|▉         | 1187/12825 [4:16:09<41:17:52, 12.77s/it]  9%|▉         | 1188/12825 [4:16:22<41:18:06, 12.78s/it]  9%|▉         | 1189/12825 [4:16:35<41:19:38, 12.79s/it]  9%|▉         | 1190/12825 [4:16:48<41:19:07, 12.78s/it]  9%|▉         | 1191/12825 [4:17:00<41:18:05, 12.78s/it]  9%|▉         | 1192/12825 [4:17:13<41:17:45, 12.78s/it]  9%|▉         | 1193/12825 [4:17:26<41:19:19, 12.79s/it]  9%|▉         | 1194/12825 [4:17:39<41:18:34, 12.79s/it]  9%|▉         | 1195/12825 [4:17:52<41:18:52, 12.79s/it]  9%|▉         | 1196/12825 [4:18:12<49:13:35, 15.24s/it]  9%|▉         | 1197/12825 [4:18:25<46:48:11, 14.49s/it]  9%|▉         | 1198/12825 [4:18:38<45:05:32, 13.96s/it]  9%|▉         | 1199/12825 [4:18:51<43:57:08, 13.61s/it]  9%|▉         | 1200/12825 [4:19:04<43:07:43, 13.36s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120254.52lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103528.32lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1175] due to args.save_total_limit
  9%|▉         | 1201/12825 [4:19:17<42:54:25, 13.29s/it]  9%|▉         | 1202/12825 [4:19:30<42:29:01, 13.16s/it]  9%|▉         | 1203/12825 [4:19:42<42:15:15, 13.09s/it]  9%|▉         | 1204/12825 [4:19:55<41:55:15, 12.99s/it]  9%|▉         | 1205/12825 [4:20:08<41:40:08, 12.91s/it]  9%|▉         | 1206/12825 [4:20:21<41:27:19, 12.84s/it]  9%|▉         | 1207/12825 [4:20:33<41:20:02, 12.81s/it]  9%|▉         | 1208/12825 [4:20:46<41:14:49, 12.78s/it]  9%|▉         | 1209/12825 [4:20:59<41:09:46, 12.76s/it]  9%|▉         | 1210/12825 [4:21:11<41:04:33, 12.73s/it]  9%|▉         | 1211/12825 [4:21:24<41:02:02, 12.72s/it]  9%|▉         | 1212/12825 [4:21:37<41:06:58, 12.75s/it]  9%|▉         | 1213/12825 [4:21:50<41:04:48, 12.74s/it]  9%|▉         | 1214/12825 [4:22:02<40:57:51, 12.70s/it]  9%|▉         | 1215/12825 [4:22:15<40:54:14, 12.68s/it]  9%|▉         | 1216/12825 [4:22:28<40:52:02, 12.67s/it]  9%|▉         | 1217/12825 [4:22:40<40:47:37, 12.65s/it]  9%|▉         | 1218/12825 [4:22:53<40:42:49, 12.63s/it] 10%|▉         | 1219/12825 [4:23:05<40:42:42, 12.63s/it] 10%|▉         | 1220/12825 [4:23:18<40:43:08, 12.63s/it] 10%|▉         | 1221/12825 [4:23:31<40:42:22, 12.63s/it] 10%|▉         | 1222/12825 [4:23:43<40:41:35, 12.63s/it] 10%|▉         | 1223/12825 [4:23:56<40:42:24, 12.63s/it] 10%|▉         | 1224/12825 [4:24:08<40:39:05, 12.61s/it] 10%|▉         | 1225/12825 [4:24:21<40:42:12, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120160.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103505.23lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1200] due to args.save_total_limit
 10%|▉         | 1226/12825 [4:24:34<41:03:01, 12.74s/it] 10%|▉         | 1227/12825 [4:24:47<40:57:04, 12.71s/it] 10%|▉         | 1228/12825 [4:24:59<40:50:11, 12.68s/it] 10%|▉         | 1229/12825 [4:25:19<47:59:46, 14.90s/it] 10%|▉         | 1230/12825 [4:25:32<45:50:35, 14.23s/it] 10%|▉         | 1231/12825 [4:25:45<44:18:36, 13.76s/it] 10%|▉         | 1232/12825 [4:25:57<43:14:35, 13.43s/it] 10%|▉         | 1233/12825 [4:26:10<42:31:57, 13.21s/it] 10%|▉         | 1234/12825 [4:26:23<42:01:48, 13.05s/it] 10%|▉         | 1235/12825 [4:26:35<41:36:26, 12.92s/it] 10%|▉         | 1236/12825 [4:26:48<41:18:27, 12.83s/it] 10%|▉         | 1237/12825 [4:27:01<41:05:18, 12.76s/it] 10%|▉         | 1238/12825 [4:27:13<41:00:00, 12.74s/it] 10%|▉         | 1239/12825 [4:27:26<40:54:44, 12.71s/it] 10%|▉         | 1240/12825 [4:27:39<40:50:27, 12.69s/it] 10%|▉         | 1241/12825 [4:27:51<40:43:02, 12.65s/it] 10%|▉         | 1242/12825 [4:28:04<40:41:15, 12.65s/it] 10%|▉         | 1243/12825 [4:28:16<40:39:21, 12.64s/it] 10%|▉         | 1244/12825 [4:28:29<40:37:31, 12.63s/it] 10%|▉         | 1245/12825 [4:28:42<40:35:38, 12.62s/it] 10%|▉         | 1246/12825 [4:28:54<40:37:23, 12.63s/it] 10%|▉         | 1247/12825 [4:29:07<40:39:27, 12.64s/it] 10%|▉         | 1248/12825 [4:29:20<40:44:14, 12.67s/it] 10%|▉         | 1249/12825 [4:29:32<40:42:38, 12.66s/it] 10%|▉         | 1250/12825 [4:29:45<40:43:01, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 117694.96lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101697.63lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1225] due to args.save_total_limit
 10%|▉         | 1251/12825 [4:29:58<41:01:07, 12.76s/it] 10%|▉         | 1252/12825 [4:30:11<40:53:42, 12.72s/it] 10%|▉         | 1253/12825 [4:30:23<40:50:00, 12.70s/it] 10%|▉         | 1254/12825 [4:30:36<40:45:56, 12.68s/it] 10%|▉         | 1255/12825 [4:30:49<40:42:38, 12.67s/it] 10%|▉         | 1256/12825 [4:31:01<40:40:17, 12.66s/it] 10%|▉         | 1257/12825 [4:31:14<40:39:08, 12.65s/it] 10%|▉         | 1258/12825 [4:31:27<40:46:15, 12.69s/it] 10%|▉         | 1259/12825 [4:31:39<40:41:17, 12.66s/it] 10%|▉         | 1260/12825 [4:31:52<40:38:33, 12.65s/it] 10%|▉         | 1261/12825 [4:32:13<48:25:08, 15.07s/it] 10%|▉         | 1262/12825 [4:32:25<46:04:22, 14.34s/it] 10%|▉         | 1263/12825 [4:32:38<44:25:21, 13.83s/it] 10%|▉         | 1264/12825 [4:32:50<43:17:41, 13.48s/it] 10%|▉         | 1265/12825 [4:33:03<42:27:36, 13.22s/it] 10%|▉         | 1266/12825 [4:33:16<41:52:58, 13.04s/it] 10%|▉         | 1267/12825 [4:33:28<41:29:47, 12.93s/it] 10%|▉         | 1268/12825 [4:33:41<41:11:19, 12.83s/it] 10%|▉         | 1269/12825 [4:33:54<41:00:07, 12.77s/it] 10%|▉         | 1270/12825 [4:34:06<40:52:11, 12.73s/it] 10%|▉         | 1271/12825 [4:34:19<40:46:37, 12.71s/it] 10%|▉         | 1272/12825 [4:34:32<40:47:28, 12.71s/it] 10%|▉         | 1273/12825 [4:34:44<40:46:08, 12.71s/it] 10%|▉         | 1274/12825 [4:34:57<40:40:59, 12.68s/it] 10%|▉         | 1275/12825 [4:35:10<40:36:58, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120162.65lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103541.85lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1250] due to args.save_total_limit
 10%|▉         | 1276/12825 [4:35:23<40:58:48, 12.77s/it] 10%|▉         | 1277/12825 [4:35:35<40:49:57, 12.73s/it] 10%|▉         | 1278/12825 [4:35:48<40:48:33, 12.72s/it] 10%|▉         | 1279/12825 [4:36:01<40:43:17, 12.70s/it] 10%|▉         | 1280/12825 [4:36:13<40:38:14, 12.67s/it] 10%|▉         | 1281/12825 [4:36:26<40:37:10, 12.67s/it] 10%|▉         | 1282/12825 [4:36:38<40:34:35, 12.65s/it] 10%|█         | 1283/12825 [4:36:51<40:33:44, 12.65s/it] 10%|█         | 1284/12825 [4:37:04<40:33:46, 12.65s/it] 10%|█         | 1285/12825 [4:37:16<40:33:42, 12.65s/it] 10%|█         | 1286/12825 [4:37:29<40:32:38, 12.65s/it] 10%|█         | 1287/12825 [4:37:42<40:30:33, 12.64s/it] 10%|█         | 1288/12825 [4:37:54<40:36:47, 12.67s/it] 10%|█         | 1289/12825 [4:38:07<40:34:23, 12.66s/it] 10%|█         | 1290/12825 [4:38:20<40:35:13, 12.67s/it] 10%|█         | 1291/12825 [4:38:32<40:32:43, 12.66s/it] 10%|█         | 1292/12825 [4:38:45<40:32:55, 12.66s/it] 10%|█         | 1293/12825 [4:39:06<48:23:50, 15.11s/it] 10%|█         | 1294/12825 [4:39:18<45:59:41, 14.36s/it] 10%|█         | 1295/12825 [4:39:31<44:20:21, 13.84s/it] 10%|█         | 1296/12825 [4:39:44<43:10:12, 13.48s/it] 10%|█         | 1297/12825 [4:39:56<42:20:34, 13.22s/it] 10%|█         | 1298/12825 [4:40:09<41:46:44, 13.05s/it] 10%|█         | 1299/12825 [4:40:22<41:22:24, 12.92s/it] 10%|█         | 1300/12825 [4:40:34<41:03:14, 12.82s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120287.09lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103538.35lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1275] due to args.save_total_limit
 10%|█         | 1301/12825 [4:40:47<41:15:54, 12.89s/it] 10%|█         | 1302/12825 [4:41:00<41:00:36, 12.81s/it] 10%|█         | 1303/12825 [4:41:13<40:50:54, 12.76s/it] 10%|█         | 1304/12825 [4:41:25<40:42:25, 12.72s/it] 10%|█         | 1305/12825 [4:41:38<40:39:15, 12.70s/it] 10%|█         | 1306/12825 [4:41:50<40:35:04, 12.68s/it] 10%|█         | 1307/12825 [4:42:03<40:32:16, 12.67s/it] 10%|█         | 1308/12825 [4:42:16<40:30:26, 12.66s/it] 10%|█         | 1309/12825 [4:42:28<40:29:22, 12.66s/it] 10%|█         | 1310/12825 [4:42:41<40:29:34, 12.66s/it] 10%|█         | 1311/12825 [4:42:54<40:29:50, 12.66s/it] 10%|█         | 1312/12825 [4:43:06<40:28:34, 12.66s/it] 10%|█         | 1313/12825 [4:43:19<40:27:50, 12.65s/it] 10%|█         | 1314/12825 [4:43:32<40:25:19, 12.64s/it] 10%|█         | 1315/12825 [4:43:44<40:29:26, 12.66s/it] 10%|█         | 1316/12825 [4:43:57<40:25:24, 12.64s/it] 10%|█         | 1317/12825 [4:44:10<40:31:56, 12.68s/it] 10%|█         | 1318/12825 [4:44:22<40:28:47, 12.66s/it] 10%|█         | 1319/12825 [4:44:35<40:27:56, 12.66s/it] 10%|█         | 1320/12825 [4:44:48<40:27:17, 12.66s/it] 10%|█         | 1321/12825 [4:45:00<40:26:17, 12.65s/it] 10%|█         | 1322/12825 [4:45:13<40:28:56, 12.67s/it] 10%|█         | 1323/12825 [4:45:26<40:26:31, 12.66s/it] 10%|█         | 1324/12825 [4:45:38<40:24:13, 12.65s/it] 10%|█         | 1325/12825 [4:45:51<40:29:23, 12.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120172.47lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103422.89lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1300] due to args.save_total_limit
 10%|█         | 1326/12825 [4:46:12<48:40:10, 15.24s/it] 10%|█         | 1327/12825 [4:46:25<46:11:45, 14.46s/it] 10%|█         | 1328/12825 [4:46:38<44:26:55, 13.92s/it] 10%|█         | 1329/12825 [4:46:50<43:11:51, 13.53s/it] 10%|█         | 1330/12825 [4:47:03<42:18:54, 13.25s/it] 10%|█         | 1331/12825 [4:47:15<41:42:09, 13.06s/it] 10%|█         | 1332/12825 [4:47:28<41:17:48, 12.94s/it] 10%|█         | 1333/12825 [4:47:41<41:00:24, 12.85s/it] 10%|█         | 1334/12825 [4:47:53<40:47:08, 12.78s/it] 10%|█         | 1335/12825 [4:48:06<40:39:10, 12.74s/it] 10%|█         | 1336/12825 [4:48:19<40:31:28, 12.70s/it] 10%|█         | 1337/12825 [4:48:31<40:25:29, 12.67s/it] 10%|█         | 1338/12825 [4:48:44<40:21:54, 12.65s/it] 10%|█         | 1339/12825 [4:48:56<40:21:24, 12.65s/it] 10%|█         | 1340/12825 [4:49:09<40:20:16, 12.64s/it] 10%|█         | 1341/12825 [4:49:22<40:21:09, 12.65s/it] 10%|█         | 1342/12825 [4:49:34<40:18:47, 12.64s/it] 10%|█         | 1343/12825 [4:49:47<40:18:10, 12.64s/it] 10%|█         | 1344/12825 [4:50:00<40:17:00, 12.63s/it] 10%|█         | 1345/12825 [4:50:12<40:15:33, 12.62s/it] 10%|█         | 1346/12825 [4:50:25<40:15:12, 12.62s/it] 11%|█         | 1347/12825 [4:50:37<40:18:48, 12.64s/it] 11%|█         | 1348/12825 [4:50:50<40:17:13, 12.64s/it] 11%|█         | 1349/12825 [4:51:03<40:18:08, 12.64s/it] 11%|█         | 1350/12825 [4:51:15<40:15:10, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120373.27lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103667.63lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1325] due to args.save_total_limit
 11%|█         | 1351/12825 [4:51:28<40:35:42, 12.74s/it] 11%|█         | 1352/12825 [4:51:41<40:29:19, 12.70s/it] 11%|█         | 1353/12825 [4:51:54<40:25:24, 12.69s/it] 11%|█         | 1354/12825 [4:52:06<40:22:09, 12.67s/it] 11%|█         | 1355/12825 [4:52:19<40:19:28, 12.66s/it] 11%|█         | 1356/12825 [4:52:31<40:17:31, 12.65s/it] 11%|█         | 1357/12825 [4:52:44<40:17:40, 12.65s/it] 11%|█         | 1358/12825 [4:53:05<48:13:09, 15.14s/it] 11%|█         | 1359/12825 [4:53:18<45:51:18, 14.40s/it] 11%|█         | 1360/12825 [4:53:30<44:09:57, 13.87s/it] 11%|█         | 1361/12825 [4:53:43<43:05:36, 13.53s/it] 11%|█         | 1362/12825 [4:53:56<42:16:04, 13.27s/it] 11%|█         | 1363/12825 [4:54:08<41:42:21, 13.10s/it] 11%|█         | 1364/12825 [4:54:21<41:16:05, 12.96s/it] 11%|█         | 1365/12825 [4:54:34<41:00:34, 12.88s/it] 11%|█         | 1366/12825 [4:54:46<40:47:58, 12.82s/it] 11%|█         | 1367/12825 [4:54:59<40:38:15, 12.77s/it] 11%|█         | 1368/12825 [4:55:12<40:28:53, 12.72s/it] 11%|█         | 1369/12825 [4:55:24<40:24:02, 12.70s/it] 11%|█         | 1370/12825 [4:55:37<40:19:24, 12.67s/it] 11%|█         | 1371/12825 [4:55:50<40:23:20, 12.69s/it] 11%|█         | 1372/12825 [4:56:02<40:20:19, 12.68s/it] 11%|█         | 1373/12825 [4:56:15<40:21:26, 12.69s/it] 11%|█         | 1374/12825 [4:56:28<40:18:42, 12.67s/it] 11%|█         | 1375/12825 [4:56:40<40:17:49, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120311.76lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103567.51lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1350] due to args.save_total_limit
 11%|█         | 1376/12825 [4:56:53<40:33:34, 12.75s/it] 11%|█         | 1377/12825 [4:57:06<40:25:28, 12.71s/it] 11%|█         | 1378/12825 [4:57:19<40:19:09, 12.68s/it] 11%|█         | 1379/12825 [4:57:31<40:14:46, 12.66s/it] 11%|█         | 1380/12825 [4:57:44<40:11:46, 12.64s/it] 11%|█         | 1381/12825 [4:57:56<40:10:19, 12.64s/it] 11%|█         | 1382/12825 [4:58:09<40:07:47, 12.62s/it] 11%|█         | 1383/12825 [4:58:22<40:07:29, 12.62s/it] 11%|█         | 1384/12825 [4:58:34<40:06:27, 12.62s/it] 11%|█         | 1385/12825 [4:58:47<40:05:36, 12.62s/it] 11%|█         | 1386/12825 [4:58:59<40:06:00, 12.62s/it] 11%|█         | 1387/12825 [4:59:12<40:08:14, 12.63s/it] 11%|█         | 1388/12825 [4:59:25<40:06:58, 12.63s/it] 11%|█         | 1389/12825 [4:59:37<40:09:58, 12.64s/it] 11%|█         | 1390/12825 [4:59:58<47:56:41, 15.09s/it] 11%|█         | 1391/12825 [5:00:11<45:34:02, 14.35s/it] 11%|█         | 1392/12825 [5:00:23<43:55:05, 13.83s/it] 11%|█         | 1393/12825 [5:00:36<42:45:22, 13.46s/it] 11%|█         | 1394/12825 [5:00:49<41:54:41, 13.20s/it] 11%|█         | 1395/12825 [5:01:01<41:23:49, 13.04s/it] 11%|█         | 1396/12825 [5:01:14<41:00:36, 12.92s/it] 11%|█         | 1397/12825 [5:01:27<40:42:47, 12.83s/it] 11%|█         | 1398/12825 [5:01:39<40:30:00, 12.76s/it] 11%|█         | 1399/12825 [5:01:52<40:21:38, 12.72s/it] 11%|█         | 1400/12825 [5:02:04<40:15:58, 12.69s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120286.96lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103539.01lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1375] due to args.save_total_limit
 11%|█         | 1401/12825 [5:02:17<40:30:48, 12.77s/it] 11%|█         | 1402/12825 [5:02:30<40:21:49, 12.72s/it] 11%|█         | 1403/12825 [5:02:43<40:15:06, 12.69s/it] 11%|█         | 1404/12825 [5:02:55<40:13:03, 12.68s/it] 11%|█         | 1405/12825 [5:03:08<40:09:00, 12.66s/it] 11%|█         | 1406/12825 [5:03:21<40:11:12, 12.67s/it] 11%|█         | 1407/12825 [5:03:33<40:09:37, 12.66s/it] 11%|█         | 1408/12825 [5:03:46<40:06:14, 12.65s/it] 11%|█         | 1409/12825 [5:03:58<40:05:05, 12.64s/it] 11%|█         | 1410/12825 [5:04:11<40:02:37, 12.63s/it] 11%|█         | 1411/12825 [5:04:24<40:05:55, 12.65s/it] 11%|█         | 1412/12825 [5:04:36<40:05:42, 12.65s/it] 11%|█         | 1413/12825 [5:04:49<40:03:28, 12.64s/it] 11%|█         | 1414/12825 [5:05:02<40:02:39, 12.63s/it] 11%|█         | 1415/12825 [5:05:14<40:01:50, 12.63s/it] 11%|█         | 1416/12825 [5:05:27<40:02:11, 12.63s/it] 11%|█         | 1417/12825 [5:05:40<40:03:11, 12.64s/it] 11%|█         | 1418/12825 [5:05:52<40:02:13, 12.64s/it] 11%|█         | 1419/12825 [5:06:05<40:05:16, 12.65s/it] 11%|█         | 1420/12825 [5:06:18<40:09:21, 12.68s/it] 11%|█         | 1421/12825 [5:06:30<40:08:15, 12.67s/it] 11%|█         | 1422/12825 [5:06:43<40:07:12, 12.67s/it] 11%|█         | 1423/12825 [5:07:04<47:59:07, 15.15s/it] 11%|█         | 1424/12825 [5:07:16<45:36:17, 14.40s/it] 11%|█         | 1425/12825 [5:07:29<43:57:00, 13.88s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120231.54lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103513.17lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1400] due to args.save_total_limit
 11%|█         | 1426/12825 [5:07:42<43:06:32, 13.61s/it] 11%|█         | 1427/12825 [5:07:55<42:09:55, 13.32s/it] 11%|█         | 1428/12825 [5:08:07<41:30:53, 13.11s/it] 11%|█         | 1429/12825 [5:08:20<41:03:49, 12.97s/it] 11%|█         | 1430/12825 [5:08:33<40:44:09, 12.87s/it] 11%|█         | 1431/12825 [5:08:45<40:31:00, 12.80s/it] 11%|█         | 1432/12825 [5:08:58<40:22:56, 12.76s/it] 11%|█         | 1433/12825 [5:09:11<40:17:01, 12.73s/it] 11%|█         | 1434/12825 [5:09:23<40:12:50, 12.71s/it] 11%|█         | 1435/12825 [5:09:36<40:10:20, 12.70s/it] 11%|█         | 1436/12825 [5:09:49<40:04:52, 12.67s/it] 11%|█         | 1437/12825 [5:10:01<40:03:59, 12.67s/it] 11%|█         | 1438/12825 [5:10:14<40:06:55, 12.68s/it] 11%|█         | 1439/12825 [5:10:27<40:05:25, 12.68s/it] 11%|█         | 1440/12825 [5:10:39<40:03:49, 12.67s/it] 11%|█         | 1441/12825 [5:10:52<40:03:20, 12.67s/it] 11%|█         | 1442/12825 [5:11:05<40:03:15, 12.67s/it] 11%|█▏        | 1443/12825 [5:11:17<40:03:20, 12.67s/it] 11%|█▏        | 1444/12825 [5:11:30<40:05:46, 12.68s/it] 11%|█▏        | 1445/12825 [5:11:43<40:03:02, 12.67s/it] 11%|█▏        | 1446/12825 [5:11:55<40:03:17, 12.67s/it] 11%|█▏        | 1447/12825 [5:12:08<40:01:55, 12.67s/it] 11%|█▏        | 1448/12825 [5:12:21<40:00:08, 12.66s/it] 11%|█▏        | 1449/12825 [5:12:33<39:58:13, 12.65s/it] 11%|█▏        | 1450/12825 [5:12:46<39:57:21, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120257.08lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103513.65lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1425] due to args.save_total_limit
 11%|█▏        | 1451/12825 [5:12:59<40:15:26, 12.74s/it] 11%|█▏        | 1452/12825 [5:13:11<40:06:41, 12.70s/it] 11%|█▏        | 1453/12825 [5:13:24<40:03:52, 12.68s/it] 11%|█▏        | 1454/12825 [5:13:37<40:00:44, 12.67s/it] 11%|█▏        | 1455/12825 [5:13:57<46:54:19, 14.85s/it] 11%|█▏        | 1456/12825 [5:14:09<44:49:15, 14.19s/it] 11%|█▏        | 1457/12825 [5:14:22<43:21:09, 13.73s/it] 11%|█▏        | 1458/12825 [5:14:35<42:21:07, 13.41s/it] 11%|█▏        | 1459/12825 [5:14:47<41:39:22, 13.19s/it] 11%|█▏        | 1460/12825 [5:15:00<41:06:49, 13.02s/it] 11%|█▏        | 1461/12825 [5:15:13<40:42:42, 12.90s/it] 11%|█▏        | 1462/12825 [5:15:25<40:27:45, 12.82s/it] 11%|█▏        | 1463/12825 [5:15:38<40:19:12, 12.78s/it] 11%|█▏        | 1464/12825 [5:15:51<40:15:25, 12.76s/it] 11%|█▏        | 1465/12825 [5:16:03<40:08:28, 12.72s/it] 11%|█▏        | 1466/12825 [5:16:16<40:03:14, 12.69s/it] 11%|█▏        | 1467/12825 [5:16:29<40:04:08, 12.70s/it] 11%|█▏        | 1468/12825 [5:16:41<40:00:51, 12.68s/it] 11%|█▏        | 1469/12825 [5:16:54<39:58:17, 12.67s/it] 11%|█▏        | 1470/12825 [5:17:06<39:55:22, 12.66s/it] 11%|█▏        | 1471/12825 [5:17:19<39:53:05, 12.65s/it] 11%|█▏        | 1472/12825 [5:17:32<39:52:41, 12.65s/it] 11%|█▏        | 1473/12825 [5:17:44<39:52:33, 12.65s/it] 11%|█▏        | 1474/12825 [5:17:57<39:54:50, 12.66s/it] 12%|█▏        | 1475/12825 [5:18:10<39:52:53, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120200.27lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103565.33lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1450] due to args.save_total_limit
 12%|█▏        | 1476/12825 [5:18:23<40:17:18, 12.78s/it] 12%|█▏        | 1477/12825 [5:18:35<40:05:32, 12.72s/it] 12%|█▏        | 1478/12825 [5:18:48<40:05:00, 12.72s/it] 12%|█▏        | 1479/12825 [5:19:01<39:57:14, 12.68s/it] 12%|█▏        | 1480/12825 [5:19:13<39:53:55, 12.66s/it] 12%|█▏        | 1481/12825 [5:19:26<39:54:06, 12.66s/it] 12%|█▏        | 1482/12825 [5:19:39<39:51:54, 12.65s/it] 12%|█▏        | 1483/12825 [5:19:51<39:47:24, 12.63s/it] 12%|█▏        | 1484/12825 [5:20:04<39:45:13, 12.62s/it] 12%|█▏        | 1485/12825 [5:20:16<39:42:53, 12.61s/it] 12%|█▏        | 1486/12825 [5:20:29<39:46:25, 12.63s/it] 12%|█▏        | 1487/12825 [5:20:42<39:45:45, 12.63s/it] 12%|█▏        | 1488/12825 [5:21:02<46:55:55, 14.90s/it] 12%|█▏        | 1489/12825 [5:21:14<44:48:56, 14.23s/it] 12%|█▏        | 1490/12825 [5:21:27<43:17:53, 13.75s/it] 12%|█▏        | 1491/12825 [5:21:40<42:15:02, 13.42s/it] 12%|█▏        | 1492/12825 [5:21:52<41:30:50, 13.19s/it] 12%|█▏        | 1493/12825 [5:22:05<40:59:22, 13.02s/it] 12%|█▏        | 1494/12825 [5:22:18<40:36:39, 12.90s/it] 12%|█▏        | 1495/12825 [5:22:30<40:18:14, 12.81s/it] 12%|█▏        | 1496/12825 [5:22:43<40:07:31, 12.75s/it] 12%|█▏        | 1497/12825 [5:22:56<40:00:41, 12.72s/it] 12%|█▏        | 1498/12825 [5:23:08<39:56:54, 12.70s/it] 12%|█▏        | 1499/12825 [5:23:21<39:53:58, 12.68s/it] 12%|█▏        | 1500/12825 [5:23:34<39:57:54, 12.70s/it]                                                          12%|█▏        | 1500/12825 [5:23:34<39:57:54, 12.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120289.90lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103631.49lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1475] due to args.save_total_limit
 12%|█▏        | 1501/12825 [5:23:47<40:14:55, 12.80s/it] 12%|█▏        | 1502/12825 [5:23:59<40:07:02, 12.75s/it] 12%|█▏        | 1503/12825 [5:24:12<40:03:07, 12.74s/it] 12%|█▏        | 1504/12825 [5:24:25<39:58:37, 12.71s/it] 12%|█▏        | 1505/12825 [5:24:37<39:55:03, 12.69s/it] 12%|█▏        | 1506/12825 [5:24:50<39:49:53, 12.67s/it] 12%|█▏        | 1507/12825 [5:25:02<39:47:26, 12.66s/it] 12%|█▏        | 1508/12825 [5:25:15<39:41:36, 12.63s/it] 12%|█▏        | 1509/12825 [5:25:28<39:39:20, 12.62s/it] 12%|█▏        | 1510/12825 [5:25:40<39:39:16, 12.62s/it] 12%|█▏        | 1511/12825 [5:25:53<39:37:36, 12.61s/it] 12%|█▏        | 1512/12825 [5:26:05<39:37:19, 12.61s/it] 12%|█▏        | 1513/12825 [5:26:18<39:50:12, 12.68s/it] 12%|█▏        | 1514/12825 [5:26:31<39:48:36, 12.67s/it] 12%|█▏        | 1515/12825 [5:26:44<39:43:40, 12.65s/it] 12%|█▏        | 1516/12825 [5:26:56<39:42:39, 12.64s/it] 12%|█▏        | 1517/12825 [5:27:09<39:38:03, 12.62s/it] 12%|█▏        | 1518/12825 [5:27:21<39:38:03, 12.62s/it] 12%|█▏        | 1519/12825 [5:27:34<39:37:24, 12.62s/it] 12%|█▏        | 1520/12825 [5:27:55<47:20:40, 15.08s/it] 12%|█▏        | 1521/12825 [5:28:07<45:06:24, 14.37s/it] 12%|█▏        | 1522/12825 [5:28:20<43:25:03, 13.83s/it] 12%|█▏        | 1523/12825 [5:28:33<42:14:19, 13.45s/it] 12%|█▏        | 1524/12825 [5:28:45<41:23:52, 13.19s/it] 12%|█▏        | 1525/12825 [5:28:58<40:48:57, 13.00s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120126.32lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 102476.07lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1500] due to args.save_total_limit
 12%|█▏        | 1526/12825 [5:29:11<40:46:59, 12.99s/it] 12%|█▏        | 1527/12825 [5:29:23<40:21:51, 12.86s/it] 12%|█▏        | 1528/12825 [5:29:36<40:06:05, 12.78s/it] 12%|█▏        | 1529/12825 [5:29:48<39:54:41, 12.72s/it] 12%|█▏        | 1530/12825 [5:30:01<39:46:02, 12.67s/it] 12%|█▏        | 1531/12825 [5:30:14<39:42:25, 12.66s/it] 12%|█▏        | 1532/12825 [5:30:26<39:37:41, 12.63s/it] 12%|█▏        | 1533/12825 [5:30:39<39:35:47, 12.62s/it] 12%|█▏        | 1534/12825 [5:30:51<39:34:23, 12.62s/it] 12%|█▏        | 1535/12825 [5:31:04<39:31:24, 12.60s/it] 12%|█▏        | 1536/12825 [5:31:17<39:33:25, 12.61s/it] 12%|█▏        | 1537/12825 [5:31:29<39:37:15, 12.64s/it] 12%|█▏        | 1538/12825 [5:31:37<35:09:12, 11.21s/it] 12%|█▏        | 1539/12825 [5:31:38<25:22:44,  8.10s/it] 12%|█▏        | 1540/12825 [5:32:04<41:55:01, 13.37s/it] 12%|█▏        | 1541/12825 [5:32:16<41:13:40, 13.15s/it] 12%|█▏        | 1542/12825 [5:32:29<40:41:21, 12.98s/it] 12%|█▏        | 1543/12825 [5:32:42<40:21:15, 12.88s/it] 12%|█▏        | 1544/12825 [5:32:54<40:07:04, 12.80s/it] 12%|█▏        | 1545/12825 [5:33:07<39:59:18, 12.76s/it] 12%|█▏        | 1546/12825 [5:33:20<39:52:34, 12.73s/it] 12%|█▏        | 1547/12825 [5:33:32<39:50:00, 12.72s/it] 12%|█▏        | 1548/12825 [5:33:45<39:44:32, 12.69s/it] 12%|█▏        | 1549/12825 [5:33:57<39:38:25, 12.66s/it] 12%|█▏        | 1550/12825 [5:34:10<39:39:58, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120260.52lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103501.92lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1525] due to args.save_total_limit
 12%|█▏        | 1551/12825 [5:34:23<39:54:28, 12.74s/it] 12%|█▏        | 1552/12825 [5:34:36<39:44:39, 12.69s/it] 12%|█▏        | 1553/12825 [5:34:56<46:40:47, 14.91s/it] 12%|█▏        | 1554/12825 [5:35:08<44:30:19, 14.22s/it] 12%|█▏        | 1555/12825 [5:35:21<42:58:49, 13.73s/it] 12%|█▏        | 1556/12825 [5:35:33<41:53:45, 13.38s/it] 12%|█▏        | 1557/12825 [5:35:46<41:08:53, 13.15s/it] 12%|█▏        | 1558/12825 [5:35:59<40:34:49, 12.97s/it] 12%|█▏        | 1559/12825 [5:36:11<40:09:35, 12.83s/it] 12%|█▏        | 1560/12825 [5:36:24<39:52:27, 12.74s/it] 12%|█▏        | 1561/12825 [5:36:36<39:40:43, 12.68s/it] 12%|█▏        | 1562/12825 [5:36:49<39:33:39, 12.64s/it] 12%|█▏        | 1563/12825 [5:37:01<39:30:20, 12.63s/it] 12%|█▏        | 1564/12825 [5:37:14<39:28:12, 12.62s/it] 12%|█▏        | 1565/12825 [5:37:27<39:27:08, 12.61s/it] 12%|█▏        | 1566/12825 [5:37:39<39:25:28, 12.61s/it] 12%|█▏        | 1567/12825 [5:37:52<39:24:33, 12.60s/it] 12%|█▏        | 1568/12825 [5:38:04<39:21:15, 12.59s/it] 12%|█▏        | 1569/12825 [5:38:17<39:20:35, 12.58s/it] 12%|█▏        | 1570/12825 [5:38:29<39:18:39, 12.57s/it] 12%|█▏        | 1571/12825 [5:38:42<39:19:05, 12.58s/it] 12%|█▏        | 1572/12825 [5:38:55<39:17:50, 12.57s/it] 12%|█▏        | 1573/12825 [5:39:07<39:20:15, 12.59s/it] 12%|█▏        | 1574/12825 [5:39:20<39:18:27, 12.58s/it] 12%|█▏        | 1575/12825 [5:39:32<39:17:39, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120164.56lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103537.12lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1550] due to args.save_total_limit
 12%|█▏        | 1576/12825 [5:39:45<39:35:01, 12.67s/it] 12%|█▏        | 1577/12825 [5:39:58<39:27:10, 12.63s/it] 12%|█▏        | 1578/12825 [5:40:10<39:23:37, 12.61s/it] 12%|█▏        | 1579/12825 [5:40:23<39:19:37, 12.59s/it] 12%|█▏        | 1580/12825 [5:40:35<39:17:25, 12.58s/it] 12%|█▏        | 1581/12825 [5:40:48<39:17:12, 12.58s/it] 12%|█▏        | 1582/12825 [5:41:00<39:14:27, 12.56s/it] 12%|█▏        | 1583/12825 [5:41:13<39:13:24, 12.56s/it] 12%|█▏        | 1584/12825 [5:41:26<39:14:27, 12.57s/it] 12%|█▏        | 1585/12825 [5:41:46<46:25:43, 14.87s/it] 12%|█▏        | 1586/12825 [5:41:58<44:15:24, 14.18s/it] 12%|█▏        | 1587/12825 [5:42:11<42:43:25, 13.69s/it] 12%|█▏        | 1588/12825 [5:42:24<41:40:11, 13.35s/it] 12%|█▏        | 1589/12825 [5:42:36<40:56:20, 13.12s/it] 12%|█▏        | 1590/12825 [5:42:49<40:24:59, 12.95s/it] 12%|█▏        | 1591/12825 [5:43:01<40:03:19, 12.84s/it] 12%|█▏        | 1592/12825 [5:43:14<39:47:11, 12.75s/it] 12%|█▏        | 1593/12825 [5:43:26<39:37:19, 12.70s/it] 12%|█▏        | 1594/12825 [5:43:39<39:30:30, 12.66s/it] 12%|█▏        | 1595/12825 [5:43:51<39:24:24, 12.63s/it] 12%|█▏        | 1596/12825 [5:44:04<39:20:24, 12.61s/it] 12%|█▏        | 1597/12825 [5:44:17<39:16:41, 12.59s/it] 12%|█▏        | 1598/12825 [5:44:29<39:15:13, 12.59s/it] 12%|█▏        | 1599/12825 [5:44:42<39:11:10, 12.57s/it] 12%|█▏        | 1600/12825 [5:44:54<39:07:32, 12.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120097.28lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103459.55lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1575] due to args.save_total_limit
 12%|█▏        | 1601/12825 [5:45:07<39:24:56, 12.64s/it] 12%|█▏        | 1602/12825 [5:45:20<39:19:55, 12.62s/it] 12%|█▏        | 1603/12825 [5:45:32<39:17:47, 12.61s/it] 13%|█▎        | 1604/12825 [5:45:45<39:23:15, 12.64s/it] 13%|█▎        | 1605/12825 [5:45:57<39:19:45, 12.62s/it] 13%|█▎        | 1606/12825 [5:46:10<39:15:40, 12.60s/it] 13%|█▎        | 1607/12825 [5:46:23<39:13:09, 12.59s/it] 13%|█▎        | 1608/12825 [5:46:35<39:17:09, 12.61s/it] 13%|█▎        | 1609/12825 [5:46:48<39:19:16, 12.62s/it] 13%|█▎        | 1610/12825 [5:47:00<39:14:31, 12.60s/it] 13%|█▎        | 1611/12825 [5:47:13<39:11:29, 12.58s/it] 13%|█▎        | 1612/12825 [5:47:26<39:10:11, 12.58s/it] 13%|█▎        | 1613/12825 [5:47:38<39:10:03, 12.58s/it] 13%|█▎        | 1614/12825 [5:47:51<39:13:32, 12.60s/it] 13%|█▎        | 1615/12825 [5:48:03<39:11:53, 12.59s/it] 13%|█▎        | 1616/12825 [5:48:16<39:18:31, 12.62s/it] 13%|█▎        | 1617/12825 [5:48:37<47:04:30, 15.12s/it] 13%|█▎        | 1618/12825 [5:48:49<44:38:02, 14.34s/it] 13%|█▎        | 1619/12825 [5:49:02<42:57:19, 13.80s/it] 13%|█▎        | 1620/12825 [5:49:15<41:46:47, 13.42s/it] 13%|█▎        | 1621/12825 [5:49:27<40:59:32, 13.17s/it] 13%|█▎        | 1622/12825 [5:49:40<40:31:24, 13.02s/it] 13%|█▎        | 1623/12825 [5:49:52<40:05:05, 12.88s/it] 13%|█▎        | 1624/12825 [5:50:05<39:50:31, 12.81s/it] 13%|█▎        | 1625/12825 [5:50:18<39:35:56, 12.73s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120252.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103501.35lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1600] due to args.save_total_limit
 13%|█▎        | 1626/12825 [5:50:30<39:42:59, 12.77s/it] 13%|█▎        | 1627/12825 [5:50:43<39:30:25, 12.70s/it] 13%|█▎        | 1628/12825 [5:50:56<39:23:13, 12.66s/it] 13%|█▎        | 1629/12825 [5:51:08<39:18:55, 12.64s/it] 13%|█▎        | 1630/12825 [5:51:21<39:14:16, 12.62s/it] 13%|█▎        | 1631/12825 [5:51:33<39:09:54, 12.60s/it] 13%|█▎        | 1632/12825 [5:51:46<39:09:12, 12.59s/it] 13%|█▎        | 1633/12825 [5:51:58<39:06:15, 12.58s/it] 13%|█▎        | 1634/12825 [5:52:11<39:06:17, 12.58s/it] 13%|█▎        | 1635/12825 [5:52:24<39:04:50, 12.57s/it] 13%|█▎        | 1636/12825 [5:52:36<39:04:22, 12.57s/it] 13%|█▎        | 1637/12825 [5:52:49<39:01:51, 12.56s/it] 13%|█▎        | 1638/12825 [5:53:01<39:01:30, 12.56s/it] 13%|█▎        | 1639/12825 [5:53:14<39:01:38, 12.56s/it] 13%|█▎        | 1640/12825 [5:53:26<38:59:50, 12.55s/it] 13%|█▎        | 1641/12825 [5:53:39<38:58:46, 12.55s/it] 13%|█▎        | 1642/12825 [5:53:51<38:59:17, 12.55s/it] 13%|█▎        | 1643/12825 [5:54:04<38:58:07, 12.55s/it] 13%|█▎        | 1644/12825 [5:54:16<38:58:09, 12.55s/it] 13%|█▎        | 1645/12825 [5:54:29<38:58:18, 12.55s/it] 13%|█▎        | 1646/12825 [5:54:42<38:59:42, 12.56s/it] 13%|█▎        | 1647/12825 [5:54:54<38:57:53, 12.55s/it] 13%|█▎        | 1648/12825 [5:55:07<39:00:29, 12.56s/it] 13%|█▎        | 1649/12825 [5:55:19<38:59:38, 12.56s/it] 13%|█▎        | 1650/12825 [5:55:40<46:40:08, 15.03s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120179.23lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103446.51lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1625] due to args.save_total_limit
 13%|█▎        | 1651/12825 [5:55:53<44:40:45, 14.39s/it] 13%|█▎        | 1652/12825 [5:56:06<43:00:40, 13.86s/it] 13%|█▎        | 1653/12825 [5:56:18<41:47:52, 13.47s/it] 13%|█▎        | 1654/12825 [5:56:31<41:04:19, 13.24s/it] 13%|█▎        | 1655/12825 [5:56:43<40:26:47, 13.04s/it] 13%|█▎        | 1656/12825 [5:56:56<40:04:52, 12.92s/it] 13%|█▎        | 1657/12825 [5:57:09<39:46:25, 12.82s/it] 13%|█▎        | 1658/12825 [5:57:21<39:33:43, 12.75s/it] 13%|█▎        | 1659/12825 [5:57:34<39:23:30, 12.70s/it] 13%|█▎        | 1660/12825 [5:57:46<39:16:53, 12.67s/it] 13%|█▎        | 1661/12825 [5:57:59<39:11:10, 12.64s/it] 13%|█▎        | 1662/12825 [5:58:12<39:13:21, 12.65s/it] 13%|█▎        | 1663/12825 [5:58:24<39:09:11, 12.63s/it] 13%|█▎        | 1664/12825 [5:58:37<39:04:15, 12.60s/it] 13%|█▎        | 1665/12825 [5:58:49<39:00:45, 12.58s/it] 13%|█▎        | 1666/12825 [5:59:02<38:57:44, 12.57s/it] 13%|█▎        | 1667/12825 [5:59:14<38:56:06, 12.56s/it] 13%|█▎        | 1668/12825 [5:59:27<38:55:54, 12.56s/it] 13%|█▎        | 1669/12825 [5:59:40<38:56:43, 12.57s/it] 13%|█▎        | 1670/12825 [5:59:52<38:58:54, 12.58s/it] 13%|█▎        | 1671/12825 [6:00:05<38:58:19, 12.58s/it] 13%|█▎        | 1672/12825 [6:00:17<38:58:01, 12.58s/it] 13%|█▎        | 1673/12825 [6:00:30<38:57:04, 12.57s/it] 13%|█▎        | 1674/12825 [6:00:42<38:55:41, 12.57s/it] 13%|█▎        | 1675/12825 [6:00:55<38:55:01, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120296.68lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103541.19lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1650] due to args.save_total_limit
 13%|█▎        | 1676/12825 [6:01:08<39:16:05, 12.68s/it] 13%|█▎        | 1677/12825 [6:01:20<39:07:51, 12.64s/it] 13%|█▎        | 1678/12825 [6:01:33<39:03:33, 12.61s/it] 13%|█▎        | 1679/12825 [6:01:46<39:00:50, 12.60s/it] 13%|█▎        | 1680/12825 [6:01:58<38:56:41, 12.58s/it] 13%|█▎        | 1681/12825 [6:02:11<38:54:17, 12.57s/it] 13%|█▎        | 1682/12825 [6:02:31<46:28:59, 15.02s/it] 13%|█▎        | 1683/12825 [6:02:44<44:10:34, 14.27s/it] 13%|█▎        | 1684/12825 [6:02:56<42:31:58, 13.74s/it] 13%|█▎        | 1685/12825 [6:03:09<41:25:37, 13.39s/it] 13%|█▎        | 1686/12825 [6:03:22<40:38:38, 13.14s/it] 13%|█▎        | 1687/12825 [6:03:34<40:05:48, 12.96s/it] 13%|█▎        | 1688/12825 [6:03:47<39:42:06, 12.83s/it] 13%|█▎        | 1689/12825 [6:03:59<39:25:39, 12.75s/it] 13%|█▎        | 1690/12825 [6:04:12<39:13:11, 12.68s/it] 13%|█▎        | 1691/12825 [6:04:24<39:11:20, 12.67s/it] 13%|█▎        | 1692/12825 [6:04:37<39:03:28, 12.63s/it] 13%|█▎        | 1693/12825 [6:04:49<38:59:30, 12.61s/it] 13%|█▎        | 1694/12825 [6:05:02<38:54:42, 12.58s/it] 13%|█▎        | 1695/12825 [6:05:14<38:51:07, 12.57s/it] 13%|█▎        | 1696/12825 [6:05:27<38:50:12, 12.56s/it] 13%|█▎        | 1697/12825 [6:05:40<38:50:33, 12.57s/it] 13%|█▎        | 1698/12825 [6:05:52<38:49:47, 12.56s/it] 13%|█▎        | 1699/12825 [6:06:05<38:54:09, 12.59s/it] 13%|█▎        | 1700/12825 [6:06:17<38:52:23, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120198.49lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103533.05lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1675] due to args.save_total_limit
 13%|█▎        | 1701/12825 [6:06:30<39:07:24, 12.66s/it] 13%|█▎        | 1702/12825 [6:06:43<39:02:51, 12.64s/it] 13%|█▎        | 1703/12825 [6:06:55<38:58:23, 12.61s/it] 13%|█▎        | 1704/12825 [6:07:08<39:01:38, 12.63s/it] 13%|█▎        | 1705/12825 [6:07:21<38:57:50, 12.61s/it] 13%|█▎        | 1706/12825 [6:07:33<38:55:12, 12.60s/it] 13%|█▎        | 1707/12825 [6:07:46<38:51:01, 12.58s/it] 13%|█▎        | 1708/12825 [6:07:58<38:49:32, 12.57s/it] 13%|█▎        | 1709/12825 [6:08:11<38:49:33, 12.57s/it] 13%|█▎        | 1710/12825 [6:08:23<38:47:13, 12.56s/it] 13%|█▎        | 1711/12825 [6:08:36<38:44:44, 12.55s/it] 13%|█▎        | 1712/12825 [6:08:48<38:43:30, 12.54s/it] 13%|█▎        | 1713/12825 [6:09:01<38:43:14, 12.54s/it] 13%|█▎        | 1714/12825 [6:09:22<46:27:46, 15.05s/it] 13%|█▎        | 1715/12825 [6:09:34<44:09:42, 14.31s/it] 13%|█▎        | 1716/12825 [6:09:47<42:31:50, 13.78s/it] 13%|█▎        | 1717/12825 [6:10:00<41:22:22, 13.41s/it] 13%|█▎        | 1718/12825 [6:10:12<40:35:13, 13.16s/it] 13%|█▎        | 1719/12825 [6:10:25<40:04:04, 12.99s/it] 13%|█▎        | 1720/12825 [6:10:37<39:40:09, 12.86s/it] 13%|█▎        | 1721/12825 [6:10:50<39:21:35, 12.76s/it] 13%|█▎        | 1722/12825 [6:11:02<39:08:10, 12.69s/it] 13%|█▎        | 1723/12825 [6:11:15<39:00:07, 12.65s/it] 13%|█▎        | 1724/12825 [6:11:27<38:54:40, 12.62s/it] 13%|█▎        | 1725/12825 [6:11:40<38:51:14, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 119932.82lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 102732.84lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1725
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1725/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1725/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1700] due to args.save_total_limit
 13%|█▎        | 1726/12825 [6:11:53<39:19:07, 12.75s/it] 13%|█▎        | 1727/12825 [6:12:06<39:11:30, 12.71s/it] 13%|█▎        | 1728/12825 [6:12:18<39:04:13, 12.67s/it] 13%|█▎        | 1729/12825 [6:12:31<39:00:21, 12.66s/it] 13%|█▎        | 1730/12825 [6:12:44<38:56:17, 12.63s/it] 13%|█▎        | 1731/12825 [6:12:56<38:51:57, 12.61s/it] 14%|█▎        | 1732/12825 [6:13:09<38:49:10, 12.60s/it] 14%|█▎        | 1733/12825 [6:13:21<38:47:08, 12.59s/it] 14%|█▎        | 1734/12825 [6:13:34<38:48:40, 12.60s/it] 14%|█▎        | 1735/12825 [6:13:46<38:47:41, 12.59s/it] 14%|█▎        | 1736/12825 [6:13:59<38:44:35, 12.58s/it] 14%|█▎        | 1737/12825 [6:14:12<38:45:08, 12.58s/it] 14%|█▎        | 1738/12825 [6:14:24<38:44:06, 12.58s/it] 14%|█▎        | 1739/12825 [6:14:37<38:42:15, 12.57s/it] 14%|█▎        | 1740/12825 [6:14:49<38:41:12, 12.56s/it] 14%|█▎        | 1741/12825 [6:15:02<38:40:14, 12.56s/it] 14%|█▎        | 1742/12825 [6:15:14<38:41:07, 12.57s/it] 14%|█▎        | 1743/12825 [6:15:27<38:43:47, 12.58s/it] 14%|█▎        | 1744/12825 [6:15:40<38:43:12, 12.58s/it] 14%|█▎        | 1745/12825 [6:15:52<38:43:07, 12.58s/it] 14%|█▎        | 1746/12825 [6:16:05<38:44:37, 12.59s/it] 14%|█▎        | 1747/12825 [6:16:25<45:51:12, 14.90s/it] 14%|█▎        | 1748/12825 [6:16:38<43:44:35, 14.22s/it] 14%|█▎        | 1749/12825 [6:16:50<42:18:17, 13.75s/it] 14%|█▎        | 1750/12825 [6:17:03<41:11:31, 13.39s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 117508.23lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101449.83lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1750
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1750/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1750/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1725] due to args.save_total_limit
 14%|█▎        | 1751/12825 [6:17:16<40:55:48, 13.31s/it] 14%|█▎        | 1752/12825 [6:17:29<40:17:52, 13.10s/it] 14%|█▎        | 1753/12825 [6:17:41<39:50:08, 12.95s/it] 14%|█▎        | 1754/12825 [6:17:54<39:31:06, 12.85s/it] 14%|█▎        | 1755/12825 [6:18:06<39:16:46, 12.77s/it] 14%|█▎        | 1756/12825 [6:18:19<39:07:52, 12.73s/it] 14%|█▎        | 1757/12825 [6:18:32<38:59:48, 12.68s/it] 14%|█▎        | 1758/12825 [6:18:44<38:59:31, 12.68s/it] 14%|█▎        | 1759/12825 [6:18:57<38:55:13, 12.66s/it] 14%|█▎        | 1760/12825 [6:19:10<38:53:13, 12.65s/it] 14%|█▎        | 1761/12825 [6:19:22<38:51:40, 12.64s/it] 14%|█▎        | 1762/12825 [6:19:35<38:48:49, 12.63s/it] 14%|█▎        | 1763/12825 [6:19:47<38:45:42, 12.61s/it] 14%|█▍        | 1764/12825 [6:20:00<38:46:03, 12.62s/it] 14%|█▍        | 1765/12825 [6:20:13<38:46:33, 12.62s/it] 14%|█▍        | 1766/12825 [6:20:25<38:45:08, 12.61s/it] 14%|█▍        | 1767/12825 [6:20:38<38:46:10, 12.62s/it] 14%|█▍        | 1768/12825 [6:20:50<38:44:52, 12.62s/it] 14%|█▍        | 1769/12825 [6:21:03<38:44:10, 12.61s/it] 14%|█▍        | 1770/12825 [6:21:16<38:43:50, 12.61s/it] 14%|█▍        | 1771/12825 [6:21:28<38:43:18, 12.61s/it] 14%|█▍        | 1772/12825 [6:21:41<38:42:40, 12.61s/it] 14%|█▍        | 1773/12825 [6:21:53<38:42:14, 12.61s/it] 14%|█▍        | 1774/12825 [6:22:06<38:41:21, 12.60s/it] 14%|█▍        | 1775/12825 [6:22:19<38:45:03, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120282.62lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103456.25lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1775
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1775/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1775/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1750] due to args.save_total_limit
 14%|█▍        | 1776/12825 [6:22:32<39:03:12, 12.72s/it] 14%|█▍        | 1777/12825 [6:22:44<38:56:10, 12.69s/it] 14%|█▍        | 1778/12825 [6:22:57<38:51:52, 12.67s/it] 14%|█▍        | 1779/12825 [6:23:18<46:15:59, 15.08s/it] 14%|█▍        | 1780/12825 [6:23:30<43:59:01, 14.34s/it] 14%|█▍        | 1781/12825 [6:23:43<42:23:32, 13.82s/it] 14%|█▍        | 1782/12825 [6:23:55<41:13:55, 13.44s/it] 14%|█▍        | 1783/12825 [6:24:08<40:30:52, 13.21s/it] 14%|█▍        | 1784/12825 [6:24:21<39:56:03, 13.02s/it] 14%|█▍        | 1785/12825 [6:24:33<39:30:53, 12.89s/it] 14%|█▍        | 1786/12825 [6:24:46<39:14:36, 12.80s/it] 14%|█▍        | 1787/12825 [6:24:58<39:02:59, 12.74s/it] 14%|█▍        | 1788/12825 [6:25:11<38:52:26, 12.68s/it] 14%|█▍        | 1789/12825 [6:25:24<38:51:46, 12.68s/it] 14%|█▍        | 1790/12825 [6:25:36<38:46:21, 12.65s/it] 14%|█▍        | 1791/12825 [6:25:49<38:45:01, 12.64s/it] 14%|█▍        | 1792/12825 [6:26:01<38:41:03, 12.62s/it] 14%|█▍        | 1793/12825 [6:26:14<38:41:57, 12.63s/it] 14%|█▍        | 1794/12825 [6:26:27<38:38:59, 12.61s/it] 14%|█▍        | 1795/12825 [6:26:39<38:37:09, 12.60s/it] 14%|█▍        | 1796/12825 [6:26:52<38:42:10, 12.63s/it] 14%|█▍        | 1797/12825 [6:27:05<38:41:30, 12.63s/it] 14%|█▍        | 1798/12825 [6:27:17<38:39:01, 12.62s/it] 14%|█▍        | 1799/12825 [6:27:30<38:38:37, 12.62s/it] 14%|█▍        | 1800/12825 [6:27:42<38:37:13, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120275.98lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103471.37lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1800
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1800/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1800/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1775] due to args.save_total_limit
 14%|█▍        | 1801/12825 [6:27:55<38:54:27, 12.71s/it] 14%|█▍        | 1802/12825 [6:28:08<38:49:06, 12.68s/it] 14%|█▍        | 1803/12825 [6:28:20<38:44:29, 12.65s/it] 14%|█▍        | 1804/12825 [6:28:33<38:43:22, 12.65s/it] 14%|█▍        | 1805/12825 [6:28:46<38:40:44, 12.64s/it] 14%|█▍        | 1806/12825 [6:28:58<38:38:31, 12.62s/it] 14%|█▍        | 1807/12825 [6:29:11<38:34:51, 12.61s/it] 14%|█▍        | 1808/12825 [6:29:23<38:35:45, 12.61s/it] 14%|█▍        | 1809/12825 [6:29:36<38:34:20, 12.61s/it] 14%|█▍        | 1810/12825 [6:29:49<38:32:56, 12.60s/it] 14%|█▍        | 1811/12825 [6:30:09<45:42:01, 14.94s/it] 14%|█▍        | 1812/12825 [6:30:22<43:31:36, 14.23s/it] 14%|█▍        | 1813/12825 [6:30:34<42:01:16, 13.74s/it] 14%|█▍        | 1814/12825 [6:30:47<40:56:38, 13.39s/it] 14%|█▍        | 1815/12825 [6:30:59<40:12:30, 13.15s/it] 14%|█▍        | 1816/12825 [6:31:12<39:40:02, 12.97s/it] 14%|█▍        | 1817/12825 [6:31:25<39:23:58, 12.89s/it] 14%|█▍        | 1818/12825 [6:31:37<39:07:41, 12.80s/it] 14%|█▍        | 1819/12825 [6:31:50<38:55:13, 12.73s/it] 14%|█▍        | 1820/12825 [6:32:02<38:45:53, 12.68s/it] 14%|█▍        | 1821/12825 [6:32:15<38:39:51, 12.65s/it] 14%|█▍        | 1822/12825 [6:32:28<38:36:10, 12.63s/it] 14%|█▍        | 1823/12825 [6:32:40<38:35:26, 12.63s/it] 14%|█▍        | 1824/12825 [6:32:53<38:34:01, 12.62s/it] 14%|█▍        | 1825/12825 [6:33:05<38:30:34, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120215.71lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103504.28lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1825
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1825/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1825/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1800] due to args.save_total_limit
 14%|█▍        | 1826/12825 [6:33:18<39:00:41, 12.77s/it] 14%|█▍        | 1827/12825 [6:33:31<38:59:07, 12.76s/it] 14%|█▍        | 1828/12825 [6:33:44<39:05:01, 12.79s/it] 14%|█▍        | 1829/12825 [6:33:57<39:02:38, 12.78s/it] 14%|█▍        | 1830/12825 [6:34:09<38:53:43, 12.74s/it] 14%|█▍        | 1831/12825 [6:34:22<38:47:30, 12.70s/it] 14%|█▍        | 1832/12825 [6:34:35<38:41:47, 12.67s/it] 14%|█▍        | 1833/12825 [6:34:47<38:39:36, 12.66s/it] 14%|█▍        | 1834/12825 [6:35:00<38:42:34, 12.68s/it] 14%|█▍        | 1835/12825 [6:35:13<38:42:20, 12.68s/it] 14%|█▍        | 1836/12825 [6:35:25<38:36:40, 12.65s/it] 14%|█▍        | 1837/12825 [6:35:38<38:34:30, 12.64s/it] 14%|█▍        | 1838/12825 [6:35:51<38:33:12, 12.63s/it] 14%|█▍        | 1839/12825 [6:36:03<38:33:55, 12.64s/it] 14%|█▍        | 1840/12825 [6:36:16<38:30:43, 12.62s/it] 14%|█▍        | 1841/12825 [6:36:28<38:29:38, 12.62s/it] 14%|█▍        | 1842/12825 [6:36:41<38:28:24, 12.61s/it] 14%|█▍        | 1843/12825 [6:36:54<38:26:47, 12.60s/it] 14%|█▍        | 1844/12825 [6:37:14<45:51:50, 15.04s/it] 14%|█▍        | 1845/12825 [6:37:27<43:38:14, 14.31s/it] 14%|█▍        | 1846/12825 [6:37:39<42:05:06, 13.80s/it] 14%|█▍        | 1847/12825 [6:37:52<40:59:06, 13.44s/it] 14%|█▍        | 1848/12825 [6:38:05<40:14:08, 13.20s/it] 14%|█▍        | 1849/12825 [6:38:17<39:42:33, 13.02s/it] 14%|█▍        | 1850/12825 [6:38:30<39:19:27, 12.90s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 119439.25lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 102432.51lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1850
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1850/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1850/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1825] due to args.save_total_limit
 14%|█▍        | 1851/12825 [6:38:43<39:23:04, 12.92s/it] 14%|█▍        | 1852/12825 [6:38:56<39:07:05, 12.83s/it] 14%|█▍        | 1853/12825 [6:39:08<38:55:23, 12.77s/it] 14%|█▍        | 1854/12825 [6:39:21<38:46:08, 12.72s/it] 14%|█▍        | 1855/12825 [6:39:33<38:41:04, 12.69s/it] 14%|█▍        | 1856/12825 [6:39:46<38:37:08, 12.67s/it] 14%|█▍        | 1857/12825 [6:39:59<38:32:36, 12.65s/it] 14%|█▍        | 1858/12825 [6:40:11<38:32:04, 12.65s/it] 14%|█▍        | 1859/12825 [6:40:24<38:31:04, 12.64s/it] 15%|█▍        | 1860/12825 [6:40:37<38:30:16, 12.64s/it] 15%|█▍        | 1861/12825 [6:40:49<38:29:05, 12.64s/it] 15%|█▍        | 1862/12825 [6:41:02<38:32:16, 12.65s/it] 15%|█▍        | 1863/12825 [6:41:14<38:29:51, 12.64s/it] 15%|█▍        | 1864/12825 [6:41:27<38:28:10, 12.63s/it] 15%|█▍        | 1865/12825 [6:41:40<38:26:50, 12.63s/it] 15%|█▍        | 1866/12825 [6:41:52<38:30:31, 12.65s/it] 15%|█▍        | 1867/12825 [6:42:05<38:31:12, 12.65s/it] 15%|█▍        | 1868/12825 [6:42:18<38:30:01, 12.65s/it] 15%|█▍        | 1869/12825 [6:42:30<38:25:32, 12.63s/it] 15%|█▍        | 1870/12825 [6:42:43<38:23:24, 12.62s/it] 15%|█▍        | 1871/12825 [6:42:55<38:21:48, 12.61s/it] 15%|█▍        | 1872/12825 [6:43:08<38:22:46, 12.61s/it] 15%|█▍        | 1873/12825 [6:43:21<38:24:26, 12.62s/it] 15%|█▍        | 1874/12825 [6:43:33<38:23:53, 12.62s/it] 15%|█▍        | 1875/12825 [6:43:46<38:23:05, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120278.53lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103514.88lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1875
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1875/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1875/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1850] due to args.save_total_limit
 15%|█▍        | 1876/12825 [6:44:07<46:07:27, 15.17s/it] 15%|█▍        | 1877/12825 [6:44:20<43:47:43, 14.40s/it] 15%|█▍        | 1878/12825 [6:44:32<42:09:33, 13.86s/it] 15%|█▍        | 1879/12825 [6:44:45<41:01:44, 13.49s/it] 15%|█▍        | 1880/12825 [6:44:58<40:13:01, 13.23s/it] 15%|█▍        | 1881/12825 [6:45:10<39:39:22, 13.04s/it] 15%|█▍        | 1882/12825 [6:45:23<39:13:32, 12.90s/it] 15%|█▍        | 1883/12825 [6:45:35<38:57:29, 12.82s/it] 15%|█▍        | 1884/12825 [6:45:48<38:45:22, 12.75s/it] 15%|█▍        | 1885/12825 [6:46:01<38:39:29, 12.72s/it] 15%|█▍        | 1886/12825 [6:46:13<38:35:27, 12.70s/it] 15%|█▍        | 1887/12825 [6:46:26<38:29:37, 12.67s/it] 15%|█▍        | 1888/12825 [6:46:38<38:26:48, 12.66s/it] 15%|█▍        | 1889/12825 [6:46:51<38:23:45, 12.64s/it] 15%|█▍        | 1890/12825 [6:47:04<38:20:53, 12.62s/it] 15%|█▍        | 1891/12825 [6:47:16<38:19:01, 12.62s/it] 15%|█▍        | 1892/12825 [6:47:29<38:18:40, 12.62s/it] 15%|█▍        | 1893/12825 [6:47:42<38:20:16, 12.62s/it] 15%|█▍        | 1894/12825 [6:47:54<38:19:17, 12.62s/it] 15%|█▍        | 1895/12825 [6:48:07<38:19:00, 12.62s/it] 15%|█▍        | 1896/12825 [6:48:19<38:23:15, 12.64s/it] 15%|█▍        | 1897/12825 [6:48:32<38:22:34, 12.64s/it] 15%|█▍        | 1898/12825 [6:48:45<38:20:17, 12.63s/it] 15%|█▍        | 1899/12825 [6:48:57<38:18:48, 12.62s/it] 15%|█▍        | 1900/12825 [6:49:10<38:17:56, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120263.08lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103498.61lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1900
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1900/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1900/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1875] due to args.save_total_limit
 15%|█▍        | 1901/12825 [6:49:23<38:39:47, 12.74s/it] 15%|█▍        | 1902/12825 [6:49:36<38:33:42, 12.71s/it] 15%|█▍        | 1903/12825 [6:49:48<38:28:28, 12.68s/it] 15%|█▍        | 1904/12825 [6:50:01<38:24:21, 12.66s/it] 15%|█▍        | 1905/12825 [6:50:13<38:20:22, 12.64s/it] 15%|█▍        | 1906/12825 [6:50:26<38:19:28, 12.64s/it] 15%|█▍        | 1907/12825 [6:50:39<38:17:38, 12.63s/it] 15%|█▍        | 1908/12825 [6:50:51<38:15:19, 12.62s/it] 15%|█▍        | 1909/12825 [6:51:12<45:41:09, 15.07s/it] 15%|█▍        | 1910/12825 [6:51:25<43:27:31, 14.33s/it] 15%|█▍        | 1911/12825 [6:51:37<41:57:20, 13.84s/it] 15%|█▍        | 1912/12825 [6:51:50<40:49:39, 13.47s/it] 15%|█▍        | 1913/12825 [6:52:02<40:01:51, 13.21s/it] 15%|█▍        | 1914/12825 [6:52:15<39:28:58, 13.03s/it] 15%|█▍        | 1915/12825 [6:52:28<39:05:40, 12.90s/it] 15%|█▍        | 1916/12825 [6:52:40<38:48:44, 12.81s/it] 15%|█▍        | 1917/12825 [6:52:53<38:36:19, 12.74s/it] 15%|█▍        | 1918/12825 [6:53:06<38:29:52, 12.71s/it] 15%|█▍        | 1919/12825 [6:53:18<38:23:50, 12.67s/it] 15%|█▍        | 1920/12825 [6:53:31<38:19:19, 12.65s/it] 15%|█▍        | 1921/12825 [6:53:43<38:17:36, 12.64s/it] 15%|█▍        | 1922/12825 [6:53:56<38:15:51, 12.63s/it] 15%|█▍        | 1923/12825 [6:54:09<38:16:20, 12.64s/it] 15%|█▌        | 1924/12825 [6:54:21<38:20:29, 12.66s/it] 15%|█▌        | 1925/12825 [6:54:34<38:18:00, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120204.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 99215.46lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1925
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1925/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1925/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1900] due to args.save_total_limit
 15%|█▌        | 1926/12825 [6:54:47<38:44:12, 12.80s/it] 15%|█▌        | 1927/12825 [6:55:00<38:33:55, 12.74s/it] 15%|█▌        | 1928/12825 [6:55:12<38:26:06, 12.70s/it] 15%|█▌        | 1929/12825 [6:55:25<38:21:16, 12.67s/it] 15%|█▌        | 1930/12825 [6:55:37<38:16:29, 12.65s/it] 15%|█▌        | 1931/12825 [6:55:50<38:14:13, 12.64s/it] 15%|█▌        | 1932/12825 [6:56:03<38:12:35, 12.63s/it] 15%|█▌        | 1933/12825 [6:56:15<38:13:52, 12.64s/it] 15%|█▌        | 1934/12825 [6:56:28<38:13:58, 12.64s/it] 15%|█▌        | 1935/12825 [6:56:41<38:12:24, 12.63s/it] 15%|█▌        | 1936/12825 [6:56:53<38:11:27, 12.63s/it] 15%|█▌        | 1937/12825 [6:57:06<38:10:57, 12.62s/it] 15%|█▌        | 1938/12825 [6:57:18<38:09:07, 12.62s/it] 15%|█▌        | 1939/12825 [6:57:31<38:08:10, 12.61s/it] 15%|█▌        | 1940/12825 [6:57:44<38:07:37, 12.61s/it] 15%|█▌        | 1941/12825 [6:58:04<45:31:06, 15.06s/it] 15%|█▌        | 1942/12825 [6:58:17<43:17:59, 14.32s/it] 15%|█▌        | 1943/12825 [6:58:30<41:50:46, 13.84s/it] 15%|█▌        | 1944/12825 [6:58:42<40:43:11, 13.47s/it] 15%|█▌        | 1945/12825 [6:58:55<39:54:34, 13.21s/it] 15%|█▌        | 1946/12825 [6:59:08<39:21:39, 13.03s/it] 15%|█▌        | 1947/12825 [6:59:20<39:01:04, 12.91s/it] 15%|█▌        | 1948/12825 [6:59:33<38:42:29, 12.81s/it] 15%|█▌        | 1949/12825 [6:59:45<38:30:58, 12.75s/it] 15%|█▌        | 1950/12825 [6:59:58<38:22:08, 12.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120221.20lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103570.17lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1950
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1950/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1950/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-25] due to args.save_total_limit
 15%|█▌        | 1951/12825 [7:00:11<38:37:00, 12.78s/it] 15%|█▌        | 1952/12825 [7:00:24<38:26:17, 12.73s/it] 15%|█▌        | 1953/12825 [7:00:36<38:18:53, 12.69s/it] 15%|█▌        | 1954/12825 [7:00:49<38:15:38, 12.67s/it] 15%|█▌        | 1955/12825 [7:01:01<38:11:45, 12.65s/it] 15%|█▌        | 1956/12825 [7:01:14<38:14:12, 12.66s/it] 15%|█▌        | 1957/12825 [7:01:27<38:12:16, 12.66s/it] 15%|█▌        | 1958/12825 [7:01:39<38:15:28, 12.67s/it] 15%|█▌        | 1959/12825 [7:01:52<38:11:56, 12.66s/it] 15%|█▌        | 1960/12825 [7:02:05<38:09:43, 12.64s/it] 15%|█▌        | 1961/12825 [7:02:17<38:09:32, 12.64s/it] 15%|█▌        | 1962/12825 [7:02:30<38:08:48, 12.64s/it] 15%|█▌        | 1963/12825 [7:02:43<38:07:47, 12.64s/it] 15%|█▌        | 1964/12825 [7:02:55<38:07:32, 12.64s/it] 15%|█▌        | 1965/12825 [7:03:08<38:05:22, 12.63s/it] 15%|█▌        | 1966/12825 [7:03:20<38:05:08, 12.63s/it] 15%|█▌        | 1967/12825 [7:03:33<38:04:11, 12.62s/it] 15%|█▌        | 1968/12825 [7:03:46<38:03:07, 12.62s/it] 15%|█▌        | 1969/12825 [7:03:58<38:06:11, 12.64s/it] 15%|█▌        | 1970/12825 [7:04:11<38:04:27, 12.63s/it] 15%|█▌        | 1971/12825 [7:04:24<38:02:56, 12.62s/it] 15%|█▌        | 1972/12825 [7:04:36<38:00:54, 12.61s/it] 15%|█▌        | 1973/12825 [7:04:57<45:10:19, 14.99s/it] 15%|█▌        | 1974/12825 [7:05:09<42:58:55, 14.26s/it] 15%|█▌        | 1975/12825 [7:05:22<41:29:58, 13.77s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120259.25lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103510.81lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1975
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1975/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1975/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-1975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1925] due to args.save_total_limit
 15%|█▌        | 1976/12825 [7:05:35<40:45:29, 13.52s/it] 15%|█▌        | 1977/12825 [7:05:47<39:54:58, 13.25s/it] 15%|█▌        | 1978/12825 [7:06:00<39:26:47, 13.09s/it] 15%|█▌        | 1979/12825 [7:06:13<39:00:05, 12.95s/it] 15%|█▌        | 1980/12825 [7:06:25<38:43:19, 12.85s/it] 15%|█▌        | 1981/12825 [7:06:38<38:31:17, 12.79s/it] 15%|█▌        | 1982/12825 [7:06:51<38:23:31, 12.75s/it] 15%|█▌        | 1983/12825 [7:07:03<38:19:05, 12.72s/it] 15%|█▌        | 1984/12825 [7:07:16<38:12:45, 12.69s/it] 15%|█▌        | 1985/12825 [7:07:29<38:10:37, 12.68s/it] 15%|█▌        | 1986/12825 [7:07:41<38:08:50, 12.67s/it] 15%|█▌        | 1987/12825 [7:07:54<38:07:02, 12.66s/it] 16%|█▌        | 1988/12825 [7:08:06<38:04:06, 12.65s/it] 16%|█▌        | 1989/12825 [7:08:19<38:02:06, 12.64s/it] 16%|█▌        | 1990/12825 [7:08:32<38:01:29, 12.63s/it] 16%|█▌        | 1991/12825 [7:08:44<38:02:10, 12.64s/it] 16%|█▌        | 1992/12825 [7:08:57<38:03:56, 12.65s/it] 16%|█▌        | 1993/12825 [7:09:10<38:06:46, 12.67s/it] 16%|█▌        | 1994/12825 [7:09:22<38:08:00, 12.67s/it] 16%|█▌        | 1995/12825 [7:09:35<38:08:29, 12.68s/it] 16%|█▌        | 1996/12825 [7:09:48<38:06:56, 12.67s/it] 16%|█▌        | 1997/12825 [7:10:00<38:06:29, 12.67s/it] 16%|█▌        | 1998/12825 [7:10:13<38:12:17, 12.70s/it] 16%|█▌        | 1999/12825 [7:10:26<38:10:34, 12.69s/it] 16%|█▌        | 2000/12825 [7:10:39<38:08:00, 12.68s/it]                                                          16%|█▌        | 2000/12825 [7:10:39<38:08:00, 12.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120156.02lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103444.25lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2000
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2000/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2000/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1950] due to args.save_total_limit
 16%|█▌        | 2001/12825 [7:10:52<38:25:07, 12.78s/it] 16%|█▌        | 2002/12825 [7:11:04<38:19:52, 12.75s/it] 16%|█▌        | 2003/12825 [7:11:17<38:13:23, 12.72s/it] 16%|█▌        | 2004/12825 [7:11:30<38:14:22, 12.72s/it] 16%|█▌        | 2005/12825 [7:11:42<38:17:29, 12.74s/it] 16%|█▌        | 2006/12825 [7:12:03<45:47:14, 15.24s/it] 16%|█▌        | 2007/12825 [7:12:16<43:25:49, 14.45s/it] 16%|█▌        | 2008/12825 [7:12:29<41:46:04, 13.90s/it] 16%|█▌        | 2009/12825 [7:12:41<40:36:58, 13.52s/it] 16%|█▌        | 2010/12825 [7:12:54<39:48:15, 13.25s/it] 16%|█▌        | 2011/12825 [7:13:07<39:15:38, 13.07s/it] 16%|█▌        | 2012/12825 [7:13:19<38:49:55, 12.93s/it] 16%|█▌        | 2013/12825 [7:13:32<38:33:04, 12.84s/it] 16%|█▌        | 2014/12825 [7:13:45<38:27:24, 12.81s/it] 16%|█▌        | 2015/12825 [7:13:57<38:19:39, 12.76s/it] 16%|█▌        | 2016/12825 [7:14:10<38:12:20, 12.72s/it] 16%|█▌        | 2017/12825 [7:14:22<38:07:24, 12.70s/it] 16%|█▌        | 2018/12825 [7:14:35<38:02:41, 12.67s/it] 16%|█▌        | 2019/12825 [7:14:48<38:01:36, 12.67s/it] 16%|█▌        | 2020/12825 [7:15:00<38:00:06, 12.66s/it] 16%|█▌        | 2021/12825 [7:15:13<37:58:08, 12.65s/it] 16%|█▌        | 2022/12825 [7:15:26<37:56:07, 12.64s/it] 16%|█▌        | 2023/12825 [7:15:38<37:56:52, 12.65s/it] 16%|█▌        | 2024/12825 [7:15:51<37:56:23, 12.65s/it] 16%|█▌        | 2025/12825 [7:16:04<37:55:11, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120297.44lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103625.99lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2025
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2025/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2025/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-1975] due to args.save_total_limit
 16%|█▌        | 2026/12825 [7:16:17<38:14:17, 12.75s/it] 16%|█▌        | 2027/12825 [7:16:29<38:07:05, 12.71s/it] 16%|█▌        | 2028/12825 [7:16:42<38:03:30, 12.69s/it] 16%|█▌        | 2029/12825 [7:16:54<37:59:45, 12.67s/it] 16%|█▌        | 2030/12825 [7:17:07<37:58:21, 12.66s/it] 16%|█▌        | 2031/12825 [7:17:20<37:57:32, 12.66s/it] 16%|█▌        | 2032/12825 [7:17:32<37:56:57, 12.66s/it] 16%|█▌        | 2033/12825 [7:17:45<37:57:13, 12.66s/it] 16%|█▌        | 2034/12825 [7:17:58<37:55:44, 12.65s/it] 16%|█▌        | 2035/12825 [7:18:10<37:55:11, 12.65s/it] 16%|█▌        | 2036/12825 [7:18:23<37:56:58, 12.66s/it] 16%|█▌        | 2037/12825 [7:18:36<37:54:52, 12.65s/it] 16%|█▌        | 2038/12825 [7:18:56<44:55:45, 14.99s/it] 16%|█▌        | 2039/12825 [7:19:09<42:46:42, 14.28s/it] 16%|█▌        | 2040/12825 [7:19:21<41:19:26, 13.79s/it] 16%|█▌        | 2041/12825 [7:19:34<40:15:39, 13.44s/it] 16%|█▌        | 2042/12825 [7:19:47<39:30:44, 13.19s/it] 16%|█▌        | 2043/12825 [7:19:59<38:59:19, 13.02s/it] 16%|█▌        | 2044/12825 [7:20:12<38:35:50, 12.89s/it] 16%|█▌        | 2045/12825 [7:20:24<38:20:19, 12.80s/it] 16%|█▌        | 2046/12825 [7:20:37<38:09:25, 12.74s/it] 16%|█▌        | 2047/12825 [7:20:50<38:03:03, 12.71s/it] 16%|█▌        | 2048/12825 [7:21:02<37:56:54, 12.68s/it] 16%|█▌        | 2049/12825 [7:21:15<37:52:15, 12.65s/it] 16%|█▌        | 2050/12825 [7:21:28<37:52:10, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120217.12lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103507.31lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2050
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2050/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2050/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2000] due to args.save_total_limit
 16%|█▌        | 2051/12825 [7:21:36<33:55:39, 11.34s/it] 16%|█▌        | 2052/12825 [7:21:37<24:29:08,  8.18s/it] 16%|█▌        | 2053/12825 [7:22:02<40:08:27, 13.42s/it] 16%|█▌        | 2054/12825 [7:22:15<39:28:00, 13.19s/it] 16%|█▌        | 2055/12825 [7:22:28<38:57:05, 13.02s/it] 16%|█▌        | 2056/12825 [7:22:40<38:37:41, 12.91s/it] 16%|█▌        | 2057/12825 [7:22:53<38:23:44, 12.84s/it] 16%|█▌        | 2058/12825 [7:23:06<38:18:50, 12.81s/it] 16%|█▌        | 2059/12825 [7:23:18<38:08:58, 12.76s/it] 16%|█▌        | 2060/12825 [7:23:31<38:03:48, 12.73s/it] 16%|█▌        | 2061/12825 [7:23:44<38:02:12, 12.72s/it] 16%|█▌        | 2062/12825 [7:23:56<37:56:55, 12.69s/it] 16%|█▌        | 2063/12825 [7:24:09<37:53:47, 12.68s/it] 16%|█▌        | 2064/12825 [7:24:22<37:52:16, 12.67s/it] 16%|█▌        | 2065/12825 [7:24:34<37:49:58, 12.66s/it] 16%|█▌        | 2066/12825 [7:24:47<37:48:30, 12.65s/it] 16%|█▌        | 2067/12825 [7:24:59<37:48:30, 12.65s/it] 16%|█▌        | 2068/12825 [7:25:12<37:47:20, 12.65s/it] 16%|█▌        | 2069/12825 [7:25:25<37:47:44, 12.65s/it] 16%|█▌        | 2070/12825 [7:25:37<37:50:15, 12.67s/it] 16%|█▌        | 2071/12825 [7:25:58<44:47:58, 15.00s/it] 16%|█▌        | 2072/12825 [7:26:11<42:41:05, 14.29s/it] 16%|█▌        | 2073/12825 [7:26:23<41:17:19, 13.82s/it] 16%|█▌        | 2074/12825 [7:26:36<40:12:18, 13.46s/it] 16%|█▌        | 2075/12825 [7:26:48<39:27:36, 13.21s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120176.55lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103533.33lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2075
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2075/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2075/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2025] due to args.save_total_limit
 16%|█▌        | 2076/12825 [7:27:01<39:14:20, 13.14s/it] 16%|█▌        | 2077/12825 [7:27:14<38:55:10, 13.04s/it] 16%|█▌        | 2078/12825 [7:27:27<38:32:33, 12.91s/it] 16%|█▌        | 2079/12825 [7:27:39<38:16:25, 12.82s/it] 16%|█▌        | 2080/12825 [7:27:52<38:08:53, 12.78s/it] 16%|█▌        | 2081/12825 [7:28:05<38:04:07, 12.76s/it] 16%|█▌        | 2082/12825 [7:28:18<37:59:00, 12.73s/it] 16%|█▌        | 2083/12825 [7:28:30<38:00:13, 12.74s/it] 16%|█▌        | 2084/12825 [7:28:43<37:52:38, 12.70s/it] 16%|█▋        | 2085/12825 [7:28:56<37:50:38, 12.69s/it] 16%|█▋        | 2086/12825 [7:29:08<37:51:28, 12.69s/it] 16%|█▋        | 2087/12825 [7:29:21<37:50:39, 12.69s/it] 16%|█▋        | 2088/12825 [7:29:34<37:46:35, 12.67s/it] 16%|█▋        | 2089/12825 [7:29:46<37:44:24, 12.66s/it] 16%|█▋        | 2090/12825 [7:29:59<37:47:48, 12.68s/it] 16%|█▋        | 2091/12825 [7:30:12<37:47:41, 12.68s/it] 16%|█▋        | 2092/12825 [7:30:24<37:45:10, 12.66s/it] 16%|█▋        | 2093/12825 [7:30:37<37:45:08, 12.66s/it] 16%|█▋        | 2094/12825 [7:30:50<37:47:17, 12.68s/it] 16%|█▋        | 2095/12825 [7:31:02<37:48:01, 12.68s/it] 16%|█▋        | 2096/12825 [7:31:15<37:46:24, 12.67s/it] 16%|█▋        | 2097/12825 [7:31:28<37:53:47, 12.72s/it] 16%|█▋        | 2098/12825 [7:31:40<37:50:48, 12.70s/it] 16%|█▋        | 2099/12825 [7:31:53<37:48:23, 12.69s/it] 16%|█▋        | 2100/12825 [7:32:06<37:46:44, 12.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120354.21lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103676.08lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2050] due to args.save_total_limit
 16%|█▋        | 2101/12825 [7:32:19<38:02:50, 12.77s/it] 16%|█▋        | 2102/12825 [7:32:31<37:57:24, 12.74s/it] 16%|█▋        | 2103/12825 [7:32:44<37:50:32, 12.71s/it] 16%|█▋        | 2104/12825 [7:33:05<44:54:24, 15.08s/it] 16%|█▋        | 2105/12825 [7:33:17<42:50:19, 14.39s/it] 16%|█▋        | 2106/12825 [7:33:30<41:16:22, 13.86s/it] 16%|█▋        | 2107/12825 [7:33:43<40:13:47, 13.51s/it] 16%|█▋        | 2108/12825 [7:33:55<39:26:46, 13.25s/it] 16%|█▋        | 2109/12825 [7:34:08<38:53:48, 13.07s/it] 16%|█▋        | 2110/12825 [7:34:21<38:30:05, 12.94s/it] 16%|█▋        | 2111/12825 [7:34:33<38:13:31, 12.84s/it] 16%|█▋        | 2112/12825 [7:34:46<38:01:26, 12.78s/it] 16%|█▋        | 2113/12825 [7:34:59<37:53:32, 12.73s/it] 16%|█▋        | 2114/12825 [7:35:11<37:49:14, 12.71s/it] 16%|█▋        | 2115/12825 [7:35:24<37:45:33, 12.69s/it] 16%|█▋        | 2116/12825 [7:35:37<37:43:32, 12.68s/it] 17%|█▋        | 2117/12825 [7:35:49<37:43:36, 12.68s/it] 17%|█▋        | 2118/12825 [7:36:02<37:41:32, 12.67s/it] 17%|█▋        | 2119/12825 [7:36:14<37:38:52, 12.66s/it] 17%|█▋        | 2120/12825 [7:36:27<37:36:56, 12.65s/it] 17%|█▋        | 2121/12825 [7:36:40<37:32:46, 12.63s/it] 17%|█▋        | 2122/12825 [7:36:52<37:30:27, 12.62s/it] 17%|█▋        | 2123/12825 [7:37:05<37:30:01, 12.61s/it] 17%|█▋        | 2124/12825 [7:37:17<37:29:27, 12.61s/it] 17%|█▋        | 2125/12825 [7:37:30<37:27:54, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 119633.69lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 102574.09lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2075] due to args.save_total_limit
 17%|█▋        | 2126/12825 [7:37:43<37:54:07, 12.75s/it] 17%|█▋        | 2127/12825 [7:37:56<37:45:02, 12.70s/it] 17%|█▋        | 2128/12825 [7:38:08<37:38:22, 12.67s/it] 17%|█▋        | 2129/12825 [7:38:21<37:33:58, 12.64s/it] 17%|█▋        | 2130/12825 [7:38:34<37:33:22, 12.64s/it] 17%|█▋        | 2131/12825 [7:38:46<37:34:41, 12.65s/it] 17%|█▋        | 2132/12825 [7:38:59<37:30:25, 12.63s/it] 17%|█▋        | 2133/12825 [7:39:11<37:29:33, 12.62s/it] 17%|█▋        | 2134/12825 [7:39:24<37:29:12, 12.62s/it] 17%|█▋        | 2135/12825 [7:39:37<37:28:54, 12.62s/it] 17%|█▋        | 2136/12825 [7:39:57<44:37:45, 15.03s/it] 17%|█▋        | 2137/12825 [7:40:10<42:26:48, 14.30s/it] 17%|█▋        | 2138/12825 [7:40:23<40:56:10, 13.79s/it] 17%|█▋        | 2139/12825 [7:40:35<39:51:41, 13.43s/it] 17%|█▋        | 2140/12825 [7:40:48<39:05:29, 13.17s/it] 17%|█▋        | 2141/12825 [7:41:00<38:34:56, 13.00s/it] 17%|█▋        | 2142/12825 [7:41:13<38:11:32, 12.87s/it] 17%|█▋        | 2143/12825 [7:41:26<38:02:27, 12.82s/it] 17%|█▋        | 2144/12825 [7:41:38<37:51:01, 12.76s/it] 17%|█▋        | 2145/12825 [7:41:51<37:43:01, 12.71s/it] 17%|█▋        | 2146/12825 [7:42:03<37:37:46, 12.69s/it] 17%|█▋        | 2147/12825 [7:42:16<37:33:25, 12.66s/it] 17%|█▋        | 2148/12825 [7:42:29<37:30:28, 12.65s/it] 17%|█▋        | 2149/12825 [7:42:41<37:27:50, 12.63s/it] 17%|█▋        | 2150/12825 [7:42:54<37:25:09, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120259.76lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103577.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2100] due to args.save_total_limit
 17%|█▋        | 2151/12825 [7:43:07<37:43:52, 12.73s/it] 17%|█▋        | 2152/12825 [7:43:19<37:35:43, 12.68s/it] 17%|█▋        | 2153/12825 [7:43:32<37:32:22, 12.66s/it] 17%|█▋        | 2154/12825 [7:43:45<37:28:45, 12.64s/it] 17%|█▋        | 2155/12825 [7:43:57<37:26:40, 12.63s/it] 17%|█▋        | 2156/12825 [7:44:10<37:26:30, 12.63s/it] 17%|█▋        | 2157/12825 [7:44:22<37:26:44, 12.64s/it] 17%|█▋        | 2158/12825 [7:44:35<37:27:06, 12.64s/it] 17%|█▋        | 2159/12825 [7:44:48<37:29:24, 12.65s/it] 17%|█▋        | 2160/12825 [7:45:00<37:25:41, 12.63s/it] 17%|█▋        | 2161/12825 [7:45:13<37:22:59, 12.62s/it] 17%|█▋        | 2162/12825 [7:45:26<37:22:22, 12.62s/it] 17%|█▋        | 2163/12825 [7:45:38<37:21:34, 12.61s/it] 17%|█▋        | 2164/12825 [7:45:51<37:20:48, 12.61s/it] 17%|█▋        | 2165/12825 [7:46:03<37:19:14, 12.60s/it] 17%|█▋        | 2166/12825 [7:46:16<37:16:18, 12.59s/it] 17%|█▋        | 2167/12825 [7:46:28<37:15:17, 12.58s/it] 17%|█▋        | 2168/12825 [7:46:49<44:26:18, 15.01s/it] 17%|█▋        | 2169/12825 [7:47:02<42:16:26, 14.28s/it] 17%|█▋        | 2170/12825 [7:47:14<40:46:42, 13.78s/it] 17%|█▋        | 2171/12825 [7:47:27<39:43:20, 13.42s/it] 17%|█▋        | 2172/12825 [7:47:40<39:01:21, 13.19s/it] 17%|█▋        | 2173/12825 [7:47:52<38:29:21, 13.01s/it] 17%|█▋        | 2174/12825 [7:48:05<38:11:20, 12.91s/it] 17%|█▋        | 2175/12825 [7:48:17<37:56:19, 12.82s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120267.04lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103604.56lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2125] due to args.save_total_limit
 17%|█▋        | 2176/12825 [7:48:30<38:03:25, 12.87s/it] 17%|█▋        | 2177/12825 [7:48:43<37:55:58, 12.82s/it] 17%|█▋        | 2178/12825 [7:48:56<37:46:45, 12.77s/it] 17%|█▋        | 2179/12825 [7:49:09<37:46:41, 12.77s/it] 17%|█▋        | 2180/12825 [7:49:21<37:41:53, 12.75s/it] 17%|█▋        | 2181/12825 [7:49:34<37:34:47, 12.71s/it] 17%|█▋        | 2182/12825 [7:49:46<37:26:45, 12.67s/it] 17%|█▋        | 2183/12825 [7:49:59<37:24:46, 12.66s/it] 17%|█▋        | 2184/12825 [7:50:12<37:24:32, 12.66s/it] 17%|█▋        | 2185/12825 [7:50:24<37:21:29, 12.64s/it] 17%|█▋        | 2186/12825 [7:50:37<37:21:47, 12.64s/it] 17%|█▋        | 2187/12825 [7:50:50<37:22:05, 12.65s/it] 17%|█▋        | 2188/12825 [7:51:02<37:21:49, 12.65s/it] 17%|█▋        | 2189/12825 [7:51:15<37:29:50, 12.69s/it] 17%|█▋        | 2190/12825 [7:51:28<37:26:47, 12.68s/it] 17%|█▋        | 2191/12825 [7:51:40<37:28:08, 12.68s/it] 17%|█▋        | 2192/12825 [7:51:53<37:31:38, 12.71s/it] 17%|█▋        | 2193/12825 [7:52:06<37:37:39, 12.74s/it] 17%|█▋        | 2194/12825 [7:52:19<37:34:59, 12.73s/it] 17%|█▋        | 2195/12825 [7:52:31<37:30:45, 12.70s/it] 17%|█▋        | 2196/12825 [7:52:44<37:29:28, 12.70s/it] 17%|█▋        | 2197/12825 [7:52:57<37:24:41, 12.67s/it] 17%|█▋        | 2198/12825 [7:53:09<37:21:49, 12.66s/it] 17%|█▋        | 2199/12825 [7:53:22<37:18:09, 12.64s/it] 17%|█▋        | 2200/12825 [7:53:42<44:05:33, 14.94s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120302.68lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103563.16lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2150] due to args.save_total_limit
 17%|█▋        | 2201/12825 [7:53:55<42:20:47, 14.35s/it] 17%|█▋        | 2202/12825 [7:54:08<40:49:03, 13.83s/it] 17%|█▋        | 2203/12825 [7:54:20<39:45:01, 13.47s/it] 17%|█▋        | 2204/12825 [7:54:33<38:59:53, 13.22s/it] 17%|█▋        | 2205/12825 [7:54:46<38:27:59, 13.04s/it] 17%|█▋        | 2206/12825 [7:54:58<38:04:14, 12.91s/it] 17%|█▋        | 2207/12825 [7:55:11<37:49:30, 12.82s/it] 17%|█▋        | 2208/12825 [7:55:24<37:37:53, 12.76s/it] 17%|█▋        | 2209/12825 [7:55:36<37:32:01, 12.73s/it] 17%|█▋        | 2210/12825 [7:55:49<37:24:46, 12.69s/it] 17%|█▋        | 2211/12825 [7:56:01<37:20:06, 12.66s/it] 17%|█▋        | 2212/12825 [7:56:14<37:16:05, 12.64s/it] 17%|█▋        | 2213/12825 [7:56:27<37:13:39, 12.63s/it] 17%|█▋        | 2214/12825 [7:56:39<37:11:57, 12.62s/it] 17%|█▋        | 2215/12825 [7:56:52<37:13:08, 12.63s/it] 17%|█▋        | 2216/12825 [7:57:04<37:12:01, 12.62s/it] 17%|█▋        | 2217/12825 [7:57:17<37:11:01, 12.62s/it] 17%|█▋        | 2218/12825 [7:57:30<37:11:31, 12.62s/it] 17%|█▋        | 2219/12825 [7:57:42<37:11:17, 12.62s/it] 17%|█▋        | 2220/12825 [7:57:55<37:12:50, 12.63s/it] 17%|█▋        | 2221/12825 [7:58:08<37:11:47, 12.63s/it] 17%|█▋        | 2222/12825 [7:58:20<37:10:11, 12.62s/it] 17%|█▋        | 2223/12825 [7:58:33<37:09:29, 12.62s/it] 17%|█▋        | 2224/12825 [7:58:45<37:07:47, 12.61s/it] 17%|█▋        | 2225/12825 [7:58:58<37:09:39, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120286.20lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103527.09lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2175] due to args.save_total_limit
 17%|█▋        | 2226/12825 [7:59:11<37:28:22, 12.73s/it] 17%|█▋        | 2227/12825 [7:59:24<37:22:53, 12.70s/it] 17%|█▋        | 2228/12825 [7:59:36<37:19:13, 12.68s/it] 17%|█▋        | 2229/12825 [7:59:49<37:17:43, 12.67s/it] 17%|█▋        | 2230/12825 [8:00:02<37:15:17, 12.66s/it] 17%|█▋        | 2231/12825 [8:00:14<37:14:21, 12.65s/it] 17%|█▋        | 2232/12825 [8:00:27<37:13:08, 12.65s/it] 17%|█▋        | 2233/12825 [8:00:48<44:24:00, 15.09s/it] 17%|█▋        | 2234/12825 [8:01:00<42:11:13, 14.34s/it] 17%|█▋        | 2235/12825 [8:01:13<40:38:22, 13.82s/it] 17%|█▋        | 2236/12825 [8:01:25<39:32:23, 13.44s/it] 17%|█▋        | 2237/12825 [8:01:38<38:46:01, 13.18s/it] 17%|█▋        | 2238/12825 [8:01:50<38:13:14, 13.00s/it] 17%|█▋        | 2239/12825 [8:02:03<37:51:08, 12.87s/it] 17%|█▋        | 2240/12825 [8:02:16<37:35:36, 12.79s/it] 17%|█▋        | 2241/12825 [8:02:28<37:24:32, 12.72s/it] 17%|█▋        | 2242/12825 [8:02:41<37:17:15, 12.68s/it] 17%|█▋        | 2243/12825 [8:02:53<37:13:36, 12.66s/it] 17%|█▋        | 2244/12825 [8:03:06<37:10:09, 12.65s/it] 18%|█▊        | 2245/12825 [8:03:19<37:08:16, 12.64s/it] 18%|█▊        | 2246/12825 [8:03:31<37:04:10, 12.61s/it] 18%|█▊        | 2247/12825 [8:03:44<37:02:14, 12.60s/it] 18%|█▊        | 2248/12825 [8:03:56<37:01:48, 12.60s/it] 18%|█▊        | 2249/12825 [8:04:09<37:02:29, 12.61s/it] 18%|█▊        | 2250/12825 [8:04:22<37:00:09, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 117699.98lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101705.48lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2200] due to args.save_total_limit
 18%|█▊        | 2251/12825 [8:04:35<37:18:51, 12.70s/it] 18%|█▊        | 2252/12825 [8:04:47<37:11:25, 12.66s/it] 18%|█▊        | 2253/12825 [8:05:00<37:07:22, 12.64s/it] 18%|█▊        | 2254/12825 [8:05:12<37:04:48, 12.63s/it] 18%|█▊        | 2255/12825 [8:05:25<37:04:21, 12.63s/it] 18%|█▊        | 2256/12825 [8:05:38<37:02:22, 12.62s/it] 18%|█▊        | 2257/12825 [8:05:50<37:00:26, 12.61s/it] 18%|█▊        | 2258/12825 [8:06:03<36:59:33, 12.60s/it] 18%|█▊        | 2259/12825 [8:06:15<36:58:32, 12.60s/it] 18%|█▊        | 2260/12825 [8:06:28<36:57:49, 12.60s/it] 18%|█▊        | 2261/12825 [8:06:40<36:59:26, 12.61s/it] 18%|█▊        | 2262/12825 [8:06:53<36:59:39, 12.61s/it] 18%|█▊        | 2263/12825 [8:07:06<36:58:23, 12.60s/it] 18%|█▊        | 2264/12825 [8:07:18<36:56:45, 12.59s/it] 18%|█▊        | 2265/12825 [8:07:39<44:09:55, 15.06s/it] 18%|█▊        | 2266/12825 [8:07:52<42:01:39, 14.33s/it] 18%|█▊        | 2267/12825 [8:08:04<40:30:44, 13.81s/it] 18%|█▊        | 2268/12825 [8:08:17<39:26:31, 13.45s/it] 18%|█▊        | 2269/12825 [8:08:30<38:41:20, 13.19s/it] 18%|█▊        | 2270/12825 [8:08:42<38:11:20, 13.03s/it] 18%|█▊        | 2271/12825 [8:08:55<37:49:00, 12.90s/it] 18%|█▊        | 2272/12825 [8:09:07<37:32:48, 12.81s/it] 18%|█▊        | 2273/12825 [8:09:20<37:21:20, 12.74s/it] 18%|█▊        | 2274/12825 [8:09:33<37:11:55, 12.69s/it] 18%|█▊        | 2275/12825 [8:09:45<37:09:15, 12.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120207.04lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103573.29lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2225] due to args.save_total_limit
 18%|█▊        | 2276/12825 [8:09:58<37:25:31, 12.77s/it] 18%|█▊        | 2277/12825 [8:10:11<37:16:58, 12.72s/it] 18%|█▊        | 2278/12825 [8:10:23<37:10:44, 12.69s/it] 18%|█▊        | 2279/12825 [8:10:36<37:08:58, 12.68s/it] 18%|█▊        | 2280/12825 [8:10:49<37:05:07, 12.66s/it] 18%|█▊        | 2281/12825 [8:11:01<37:02:15, 12.65s/it] 18%|█▊        | 2282/12825 [8:11:14<37:00:22, 12.64s/it] 18%|█▊        | 2283/12825 [8:11:26<36:59:31, 12.63s/it] 18%|█▊        | 2284/12825 [8:11:39<36:58:52, 12.63s/it] 18%|█▊        | 2285/12825 [8:11:52<36:58:44, 12.63s/it] 18%|█▊        | 2286/12825 [8:12:04<36:57:21, 12.62s/it] 18%|█▊        | 2287/12825 [8:12:17<36:54:45, 12.61s/it] 18%|█▊        | 2288/12825 [8:12:30<36:58:26, 12.63s/it] 18%|█▊        | 2289/12825 [8:12:42<36:59:40, 12.64s/it] 18%|█▊        | 2290/12825 [8:12:55<36:58:53, 12.64s/it] 18%|█▊        | 2291/12825 [8:13:08<36:57:51, 12.63s/it] 18%|█▊        | 2292/12825 [8:13:20<36:58:46, 12.64s/it] 18%|█▊        | 2293/12825 [8:13:33<36:57:56, 12.64s/it] 18%|█▊        | 2294/12825 [8:13:45<36:57:20, 12.63s/it] 18%|█▊        | 2295/12825 [8:13:58<36:56:31, 12.63s/it] 18%|█▊        | 2296/12825 [8:14:11<36:56:08, 12.63s/it] 18%|█▊        | 2297/12825 [8:14:23<36:57:46, 12.64s/it] 18%|█▊        | 2298/12825 [8:14:44<44:05:52, 15.08s/it] 18%|█▊        | 2299/12825 [8:14:57<41:56:23, 14.34s/it] 18%|█▊        | 2300/12825 [8:15:09<40:26:26, 13.83s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120349.09lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103375.88lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2250] due to args.save_total_limit
 18%|█▊        | 2301/12825 [8:15:22<39:38:11, 13.56s/it] 18%|█▊        | 2302/12825 [8:15:35<38:56:16, 13.32s/it] 18%|█▊        | 2303/12825 [8:15:48<38:23:40, 13.14s/it] 18%|█▊        | 2304/12825 [8:16:00<37:59:47, 13.00s/it] 18%|█▊        | 2305/12825 [8:16:13<37:54:07, 12.97s/it] 18%|█▊        | 2306/12825 [8:16:26<37:36:22, 12.87s/it] 18%|█▊        | 2307/12825 [8:16:39<37:25:09, 12.81s/it] 18%|█▊        | 2308/12825 [8:16:51<37:15:31, 12.75s/it] 18%|█▊        | 2309/12825 [8:17:04<37:12:35, 12.74s/it] 18%|█▊        | 2310/12825 [8:17:17<37:07:21, 12.71s/it] 18%|█▊        | 2311/12825 [8:17:29<37:08:57, 12.72s/it] 18%|█▊        | 2312/12825 [8:17:42<37:06:01, 12.70s/it] 18%|█▊        | 2313/12825 [8:17:55<37:09:16, 12.72s/it] 18%|█▊        | 2314/12825 [8:18:07<37:02:00, 12.68s/it] 18%|█▊        | 2315/12825 [8:18:20<36:56:45, 12.66s/it] 18%|█▊        | 2316/12825 [8:18:33<36:58:58, 12.67s/it] 18%|█▊        | 2317/12825 [8:18:45<36:55:46, 12.65s/it] 18%|█▊        | 2318/12825 [8:18:58<36:54:01, 12.64s/it] 18%|█▊        | 2319/12825 [8:19:11<36:51:11, 12.63s/it] 18%|█▊        | 2320/12825 [8:19:23<36:59:14, 12.68s/it] 18%|█▊        | 2321/12825 [8:19:36<37:02:16, 12.69s/it] 18%|█▊        | 2322/12825 [8:19:49<37:00:34, 12.69s/it] 18%|█▊        | 2323/12825 [8:20:01<37:00:49, 12.69s/it] 18%|█▊        | 2324/12825 [8:20:14<37:05:06, 12.71s/it] 18%|█▊        | 2325/12825 [8:20:27<37:08:36, 12.73s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120332.85lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103603.90lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2275] due to args.save_total_limit
 18%|█▊        | 2326/12825 [8:20:40<37:20:55, 12.81s/it] 18%|█▊        | 2327/12825 [8:20:53<37:19:21, 12.80s/it] 18%|█▊        | 2328/12825 [8:21:05<37:09:56, 12.75s/it] 18%|█▊        | 2329/12825 [8:21:18<37:01:01, 12.70s/it] 18%|█▊        | 2330/12825 [8:21:39<44:03:18, 15.11s/it] 18%|█▊        | 2331/12825 [8:21:51<41:55:02, 14.38s/it] 18%|█▊        | 2332/12825 [8:22:04<40:23:56, 13.86s/it] 18%|█▊        | 2333/12825 [8:22:17<39:20:32, 13.50s/it] 18%|█▊        | 2334/12825 [8:22:29<38:34:45, 13.24s/it] 18%|█▊        | 2335/12825 [8:22:42<38:01:56, 13.05s/it] 18%|█▊        | 2336/12825 [8:22:55<37:40:35, 12.93s/it] 18%|█▊        | 2337/12825 [8:23:07<37:23:43, 12.84s/it] 18%|█▊        | 2338/12825 [8:23:20<37:12:28, 12.77s/it] 18%|█▊        | 2339/12825 [8:23:32<37:01:05, 12.71s/it] 18%|█▊        | 2340/12825 [8:23:45<36:55:04, 12.68s/it] 18%|█▊        | 2341/12825 [8:23:58<36:50:40, 12.65s/it] 18%|█▊        | 2342/12825 [8:24:10<36:49:30, 12.65s/it] 18%|█▊        | 2343/12825 [8:24:23<36:47:49, 12.64s/it] 18%|█▊        | 2344/12825 [8:24:35<36:46:38, 12.63s/it] 18%|█▊        | 2345/12825 [8:24:48<36:44:50, 12.62s/it] 18%|█▊        | 2346/12825 [8:25:01<36:46:46, 12.64s/it] 18%|█▊        | 2347/12825 [8:25:13<36:46:21, 12.63s/it] 18%|█▊        | 2348/12825 [8:25:26<36:42:11, 12.61s/it] 18%|█▊        | 2349/12825 [8:25:38<36:41:38, 12.61s/it] 18%|█▊        | 2350/12825 [8:25:51<36:40:35, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120239.20lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103516.20lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2300] due to args.save_total_limit
 18%|█▊        | 2351/12825 [8:26:04<37:03:01, 12.73s/it] 18%|█▊        | 2352/12825 [8:26:17<36:58:37, 12.71s/it] 18%|█▊        | 2353/12825 [8:26:29<36:56:48, 12.70s/it] 18%|█▊        | 2354/12825 [8:26:42<36:56:51, 12.70s/it] 18%|█▊        | 2355/12825 [8:26:55<37:00:18, 12.72s/it] 18%|█▊        | 2356/12825 [8:27:08<37:02:51, 12.74s/it] 18%|█▊        | 2357/12825 [8:27:20<36:55:18, 12.70s/it] 18%|█▊        | 2358/12825 [8:27:33<36:51:57, 12.68s/it] 18%|█▊        | 2359/12825 [8:27:46<36:52:52, 12.69s/it] 18%|█▊        | 2360/12825 [8:27:58<36:52:04, 12.68s/it] 18%|█▊        | 2361/12825 [8:28:11<36:54:55, 12.70s/it] 18%|█▊        | 2362/12825 [8:28:32<43:58:04, 15.13s/it] 18%|█▊        | 2363/12825 [8:28:45<41:50:55, 14.40s/it] 18%|█▊        | 2364/12825 [8:28:57<40:17:59, 13.87s/it] 18%|█▊        | 2365/12825 [8:29:10<39:11:06, 13.49s/it] 18%|█▊        | 2366/12825 [8:29:22<38:24:06, 13.22s/it] 18%|█▊        | 2367/12825 [8:29:35<37:53:55, 13.05s/it] 18%|█▊        | 2368/12825 [8:29:48<37:30:05, 12.91s/it] 18%|█▊        | 2369/12825 [8:30:00<37:14:42, 12.82s/it] 18%|█▊        | 2370/12825 [8:30:13<36:58:36, 12.73s/it] 18%|█▊        | 2371/12825 [8:30:25<36:54:04, 12.71s/it] 18%|█▊        | 2372/12825 [8:30:38<36:48:02, 12.67s/it] 19%|█▊        | 2373/12825 [8:30:51<36:44:23, 12.65s/it] 19%|█▊        | 2374/12825 [8:31:03<36:38:54, 12.62s/it] 19%|█▊        | 2375/12825 [8:31:16<36:35:18, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120316.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103583.05lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2325] due to args.save_total_limit
 19%|█▊        | 2376/12825 [8:31:29<36:51:08, 12.70s/it] 19%|█▊        | 2377/12825 [8:31:41<36:49:39, 12.69s/it] 19%|█▊        | 2378/12825 [8:31:54<36:45:46, 12.67s/it] 19%|█▊        | 2379/12825 [8:32:07<36:48:24, 12.68s/it] 19%|█▊        | 2380/12825 [8:32:19<36:47:11, 12.68s/it] 19%|█▊        | 2381/12825 [8:32:32<36:50:08, 12.70s/it] 19%|█▊        | 2382/12825 [8:32:45<36:46:19, 12.68s/it] 19%|█▊        | 2383/12825 [8:32:57<36:49:04, 12.69s/it] 19%|█▊        | 2384/12825 [8:33:10<36:50:56, 12.71s/it] 19%|█▊        | 2385/12825 [8:33:23<36:53:02, 12.72s/it] 19%|█▊        | 2386/12825 [8:33:36<36:50:47, 12.71s/it] 19%|█▊        | 2387/12825 [8:33:48<36:49:00, 12.70s/it] 19%|█▊        | 2388/12825 [8:34:01<36:49:29, 12.70s/it] 19%|█▊        | 2389/12825 [8:34:14<36:46:14, 12.68s/it] 19%|█▊        | 2390/12825 [8:34:26<36:43:25, 12.67s/it] 19%|█▊        | 2391/12825 [8:34:39<36:40:22, 12.65s/it] 19%|█▊        | 2392/12825 [8:34:51<36:39:40, 12.65s/it] 19%|█▊        | 2393/12825 [8:35:04<36:43:40, 12.67s/it] 19%|█▊        | 2394/12825 [8:35:17<36:44:16, 12.68s/it] 19%|█▊        | 2395/12825 [8:35:38<44:02:22, 15.20s/it] 19%|█▊        | 2396/12825 [8:35:51<41:50:35, 14.44s/it] 19%|█▊        | 2397/12825 [8:36:03<40:20:16, 13.93s/it] 19%|█▊        | 2398/12825 [8:36:16<39:13:31, 13.54s/it] 19%|█▊        | 2399/12825 [8:36:29<38:33:54, 13.32s/it] 19%|█▊        | 2400/12825 [8:36:42<38:01:19, 13.13s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120142.64lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103519.04lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2350] due to args.save_total_limit
 19%|█▊        | 2401/12825 [8:36:54<37:51:31, 13.07s/it] 19%|█▊        | 2402/12825 [8:37:07<37:34:00, 12.98s/it] 19%|█▊        | 2403/12825 [8:37:20<37:18:29, 12.89s/it] 19%|█▊        | 2404/12825 [8:37:33<37:05:54, 12.82s/it] 19%|█▉        | 2405/12825 [8:37:45<36:58:53, 12.78s/it] 19%|█▉        | 2406/12825 [8:37:58<36:51:07, 12.73s/it] 19%|█▉        | 2407/12825 [8:38:11<36:47:47, 12.72s/it] 19%|█▉        | 2408/12825 [8:38:23<36:44:28, 12.70s/it] 19%|█▉        | 2409/12825 [8:38:36<36:48:31, 12.72s/it] 19%|█▉        | 2410/12825 [8:38:49<36:42:04, 12.69s/it] 19%|█▉        | 2411/12825 [8:39:01<36:38:41, 12.67s/it] 19%|█▉        | 2412/12825 [8:39:14<36:34:40, 12.65s/it] 19%|█▉        | 2413/12825 [8:39:26<36:35:10, 12.65s/it] 19%|█▉        | 2414/12825 [8:39:39<36:38:42, 12.67s/it] 19%|█▉        | 2415/12825 [8:39:52<36:40:13, 12.68s/it] 19%|█▉        | 2416/12825 [8:40:05<36:43:56, 12.70s/it] 19%|█▉        | 2417/12825 [8:40:17<36:42:26, 12.70s/it] 19%|█▉        | 2418/12825 [8:40:30<36:40:16, 12.69s/it] 19%|█▉        | 2419/12825 [8:40:43<36:39:59, 12.68s/it] 19%|█▉        | 2420/12825 [8:40:55<36:35:01, 12.66s/it] 19%|█▉        | 2421/12825 [8:41:08<36:36:11, 12.67s/it] 19%|█▉        | 2422/12825 [8:41:21<36:33:45, 12.65s/it] 19%|█▉        | 2423/12825 [8:41:33<36:38:37, 12.68s/it] 19%|█▉        | 2424/12825 [8:41:46<36:41:46, 12.70s/it] 19%|█▉        | 2425/12825 [8:41:59<36:43:02, 12.71s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120163.92lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103547.15lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2375] due to args.save_total_limit
 19%|█▉        | 2426/12825 [8:42:12<36:54:42, 12.78s/it] 19%|█▉        | 2427/12825 [8:42:35<46:17:00, 16.02s/it] 19%|█▉        | 2428/12825 [8:42:48<43:19:58, 15.00s/it] 19%|█▉        | 2429/12825 [8:43:01<41:19:05, 14.31s/it] 19%|█▉        | 2430/12825 [8:43:13<39:57:10, 13.84s/it] 19%|█▉        | 2431/12825 [8:43:26<38:55:51, 13.48s/it] 19%|█▉        | 2432/12825 [8:43:39<38:11:15, 13.23s/it] 19%|█▉        | 2433/12825 [8:43:51<37:43:19, 13.07s/it] 19%|█▉        | 2434/12825 [8:44:04<37:22:41, 12.95s/it] 19%|█▉        | 2435/12825 [8:44:17<37:09:39, 12.88s/it] 19%|█▉        | 2436/12825 [8:44:29<37:01:23, 12.83s/it] 19%|█▉        | 2437/12825 [8:44:42<36:52:17, 12.78s/it] 19%|█▉        | 2438/12825 [8:44:55<36:45:32, 12.74s/it] 19%|█▉        | 2439/12825 [8:45:07<36:42:04, 12.72s/it] 19%|█▉        | 2440/12825 [8:45:20<36:41:52, 12.72s/it] 19%|█▉        | 2441/12825 [8:45:33<36:41:30, 12.72s/it] 19%|█▉        | 2442/12825 [8:45:46<36:41:12, 12.72s/it] 19%|█▉        | 2443/12825 [8:45:58<36:40:41, 12.72s/it] 19%|█▉        | 2444/12825 [8:46:11<36:39:13, 12.71s/it] 19%|█▉        | 2445/12825 [8:46:24<36:38:17, 12.71s/it] 19%|█▉        | 2446/12825 [8:46:36<36:40:18, 12.72s/it] 19%|█▉        | 2447/12825 [8:46:49<36:42:14, 12.73s/it] 19%|█▉        | 2448/12825 [8:47:02<36:42:19, 12.73s/it] 19%|█▉        | 2449/12825 [8:47:15<36:46:35, 12.76s/it] 19%|█▉        | 2450/12825 [8:47:28<36:46:27, 12.76s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120304.47lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103570.83lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2400] due to args.save_total_limit
 19%|█▉        | 2451/12825 [8:47:40<36:56:13, 12.82s/it] 19%|█▉        | 2452/12825 [8:47:53<36:46:56, 12.77s/it] 19%|█▉        | 2453/12825 [8:48:06<36:38:56, 12.72s/it] 19%|█▉        | 2454/12825 [8:48:18<36:34:53, 12.70s/it] 19%|█▉        | 2455/12825 [8:48:31<36:29:20, 12.67s/it] 19%|█▉        | 2456/12825 [8:48:44<36:26:49, 12.65s/it] 19%|█▉        | 2457/12825 [8:48:56<36:24:46, 12.64s/it] 19%|█▉        | 2458/12825 [8:49:09<36:23:46, 12.64s/it] 19%|█▉        | 2459/12825 [8:49:30<43:21:11, 15.06s/it] 19%|█▉        | 2460/12825 [8:49:42<41:12:20, 14.31s/it] 19%|█▉        | 2461/12825 [8:49:55<39:50:33, 13.84s/it] 19%|█▉        | 2462/12825 [8:50:07<38:47:46, 13.48s/it] 19%|█▉        | 2463/12825 [8:50:20<38:03:54, 13.22s/it] 19%|█▉        | 2464/12825 [8:50:33<37:35:50, 13.06s/it] 19%|█▉        | 2465/12825 [8:50:45<37:15:04, 12.94s/it] 19%|█▉        | 2466/12825 [8:50:58<37:02:32, 12.87s/it] 19%|█▉        | 2467/12825 [8:51:11<36:49:37, 12.80s/it] 19%|█▉        | 2468/12825 [8:51:23<36:42:07, 12.76s/it] 19%|█▉        | 2469/12825 [8:51:36<36:33:20, 12.71s/it] 19%|█▉        | 2470/12825 [8:51:49<36:28:08, 12.68s/it] 19%|█▉        | 2471/12825 [8:52:01<36:28:19, 12.68s/it] 19%|█▉        | 2472/12825 [8:52:14<36:26:01, 12.67s/it] 19%|█▉        | 2473/12825 [8:52:27<36:30:22, 12.70s/it] 19%|█▉        | 2474/12825 [8:52:39<36:31:51, 12.71s/it] 19%|█▉        | 2475/12825 [8:52:52<36:33:10, 12.71s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120270.49lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103554.92lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2450] due to args.save_total_limit
 19%|█▉        | 2476/12825 [8:53:05<36:44:40, 12.78s/it] 19%|█▉        | 2477/12825 [8:53:18<36:40:43, 12.76s/it] 19%|█▉        | 2478/12825 [8:53:31<36:38:50, 12.75s/it] 19%|█▉        | 2479/12825 [8:53:43<36:36:30, 12.74s/it] 19%|█▉        | 2480/12825 [8:53:56<36:37:01, 12.74s/it] 19%|█▉        | 2481/12825 [8:54:09<36:36:24, 12.74s/it] 19%|█▉        | 2482/12825 [8:54:22<36:37:48, 12.75s/it] 19%|█▉        | 2483/12825 [8:54:34<36:36:03, 12.74s/it] 19%|█▉        | 2484/12825 [8:54:47<36:36:43, 12.75s/it] 19%|█▉        | 2485/12825 [8:55:00<36:33:47, 12.73s/it] 19%|█▉        | 2486/12825 [8:55:12<36:29:51, 12.71s/it] 19%|█▉        | 2487/12825 [8:55:25<36:27:30, 12.70s/it] 19%|█▉        | 2488/12825 [8:55:38<36:25:35, 12.69s/it] 19%|█▉        | 2489/12825 [8:55:50<36:26:47, 12.69s/it] 19%|█▉        | 2490/12825 [8:56:03<36:26:34, 12.69s/it] 19%|█▉        | 2491/12825 [8:56:16<36:25:21, 12.69s/it] 19%|█▉        | 2492/12825 [8:56:36<43:17:58, 15.09s/it] 19%|█▉        | 2493/12825 [8:56:49<41:16:22, 14.38s/it] 19%|█▉        | 2494/12825 [8:57:02<39:49:37, 13.88s/it] 19%|█▉        | 2495/12825 [8:57:15<38:46:13, 13.51s/it] 19%|█▉        | 2496/12825 [8:57:27<38:04:06, 13.27s/it] 19%|█▉        | 2497/12825 [8:57:40<37:40:09, 13.13s/it] 19%|█▉        | 2498/12825 [8:57:53<37:18:54, 13.01s/it] 19%|█▉        | 2499/12825 [8:58:06<37:03:54, 12.92s/it] 19%|█▉        | 2500/12825 [8:58:18<36:50:33, 12.85s/it]                                                          19%|█▉        | 2500/12825 [8:58:18<36:50:33, 12.85s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120160.99lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103430.83lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2425] due to args.save_total_limit
 20%|█▉        | 2501/12825 [8:58:31<36:53:19, 12.86s/it] 20%|█▉        | 2502/12825 [8:58:44<36:36:20, 12.77s/it] 20%|█▉        | 2503/12825 [8:58:56<36:25:56, 12.71s/it] 20%|█▉        | 2504/12825 [8:59:09<36:18:59, 12.67s/it] 20%|█▉        | 2505/12825 [8:59:21<36:15:03, 12.65s/it] 20%|█▉        | 2506/12825 [8:59:34<36:10:27, 12.62s/it] 20%|█▉        | 2507/12825 [8:59:47<36:09:34, 12.62s/it] 20%|█▉        | 2508/12825 [8:59:59<36:07:37, 12.61s/it] 20%|█▉        | 2509/12825 [9:00:12<36:05:16, 12.59s/it] 20%|█▉        | 2510/12825 [9:00:24<36:02:51, 12.58s/it] 20%|█▉        | 2511/12825 [9:00:37<36:03:11, 12.58s/it] 20%|█▉        | 2512/12825 [9:00:49<36:02:53, 12.58s/it] 20%|█▉        | 2513/12825 [9:01:02<36:02:22, 12.58s/it] 20%|█▉        | 2514/12825 [9:01:15<36:00:35, 12.57s/it] 20%|█▉        | 2515/12825 [9:01:27<36:00:12, 12.57s/it] 20%|█▉        | 2516/12825 [9:01:40<36:01:22, 12.58s/it] 20%|█▉        | 2517/12825 [9:01:52<36:00:01, 12.57s/it] 20%|█▉        | 2518/12825 [9:02:05<36:01:10, 12.58s/it] 20%|█▉        | 2519/12825 [9:02:17<36:00:59, 12.58s/it] 20%|█▉        | 2520/12825 [9:02:30<36:00:06, 12.58s/it] 20%|█▉        | 2521/12825 [9:02:43<35:59:11, 12.57s/it] 20%|█▉        | 2522/12825 [9:02:55<35:59:47, 12.58s/it] 20%|█▉        | 2523/12825 [9:03:08<35:59:52, 12.58s/it] 20%|█▉        | 2524/12825 [9:03:29<43:04:44, 15.06s/it] 20%|█▉        | 2525/12825 [9:03:41<40:57:46, 14.32s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120217.37lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103596.13lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2475] due to args.save_total_limit
 20%|█▉        | 2526/12825 [9:03:54<39:46:30, 13.90s/it] 20%|█▉        | 2527/12825 [9:04:07<38:40:13, 13.52s/it] 20%|█▉        | 2528/12825 [9:04:19<37:52:34, 13.24s/it] 20%|█▉        | 2529/12825 [9:04:32<37:22:23, 13.07s/it] 20%|█▉        | 2530/12825 [9:04:45<36:59:09, 12.93s/it] 20%|█▉        | 2531/12825 [9:04:57<36:42:31, 12.84s/it] 20%|█▉        | 2532/12825 [9:05:10<36:31:23, 12.77s/it] 20%|█▉        | 2533/12825 [9:05:23<36:23:54, 12.73s/it] 20%|█▉        | 2534/12825 [9:05:35<36:16:59, 12.69s/it] 20%|█▉        | 2535/12825 [9:05:48<36:16:16, 12.69s/it] 20%|█▉        | 2536/12825 [9:06:00<36:11:38, 12.66s/it] 20%|█▉        | 2537/12825 [9:06:13<36:08:26, 12.65s/it] 20%|█▉        | 2538/12825 [9:06:26<36:07:01, 12.64s/it] 20%|█▉        | 2539/12825 [9:06:38<36:06:54, 12.64s/it] 20%|█▉        | 2540/12825 [9:06:51<36:06:28, 12.64s/it] 20%|█▉        | 2541/12825 [9:07:04<36:07:54, 12.65s/it] 20%|█▉        | 2542/12825 [9:07:16<36:06:48, 12.64s/it] 20%|█▉        | 2543/12825 [9:07:29<36:03:34, 12.63s/it] 20%|█▉        | 2544/12825 [9:07:41<36:01:42, 12.62s/it] 20%|█▉        | 2545/12825 [9:07:54<36:01:44, 12.62s/it] 20%|█▉        | 2546/12825 [9:08:07<36:00:39, 12.61s/it] 20%|█▉        | 2547/12825 [9:08:19<36:00:49, 12.61s/it] 20%|█▉        | 2548/12825 [9:08:32<36:13:11, 12.69s/it] 20%|█▉        | 2549/12825 [9:08:45<36:07:13, 12.65s/it] 20%|█▉        | 2550/12825 [9:08:57<36:05:37, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120286.07lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103564.48lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2525] due to args.save_total_limit
 20%|█▉        | 2551/12825 [9:09:10<36:21:36, 12.74s/it] 20%|█▉        | 2552/12825 [9:09:23<36:13:52, 12.70s/it] 20%|█▉        | 2553/12825 [9:09:35<36:09:00, 12.67s/it] 20%|█▉        | 2554/12825 [9:09:48<36:04:13, 12.64s/it] 20%|█▉        | 2555/12825 [9:10:01<36:00:01, 12.62s/it] 20%|█▉        | 2556/12825 [9:10:21<42:39:17, 14.95s/it] 20%|█▉        | 2557/12825 [9:10:34<40:37:38, 14.24s/it] 20%|█▉        | 2558/12825 [9:10:46<39:11:41, 13.74s/it] 20%|█▉        | 2559/12825 [9:10:59<38:10:01, 13.38s/it] 20%|█▉        | 2560/12825 [9:11:11<37:28:48, 13.14s/it] 20%|█▉        | 2561/12825 [9:11:24<36:59:24, 12.97s/it] 20%|█▉        | 2562/12825 [9:11:36<36:37:53, 12.85s/it] 20%|█▉        | 2563/12825 [9:11:49<36:23:15, 12.77s/it] 20%|█▉        | 2564/12825 [9:11:57<32:14:34, 11.31s/it] 20%|██        | 2565/12825 [9:11:58<23:16:15,  8.17s/it] 20%|██        | 2566/12825 [9:12:23<38:08:02, 13.38s/it] 20%|██        | 2567/12825 [9:12:36<37:28:11, 13.15s/it] 20%|██        | 2568/12825 [9:12:49<37:00:30, 12.99s/it] 20%|██        | 2569/12825 [9:13:01<36:42:17, 12.88s/it] 20%|██        | 2570/12825 [9:13:14<36:30:35, 12.82s/it] 20%|██        | 2571/12825 [9:13:26<36:20:25, 12.76s/it] 20%|██        | 2572/12825 [9:13:39<36:13:37, 12.72s/it] 20%|██        | 2573/12825 [9:13:52<36:09:21, 12.70s/it] 20%|██        | 2574/12825 [9:14:04<36:04:14, 12.67s/it] 20%|██        | 2575/12825 [9:14:17<36:01:47, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120303.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103551.70lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2500] due to args.save_total_limit
 20%|██        | 2576/12825 [9:14:30<36:15:12, 12.73s/it] 20%|██        | 2577/12825 [9:14:42<36:06:54, 12.69s/it] 20%|██        | 2578/12825 [9:14:55<36:00:55, 12.65s/it] 20%|██        | 2579/12825 [9:15:08<35:55:44, 12.62s/it] 20%|██        | 2580/12825 [9:15:20<35:51:37, 12.60s/it] 20%|██        | 2581/12825 [9:15:33<35:51:59, 12.60s/it] 20%|██        | 2582/12825 [9:15:45<35:49:53, 12.59s/it] 20%|██        | 2583/12825 [9:15:58<35:47:42, 12.58s/it] 20%|██        | 2584/12825 [9:16:10<35:45:58, 12.57s/it] 20%|██        | 2585/12825 [9:16:23<35:44:49, 12.57s/it] 20%|██        | 2586/12825 [9:16:36<35:47:55, 12.59s/it] 20%|██        | 2587/12825 [9:16:48<35:47:55, 12.59s/it] 20%|██        | 2588/12825 [9:17:01<35:45:30, 12.57s/it] 20%|██        | 2589/12825 [9:17:22<42:53:36, 15.09s/it] 20%|██        | 2590/12825 [9:17:34<40:43:02, 14.32s/it] 20%|██        | 2591/12825 [9:17:47<39:11:24, 13.79s/it] 20%|██        | 2592/12825 [9:17:59<38:10:33, 13.43s/it] 20%|██        | 2593/12825 [9:18:12<37:26:06, 13.17s/it] 20%|██        | 2594/12825 [9:18:24<36:54:19, 12.99s/it] 20%|██        | 2595/12825 [9:18:37<36:31:24, 12.85s/it] 20%|██        | 2596/12825 [9:18:50<36:16:14, 12.77s/it] 20%|██        | 2597/12825 [9:19:02<36:06:08, 12.71s/it] 20%|██        | 2598/12825 [9:19:15<35:58:54, 12.67s/it] 20%|██        | 2599/12825 [9:19:27<35:52:08, 12.63s/it] 20%|██        | 2600/12825 [9:19:40<35:48:40, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120380.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103494.35lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2550] due to args.save_total_limit
 20%|██        | 2601/12825 [9:19:53<36:04:41, 12.70s/it] 20%|██        | 2602/12825 [9:20:05<35:58:59, 12.67s/it] 20%|██        | 2603/12825 [9:20:18<35:55:19, 12.65s/it] 20%|██        | 2604/12825 [9:20:30<35:51:40, 12.63s/it] 20%|██        | 2605/12825 [9:20:43<35:51:27, 12.63s/it] 20%|██        | 2606/12825 [9:20:56<35:47:43, 12.61s/it] 20%|██        | 2607/12825 [9:21:08<35:47:57, 12.61s/it] 20%|██        | 2608/12825 [9:21:21<35:44:52, 12.60s/it] 20%|██        | 2609/12825 [9:21:33<35:43:11, 12.59s/it] 20%|██        | 2610/12825 [9:21:46<35:42:58, 12.59s/it] 20%|██        | 2611/12825 [9:21:59<35:42:43, 12.59s/it] 20%|██        | 2612/12825 [9:22:11<35:47:29, 12.62s/it] 20%|██        | 2613/12825 [9:22:24<35:43:56, 12.60s/it] 20%|██        | 2614/12825 [9:22:36<35:43:34, 12.60s/it] 20%|██        | 2615/12825 [9:22:49<35:40:35, 12.58s/it] 20%|██        | 2616/12825 [9:23:02<35:40:04, 12.58s/it] 20%|██        | 2617/12825 [9:23:14<35:41:47, 12.59s/it] 20%|██        | 2618/12825 [9:23:27<35:40:55, 12.58s/it] 20%|██        | 2619/12825 [9:23:39<35:40:49, 12.59s/it] 20%|██        | 2620/12825 [9:23:52<35:39:19, 12.58s/it] 20%|██        | 2621/12825 [9:24:04<35:40:11, 12.58s/it] 20%|██        | 2622/12825 [9:24:25<42:40:55, 15.06s/it] 20%|██        | 2623/12825 [9:24:38<40:37:55, 14.34s/it] 20%|██        | 2624/12825 [9:24:51<39:07:13, 13.81s/it] 20%|██        | 2625/12825 [9:25:03<38:06:02, 13.45s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120358.04lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103610.06lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2575] due to args.save_total_limit
 20%|██        | 2626/12825 [9:25:16<37:36:40, 13.28s/it] 20%|██        | 2627/12825 [9:25:29<36:58:21, 13.05s/it] 20%|██        | 2628/12825 [9:25:41<36:33:58, 12.91s/it] 20%|██        | 2629/12825 [9:25:54<36:17:03, 12.81s/it] 21%|██        | 2630/12825 [9:26:06<36:06:40, 12.75s/it] 21%|██        | 2631/12825 [9:26:19<35:56:41, 12.69s/it] 21%|██        | 2632/12825 [9:26:31<35:50:53, 12.66s/it] 21%|██        | 2633/12825 [9:26:44<35:47:47, 12.64s/it] 21%|██        | 2634/12825 [9:26:57<35:42:14, 12.61s/it] 21%|██        | 2635/12825 [9:27:09<35:40:42, 12.60s/it] 21%|██        | 2636/12825 [9:27:22<35:39:22, 12.60s/it] 21%|██        | 2637/12825 [9:27:34<35:36:01, 12.58s/it] 21%|██        | 2638/12825 [9:27:47<35:34:45, 12.57s/it] 21%|██        | 2639/12825 [9:27:59<35:32:04, 12.56s/it] 21%|██        | 2640/12825 [9:28:12<35:31:13, 12.56s/it] 21%|██        | 2641/12825 [9:28:24<35:30:29, 12.55s/it] 21%|██        | 2642/12825 [9:28:37<35:31:52, 12.56s/it] 21%|██        | 2643/12825 [9:28:50<35:31:59, 12.56s/it] 21%|██        | 2644/12825 [9:29:02<35:32:24, 12.57s/it] 21%|██        | 2645/12825 [9:29:15<35:33:18, 12.57s/it] 21%|██        | 2646/12825 [9:29:27<35:33:31, 12.58s/it] 21%|██        | 2647/12825 [9:29:40<35:34:23, 12.58s/it] 21%|██        | 2648/12825 [9:29:53<35:33:57, 12.58s/it] 21%|██        | 2649/12825 [9:30:05<35:34:08, 12.58s/it] 21%|██        | 2650/12825 [9:30:18<35:35:58, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120367.26lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103620.68lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2600] due to args.save_total_limit
 21%|██        | 2651/12825 [9:30:31<35:53:34, 12.70s/it] 21%|██        | 2652/12825 [9:30:43<35:47:32, 12.67s/it] 21%|██        | 2653/12825 [9:30:56<35:42:44, 12.64s/it] 21%|██        | 2654/12825 [9:31:17<42:31:39, 15.05s/it] 21%|██        | 2655/12825 [9:31:29<40:26:13, 14.31s/it] 21%|██        | 2656/12825 [9:31:42<39:00:27, 13.81s/it] 21%|██        | 2657/12825 [9:31:54<37:59:08, 13.45s/it] 21%|██        | 2658/12825 [9:32:07<37:15:57, 13.20s/it] 21%|██        | 2659/12825 [9:32:20<36:44:20, 13.01s/it] 21%|██        | 2660/12825 [9:32:32<36:19:31, 12.86s/it] 21%|██        | 2661/12825 [9:32:45<36:05:32, 12.78s/it] 21%|██        | 2662/12825 [9:32:57<35:55:48, 12.73s/it] 21%|██        | 2663/12825 [9:33:10<35:48:40, 12.69s/it] 21%|██        | 2664/12825 [9:33:22<35:42:36, 12.65s/it] 21%|██        | 2665/12825 [9:33:35<35:38:07, 12.63s/it] 21%|██        | 2666/12825 [9:33:48<35:34:33, 12.61s/it] 21%|██        | 2667/12825 [9:34:00<35:38:17, 12.63s/it] 21%|██        | 2668/12825 [9:34:13<35:35:01, 12.61s/it] 21%|██        | 2669/12825 [9:34:25<35:32:46, 12.60s/it] 21%|██        | 2670/12825 [9:34:38<35:30:59, 12.59s/it] 21%|██        | 2671/12825 [9:34:51<35:29:48, 12.59s/it] 21%|██        | 2672/12825 [9:35:03<35:30:14, 12.59s/it] 21%|██        | 2673/12825 [9:35:16<35:30:02, 12.59s/it] 21%|██        | 2674/12825 [9:35:28<35:29:38, 12.59s/it] 21%|██        | 2675/12825 [9:35:41<35:29:27, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120261.42lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103613.76lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2625] due to args.save_total_limit
 21%|██        | 2676/12825 [9:35:54<35:46:17, 12.69s/it] 21%|██        | 2677/12825 [9:36:06<35:41:50, 12.66s/it] 21%|██        | 2678/12825 [9:36:19<35:42:10, 12.67s/it] 21%|██        | 2679/12825 [9:36:32<35:37:37, 12.64s/it] 21%|██        | 2680/12825 [9:36:44<35:33:52, 12.62s/it] 21%|██        | 2681/12825 [9:36:57<35:30:43, 12.60s/it] 21%|██        | 2682/12825 [9:37:09<35:27:55, 12.59s/it] 21%|██        | 2683/12825 [9:37:22<35:29:09, 12.60s/it] 21%|██        | 2684/12825 [9:37:35<35:28:43, 12.59s/it] 21%|██        | 2685/12825 [9:37:47<35:32:25, 12.62s/it] 21%|██        | 2686/12825 [9:38:00<35:29:52, 12.60s/it] 21%|██        | 2687/12825 [9:38:20<42:17:54, 15.02s/it] 21%|██        | 2688/12825 [9:38:33<40:18:44, 14.32s/it] 21%|██        | 2689/12825 [9:38:46<38:50:48, 13.80s/it] 21%|██        | 2690/12825 [9:38:58<37:48:23, 13.43s/it] 21%|██        | 2691/12825 [9:39:11<37:05:30, 13.18s/it] 21%|██        | 2692/12825 [9:39:24<36:37:15, 13.01s/it] 21%|██        | 2693/12825 [9:39:36<36:15:14, 12.88s/it] 21%|██        | 2694/12825 [9:39:49<36:00:13, 12.79s/it] 21%|██        | 2695/12825 [9:40:01<35:50:05, 12.73s/it] 21%|██        | 2696/12825 [9:40:14<35:48:09, 12.72s/it] 21%|██        | 2697/12825 [9:40:27<35:47:47, 12.72s/it] 21%|██        | 2698/12825 [9:40:39<35:41:54, 12.69s/it] 21%|██        | 2699/12825 [9:40:52<35:37:46, 12.67s/it] 21%|██        | 2700/12825 [9:41:05<35:33:10, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120197.09lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103478.65lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2650] due to args.save_total_limit
 21%|██        | 2701/12825 [9:41:18<35:50:29, 12.74s/it] 21%|██        | 2702/12825 [9:41:30<35:44:19, 12.71s/it] 21%|██        | 2703/12825 [9:41:43<35:39:21, 12.68s/it] 21%|██        | 2704/12825 [9:41:55<35:34:02, 12.65s/it] 21%|██        | 2705/12825 [9:42:08<35:33:01, 12.65s/it] 21%|██        | 2706/12825 [9:42:21<35:31:34, 12.64s/it] 21%|██        | 2707/12825 [9:42:33<35:30:09, 12.63s/it] 21%|██        | 2708/12825 [9:42:46<35:29:03, 12.63s/it] 21%|██        | 2709/12825 [9:42:58<35:28:45, 12.63s/it] 21%|██        | 2710/12825 [9:43:11<35:27:15, 12.62s/it] 21%|██        | 2711/12825 [9:43:24<35:25:33, 12.61s/it] 21%|██        | 2712/12825 [9:43:36<35:26:16, 12.62s/it] 21%|██        | 2713/12825 [9:43:49<35:25:21, 12.61s/it] 21%|██        | 2714/12825 [9:44:02<35:26:11, 12.62s/it] 21%|██        | 2715/12825 [9:44:14<35:28:34, 12.63s/it] 21%|██        | 2716/12825 [9:44:27<35:27:40, 12.63s/it] 21%|██        | 2717/12825 [9:44:39<35:25:15, 12.62s/it] 21%|██        | 2718/12825 [9:44:52<35:24:47, 12.61s/it] 21%|██        | 2719/12825 [9:45:13<42:18:34, 15.07s/it] 21%|██        | 2720/12825 [9:45:25<40:13:05, 14.33s/it] 21%|██        | 2721/12825 [9:45:38<38:44:56, 13.81s/it] 21%|██        | 2722/12825 [9:45:51<37:43:04, 13.44s/it] 21%|██        | 2723/12825 [9:46:03<36:58:50, 13.18s/it] 21%|██        | 2724/12825 [9:46:16<36:29:29, 13.01s/it] 21%|██        | 2725/12825 [9:46:28<36:07:57, 12.88s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120220.82lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103511.47lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2725
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2725/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2725/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2675] due to args.save_total_limit
 21%|██▏       | 2726/12825 [9:46:41<36:11:21, 12.90s/it] 21%|██▏       | 2727/12825 [9:46:54<35:54:53, 12.80s/it] 21%|██▏       | 2728/12825 [9:47:06<35:45:40, 12.75s/it] 21%|██▏       | 2729/12825 [9:47:19<35:40:16, 12.72s/it] 21%|██▏       | 2730/12825 [9:47:32<35:32:58, 12.68s/it] 21%|██▏       | 2731/12825 [9:47:44<35:28:50, 12.65s/it] 21%|██▏       | 2732/12825 [9:47:57<35:30:45, 12.67s/it] 21%|██▏       | 2733/12825 [9:48:10<35:27:28, 12.65s/it] 21%|██▏       | 2734/12825 [9:48:22<35:25:09, 12.64s/it] 21%|██▏       | 2735/12825 [9:48:35<35:28:38, 12.66s/it] 21%|██▏       | 2736/12825 [9:48:47<35:23:37, 12.63s/it] 21%|██▏       | 2737/12825 [9:49:00<35:21:04, 12.62s/it] 21%|██▏       | 2738/12825 [9:49:13<35:19:07, 12.61s/it] 21%|██▏       | 2739/12825 [9:49:25<35:17:37, 12.60s/it] 21%|██▏       | 2740/12825 [9:49:38<35:16:34, 12.59s/it] 21%|██▏       | 2741/12825 [9:49:50<35:14:49, 12.58s/it] 21%|██▏       | 2742/12825 [9:50:03<35:17:31, 12.60s/it] 21%|██▏       | 2743/12825 [9:50:16<35:15:57, 12.59s/it] 21%|██▏       | 2744/12825 [9:50:28<35:14:56, 12.59s/it] 21%|██▏       | 2745/12825 [9:50:41<35:16:13, 12.60s/it] 21%|██▏       | 2746/12825 [9:50:53<35:17:31, 12.61s/it] 21%|██▏       | 2747/12825 [9:51:06<35:16:25, 12.60s/it] 21%|██▏       | 2748/12825 [9:51:19<35:16:26, 12.60s/it] 21%|██▏       | 2749/12825 [9:51:31<35:14:56, 12.59s/it] 21%|██▏       | 2750/12825 [9:51:44<35:15:39, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120220.95lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103457.76lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2750
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2750/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2750/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2725] due to args.save_total_limit
 21%|██▏       | 2751/12825 [9:52:05<42:17:48, 15.12s/it] 21%|██▏       | 2752/12825 [9:52:17<40:13:09, 14.37s/it] 21%|██▏       | 2753/12825 [9:52:30<38:43:29, 13.84s/it] 21%|██▏       | 2754/12825 [9:52:43<37:40:53, 13.47s/it] 21%|██▏       | 2755/12825 [9:52:55<36:55:53, 13.20s/it] 21%|██▏       | 2756/12825 [9:53:08<36:24:24, 13.02s/it] 21%|██▏       | 2757/12825 [9:53:20<36:02:04, 12.88s/it] 22%|██▏       | 2758/12825 [9:53:33<35:46:08, 12.79s/it] 22%|██▏       | 2759/12825 [9:53:46<35:37:13, 12.74s/it] 22%|██▏       | 2760/12825 [9:53:58<35:29:22, 12.69s/it] 22%|██▏       | 2761/12825 [9:54:11<35:23:54, 12.66s/it] 22%|██▏       | 2762/12825 [9:54:23<35:20:08, 12.64s/it] 22%|██▏       | 2763/12825 [9:54:36<35:17:09, 12.62s/it] 22%|██▏       | 2764/12825 [9:54:48<35:13:24, 12.60s/it] 22%|██▏       | 2765/12825 [9:55:01<35:10:57, 12.59s/it] 22%|██▏       | 2766/12825 [9:55:14<35:11:20, 12.59s/it] 22%|██▏       | 2767/12825 [9:55:26<35:09:40, 12.59s/it] 22%|██▏       | 2768/12825 [9:55:39<35:09:35, 12.59s/it] 22%|██▏       | 2769/12825 [9:55:51<35:09:50, 12.59s/it] 22%|██▏       | 2770/12825 [9:56:04<35:10:43, 12.60s/it] 22%|██▏       | 2771/12825 [9:56:17<35:11:17, 12.60s/it] 22%|██▏       | 2772/12825 [9:56:29<35:11:46, 12.60s/it] 22%|██▏       | 2773/12825 [9:56:42<35:11:19, 12.60s/it] 22%|██▏       | 2774/12825 [9:56:54<35:13:05, 12.61s/it] 22%|██▏       | 2775/12825 [9:57:07<35:11:00, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120377.11lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103513.84lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2775
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2775/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2775/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2700] due to args.save_total_limit
 22%|██▏       | 2776/12825 [9:57:20<35:28:44, 12.71s/it] 22%|██▏       | 2777/12825 [9:57:33<35:23:58, 12.68s/it] 22%|██▏       | 2778/12825 [9:57:45<35:20:07, 12.66s/it] 22%|██▏       | 2779/12825 [9:57:58<35:14:40, 12.63s/it] 22%|██▏       | 2780/12825 [9:58:10<35:12:38, 12.62s/it] 22%|██▏       | 2781/12825 [9:58:23<35:13:37, 12.63s/it] 22%|██▏       | 2782/12825 [9:58:36<35:12:48, 12.62s/it] 22%|██▏       | 2783/12825 [9:58:56<41:38:43, 14.93s/it] 22%|██▏       | 2784/12825 [9:59:09<39:40:44, 14.23s/it] 22%|██▏       | 2785/12825 [9:59:21<38:18:37, 13.74s/it] 22%|██▏       | 2786/12825 [9:59:34<37:20:05, 13.39s/it] 22%|██▏       | 2787/12825 [9:59:46<36:38:45, 13.14s/it] 22%|██▏       | 2788/12825 [9:59:59<36:11:55, 12.98s/it] 22%|██▏       | 2789/12825 [10:00:11<35:52:00, 12.87s/it] 22%|██▏       | 2790/12825 [10:00:24<35:38:26, 12.79s/it] 22%|██▏       | 2791/12825 [10:00:37<35:28:50, 12.73s/it] 22%|██▏       | 2792/12825 [10:00:49<35:21:57, 12.69s/it] 22%|██▏       | 2793/12825 [10:01:02<35:16:49, 12.66s/it] 22%|██▏       | 2794/12825 [10:01:14<35:12:55, 12.64s/it] 22%|██▏       | 2795/12825 [10:01:27<35:16:25, 12.66s/it] 22%|██▏       | 2796/12825 [10:01:40<35:12:55, 12.64s/it] 22%|██▏       | 2797/12825 [10:01:52<35:11:25, 12.63s/it] 22%|██▏       | 2798/12825 [10:02:05<35:10:08, 12.63s/it] 22%|██▏       | 2799/12825 [10:02:18<35:09:08, 12.62s/it] 22%|██▏       | 2800/12825 [10:02:30<35:09:01, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120281.73lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103542.14lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2800
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2800/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2800/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2750] due to args.save_total_limit
 22%|██▏       | 2801/12825 [10:02:43<35:24:01, 12.71s/it] 22%|██▏       | 2802/12825 [10:02:56<35:18:05, 12.68s/it] 22%|██▏       | 2803/12825 [10:03:08<35:14:45, 12.66s/it] 22%|██▏       | 2804/12825 [10:03:21<35:11:30, 12.64s/it] 22%|██▏       | 2805/12825 [10:03:34<35:12:17, 12.65s/it] 22%|██▏       | 2806/12825 [10:03:46<35:10:03, 12.64s/it] 22%|██▏       | 2807/12825 [10:03:59<35:08:36, 12.63s/it] 22%|██▏       | 2808/12825 [10:04:11<35:07:51, 12.63s/it] 22%|██▏       | 2809/12825 [10:04:24<35:08:12, 12.63s/it] 22%|██▏       | 2810/12825 [10:04:37<35:07:13, 12.62s/it] 22%|██▏       | 2811/12825 [10:04:49<35:07:33, 12.63s/it] 22%|██▏       | 2812/12825 [10:05:02<35:12:39, 12.66s/it] 22%|██▏       | 2813/12825 [10:05:15<35:15:30, 12.68s/it] 22%|██▏       | 2814/12825 [10:05:27<35:12:18, 12.66s/it] 22%|██▏       | 2815/12825 [10:05:40<35:08:14, 12.64s/it] 22%|██▏       | 2816/12825 [10:06:01<41:57:08, 15.09s/it] 22%|██▏       | 2817/12825 [10:06:13<39:50:36, 14.33s/it] 22%|██▏       | 2818/12825 [10:06:26<38:21:00, 13.80s/it] 22%|██▏       | 2819/12825 [10:06:38<37:20:38, 13.44s/it] 22%|██▏       | 2820/12825 [10:06:51<36:37:49, 13.18s/it] 22%|██▏       | 2821/12825 [10:07:04<36:07:15, 13.00s/it] 22%|██▏       | 2822/12825 [10:07:16<35:44:05, 12.86s/it] 22%|██▏       | 2823/12825 [10:07:29<35:31:10, 12.78s/it] 22%|██▏       | 2824/12825 [10:07:41<35:21:44, 12.73s/it] 22%|██▏       | 2825/12825 [10:07:54<35:13:28, 12.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120242.39lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103514.03lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2825
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2825/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2825/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2775] due to args.save_total_limit
 22%|██▏       | 2826/12825 [10:08:07<35:24:56, 12.75s/it] 22%|██▏       | 2827/12825 [10:08:19<35:17:11, 12.71s/it] 22%|██▏       | 2828/12825 [10:08:32<35:15:14, 12.70s/it] 22%|██▏       | 2829/12825 [10:08:45<35:10:37, 12.67s/it] 22%|██▏       | 2830/12825 [10:08:57<35:07:07, 12.65s/it] 22%|██▏       | 2831/12825 [10:09:10<35:06:02, 12.64s/it] 22%|██▏       | 2832/12825 [10:09:23<35:02:59, 12.63s/it] 22%|██▏       | 2833/12825 [10:09:35<35:00:37, 12.61s/it] 22%|██▏       | 2834/12825 [10:09:48<34:59:16, 12.61s/it] 22%|██▏       | 2835/12825 [10:10:00<34:57:42, 12.60s/it] 22%|██▏       | 2836/12825 [10:10:13<34:55:43, 12.59s/it] 22%|██▏       | 2837/12825 [10:10:25<34:56:07, 12.59s/it] 22%|██▏       | 2838/12825 [10:10:38<34:55:57, 12.59s/it] 22%|██▏       | 2839/12825 [10:10:51<34:54:25, 12.58s/it] 22%|██▏       | 2840/12825 [10:11:03<34:55:07, 12.59s/it] 22%|██▏       | 2841/12825 [10:11:16<34:56:13, 12.60s/it] 22%|██▏       | 2842/12825 [10:11:28<34:55:12, 12.59s/it] 22%|██▏       | 2843/12825 [10:11:41<34:53:46, 12.59s/it] 22%|██▏       | 2844/12825 [10:11:54<34:54:32, 12.59s/it] 22%|██▏       | 2845/12825 [10:12:06<35:00:07, 12.63s/it] 22%|██▏       | 2846/12825 [10:12:19<35:04:16, 12.65s/it] 22%|██▏       | 2847/12825 [10:12:32<35:01:30, 12.64s/it] 22%|██▏       | 2848/12825 [10:12:52<41:42:21, 15.05s/it] 22%|██▏       | 2849/12825 [10:13:05<39:39:08, 14.31s/it] 22%|██▏       | 2850/12825 [10:13:17<38:12:35, 13.79s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120212.78lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103592.33lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2850
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2850/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2850/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2800] due to args.save_total_limit
 22%|██▏       | 2851/12825 [10:13:30<37:29:11, 13.53s/it] 22%|██▏       | 2852/12825 [10:13:43<36:41:36, 13.25s/it] 22%|██▏       | 2853/12825 [10:13:56<36:07:56, 13.04s/it] 22%|██▏       | 2854/12825 [10:14:08<35:44:04, 12.90s/it] 22%|██▏       | 2855/12825 [10:14:21<35:33:39, 12.84s/it] 22%|██▏       | 2856/12825 [10:14:33<35:21:11, 12.77s/it] 22%|██▏       | 2857/12825 [10:14:46<35:12:35, 12.72s/it] 22%|██▏       | 2858/12825 [10:14:59<35:06:55, 12.68s/it] 22%|██▏       | 2859/12825 [10:15:11<35:02:48, 12.66s/it] 22%|██▏       | 2860/12825 [10:15:24<34:59:13, 12.64s/it] 22%|██▏       | 2861/12825 [10:15:36<34:54:59, 12.62s/it] 22%|██▏       | 2862/12825 [10:15:49<34:52:41, 12.60s/it] 22%|██▏       | 2863/12825 [10:16:02<34:51:23, 12.60s/it] 22%|██▏       | 2864/12825 [10:16:14<34:49:07, 12.58s/it] 22%|██▏       | 2865/12825 [10:16:27<34:48:21, 12.58s/it] 22%|██▏       | 2866/12825 [10:16:39<34:47:48, 12.58s/it] 22%|██▏       | 2867/12825 [10:16:52<34:46:51, 12.57s/it] 22%|██▏       | 2868/12825 [10:17:05<34:56:45, 12.63s/it] 22%|██▏       | 2869/12825 [10:17:17<34:53:53, 12.62s/it] 22%|██▏       | 2870/12825 [10:17:30<34:52:50, 12.61s/it] 22%|██▏       | 2871/12825 [10:17:42<34:51:06, 12.60s/it] 22%|██▏       | 2872/12825 [10:17:55<34:50:02, 12.60s/it] 22%|██▏       | 2873/12825 [10:18:08<34:48:17, 12.59s/it] 22%|██▏       | 2874/12825 [10:18:20<34:48:49, 12.59s/it] 22%|██▏       | 2875/12825 [10:18:33<34:47:22, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120211.76lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103487.54lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2875
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2875/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2875/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2825] due to args.save_total_limit
 22%|██▏       | 2876/12825 [10:18:46<35:04:32, 12.69s/it] 22%|██▏       | 2877/12825 [10:18:58<34:58:42, 12.66s/it] 22%|██▏       | 2878/12825 [10:19:11<34:55:08, 12.64s/it] 22%|██▏       | 2879/12825 [10:19:23<34:52:29, 12.62s/it] 22%|██▏       | 2880/12825 [10:19:36<34:48:38, 12.60s/it] 22%|██▏       | 2881/12825 [10:19:57<41:39:07, 15.08s/it] 22%|██▏       | 2882/12825 [10:20:09<39:35:00, 14.33s/it] 22%|██▏       | 2883/12825 [10:20:22<38:08:43, 13.81s/it] 22%|██▏       | 2884/12825 [10:20:35<37:06:37, 13.44s/it] 22%|██▏       | 2885/12825 [10:20:47<36:23:06, 13.18s/it] 23%|██▎       | 2886/12825 [10:21:00<35:51:30, 12.99s/it] 23%|██▎       | 2887/12825 [10:21:12<35:31:16, 12.87s/it] 23%|██▎       | 2888/12825 [10:21:25<35:17:57, 12.79s/it] 23%|██▎       | 2889/12825 [10:21:37<35:07:37, 12.73s/it] 23%|██▎       | 2890/12825 [10:21:50<34:59:04, 12.68s/it] 23%|██▎       | 2891/12825 [10:22:03<34:55:47, 12.66s/it] 23%|██▎       | 2892/12825 [10:22:15<34:52:01, 12.64s/it] 23%|██▎       | 2893/12825 [10:22:28<34:50:45, 12.63s/it] 23%|██▎       | 2894/12825 [10:22:40<34:47:57, 12.61s/it] 23%|██▎       | 2895/12825 [10:22:53<34:46:53, 12.61s/it] 23%|██▎       | 2896/12825 [10:23:06<34:45:21, 12.60s/it] 23%|██▎       | 2897/12825 [10:23:18<34:46:10, 12.61s/it] 23%|██▎       | 2898/12825 [10:23:31<34:45:19, 12.60s/it] 23%|██▎       | 2899/12825 [10:23:43<34:44:46, 12.60s/it] 23%|██▎       | 2900/12825 [10:23:56<34:46:01, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120210.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103500.59lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2900
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2900/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2900/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2875] due to args.save_total_limit
 23%|██▎       | 2901/12825 [10:24:09<35:01:29, 12.71s/it] 23%|██▎       | 2902/12825 [10:24:22<34:56:40, 12.68s/it] 23%|██▎       | 2903/12825 [10:24:34<34:53:31, 12.66s/it] 23%|██▎       | 2904/12825 [10:24:47<34:50:46, 12.64s/it] 23%|██▎       | 2905/12825 [10:24:59<34:48:21, 12.63s/it] 23%|██▎       | 2906/12825 [10:25:12<34:46:19, 12.62s/it] 23%|██▎       | 2907/12825 [10:25:25<34:45:22, 12.62s/it] 23%|██▎       | 2908/12825 [10:25:37<34:43:53, 12.61s/it] 23%|██▎       | 2909/12825 [10:25:50<34:43:52, 12.61s/it] 23%|██▎       | 2910/12825 [10:26:02<34:42:29, 12.60s/it] 23%|██▎       | 2911/12825 [10:26:15<34:41:03, 12.59s/it] 23%|██▎       | 2912/12825 [10:26:28<34:40:55, 12.60s/it] 23%|██▎       | 2913/12825 [10:26:48<41:21:23, 15.02s/it] 23%|██▎       | 2914/12825 [10:27:01<39:20:06, 14.29s/it] 23%|██▎       | 2915/12825 [10:27:13<37:57:00, 13.79s/it] 23%|██▎       | 2916/12825 [10:27:26<36:57:55, 13.43s/it] 23%|██▎       | 2917/12825 [10:27:39<36:18:01, 13.19s/it] 23%|██▎       | 2918/12825 [10:27:51<35:50:31, 13.02s/it] 23%|██▎       | 2919/12825 [10:28:04<35:30:30, 12.90s/it] 23%|██▎       | 2920/12825 [10:28:17<35:15:16, 12.81s/it] 23%|██▎       | 2921/12825 [10:28:29<35:04:47, 12.75s/it] 23%|██▎       | 2922/12825 [10:28:42<34:57:13, 12.71s/it] 23%|██▎       | 2923/12825 [10:28:54<34:50:27, 12.67s/it] 23%|██▎       | 2924/12825 [10:29:07<34:48:32, 12.66s/it] 23%|██▎       | 2925/12825 [10:29:19<34:44:13, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120302.55lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103580.87lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2925
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2925/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2925/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2900] due to args.save_total_limit
 23%|██▎       | 2926/12825 [10:29:32<34:58:51, 12.72s/it] 23%|██▎       | 2927/12825 [10:29:45<34:52:32, 12.68s/it] 23%|██▎       | 2928/12825 [10:29:58<34:47:58, 12.66s/it] 23%|██▎       | 2929/12825 [10:30:10<34:45:11, 12.64s/it] 23%|██▎       | 2930/12825 [10:30:23<34:46:26, 12.65s/it] 23%|██▎       | 2931/12825 [10:30:36<34:43:49, 12.64s/it] 23%|██▎       | 2932/12825 [10:30:48<34:45:40, 12.65s/it] 23%|██▎       | 2933/12825 [10:31:01<34:47:56, 12.66s/it] 23%|██▎       | 2934/12825 [10:31:13<34:44:41, 12.65s/it] 23%|██▎       | 2935/12825 [10:31:26<34:42:47, 12.64s/it] 23%|██▎       | 2936/12825 [10:31:39<34:40:27, 12.62s/it] 23%|██▎       | 2937/12825 [10:31:51<34:39:44, 12.62s/it] 23%|██▎       | 2938/12825 [10:32:04<34:36:54, 12.60s/it] 23%|██▎       | 2939/12825 [10:32:16<34:34:29, 12.59s/it] 23%|██▎       | 2940/12825 [10:32:29<34:34:11, 12.59s/it] 23%|██▎       | 2941/12825 [10:32:42<34:34:22, 12.59s/it] 23%|██▎       | 2942/12825 [10:32:54<34:33:31, 12.59s/it] 23%|██▎       | 2943/12825 [10:33:07<34:33:29, 12.59s/it] 23%|██▎       | 2944/12825 [10:33:19<34:32:50, 12.59s/it] 23%|██▎       | 2945/12825 [10:33:39<40:37:21, 14.80s/it] 23%|██▎       | 2946/12825 [10:33:52<38:47:24, 14.14s/it] 23%|██▎       | 2947/12825 [10:34:05<37:31:15, 13.67s/it] 23%|██▎       | 2948/12825 [10:34:17<36:37:57, 13.35s/it] 23%|██▎       | 2949/12825 [10:34:30<35:59:17, 13.12s/it] 23%|██▎       | 2950/12825 [10:34:42<35:33:41, 12.96s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120337.20lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103600.48lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2950
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2950/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2950/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2925] due to args.save_total_limit
 23%|██▎       | 2951/12825 [10:34:55<35:30:53, 12.95s/it] 23%|██▎       | 2952/12825 [10:35:08<35:12:20, 12.84s/it] 23%|██▎       | 2953/12825 [10:35:20<34:59:36, 12.76s/it] 23%|██▎       | 2954/12825 [10:35:33<34:51:29, 12.71s/it] 23%|██▎       | 2955/12825 [10:35:46<34:45:12, 12.68s/it] 23%|██▎       | 2956/12825 [10:35:58<34:39:43, 12.64s/it] 23%|██▎       | 2957/12825 [10:36:11<34:37:08, 12.63s/it] 23%|██▎       | 2958/12825 [10:36:23<34:36:17, 12.63s/it] 23%|██▎       | 2959/12825 [10:36:36<34:37:03, 12.63s/it] 23%|██▎       | 2960/12825 [10:36:49<34:35:22, 12.62s/it] 23%|██▎       | 2961/12825 [10:37:01<34:33:18, 12.61s/it] 23%|██▎       | 2962/12825 [10:37:14<34:31:11, 12.60s/it] 23%|██▎       | 2963/12825 [10:37:26<34:33:51, 12.62s/it] 23%|██▎       | 2964/12825 [10:37:39<34:31:17, 12.60s/it] 23%|██▎       | 2965/12825 [10:37:52<34:29:27, 12.59s/it] 23%|██▎       | 2966/12825 [10:38:04<34:29:41, 12.60s/it] 23%|██▎       | 2967/12825 [10:38:17<34:27:54, 12.59s/it] 23%|██▎       | 2968/12825 [10:38:29<34:27:29, 12.58s/it] 23%|██▎       | 2969/12825 [10:38:42<34:29:50, 12.60s/it] 23%|██▎       | 2970/12825 [10:38:54<34:28:07, 12.59s/it] 23%|██▎       | 2971/12825 [10:39:07<34:28:37, 12.60s/it] 23%|██▎       | 2972/12825 [10:39:20<34:26:57, 12.59s/it] 23%|██▎       | 2973/12825 [10:39:32<34:31:05, 12.61s/it] 23%|██▎       | 2974/12825 [10:39:45<34:27:45, 12.59s/it] 23%|██▎       | 2975/12825 [10:39:57<34:27:28, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120209.08lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103588.17lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2975
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2975/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2975/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-2975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2950] due to args.save_total_limit
 23%|██▎       | 2976/12825 [10:40:10<34:44:41, 12.70s/it] 23%|██▎       | 2977/12825 [10:40:23<34:39:51, 12.67s/it] 23%|██▎       | 2978/12825 [10:40:44<41:14:51, 15.08s/it] 23%|██▎       | 2979/12825 [10:40:56<39:14:25, 14.35s/it] 23%|██▎       | 2980/12825 [10:41:09<37:48:37, 13.83s/it] 23%|██▎       | 2981/12825 [10:41:22<36:47:30, 13.45s/it] 23%|██▎       | 2982/12825 [10:41:34<36:09:04, 13.22s/it] 23%|██▎       | 2983/12825 [10:41:47<35:37:24, 13.03s/it] 23%|██▎       | 2984/12825 [10:42:00<35:20:13, 12.93s/it] 23%|██▎       | 2985/12825 [10:42:12<35:04:37, 12.83s/it] 23%|██▎       | 2986/12825 [10:42:25<34:52:06, 12.76s/it] 23%|██▎       | 2987/12825 [10:42:37<34:43:52, 12.71s/it] 23%|██▎       | 2988/12825 [10:42:50<34:37:56, 12.67s/it] 23%|██▎       | 2989/12825 [10:43:03<34:35:35, 12.66s/it] 23%|██▎       | 2990/12825 [10:43:15<34:33:41, 12.65s/it] 23%|██▎       | 2991/12825 [10:43:28<34:30:10, 12.63s/it] 23%|██▎       | 2992/12825 [10:43:40<34:27:17, 12.61s/it] 23%|██▎       | 2993/12825 [10:43:53<34:24:34, 12.60s/it] 23%|██▎       | 2994/12825 [10:44:05<34:24:25, 12.60s/it] 23%|██▎       | 2995/12825 [10:44:18<34:24:38, 12.60s/it] 23%|██▎       | 2996/12825 [10:44:31<34:25:31, 12.61s/it] 23%|██▎       | 2997/12825 [10:44:43<34:25:42, 12.61s/it] 23%|██▎       | 2998/12825 [10:44:56<34:23:34, 12.60s/it] 23%|██▎       | 2999/12825 [10:45:09<34:28:03, 12.63s/it] 23%|██▎       | 3000/12825 [10:45:21<34:26:33, 12.62s/it]                                                           23%|██▎       | 3000/12825 [10:45:21<34:26:33, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120338.22lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103601.34lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3000
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3000/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3000/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2975] due to args.save_total_limit
 23%|██▎       | 3001/12825 [10:45:34<34:41:39, 12.71s/it] 23%|██▎       | 3002/12825 [10:45:47<34:34:51, 12.67s/it] 23%|██▎       | 3003/12825 [10:45:59<34:30:00, 12.65s/it] 23%|██▎       | 3004/12825 [10:46:12<34:27:26, 12.63s/it] 23%|██▎       | 3005/12825 [10:46:24<34:24:55, 12.62s/it] 23%|██▎       | 3006/12825 [10:46:37<34:23:54, 12.61s/it] 23%|██▎       | 3007/12825 [10:46:50<34:23:44, 12.61s/it] 23%|██▎       | 3008/12825 [10:47:02<34:23:18, 12.61s/it] 23%|██▎       | 3009/12825 [10:47:15<34:21:14, 12.60s/it] 23%|██▎       | 3010/12825 [10:47:35<40:41:41, 14.93s/it] 23%|██▎       | 3011/12825 [10:47:48<38:46:52, 14.23s/it] 23%|██▎       | 3012/12825 [10:48:00<37:27:07, 13.74s/it] 23%|██▎       | 3013/12825 [10:48:13<36:31:28, 13.40s/it] 24%|██▎       | 3014/12825 [10:48:26<35:51:30, 13.16s/it] 24%|██▎       | 3015/12825 [10:48:38<35:26:54, 13.01s/it] 24%|██▎       | 3016/12825 [10:48:51<35:06:14, 12.88s/it] 24%|██▎       | 3017/12825 [10:49:04<34:55:00, 12.82s/it] 24%|██▎       | 3018/12825 [10:49:16<34:43:51, 12.75s/it] 24%|██▎       | 3019/12825 [10:49:29<34:36:22, 12.70s/it] 24%|██▎       | 3020/12825 [10:49:41<34:31:19, 12.68s/it] 24%|██▎       | 3021/12825 [10:49:54<34:26:56, 12.65s/it] 24%|██▎       | 3022/12825 [10:50:07<34:23:17, 12.63s/it] 24%|██▎       | 3023/12825 [10:50:19<34:19:39, 12.61s/it] 24%|██▎       | 3024/12825 [10:50:32<34:18:22, 12.60s/it] 24%|██▎       | 3025/12825 [10:50:44<34:18:41, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120136.14lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103532.01lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3025
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3025/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3025/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-2850] due to args.save_total_limit
 24%|██▎       | 3026/12825 [10:50:57<34:37:42, 12.72s/it] 24%|██▎       | 3027/12825 [10:51:10<34:30:08, 12.68s/it] 24%|██▎       | 3028/12825 [10:51:22<34:26:00, 12.65s/it] 24%|██▎       | 3029/12825 [10:51:35<34:22:39, 12.63s/it] 24%|██▎       | 3030/12825 [10:51:48<34:19:42, 12.62s/it] 24%|██▎       | 3031/12825 [10:52:00<34:18:53, 12.61s/it] 24%|██▎       | 3032/12825 [10:52:13<34:16:40, 12.60s/it] 24%|██▎       | 3033/12825 [10:52:25<34:16:06, 12.60s/it] 24%|██▎       | 3034/12825 [10:52:38<34:16:12, 12.60s/it] 24%|██▎       | 3035/12825 [10:52:51<34:15:50, 12.60s/it] 24%|██▎       | 3036/12825 [10:53:03<34:14:38, 12.59s/it] 24%|██▎       | 3037/12825 [10:53:16<34:14:51, 12.60s/it] 24%|██▎       | 3038/12825 [10:53:28<34:14:47, 12.60s/it] 24%|██▎       | 3039/12825 [10:53:41<34:14:43, 12.60s/it] 24%|██▎       | 3040/12825 [10:53:54<34:13:13, 12.59s/it] 24%|██▎       | 3041/12825 [10:54:06<34:19:03, 12.63s/it] 24%|██▎       | 3042/12825 [10:54:26<40:31:30, 14.91s/it] 24%|██▎       | 3043/12825 [10:54:39<38:37:09, 14.21s/it] 24%|██▎       | 3044/12825 [10:54:52<37:18:26, 13.73s/it] 24%|██▎       | 3045/12825 [10:55:04<36:23:24, 13.40s/it] 24%|██▍       | 3046/12825 [10:55:17<35:46:05, 13.17s/it] 24%|██▍       | 3047/12825 [10:55:29<35:16:52, 12.99s/it] 24%|██▍       | 3048/12825 [10:55:42<34:56:47, 12.87s/it] 24%|██▍       | 3049/12825 [10:55:55<34:42:17, 12.78s/it] 24%|██▍       | 3050/12825 [10:56:07<34:30:38, 12.71s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120168.13lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103430.64lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3050
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3050/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3050/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3000] due to args.save_total_limit
 24%|██▍       | 3051/12825 [10:56:20<34:40:16, 12.77s/it] 24%|██▍       | 3052/12825 [10:56:33<34:30:38, 12.71s/it] 24%|██▍       | 3053/12825 [10:56:45<34:24:49, 12.68s/it] 24%|██▍       | 3054/12825 [10:56:58<34:19:27, 12.65s/it] 24%|██▍       | 3055/12825 [10:57:10<34:15:04, 12.62s/it] 24%|██▍       | 3056/12825 [10:57:23<34:10:47, 12.60s/it] 24%|██▍       | 3057/12825 [10:57:36<34:10:06, 12.59s/it] 24%|██▍       | 3058/12825 [10:57:48<34:12:51, 12.61s/it] 24%|██▍       | 3059/12825 [10:58:01<34:24:01, 12.68s/it] 24%|██▍       | 3060/12825 [10:58:14<34:19:46, 12.66s/it] 24%|██▍       | 3061/12825 [10:58:26<34:17:01, 12.64s/it] 24%|██▍       | 3062/12825 [10:58:39<34:15:25, 12.63s/it] 24%|██▍       | 3063/12825 [10:58:51<34:13:22, 12.62s/it] 24%|██▍       | 3064/12825 [10:59:04<34:11:48, 12.61s/it] 24%|██▍       | 3065/12825 [10:59:17<34:10:07, 12.60s/it] 24%|██▍       | 3066/12825 [10:59:29<34:10:17, 12.61s/it] 24%|██▍       | 3067/12825 [10:59:42<34:09:37, 12.60s/it] 24%|██▍       | 3068/12825 [10:59:54<34:10:18, 12.61s/it] 24%|██▍       | 3069/12825 [11:00:07<34:09:51, 12.61s/it] 24%|██▍       | 3070/12825 [11:00:20<34:07:45, 12.60s/it] 24%|██▍       | 3071/12825 [11:00:32<34:08:02, 12.60s/it] 24%|██▍       | 3072/12825 [11:00:45<34:07:32, 12.60s/it] 24%|██▍       | 3073/12825 [11:00:57<34:06:53, 12.59s/it] 24%|██▍       | 3074/12825 [11:01:18<40:15:50, 14.87s/it] 24%|██▍       | 3075/12825 [11:01:30<38:23:13, 14.17s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120307.67lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103612.14lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3075
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3075/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3075/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3025] due to args.save_total_limit
 24%|██▍       | 3076/12825 [11:01:43<37:21:55, 13.80s/it] 24%|██▍       | 3077/12825 [11:01:51<32:34:25, 12.03s/it] 24%|██▍       | 3078/12825 [11:01:52<23:28:02,  8.67s/it] 24%|██▍       | 3079/12825 [11:02:17<37:10:52, 13.73s/it] 24%|██▍       | 3080/12825 [11:02:30<36:15:23, 13.39s/it] 24%|██▍       | 3081/12825 [11:02:43<35:36:04, 13.15s/it] 24%|██▍       | 3082/12825 [11:02:55<35:10:10, 13.00s/it] 24%|██▍       | 3083/12825 [11:03:08<34:50:51, 12.88s/it] 24%|██▍       | 3084/12825 [11:03:20<34:36:03, 12.79s/it] 24%|██▍       | 3085/12825 [11:03:33<34:26:47, 12.73s/it] 24%|██▍       | 3086/12825 [11:03:46<34:30:27, 12.76s/it] 24%|██▍       | 3087/12825 [11:03:58<34:23:29, 12.71s/it] 24%|██▍       | 3088/12825 [11:04:11<34:20:22, 12.70s/it] 24%|██▍       | 3089/12825 [11:04:24<34:20:52, 12.70s/it] 24%|██▍       | 3090/12825 [11:04:36<34:18:35, 12.69s/it] 24%|██▍       | 3091/12825 [11:04:49<34:16:18, 12.68s/it] 24%|██▍       | 3092/12825 [11:05:02<34:15:29, 12.67s/it] 24%|██▍       | 3093/12825 [11:05:14<34:16:06, 12.68s/it] 24%|██▍       | 3094/12825 [11:05:27<34:14:39, 12.67s/it] 24%|██▍       | 3095/12825 [11:05:40<34:14:36, 12.67s/it] 24%|██▍       | 3096/12825 [11:05:52<34:12:21, 12.66s/it] 24%|██▍       | 3097/12825 [11:06:05<34:10:42, 12.65s/it] 24%|██▍       | 3098/12825 [11:06:18<34:08:26, 12.64s/it] 24%|██▍       | 3099/12825 [11:06:30<34:06:47, 12.63s/it] 24%|██▍       | 3100/12825 [11:06:43<34:08:33, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120271.38lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103553.40lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3050] due to args.save_total_limit
 24%|██▍       | 3101/12825 [11:06:56<34:26:27, 12.75s/it] 24%|██▍       | 3102/12825 [11:07:08<34:21:22, 12.72s/it] 24%|██▍       | 3103/12825 [11:07:21<34:17:15, 12.70s/it] 24%|██▍       | 3104/12825 [11:07:34<34:15:46, 12.69s/it] 24%|██▍       | 3105/12825 [11:07:46<34:11:31, 12.66s/it] 24%|██▍       | 3106/12825 [11:07:59<34:10:34, 12.66s/it] 24%|██▍       | 3107/12825 [11:08:19<40:21:16, 14.95s/it] 24%|██▍       | 3108/12825 [11:08:32<38:26:43, 14.24s/it] 24%|██▍       | 3109/12825 [11:08:45<37:09:06, 13.77s/it] 24%|██▍       | 3110/12825 [11:08:57<36:14:52, 13.43s/it] 24%|██▍       | 3111/12825 [11:09:10<35:40:18, 13.22s/it] 24%|██▍       | 3112/12825 [11:09:23<35:10:48, 13.04s/it] 24%|██▍       | 3113/12825 [11:09:35<34:50:46, 12.92s/it] 24%|██▍       | 3114/12825 [11:09:48<34:39:39, 12.85s/it] 24%|██▍       | 3115/12825 [11:10:01<34:28:34, 12.78s/it] 24%|██▍       | 3116/12825 [11:10:13<34:23:13, 12.75s/it] 24%|██▍       | 3117/12825 [11:10:26<34:18:57, 12.73s/it] 24%|██▍       | 3118/12825 [11:10:39<34:14:43, 12.70s/it] 24%|██▍       | 3119/12825 [11:10:51<34:10:59, 12.68s/it] 24%|██▍       | 3120/12825 [11:11:04<34:06:44, 12.65s/it] 24%|██▍       | 3121/12825 [11:11:16<34:04:47, 12.64s/it] 24%|██▍       | 3122/12825 [11:11:29<34:03:45, 12.64s/it] 24%|██▍       | 3123/12825 [11:11:42<34:03:32, 12.64s/it] 24%|██▍       | 3124/12825 [11:11:54<34:01:11, 12.62s/it] 24%|██▍       | 3125/12825 [11:12:07<34:01:08, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120160.23lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103536.83lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3075] due to args.save_total_limit
 24%|██▍       | 3126/12825 [11:12:20<34:16:59, 12.72s/it] 24%|██▍       | 3127/12825 [11:12:32<34:12:26, 12.70s/it] 24%|██▍       | 3128/12825 [11:12:45<34:07:15, 12.67s/it] 24%|██▍       | 3129/12825 [11:12:58<34:05:19, 12.66s/it] 24%|██▍       | 3130/12825 [11:13:10<34:01:33, 12.63s/it] 24%|██▍       | 3131/12825 [11:13:23<34:03:30, 12.65s/it] 24%|██▍       | 3132/12825 [11:13:36<34:04:07, 12.65s/it] 24%|██▍       | 3133/12825 [11:13:48<34:02:50, 12.65s/it] 24%|██▍       | 3134/12825 [11:14:01<34:00:44, 12.63s/it] 24%|██▍       | 3135/12825 [11:14:13<34:00:26, 12.63s/it] 24%|██▍       | 3136/12825 [11:14:26<33:57:22, 12.62s/it] 24%|██▍       | 3137/12825 [11:14:39<33:56:18, 12.61s/it] 24%|██▍       | 3138/12825 [11:14:51<34:00:28, 12.64s/it] 24%|██▍       | 3139/12825 [11:15:04<33:57:52, 12.62s/it] 24%|██▍       | 3140/12825 [11:15:24<40:02:32, 14.88s/it] 24%|██▍       | 3141/12825 [11:15:37<38:11:24, 14.20s/it] 24%|██▍       | 3142/12825 [11:15:49<36:51:49, 13.71s/it] 25%|██▍       | 3143/12825 [11:16:02<35:58:20, 13.38s/it] 25%|██▍       | 3144/12825 [11:16:14<35:19:12, 13.13s/it] 25%|██▍       | 3145/12825 [11:16:27<34:52:30, 12.97s/it] 25%|██▍       | 3146/12825 [11:16:40<34:35:06, 12.86s/it] 25%|██▍       | 3147/12825 [11:16:52<34:21:52, 12.78s/it] 25%|██▍       | 3148/12825 [11:17:05<34:16:10, 12.75s/it] 25%|██▍       | 3149/12825 [11:17:18<34:10:15, 12.71s/it] 25%|██▍       | 3150/12825 [11:17:30<34:06:14, 12.69s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120260.01lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103540.62lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3100] due to args.save_total_limit
 25%|██▍       | 3151/12825 [11:17:43<34:20:41, 12.78s/it] 25%|██▍       | 3152/12825 [11:17:56<34:13:00, 12.73s/it] 25%|██▍       | 3153/12825 [11:18:08<34:10:47, 12.72s/it] 25%|██▍       | 3154/12825 [11:18:21<34:05:47, 12.69s/it] 25%|██▍       | 3155/12825 [11:18:34<34:09:36, 12.72s/it] 25%|██▍       | 3156/12825 [11:18:46<34:03:05, 12.68s/it] 25%|██▍       | 3157/12825 [11:18:59<34:00:08, 12.66s/it] 25%|██▍       | 3158/12825 [11:19:12<33:57:13, 12.64s/it] 25%|██▍       | 3159/12825 [11:19:24<33:56:30, 12.64s/it] 25%|██▍       | 3160/12825 [11:19:37<33:54:42, 12.63s/it] 25%|██▍       | 3161/12825 [11:19:50<33:53:55, 12.63s/it] 25%|██▍       | 3162/12825 [11:20:02<33:52:42, 12.62s/it] 25%|██▍       | 3163/12825 [11:20:15<33:52:48, 12.62s/it] 25%|██▍       | 3164/12825 [11:20:27<33:53:01, 12.63s/it] 25%|██▍       | 3165/12825 [11:20:40<33:53:07, 12.63s/it] 25%|██▍       | 3166/12825 [11:20:53<33:52:50, 12.63s/it] 25%|██▍       | 3167/12825 [11:21:05<33:51:54, 12.62s/it] 25%|██▍       | 3168/12825 [11:21:18<33:51:34, 12.62s/it] 25%|██▍       | 3169/12825 [11:21:31<33:52:15, 12.63s/it] 25%|██▍       | 3170/12825 [11:21:43<33:53:43, 12.64s/it] 25%|██▍       | 3171/12825 [11:21:56<33:53:21, 12.64s/it] 25%|██▍       | 3172/12825 [11:22:16<40:14:27, 15.01s/it] 25%|██▍       | 3173/12825 [11:22:29<38:18:13, 14.29s/it] 25%|██▍       | 3174/12825 [11:22:42<36:57:41, 13.79s/it] 25%|██▍       | 3175/12825 [11:22:54<36:00:46, 13.43s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120271.51lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103564.96lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3125] due to args.save_total_limit
 25%|██▍       | 3176/12825 [11:23:07<35:39:04, 13.30s/it] 25%|██▍       | 3177/12825 [11:23:20<35:04:40, 13.09s/it] 25%|██▍       | 3178/12825 [11:23:32<34:42:24, 12.95s/it] 25%|██▍       | 3179/12825 [11:23:45<34:24:51, 12.84s/it] 25%|██▍       | 3180/12825 [11:23:58<34:11:28, 12.76s/it] 25%|██▍       | 3181/12825 [11:24:10<34:03:53, 12.72s/it] 25%|██▍       | 3182/12825 [11:24:23<33:58:16, 12.68s/it] 25%|██▍       | 3183/12825 [11:24:35<33:54:46, 12.66s/it] 25%|██▍       | 3184/12825 [11:24:48<33:51:16, 12.64s/it] 25%|██▍       | 3185/12825 [11:25:01<33:45:41, 12.61s/it] 25%|██▍       | 3186/12825 [11:25:13<33:47:34, 12.62s/it] 25%|██▍       | 3187/12825 [11:25:26<33:46:55, 12.62s/it] 25%|██▍       | 3188/12825 [11:25:38<33:46:46, 12.62s/it] 25%|██▍       | 3189/12825 [11:25:51<33:47:11, 12.62s/it] 25%|██▍       | 3190/12825 [11:26:04<33:46:24, 12.62s/it] 25%|██▍       | 3191/12825 [11:26:16<33:47:04, 12.62s/it] 25%|██▍       | 3192/12825 [11:26:29<33:46:49, 12.62s/it] 25%|██▍       | 3193/12825 [11:26:42<33:47:07, 12.63s/it] 25%|██▍       | 3194/12825 [11:26:54<33:46:31, 12.63s/it] 25%|██▍       | 3195/12825 [11:27:07<33:45:42, 12.62s/it] 25%|██▍       | 3196/12825 [11:27:19<33:44:23, 12.61s/it] 25%|██▍       | 3197/12825 [11:27:32<33:42:12, 12.60s/it] 25%|██▍       | 3198/12825 [11:27:45<33:43:16, 12.61s/it] 25%|██▍       | 3199/12825 [11:27:57<33:43:22, 12.61s/it] 25%|██▍       | 3200/12825 [11:28:10<33:41:49, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120216.35lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103514.78lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3150] due to args.save_total_limit
 25%|██▍       | 3201/12825 [11:28:23<33:57:45, 12.70s/it] 25%|██▍       | 3202/12825 [11:28:35<33:53:47, 12.68s/it] 25%|██▍       | 3203/12825 [11:28:48<33:49:18, 12.65s/it] 25%|██▍       | 3204/12825 [11:29:08<40:06:33, 15.01s/it] 25%|██▍       | 3205/12825 [11:29:21<38:09:46, 14.28s/it] 25%|██▍       | 3206/12825 [11:29:34<36:49:47, 13.78s/it] 25%|██▌       | 3207/12825 [11:29:46<35:54:38, 13.44s/it] 25%|██▌       | 3208/12825 [11:29:59<35:14:20, 13.19s/it] 25%|██▌       | 3209/12825 [11:30:12<34:46:10, 13.02s/it] 25%|██▌       | 3210/12825 [11:30:24<34:26:03, 12.89s/it] 25%|██▌       | 3211/12825 [11:30:37<34:13:05, 12.81s/it] 25%|██▌       | 3212/12825 [11:30:49<34:02:58, 12.75s/it] 25%|██▌       | 3213/12825 [11:31:02<33:55:58, 12.71s/it] 25%|██▌       | 3214/12825 [11:31:15<33:49:51, 12.67s/it] 25%|██▌       | 3215/12825 [11:31:27<33:49:05, 12.67s/it] 25%|██▌       | 3216/12825 [11:31:40<33:44:31, 12.64s/it] 25%|██▌       | 3217/12825 [11:31:52<33:44:23, 12.64s/it] 25%|██▌       | 3218/12825 [11:32:05<33:42:29, 12.63s/it] 25%|██▌       | 3219/12825 [11:32:18<33:40:04, 12.62s/it] 25%|██▌       | 3220/12825 [11:32:30<33:39:24, 12.61s/it] 25%|██▌       | 3221/12825 [11:32:43<33:39:53, 12.62s/it] 25%|██▌       | 3222/12825 [11:32:56<33:43:40, 12.64s/it] 25%|██▌       | 3223/12825 [11:33:08<33:42:37, 12.64s/it] 25%|██▌       | 3224/12825 [11:33:21<33:39:32, 12.62s/it] 25%|██▌       | 3225/12825 [11:33:34<34:03:09, 12.77s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 117646.79lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101586.33lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3200] due to args.save_total_limit
 25%|██▌       | 3226/12825 [11:33:47<34:11:40, 12.82s/it] 25%|██▌       | 3227/12825 [11:33:59<34:00:22, 12.76s/it] 25%|██▌       | 3228/12825 [11:34:12<33:55:38, 12.73s/it] 25%|██▌       | 3229/12825 [11:34:25<33:48:16, 12.68s/it] 25%|██▌       | 3230/12825 [11:34:37<33:48:45, 12.69s/it] 25%|██▌       | 3231/12825 [11:34:50<33:43:44, 12.66s/it] 25%|██▌       | 3232/12825 [11:35:03<33:41:15, 12.64s/it] 25%|██▌       | 3233/12825 [11:35:15<33:39:17, 12.63s/it] 25%|██▌       | 3234/12825 [11:35:28<33:39:17, 12.63s/it] 25%|██▌       | 3235/12825 [11:35:40<33:36:29, 12.62s/it] 25%|██▌       | 3236/12825 [11:35:53<33:35:24, 12.61s/it] 25%|██▌       | 3237/12825 [11:36:13<39:34:11, 14.86s/it] 25%|██▌       | 3238/12825 [11:36:26<37:45:43, 14.18s/it] 25%|██▌       | 3239/12825 [11:36:38<36:35:59, 13.74s/it] 25%|██▌       | 3240/12825 [11:36:51<35:41:33, 13.41s/it] 25%|██▌       | 3241/12825 [11:37:04<35:04:16, 13.17s/it] 25%|██▌       | 3242/12825 [11:37:16<34:36:44, 13.00s/it] 25%|██▌       | 3243/12825 [11:37:29<34:18:15, 12.89s/it] 25%|██▌       | 3244/12825 [11:37:42<34:05:39, 12.81s/it] 25%|██▌       | 3245/12825 [11:37:54<33:56:56, 12.76s/it] 25%|██▌       | 3246/12825 [11:38:07<33:50:50, 12.72s/it] 25%|██▌       | 3247/12825 [11:38:19<33:44:36, 12.68s/it] 25%|██▌       | 3248/12825 [11:38:32<33:40:49, 12.66s/it] 25%|██▌       | 3249/12825 [11:38:45<33:38:36, 12.65s/it] 25%|██▌       | 3250/12825 [11:38:57<33:36:28, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120152.45lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103551.89lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3225] due to args.save_total_limit
 25%|██▌       | 3251/12825 [11:39:10<33:48:52, 12.71s/it] 25%|██▌       | 3252/12825 [11:39:23<33:41:58, 12.67s/it] 25%|██▌       | 3253/12825 [11:39:35<33:42:05, 12.68s/it] 25%|██▌       | 3254/12825 [11:39:48<33:38:13, 12.65s/it] 25%|██▌       | 3255/12825 [11:40:01<33:34:41, 12.63s/it] 25%|██▌       | 3256/12825 [11:40:13<33:32:33, 12.62s/it] 25%|██▌       | 3257/12825 [11:40:26<33:33:54, 12.63s/it] 25%|██▌       | 3258/12825 [11:40:38<33:31:37, 12.62s/it] 25%|██▌       | 3259/12825 [11:40:51<33:33:07, 12.63s/it] 25%|██▌       | 3260/12825 [11:41:04<33:29:27, 12.61s/it] 25%|██▌       | 3261/12825 [11:41:16<33:26:16, 12.59s/it] 25%|██▌       | 3262/12825 [11:41:29<33:36:35, 12.65s/it] 25%|██▌       | 3263/12825 [11:41:42<33:33:00, 12.63s/it] 25%|██▌       | 3264/12825 [11:41:54<33:31:24, 12.62s/it] 25%|██▌       | 3265/12825 [11:42:07<33:30:15, 12.62s/it] 25%|██▌       | 3266/12825 [11:42:19<33:31:03, 12.62s/it] 25%|██▌       | 3267/12825 [11:42:32<33:32:39, 12.63s/it] 25%|██▌       | 3268/12825 [11:42:45<33:37:05, 12.66s/it] 25%|██▌       | 3269/12825 [11:43:05<39:39:38, 14.94s/it] 25%|██▌       | 3270/12825 [11:43:18<37:48:20, 14.24s/it] 26%|██▌       | 3271/12825 [11:43:30<36:32:10, 13.77s/it] 26%|██▌       | 3272/12825 [11:43:43<35:36:58, 13.42s/it] 26%|██▌       | 3273/12825 [11:43:56<34:59:21, 13.19s/it] 26%|██▌       | 3274/12825 [11:44:08<34:32:52, 13.02s/it] 26%|██▌       | 3275/12825 [11:44:21<34:12:05, 12.89s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120356.25lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103619.73lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3175] due to args.save_total_limit
 26%|██▌       | 3276/12825 [11:44:34<34:14:52, 12.91s/it] 26%|██▌       | 3277/12825 [11:44:46<34:02:04, 12.83s/it] 26%|██▌       | 3278/12825 [11:44:59<33:50:38, 12.76s/it] 26%|██▌       | 3279/12825 [11:45:12<33:44:49, 12.73s/it] 26%|██▌       | 3280/12825 [11:45:24<33:43:52, 12.72s/it] 26%|██▌       | 3281/12825 [11:45:37<33:39:25, 12.70s/it] 26%|██▌       | 3282/12825 [11:45:50<33:40:54, 12.71s/it] 26%|██▌       | 3283/12825 [11:46:02<33:36:26, 12.68s/it] 26%|██▌       | 3284/12825 [11:46:15<33:34:07, 12.67s/it] 26%|██▌       | 3285/12825 [11:46:28<33:30:44, 12.65s/it] 26%|██▌       | 3286/12825 [11:46:40<33:30:32, 12.65s/it] 26%|██▌       | 3287/12825 [11:46:53<33:29:39, 12.64s/it] 26%|██▌       | 3288/12825 [11:47:05<33:29:28, 12.64s/it] 26%|██▌       | 3289/12825 [11:47:18<33:30:42, 12.65s/it] 26%|██▌       | 3290/12825 [11:47:31<33:30:10, 12.65s/it] 26%|██▌       | 3291/12825 [11:47:43<33:29:31, 12.65s/it] 26%|██▌       | 3292/12825 [11:47:56<33:31:09, 12.66s/it] 26%|██▌       | 3293/12825 [11:48:09<33:35:11, 12.68s/it] 26%|██▌       | 3294/12825 [11:48:22<33:33:51, 12.68s/it] 26%|██▌       | 3295/12825 [11:48:34<33:30:46, 12.66s/it] 26%|██▌       | 3296/12825 [11:48:47<33:30:45, 12.66s/it] 26%|██▌       | 3297/12825 [11:48:59<33:31:26, 12.67s/it] 26%|██▌       | 3298/12825 [11:49:12<33:31:01, 12.67s/it] 26%|██▌       | 3299/12825 [11:49:25<33:29:23, 12.66s/it] 26%|██▌       | 3300/12825 [11:49:37<33:27:35, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120295.78lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103560.32lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3250] due to args.save_total_limit
 26%|██▌       | 3301/12825 [11:49:50<33:41:32, 12.74s/it] 26%|██▌       | 3302/12825 [11:50:11<39:36:40, 14.97s/it] 26%|██▌       | 3303/12825 [11:50:23<37:44:42, 14.27s/it] 26%|██▌       | 3304/12825 [11:50:36<36:27:09, 13.78s/it] 26%|██▌       | 3305/12825 [11:50:48<35:31:22, 13.43s/it] 26%|██▌       | 3306/12825 [11:51:01<34:51:12, 13.18s/it] 26%|██▌       | 3307/12825 [11:51:14<34:26:27, 13.03s/it] 26%|██▌       | 3308/12825 [11:51:26<34:09:38, 12.92s/it] 26%|██▌       | 3309/12825 [11:51:39<33:55:34, 12.83s/it] 26%|██▌       | 3310/12825 [11:51:52<33:45:31, 12.77s/it] 26%|██▌       | 3311/12825 [11:52:04<33:40:09, 12.74s/it] 26%|██▌       | 3312/12825 [11:52:17<33:34:20, 12.70s/it] 26%|██▌       | 3313/12825 [11:52:30<33:32:20, 12.69s/it] 26%|██▌       | 3314/12825 [11:52:42<33:30:34, 12.68s/it] 26%|██▌       | 3315/12825 [11:52:55<33:29:43, 12.68s/it] 26%|██▌       | 3316/12825 [11:53:08<33:27:18, 12.67s/it] 26%|██▌       | 3317/12825 [11:53:20<33:26:08, 12.66s/it] 26%|██▌       | 3318/12825 [11:53:33<33:24:36, 12.65s/it] 26%|██▌       | 3319/12825 [11:53:45<33:22:25, 12.64s/it] 26%|██▌       | 3320/12825 [11:53:58<33:21:21, 12.63s/it] 26%|██▌       | 3321/12825 [11:54:11<33:21:30, 12.64s/it] 26%|██▌       | 3322/12825 [11:54:23<33:21:26, 12.64s/it] 26%|██▌       | 3323/12825 [11:54:36<33:20:32, 12.63s/it] 26%|██▌       | 3324/12825 [11:54:49<33:20:39, 12.63s/it] 26%|██▌       | 3325/12825 [11:55:01<33:21:09, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120308.18lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103525.10lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3300] due to args.save_total_limit
 26%|██▌       | 3326/12825 [11:55:14<33:37:09, 12.74s/it] 26%|██▌       | 3327/12825 [11:55:27<33:31:27, 12.71s/it] 26%|██▌       | 3328/12825 [11:55:39<33:28:13, 12.69s/it] 26%|██▌       | 3329/12825 [11:55:52<33:25:51, 12.67s/it] 26%|██▌       | 3330/12825 [11:56:05<33:25:29, 12.67s/it] 26%|██▌       | 3331/12825 [11:56:17<33:23:02, 12.66s/it] 26%|██▌       | 3332/12825 [11:56:30<33:21:40, 12.65s/it] 26%|██▌       | 3333/12825 [11:56:43<33:20:09, 12.64s/it] 26%|██▌       | 3334/12825 [11:57:03<39:19:03, 14.91s/it] 26%|██▌       | 3335/12825 [11:57:16<37:31:13, 14.23s/it] 26%|██▌       | 3336/12825 [11:57:28<36:15:45, 13.76s/it] 26%|██▌       | 3337/12825 [11:57:41<35:24:27, 13.43s/it] 26%|██▌       | 3338/12825 [11:57:54<34:47:13, 13.20s/it] 26%|██▌       | 3339/12825 [11:58:06<34:19:37, 13.03s/it] 26%|██▌       | 3340/12825 [11:58:19<34:01:36, 12.91s/it] 26%|██▌       | 3341/12825 [11:58:31<33:49:03, 12.84s/it] 26%|██▌       | 3342/12825 [11:58:44<33:39:42, 12.78s/it] 26%|██▌       | 3343/12825 [11:58:57<33:33:34, 12.74s/it] 26%|██▌       | 3344/12825 [11:59:09<33:29:46, 12.72s/it] 26%|██▌       | 3345/12825 [11:59:22<33:25:56, 12.70s/it] 26%|██▌       | 3346/12825 [11:59:35<33:23:48, 12.68s/it] 26%|██▌       | 3347/12825 [11:59:47<33:23:16, 12.68s/it] 26%|██▌       | 3348/12825 [12:00:00<33:21:15, 12.67s/it] 26%|██▌       | 3349/12825 [12:00:13<33:19:09, 12.66s/it] 26%|██▌       | 3350/12825 [12:00:25<33:17:33, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120279.68lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103519.80lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3275] due to args.save_total_limit
 26%|██▌       | 3351/12825 [12:00:38<33:32:50, 12.75s/it] 26%|██▌       | 3352/12825 [12:00:51<33:28:31, 12.72s/it] 26%|██▌       | 3353/12825 [12:01:04<33:26:25, 12.71s/it] 26%|██▌       | 3354/12825 [12:01:16<33:22:36, 12.69s/it] 26%|██▌       | 3355/12825 [12:01:29<33:21:50, 12.68s/it] 26%|██▌       | 3356/12825 [12:01:42<33:18:28, 12.66s/it] 26%|██▌       | 3357/12825 [12:01:54<33:16:47, 12.65s/it] 26%|██▌       | 3358/12825 [12:02:07<33:16:42, 12.65s/it] 26%|██▌       | 3359/12825 [12:02:19<33:17:06, 12.66s/it] 26%|██▌       | 3360/12825 [12:02:32<33:15:23, 12.65s/it] 26%|██▌       | 3361/12825 [12:02:45<33:12:11, 12.63s/it] 26%|██▌       | 3362/12825 [12:02:57<33:10:55, 12.62s/it] 26%|██▌       | 3363/12825 [12:03:10<33:11:34, 12.63s/it] 26%|██▌       | 3364/12825 [12:03:23<33:12:12, 12.63s/it] 26%|██▌       | 3365/12825 [12:03:35<33:13:04, 12.64s/it] 26%|██▌       | 3366/12825 [12:03:55<39:09:43, 14.90s/it] 26%|██▋       | 3367/12825 [12:04:08<37:22:54, 14.23s/it] 26%|██▋       | 3368/12825 [12:04:21<36:07:17, 13.75s/it] 26%|██▋       | 3369/12825 [12:04:33<35:13:26, 13.41s/it] 26%|██▋       | 3370/12825 [12:04:46<34:39:10, 13.19s/it] 26%|██▋       | 3371/12825 [12:04:59<34:14:26, 13.04s/it] 26%|██▋       | 3372/12825 [12:05:11<33:54:31, 12.91s/it] 26%|██▋       | 3373/12825 [12:05:24<33:42:00, 12.84s/it] 26%|██▋       | 3374/12825 [12:05:37<33:31:41, 12.77s/it] 26%|██▋       | 3375/12825 [12:05:49<33:24:21, 12.73s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120026.00lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103298.09lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3325] due to args.save_total_limit
 26%|██▋       | 3376/12825 [12:06:02<33:35:29, 12.80s/it] 26%|██▋       | 3377/12825 [12:06:15<33:26:02, 12.74s/it] 26%|██▋       | 3378/12825 [12:06:27<33:20:34, 12.71s/it] 26%|██▋       | 3379/12825 [12:06:40<33:16:40, 12.68s/it] 26%|██▋       | 3380/12825 [12:06:53<33:13:24, 12.66s/it] 26%|██▋       | 3381/12825 [12:07:05<33:10:53, 12.65s/it] 26%|██▋       | 3382/12825 [12:07:18<33:10:44, 12.65s/it] 26%|██▋       | 3383/12825 [12:07:31<33:09:01, 12.64s/it] 26%|██▋       | 3384/12825 [12:07:43<33:07:32, 12.63s/it] 26%|██▋       | 3385/12825 [12:07:56<33:06:12, 12.62s/it] 26%|██▋       | 3386/12825 [12:08:08<33:07:30, 12.63s/it] 26%|██▋       | 3387/12825 [12:08:21<33:06:19, 12.63s/it] 26%|██▋       | 3388/12825 [12:08:34<33:08:03, 12.64s/it] 26%|██▋       | 3389/12825 [12:08:46<33:07:18, 12.64s/it] 26%|██▋       | 3390/12825 [12:08:59<33:06:07, 12.63s/it] 26%|██▋       | 3391/12825 [12:09:12<33:05:01, 12.62s/it] 26%|██▋       | 3392/12825 [12:09:24<33:01:53, 12.61s/it] 26%|██▋       | 3393/12825 [12:09:37<33:02:34, 12.61s/it] 26%|██▋       | 3394/12825 [12:09:49<33:06:00, 12.64s/it] 26%|██▋       | 3395/12825 [12:10:02<33:06:01, 12.64s/it] 26%|██▋       | 3396/12825 [12:10:15<33:06:13, 12.64s/it] 26%|██▋       | 3397/12825 [12:10:27<33:04:07, 12.63s/it] 26%|██▋       | 3398/12825 [12:10:40<33:03:04, 12.62s/it] 27%|██▋       | 3399/12825 [12:11:01<39:21:02, 15.03s/it] 27%|██▋       | 3400/12825 [12:11:13<37:27:04, 14.30s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120281.60lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103568.18lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3350] due to args.save_total_limit
 27%|██▋       | 3401/12825 [12:11:26<36:24:31, 13.91s/it] 27%|██▋       | 3402/12825 [12:11:39<35:23:09, 13.52s/it] 27%|██▋       | 3403/12825 [12:11:52<34:45:10, 13.28s/it] 27%|██▋       | 3404/12825 [12:12:04<34:15:08, 13.09s/it] 27%|██▋       | 3405/12825 [12:12:17<33:52:28, 12.95s/it] 27%|██▋       | 3406/12825 [12:12:29<33:39:59, 12.87s/it] 27%|██▋       | 3407/12825 [12:12:42<33:30:55, 12.81s/it] 27%|██▋       | 3408/12825 [12:12:55<33:23:28, 12.77s/it] 27%|██▋       | 3409/12825 [12:13:07<33:17:12, 12.73s/it] 27%|██▋       | 3410/12825 [12:13:20<33:15:02, 12.71s/it] 27%|██▋       | 3411/12825 [12:13:33<33:10:54, 12.69s/it] 27%|██▋       | 3412/12825 [12:13:45<33:09:34, 12.68s/it] 27%|██▋       | 3413/12825 [12:13:58<33:08:37, 12.68s/it] 27%|██▋       | 3414/12825 [12:14:11<33:06:33, 12.67s/it] 27%|██▋       | 3415/12825 [12:14:23<33:07:13, 12.67s/it] 27%|██▋       | 3416/12825 [12:14:36<33:08:23, 12.68s/it] 27%|██▋       | 3417/12825 [12:14:49<33:06:18, 12.67s/it] 27%|██▋       | 3418/12825 [12:15:01<33:04:55, 12.66s/it] 27%|██▋       | 3419/12825 [12:15:14<33:03:15, 12.65s/it] 27%|██▋       | 3420/12825 [12:15:27<33:02:47, 12.65s/it] 27%|██▋       | 3421/12825 [12:15:39<33:01:38, 12.64s/it] 27%|██▋       | 3422/12825 [12:15:52<33:01:07, 12.64s/it] 27%|██▋       | 3423/12825 [12:16:05<33:01:05, 12.64s/it] 27%|██▋       | 3424/12825 [12:16:17<33:00:15, 12.64s/it] 27%|██▋       | 3425/12825 [12:16:30<33:00:14, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120322.11lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103605.89lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3375] due to args.save_total_limit
 27%|██▋       | 3426/12825 [12:16:43<33:23:09, 12.79s/it] 27%|██▋       | 3427/12825 [12:16:56<33:13:56, 12.73s/it] 27%|██▋       | 3428/12825 [12:17:08<33:07:43, 12.69s/it] 27%|██▋       | 3429/12825 [12:17:21<33:05:31, 12.68s/it] 27%|██▋       | 3430/12825 [12:17:33<33:03:33, 12.67s/it] 27%|██▋       | 3431/12825 [12:17:54<38:50:33, 14.89s/it] 27%|██▋       | 3432/12825 [12:18:06<37:03:35, 14.20s/it] 27%|██▋       | 3433/12825 [12:18:19<35:48:29, 13.73s/it] 27%|██▋       | 3434/12825 [12:18:31<34:56:38, 13.40s/it] 27%|██▋       | 3435/12825 [12:18:44<34:22:04, 13.18s/it] 27%|██▋       | 3436/12825 [12:18:57<33:57:11, 13.02s/it] 27%|██▋       | 3437/12825 [12:19:09<33:40:21, 12.91s/it] 27%|██▋       | 3438/12825 [12:19:22<33:27:00, 12.83s/it] 27%|██▋       | 3439/12825 [12:19:35<33:17:37, 12.77s/it] 27%|██▋       | 3440/12825 [12:19:47<33:10:32, 12.73s/it] 27%|██▋       | 3441/12825 [12:20:00<33:06:30, 12.70s/it] 27%|██▋       | 3442/12825 [12:20:13<33:04:00, 12.69s/it] 27%|██▋       | 3443/12825 [12:20:25<33:03:00, 12.68s/it] 27%|██▋       | 3444/12825 [12:20:38<32:59:46, 12.66s/it] 27%|██▋       | 3445/12825 [12:20:50<32:57:17, 12.65s/it] 27%|██▋       | 3446/12825 [12:21:03<32:55:43, 12.64s/it] 27%|██▋       | 3447/12825 [12:21:16<32:55:19, 12.64s/it] 27%|██▋       | 3448/12825 [12:21:28<32:55:40, 12.64s/it] 27%|██▋       | 3449/12825 [12:21:41<33:05:32, 12.71s/it] 27%|██▋       | 3450/12825 [12:21:54<33:00:18, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120450.09lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103748.17lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3400] due to args.save_total_limit
 27%|██▋       | 3451/12825 [12:22:07<33:13:40, 12.76s/it] 27%|██▋       | 3452/12825 [12:22:19<33:09:19, 12.73s/it] 27%|██▋       | 3453/12825 [12:22:32<33:03:53, 12.70s/it] 27%|██▋       | 3454/12825 [12:22:45<33:01:27, 12.69s/it] 27%|██▋       | 3455/12825 [12:22:57<32:58:02, 12.67s/it] 27%|██▋       | 3456/12825 [12:23:10<32:58:52, 12.67s/it] 27%|██▋       | 3457/12825 [12:23:23<32:57:07, 12.66s/it] 27%|██▋       | 3458/12825 [12:23:35<32:52:30, 12.63s/it] 27%|██▋       | 3459/12825 [12:23:48<32:49:55, 12.62s/it] 27%|██▋       | 3460/12825 [12:24:00<32:51:14, 12.63s/it] 27%|██▋       | 3461/12825 [12:24:13<32:49:40, 12.62s/it] 27%|██▋       | 3462/12825 [12:24:26<32:50:48, 12.63s/it] 27%|██▋       | 3463/12825 [12:24:38<32:49:47, 12.62s/it] 27%|██▋       | 3464/12825 [12:24:59<38:56:39, 14.98s/it] 27%|██▋       | 3465/12825 [12:25:11<37:07:03, 14.28s/it] 27%|██▋       | 3466/12825 [12:25:24<35:49:16, 13.78s/it] 27%|██▋       | 3467/12825 [12:25:37<34:55:25, 13.44s/it] 27%|██▋       | 3468/12825 [12:25:49<34:18:42, 13.20s/it] 27%|██▋       | 3469/12825 [12:26:02<33:51:45, 13.03s/it] 27%|██▋       | 3470/12825 [12:26:15<33:32:14, 12.91s/it] 27%|██▋       | 3471/12825 [12:26:27<33:19:52, 12.83s/it] 27%|██▋       | 3472/12825 [12:26:40<33:14:21, 12.79s/it] 27%|██▋       | 3473/12825 [12:26:53<33:08:18, 12.76s/it] 27%|██▋       | 3474/12825 [12:27:05<33:03:32, 12.73s/it] 27%|██▋       | 3475/12825 [12:27:18<32:58:32, 12.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120305.75lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103562.02lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3425] due to args.save_total_limit
 27%|██▋       | 3476/12825 [12:27:31<33:11:44, 12.78s/it] 27%|██▋       | 3477/12825 [12:27:44<33:06:22, 12.75s/it] 27%|██▋       | 3478/12825 [12:27:56<33:01:18, 12.72s/it] 27%|██▋       | 3479/12825 [12:28:09<32:57:24, 12.69s/it] 27%|██▋       | 3480/12825 [12:28:21<32:54:47, 12.68s/it] 27%|██▋       | 3481/12825 [12:28:34<32:53:35, 12.67s/it] 27%|██▋       | 3482/12825 [12:28:47<32:55:05, 12.68s/it] 27%|██▋       | 3483/12825 [12:29:00<32:53:53, 12.68s/it] 27%|██▋       | 3484/12825 [12:29:12<32:51:21, 12.66s/it] 27%|██▋       | 3485/12825 [12:29:25<32:52:00, 12.67s/it] 27%|██▋       | 3486/12825 [12:29:37<32:50:38, 12.66s/it] 27%|██▋       | 3487/12825 [12:29:50<32:51:02, 12.66s/it] 27%|██▋       | 3488/12825 [12:30:03<32:51:11, 12.67s/it] 27%|██▋       | 3489/12825 [12:30:15<32:50:41, 12.67s/it] 27%|██▋       | 3490/12825 [12:30:28<32:50:18, 12.66s/it] 27%|██▋       | 3491/12825 [12:30:41<32:53:29, 12.69s/it] 27%|██▋       | 3492/12825 [12:30:54<32:54:30, 12.69s/it] 27%|██▋       | 3493/12825 [12:31:06<32:51:19, 12.67s/it] 27%|██▋       | 3494/12825 [12:31:19<32:51:13, 12.68s/it] 27%|██▋       | 3495/12825 [12:31:32<32:50:12, 12.67s/it] 27%|██▋       | 3496/12825 [12:31:52<38:55:47, 15.02s/it] 27%|██▋       | 3497/12825 [12:32:05<37:03:57, 14.31s/it] 27%|██▋       | 3498/12825 [12:32:17<35:46:16, 13.81s/it] 27%|██▋       | 3499/12825 [12:32:30<34:51:54, 13.46s/it] 27%|██▋       | 3500/12825 [12:32:43<34:15:40, 13.23s/it]                                                           27%|██▋       | 3500/12825 [12:32:43<34:15:40, 13.23s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120109.51lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103516.86lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3450] due to args.save_total_limit
 27%|██▋       | 3501/12825 [12:32:56<34:04:58, 13.16s/it] 27%|██▋       | 3502/12825 [12:33:08<33:41:21, 13.01s/it] 27%|██▋       | 3503/12825 [12:33:21<33:24:23, 12.90s/it] 27%|██▋       | 3504/12825 [12:33:34<33:11:15, 12.82s/it] 27%|██▋       | 3505/12825 [12:33:46<33:03:41, 12.77s/it] 27%|██▋       | 3506/12825 [12:33:59<32:56:34, 12.73s/it] 27%|██▋       | 3507/12825 [12:34:12<32:54:35, 12.71s/it] 27%|██▋       | 3508/12825 [12:34:24<32:51:06, 12.69s/it] 27%|██▋       | 3509/12825 [12:34:37<32:50:31, 12.69s/it] 27%|██▋       | 3510/12825 [12:34:50<32:49:15, 12.68s/it] 27%|██▋       | 3511/12825 [12:35:02<32:46:59, 12.67s/it] 27%|██▋       | 3512/12825 [12:35:15<32:45:17, 12.66s/it] 27%|██▋       | 3513/12825 [12:35:28<32:45:23, 12.66s/it] 27%|██▋       | 3514/12825 [12:35:40<32:47:06, 12.68s/it] 27%|██▋       | 3515/12825 [12:35:53<32:45:11, 12.66s/it] 27%|██▋       | 3516/12825 [12:36:06<32:44:31, 12.66s/it] 27%|██▋       | 3517/12825 [12:36:18<32:44:12, 12.66s/it] 27%|██▋       | 3518/12825 [12:36:31<32:44:14, 12.66s/it] 27%|██▋       | 3519/12825 [12:36:43<32:42:01, 12.65s/it] 27%|██▋       | 3520/12825 [12:36:56<32:42:35, 12.66s/it] 27%|██▋       | 3521/12825 [12:37:09<32:42:10, 12.65s/it] 27%|██▋       | 3522/12825 [12:37:21<32:42:40, 12.66s/it] 27%|██▋       | 3523/12825 [12:37:34<32:41:27, 12.65s/it] 27%|██▋       | 3524/12825 [12:37:47<32:41:36, 12.65s/it] 27%|██▋       | 3525/12825 [12:37:59<32:42:15, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120264.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103531.53lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3500] due to args.save_total_limit
 27%|██▋       | 3526/12825 [12:38:12<32:57:16, 12.76s/it] 28%|██▊       | 3527/12825 [12:38:25<32:52:09, 12.73s/it] 28%|██▊       | 3528/12825 [12:38:45<38:42:31, 14.99s/it] 28%|██▊       | 3529/12825 [12:38:58<36:51:45, 14.28s/it] 28%|██▊       | 3530/12825 [12:39:11<35:35:18, 13.78s/it] 28%|██▊       | 3531/12825 [12:39:23<34:43:14, 13.45s/it] 28%|██▊       | 3532/12825 [12:39:36<34:05:25, 13.21s/it] 28%|██▊       | 3533/12825 [12:39:49<33:37:54, 13.03s/it] 28%|██▊       | 3534/12825 [12:40:01<33:20:02, 12.92s/it] 28%|██▊       | 3535/12825 [12:40:14<33:06:04, 12.83s/it] 28%|██▊       | 3536/12825 [12:40:26<32:57:16, 12.77s/it] 28%|██▊       | 3537/12825 [12:40:39<32:55:04, 12.76s/it] 28%|██▊       | 3538/12825 [12:40:52<32:51:01, 12.73s/it] 28%|██▊       | 3539/12825 [12:41:04<32:46:35, 12.71s/it] 28%|██▊       | 3540/12825 [12:41:17<32:43:31, 12.69s/it] 28%|██▊       | 3541/12825 [12:41:30<32:42:06, 12.68s/it] 28%|██▊       | 3542/12825 [12:41:42<32:38:47, 12.66s/it] 28%|██▊       | 3543/12825 [12:41:55<32:36:28, 12.65s/it] 28%|██▊       | 3544/12825 [12:42:08<32:37:24, 12.65s/it] 28%|██▊       | 3545/12825 [12:42:20<32:37:20, 12.66s/it] 28%|██▊       | 3546/12825 [12:42:33<32:38:11, 12.66s/it] 28%|██▊       | 3547/12825 [12:42:46<32:37:50, 12.66s/it] 28%|██▊       | 3548/12825 [12:42:58<32:36:07, 12.65s/it] 28%|██▊       | 3549/12825 [12:43:11<32:35:56, 12.65s/it] 28%|██▊       | 3550/12825 [12:43:24<32:35:19, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120304.47lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103602.85lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3525] due to args.save_total_limit
 28%|██▊       | 3551/12825 [12:43:37<32:50:23, 12.75s/it] 28%|██▊       | 3552/12825 [12:43:49<32:44:44, 12.71s/it] 28%|██▊       | 3553/12825 [12:44:02<32:39:53, 12.68s/it] 28%|██▊       | 3554/12825 [12:44:14<32:35:48, 12.66s/it] 28%|██▊       | 3555/12825 [12:44:27<32:33:52, 12.65s/it] 28%|██▊       | 3556/12825 [12:44:40<32:32:03, 12.64s/it] 28%|██▊       | 3557/12825 [12:44:52<32:30:36, 12.63s/it] 28%|██▊       | 3558/12825 [12:45:05<32:31:14, 12.63s/it] 28%|██▊       | 3559/12825 [12:45:17<32:28:53, 12.62s/it] 28%|██▊       | 3560/12825 [12:45:30<32:29:05, 12.62s/it] 28%|██▊       | 3561/12825 [12:45:50<38:12:29, 14.85s/it] 28%|██▊       | 3562/12825 [12:46:03<36:29:31, 14.18s/it] 28%|██▊       | 3563/12825 [12:46:15<35:17:06, 13.71s/it] 28%|██▊       | 3564/12825 [12:46:28<34:25:56, 13.38s/it] 28%|██▊       | 3565/12825 [12:46:41<33:49:02, 13.15s/it] 28%|██▊       | 3566/12825 [12:46:53<33:26:52, 13.00s/it] 28%|██▊       | 3567/12825 [12:47:06<33:10:29, 12.90s/it] 28%|██▊       | 3568/12825 [12:47:19<32:59:00, 12.83s/it] 28%|██▊       | 3569/12825 [12:47:31<32:56:08, 12.81s/it] 28%|██▊       | 3570/12825 [12:47:44<32:48:30, 12.76s/it] 28%|██▊       | 3571/12825 [12:47:57<32:43:17, 12.73s/it] 28%|██▊       | 3572/12825 [12:48:09<32:41:51, 12.72s/it] 28%|██▊       | 3573/12825 [12:48:22<32:40:01, 12.71s/it] 28%|██▊       | 3574/12825 [12:48:35<32:35:48, 12.69s/it] 28%|██▊       | 3575/12825 [12:48:47<32:34:31, 12.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120085.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103487.16lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3475] due to args.save_total_limit
 28%|██▊       | 3576/12825 [12:49:00<32:48:32, 12.77s/it] 28%|██▊       | 3577/12825 [12:49:13<32:42:38, 12.73s/it] 28%|██▊       | 3578/12825 [12:49:26<32:44:25, 12.75s/it] 28%|██▊       | 3579/12825 [12:49:38<32:41:02, 12.73s/it] 28%|██▊       | 3580/12825 [12:49:51<32:38:45, 12.71s/it] 28%|██▊       | 3581/12825 [12:50:04<32:34:53, 12.69s/it] 28%|██▊       | 3582/12825 [12:50:16<32:31:36, 12.67s/it] 28%|██▊       | 3583/12825 [12:50:29<32:28:42, 12.65s/it] 28%|██▊       | 3584/12825 [12:50:42<32:26:47, 12.64s/it] 28%|██▊       | 3585/12825 [12:50:54<32:25:10, 12.63s/it] 28%|██▊       | 3586/12825 [12:51:07<32:24:01, 12.62s/it] 28%|██▊       | 3587/12825 [12:51:19<32:23:53, 12.63s/it] 28%|██▊       | 3588/12825 [12:51:32<32:23:42, 12.63s/it] 28%|██▊       | 3589/12825 [12:51:45<32:25:56, 12.64s/it] 28%|██▊       | 3590/12825 [12:51:53<28:46:51, 11.22s/it] 28%|██▊       | 3591/12825 [12:51:53<20:46:38,  8.10s/it] 28%|██▊       | 3592/12825 [12:52:19<34:17:10, 13.37s/it] 28%|██▊       | 3593/12825 [12:52:39<39:38:26, 15.46s/it] 28%|██▊       | 3594/12825 [12:52:52<37:30:31, 14.63s/it] 28%|██▊       | 3595/12825 [12:53:05<36:00:38, 14.05s/it] 28%|██▊       | 3596/12825 [12:53:18<34:57:43, 13.64s/it] 28%|██▊       | 3597/12825 [12:53:30<34:14:21, 13.36s/it] 28%|██▊       | 3598/12825 [12:53:43<33:42:42, 13.15s/it] 28%|██▊       | 3599/12825 [12:53:56<33:21:40, 13.02s/it] 28%|██▊       | 3600/12825 [12:54:08<33:08:16, 12.93s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120249.29lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103530.97lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3550] due to args.save_total_limit
 28%|██▊       | 3601/12825 [12:54:21<33:13:00, 12.96s/it] 28%|██▊       | 3602/12825 [12:54:34<33:01:21, 12.89s/it] 28%|██▊       | 3603/12825 [12:54:47<32:53:01, 12.84s/it] 28%|██▊       | 3604/12825 [12:55:00<32:46:19, 12.79s/it] 28%|██▊       | 3605/12825 [12:55:12<32:42:45, 12.77s/it] 28%|██▊       | 3606/12825 [12:55:25<32:39:27, 12.75s/it] 28%|██▊       | 3607/12825 [12:55:38<32:39:27, 12.75s/it] 28%|██▊       | 3608/12825 [12:55:50<32:39:20, 12.75s/it] 28%|██▊       | 3609/12825 [12:56:03<32:38:42, 12.75s/it] 28%|██▊       | 3610/12825 [12:56:16<32:38:53, 12.75s/it] 28%|██▊       | 3611/12825 [12:56:29<32:37:35, 12.75s/it] 28%|██▊       | 3612/12825 [12:56:41<32:36:15, 12.74s/it] 28%|██▊       | 3613/12825 [12:56:54<32:35:53, 12.74s/it] 28%|██▊       | 3614/12825 [12:57:07<32:37:45, 12.75s/it] 28%|██▊       | 3615/12825 [12:57:20<32:37:54, 12.76s/it] 28%|██▊       | 3616/12825 [12:57:32<32:37:27, 12.75s/it] 28%|██▊       | 3617/12825 [12:57:45<32:36:24, 12.75s/it] 28%|██▊       | 3618/12825 [12:57:58<32:35:21, 12.74s/it] 28%|██▊       | 3619/12825 [12:58:11<32:35:08, 12.74s/it] 28%|██▊       | 3620/12825 [12:58:23<32:35:16, 12.74s/it] 28%|██▊       | 3621/12825 [12:58:36<32:36:30, 12.75s/it] 28%|██▊       | 3622/12825 [12:58:49<32:35:39, 12.75s/it] 28%|██▊       | 3623/12825 [12:59:02<32:35:05, 12.75s/it] 28%|██▊       | 3624/12825 [12:59:14<32:34:50, 12.75s/it] 28%|██▊       | 3625/12825 [12:59:27<32:34:40, 12.75s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120238.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103588.45lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3575] due to args.save_total_limit
 28%|██▊       | 3626/12825 [12:59:48<39:04:03, 15.29s/it] 28%|██▊       | 3627/12825 [13:00:01<37:05:40, 14.52s/it] 28%|██▊       | 3628/12825 [13:00:14<35:45:04, 13.99s/it] 28%|██▊       | 3629/12825 [13:00:27<34:44:19, 13.60s/it] 28%|██▊       | 3630/12825 [13:00:39<34:03:39, 13.34s/it] 28%|██▊       | 3631/12825 [13:00:52<33:32:12, 13.13s/it] 28%|██▊       | 3632/12825 [13:01:05<33:11:38, 13.00s/it] 28%|██▊       | 3633/12825 [13:01:17<32:56:24, 12.90s/it] 28%|██▊       | 3634/12825 [13:01:30<32:44:57, 12.83s/it] 28%|██▊       | 3635/12825 [13:01:43<32:37:04, 12.78s/it] 28%|██▊       | 3636/12825 [13:01:55<32:32:33, 12.75s/it] 28%|██▊       | 3637/12825 [13:02:08<32:30:08, 12.73s/it] 28%|██▊       | 3638/12825 [13:02:21<32:27:01, 12.72s/it] 28%|██▊       | 3639/12825 [13:02:33<32:25:54, 12.71s/it] 28%|██▊       | 3640/12825 [13:02:46<32:26:10, 12.71s/it] 28%|██▊       | 3641/12825 [13:02:59<32:26:42, 12.72s/it] 28%|██▊       | 3642/12825 [13:03:11<32:25:15, 12.71s/it] 28%|██▊       | 3643/12825 [13:03:24<32:25:56, 12.72s/it] 28%|██▊       | 3644/12825 [13:03:37<32:28:07, 12.73s/it] 28%|██▊       | 3645/12825 [13:03:50<32:28:14, 12.73s/it] 28%|██▊       | 3646/12825 [13:04:02<32:27:31, 12.73s/it] 28%|██▊       | 3647/12825 [13:04:15<32:38:31, 12.80s/it] 28%|██▊       | 3648/12825 [13:04:28<32:31:30, 12.76s/it] 28%|██▊       | 3649/12825 [13:04:41<32:27:40, 12.74s/it] 28%|██▊       | 3650/12825 [13:04:53<32:25:43, 12.72s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120437.66lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103651.12lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3625] due to args.save_total_limit
 28%|██▊       | 3651/12825 [13:05:06<32:39:57, 12.82s/it] 28%|██▊       | 3652/12825 [13:05:19<32:35:07, 12.79s/it] 28%|██▊       | 3653/12825 [13:05:32<32:29:05, 12.75s/it] 28%|██▊       | 3654/12825 [13:05:45<32:26:17, 12.73s/it] 28%|██▊       | 3655/12825 [13:05:57<32:25:05, 12.73s/it] 29%|██▊       | 3656/12825 [13:06:10<32:22:58, 12.71s/it] 29%|██▊       | 3657/12825 [13:06:23<32:20:58, 12.70s/it] 29%|██▊       | 3658/12825 [13:06:43<38:14:50, 15.02s/it] 29%|██▊       | 3659/12825 [13:06:56<36:28:09, 14.32s/it] 29%|██▊       | 3660/12825 [13:07:08<35:12:32, 13.83s/it] 29%|██▊       | 3661/12825 [13:07:21<34:20:28, 13.49s/it] 29%|██▊       | 3662/12825 [13:07:34<33:44:43, 13.26s/it] 29%|██▊       | 3663/12825 [13:07:47<33:21:56, 13.11s/it] 29%|██▊       | 3664/12825 [13:07:59<33:01:36, 12.98s/it] 29%|██▊       | 3665/12825 [13:08:12<32:47:49, 12.89s/it] 29%|██▊       | 3666/12825 [13:08:25<32:39:00, 12.83s/it] 29%|██▊       | 3667/12825 [13:08:37<32:32:45, 12.79s/it] 29%|██▊       | 3668/12825 [13:08:50<32:27:32, 12.76s/it] 29%|██▊       | 3669/12825 [13:09:03<32:26:40, 12.76s/it] 29%|██▊       | 3670/12825 [13:09:15<32:23:06, 12.73s/it] 29%|██▊       | 3671/12825 [13:09:28<32:18:14, 12.70s/it] 29%|██▊       | 3672/12825 [13:09:41<32:16:13, 12.69s/it] 29%|██▊       | 3673/12825 [13:09:53<32:14:13, 12.68s/it] 29%|██▊       | 3674/12825 [13:10:06<32:12:05, 12.67s/it] 29%|██▊       | 3675/12825 [13:10:19<32:12:43, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120462.39lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103772.79lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3600] due to args.save_total_limit
 29%|██▊       | 3676/12825 [13:10:32<32:26:26, 12.76s/it] 29%|██▊       | 3677/12825 [13:10:44<32:21:04, 12.73s/it] 29%|██▊       | 3678/12825 [13:10:57<32:18:35, 12.72s/it] 29%|██▊       | 3679/12825 [13:11:10<32:17:24, 12.71s/it] 29%|██▊       | 3680/12825 [13:11:22<32:13:50, 12.69s/it] 29%|██▊       | 3681/12825 [13:11:35<32:12:33, 12.68s/it] 29%|██▊       | 3682/12825 [13:11:48<32:15:04, 12.70s/it] 29%|██▊       | 3683/12825 [13:12:00<32:13:16, 12.69s/it] 29%|██▊       | 3684/12825 [13:12:13<32:11:43, 12.68s/it] 29%|██▊       | 3685/12825 [13:12:26<32:12:26, 12.69s/it] 29%|██▊       | 3686/12825 [13:12:38<32:10:40, 12.68s/it] 29%|██▊       | 3687/12825 [13:12:51<32:13:39, 12.70s/it] 29%|██▉       | 3688/12825 [13:13:04<32:09:55, 12.67s/it] 29%|██▉       | 3689/12825 [13:13:16<32:07:34, 12.66s/it] 29%|██▉       | 3690/12825 [13:13:29<32:05:29, 12.65s/it] 29%|██▉       | 3691/12825 [13:13:50<38:02:03, 14.99s/it] 29%|██▉       | 3692/12825 [13:14:02<36:10:58, 14.26s/it] 29%|██▉       | 3693/12825 [13:14:15<34:52:18, 13.75s/it] 29%|██▉       | 3694/12825 [13:14:27<33:56:56, 13.38s/it] 29%|██▉       | 3695/12825 [13:14:40<33:23:32, 13.17s/it] 29%|██▉       | 3696/12825 [13:14:52<32:54:47, 12.98s/it] 29%|██▉       | 3697/12825 [13:15:05<32:35:17, 12.85s/it] 29%|██▉       | 3698/12825 [13:15:17<32:20:22, 12.76s/it] 29%|██▉       | 3699/12825 [13:15:30<32:10:21, 12.69s/it] 29%|██▉       | 3700/12825 [13:15:43<32:03:41, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120440.09lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103773.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3650] due to args.save_total_limit
 29%|██▉       | 3701/12825 [13:15:55<32:13:17, 12.71s/it] 29%|██▉       | 3702/12825 [13:16:08<32:06:12, 12.67s/it] 29%|██▉       | 3703/12825 [13:16:21<32:00:27, 12.63s/it] 29%|██▉       | 3704/12825 [13:16:33<31:55:48, 12.60s/it] 29%|██▉       | 3705/12825 [13:16:46<31:51:55, 12.58s/it] 29%|██▉       | 3706/12825 [13:16:58<31:51:02, 12.57s/it] 29%|██▉       | 3707/12825 [13:17:11<31:48:05, 12.56s/it] 29%|██▉       | 3708/12825 [13:17:23<31:48:45, 12.56s/it] 29%|██▉       | 3709/12825 [13:17:36<31:48:22, 12.56s/it] 29%|██▉       | 3710/12825 [13:17:48<31:47:45, 12.56s/it] 29%|██▉       | 3711/12825 [13:18:01<31:50:40, 12.58s/it] 29%|██▉       | 3712/12825 [13:18:14<31:48:34, 12.57s/it] 29%|██▉       | 3713/12825 [13:18:26<31:47:06, 12.56s/it] 29%|██▉       | 3714/12825 [13:18:39<31:46:05, 12.55s/it] 29%|██▉       | 3715/12825 [13:18:51<31:45:58, 12.55s/it] 29%|██▉       | 3716/12825 [13:19:04<31:47:24, 12.56s/it] 29%|██▉       | 3717/12825 [13:19:16<31:45:56, 12.56s/it] 29%|██▉       | 3718/12825 [13:19:29<31:44:02, 12.54s/it] 29%|██▉       | 3719/12825 [13:19:41<31:44:03, 12.55s/it] 29%|██▉       | 3720/12825 [13:19:54<31:44:03, 12.55s/it] 29%|██▉       | 3721/12825 [13:20:07<31:48:31, 12.58s/it] 29%|██▉       | 3722/12825 [13:20:19<31:45:45, 12.56s/it] 29%|██▉       | 3723/12825 [13:20:38<36:39:10, 14.50s/it] 29%|██▉       | 3724/12825 [13:20:51<35:31:29, 14.05s/it] 29%|██▉       | 3725/12825 [13:21:04<34:29:45, 13.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 106568.52lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 93226.78lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3725
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3725/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3725/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3700] due to args.save_total_limit
 29%|██▉       | 3726/12825 [13:21:17<33:55:11, 13.42s/it] 29%|██▉       | 3727/12825 [13:21:29<33:14:19, 13.15s/it] 29%|██▉       | 3728/12825 [13:21:42<32:44:43, 12.96s/it] 29%|██▉       | 3729/12825 [13:21:54<32:28:07, 12.85s/it] 29%|██▉       | 3730/12825 [13:22:07<32:22:33, 12.82s/it] 29%|██▉       | 3731/12825 [13:22:20<32:14:06, 12.76s/it] 29%|██▉       | 3732/12825 [13:22:32<32:06:31, 12.71s/it] 29%|██▉       | 3733/12825 [13:22:45<32:04:42, 12.70s/it] 29%|██▉       | 3734/12825 [13:22:58<31:58:45, 12.66s/it] 29%|██▉       | 3735/12825 [13:23:10<31:53:12, 12.63s/it] 29%|██▉       | 3736/12825 [13:23:23<31:51:16, 12.62s/it] 29%|██▉       | 3737/12825 [13:23:35<31:50:24, 12.61s/it] 29%|██▉       | 3738/12825 [13:23:48<31:49:11, 12.61s/it] 29%|██▉       | 3739/12825 [13:24:00<31:48:26, 12.60s/it] 29%|██▉       | 3740/12825 [13:24:13<31:49:37, 12.61s/it] 29%|██▉       | 3741/12825 [13:24:26<31:49:23, 12.61s/it] 29%|██▉       | 3742/12825 [13:24:38<31:47:21, 12.60s/it] 29%|██▉       | 3743/12825 [13:24:51<31:52:30, 12.63s/it] 29%|██▉       | 3744/12825 [13:25:04<31:51:40, 12.63s/it] 29%|██▉       | 3745/12825 [13:25:16<31:49:51, 12.62s/it] 29%|██▉       | 3746/12825 [13:25:29<31:47:49, 12.61s/it] 29%|██▉       | 3747/12825 [13:25:41<31:46:11, 12.60s/it] 29%|██▉       | 3748/12825 [13:25:54<31:47:52, 12.61s/it] 29%|██▉       | 3749/12825 [13:26:07<31:45:20, 12.60s/it] 29%|██▉       | 3750/12825 [13:26:19<31:45:20, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120538.42lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103754.63lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3750
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3750/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3750/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3675] due to args.save_total_limit
 29%|██▉       | 3751/12825 [13:26:32<31:59:22, 12.69s/it] 29%|██▉       | 3752/12825 [13:26:45<31:52:44, 12.65s/it] 29%|██▉       | 3753/12825 [13:26:57<31:54:46, 12.66s/it] 29%|██▉       | 3754/12825 [13:27:10<31:51:14, 12.64s/it] 29%|██▉       | 3755/12825 [13:27:30<37:25:45, 14.86s/it] 29%|██▉       | 3756/12825 [13:27:43<35:40:42, 14.16s/it] 29%|██▉       | 3757/12825 [13:27:55<34:28:38, 13.69s/it] 29%|██▉       | 3758/12825 [13:28:08<33:38:51, 13.36s/it] 29%|██▉       | 3759/12825 [13:28:20<33:02:40, 13.12s/it] 29%|██▉       | 3760/12825 [13:28:33<32:37:49, 12.96s/it] 29%|██▉       | 3761/12825 [13:28:45<32:24:21, 12.87s/it] 29%|██▉       | 3762/12825 [13:28:58<32:10:56, 12.78s/it] 29%|██▉       | 3763/12825 [13:29:11<32:01:19, 12.72s/it] 29%|██▉       | 3764/12825 [13:29:23<31:56:21, 12.69s/it] 29%|██▉       | 3765/12825 [13:29:36<31:50:41, 12.65s/it] 29%|██▉       | 3766/12825 [13:29:48<31:49:06, 12.64s/it] 29%|██▉       | 3767/12825 [13:30:01<31:46:20, 12.63s/it] 29%|██▉       | 3768/12825 [13:30:14<31:45:08, 12.62s/it] 29%|██▉       | 3769/12825 [13:30:26<31:43:45, 12.61s/it] 29%|██▉       | 3770/12825 [13:30:39<31:44:46, 12.62s/it] 29%|██▉       | 3771/12825 [13:30:51<31:42:52, 12.61s/it] 29%|██▉       | 3772/12825 [13:31:04<31:40:38, 12.60s/it] 29%|██▉       | 3773/12825 [13:31:17<31:39:23, 12.59s/it] 29%|██▉       | 3774/12825 [13:31:29<31:38:50, 12.59s/it] 29%|██▉       | 3775/12825 [13:31:42<31:37:53, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120507.89lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103710.83lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3775
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3775/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3775/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3725] due to args.save_total_limit
 29%|██▉       | 3776/12825 [13:31:55<31:53:02, 12.68s/it] 29%|██▉       | 3777/12825 [13:32:07<31:50:27, 12.67s/it] 29%|██▉       | 3778/12825 [13:32:20<31:46:51, 12.65s/it] 29%|██▉       | 3779/12825 [13:32:32<31:42:38, 12.62s/it] 29%|██▉       | 3780/12825 [13:32:45<31:40:49, 12.61s/it] 29%|██▉       | 3781/12825 [13:32:58<31:39:15, 12.60s/it] 29%|██▉       | 3782/12825 [13:33:10<31:37:41, 12.59s/it] 29%|██▉       | 3783/12825 [13:33:23<31:36:39, 12.59s/it] 30%|██▉       | 3784/12825 [13:33:35<31:40:29, 12.61s/it] 30%|██▉       | 3785/12825 [13:33:48<31:38:02, 12.60s/it] 30%|██▉       | 3786/12825 [13:34:01<31:37:13, 12.59s/it] 30%|██▉       | 3787/12825 [13:34:21<37:33:16, 14.96s/it] 30%|██▉       | 3788/12825 [13:34:34<35:45:25, 14.24s/it] 30%|██▉       | 3789/12825 [13:34:46<34:29:55, 13.74s/it] 30%|██▉       | 3790/12825 [13:34:59<33:35:48, 13.39s/it] 30%|██▉       | 3791/12825 [13:35:11<32:58:26, 13.14s/it] 30%|██▉       | 3792/12825 [13:35:24<32:33:31, 12.98s/it] 30%|██▉       | 3793/12825 [13:35:37<32:16:10, 12.86s/it] 30%|██▉       | 3794/12825 [13:35:49<32:02:54, 12.78s/it] 30%|██▉       | 3795/12825 [13:36:02<31:53:14, 12.71s/it] 30%|██▉       | 3796/12825 [13:36:14<31:47:00, 12.67s/it] 30%|██▉       | 3797/12825 [13:36:27<31:44:11, 12.66s/it] 30%|██▉       | 3798/12825 [13:36:39<31:40:49, 12.63s/it] 30%|██▉       | 3799/12825 [13:36:52<31:37:34, 12.61s/it] 30%|██▉       | 3800/12825 [13:37:05<31:35:10, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120513.15lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103733.91lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3800
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3800/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3800/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3775] due to args.save_total_limit
 30%|██▉       | 3801/12825 [13:37:17<31:48:10, 12.69s/it] 30%|██▉       | 3802/12825 [13:37:30<31:43:32, 12.66s/it] 30%|██▉       | 3803/12825 [13:37:43<31:38:29, 12.63s/it] 30%|██▉       | 3804/12825 [13:37:55<31:36:34, 12.61s/it] 30%|██▉       | 3805/12825 [13:38:08<31:35:25, 12.61s/it] 30%|██▉       | 3806/12825 [13:38:20<31:33:56, 12.60s/it] 30%|██▉       | 3807/12825 [13:38:33<31:31:54, 12.59s/it] 30%|██▉       | 3808/12825 [13:38:46<31:32:38, 12.59s/it] 30%|██▉       | 3809/12825 [13:38:58<31:31:25, 12.59s/it] 30%|██▉       | 3810/12825 [13:39:11<31:30:25, 12.58s/it] 30%|██▉       | 3811/12825 [13:39:23<31:29:37, 12.58s/it] 30%|██▉       | 3812/12825 [13:39:36<31:33:05, 12.60s/it] 30%|██▉       | 3813/12825 [13:39:48<31:31:33, 12.59s/it] 30%|██▉       | 3814/12825 [13:40:01<31:31:25, 12.59s/it] 30%|██▉       | 3815/12825 [13:40:14<31:31:30, 12.60s/it] 30%|██▉       | 3816/12825 [13:40:26<31:31:12, 12.60s/it] 30%|██▉       | 3817/12825 [13:40:39<31:29:39, 12.59s/it] 30%|██▉       | 3818/12825 [13:40:51<31:29:22, 12.59s/it] 30%|██▉       | 3819/12825 [13:41:04<31:28:26, 12.58s/it] 30%|██▉       | 3820/12825 [13:41:24<37:15:36, 14.90s/it] 30%|██▉       | 3821/12825 [13:41:37<35:31:32, 14.20s/it] 30%|██▉       | 3822/12825 [13:41:49<34:16:34, 13.71s/it] 30%|██▉       | 3823/12825 [13:42:02<33:25:19, 13.37s/it] 30%|██▉       | 3824/12825 [13:42:15<32:49:58, 13.13s/it] 30%|██▉       | 3825/12825 [13:42:27<32:24:17, 12.96s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120454.57lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103778.97lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3825
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3825/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3825/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3800] due to args.save_total_limit
 30%|██▉       | 3826/12825 [13:42:40<32:21:19, 12.94s/it] 30%|██▉       | 3827/12825 [13:42:53<32:04:49, 12.83s/it] 30%|██▉       | 3828/12825 [13:43:05<31:54:26, 12.77s/it] 30%|██▉       | 3829/12825 [13:43:18<31:51:43, 12.75s/it] 30%|██▉       | 3830/12825 [13:43:31<31:44:35, 12.70s/it] 30%|██▉       | 3831/12825 [13:43:43<31:43:30, 12.70s/it] 30%|██▉       | 3832/12825 [13:43:56<31:37:22, 12.66s/it] 30%|██▉       | 3833/12825 [13:44:08<31:32:57, 12.63s/it] 30%|██▉       | 3834/12825 [13:44:21<31:29:48, 12.61s/it] 30%|██▉       | 3835/12825 [13:44:33<31:26:43, 12.59s/it] 30%|██▉       | 3836/12825 [13:44:46<31:24:05, 12.58s/it] 30%|██▉       | 3837/12825 [13:44:59<31:23:54, 12.58s/it] 30%|██▉       | 3838/12825 [13:45:11<31:25:06, 12.59s/it] 30%|██▉       | 3839/12825 [13:45:24<31:24:04, 12.58s/it] 30%|██▉       | 3840/12825 [13:45:36<31:26:13, 12.60s/it] 30%|██▉       | 3841/12825 [13:45:49<31:24:36, 12.59s/it] 30%|██▉       | 3842/12825 [13:46:02<31:28:04, 12.61s/it] 30%|██▉       | 3843/12825 [13:46:14<31:33:26, 12.65s/it] 30%|██▉       | 3844/12825 [13:46:27<31:32:24, 12.64s/it] 30%|██▉       | 3845/12825 [13:46:40<31:29:19, 12.62s/it] 30%|██▉       | 3846/12825 [13:46:52<31:26:07, 12.60s/it] 30%|██▉       | 3847/12825 [13:47:05<31:24:58, 12.60s/it] 30%|███       | 3848/12825 [13:47:17<31:24:15, 12.59s/it] 30%|███       | 3849/12825 [13:47:30<31:21:17, 12.58s/it] 30%|███       | 3850/12825 [13:47:42<31:19:46, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120543.04lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103766.32lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3850
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3850/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3850/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3825] due to args.save_total_limit
 30%|███       | 3851/12825 [13:47:55<31:42:50, 12.72s/it] 30%|███       | 3852/12825 [13:48:16<37:12:02, 14.93s/it] 30%|███       | 3853/12825 [13:48:28<35:24:32, 14.21s/it] 30%|███       | 3854/12825 [13:48:41<34:11:53, 13.72s/it] 30%|███       | 3855/12825 [13:48:53<33:18:33, 13.37s/it] 30%|███       | 3856/12825 [13:49:06<32:41:11, 13.12s/it] 30%|███       | 3857/12825 [13:49:18<32:15:51, 12.95s/it] 30%|███       | 3858/12825 [13:49:31<31:56:24, 12.82s/it] 30%|███       | 3859/12825 [13:49:43<31:45:22, 12.75s/it] 30%|███       | 3860/12825 [13:49:56<31:35:21, 12.69s/it] 30%|███       | 3861/12825 [13:50:09<31:29:30, 12.65s/it] 30%|███       | 3862/12825 [13:50:21<31:25:22, 12.62s/it] 30%|███       | 3863/12825 [13:50:34<31:24:26, 12.62s/it] 30%|███       | 3864/12825 [13:50:46<31:24:41, 12.62s/it] 30%|███       | 3865/12825 [13:50:59<31:23:32, 12.61s/it] 30%|███       | 3866/12825 [13:51:11<31:19:44, 12.59s/it] 30%|███       | 3867/12825 [13:51:24<31:16:33, 12.57s/it] 30%|███       | 3868/12825 [13:51:37<31:15:37, 12.56s/it] 30%|███       | 3869/12825 [13:51:49<31:13:51, 12.55s/it] 30%|███       | 3870/12825 [13:52:02<31:13:09, 12.55s/it] 30%|███       | 3871/12825 [13:52:14<31:13:15, 12.55s/it] 30%|███       | 3872/12825 [13:52:27<31:13:36, 12.56s/it] 30%|███       | 3873/12825 [13:52:39<31:13:21, 12.56s/it] 30%|███       | 3874/12825 [13:52:52<31:11:52, 12.55s/it] 30%|███       | 3875/12825 [13:53:04<31:11:53, 12.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120529.57lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103701.90lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3875
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3875/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3875/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3750] due to args.save_total_limit
 30%|███       | 3876/12825 [13:53:17<31:25:33, 12.64s/it] 30%|███       | 3877/12825 [13:53:30<31:28:08, 12.66s/it] 30%|███       | 3878/12825 [13:53:42<31:21:58, 12.62s/it] 30%|███       | 3879/12825 [13:53:55<31:19:25, 12.61s/it] 30%|███       | 3880/12825 [13:54:08<31:21:17, 12.62s/it] 30%|███       | 3881/12825 [13:54:20<31:18:34, 12.60s/it] 30%|███       | 3882/12825 [13:54:33<31:16:13, 12.59s/it] 30%|███       | 3883/12825 [13:54:45<31:14:41, 12.58s/it] 30%|███       | 3884/12825 [13:54:58<31:14:01, 12.58s/it] 30%|███       | 3885/12825 [13:55:18<36:53:18, 14.85s/it] 30%|███       | 3886/12825 [13:55:31<35:09:45, 14.16s/it] 30%|███       | 3887/12825 [13:55:43<33:57:46, 13.68s/it] 30%|███       | 3888/12825 [13:55:56<33:05:56, 13.33s/it] 30%|███       | 3889/12825 [13:56:08<32:32:17, 13.11s/it] 30%|███       | 3890/12825 [13:56:21<32:09:35, 12.96s/it] 30%|███       | 3891/12825 [13:56:33<31:54:00, 12.85s/it] 30%|███       | 3892/12825 [13:56:46<31:40:32, 12.77s/it] 30%|███       | 3893/12825 [13:56:59<31:31:57, 12.71s/it] 30%|███       | 3894/12825 [13:57:11<31:26:57, 12.68s/it] 30%|███       | 3895/12825 [13:57:24<31:22:44, 12.65s/it] 30%|███       | 3896/12825 [13:57:36<31:20:35, 12.64s/it] 30%|███       | 3897/12825 [13:57:49<31:18:54, 12.63s/it] 30%|███       | 3898/12825 [13:58:02<31:18:12, 12.62s/it] 30%|███       | 3899/12825 [13:58:14<31:16:32, 12.61s/it] 30%|███       | 3900/12825 [13:58:27<31:15:06, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120418.71lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103679.02lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3900
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3900/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3900/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3850] due to args.save_total_limit
 30%|███       | 3901/12825 [13:58:40<31:28:33, 12.70s/it] 30%|███       | 3902/12825 [13:58:52<31:23:36, 12.67s/it] 30%|███       | 3903/12825 [13:59:05<31:19:35, 12.64s/it] 30%|███       | 3904/12825 [13:59:18<31:18:16, 12.63s/it] 30%|███       | 3905/12825 [13:59:30<31:21:36, 12.66s/it] 30%|███       | 3906/12825 [13:59:43<31:18:20, 12.64s/it] 30%|███       | 3907/12825 [13:59:55<31:15:43, 12.62s/it] 30%|███       | 3908/12825 [14:00:08<31:14:30, 12.61s/it] 30%|███       | 3909/12825 [14:00:21<31:13:32, 12.61s/it] 30%|███       | 3910/12825 [14:00:33<31:11:26, 12.60s/it] 30%|███       | 3911/12825 [14:00:46<31:14:28, 12.62s/it] 31%|███       | 3912/12825 [14:00:58<31:14:32, 12.62s/it] 31%|███       | 3913/12825 [14:01:11<31:13:13, 12.61s/it] 31%|███       | 3914/12825 [14:01:24<31:12:27, 12.61s/it] 31%|███       | 3915/12825 [14:01:36<31:11:42, 12.60s/it] 31%|███       | 3916/12825 [14:01:49<31:11:13, 12.60s/it] 31%|███       | 3917/12825 [14:02:09<36:52:23, 14.90s/it] 31%|███       | 3918/12825 [14:02:22<35:09:00, 14.21s/it] 31%|███       | 3919/12825 [14:02:34<33:56:46, 13.72s/it] 31%|███       | 3920/12825 [14:02:47<33:05:59, 13.38s/it] 31%|███       | 3921/12825 [14:02:59<32:29:45, 13.14s/it] 31%|███       | 3922/12825 [14:03:12<32:06:12, 12.98s/it] 31%|███       | 3923/12825 [14:03:25<31:48:38, 12.86s/it] 31%|███       | 3924/12825 [14:03:37<31:35:40, 12.78s/it] 31%|███       | 3925/12825 [14:03:50<31:25:44, 12.71s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120416.40lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103737.90lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3925
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3925/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3925/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3900] due to args.save_total_limit
 31%|███       | 3926/12825 [14:04:03<31:34:31, 12.77s/it] 31%|███       | 3927/12825 [14:04:15<31:25:34, 12.71s/it] 31%|███       | 3928/12825 [14:04:28<31:20:24, 12.68s/it] 31%|███       | 3929/12825 [14:04:40<31:16:28, 12.66s/it] 31%|███       | 3930/12825 [14:04:53<31:13:43, 12.64s/it] 31%|███       | 3931/12825 [14:05:06<31:11:52, 12.63s/it] 31%|███       | 3932/12825 [14:05:18<31:11:05, 12.62s/it] 31%|███       | 3933/12825 [14:05:31<31:08:47, 12.61s/it] 31%|███       | 3934/12825 [14:05:43<31:07:36, 12.60s/it] 31%|███       | 3935/12825 [14:05:56<31:06:46, 12.60s/it] 31%|███       | 3936/12825 [14:06:09<31:06:55, 12.60s/it] 31%|███       | 3937/12825 [14:06:21<31:06:42, 12.60s/it] 31%|███       | 3938/12825 [14:06:34<31:05:27, 12.59s/it] 31%|███       | 3939/12825 [14:06:46<31:04:47, 12.59s/it] 31%|███       | 3940/12825 [14:06:59<31:03:45, 12.59s/it] 31%|███       | 3941/12825 [14:07:12<31:03:08, 12.58s/it] 31%|███       | 3942/12825 [14:07:24<31:02:48, 12.58s/it] 31%|███       | 3943/12825 [14:07:37<31:04:30, 12.60s/it] 31%|███       | 3944/12825 [14:07:49<31:04:56, 12.60s/it] 31%|███       | 3945/12825 [14:08:02<31:02:57, 12.59s/it] 31%|███       | 3946/12825 [14:08:15<31:05:08, 12.60s/it] 31%|███       | 3947/12825 [14:08:27<31:04:11, 12.60s/it] 31%|███       | 3948/12825 [14:08:40<31:06:55, 12.62s/it] 31%|███       | 3949/12825 [14:09:00<36:46:49, 14.92s/it] 31%|███       | 3950/12825 [14:09:13<35:02:35, 14.21s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120317.00lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103553.40lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3950
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3950/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3950/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3925] due to args.save_total_limit
 31%|███       | 3951/12825 [14:09:26<34:04:06, 13.82s/it] 31%|███       | 3952/12825 [14:09:38<33:08:24, 13.45s/it] 31%|███       | 3953/12825 [14:09:51<32:29:47, 13.19s/it] 31%|███       | 3954/12825 [14:10:03<32:03:51, 13.01s/it] 31%|███       | 3955/12825 [14:10:16<31:43:33, 12.88s/it] 31%|███       | 3956/12825 [14:10:29<31:31:33, 12.80s/it] 31%|███       | 3957/12825 [14:10:41<31:21:54, 12.73s/it] 31%|███       | 3958/12825 [14:10:54<31:16:18, 12.70s/it] 31%|███       | 3959/12825 [14:11:06<31:12:07, 12.67s/it] 31%|███       | 3960/12825 [14:11:19<31:06:55, 12.64s/it] 31%|███       | 3961/12825 [14:11:31<31:06:02, 12.63s/it] 31%|███       | 3962/12825 [14:11:44<31:03:28, 12.62s/it] 31%|███       | 3963/12825 [14:11:57<31:01:40, 12.60s/it] 31%|███       | 3964/12825 [14:12:09<30:58:40, 12.59s/it] 31%|███       | 3965/12825 [14:12:22<30:58:09, 12.58s/it] 31%|███       | 3966/12825 [14:12:34<30:57:27, 12.58s/it] 31%|███       | 3967/12825 [14:12:47<30:56:31, 12.58s/it] 31%|███       | 3968/12825 [14:13:00<30:59:58, 12.60s/it] 31%|███       | 3969/12825 [14:13:12<30:58:28, 12.59s/it] 31%|███       | 3970/12825 [14:13:25<30:59:36, 12.60s/it] 31%|███       | 3971/12825 [14:13:37<30:58:29, 12.59s/it] 31%|███       | 3972/12825 [14:13:50<30:57:30, 12.59s/it] 31%|███       | 3973/12825 [14:14:03<30:58:06, 12.59s/it] 31%|███       | 3974/12825 [14:14:15<30:57:02, 12.59s/it] 31%|███       | 3975/12825 [14:14:28<30:57:05, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120381.71lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103725.17lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3975
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3975/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3975/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-3975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3950] due to args.save_total_limit
 31%|███       | 3976/12825 [14:14:41<31:11:01, 12.69s/it] 31%|███       | 3977/12825 [14:14:53<31:05:20, 12.65s/it] 31%|███       | 3978/12825 [14:15:06<31:03:07, 12.64s/it] 31%|███       | 3979/12825 [14:15:18<31:01:22, 12.63s/it] 31%|███       | 3980/12825 [14:15:31<30:58:41, 12.61s/it] 31%|███       | 3981/12825 [14:15:44<31:02:16, 12.63s/it] 31%|███       | 3982/12825 [14:16:04<36:39:34, 14.92s/it] 31%|███       | 3983/12825 [14:16:16<34:56:12, 14.22s/it] 31%|███       | 3984/12825 [14:16:29<33:43:13, 13.73s/it] 31%|███       | 3985/12825 [14:16:42<32:55:23, 13.41s/it] 31%|███       | 3986/12825 [14:16:54<32:17:32, 13.15s/it] 31%|███       | 3987/12825 [14:17:07<31:54:53, 13.00s/it] 31%|███       | 3988/12825 [14:17:20<31:35:38, 12.87s/it] 31%|███       | 3989/12825 [14:17:32<31:23:25, 12.79s/it] 31%|███       | 3990/12825 [14:17:45<31:14:21, 12.73s/it] 31%|███       | 3991/12825 [14:17:57<31:08:18, 12.69s/it] 31%|███       | 3992/12825 [14:18:10<31:02:48, 12.65s/it] 31%|███       | 3993/12825 [14:18:22<30:59:30, 12.63s/it] 31%|███       | 3994/12825 [14:18:35<30:56:56, 12.62s/it] 31%|███       | 3995/12825 [14:18:48<30:55:32, 12.61s/it] 31%|███       | 3996/12825 [14:19:00<30:53:11, 12.59s/it] 31%|███       | 3997/12825 [14:19:13<30:53:21, 12.60s/it] 31%|███       | 3998/12825 [14:19:25<30:57:37, 12.63s/it] 31%|███       | 3999/12825 [14:19:38<30:56:13, 12.62s/it] 31%|███       | 4000/12825 [14:19:51<30:55:21, 12.61s/it]                                                           31%|███       | 4000/12825 [14:19:51<30:55:21, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120535.85lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103753.20lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4000
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4000/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4000/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3975] due to args.save_total_limit
 31%|███       | 4001/12825 [14:20:04<31:09:59, 12.72s/it] 31%|███       | 4002/12825 [14:20:16<31:04:36, 12.68s/it] 31%|███       | 4003/12825 [14:20:29<31:01:13, 12.66s/it] 31%|███       | 4004/12825 [14:20:41<30:57:25, 12.63s/it] 31%|███       | 4005/12825 [14:20:54<30:56:14, 12.63s/it] 31%|███       | 4006/12825 [14:21:07<30:54:15, 12.62s/it] 31%|███       | 4007/12825 [14:21:19<30:54:00, 12.62s/it] 31%|███▏      | 4008/12825 [14:21:32<30:55:40, 12.63s/it] 31%|███▏      | 4009/12825 [14:21:45<30:58:54, 12.65s/it] 31%|███▏      | 4010/12825 [14:21:57<30:57:15, 12.64s/it] 31%|███▏      | 4011/12825 [14:22:10<30:54:37, 12.63s/it] 31%|███▏      | 4012/12825 [14:22:22<30:55:04, 12.63s/it] 31%|███▏      | 4013/12825 [14:22:35<30:52:26, 12.61s/it] 31%|███▏      | 4014/12825 [14:22:55<36:25:57, 14.89s/it] 31%|███▏      | 4015/12825 [14:23:08<34:44:11, 14.19s/it] 31%|███▏      | 4016/12825 [14:23:20<33:34:53, 13.72s/it] 31%|███▏      | 4017/12825 [14:23:33<32:44:54, 13.38s/it] 31%|███▏      | 4018/12825 [14:23:46<32:09:11, 13.14s/it] 31%|███▏      | 4019/12825 [14:23:58<31:44:33, 12.98s/it] 31%|███▏      | 4020/12825 [14:24:11<31:25:58, 12.85s/it] 31%|███▏      | 4021/12825 [14:24:23<31:12:51, 12.76s/it] 31%|███▏      | 4022/12825 [14:24:36<31:05:37, 12.72s/it] 31%|███▏      | 4023/12825 [14:24:48<30:58:46, 12.67s/it] 31%|███▏      | 4024/12825 [14:25:01<30:52:22, 12.63s/it] 31%|███▏      | 4025/12825 [14:25:13<30:47:04, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120410.26lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103663.93lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4025
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4025/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4025/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4000] due to args.save_total_limit
 31%|███▏      | 4026/12825 [14:25:26<31:01:02, 12.69s/it] 31%|███▏      | 4027/12825 [14:25:39<30:58:12, 12.67s/it] 31%|███▏      | 4028/12825 [14:25:52<30:54:08, 12.65s/it] 31%|███▏      | 4029/12825 [14:26:04<30:50:08, 12.62s/it] 31%|███▏      | 4030/12825 [14:26:17<30:45:39, 12.59s/it] 31%|███▏      | 4031/12825 [14:26:29<30:43:54, 12.58s/it] 31%|███▏      | 4032/12825 [14:26:42<30:41:57, 12.57s/it] 31%|███▏      | 4033/12825 [14:26:54<30:40:32, 12.56s/it] 31%|███▏      | 4034/12825 [14:27:07<30:44:27, 12.59s/it] 31%|███▏      | 4035/12825 [14:27:20<30:43:36, 12.58s/it] 31%|███▏      | 4036/12825 [14:27:32<30:42:30, 12.58s/it] 31%|███▏      | 4037/12825 [14:27:45<30:42:07, 12.58s/it] 31%|███▏      | 4038/12825 [14:27:57<30:41:07, 12.57s/it] 31%|███▏      | 4039/12825 [14:28:10<30:40:04, 12.57s/it] 32%|███▏      | 4040/12825 [14:28:22<30:38:45, 12.56s/it] 32%|███▏      | 4041/12825 [14:28:35<30:40:05, 12.57s/it] 32%|███▏      | 4042/12825 [14:28:48<30:39:43, 12.57s/it] 32%|███▏      | 4043/12825 [14:29:00<30:43:54, 12.60s/it] 32%|███▏      | 4044/12825 [14:29:13<30:41:14, 12.58s/it] 32%|███▏      | 4045/12825 [14:29:25<30:40:03, 12.57s/it] 32%|███▏      | 4046/12825 [14:29:45<36:07:58, 14.82s/it] 32%|███▏      | 4047/12825 [14:29:58<34:28:01, 14.14s/it] 32%|███▏      | 4048/12825 [14:30:10<33:19:37, 13.67s/it] 32%|███▏      | 4049/12825 [14:30:23<32:36:10, 13.37s/it] 32%|███▏      | 4050/12825 [14:30:36<32:00:57, 13.13s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120382.87lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103718.14lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4050
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4050/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4050/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4025] due to args.save_total_limit
 32%|███▏      | 4051/12825 [14:30:49<31:56:24, 13.11s/it] 32%|███▏      | 4052/12825 [14:31:01<31:36:15, 12.97s/it] 32%|███▏      | 4053/12825 [14:31:14<31:17:02, 12.84s/it] 32%|███▏      | 4054/12825 [14:31:27<31:04:39, 12.76s/it] 32%|███▏      | 4055/12825 [14:31:39<30:54:18, 12.69s/it] 32%|███▏      | 4056/12825 [14:31:52<30:47:10, 12.64s/it] 32%|███▏      | 4057/12825 [14:32:04<30:43:30, 12.62s/it] 32%|███▏      | 4058/12825 [14:32:17<30:40:45, 12.60s/it] 32%|███▏      | 4059/12825 [14:32:29<30:39:25, 12.59s/it] 32%|███▏      | 4060/12825 [14:32:42<30:39:45, 12.59s/it] 32%|███▏      | 4061/12825 [14:32:54<30:38:24, 12.59s/it] 32%|███▏      | 4062/12825 [14:33:07<30:36:26, 12.57s/it] 32%|███▏      | 4063/12825 [14:33:20<30:36:39, 12.58s/it] 32%|███▏      | 4064/12825 [14:33:32<30:36:46, 12.58s/it] 32%|███▏      | 4065/12825 [14:33:45<30:40:45, 12.61s/it] 32%|███▏      | 4066/12825 [14:33:57<30:40:20, 12.61s/it] 32%|███▏      | 4067/12825 [14:34:10<30:38:41, 12.60s/it] 32%|███▏      | 4068/12825 [14:34:23<30:38:53, 12.60s/it] 32%|███▏      | 4069/12825 [14:34:35<30:38:12, 12.60s/it] 32%|███▏      | 4070/12825 [14:34:48<30:36:46, 12.59s/it] 32%|███▏      | 4071/12825 [14:35:00<30:37:15, 12.59s/it] 32%|███▏      | 4072/12825 [14:35:13<30:36:12, 12.59s/it] 32%|███▏      | 4073/12825 [14:35:26<30:36:18, 12.59s/it] 32%|███▏      | 4074/12825 [14:35:38<30:35:39, 12.59s/it] 32%|███▏      | 4075/12825 [14:35:51<30:33:14, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120443.68lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103570.35lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4075
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4075/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4075/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4050] due to args.save_total_limit
 32%|███▏      | 4076/12825 [14:36:04<30:47:06, 12.67s/it] 32%|███▏      | 4077/12825 [14:36:16<30:42:51, 12.64s/it] 32%|███▏      | 4078/12825 [14:36:29<30:37:36, 12.61s/it] 32%|███▏      | 4079/12825 [14:36:49<36:08:31, 14.88s/it] 32%|███▏      | 4080/12825 [14:37:01<34:27:17, 14.18s/it] 32%|███▏      | 4081/12825 [14:37:14<33:16:15, 13.70s/it] 32%|███▏      | 4082/12825 [14:37:27<32:27:04, 13.36s/it] 32%|███▏      | 4083/12825 [14:37:39<31:51:25, 13.12s/it] 32%|███▏      | 4084/12825 [14:37:52<31:27:00, 12.95s/it] 32%|███▏      | 4085/12825 [14:38:04<31:09:01, 12.83s/it] 32%|███▏      | 4086/12825 [14:38:17<30:56:00, 12.74s/it] 32%|███▏      | 4087/12825 [14:38:29<30:48:53, 12.70s/it] 32%|███▏      | 4088/12825 [14:38:42<30:43:56, 12.66s/it] 32%|███▏      | 4089/12825 [14:38:54<30:39:47, 12.64s/it] 32%|███▏      | 4090/12825 [14:39:07<30:35:27, 12.61s/it] 32%|███▏      | 4091/12825 [14:39:20<30:34:23, 12.60s/it] 32%|███▏      | 4092/12825 [14:39:32<30:32:38, 12.59s/it] 32%|███▏      | 4093/12825 [14:39:45<30:32:20, 12.59s/it] 32%|███▏      | 4094/12825 [14:39:57<30:29:53, 12.58s/it] 32%|███▏      | 4095/12825 [14:40:10<30:28:09, 12.56s/it] 32%|███▏      | 4096/12825 [14:40:22<30:27:14, 12.56s/it] 32%|███▏      | 4097/12825 [14:40:35<30:33:21, 12.60s/it] 32%|███▏      | 4098/12825 [14:40:48<30:31:27, 12.59s/it] 32%|███▏      | 4099/12825 [14:41:00<30:30:19, 12.59s/it] 32%|███▏      | 4100/12825 [14:41:13<30:30:07, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120486.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103751.87lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-3875] due to args.save_total_limit
 32%|███▏      | 4101/12825 [14:41:26<30:43:37, 12.68s/it] 32%|███▏      | 4102/12825 [14:41:38<30:38:03, 12.64s/it] 32%|███▏      | 4103/12825 [14:41:46<27:10:44, 11.22s/it] 32%|███▏      | 4104/12825 [14:41:47<19:37:15,  8.10s/it] 32%|███▏      | 4105/12825 [14:42:12<32:13:01, 13.30s/it] 32%|███▏      | 4106/12825 [14:42:25<31:43:48, 13.10s/it] 32%|███▏      | 4107/12825 [14:42:38<31:23:44, 12.96s/it] 32%|███▏      | 4108/12825 [14:42:50<31:07:30, 12.85s/it] 32%|███▏      | 4109/12825 [14:43:03<30:56:18, 12.78s/it] 32%|███▏      | 4110/12825 [14:43:15<30:47:47, 12.72s/it] 32%|███▏      | 4111/12825 [14:43:28<30:42:12, 12.68s/it] 32%|███▏      | 4112/12825 [14:43:48<36:08:05, 14.93s/it] 32%|███▏      | 4113/12825 [14:44:01<34:26:50, 14.23s/it] 32%|███▏      | 4114/12825 [14:44:13<33:16:17, 13.75s/it] 32%|███▏      | 4115/12825 [14:44:26<32:25:40, 13.40s/it] 32%|███▏      | 4116/12825 [14:44:39<31:50:36, 13.16s/it] 32%|███▏      | 4117/12825 [14:44:51<31:25:34, 12.99s/it] 32%|███▏      | 4118/12825 [14:45:04<31:07:30, 12.87s/it] 32%|███▏      | 4119/12825 [14:45:16<30:55:44, 12.79s/it] 32%|███▏      | 4120/12825 [14:45:29<30:46:00, 12.72s/it] 32%|███▏      | 4121/12825 [14:45:42<30:40:36, 12.69s/it] 32%|███▏      | 4122/12825 [14:45:54<30:36:55, 12.66s/it] 32%|███▏      | 4123/12825 [14:46:07<30:32:39, 12.64s/it] 32%|███▏      | 4124/12825 [14:46:19<30:30:21, 12.62s/it] 32%|███▏      | 4125/12825 [14:46:32<30:29:05, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120497.25lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103723.84lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4075] due to args.save_total_limit
 32%|███▏      | 4126/12825 [14:46:45<30:49:43, 12.76s/it] 32%|███▏      | 4127/12825 [14:46:58<30:43:46, 12.72s/it] 32%|███▏      | 4128/12825 [14:47:10<30:39:22, 12.69s/it] 32%|███▏      | 4129/12825 [14:47:23<30:35:23, 12.66s/it] 32%|███▏      | 4130/12825 [14:47:36<30:33:55, 12.66s/it] 32%|███▏      | 4131/12825 [14:47:48<30:36:33, 12.67s/it] 32%|███▏      | 4132/12825 [14:48:01<30:31:15, 12.64s/it] 32%|███▏      | 4133/12825 [14:48:13<30:28:55, 12.62s/it] 32%|███▏      | 4134/12825 [14:48:26<30:27:59, 12.62s/it] 32%|███▏      | 4135/12825 [14:48:39<30:28:11, 12.62s/it] 32%|███▏      | 4136/12825 [14:48:51<30:26:55, 12.62s/it] 32%|███▏      | 4137/12825 [14:49:04<30:26:13, 12.61s/it] 32%|███▏      | 4138/12825 [14:49:16<30:25:06, 12.61s/it] 32%|███▏      | 4139/12825 [14:49:29<30:25:58, 12.61s/it] 32%|███▏      | 4140/12825 [14:49:42<30:24:32, 12.60s/it] 32%|███▏      | 4141/12825 [14:49:54<30:25:16, 12.61s/it] 32%|███▏      | 4142/12825 [14:50:07<30:25:59, 12.62s/it] 32%|███▏      | 4143/12825 [14:50:20<30:24:59, 12.61s/it] 32%|███▏      | 4144/12825 [14:50:40<35:54:28, 14.89s/it] 32%|███▏      | 4145/12825 [14:50:52<34:14:46, 14.20s/it] 32%|███▏      | 4146/12825 [14:51:05<33:03:41, 13.71s/it] 32%|███▏      | 4147/12825 [14:51:18<32:17:13, 13.39s/it] 32%|███▏      | 4148/12825 [14:51:30<31:42:49, 13.16s/it] 32%|███▏      | 4149/12825 [14:51:43<31:18:36, 12.99s/it] 32%|███▏      | 4150/12825 [14:51:55<31:01:27, 12.87s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120518.41lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103646.19lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4125] due to args.save_total_limit
 32%|███▏      | 4151/12825 [14:52:08<31:05:39, 12.91s/it] 32%|███▏      | 4152/12825 [14:52:21<30:50:36, 12.80s/it] 32%|███▏      | 4153/12825 [14:52:34<30:42:15, 12.75s/it] 32%|███▏      | 4154/12825 [14:52:46<30:37:16, 12.71s/it] 32%|███▏      | 4155/12825 [14:52:59<30:33:35, 12.69s/it] 32%|███▏      | 4156/12825 [14:53:11<30:29:50, 12.66s/it] 32%|███▏      | 4157/12825 [14:53:24<30:27:40, 12.65s/it] 32%|███▏      | 4158/12825 [14:53:37<30:26:07, 12.64s/it] 32%|███▏      | 4159/12825 [14:53:49<30:25:33, 12.64s/it] 32%|███▏      | 4160/12825 [14:54:02<30:23:23, 12.63s/it] 32%|███▏      | 4161/12825 [14:54:14<30:22:32, 12.62s/it] 32%|███▏      | 4162/12825 [14:54:27<30:21:50, 12.62s/it] 32%|███▏      | 4163/12825 [14:54:40<30:21:56, 12.62s/it] 32%|███▏      | 4164/12825 [14:54:52<30:22:25, 12.62s/it] 32%|███▏      | 4165/12825 [14:55:05<30:21:20, 12.62s/it] 32%|███▏      | 4166/12825 [14:55:18<30:20:13, 12.61s/it] 32%|███▏      | 4167/12825 [14:55:30<30:21:50, 12.63s/it] 32%|███▏      | 4168/12825 [14:55:43<30:21:21, 12.62s/it] 33%|███▎      | 4169/12825 [14:55:55<30:21:51, 12.63s/it] 33%|███▎      | 4170/12825 [14:56:08<30:20:16, 12.62s/it] 33%|███▎      | 4171/12825 [14:56:21<30:20:38, 12.62s/it] 33%|███▎      | 4172/12825 [14:56:33<30:25:34, 12.66s/it] 33%|███▎      | 4173/12825 [14:56:46<30:22:39, 12.64s/it] 33%|███▎      | 4174/12825 [14:56:59<30:20:56, 12.63s/it] 33%|███▎      | 4175/12825 [14:57:11<30:20:37, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120502.25lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103704.08lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4150] due to args.save_total_limit
 33%|███▎      | 4176/12825 [14:57:32<35:57:29, 14.97s/it] 33%|███▎      | 4177/12825 [14:57:44<34:15:16, 14.26s/it] 33%|███▎      | 4178/12825 [14:57:57<33:04:01, 13.77s/it] 33%|███▎      | 4179/12825 [14:58:10<32:13:08, 13.42s/it] 33%|███▎      | 4180/12825 [14:58:22<31:39:17, 13.18s/it] 33%|███▎      | 4181/12825 [14:58:35<31:14:13, 13.01s/it] 33%|███▎      | 4182/12825 [14:58:47<30:55:12, 12.88s/it] 33%|███▎      | 4183/12825 [14:59:00<30:43:29, 12.80s/it] 33%|███▎      | 4184/12825 [14:59:13<30:34:06, 12.74s/it] 33%|███▎      | 4185/12825 [14:59:25<30:27:59, 12.69s/it] 33%|███▎      | 4186/12825 [14:59:38<30:22:38, 12.66s/it] 33%|███▎      | 4187/12825 [14:59:50<30:20:34, 12.65s/it] 33%|███▎      | 4188/12825 [15:00:03<30:19:53, 12.64s/it] 33%|███▎      | 4189/12825 [15:00:16<30:17:22, 12.63s/it] 33%|███▎      | 4190/12825 [15:00:28<30:14:25, 12.61s/it] 33%|███▎      | 4191/12825 [15:00:41<30:13:04, 12.60s/it] 33%|███▎      | 4192/12825 [15:00:53<30:12:26, 12.60s/it] 33%|███▎      | 4193/12825 [15:01:06<30:13:01, 12.60s/it] 33%|███▎      | 4194/12825 [15:01:19<30:12:28, 12.60s/it] 33%|███▎      | 4195/12825 [15:01:31<30:10:59, 12.59s/it] 33%|███▎      | 4196/12825 [15:01:44<30:13:29, 12.61s/it] 33%|███▎      | 4197/12825 [15:01:56<30:12:54, 12.61s/it] 33%|███▎      | 4198/12825 [15:02:09<30:12:53, 12.61s/it] 33%|███▎      | 4199/12825 [15:02:22<30:12:16, 12.61s/it] 33%|███▎      | 4200/12825 [15:02:34<30:10:52, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120578.59lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103795.62lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4175] due to args.save_total_limit
 33%|███▎      | 4201/12825 [15:02:47<30:25:46, 12.70s/it] 33%|███▎      | 4202/12825 [15:03:00<30:20:55, 12.67s/it] 33%|███▎      | 4203/12825 [15:03:12<30:18:36, 12.66s/it] 33%|███▎      | 4204/12825 [15:03:25<30:16:01, 12.64s/it] 33%|███▎      | 4205/12825 [15:03:38<30:15:55, 12.64s/it] 33%|███▎      | 4206/12825 [15:03:50<30:14:02, 12.63s/it] 33%|███▎      | 4207/12825 [15:04:03<30:12:50, 12.62s/it] 33%|███▎      | 4208/12825 [15:04:15<30:13:16, 12.63s/it] 33%|███▎      | 4209/12825 [15:04:36<35:36:53, 14.88s/it] 33%|███▎      | 4210/12825 [15:04:48<33:59:19, 14.20s/it] 33%|███▎      | 4211/12825 [15:05:01<32:49:15, 13.72s/it] 33%|███▎      | 4212/12825 [15:05:13<32:00:12, 13.38s/it] 33%|███▎      | 4213/12825 [15:05:26<31:26:21, 13.14s/it] 33%|███▎      | 4214/12825 [15:05:38<31:02:11, 12.98s/it] 33%|███▎      | 4215/12825 [15:05:51<30:45:33, 12.86s/it] 33%|███▎      | 4216/12825 [15:06:04<30:35:01, 12.79s/it] 33%|███▎      | 4217/12825 [15:06:16<30:29:48, 12.75s/it] 33%|███▎      | 4218/12825 [15:06:29<30:31:44, 12.77s/it] 33%|███▎      | 4219/12825 [15:06:42<30:26:13, 12.73s/it] 33%|███▎      | 4220/12825 [15:06:54<30:20:20, 12.69s/it] 33%|███▎      | 4221/12825 [15:07:07<30:17:08, 12.67s/it] 33%|███▎      | 4222/12825 [15:07:20<30:14:05, 12.65s/it] 33%|███▎      | 4223/12825 [15:07:32<30:11:42, 12.64s/it] 33%|███▎      | 4224/12825 [15:07:45<30:10:11, 12.63s/it] 33%|███▎      | 4225/12825 [15:07:57<30:09:37, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120347.04lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103635.75lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4200] due to args.save_total_limit
 33%|███▎      | 4226/12825 [15:08:10<30:23:48, 12.73s/it] 33%|███▎      | 4227/12825 [15:08:23<30:17:24, 12.68s/it] 33%|███▎      | 4228/12825 [15:08:36<30:13:08, 12.65s/it] 33%|███▎      | 4229/12825 [15:08:48<30:10:09, 12.63s/it] 33%|███▎      | 4230/12825 [15:09:01<30:09:57, 12.63s/it] 33%|███▎      | 4231/12825 [15:09:13<30:10:32, 12.64s/it] 33%|███▎      | 4232/12825 [15:09:26<30:09:20, 12.63s/it] 33%|███▎      | 4233/12825 [15:09:39<30:09:36, 12.64s/it] 33%|███▎      | 4234/12825 [15:09:51<30:08:03, 12.63s/it] 33%|███▎      | 4235/12825 [15:10:04<30:07:14, 12.62s/it] 33%|███▎      | 4236/12825 [15:10:17<30:06:26, 12.62s/it] 33%|███▎      | 4237/12825 [15:10:29<30:09:48, 12.64s/it] 33%|███▎      | 4238/12825 [15:10:42<30:10:08, 12.65s/it] 33%|███▎      | 4239/12825 [15:10:55<30:08:28, 12.64s/it] 33%|███▎      | 4240/12825 [15:11:07<30:09:31, 12.65s/it] 33%|███▎      | 4241/12825 [15:11:27<35:31:30, 14.90s/it] 33%|███▎      | 4242/12825 [15:11:40<33:52:07, 14.21s/it] 33%|███▎      | 4243/12825 [15:11:53<32:41:07, 13.71s/it] 33%|███▎      | 4244/12825 [15:12:05<31:54:20, 13.39s/it] 33%|███▎      | 4245/12825 [15:12:18<31:20:07, 13.15s/it] 33%|███▎      | 4246/12825 [15:12:30<31:01:42, 13.02s/it] 33%|███▎      | 4247/12825 [15:12:43<30:43:31, 12.89s/it] 33%|███▎      | 4248/12825 [15:12:56<30:30:48, 12.81s/it] 33%|███▎      | 4249/12825 [15:13:08<30:20:53, 12.74s/it] 33%|███▎      | 4250/12825 [15:13:21<30:14:34, 12.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 117693.98lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101645.23lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4225] due to args.save_total_limit
 33%|███▎      | 4251/12825 [15:13:34<30:24:06, 12.76s/it] 33%|███▎      | 4252/12825 [15:13:46<30:17:43, 12.72s/it] 33%|███▎      | 4253/12825 [15:13:59<30:11:33, 12.68s/it] 33%|███▎      | 4254/12825 [15:14:12<30:08:15, 12.66s/it] 33%|███▎      | 4255/12825 [15:14:24<30:05:48, 12.64s/it] 33%|███▎      | 4256/12825 [15:14:37<30:03:24, 12.63s/it] 33%|███▎      | 4257/12825 [15:14:49<30:01:22, 12.61s/it] 33%|███▎      | 4258/12825 [15:15:02<30:02:40, 12.63s/it] 33%|███▎      | 4259/12825 [15:15:15<30:02:12, 12.62s/it] 33%|███▎      | 4260/12825 [15:15:27<30:02:29, 12.63s/it] 33%|███▎      | 4261/12825 [15:15:40<30:01:25, 12.62s/it] 33%|███▎      | 4262/12825 [15:15:52<30:01:13, 12.62s/it] 33%|███▎      | 4263/12825 [15:16:05<30:05:28, 12.65s/it] 33%|███▎      | 4264/12825 [15:16:18<30:09:47, 12.68s/it] 33%|███▎      | 4265/12825 [15:16:31<30:13:57, 12.71s/it] 33%|███▎      | 4266/12825 [15:16:44<30:17:42, 12.74s/it] 33%|███▎      | 4267/12825 [15:16:56<30:18:40, 12.75s/it] 33%|███▎      | 4268/12825 [15:17:09<30:18:50, 12.75s/it] 33%|███▎      | 4269/12825 [15:17:22<30:12:31, 12.71s/it] 33%|███▎      | 4270/12825 [15:17:34<30:08:06, 12.68s/it] 33%|███▎      | 4271/12825 [15:17:47<30:10:00, 12.70s/it] 33%|███▎      | 4272/12825 [15:18:00<30:07:20, 12.68s/it] 33%|███▎      | 4273/12825 [15:18:20<35:25:15, 14.91s/it] 33%|███▎      | 4274/12825 [15:18:32<33:47:31, 14.23s/it] 33%|███▎      | 4275/12825 [15:18:45<32:38:45, 13.75s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120372.63lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 78423.89lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4100] due to args.save_total_limit
 33%|███▎      | 4276/12825 [15:18:58<32:08:56, 13.54s/it] 33%|███▎      | 4277/12825 [15:19:11<31:28:30, 13.26s/it] 33%|███▎      | 4278/12825 [15:19:23<31:01:15, 13.07s/it] 33%|███▎      | 4279/12825 [15:19:36<30:40:49, 12.92s/it] 33%|███▎      | 4280/12825 [15:19:49<30:28:33, 12.84s/it] 33%|███▎      | 4281/12825 [15:20:01<30:19:02, 12.77s/it] 33%|███▎      | 4282/12825 [15:20:14<30:12:01, 12.73s/it] 33%|███▎      | 4283/12825 [15:20:26<30:07:15, 12.69s/it] 33%|███▎      | 4284/12825 [15:20:39<30:03:28, 12.67s/it] 33%|███▎      | 4285/12825 [15:20:52<30:00:38, 12.65s/it] 33%|███▎      | 4286/12825 [15:21:04<29:57:42, 12.63s/it] 33%|███▎      | 4287/12825 [15:21:17<29:58:15, 12.64s/it] 33%|███▎      | 4288/12825 [15:21:30<29:57:57, 12.64s/it] 33%|███▎      | 4289/12825 [15:21:42<29:55:25, 12.62s/it] 33%|███▎      | 4290/12825 [15:21:55<29:54:09, 12.61s/it] 33%|███▎      | 4291/12825 [15:22:07<29:53:08, 12.61s/it] 33%|███▎      | 4292/12825 [15:22:20<29:53:10, 12.61s/it] 33%|███▎      | 4293/12825 [15:22:33<29:53:43, 12.61s/it] 33%|███▎      | 4294/12825 [15:22:45<29:52:46, 12.61s/it] 33%|███▎      | 4295/12825 [15:22:58<29:53:18, 12.61s/it] 33%|███▎      | 4296/12825 [15:23:10<29:53:55, 12.62s/it] 34%|███▎      | 4297/12825 [15:23:23<29:53:10, 12.62s/it] 34%|███▎      | 4298/12825 [15:23:36<29:51:40, 12.61s/it] 34%|███▎      | 4299/12825 [15:23:48<29:50:18, 12.60s/it] 34%|███▎      | 4300/12825 [15:24:01<29:48:50, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120230.90lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103533.99lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4250] due to args.save_total_limit
 34%|███▎      | 4301/12825 [15:24:14<30:03:46, 12.70s/it] 34%|███▎      | 4302/12825 [15:24:26<30:00:13, 12.67s/it] 34%|███▎      | 4303/12825 [15:24:39<29:56:40, 12.65s/it] 34%|███▎      | 4304/12825 [15:24:52<29:55:05, 12.64s/it] 34%|███▎      | 4305/12825 [15:25:04<29:53:37, 12.63s/it] 34%|███▎      | 4306/12825 [15:25:24<35:02:35, 14.81s/it] 34%|███▎      | 4307/12825 [15:25:37<33:28:21, 14.15s/it] 34%|███▎      | 4308/12825 [15:25:49<32:21:08, 13.67s/it] 34%|███▎      | 4309/12825 [15:26:02<31:34:30, 13.35s/it] 34%|███▎      | 4310/12825 [15:26:14<31:03:50, 13.13s/it] 34%|███▎      | 4311/12825 [15:26:27<30:40:40, 12.97s/it] 34%|███▎      | 4312/12825 [15:26:40<30:25:10, 12.86s/it] 34%|███▎      | 4313/12825 [15:26:52<30:17:49, 12.81s/it] 34%|███▎      | 4314/12825 [15:27:05<30:08:36, 12.75s/it] 34%|███▎      | 4315/12825 [15:27:18<30:02:13, 12.71s/it] 34%|███▎      | 4316/12825 [15:27:30<29:59:40, 12.69s/it] 34%|███▎      | 4317/12825 [15:27:43<29:56:12, 12.67s/it] 34%|███▎      | 4318/12825 [15:27:55<29:54:06, 12.65s/it] 34%|███▎      | 4319/12825 [15:28:08<29:52:18, 12.64s/it] 34%|███▎      | 4320/12825 [15:28:21<29:49:21, 12.62s/it] 34%|███▎      | 4321/12825 [15:28:33<29:47:38, 12.61s/it] 34%|███▎      | 4322/12825 [15:28:46<29:47:57, 12.62s/it] 34%|███▎      | 4323/12825 [15:28:58<29:47:02, 12.61s/it] 34%|███▎      | 4324/12825 [15:29:11<29:45:37, 12.60s/it] 34%|███▎      | 4325/12825 [15:29:24<29:46:16, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120330.68lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103603.23lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4275] due to args.save_total_limit
 34%|███▎      | 4326/12825 [15:29:37<29:59:21, 12.70s/it] 34%|███▎      | 4327/12825 [15:29:49<29:54:35, 12.67s/it] 34%|███▎      | 4328/12825 [15:30:02<29:52:13, 12.66s/it] 34%|███▍      | 4329/12825 [15:30:14<29:50:28, 12.64s/it] 34%|███▍      | 4330/12825 [15:30:27<29:47:53, 12.63s/it] 34%|███▍      | 4331/12825 [15:30:40<29:46:27, 12.62s/it] 34%|███▍      | 4332/12825 [15:30:52<29:46:28, 12.62s/it] 34%|███▍      | 4333/12825 [15:31:05<29:47:03, 12.63s/it] 34%|███▍      | 4334/12825 [15:31:17<29:48:07, 12.64s/it] 34%|███▍      | 4335/12825 [15:31:30<29:48:53, 12.64s/it] 34%|███▍      | 4336/12825 [15:31:43<29:48:11, 12.64s/it] 34%|███▍      | 4337/12825 [15:31:55<29:47:11, 12.63s/it] 34%|███▍      | 4338/12825 [15:32:14<34:00:55, 14.43s/it] 34%|███▍      | 4339/12825 [15:32:27<32:43:17, 13.88s/it] 34%|███▍      | 4340/12825 [15:32:39<31:47:52, 13.49s/it] 34%|███▍      | 4341/12825 [15:32:52<31:10:40, 13.23s/it] 34%|███▍      | 4342/12825 [15:33:04<30:43:21, 13.04s/it] 34%|███▍      | 4343/12825 [15:33:17<30:25:23, 12.91s/it] 34%|███▍      | 4344/12825 [15:33:30<30:13:14, 12.83s/it] 34%|███▍      | 4345/12825 [15:33:42<30:05:31, 12.77s/it] 34%|███▍      | 4346/12825 [15:33:55<29:58:13, 12.72s/it] 34%|███▍      | 4347/12825 [15:34:07<29:52:11, 12.68s/it] 34%|███▍      | 4348/12825 [15:34:20<29:48:16, 12.66s/it] 34%|███▍      | 4349/12825 [15:34:33<29:51:28, 12.68s/it] 34%|███▍      | 4350/12825 [15:34:45<29:48:30, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120171.32lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103486.12lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4325] due to args.save_total_limit
 34%|███▍      | 4351/12825 [15:34:58<30:00:04, 12.75s/it] 34%|███▍      | 4352/12825 [15:35:11<29:52:51, 12.70s/it] 34%|███▍      | 4353/12825 [15:35:24<29:48:35, 12.67s/it] 34%|███▍      | 4354/12825 [15:35:36<29:45:33, 12.65s/it] 34%|███▍      | 4355/12825 [15:35:49<29:43:04, 12.63s/it] 34%|███▍      | 4356/12825 [15:36:01<29:41:26, 12.62s/it] 34%|███▍      | 4357/12825 [15:36:14<29:39:47, 12.61s/it] 34%|███▍      | 4358/12825 [15:36:27<29:41:03, 12.62s/it] 34%|███▍      | 4359/12825 [15:36:39<29:43:51, 12.64s/it] 34%|███▍      | 4360/12825 [15:36:52<29:46:14, 12.66s/it] 34%|███▍      | 4361/12825 [15:37:05<29:43:57, 12.65s/it] 34%|███▍      | 4362/12825 [15:37:17<29:43:36, 12.65s/it] 34%|███▍      | 4363/12825 [15:37:30<29:42:11, 12.64s/it] 34%|███▍      | 4364/12825 [15:37:43<29:43:07, 12.64s/it] 34%|███▍      | 4365/12825 [15:37:55<29:42:28, 12.64s/it] 34%|███▍      | 4366/12825 [15:38:08<29:42:25, 12.64s/it] 34%|███▍      | 4367/12825 [15:38:20<29:41:56, 12.64s/it] 34%|███▍      | 4368/12825 [15:38:33<29:40:24, 12.63s/it] 34%|███▍      | 4369/12825 [15:38:46<29:41:27, 12.64s/it] 34%|███▍      | 4370/12825 [15:39:08<36:21:03, 15.48s/it] 34%|███▍      | 4371/12825 [15:39:20<34:18:09, 14.61s/it] 34%|███▍      | 4372/12825 [15:39:33<32:54:03, 14.01s/it] 34%|███▍      | 4373/12825 [15:39:46<31:53:58, 13.59s/it] 34%|███▍      | 4374/12825 [15:39:58<31:11:18, 13.29s/it] 34%|███▍      | 4375/12825 [15:40:11<30:41:29, 13.08s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120283.13lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103553.40lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4350] due to args.save_total_limit
 34%|███▍      | 4376/12825 [15:40:24<30:39:10, 13.06s/it] 34%|███▍      | 4377/12825 [15:40:36<30:18:04, 12.91s/it] 34%|███▍      | 4378/12825 [15:40:49<30:04:47, 12.82s/it] 34%|███▍      | 4379/12825 [15:41:02<29:56:04, 12.76s/it] 34%|███▍      | 4380/12825 [15:41:14<29:50:16, 12.72s/it] 34%|███▍      | 4381/12825 [15:41:27<29:46:40, 12.70s/it] 34%|███▍      | 4382/12825 [15:41:39<29:42:48, 12.67s/it] 34%|███▍      | 4383/12825 [15:41:52<29:41:22, 12.66s/it] 34%|███▍      | 4384/12825 [15:42:05<29:38:52, 12.64s/it] 34%|███▍      | 4385/12825 [15:42:17<29:36:46, 12.63s/it] 34%|███▍      | 4386/12825 [15:42:30<29:37:03, 12.63s/it] 34%|███▍      | 4387/12825 [15:42:43<29:36:13, 12.63s/it] 34%|███▍      | 4388/12825 [15:42:55<29:35:39, 12.63s/it] 34%|███▍      | 4389/12825 [15:43:08<29:34:41, 12.62s/it] 34%|███▍      | 4390/12825 [15:43:20<29:33:34, 12.62s/it] 34%|███▍      | 4391/12825 [15:43:33<29:37:20, 12.64s/it] 34%|███▍      | 4392/12825 [15:43:46<29:35:16, 12.63s/it] 34%|███▍      | 4393/12825 [15:43:58<29:35:01, 12.63s/it] 34%|███▍      | 4394/12825 [15:44:11<29:34:08, 12.63s/it] 34%|███▍      | 4395/12825 [15:44:24<29:33:23, 12.62s/it] 34%|███▍      | 4396/12825 [15:44:36<29:34:56, 12.63s/it] 34%|███▍      | 4397/12825 [15:44:49<29:34:02, 12.63s/it] 34%|███▍      | 4398/12825 [15:45:02<29:35:36, 12.64s/it] 34%|███▍      | 4399/12825 [15:45:14<29:34:36, 12.64s/it] 34%|███▍      | 4400/12825 [15:45:27<29:34:11, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120264.35lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103635.18lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4300] due to args.save_total_limit
 34%|███▍      | 4401/12825 [15:45:40<29:47:06, 12.73s/it] 34%|███▍      | 4402/12825 [15:45:52<29:42:54, 12.70s/it] 34%|███▍      | 4403/12825 [15:46:12<34:47:22, 14.87s/it] 34%|███▍      | 4404/12825 [15:46:25<33:12:16, 14.20s/it] 34%|███▍      | 4405/12825 [15:46:38<32:05:13, 13.72s/it] 34%|███▍      | 4406/12825 [15:46:50<31:18:05, 13.38s/it] 34%|███▍      | 4407/12825 [15:47:03<30:46:47, 13.16s/it] 34%|███▍      | 4408/12825 [15:47:15<30:24:15, 13.00s/it] 34%|███▍      | 4409/12825 [15:47:28<30:08:43, 12.89s/it] 34%|███▍      | 4410/12825 [15:47:41<29:58:48, 12.83s/it] 34%|███▍      | 4411/12825 [15:47:53<29:49:28, 12.76s/it] 34%|███▍      | 4412/12825 [15:48:06<29:45:53, 12.74s/it] 34%|███▍      | 4413/12825 [15:48:19<29:45:23, 12.73s/it] 34%|███▍      | 4414/12825 [15:48:31<29:41:14, 12.71s/it] 34%|███▍      | 4415/12825 [15:48:44<29:38:06, 12.69s/it] 34%|███▍      | 4416/12825 [15:48:57<29:35:37, 12.67s/it] 34%|███▍      | 4417/12825 [15:49:09<29:35:20, 12.67s/it] 34%|███▍      | 4418/12825 [15:49:22<29:33:11, 12.66s/it] 34%|███▍      | 4419/12825 [15:49:35<29:40:20, 12.71s/it] 34%|███▍      | 4420/12825 [15:49:47<29:36:19, 12.68s/it] 34%|███▍      | 4421/12825 [15:50:00<29:33:37, 12.66s/it] 34%|███▍      | 4422/12825 [15:50:13<29:32:08, 12.65s/it] 34%|███▍      | 4423/12825 [15:50:25<29:30:54, 12.65s/it] 34%|███▍      | 4424/12825 [15:50:38<29:29:50, 12.64s/it] 35%|███▍      | 4425/12825 [15:50:50<29:27:44, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 88931.46lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 79494.06lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4375] due to args.save_total_limit
 35%|███▍      | 4426/12825 [15:51:04<29:46:48, 12.76s/it] 35%|███▍      | 4427/12825 [15:51:16<29:41:04, 12.72s/it] 35%|███▍      | 4428/12825 [15:51:29<29:36:34, 12.69s/it] 35%|███▍      | 4429/12825 [15:51:41<29:34:02, 12.68s/it] 35%|███▍      | 4430/12825 [15:51:54<29:31:38, 12.66s/it] 35%|███▍      | 4431/12825 [15:52:07<29:30:39, 12.66s/it] 35%|███▍      | 4432/12825 [15:52:19<29:29:24, 12.65s/it] 35%|███▍      | 4433/12825 [15:52:32<29:28:38, 12.65s/it] 35%|███▍      | 4434/12825 [15:52:45<29:29:18, 12.65s/it] 35%|███▍      | 4435/12825 [15:53:05<34:38:41, 14.87s/it] 35%|███▍      | 4436/12825 [15:53:17<33:03:15, 14.18s/it] 35%|███▍      | 4437/12825 [15:53:30<31:57:29, 13.72s/it] 35%|███▍      | 4438/12825 [15:53:43<31:11:28, 13.39s/it] 35%|███▍      | 4439/12825 [15:53:55<30:39:22, 13.16s/it] 35%|███▍      | 4440/12825 [15:54:08<30:16:51, 13.00s/it] 35%|███▍      | 4441/12825 [15:54:20<30:01:08, 12.89s/it] 35%|███▍      | 4442/12825 [15:54:33<29:49:39, 12.81s/it] 35%|███▍      | 4443/12825 [15:54:46<29:42:54, 12.76s/it] 35%|███▍      | 4444/12825 [15:54:58<29:37:58, 12.73s/it] 35%|███▍      | 4445/12825 [15:55:11<29:33:18, 12.70s/it] 35%|███▍      | 4446/12825 [15:55:24<29:31:52, 12.69s/it] 35%|███▍      | 4447/12825 [15:55:36<29:27:39, 12.66s/it] 35%|███▍      | 4448/12825 [15:55:49<29:25:42, 12.65s/it] 35%|███▍      | 4449/12825 [15:56:01<29:23:27, 12.63s/it] 35%|███▍      | 4450/12825 [15:56:14<29:22:33, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120279.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103557.00lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4400] due to args.save_total_limit
 35%|███▍      | 4451/12825 [15:56:27<29:38:49, 12.75s/it] 35%|███▍      | 4452/12825 [15:56:40<29:34:41, 12.72s/it] 35%|███▍      | 4453/12825 [15:56:52<29:30:40, 12.69s/it] 35%|███▍      | 4454/12825 [15:57:05<29:27:19, 12.67s/it] 35%|███▍      | 4455/12825 [15:57:18<29:26:58, 12.67s/it] 35%|███▍      | 4456/12825 [15:57:30<29:26:04, 12.66s/it] 35%|███▍      | 4457/12825 [15:57:43<29:22:55, 12.64s/it] 35%|███▍      | 4458/12825 [15:57:56<29:25:01, 12.66s/it] 35%|███▍      | 4459/12825 [15:58:08<29:23:13, 12.65s/it] 35%|███▍      | 4460/12825 [15:58:21<29:21:08, 12.63s/it] 35%|███▍      | 4461/12825 [15:58:33<29:21:40, 12.64s/it] 35%|███▍      | 4462/12825 [15:58:46<29:22:18, 12.64s/it] 35%|███▍      | 4463/12825 [15:58:59<29:21:18, 12.64s/it] 35%|███▍      | 4464/12825 [15:59:11<29:20:22, 12.63s/it] 35%|███▍      | 4465/12825 [15:59:24<29:20:04, 12.63s/it] 35%|███▍      | 4466/12825 [15:59:37<29:19:36, 12.63s/it] 35%|███▍      | 4467/12825 [15:59:57<34:36:05, 14.90s/it] 35%|███▍      | 4468/12825 [16:00:09<32:59:51, 14.21s/it] 35%|███▍      | 4469/12825 [16:00:22<31:51:44, 13.73s/it] 35%|███▍      | 4470/12825 [16:00:35<31:06:25, 13.40s/it] 35%|███▍      | 4471/12825 [16:00:47<30:33:13, 13.17s/it] 35%|███▍      | 4472/12825 [16:01:00<30:10:44, 13.01s/it] 35%|███▍      | 4473/12825 [16:01:13<29:54:41, 12.89s/it] 35%|███▍      | 4474/12825 [16:01:25<29:42:51, 12.81s/it] 35%|███▍      | 4475/12825 [16:01:38<29:34:47, 12.75s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120299.62lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103574.24lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4425] due to args.save_total_limit
 35%|███▍      | 4476/12825 [16:01:51<29:42:47, 12.81s/it] 35%|███▍      | 4477/12825 [16:02:03<29:38:36, 12.78s/it] 35%|███▍      | 4478/12825 [16:02:16<29:30:32, 12.73s/it] 35%|███▍      | 4479/12825 [16:02:29<29:26:06, 12.70s/it] 35%|███▍      | 4480/12825 [16:02:41<29:23:21, 12.68s/it] 35%|███▍      | 4481/12825 [16:02:54<29:24:58, 12.69s/it] 35%|███▍      | 4482/12825 [16:03:07<29:21:47, 12.67s/it] 35%|███▍      | 4483/12825 [16:03:19<29:22:55, 12.68s/it] 35%|███▍      | 4484/12825 [16:03:32<29:20:53, 12.67s/it] 35%|███▍      | 4485/12825 [16:03:45<29:18:34, 12.65s/it] 35%|███▍      | 4486/12825 [16:03:57<29:20:49, 12.67s/it] 35%|███▍      | 4487/12825 [16:04:10<29:24:39, 12.70s/it] 35%|███▍      | 4488/12825 [16:04:23<29:25:10, 12.70s/it] 35%|███▌      | 4489/12825 [16:04:36<29:30:07, 12.74s/it] 35%|███▌      | 4490/12825 [16:04:48<29:34:21, 12.77s/it] 35%|███▌      | 4491/12825 [16:05:01<29:32:12, 12.76s/it] 35%|███▌      | 4492/12825 [16:05:14<29:30:44, 12.75s/it] 35%|███▌      | 4493/12825 [16:05:27<29:31:59, 12.76s/it] 35%|███▌      | 4494/12825 [16:05:39<29:30:45, 12.75s/it] 35%|███▌      | 4495/12825 [16:05:52<29:30:21, 12.75s/it] 35%|███▌      | 4496/12825 [16:06:05<29:30:45, 12.76s/it] 35%|███▌      | 4497/12825 [16:06:18<29:29:35, 12.75s/it] 35%|███▌      | 4498/12825 [16:06:30<29:28:43, 12.74s/it] 35%|███▌      | 4499/12825 [16:06:43<29:26:42, 12.73s/it] 35%|███▌      | 4500/12825 [16:07:04<34:51:00, 15.07s/it]                                                           35%|███▌      | 4500/12825 [16:07:04<34:51:00, 15.07s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120218.90lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103494.54lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4450] due to args.save_total_limit
 35%|███▌      | 4501/12825 [16:07:17<33:20:39, 14.42s/it] 35%|███▌      | 4502/12825 [16:07:29<32:01:38, 13.85s/it] 35%|███▌      | 4503/12825 [16:07:42<31:07:47, 13.47s/it] 35%|███▌      | 4504/12825 [16:07:54<30:31:15, 13.20s/it] 35%|███▌      | 4505/12825 [16:08:07<30:05:29, 13.02s/it] 35%|███▌      | 4506/12825 [16:08:19<29:46:51, 12.89s/it] 35%|███▌      | 4507/12825 [16:08:32<29:34:34, 12.80s/it] 35%|███▌      | 4508/12825 [16:08:45<29:27:08, 12.75s/it] 35%|███▌      | 4509/12825 [16:08:57<29:20:37, 12.70s/it] 35%|███▌      | 4510/12825 [16:09:10<29:17:15, 12.68s/it] 35%|███▌      | 4511/12825 [16:09:22<29:13:37, 12.66s/it] 35%|███▌      | 4512/12825 [16:09:35<29:11:13, 12.64s/it] 35%|███▌      | 4513/12825 [16:09:48<29:09:45, 12.63s/it] 35%|███▌      | 4514/12825 [16:10:00<29:09:15, 12.63s/it] 35%|███▌      | 4515/12825 [16:10:13<29:07:34, 12.62s/it] 35%|███▌      | 4516/12825 [16:10:25<29:06:45, 12.61s/it] 35%|███▌      | 4517/12825 [16:10:38<29:05:31, 12.61s/it] 35%|███▌      | 4518/12825 [16:10:51<29:06:00, 12.61s/it] 35%|███▌      | 4519/12825 [16:11:03<29:04:25, 12.60s/it] 35%|███▌      | 4520/12825 [16:11:16<29:04:09, 12.60s/it] 35%|███▌      | 4521/12825 [16:11:28<29:04:18, 12.60s/it] 35%|███▌      | 4522/12825 [16:11:41<29:03:26, 12.60s/it] 35%|███▌      | 4523/12825 [16:11:54<29:03:20, 12.60s/it] 35%|███▌      | 4524/12825 [16:12:06<29:03:16, 12.60s/it] 35%|███▌      | 4525/12825 [16:12:19<29:01:40, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120205.38lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103599.44lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4475] due to args.save_total_limit
 35%|███▌      | 4526/12825 [16:12:32<29:13:28, 12.68s/it] 35%|███▌      | 4527/12825 [16:12:44<29:09:12, 12.65s/it] 35%|███▌      | 4528/12825 [16:12:57<29:06:33, 12.63s/it] 35%|███▌      | 4529/12825 [16:13:09<29:03:03, 12.61s/it] 35%|███▌      | 4530/12825 [16:13:22<29:00:23, 12.59s/it] 35%|███▌      | 4531/12825 [16:13:35<28:59:04, 12.58s/it] 35%|███▌      | 4532/12825 [16:13:55<34:14:04, 14.86s/it] 35%|███▌      | 4533/12825 [16:14:07<32:39:48, 14.18s/it] 35%|███▌      | 4534/12825 [16:14:20<31:34:04, 13.71s/it] 35%|███▌      | 4535/12825 [16:14:32<30:46:32, 13.36s/it] 35%|███▌      | 4536/12825 [16:14:45<30:15:38, 13.14s/it] 35%|███▌      | 4537/12825 [16:14:58<29:53:49, 12.99s/it] 35%|███▌      | 4538/12825 [16:15:10<29:36:17, 12.86s/it] 35%|███▌      | 4539/12825 [16:15:23<29:24:34, 12.78s/it] 35%|███▌      | 4540/12825 [16:15:35<29:16:03, 12.72s/it] 35%|███▌      | 4541/12825 [16:15:48<29:11:24, 12.69s/it] 35%|███▌      | 4542/12825 [16:16:01<29:06:43, 12.65s/it] 35%|███▌      | 4543/12825 [16:16:13<29:03:22, 12.63s/it] 35%|███▌      | 4544/12825 [16:16:26<29:01:42, 12.62s/it] 35%|███▌      | 4545/12825 [16:16:38<28:58:09, 12.60s/it] 35%|███▌      | 4546/12825 [16:16:51<28:58:25, 12.60s/it] 35%|███▌      | 4547/12825 [16:17:04<28:57:52, 12.60s/it] 35%|███▌      | 4548/12825 [16:17:16<28:55:56, 12.58s/it] 35%|███▌      | 4549/12825 [16:17:29<28:56:00, 12.59s/it] 35%|███▌      | 4550/12825 [16:17:41<28:55:22, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120401.81lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103727.83lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4500] due to args.save_total_limit
 35%|███▌      | 4551/12825 [16:17:54<29:10:24, 12.69s/it] 35%|███▌      | 4552/12825 [16:18:07<29:05:08, 12.66s/it] 36%|███▌      | 4553/12825 [16:18:19<29:01:12, 12.63s/it] 36%|███▌      | 4554/12825 [16:18:32<29:00:28, 12.63s/it] 36%|███▌      | 4555/12825 [16:18:45<28:56:43, 12.60s/it] 36%|███▌      | 4556/12825 [16:18:57<28:55:37, 12.59s/it] 36%|███▌      | 4557/12825 [16:19:10<28:56:21, 12.60s/it] 36%|███▌      | 4558/12825 [16:19:22<28:56:26, 12.60s/it] 36%|███▌      | 4559/12825 [16:19:35<28:56:13, 12.60s/it] 36%|███▌      | 4560/12825 [16:19:48<29:00:52, 12.64s/it] 36%|███▌      | 4561/12825 [16:20:00<28:59:30, 12.63s/it] 36%|███▌      | 4562/12825 [16:20:13<28:56:53, 12.61s/it] 36%|███▌      | 4563/12825 [16:20:25<28:55:05, 12.60s/it] 36%|███▌      | 4564/12825 [16:20:38<28:52:58, 12.59s/it] 36%|███▌      | 4565/12825 [16:20:58<34:08:49, 14.88s/it] 36%|███▌      | 4566/12825 [16:21:11<32:34:17, 14.20s/it] 36%|███▌      | 4567/12825 [16:21:23<31:27:57, 13.72s/it] 36%|███▌      | 4568/12825 [16:21:36<30:40:45, 13.38s/it] 36%|███▌      | 4569/12825 [16:21:49<30:07:25, 13.14s/it] 36%|███▌      | 4570/12825 [16:22:01<29:44:54, 12.97s/it] 36%|███▌      | 4571/12825 [16:22:14<29:28:11, 12.85s/it] 36%|███▌      | 4572/12825 [16:22:26<29:16:52, 12.77s/it] 36%|███▌      | 4573/12825 [16:22:39<29:09:07, 12.72s/it] 36%|███▌      | 4574/12825 [16:22:51<29:03:27, 12.68s/it] 36%|███▌      | 4575/12825 [16:23:04<29:02:03, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120246.09lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103524.34lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4550] due to args.save_total_limit
 36%|███▌      | 4576/12825 [16:23:17<29:13:12, 12.75s/it] 36%|███▌      | 4577/12825 [16:23:30<29:07:40, 12.71s/it] 36%|███▌      | 4578/12825 [16:23:42<29:02:52, 12.68s/it] 36%|███▌      | 4579/12825 [16:23:55<28:59:39, 12.66s/it] 36%|███▌      | 4580/12825 [16:24:07<28:56:30, 12.64s/it] 36%|███▌      | 4581/12825 [16:24:20<28:55:39, 12.63s/it] 36%|███▌      | 4582/12825 [16:24:33<28:53:24, 12.62s/it] 36%|███▌      | 4583/12825 [16:24:45<28:51:51, 12.61s/it] 36%|███▌      | 4584/12825 [16:24:58<28:52:33, 12.61s/it] 36%|███▌      | 4585/12825 [16:25:11<28:52:10, 12.61s/it] 36%|███▌      | 4586/12825 [16:25:23<28:52:14, 12.61s/it] 36%|███▌      | 4587/12825 [16:25:36<28:52:07, 12.62s/it] 36%|███▌      | 4588/12825 [16:25:48<28:52:30, 12.62s/it] 36%|███▌      | 4589/12825 [16:26:01<28:52:01, 12.62s/it] 36%|███▌      | 4590/12825 [16:26:14<28:51:10, 12.61s/it] 36%|███▌      | 4591/12825 [16:26:26<28:51:09, 12.61s/it] 36%|███▌      | 4592/12825 [16:26:39<28:51:10, 12.62s/it] 36%|███▌      | 4593/12825 [16:26:51<28:49:24, 12.60s/it] 36%|███▌      | 4594/12825 [16:27:04<28:50:37, 12.62s/it] 36%|███▌      | 4595/12825 [16:27:17<28:49:51, 12.61s/it] 36%|███▌      | 4596/12825 [16:27:29<28:49:50, 12.61s/it] 36%|███▌      | 4597/12825 [16:27:50<34:32:52, 15.12s/it] 36%|███▌      | 4598/12825 [16:28:03<32:48:52, 14.36s/it] 36%|███▌      | 4599/12825 [16:28:15<31:35:09, 13.82s/it] 36%|███▌      | 4600/12825 [16:28:28<30:44:53, 13.46s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120341.16lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103591.10lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4575] due to args.save_total_limit
 36%|███▌      | 4601/12825 [16:28:41<30:23:15, 13.30s/it] 36%|███▌      | 4602/12825 [16:28:54<29:54:14, 13.09s/it] 36%|███▌      | 4603/12825 [16:29:06<29:34:15, 12.95s/it] 36%|███▌      | 4604/12825 [16:29:19<29:27:47, 12.90s/it] 36%|███▌      | 4605/12825 [16:29:32<29:15:10, 12.81s/it] 36%|███▌      | 4606/12825 [16:29:44<29:05:59, 12.75s/it] 36%|███▌      | 4607/12825 [16:29:57<29:05:12, 12.74s/it] 36%|███▌      | 4608/12825 [16:30:09<28:59:35, 12.70s/it] 36%|███▌      | 4609/12825 [16:30:22<28:56:59, 12.68s/it] 36%|███▌      | 4610/12825 [16:30:35<28:52:58, 12.66s/it] 36%|███▌      | 4611/12825 [16:30:47<28:49:33, 12.63s/it] 36%|███▌      | 4612/12825 [16:31:00<28:49:24, 12.63s/it] 36%|███▌      | 4613/12825 [16:31:13<28:51:54, 12.65s/it] 36%|███▌      | 4614/12825 [16:31:25<28:54:41, 12.68s/it] 36%|███▌      | 4615/12825 [16:31:38<28:58:17, 12.70s/it] 36%|███▌      | 4616/12825 [16:31:46<25:45:11, 11.29s/it] 36%|███▌      | 4617/12825 [16:31:47<18:35:15,  8.15s/it] 36%|███▌      | 4618/12825 [16:32:13<30:39:59, 13.45s/it] 36%|███▌      | 4619/12825 [16:32:26<30:14:26, 13.27s/it] 36%|███▌      | 4620/12825 [16:32:38<29:52:46, 13.11s/it] 36%|███▌      | 4621/12825 [16:32:51<29:37:21, 13.00s/it] 36%|███▌      | 4622/12825 [16:33:04<29:27:12, 12.93s/it] 36%|███▌      | 4623/12825 [16:33:17<29:20:20, 12.88s/it] 36%|███▌      | 4624/12825 [16:33:29<29:15:03, 12.84s/it] 36%|███▌      | 4625/12825 [16:33:42<29:12:02, 12.82s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120158.06lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103412.13lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4600] due to args.save_total_limit
 36%|███▌      | 4626/12825 [16:33:55<29:17:00, 12.86s/it] 36%|███▌      | 4627/12825 [16:34:08<29:05:17, 12.77s/it] 36%|███▌      | 4628/12825 [16:34:20<28:56:36, 12.71s/it] 36%|███▌      | 4629/12825 [16:34:40<34:00:39, 14.94s/it] 36%|███▌      | 4630/12825 [16:34:53<32:23:42, 14.23s/it] 36%|███▌      | 4631/12825 [16:35:06<31:16:16, 13.74s/it] 36%|███▌      | 4632/12825 [16:35:18<30:30:09, 13.40s/it] 36%|███▌      | 4633/12825 [16:35:31<29:56:59, 13.16s/it] 36%|███▌      | 4634/12825 [16:35:43<29:31:51, 12.98s/it] 36%|███▌      | 4635/12825 [16:35:56<29:14:17, 12.85s/it] 36%|███▌      | 4636/12825 [16:36:08<29:04:26, 12.78s/it] 36%|███▌      | 4637/12825 [16:36:21<28:57:13, 12.73s/it] 36%|███▌      | 4638/12825 [16:36:34<28:52:04, 12.69s/it] 36%|███▌      | 4639/12825 [16:36:46<28:47:53, 12.66s/it] 36%|███▌      | 4640/12825 [16:36:59<28:44:02, 12.64s/it] 36%|███▌      | 4641/12825 [16:37:11<28:43:03, 12.63s/it] 36%|███▌      | 4642/12825 [16:37:24<28:40:54, 12.62s/it] 36%|███▌      | 4643/12825 [16:37:37<28:40:55, 12.62s/it] 36%|███▌      | 4644/12825 [16:37:49<28:39:20, 12.61s/it] 36%|███▌      | 4645/12825 [16:38:02<28:36:43, 12.59s/it] 36%|███▌      | 4646/12825 [16:38:14<28:36:19, 12.59s/it] 36%|███▌      | 4647/12825 [16:38:27<28:41:00, 12.63s/it] 36%|███▌      | 4648/12825 [16:38:40<28:48:15, 12.68s/it] 36%|███▌      | 4649/12825 [16:38:53<28:45:41, 12.66s/it] 36%|███▋      | 4650/12825 [16:39:05<28:43:00, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120274.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103403.25lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4625] due to args.save_total_limit
 36%|███▋      | 4651/12825 [16:39:18<28:56:43, 12.75s/it] 36%|███▋      | 4652/12825 [16:39:31<28:50:41, 12.71s/it] 36%|███▋      | 4653/12825 [16:39:43<28:47:05, 12.68s/it] 36%|███▋      | 4654/12825 [16:39:56<28:43:43, 12.66s/it] 36%|███▋      | 4655/12825 [16:40:09<28:42:12, 12.65s/it] 36%|███▋      | 4656/12825 [16:40:21<28:39:51, 12.63s/it] 36%|███▋      | 4657/12825 [16:40:34<28:37:08, 12.61s/it] 36%|███▋      | 4658/12825 [16:40:47<28:42:02, 12.65s/it] 36%|███▋      | 4659/12825 [16:40:59<28:39:30, 12.63s/it] 36%|███▋      | 4660/12825 [16:41:12<28:38:07, 12.63s/it] 36%|███▋      | 4661/12825 [16:41:24<28:38:00, 12.63s/it] 36%|███▋      | 4662/12825 [16:41:45<33:46:05, 14.89s/it] 36%|███▋      | 4663/12825 [16:41:57<32:11:10, 14.20s/it] 36%|███▋      | 4664/12825 [16:42:10<31:06:48, 13.72s/it] 36%|███▋      | 4665/12825 [16:42:22<30:21:31, 13.39s/it] 36%|███▋      | 4666/12825 [16:42:35<29:48:22, 13.15s/it] 36%|███▋      | 4667/12825 [16:42:47<29:24:03, 12.97s/it] 36%|███▋      | 4668/12825 [16:43:00<29:09:38, 12.87s/it] 36%|███▋      | 4669/12825 [16:43:13<29:00:25, 12.80s/it] 36%|███▋      | 4670/12825 [16:43:25<28:51:39, 12.74s/it] 36%|███▋      | 4671/12825 [16:43:38<28:46:14, 12.70s/it] 36%|███▋      | 4672/12825 [16:43:51<28:46:11, 12.70s/it] 36%|███▋      | 4673/12825 [16:44:03<28:43:20, 12.68s/it] 36%|███▋      | 4674/12825 [16:44:16<28:39:57, 12.66s/it] 36%|███▋      | 4675/12825 [16:44:29<28:36:20, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120188.16lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103509.48lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4650] due to args.save_total_limit
 36%|███▋      | 4676/12825 [16:44:41<28:47:29, 12.72s/it] 36%|███▋      | 4677/12825 [16:44:54<28:41:58, 12.68s/it] 36%|███▋      | 4678/12825 [16:45:07<28:39:50, 12.67s/it] 36%|███▋      | 4679/12825 [16:45:19<28:38:18, 12.66s/it] 36%|███▋      | 4680/12825 [16:45:32<28:36:29, 12.64s/it] 36%|███▋      | 4681/12825 [16:45:44<28:33:00, 12.62s/it] 37%|███▋      | 4682/12825 [16:45:57<28:36:33, 12.65s/it] 37%|███▋      | 4683/12825 [16:46:10<28:36:04, 12.65s/it] 37%|███▋      | 4684/12825 [16:46:22<28:34:03, 12.63s/it] 37%|███▋      | 4685/12825 [16:46:35<28:32:19, 12.62s/it] 37%|███▋      | 4686/12825 [16:46:48<28:31:15, 12.62s/it] 37%|███▋      | 4687/12825 [16:47:00<28:30:34, 12.61s/it] 37%|███▋      | 4688/12825 [16:47:13<28:30:16, 12.61s/it] 37%|███▋      | 4689/12825 [16:47:25<28:28:55, 12.60s/it] 37%|███▋      | 4690/12825 [16:47:38<28:29:48, 12.61s/it] 37%|███▋      | 4691/12825 [16:47:51<28:29:20, 12.61s/it] 37%|███▋      | 4692/12825 [16:48:03<28:29:21, 12.61s/it] 37%|███▋      | 4693/12825 [16:48:16<28:29:12, 12.61s/it] 37%|███▋      | 4694/12825 [16:48:36<33:38:08, 14.89s/it] 37%|███▋      | 4695/12825 [16:48:49<32:03:44, 14.20s/it] 37%|███▋      | 4696/12825 [16:49:01<30:57:46, 13.71s/it] 37%|███▋      | 4697/12825 [16:49:14<30:12:11, 13.38s/it] 37%|███▋      | 4698/12825 [16:49:27<29:43:39, 13.17s/it] 37%|███▋      | 4699/12825 [16:49:39<29:19:28, 12.99s/it] 37%|███▋      | 4700/12825 [16:49:52<29:04:02, 12.88s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120133.71lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103494.35lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4675] due to args.save_total_limit
 37%|███▋      | 4701/12825 [16:50:05<29:13:07, 12.95s/it] 37%|███▋      | 4702/12825 [16:50:18<29:04:03, 12.88s/it] 37%|███▋      | 4703/12825 [16:50:30<28:57:26, 12.84s/it] 37%|███▋      | 4704/12825 [16:50:43<28:51:02, 12.79s/it] 37%|███▋      | 4705/12825 [16:50:56<28:49:08, 12.78s/it] 37%|███▋      | 4706/12825 [16:51:08<28:46:44, 12.76s/it] 37%|███▋      | 4707/12825 [16:51:21<28:45:59, 12.76s/it] 37%|███▋      | 4708/12825 [16:51:34<28:44:27, 12.75s/it] 37%|███▋      | 4709/12825 [16:51:47<28:44:37, 12.75s/it] 37%|███▋      | 4710/12825 [16:51:59<28:43:39, 12.74s/it] 37%|███▋      | 4711/12825 [16:52:12<28:43:46, 12.75s/it] 37%|███▋      | 4712/12825 [16:52:25<28:42:25, 12.74s/it] 37%|███▋      | 4713/12825 [16:52:38<28:42:14, 12.74s/it] 37%|███▋      | 4714/12825 [16:52:50<28:41:32, 12.73s/it] 37%|███▋      | 4715/12825 [16:53:03<28:41:22, 12.74s/it] 37%|███▋      | 4716/12825 [16:53:16<28:42:08, 12.74s/it] 37%|███▋      | 4717/12825 [16:53:29<28:41:40, 12.74s/it] 37%|███▋      | 4718/12825 [16:53:41<28:40:35, 12.73s/it] 37%|███▋      | 4719/12825 [16:53:54<28:42:10, 12.75s/it] 37%|███▋      | 4720/12825 [16:54:07<28:41:21, 12.74s/it] 37%|███▋      | 4721/12825 [16:54:20<28:40:31, 12.74s/it] 37%|███▋      | 4722/12825 [16:54:32<28:38:47, 12.73s/it] 37%|███▋      | 4723/12825 [16:54:45<28:38:43, 12.73s/it] 37%|███▋      | 4724/12825 [16:54:58<28:38:28, 12.73s/it] 37%|███▋      | 4725/12825 [16:55:10<28:38:19, 12.73s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120243.92lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103378.24lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4725
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4725/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4725/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4700] due to args.save_total_limit
 37%|███▋      | 4726/12825 [16:55:23<28:52:01, 12.83s/it] 37%|███▋      | 4727/12825 [16:55:44<33:56:56, 15.09s/it] 37%|███▋      | 4728/12825 [16:55:57<32:21:00, 14.38s/it] 37%|███▋      | 4729/12825 [16:56:09<31:13:38, 13.89s/it] 37%|███▋      | 4730/12825 [16:56:22<30:26:02, 13.53s/it] 37%|███▋      | 4731/12825 [16:56:35<29:57:27, 13.32s/it] 37%|███▋      | 4732/12825 [16:56:48<30:08:31, 13.41s/it] 37%|███▋      | 4733/12825 [16:57:01<29:39:10, 13.19s/it] 37%|███▋      | 4734/12825 [16:57:14<29:24:35, 13.09s/it] 37%|███▋      | 4735/12825 [16:57:27<29:09:54, 12.98s/it] 37%|███▋      | 4736/12825 [16:57:39<28:59:20, 12.90s/it] 37%|███▋      | 4737/12825 [16:57:52<28:51:15, 12.84s/it] 37%|███▋      | 4738/12825 [16:58:05<28:45:51, 12.80s/it] 37%|███▋      | 4739/12825 [16:58:18<28:42:09, 12.78s/it] 37%|███▋      | 4740/12825 [16:58:30<28:40:30, 12.77s/it] 37%|███▋      | 4741/12825 [16:58:43<28:38:10, 12.75s/it] 37%|███▋      | 4742/12825 [16:58:56<28:37:40, 12.75s/it] 37%|███▋      | 4743/12825 [16:59:09<28:37:34, 12.75s/it] 37%|███▋      | 4744/12825 [16:59:21<28:36:44, 12.75s/it] 37%|███▋      | 4745/12825 [16:59:34<28:35:59, 12.74s/it] 37%|███▋      | 4746/12825 [16:59:47<28:34:53, 12.74s/it] 37%|███▋      | 4747/12825 [16:59:59<28:34:05, 12.73s/it] 37%|███▋      | 4748/12825 [17:00:12<28:33:37, 12.73s/it] 37%|███▋      | 4749/12825 [17:00:25<28:33:49, 12.73s/it] 37%|███▋      | 4750/12825 [17:00:38<28:34:33, 12.74s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 117704.50lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101705.94lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4750
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4750/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4750/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4525] due to args.save_total_limit
 37%|███▋      | 4751/12825 [17:00:51<28:41:49, 12.80s/it] 37%|███▋      | 4752/12825 [17:01:03<28:33:39, 12.74s/it] 37%|███▋      | 4753/12825 [17:01:16<28:28:25, 12.70s/it] 37%|███▋      | 4754/12825 [17:01:28<28:24:37, 12.67s/it] 37%|███▋      | 4755/12825 [17:01:41<28:21:10, 12.65s/it] 37%|███▋      | 4756/12825 [17:01:54<28:19:34, 12.64s/it] 37%|███▋      | 4757/12825 [17:02:06<28:18:05, 12.63s/it] 37%|███▋      | 4758/12825 [17:02:19<28:16:48, 12.62s/it] 37%|███▋      | 4759/12825 [17:02:39<33:17:32, 14.86s/it] 37%|███▋      | 4760/12825 [17:02:51<31:44:55, 14.17s/it] 37%|███▋      | 4761/12825 [17:03:04<30:40:47, 13.70s/it] 37%|███▋      | 4762/12825 [17:03:17<29:55:25, 13.36s/it] 37%|███▋      | 4763/12825 [17:03:29<29:23:30, 13.12s/it] 37%|███▋      | 4764/12825 [17:03:42<29:01:12, 12.96s/it] 37%|███▋      | 4765/12825 [17:03:54<28:45:41, 12.85s/it] 37%|███▋      | 4766/12825 [17:04:07<28:33:54, 12.76s/it] 37%|███▋      | 4767/12825 [17:04:19<28:25:42, 12.70s/it] 37%|███▋      | 4768/12825 [17:04:32<28:21:15, 12.67s/it] 37%|███▋      | 4769/12825 [17:04:45<28:17:16, 12.64s/it] 37%|███▋      | 4770/12825 [17:04:57<28:14:28, 12.62s/it] 37%|███▋      | 4771/12825 [17:05:10<28:11:55, 12.60s/it] 37%|███▋      | 4772/12825 [17:05:22<28:10:02, 12.59s/it] 37%|███▋      | 4773/12825 [17:05:35<28:14:40, 12.63s/it] 37%|███▋      | 4774/12825 [17:05:48<28:20:00, 12.67s/it] 37%|███▋      | 4775/12825 [17:06:00<28:18:14, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120184.46lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103437.25lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4775
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4775/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4775/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4725] due to args.save_total_limit
 37%|███▋      | 4776/12825 [17:06:14<28:38:40, 12.81s/it] 37%|███▋      | 4777/12825 [17:06:26<28:36:54, 12.80s/it] 37%|███▋      | 4778/12825 [17:06:39<28:36:37, 12.80s/it] 37%|███▋      | 4779/12825 [17:06:52<28:32:20, 12.77s/it] 37%|███▋      | 4780/12825 [17:07:05<28:29:37, 12.75s/it] 37%|███▋      | 4781/12825 [17:07:17<28:28:42, 12.75s/it] 37%|███▋      | 4782/12825 [17:07:30<28:28:06, 12.74s/it] 37%|███▋      | 4783/12825 [17:07:43<28:28:59, 12.75s/it] 37%|███▋      | 4784/12825 [17:07:56<28:28:17, 12.75s/it] 37%|███▋      | 4785/12825 [17:08:08<28:28:59, 12.75s/it] 37%|███▋      | 4786/12825 [17:08:21<28:26:31, 12.74s/it] 37%|███▋      | 4787/12825 [17:08:34<28:28:06, 12.75s/it] 37%|███▋      | 4788/12825 [17:08:47<28:26:36, 12.74s/it] 37%|███▋      | 4789/12825 [17:08:59<28:25:43, 12.74s/it] 37%|███▋      | 4790/12825 [17:09:12<28:28:45, 12.76s/it] 37%|███▋      | 4791/12825 [17:09:34<34:21:28, 15.40s/it] 37%|███▋      | 4792/12825 [17:09:46<32:33:17, 14.59s/it] 37%|███▋      | 4793/12825 [17:09:59<31:19:25, 14.04s/it] 37%|███▋      | 4794/12825 [17:10:12<30:27:02, 13.65s/it] 37%|███▋      | 4795/12825 [17:10:25<29:52:05, 13.39s/it] 37%|███▋      | 4796/12825 [17:10:37<29:25:42, 13.19s/it] 37%|███▋      | 4797/12825 [17:10:50<29:06:51, 13.06s/it] 37%|███▋      | 4798/12825 [17:11:03<28:51:35, 12.94s/it] 37%|███▋      | 4799/12825 [17:11:16<28:43:10, 12.88s/it] 37%|███▋      | 4800/12825 [17:11:28<28:36:33, 12.83s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120480.46lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103697.63lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4800
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4800/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4800/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4750] due to args.save_total_limit
 37%|███▋      | 4801/12825 [17:11:41<28:44:38, 12.90s/it] 37%|███▋      | 4802/12825 [17:11:54<28:33:24, 12.81s/it] 37%|███▋      | 4803/12825 [17:12:07<28:25:18, 12.75s/it] 37%|███▋      | 4804/12825 [17:12:19<28:20:04, 12.72s/it] 37%|███▋      | 4805/12825 [17:12:32<28:14:27, 12.68s/it] 37%|███▋      | 4806/12825 [17:12:44<28:14:41, 12.68s/it] 37%|███▋      | 4807/12825 [17:12:57<28:10:21, 12.65s/it] 37%|███▋      | 4808/12825 [17:13:10<28:07:48, 12.63s/it] 37%|███▋      | 4809/12825 [17:13:22<28:06:43, 12.63s/it] 38%|███▊      | 4810/12825 [17:13:35<28:05:43, 12.62s/it] 38%|███▊      | 4811/12825 [17:13:47<28:04:29, 12.61s/it] 38%|███▊      | 4812/12825 [17:14:00<28:05:56, 12.62s/it] 38%|███▊      | 4813/12825 [17:14:13<28:05:44, 12.62s/it] 38%|███▊      | 4814/12825 [17:14:25<28:04:28, 12.62s/it] 38%|███▊      | 4815/12825 [17:14:38<28:03:22, 12.61s/it] 38%|███▊      | 4816/12825 [17:14:50<28:02:22, 12.60s/it] 38%|███▊      | 4817/12825 [17:15:03<28:02:34, 12.61s/it] 38%|███▊      | 4818/12825 [17:15:16<28:04:22, 12.62s/it] 38%|███▊      | 4819/12825 [17:15:28<28:04:26, 12.62s/it] 38%|███▊      | 4820/12825 [17:15:41<28:05:24, 12.63s/it] 38%|███▊      | 4821/12825 [17:15:54<28:03:56, 12.62s/it] 38%|███▊      | 4822/12825 [17:16:06<28:02:09, 12.61s/it] 38%|███▊      | 4823/12825 [17:16:19<28:01:18, 12.61s/it] 38%|███▊      | 4824/12825 [17:16:39<33:22:32, 15.02s/it] 38%|███▊      | 4825/12825 [17:16:52<31:44:30, 14.28s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120481.23lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103708.07lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4825
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4825/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4825/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4800] due to args.save_total_limit
 38%|███▊      | 4826/12825 [17:17:05<30:51:13, 13.89s/it] 38%|███▊      | 4827/12825 [17:17:18<29:58:14, 13.49s/it] 38%|███▊      | 4828/12825 [17:17:30<29:22:43, 13.23s/it] 38%|███▊      | 4829/12825 [17:17:43<28:56:05, 13.03s/it] 38%|███▊      | 4830/12825 [17:17:55<28:38:56, 12.90s/it] 38%|███▊      | 4831/12825 [17:18:08<28:33:03, 12.86s/it] 38%|███▊      | 4832/12825 [17:18:21<28:21:35, 12.77s/it] 38%|███▊      | 4833/12825 [17:18:33<28:15:11, 12.73s/it] 38%|███▊      | 4834/12825 [17:18:46<28:10:22, 12.69s/it] 38%|███▊      | 4835/12825 [17:18:58<28:06:49, 12.67s/it] 38%|███▊      | 4836/12825 [17:19:11<28:10:22, 12.70s/it] 38%|███▊      | 4837/12825 [17:19:24<28:07:19, 12.67s/it] 38%|███▊      | 4838/12825 [17:19:36<28:03:51, 12.65s/it] 38%|███▊      | 4839/12825 [17:19:49<28:00:49, 12.63s/it] 38%|███▊      | 4840/12825 [17:20:02<28:01:34, 12.64s/it] 38%|███▊      | 4841/12825 [17:20:14<28:01:50, 12.64s/it] 38%|███▊      | 4842/12825 [17:20:27<28:00:21, 12.63s/it] 38%|███▊      | 4843/12825 [17:20:40<28:03:03, 12.65s/it] 38%|███▊      | 4844/12825 [17:20:52<28:02:46, 12.65s/it] 38%|███▊      | 4845/12825 [17:21:05<28:01:37, 12.64s/it] 38%|███▊      | 4846/12825 [17:21:18<27:59:55, 12.63s/it] 38%|███▊      | 4847/12825 [17:21:30<27:59:47, 12.63s/it] 38%|███▊      | 4848/12825 [17:21:43<28:01:44, 12.65s/it] 38%|███▊      | 4849/12825 [17:21:55<28:01:12, 12.65s/it] 38%|███▊      | 4850/12825 [17:22:08<27:59:31, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120437.41lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103701.33lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4850
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4850/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4850/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4825] due to args.save_total_limit
 38%|███▊      | 4851/12825 [17:22:21<28:20:11, 12.79s/it] 38%|███▊      | 4852/12825 [17:22:34<28:11:47, 12.73s/it] 38%|███▊      | 4853/12825 [17:22:46<28:07:44, 12.70s/it] 38%|███▊      | 4854/12825 [17:22:59<28:03:39, 12.67s/it] 38%|███▊      | 4855/12825 [17:23:12<28:01:31, 12.66s/it] 38%|███▊      | 4856/12825 [17:23:33<33:56:03, 15.33s/it] 38%|███▊      | 4857/12825 [17:23:46<32:06:08, 14.50s/it] 38%|███▊      | 4858/12825 [17:23:58<30:50:46, 13.94s/it] 38%|███▊      | 4859/12825 [17:24:11<29:59:02, 13.55s/it] 38%|███▊      | 4860/12825 [17:24:24<29:19:19, 13.25s/it] 38%|███▊      | 4861/12825 [17:24:36<28:51:22, 13.04s/it] 38%|███▊      | 4862/12825 [17:24:49<28:31:42, 12.90s/it] 38%|███▊      | 4863/12825 [17:25:01<28:19:27, 12.81s/it] 38%|███▊      | 4864/12825 [17:25:14<28:10:33, 12.74s/it] 38%|███▊      | 4865/12825 [17:25:27<28:08:02, 12.72s/it] 38%|███▊      | 4866/12825 [17:25:39<28:06:25, 12.71s/it] 38%|███▊      | 4867/12825 [17:25:52<28:01:44, 12.68s/it] 38%|███▊      | 4868/12825 [17:26:05<27:57:50, 12.65s/it] 38%|███▊      | 4869/12825 [17:26:17<27:54:17, 12.63s/it] 38%|███▊      | 4870/12825 [17:26:30<27:51:52, 12.61s/it] 38%|███▊      | 4871/12825 [17:26:42<27:49:58, 12.60s/it] 38%|███▊      | 4872/12825 [17:26:55<27:49:13, 12.59s/it] 38%|███▊      | 4873/12825 [17:27:07<27:48:48, 12.59s/it] 38%|███▊      | 4874/12825 [17:27:20<27:48:44, 12.59s/it] 38%|███▊      | 4875/12825 [17:27:33<27:47:25, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120480.33lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103091.58lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4875
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4875/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4875/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4850] due to args.save_total_limit
 38%|███▊      | 4876/12825 [17:27:46<28:01:54, 12.70s/it] 38%|███▊      | 4877/12825 [17:27:58<27:58:53, 12.67s/it] 38%|███▊      | 4878/12825 [17:28:11<27:55:14, 12.65s/it] 38%|███▊      | 4879/12825 [17:28:23<27:53:35, 12.64s/it] 38%|███▊      | 4880/12825 [17:28:36<27:53:40, 12.64s/it] 38%|███▊      | 4881/12825 [17:28:49<27:50:51, 12.62s/it] 38%|███▊      | 4882/12825 [17:29:01<27:49:25, 12.61s/it] 38%|███▊      | 4883/12825 [17:29:14<27:48:33, 12.61s/it] 38%|███▊      | 4884/12825 [17:29:26<27:48:13, 12.60s/it] 38%|███▊      | 4885/12825 [17:29:39<27:51:06, 12.63s/it] 38%|███▊      | 4886/12825 [17:29:52<27:49:40, 12.62s/it] 38%|███▊      | 4887/12825 [17:30:04<27:47:28, 12.60s/it] 38%|███▊      | 4888/12825 [17:30:17<27:47:04, 12.60s/it] 38%|███▊      | 4889/12825 [17:30:37<32:56:24, 14.94s/it] 38%|███▊      | 4890/12825 [17:30:50<31:22:17, 14.23s/it] 38%|███▊      | 4891/12825 [17:31:02<30:17:27, 13.74s/it] 38%|███▊      | 4892/12825 [17:31:15<29:31:24, 13.40s/it] 38%|███▊      | 4893/12825 [17:31:28<29:02:55, 13.18s/it] 38%|███▊      | 4894/12825 [17:31:40<28:42:04, 13.03s/it] 38%|███▊      | 4895/12825 [17:31:53<28:29:18, 12.93s/it] 38%|███▊      | 4896/12825 [17:32:06<28:19:51, 12.86s/it] 38%|███▊      | 4897/12825 [17:32:18<28:13:50, 12.82s/it] 38%|███▊      | 4898/12825 [17:32:31<28:09:57, 12.79s/it] 38%|███▊      | 4899/12825 [17:32:44<28:08:25, 12.78s/it] 38%|███▊      | 4900/12825 [17:32:57<28:04:09, 12.75s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120632.92lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103941.28lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4900
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4900/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4900/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4775] due to args.save_total_limit
 38%|███▊      | 4901/12825 [17:33:10<28:15:34, 12.84s/it] 38%|███▊      | 4902/12825 [17:33:22<28:10:31, 12.80s/it] 38%|███▊      | 4903/12825 [17:33:35<28:07:51, 12.78s/it] 38%|███▊      | 4904/12825 [17:33:48<28:04:08, 12.76s/it] 38%|███▊      | 4905/12825 [17:34:01<28:01:52, 12.74s/it] 38%|███▊      | 4906/12825 [17:34:13<28:00:01, 12.73s/it] 38%|███▊      | 4907/12825 [17:34:26<27:58:02, 12.72s/it] 38%|███▊      | 4908/12825 [17:34:39<27:57:12, 12.71s/it] 38%|███▊      | 4909/12825 [17:34:51<27:57:09, 12.71s/it] 38%|███▊      | 4910/12825 [17:35:04<27:56:11, 12.71s/it] 38%|███▊      | 4911/12825 [17:35:17<27:57:12, 12.72s/it] 38%|███▊      | 4912/12825 [17:35:30<27:58:54, 12.73s/it] 38%|███▊      | 4913/12825 [17:35:42<27:59:26, 12.74s/it] 38%|███▊      | 4914/12825 [17:35:55<28:02:59, 12.76s/it] 38%|███▊      | 4915/12825 [17:36:08<28:01:54, 12.76s/it] 38%|███▊      | 4916/12825 [17:36:21<28:00:59, 12.75s/it] 38%|███▊      | 4917/12825 [17:36:33<28:00:27, 12.75s/it] 38%|███▊      | 4918/12825 [17:36:46<27:58:43, 12.74s/it] 38%|███▊      | 4919/12825 [17:36:59<27:57:51, 12.73s/it] 38%|███▊      | 4920/12825 [17:37:11<27:57:12, 12.73s/it] 38%|███▊      | 4921/12825 [17:37:32<33:23:40, 15.21s/it] 38%|███▊      | 4922/12825 [17:37:45<31:44:04, 14.46s/it] 38%|███▊      | 4923/12825 [17:37:58<30:34:27, 13.93s/it] 38%|███▊      | 4924/12825 [17:38:11<29:46:06, 13.56s/it] 38%|███▊      | 4925/12825 [17:38:23<29:12:48, 13.31s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 75714.32lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 68640.43lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4925
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4925/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4925/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4875] due to args.save_total_limit
 38%|███▊      | 4926/12825 [17:38:37<29:09:56, 13.29s/it] 38%|███▊      | 4927/12825 [17:38:49<28:45:57, 13.11s/it] 38%|███▊      | 4928/12825 [17:39:02<28:29:38, 12.99s/it] 38%|███▊      | 4929/12825 [17:39:15<28:17:44, 12.90s/it] 38%|███▊      | 4930/12825 [17:39:27<28:10:16, 12.85s/it] 38%|███▊      | 4931/12825 [17:39:40<28:03:44, 12.80s/it] 38%|███▊      | 4932/12825 [17:39:53<28:00:38, 12.78s/it] 38%|███▊      | 4933/12825 [17:40:05<27:58:55, 12.76s/it] 38%|███▊      | 4934/12825 [17:40:18<27:57:13, 12.75s/it] 38%|███▊      | 4935/12825 [17:40:31<27:55:50, 12.74s/it] 38%|███▊      | 4936/12825 [17:40:44<27:54:27, 12.74s/it] 38%|███▊      | 4937/12825 [17:40:56<27:52:33, 12.72s/it] 39%|███▊      | 4938/12825 [17:41:09<27:51:51, 12.72s/it] 39%|███▊      | 4939/12825 [17:41:22<27:51:01, 12.71s/it] 39%|███▊      | 4940/12825 [17:41:34<27:49:32, 12.70s/it] 39%|███▊      | 4941/12825 [17:41:47<27:49:32, 12.71s/it] 39%|███▊      | 4942/12825 [17:42:00<27:47:47, 12.69s/it] 39%|███▊      | 4943/12825 [17:42:13<27:50:20, 12.72s/it] 39%|███▊      | 4944/12825 [17:42:25<27:48:59, 12.71s/it] 39%|███▊      | 4945/12825 [17:42:38<27:48:05, 12.70s/it] 39%|███▊      | 4946/12825 [17:42:51<27:47:53, 12.70s/it] 39%|███▊      | 4947/12825 [17:43:03<27:49:35, 12.72s/it] 39%|███▊      | 4948/12825 [17:43:16<27:48:58, 12.71s/it] 39%|███▊      | 4949/12825 [17:43:29<27:49:02, 12.71s/it] 39%|███▊      | 4950/12825 [17:43:42<27:49:09, 12.72s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120467.90lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103703.23lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4950
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4950/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4950/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4925] due to args.save_total_limit
 39%|███▊      | 4951/12825 [17:43:55<28:01:57, 12.82s/it] 39%|███▊      | 4952/12825 [17:44:07<27:56:58, 12.78s/it] 39%|███▊      | 4953/12825 [17:44:29<33:35:13, 15.36s/it] 39%|███▊      | 4954/12825 [17:44:41<31:50:37, 14.56s/it] 39%|███▊      | 4955/12825 [17:44:54<30:37:45, 14.01s/it] 39%|███▊      | 4956/12825 [17:45:07<29:44:56, 13.61s/it] 39%|███▊      | 4957/12825 [17:45:19<29:08:58, 13.34s/it] 39%|███▊      | 4958/12825 [17:45:32<28:44:56, 13.16s/it] 39%|███▊      | 4959/12825 [17:45:45<28:31:11, 13.05s/it] 39%|███▊      | 4960/12825 [17:45:58<28:16:54, 12.95s/it] 39%|███▊      | 4961/12825 [17:46:10<28:07:16, 12.87s/it] 39%|███▊      | 4962/12825 [17:46:23<28:00:17, 12.82s/it] 39%|███▊      | 4963/12825 [17:46:36<27:55:55, 12.79s/it] 39%|███▊      | 4964/12825 [17:46:49<27:53:07, 12.77s/it] 39%|███▊      | 4965/12825 [17:47:01<27:48:52, 12.74s/it] 39%|███▊      | 4966/12825 [17:47:14<27:47:26, 12.73s/it] 39%|███▊      | 4967/12825 [17:47:27<27:46:33, 12.72s/it] 39%|███▊      | 4968/12825 [17:47:39<27:45:58, 12.72s/it] 39%|███▊      | 4969/12825 [17:47:52<27:46:12, 12.73s/it] 39%|███▉      | 4970/12825 [17:48:05<27:44:18, 12.71s/it] 39%|███▉      | 4971/12825 [17:48:17<27:42:55, 12.70s/it] 39%|███▉      | 4972/12825 [17:48:30<27:42:36, 12.70s/it] 39%|███▉      | 4973/12825 [17:48:43<27:42:53, 12.71s/it] 39%|███▉      | 4974/12825 [17:48:56<27:41:46, 12.70s/it] 39%|███▉      | 4975/12825 [17:49:08<27:43:52, 12.72s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120505.20lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103711.59lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4975
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4975/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4975/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-4975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4900] due to args.save_total_limit
 39%|███▉      | 4976/12825 [17:49:21<27:55:53, 12.81s/it] 39%|███▉      | 4977/12825 [17:49:34<27:53:03, 12.79s/it] 39%|███▉      | 4978/12825 [17:49:47<27:49:11, 12.76s/it] 39%|███▉      | 4979/12825 [17:49:59<27:45:50, 12.74s/it] 39%|███▉      | 4980/12825 [17:50:12<27:44:22, 12.73s/it] 39%|███▉      | 4981/12825 [17:50:25<27:43:06, 12.72s/it] 39%|███▉      | 4982/12825 [17:50:38<27:41:31, 12.71s/it] 39%|███▉      | 4983/12825 [17:50:50<27:40:49, 12.71s/it] 39%|███▉      | 4984/12825 [17:51:03<27:40:31, 12.71s/it] 39%|███▉      | 4985/12825 [17:51:16<27:40:16, 12.71s/it] 39%|███▉      | 4986/12825 [17:51:37<33:19:09, 15.30s/it] 39%|███▉      | 4987/12825 [17:51:50<31:36:02, 14.51s/it] 39%|███▉      | 4988/12825 [17:52:02<30:23:29, 13.96s/it] 39%|███▉      | 4989/12825 [17:52:15<29:34:50, 13.59s/it] 39%|███▉      | 4990/12825 [17:52:28<29:00:30, 13.33s/it] 39%|███▉      | 4991/12825 [17:52:41<28:39:53, 13.17s/it] 39%|███▉      | 4992/12825 [17:52:53<28:24:49, 13.06s/it] 39%|███▉      | 4993/12825 [17:53:06<28:13:00, 12.97s/it] 39%|███▉      | 4994/12825 [17:53:19<28:02:16, 12.89s/it] 39%|███▉      | 4995/12825 [17:53:32<27:54:25, 12.83s/it] 39%|███▉      | 4996/12825 [17:53:44<27:49:08, 12.79s/it] 39%|███▉      | 4997/12825 [17:53:57<27:45:26, 12.77s/it] 39%|███▉      | 4998/12825 [17:54:10<27:43:15, 12.75s/it] 39%|███▉      | 4999/12825 [17:54:22<27:41:21, 12.74s/it] 39%|███▉      | 5000/12825 [17:54:35<27:40:47, 12.73s/it]                                                           39%|███▉      | 5000/12825 [17:54:35<27:40:47, 12.73s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120459.82lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103686.71lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5000
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5000/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5000/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4950] due to args.save_total_limit
 39%|███▉      | 5001/12825 [17:54:48<27:52:48, 12.83s/it] 39%|███▉      | 5002/12825 [17:55:01<27:49:26, 12.80s/it] 39%|███▉      | 5003/12825 [17:55:14<27:44:45, 12.77s/it] 39%|███▉      | 5004/12825 [17:55:26<27:41:48, 12.75s/it] 39%|███▉      | 5005/12825 [17:55:39<27:41:09, 12.75s/it] 39%|███▉      | 5006/12825 [17:55:52<27:39:01, 12.73s/it] 39%|███▉      | 5007/12825 [17:56:04<27:35:31, 12.71s/it] 39%|███▉      | 5008/12825 [17:56:17<27:33:12, 12.69s/it] 39%|███▉      | 5009/12825 [17:56:30<27:31:22, 12.68s/it] 39%|███▉      | 5010/12825 [17:56:42<27:29:54, 12.67s/it] 39%|███▉      | 5011/12825 [17:56:55<27:27:23, 12.65s/it] 39%|███▉      | 5012/12825 [17:57:08<27:31:52, 12.69s/it] 39%|███▉      | 5013/12825 [17:57:20<27:28:30, 12.66s/it] 39%|███▉      | 5014/12825 [17:57:33<27:31:53, 12.69s/it] 39%|███▉      | 5015/12825 [17:57:46<27:32:54, 12.70s/it] 39%|███▉      | 5016/12825 [17:57:59<27:32:32, 12.70s/it] 39%|███▉      | 5017/12825 [17:58:11<27:36:08, 12.73s/it] 39%|███▉      | 5018/12825 [17:58:32<32:40:08, 15.06s/it] 39%|███▉      | 5019/12825 [17:58:45<31:08:13, 14.36s/it] 39%|███▉      | 5020/12825 [17:58:57<30:02:40, 13.86s/it] 39%|███▉      | 5021/12825 [17:59:10<29:18:18, 13.52s/it] 39%|███▉      | 5022/12825 [17:59:23<28:44:35, 13.26s/it] 39%|███▉      | 5023/12825 [17:59:35<28:23:48, 13.10s/it] 39%|███▉      | 5024/12825 [17:59:48<28:05:19, 12.96s/it] 39%|███▉      | 5025/12825 [18:00:01<27:53:06, 12.87s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120458.41lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103713.96lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5025
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5025/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5025/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5000] due to args.save_total_limit
 39%|███▉      | 5026/12825 [18:00:14<27:54:01, 12.88s/it] 39%|███▉      | 5027/12825 [18:00:26<27:42:24, 12.79s/it] 39%|███▉      | 5028/12825 [18:00:39<27:37:04, 12.75s/it] 39%|███▉      | 5029/12825 [18:00:52<27:35:58, 12.74s/it] 39%|███▉      | 5030/12825 [18:01:04<27:35:48, 12.75s/it] 39%|███▉      | 5031/12825 [18:01:17<27:35:20, 12.74s/it] 39%|███▉      | 5032/12825 [18:01:30<27:34:20, 12.74s/it] 39%|███▉      | 5033/12825 [18:01:42<27:33:48, 12.73s/it] 39%|███▉      | 5034/12825 [18:01:55<27:33:38, 12.74s/it] 39%|███▉      | 5035/12825 [18:02:08<27:33:32, 12.74s/it] 39%|███▉      | 5036/12825 [18:02:21<27:33:41, 12.74s/it] 39%|███▉      | 5037/12825 [18:02:33<27:33:14, 12.74s/it] 39%|███▉      | 5038/12825 [18:02:46<27:32:40, 12.73s/it] 39%|███▉      | 5039/12825 [18:02:59<27:30:39, 12.72s/it] 39%|███▉      | 5040/12825 [18:03:12<27:30:52, 12.72s/it] 39%|███▉      | 5041/12825 [18:03:24<27:29:41, 12.72s/it] 39%|███▉      | 5042/12825 [18:03:37<27:31:24, 12.73s/it] 39%|███▉      | 5043/12825 [18:03:50<27:31:59, 12.74s/it] 39%|███▉      | 5044/12825 [18:04:02<27:31:19, 12.73s/it] 39%|███▉      | 5045/12825 [18:04:15<27:30:57, 12.73s/it] 39%|███▉      | 5046/12825 [18:04:28<27:29:08, 12.72s/it] 39%|███▉      | 5047/12825 [18:04:41<27:28:31, 12.72s/it] 39%|███▉      | 5048/12825 [18:04:53<27:29:08, 12.72s/it] 39%|███▉      | 5049/12825 [18:05:06<27:29:59, 12.73s/it] 39%|███▉      | 5050/12825 [18:05:27<32:58:04, 15.26s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120343.46lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103606.17lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5050
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5050/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5050/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5025] due to args.save_total_limit
 39%|███▉      | 5051/12825 [18:05:40<31:30:59, 14.59s/it] 39%|███▉      | 5052/12825 [18:05:53<30:12:39, 13.99s/it] 39%|███▉      | 5053/12825 [18:06:05<29:16:38, 13.56s/it] 39%|███▉      | 5054/12825 [18:06:18<28:39:28, 13.28s/it] 39%|███▉      | 5055/12825 [18:06:31<28:15:55, 13.10s/it] 39%|███▉      | 5056/12825 [18:06:43<27:56:05, 12.94s/it] 39%|███▉      | 5057/12825 [18:06:56<27:42:08, 12.84s/it] 39%|███▉      | 5058/12825 [18:07:09<27:32:29, 12.77s/it] 39%|███▉      | 5059/12825 [18:07:21<27:24:55, 12.71s/it] 39%|███▉      | 5060/12825 [18:07:34<27:18:38, 12.66s/it] 39%|███▉      | 5061/12825 [18:07:46<27:16:00, 12.64s/it] 39%|███▉      | 5062/12825 [18:07:59<27:12:24, 12.62s/it] 39%|███▉      | 5063/12825 [18:08:11<27:14:14, 12.63s/it] 39%|███▉      | 5064/12825 [18:08:24<27:11:53, 12.62s/it] 39%|███▉      | 5065/12825 [18:08:37<27:09:31, 12.60s/it] 40%|███▉      | 5066/12825 [18:08:49<27:09:32, 12.60s/it] 40%|███▉      | 5067/12825 [18:09:02<27:07:52, 12.59s/it] 40%|███▉      | 5068/12825 [18:09:14<27:06:55, 12.58s/it] 40%|███▉      | 5069/12825 [18:09:27<27:06:12, 12.58s/it] 40%|███▉      | 5070/12825 [18:09:40<27:10:04, 12.61s/it] 40%|███▉      | 5071/12825 [18:09:52<27:12:41, 12.63s/it] 40%|███▉      | 5072/12825 [18:10:05<27:13:59, 12.65s/it] 40%|███▉      | 5073/12825 [18:10:18<27:10:30, 12.62s/it] 40%|███▉      | 5074/12825 [18:10:30<27:07:57, 12.60s/it] 40%|███▉      | 5075/12825 [18:10:43<27:07:09, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120483.66lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103573.76lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5075
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5075/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5075/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-4975] due to args.save_total_limit
 40%|███▉      | 5076/12825 [18:10:56<27:20:38, 12.70s/it] 40%|███▉      | 5077/12825 [18:11:08<27:17:17, 12.68s/it] 40%|███▉      | 5078/12825 [18:11:21<27:19:04, 12.69s/it] 40%|███▉      | 5079/12825 [18:11:34<27:20:48, 12.71s/it] 40%|███▉      | 5080/12825 [18:11:46<27:17:06, 12.68s/it] 40%|███▉      | 5081/12825 [18:11:59<27:11:53, 12.64s/it] 40%|███▉      | 5082/12825 [18:12:12<27:14:27, 12.67s/it] 40%|███▉      | 5083/12825 [18:12:33<33:06:03, 15.39s/it] 40%|███▉      | 5084/12825 [18:12:46<31:21:53, 14.59s/it] 40%|███▉      | 5085/12825 [18:12:59<30:04:37, 13.99s/it] 40%|███▉      | 5086/12825 [18:13:11<29:11:01, 13.58s/it] 40%|███▉      | 5087/12825 [18:13:24<28:34:08, 13.29s/it] 40%|███▉      | 5088/12825 [18:13:37<28:07:12, 13.08s/it] 40%|███▉      | 5089/12825 [18:13:49<27:49:05, 12.95s/it] 40%|███▉      | 5090/12825 [18:14:02<27:35:32, 12.84s/it] 40%|███▉      | 5091/12825 [18:14:14<27:26:00, 12.77s/it] 40%|███▉      | 5092/12825 [18:14:27<27:18:05, 12.71s/it] 40%|███▉      | 5093/12825 [18:14:40<27:16:52, 12.70s/it] 40%|███▉      | 5094/12825 [18:14:52<27:17:10, 12.71s/it] 40%|███▉      | 5095/12825 [18:15:05<27:17:25, 12.71s/it] 40%|███▉      | 5096/12825 [18:15:18<27:19:07, 12.72s/it] 40%|███▉      | 5097/12825 [18:15:30<27:17:24, 12.71s/it] 40%|███▉      | 5098/12825 [18:15:43<27:15:51, 12.70s/it] 40%|███▉      | 5099/12825 [18:15:56<27:15:02, 12.70s/it] 40%|███▉      | 5100/12825 [18:16:09<27:16:19, 12.71s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120463.92lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103689.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5050] due to args.save_total_limit
 40%|███▉      | 5101/12825 [18:16:22<27:30:34, 12.82s/it] 40%|███▉      | 5102/12825 [18:16:34<27:25:20, 12.78s/it] 40%|███▉      | 5103/12825 [18:16:47<27:21:49, 12.76s/it] 40%|███▉      | 5104/12825 [18:17:00<27:20:09, 12.75s/it] 40%|███▉      | 5105/12825 [18:17:13<27:19:46, 12.74s/it] 40%|███▉      | 5106/12825 [18:17:25<27:18:21, 12.74s/it] 40%|███▉      | 5107/12825 [18:17:38<27:18:21, 12.74s/it] 40%|███▉      | 5108/12825 [18:17:51<27:16:54, 12.73s/it] 40%|███▉      | 5109/12825 [18:18:03<27:15:56, 12.72s/it] 40%|███▉      | 5110/12825 [18:18:16<27:14:58, 12.72s/it] 40%|███▉      | 5111/12825 [18:18:29<27:15:25, 12.72s/it] 40%|███▉      | 5112/12825 [18:18:42<27:14:39, 12.72s/it] 40%|███▉      | 5113/12825 [18:18:54<27:14:38, 12.72s/it] 40%|███▉      | 5114/12825 [18:19:07<27:12:46, 12.70s/it] 40%|███▉      | 5115/12825 [18:19:28<32:31:48, 15.19s/it] 40%|███▉      | 5116/12825 [18:19:41<30:56:59, 14.45s/it] 40%|███▉      | 5117/12825 [18:19:53<29:53:49, 13.96s/it] 40%|███▉      | 5118/12825 [18:20:06<29:04:37, 13.58s/it] 40%|███▉      | 5119/12825 [18:20:19<28:30:32, 13.32s/it] 40%|███▉      | 5120/12825 [18:20:32<28:06:23, 13.13s/it] 40%|███▉      | 5121/12825 [18:20:44<27:48:54, 13.00s/it] 40%|███▉      | 5122/12825 [18:20:57<27:37:27, 12.91s/it] 40%|███▉      | 5123/12825 [18:21:10<27:30:52, 12.86s/it] 40%|███▉      | 5124/12825 [18:21:22<27:24:11, 12.81s/it] 40%|███▉      | 5125/12825 [18:21:35<27:23:53, 12.81s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120428.18lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103666.11lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5100] due to args.save_total_limit
 40%|███▉      | 5126/12825 [18:21:48<27:35:18, 12.90s/it] 40%|███▉      | 5127/12825 [18:22:01<27:29:17, 12.85s/it] 40%|███▉      | 5128/12825 [18:22:14<27:23:33, 12.81s/it] 40%|███▉      | 5129/12825 [18:22:22<24:18:02, 11.37s/it] 40%|████      | 5130/12825 [18:22:23<17:32:09,  8.20s/it] 40%|████      | 5131/12825 [18:22:48<28:50:44, 13.50s/it] 40%|████      | 5132/12825 [18:23:01<28:21:53, 13.27s/it] 40%|████      | 5133/12825 [18:23:14<28:01:41, 13.12s/it] 40%|████      | 5134/12825 [18:23:27<27:46:37, 13.00s/it] 40%|████      | 5135/12825 [18:23:39<27:36:32, 12.92s/it] 40%|████      | 5136/12825 [18:23:52<27:29:35, 12.87s/it] 40%|████      | 5137/12825 [18:24:05<27:25:17, 12.84s/it] 40%|████      | 5138/12825 [18:24:18<27:20:41, 12.81s/it] 40%|████      | 5139/12825 [18:24:30<27:17:32, 12.78s/it] 40%|████      | 5140/12825 [18:24:43<27:15:51, 12.77s/it] 40%|████      | 5141/12825 [18:24:56<27:15:45, 12.77s/it] 40%|████      | 5142/12825 [18:25:09<27:16:03, 12.78s/it] 40%|████      | 5143/12825 [18:25:21<27:14:56, 12.77s/it] 40%|████      | 5144/12825 [18:25:34<27:15:39, 12.78s/it] 40%|████      | 5145/12825 [18:25:47<27:15:28, 12.78s/it] 40%|████      | 5146/12825 [18:26:00<27:14:52, 12.77s/it] 40%|████      | 5147/12825 [18:26:13<27:13:49, 12.77s/it] 40%|████      | 5148/12825 [18:26:35<33:11:49, 15.57s/it] 40%|████      | 5149/12825 [18:26:47<31:22:02, 14.71s/it] 40%|████      | 5150/12825 [18:27:00<30:04:08, 14.10s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120507.89lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103716.72lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5075] due to args.save_total_limit
 40%|████      | 5151/12825 [18:27:13<29:24:18, 13.79s/it] 40%|████      | 5152/12825 [18:27:26<28:44:53, 13.49s/it] 40%|████      | 5153/12825 [18:27:39<28:15:08, 13.26s/it] 40%|████      | 5154/12825 [18:27:51<27:56:06, 13.11s/it] 40%|████      | 5155/12825 [18:28:04<27:43:15, 13.01s/it] 40%|████      | 5156/12825 [18:28:17<27:28:49, 12.90s/it] 40%|████      | 5157/12825 [18:28:29<27:17:46, 12.82s/it] 40%|████      | 5158/12825 [18:28:42<27:10:09, 12.76s/it] 40%|████      | 5159/12825 [18:28:55<27:05:40, 12.72s/it] 40%|████      | 5160/12825 [18:29:07<27:01:16, 12.69s/it] 40%|████      | 5161/12825 [18:29:20<26:59:19, 12.68s/it] 40%|████      | 5162/12825 [18:29:33<26:57:20, 12.66s/it] 40%|████      | 5163/12825 [18:29:45<26:53:14, 12.63s/it] 40%|████      | 5164/12825 [18:29:58<26:52:20, 12.63s/it] 40%|████      | 5165/12825 [18:30:10<26:52:43, 12.63s/it] 40%|████      | 5166/12825 [18:30:23<26:51:45, 12.63s/it] 40%|████      | 5167/12825 [18:30:36<26:51:42, 12.63s/it] 40%|████      | 5168/12825 [18:30:48<26:51:28, 12.63s/it] 40%|████      | 5169/12825 [18:31:01<26:49:54, 12.62s/it] 40%|████      | 5170/12825 [18:31:13<26:48:10, 12.60s/it] 40%|████      | 5171/12825 [18:31:26<26:46:52, 12.60s/it] 40%|████      | 5172/12825 [18:31:39<26:48:10, 12.61s/it] 40%|████      | 5173/12825 [18:31:51<26:48:27, 12.61s/it] 40%|████      | 5174/12825 [18:32:04<26:50:14, 12.63s/it] 40%|████      | 5175/12825 [18:32:17<26:48:43, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120544.96lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103718.33lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5125] due to args.save_total_limit
 40%|████      | 5176/12825 [18:32:29<27:02:18, 12.73s/it] 40%|████      | 5177/12825 [18:32:42<27:01:42, 12.72s/it] 40%|████      | 5178/12825 [18:32:55<26:56:25, 12.68s/it] 40%|████      | 5179/12825 [18:33:07<26:54:07, 12.67s/it] 40%|████      | 5180/12825 [18:33:28<31:39:04, 14.90s/it] 40%|████      | 5181/12825 [18:33:40<30:10:57, 14.21s/it] 40%|████      | 5182/12825 [18:33:53<29:09:14, 13.73s/it] 40%|████      | 5183/12825 [18:34:05<28:25:33, 13.39s/it] 40%|████      | 5184/12825 [18:34:18<27:53:24, 13.14s/it] 40%|████      | 5185/12825 [18:34:30<27:31:05, 12.97s/it] 40%|████      | 5186/12825 [18:34:43<27:16:44, 12.86s/it] 40%|████      | 5187/12825 [18:34:56<27:06:35, 12.78s/it] 40%|████      | 5188/12825 [18:35:08<27:00:38, 12.73s/it] 40%|████      | 5189/12825 [18:35:21<26:54:32, 12.69s/it] 40%|████      | 5190/12825 [18:35:33<26:50:18, 12.65s/it] 40%|████      | 5191/12825 [18:35:46<26:48:50, 12.64s/it] 40%|████      | 5192/12825 [18:35:59<26:45:35, 12.62s/it] 40%|████      | 5193/12825 [18:36:11<26:47:17, 12.64s/it] 40%|████      | 5194/12825 [18:36:24<26:46:41, 12.63s/it] 41%|████      | 5195/12825 [18:36:37<26:46:05, 12.63s/it] 41%|████      | 5196/12825 [18:36:49<26:44:20, 12.62s/it] 41%|████      | 5197/12825 [18:37:02<26:43:25, 12.61s/it] 41%|████      | 5198/12825 [18:37:14<26:40:58, 12.59s/it] 41%|████      | 5199/12825 [18:37:27<26:40:07, 12.59s/it] 41%|████      | 5200/12825 [18:37:39<26:39:28, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120488.02lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103476.85lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5150] due to args.save_total_limit
 41%|████      | 5201/12825 [18:37:52<26:54:46, 12.71s/it] 41%|████      | 5202/12825 [18:38:05<26:55:28, 12.72s/it] 41%|████      | 5203/12825 [18:38:18<26:53:19, 12.70s/it] 41%|████      | 5204/12825 [18:38:30<26:51:19, 12.69s/it] 41%|████      | 5205/12825 [18:38:43<26:49:40, 12.67s/it] 41%|████      | 5206/12825 [18:38:56<26:48:07, 12.66s/it] 41%|████      | 5207/12825 [18:39:08<26:47:10, 12.66s/it] 41%|████      | 5208/12825 [18:39:21<26:47:44, 12.66s/it] 41%|████      | 5209/12825 [18:39:34<26:47:28, 12.66s/it] 41%|████      | 5210/12825 [18:39:46<26:46:36, 12.66s/it] 41%|████      | 5211/12825 [18:39:59<26:44:43, 12.65s/it] 41%|████      | 5212/12825 [18:40:12<26:44:39, 12.65s/it] 41%|████      | 5213/12825 [18:40:32<31:28:13, 14.88s/it] 41%|████      | 5214/12825 [18:40:44<30:00:22, 14.19s/it] 41%|████      | 5215/12825 [18:40:57<28:59:40, 13.72s/it] 41%|████      | 5216/12825 [18:41:10<28:18:49, 13.40s/it] 41%|████      | 5217/12825 [18:41:22<27:51:25, 13.18s/it] 41%|████      | 5218/12825 [18:41:35<27:32:40, 13.04s/it] 41%|████      | 5219/12825 [18:41:48<27:17:12, 12.92s/it] 41%|████      | 5220/12825 [18:42:00<27:05:50, 12.83s/it] 41%|████      | 5221/12825 [18:42:13<26:58:15, 12.77s/it] 41%|████      | 5222/12825 [18:42:25<26:51:50, 12.72s/it] 41%|████      | 5223/12825 [18:42:38<26:49:21, 12.70s/it] 41%|████      | 5224/12825 [18:42:51<26:47:50, 12.69s/it] 41%|████      | 5225/12825 [18:43:04<26:48:25, 12.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120405.39lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103641.25lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5175] due to args.save_total_limit
 41%|████      | 5226/12825 [18:43:16<26:58:44, 12.78s/it] 41%|████      | 5227/12825 [18:43:29<26:52:54, 12.74s/it] 41%|████      | 5228/12825 [18:43:42<26:49:40, 12.71s/it] 41%|████      | 5229/12825 [18:43:54<26:46:30, 12.69s/it] 41%|████      | 5230/12825 [18:44:07<26:44:26, 12.67s/it] 41%|████      | 5231/12825 [18:44:20<26:42:02, 12.66s/it] 41%|████      | 5232/12825 [18:44:32<26:41:05, 12.65s/it] 41%|████      | 5233/12825 [18:44:45<26:41:00, 12.65s/it] 41%|████      | 5234/12825 [18:44:58<26:39:41, 12.64s/it] 41%|████      | 5235/12825 [18:45:10<26:42:27, 12.67s/it] 41%|████      | 5236/12825 [18:45:23<26:41:15, 12.66s/it] 41%|████      | 5237/12825 [18:45:36<26:39:07, 12.64s/it] 41%|████      | 5238/12825 [18:45:48<26:38:37, 12.64s/it] 41%|████      | 5239/12825 [18:46:01<26:36:57, 12.63s/it] 41%|████      | 5240/12825 [18:46:13<26:38:34, 12.65s/it] 41%|████      | 5241/12825 [18:46:26<26:37:53, 12.64s/it] 41%|████      | 5242/12825 [18:46:39<26:37:39, 12.64s/it] 41%|████      | 5243/12825 [18:46:51<26:37:23, 12.64s/it] 41%|████      | 5244/12825 [18:47:04<26:38:13, 12.65s/it] 41%|████      | 5245/12825 [18:47:24<31:29:50, 14.96s/it] 41%|████      | 5246/12825 [18:47:37<29:59:50, 14.25s/it] 41%|████      | 5247/12825 [18:47:50<28:58:10, 13.76s/it] 41%|████      | 5248/12825 [18:48:02<28:15:23, 13.43s/it] 41%|████      | 5249/12825 [18:48:15<27:45:37, 13.19s/it] 41%|████      | 5250/12825 [18:48:28<27:24:11, 13.02s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 118044.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101909.40lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5200] due to args.save_total_limit
 41%|████      | 5251/12825 [18:48:41<27:21:38, 13.00s/it] 41%|████      | 5252/12825 [18:48:53<27:06:25, 12.89s/it] 41%|████      | 5253/12825 [18:49:06<26:55:57, 12.80s/it] 41%|████      | 5254/12825 [18:49:18<26:49:45, 12.76s/it] 41%|████      | 5255/12825 [18:49:31<26:44:21, 12.72s/it] 41%|████      | 5256/12825 [18:49:44<26:41:01, 12.69s/it] 41%|████      | 5257/12825 [18:49:56<26:38:25, 12.67s/it] 41%|████      | 5258/12825 [18:50:09<26:35:47, 12.65s/it] 41%|████      | 5259/12825 [18:50:21<26:34:22, 12.64s/it] 41%|████      | 5260/12825 [18:50:34<26:33:05, 12.64s/it] 41%|████      | 5261/12825 [18:50:47<26:33:03, 12.64s/it] 41%|████      | 5262/12825 [18:50:59<26:32:33, 12.63s/it] 41%|████      | 5263/12825 [18:51:12<26:30:44, 12.62s/it] 41%|████      | 5264/12825 [18:51:25<26:31:04, 12.63s/it] 41%|████      | 5265/12825 [18:51:37<26:31:21, 12.63s/it] 41%|████      | 5266/12825 [18:51:50<26:31:14, 12.63s/it] 41%|████      | 5267/12825 [18:52:03<26:32:24, 12.64s/it] 41%|████      | 5268/12825 [18:52:15<26:31:11, 12.63s/it] 41%|████      | 5269/12825 [18:52:28<26:33:16, 12.65s/it] 41%|████      | 5270/12825 [18:52:41<26:34:02, 12.66s/it] 41%|████      | 5271/12825 [18:52:53<26:33:53, 12.66s/it] 41%|████      | 5272/12825 [18:53:06<26:34:36, 12.67s/it] 41%|████      | 5273/12825 [18:53:19<26:33:20, 12.66s/it] 41%|████      | 5274/12825 [18:53:31<26:33:02, 12.66s/it] 41%|████      | 5275/12825 [18:53:44<26:30:52, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120531.88lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103722.13lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5225] due to args.save_total_limit
 41%|████      | 5276/12825 [18:53:57<26:55:53, 12.84s/it] 41%|████      | 5277/12825 [18:54:10<26:47:54, 12.78s/it] 41%|████      | 5278/12825 [18:54:30<31:23:09, 14.97s/it] 41%|████      | 5279/12825 [18:54:42<29:55:33, 14.28s/it] 41%|████      | 5280/12825 [18:54:55<28:54:21, 13.79s/it] 41%|████      | 5281/12825 [18:55:08<28:09:49, 13.44s/it] 41%|████      | 5282/12825 [18:55:20<27:38:38, 13.19s/it] 41%|████      | 5283/12825 [18:55:33<27:16:58, 13.02s/it] 41%|████      | 5284/12825 [18:55:46<27:01:34, 12.90s/it] 41%|████      | 5285/12825 [18:55:58<26:51:27, 12.82s/it] 41%|████      | 5286/12825 [18:56:11<26:43:33, 12.76s/it] 41%|████      | 5287/12825 [18:56:24<26:38:33, 12.72s/it] 41%|████      | 5288/12825 [18:56:36<26:35:38, 12.70s/it] 41%|████      | 5289/12825 [18:56:49<26:33:28, 12.69s/it] 41%|████      | 5290/12825 [18:57:01<26:30:42, 12.67s/it] 41%|████▏     | 5291/12825 [18:57:14<26:27:53, 12.65s/it] 41%|████▏     | 5292/12825 [18:57:27<26:25:27, 12.63s/it] 41%|████▏     | 5293/12825 [18:57:39<26:23:06, 12.61s/it] 41%|████▏     | 5294/12825 [18:57:52<26:22:47, 12.61s/it] 41%|████▏     | 5295/12825 [18:58:04<26:21:23, 12.60s/it] 41%|████▏     | 5296/12825 [18:58:17<26:20:42, 12.60s/it] 41%|████▏     | 5297/12825 [18:58:30<26:21:36, 12.61s/it] 41%|████▏     | 5298/12825 [18:58:42<26:22:29, 12.61s/it] 41%|████▏     | 5299/12825 [18:58:55<26:23:02, 12.62s/it] 41%|████▏     | 5300/12825 [18:59:08<26:23:49, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120496.35lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103730.30lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5250] due to args.save_total_limit
 41%|████▏     | 5301/12825 [18:59:20<26:36:42, 12.73s/it] 41%|████▏     | 5302/12825 [18:59:33<26:34:02, 12.71s/it] 41%|████▏     | 5303/12825 [18:59:46<26:32:19, 12.70s/it] 41%|████▏     | 5304/12825 [18:59:58<26:29:51, 12.68s/it] 41%|████▏     | 5305/12825 [19:00:11<26:28:21, 12.67s/it] 41%|████▏     | 5306/12825 [19:00:24<26:27:08, 12.66s/it] 41%|████▏     | 5307/12825 [19:00:36<26:26:24, 12.66s/it] 41%|████▏     | 5308/12825 [19:00:49<26:25:03, 12.65s/it] 41%|████▏     | 5309/12825 [19:01:02<26:24:30, 12.65s/it] 41%|████▏     | 5310/12825 [19:01:22<31:05:44, 14.90s/it] 41%|████▏     | 5311/12825 [19:01:34<29:40:17, 14.22s/it] 41%|████▏     | 5312/12825 [19:01:47<28:40:31, 13.74s/it] 41%|████▏     | 5313/12825 [19:02:00<27:58:04, 13.40s/it] 41%|████▏     | 5314/12825 [19:02:12<27:27:59, 13.16s/it] 41%|████▏     | 5315/12825 [19:02:25<27:08:06, 13.01s/it] 41%|████▏     | 5316/12825 [19:02:38<26:54:32, 12.90s/it] 41%|████▏     | 5317/12825 [19:02:50<26:43:14, 12.81s/it] 41%|████▏     | 5318/12825 [19:03:03<26:35:55, 12.76s/it] 41%|████▏     | 5319/12825 [19:03:15<26:32:06, 12.73s/it] 41%|████▏     | 5320/12825 [19:03:28<26:28:29, 12.70s/it] 41%|████▏     | 5321/12825 [19:03:41<26:25:30, 12.68s/it] 41%|████▏     | 5322/12825 [19:03:53<26:21:59, 12.65s/it] 42%|████▏     | 5323/12825 [19:04:06<26:20:05, 12.64s/it] 42%|████▏     | 5324/12825 [19:04:19<26:19:54, 12.64s/it] 42%|████▏     | 5325/12825 [19:04:31<26:18:22, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120511.74lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103747.50lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5275] due to args.save_total_limit
 42%|████▏     | 5326/12825 [19:04:44<26:30:53, 12.73s/it] 42%|████▏     | 5327/12825 [19:04:57<26:27:11, 12.70s/it] 42%|████▏     | 5328/12825 [19:05:09<26:25:31, 12.69s/it] 42%|████▏     | 5329/12825 [19:05:22<26:24:01, 12.68s/it] 42%|████▏     | 5330/12825 [19:05:35<26:24:01, 12.68s/it] 42%|████▏     | 5331/12825 [19:05:47<26:23:29, 12.68s/it] 42%|████▏     | 5332/12825 [19:06:00<26:22:12, 12.67s/it] 42%|████▏     | 5333/12825 [19:06:13<26:20:38, 12.66s/it] 42%|████▏     | 5334/12825 [19:06:25<26:20:54, 12.66s/it] 42%|████▏     | 5335/12825 [19:06:38<26:18:54, 12.65s/it] 42%|████▏     | 5336/12825 [19:06:51<26:20:00, 12.66s/it] 42%|████▏     | 5337/12825 [19:07:03<26:20:38, 12.67s/it] 42%|████▏     | 5338/12825 [19:07:16<26:19:55, 12.66s/it] 42%|████▏     | 5339/12825 [19:07:29<26:19:49, 12.66s/it] 42%|████▏     | 5340/12825 [19:07:41<26:20:30, 12.67s/it] 42%|████▏     | 5341/12825 [19:07:54<26:20:39, 12.67s/it] 42%|████▏     | 5342/12825 [19:08:14<31:04:42, 14.95s/it] 42%|████▏     | 5343/12825 [19:08:27<29:35:57, 14.24s/it] 42%|████▏     | 5344/12825 [19:08:40<28:34:36, 13.75s/it] 42%|████▏     | 5345/12825 [19:08:52<27:52:55, 13.42s/it] 42%|████▏     | 5346/12825 [19:09:05<27:22:38, 13.18s/it] 42%|████▏     | 5347/12825 [19:09:17<27:01:18, 13.01s/it] 42%|████▏     | 5348/12825 [19:09:30<26:45:45, 12.89s/it] 42%|████▏     | 5349/12825 [19:09:43<26:34:54, 12.80s/it] 42%|████▏     | 5350/12825 [19:09:55<26:27:30, 12.74s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120398.10lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103679.30lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5300] due to args.save_total_limit
 42%|████▏     | 5351/12825 [19:10:08<26:35:56, 12.81s/it] 42%|████▏     | 5352/12825 [19:10:21<26:28:20, 12.75s/it] 42%|████▏     | 5353/12825 [19:10:34<26:26:20, 12.74s/it] 42%|████▏     | 5354/12825 [19:10:46<26:21:44, 12.70s/it] 42%|████▏     | 5355/12825 [19:10:59<26:19:02, 12.68s/it] 42%|████▏     | 5356/12825 [19:11:11<26:17:23, 12.67s/it] 42%|████▏     | 5357/12825 [19:11:24<26:15:57, 12.66s/it] 42%|████▏     | 5358/12825 [19:11:37<26:15:59, 12.66s/it] 42%|████▏     | 5359/12825 [19:11:49<26:15:10, 12.66s/it] 42%|████▏     | 5360/12825 [19:12:02<26:13:33, 12.65s/it] 42%|████▏     | 5361/12825 [19:12:15<26:14:07, 12.65s/it] 42%|████▏     | 5362/12825 [19:12:27<26:13:35, 12.65s/it] 42%|████▏     | 5363/12825 [19:12:40<26:11:46, 12.64s/it] 42%|████▏     | 5364/12825 [19:12:53<26:11:46, 12.64s/it] 42%|████▏     | 5365/12825 [19:13:05<26:11:46, 12.64s/it] 42%|████▏     | 5366/12825 [19:13:18<26:14:26, 12.66s/it] 42%|████▏     | 5367/12825 [19:13:31<26:13:17, 12.66s/it] 42%|████▏     | 5368/12825 [19:13:43<26:11:35, 12.65s/it] 42%|████▏     | 5369/12825 [19:13:56<26:09:22, 12.63s/it] 42%|████▏     | 5370/12825 [19:14:08<26:10:29, 12.64s/it] 42%|████▏     | 5371/12825 [19:14:21<26:12:52, 12.66s/it] 42%|████▏     | 5372/12825 [19:14:34<26:12:33, 12.66s/it] 42%|████▏     | 5373/12825 [19:14:46<26:11:37, 12.65s/it] 42%|████▏     | 5374/12825 [19:14:59<26:09:35, 12.64s/it] 42%|████▏     | 5375/12825 [19:15:19<30:52:05, 14.92s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120423.96lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103661.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5350] due to args.save_total_limit
 42%|████▏     | 5376/12825 [19:15:32<29:38:33, 14.33s/it] 42%|████▏     | 5377/12825 [19:15:45<28:35:34, 13.82s/it] 42%|████▏     | 5378/12825 [19:15:57<27:50:23, 13.46s/it] 42%|████▏     | 5379/12825 [19:16:10<27:19:25, 13.21s/it] 42%|████▏     | 5380/12825 [19:16:23<26:58:16, 13.04s/it] 42%|████▏     | 5381/12825 [19:16:35<26:42:10, 12.91s/it] 42%|████▏     | 5382/12825 [19:16:48<26:32:05, 12.83s/it] 42%|████▏     | 5383/12825 [19:17:01<26:24:40, 12.78s/it] 42%|████▏     | 5384/12825 [19:17:13<26:19:29, 12.74s/it] 42%|████▏     | 5385/12825 [19:17:26<26:14:19, 12.70s/it] 42%|████▏     | 5386/12825 [19:17:39<26:13:05, 12.69s/it] 42%|████▏     | 5387/12825 [19:17:51<26:12:13, 12.68s/it] 42%|████▏     | 5388/12825 [19:18:04<26:09:12, 12.66s/it] 42%|████▏     | 5389/12825 [19:18:17<26:11:28, 12.68s/it] 42%|████▏     | 5390/12825 [19:18:29<26:08:36, 12.66s/it] 42%|████▏     | 5391/12825 [19:18:42<26:07:02, 12.65s/it] 42%|████▏     | 5392/12825 [19:18:54<26:06:04, 12.64s/it] 42%|████▏     | 5393/12825 [19:19:07<26:05:25, 12.64s/it] 42%|████▏     | 5394/12825 [19:19:20<26:05:06, 12.64s/it] 42%|████▏     | 5395/12825 [19:19:32<26:04:16, 12.63s/it] 42%|████▏     | 5396/12825 [19:19:45<26:02:34, 12.62s/it] 42%|████▏     | 5397/12825 [19:19:58<26:01:15, 12.61s/it] 42%|████▏     | 5398/12825 [19:20:10<26:01:17, 12.61s/it] 42%|████▏     | 5399/12825 [19:20:23<26:02:37, 12.63s/it] 42%|████▏     | 5400/12825 [19:20:35<26:02:45, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120485.20lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103725.55lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5375] due to args.save_total_limit
 42%|████▏     | 5401/12825 [19:20:48<26:15:13, 12.73s/it] 42%|████▏     | 5402/12825 [19:21:01<26:14:01, 12.72s/it] 42%|████▏     | 5403/12825 [19:21:14<26:10:05, 12.69s/it] 42%|████▏     | 5404/12825 [19:21:26<26:09:13, 12.69s/it] 42%|████▏     | 5405/12825 [19:21:39<26:07:30, 12.68s/it] 42%|████▏     | 5406/12825 [19:21:52<26:05:39, 12.66s/it] 42%|████▏     | 5407/12825 [19:22:12<30:44:04, 14.92s/it] 42%|████▏     | 5408/12825 [19:22:24<29:18:09, 14.22s/it] 42%|████▏     | 5409/12825 [19:22:37<28:16:27, 13.73s/it] 42%|████▏     | 5410/12825 [19:22:50<27:35:38, 13.40s/it] 42%|████▏     | 5411/12825 [19:23:02<27:06:57, 13.17s/it] 42%|████▏     | 5412/12825 [19:23:15<26:46:30, 13.00s/it] 42%|████▏     | 5413/12825 [19:23:28<26:32:37, 12.89s/it] 42%|████▏     | 5414/12825 [19:23:40<26:20:43, 12.80s/it] 42%|████▏     | 5415/12825 [19:23:53<26:13:58, 12.74s/it] 42%|████▏     | 5416/12825 [19:24:05<26:09:30, 12.71s/it] 42%|████▏     | 5417/12825 [19:24:18<26:09:24, 12.71s/it] 42%|████▏     | 5418/12825 [19:24:31<26:05:42, 12.68s/it] 42%|████▏     | 5419/12825 [19:24:43<26:02:23, 12.66s/it] 42%|████▏     | 5420/12825 [19:24:56<25:59:22, 12.64s/it] 42%|████▏     | 5421/12825 [19:25:08<25:57:41, 12.62s/it] 42%|████▏     | 5422/12825 [19:25:21<25:57:16, 12.62s/it] 42%|████▏     | 5423/12825 [19:25:34<25:56:16, 12.62s/it] 42%|████▏     | 5424/12825 [19:25:46<25:55:07, 12.61s/it] 42%|████▏     | 5425/12825 [19:25:59<25:53:59, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120614.55lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103903.04lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5400] due to args.save_total_limit
 42%|████▏     | 5426/12825 [19:26:12<26:07:18, 12.71s/it] 42%|████▏     | 5427/12825 [19:26:24<26:03:06, 12.68s/it] 42%|████▏     | 5428/12825 [19:26:37<26:00:54, 12.66s/it] 42%|████▏     | 5429/12825 [19:26:50<25:58:53, 12.65s/it] 42%|████▏     | 5430/12825 [19:27:02<26:01:07, 12.67s/it] 42%|████▏     | 5431/12825 [19:27:15<26:00:04, 12.66s/it] 42%|████▏     | 5432/12825 [19:27:28<26:03:04, 12.69s/it] 42%|████▏     | 5433/12825 [19:27:40<26:00:52, 12.67s/it] 42%|████▏     | 5434/12825 [19:27:53<25:59:48, 12.66s/it] 42%|████▏     | 5435/12825 [19:28:06<25:57:53, 12.65s/it] 42%|████▏     | 5436/12825 [19:28:18<25:57:57, 12.65s/it] 42%|████▏     | 5437/12825 [19:28:31<25:57:55, 12.65s/it] 42%|████▏     | 5438/12825 [19:28:44<25:55:49, 12.64s/it] 42%|████▏     | 5439/12825 [19:29:04<30:37:28, 14.93s/it] 42%|████▏     | 5440/12825 [19:29:16<29:11:52, 14.23s/it] 42%|████▏     | 5441/12825 [19:29:29<28:12:09, 13.75s/it] 42%|████▏     | 5442/12825 [19:29:42<27:29:52, 13.41s/it] 42%|████▏     | 5443/12825 [19:29:54<26:59:49, 13.17s/it] 42%|████▏     | 5444/12825 [19:30:07<26:39:39, 13.00s/it] 42%|████▏     | 5445/12825 [19:30:20<26:25:34, 12.89s/it] 42%|████▏     | 5446/12825 [19:30:32<26:15:08, 12.81s/it] 42%|████▏     | 5447/12825 [19:30:45<26:07:40, 12.75s/it] 42%|████▏     | 5448/12825 [19:30:57<26:02:24, 12.71s/it] 42%|████▏     | 5449/12825 [19:31:10<25:57:35, 12.67s/it] 42%|████▏     | 5450/12825 [19:31:23<25:54:56, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120502.76lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103734.48lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5425] due to args.save_total_limit
 43%|████▎     | 5451/12825 [19:31:36<26:09:34, 12.77s/it] 43%|████▎     | 5452/12825 [19:31:48<26:04:51, 12.73s/it] 43%|████▎     | 5453/12825 [19:32:01<25:59:33, 12.69s/it] 43%|████▎     | 5454/12825 [19:32:13<25:56:19, 12.67s/it] 43%|████▎     | 5455/12825 [19:32:26<25:54:25, 12.65s/it] 43%|████▎     | 5456/12825 [19:32:39<25:52:57, 12.64s/it] 43%|████▎     | 5457/12825 [19:32:51<25:51:18, 12.63s/it] 43%|████▎     | 5458/12825 [19:33:04<25:53:32, 12.65s/it] 43%|████▎     | 5459/12825 [19:33:17<25:51:21, 12.64s/it] 43%|████▎     | 5460/12825 [19:33:29<25:50:05, 12.63s/it] 43%|████▎     | 5461/12825 [19:33:42<25:50:29, 12.63s/it] 43%|████▎     | 5462/12825 [19:33:54<25:50:14, 12.63s/it] 43%|████▎     | 5463/12825 [19:34:07<25:49:15, 12.63s/it] 43%|████▎     | 5464/12825 [19:34:20<25:49:06, 12.63s/it] 43%|████▎     | 5465/12825 [19:34:32<25:49:49, 12.63s/it] 43%|████▎     | 5466/12825 [19:34:45<25:49:16, 12.63s/it] 43%|████▎     | 5467/12825 [19:34:58<25:48:59, 12.63s/it] 43%|████▎     | 5468/12825 [19:35:10<25:47:45, 12.62s/it] 43%|████▎     | 5469/12825 [19:35:23<25:48:26, 12.63s/it] 43%|████▎     | 5470/12825 [19:35:35<25:47:21, 12.62s/it] 43%|████▎     | 5471/12825 [19:35:48<25:46:29, 12.62s/it] 43%|████▎     | 5472/12825 [19:36:08<30:15:29, 14.81s/it] 43%|████▎     | 5473/12825 [19:36:21<28:53:36, 14.15s/it] 43%|████▎     | 5474/12825 [19:36:33<27:56:40, 13.69s/it] 43%|████▎     | 5475/12825 [19:36:46<27:16:57, 13.36s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120477.12lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103705.70lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5450] due to args.save_total_limit
 43%|████▎     | 5476/12825 [19:36:59<27:03:42, 13.26s/it] 43%|████▎     | 5477/12825 [19:37:11<26:40:18, 13.07s/it] 43%|████▎     | 5478/12825 [19:37:24<26:24:37, 12.94s/it] 43%|████▎     | 5479/12825 [19:37:37<26:13:42, 12.85s/it] 43%|████▎     | 5480/12825 [19:37:49<26:05:49, 12.79s/it] 43%|████▎     | 5481/12825 [19:38:02<25:59:55, 12.74s/it] 43%|████▎     | 5482/12825 [19:38:15<25:56:01, 12.71s/it] 43%|████▎     | 5483/12825 [19:38:27<25:52:15, 12.69s/it] 43%|████▎     | 5484/12825 [19:38:40<25:49:24, 12.66s/it] 43%|████▎     | 5485/12825 [19:38:53<25:46:39, 12.64s/it] 43%|████▎     | 5486/12825 [19:39:05<25:45:44, 12.64s/it] 43%|████▎     | 5487/12825 [19:39:18<25:44:48, 12.63s/it] 43%|████▎     | 5488/12825 [19:39:30<25:43:43, 12.62s/it] 43%|████▎     | 5489/12825 [19:39:43<25:42:19, 12.61s/it] 43%|████▎     | 5490/12825 [19:39:56<25:43:09, 12.62s/it] 43%|████▎     | 5491/12825 [19:40:08<25:42:07, 12.62s/it] 43%|████▎     | 5492/12825 [19:40:21<25:41:08, 12.61s/it] 43%|████▎     | 5493/12825 [19:40:33<25:39:25, 12.60s/it] 43%|████▎     | 5494/12825 [19:40:46<25:42:47, 12.63s/it] 43%|████▎     | 5495/12825 [19:40:59<25:42:29, 12.63s/it] 43%|████▎     | 5496/12825 [19:41:11<25:40:09, 12.61s/it] 43%|████▎     | 5497/12825 [19:41:24<25:40:04, 12.61s/it] 43%|████▎     | 5498/12825 [19:41:36<25:38:47, 12.60s/it] 43%|████▎     | 5499/12825 [19:41:49<25:38:08, 12.60s/it] 43%|████▎     | 5500/12825 [19:42:02<25:37:17, 12.59s/it]                                                           43%|████▎     | 5500/12825 [19:42:02<25:37:17, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120507.00lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103698.10lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5475] due to args.save_total_limit
 43%|████▎     | 5501/12825 [19:42:15<25:51:37, 12.71s/it] 43%|████▎     | 5502/12825 [19:42:27<25:46:55, 12.67s/it] 43%|████▎     | 5503/12825 [19:42:40<25:43:16, 12.65s/it] 43%|████▎     | 5504/12825 [19:43:00<30:26:36, 14.97s/it] 43%|████▎     | 5505/12825 [19:43:13<28:59:23, 14.26s/it] 43%|████▎     | 5506/12825 [19:43:25<27:58:38, 13.76s/it] 43%|████▎     | 5507/12825 [19:43:38<27:15:36, 13.41s/it] 43%|████▎     | 5508/12825 [19:43:51<26:45:46, 13.17s/it] 43%|████▎     | 5509/12825 [19:44:03<26:26:23, 13.01s/it] 43%|████▎     | 5510/12825 [19:44:16<26:10:20, 12.88s/it] 43%|████▎     | 5511/12825 [19:44:28<26:02:32, 12.82s/it] 43%|████▎     | 5512/12825 [19:44:41<25:53:19, 12.74s/it] 43%|████▎     | 5513/12825 [19:44:54<25:45:57, 12.69s/it] 43%|████▎     | 5514/12825 [19:45:06<25:40:28, 12.64s/it] 43%|████▎     | 5515/12825 [19:45:19<25:36:49, 12.61s/it] 43%|████▎     | 5516/12825 [19:45:31<25:34:33, 12.60s/it] 43%|████▎     | 5517/12825 [19:45:44<25:33:35, 12.59s/it] 43%|████▎     | 5518/12825 [19:45:56<25:31:47, 12.58s/it] 43%|████▎     | 5519/12825 [19:46:09<25:32:12, 12.58s/it] 43%|████▎     | 5520/12825 [19:46:22<25:31:26, 12.58s/it] 43%|████▎     | 5521/12825 [19:46:34<25:31:21, 12.58s/it] 43%|████▎     | 5522/12825 [19:46:47<25:32:40, 12.59s/it] 43%|████▎     | 5523/12825 [19:46:59<25:33:27, 12.60s/it] 43%|████▎     | 5524/12825 [19:47:12<25:34:19, 12.61s/it] 43%|████▎     | 5525/12825 [19:47:25<25:34:01, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120429.85lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103652.92lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5325] due to args.save_total_limit
 43%|████▎     | 5526/12825 [19:47:38<25:48:42, 12.73s/it] 43%|████▎     | 5527/12825 [19:47:50<25:48:55, 12.73s/it] 43%|████▎     | 5528/12825 [19:48:03<25:44:47, 12.70s/it] 43%|████▎     | 5529/12825 [19:48:16<25:41:54, 12.68s/it] 43%|████▎     | 5530/12825 [19:48:28<25:39:08, 12.66s/it] 43%|████▎     | 5531/12825 [19:48:41<25:36:57, 12.64s/it] 43%|████▎     | 5532/12825 [19:48:53<25:34:46, 12.63s/it] 43%|████▎     | 5533/12825 [19:49:06<25:32:38, 12.61s/it] 43%|████▎     | 5534/12825 [19:49:19<25:32:41, 12.61s/it] 43%|████▎     | 5535/12825 [19:49:31<25:31:27, 12.60s/it] 43%|████▎     | 5536/12825 [19:49:44<25:30:55, 12.60s/it] 43%|████▎     | 5537/12825 [19:50:04<30:02:47, 14.84s/it] 43%|████▎     | 5538/12825 [19:50:16<28:41:27, 14.17s/it] 43%|████▎     | 5539/12825 [19:50:29<27:43:58, 13.70s/it] 43%|████▎     | 5540/12825 [19:50:42<27:03:49, 13.37s/it] 43%|████▎     | 5541/12825 [19:50:54<26:35:44, 13.14s/it] 43%|████▎     | 5542/12825 [19:51:07<26:14:51, 12.97s/it] 43%|████▎     | 5543/12825 [19:51:19<26:00:56, 12.86s/it] 43%|████▎     | 5544/12825 [19:51:32<25:50:33, 12.78s/it] 43%|████▎     | 5545/12825 [19:51:45<25:43:17, 12.72s/it] 43%|████▎     | 5546/12825 [19:51:57<25:39:37, 12.69s/it] 43%|████▎     | 5547/12825 [19:52:10<25:40:14, 12.70s/it] 43%|████▎     | 5548/12825 [19:52:23<25:38:39, 12.69s/it] 43%|████▎     | 5549/12825 [19:52:35<25:35:10, 12.66s/it] 43%|████▎     | 5550/12825 [19:52:48<25:32:02, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120529.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103769.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5500] due to args.save_total_limit
 43%|████▎     | 5551/12825 [19:53:01<25:43:46, 12.73s/it] 43%|████▎     | 5552/12825 [19:53:13<25:42:46, 12.73s/it] 43%|████▎     | 5553/12825 [19:53:26<25:39:17, 12.70s/it] 43%|████▎     | 5554/12825 [19:53:39<25:36:45, 12.68s/it] 43%|████▎     | 5555/12825 [19:53:51<25:34:56, 12.67s/it] 43%|████▎     | 5556/12825 [19:54:04<25:34:04, 12.66s/it] 43%|████▎     | 5557/12825 [19:54:17<25:32:45, 12.65s/it] 43%|████▎     | 5558/12825 [19:54:29<25:31:13, 12.64s/it] 43%|████▎     | 5559/12825 [19:54:42<25:30:22, 12.64s/it] 43%|████▎     | 5560/12825 [19:54:55<25:29:22, 12.63s/it] 43%|████▎     | 5561/12825 [19:55:07<25:28:47, 12.63s/it] 43%|████▎     | 5562/12825 [19:55:20<25:27:30, 12.62s/it] 43%|████▎     | 5563/12825 [19:55:32<25:27:01, 12.62s/it] 43%|████▎     | 5564/12825 [19:55:45<25:26:54, 12.62s/it] 43%|████▎     | 5565/12825 [19:55:58<25:27:27, 12.62s/it] 43%|████▎     | 5566/12825 [19:56:10<25:27:43, 12.63s/it] 43%|████▎     | 5567/12825 [19:56:23<25:25:24, 12.61s/it] 43%|████▎     | 5568/12825 [19:56:35<25:24:32, 12.60s/it] 43%|████▎     | 5569/12825 [19:56:55<29:51:47, 14.82s/it] 43%|████▎     | 5570/12825 [19:57:08<28:31:05, 14.15s/it] 43%|████▎     | 5571/12825 [19:57:21<27:34:33, 13.69s/it] 43%|████▎     | 5572/12825 [19:57:33<26:54:44, 13.36s/it] 43%|████▎     | 5573/12825 [19:57:46<26:25:50, 13.12s/it] 43%|████▎     | 5574/12825 [19:57:58<26:09:14, 12.99s/it] 43%|████▎     | 5575/12825 [19:58:11<25:55:34, 12.87s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120421.14lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103673.61lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5550] due to args.save_total_limit
 43%|████▎     | 5576/12825 [19:58:24<25:57:13, 12.89s/it] 43%|████▎     | 5577/12825 [19:58:37<25:47:45, 12.81s/it] 43%|████▎     | 5578/12825 [19:58:49<25:41:17, 12.76s/it] 44%|████▎     | 5579/12825 [19:59:02<25:34:11, 12.70s/it] 44%|████▎     | 5580/12825 [19:59:14<25:28:46, 12.66s/it] 44%|████▎     | 5581/12825 [19:59:27<25:26:11, 12.64s/it] 44%|████▎     | 5582/12825 [19:59:40<25:24:19, 12.63s/it] 44%|████▎     | 5583/12825 [19:59:52<25:24:12, 12.63s/it] 44%|████▎     | 5584/12825 [20:00:05<25:23:39, 12.63s/it] 44%|████▎     | 5585/12825 [20:00:17<25:22:23, 12.62s/it] 44%|████▎     | 5586/12825 [20:00:30<25:21:49, 12.61s/it] 44%|████▎     | 5587/12825 [20:00:43<25:22:19, 12.62s/it] 44%|████▎     | 5588/12825 [20:00:55<25:20:44, 12.61s/it] 44%|████▎     | 5589/12825 [20:01:08<25:20:31, 12.61s/it] 44%|████▎     | 5590/12825 [20:01:20<25:19:51, 12.60s/it] 44%|████▎     | 5591/12825 [20:01:33<25:23:23, 12.64s/it] 44%|████▎     | 5592/12825 [20:01:46<25:20:55, 12.62s/it] 44%|████▎     | 5593/12825 [20:01:58<25:20:27, 12.61s/it] 44%|████▎     | 5594/12825 [20:02:11<25:22:32, 12.63s/it] 44%|████▎     | 5595/12825 [20:02:24<25:21:02, 12.62s/it] 44%|████▎     | 5596/12825 [20:02:36<25:20:49, 12.62s/it] 44%|████▎     | 5597/12825 [20:02:49<25:21:37, 12.63s/it] 44%|████▎     | 5598/12825 [20:03:01<25:19:39, 12.62s/it] 44%|████▎     | 5599/12825 [20:03:14<25:18:41, 12.61s/it] 44%|████▎     | 5600/12825 [20:03:27<25:18:54, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120479.94lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103689.56lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5575] due to args.save_total_limit
 44%|████▎     | 5601/12825 [20:03:47<30:00:37, 14.96s/it] 44%|████▎     | 5602/12825 [20:04:00<28:36:07, 14.26s/it] 44%|████▎     | 5603/12825 [20:04:12<27:36:35, 13.76s/it] 44%|████▎     | 5604/12825 [20:04:25<26:53:47, 13.41s/it] 44%|████▎     | 5605/12825 [20:04:37<26:23:18, 13.16s/it] 44%|████▎     | 5606/12825 [20:04:50<26:05:14, 13.01s/it] 44%|████▎     | 5607/12825 [20:05:03<25:49:15, 12.88s/it] 44%|████▎     | 5608/12825 [20:05:15<25:37:32, 12.78s/it] 44%|████▎     | 5609/12825 [20:05:28<25:30:49, 12.73s/it] 44%|████▎     | 5610/12825 [20:05:41<25:30:01, 12.72s/it] 44%|████▍     | 5611/12825 [20:05:53<25:24:56, 12.68s/it] 44%|████▍     | 5612/12825 [20:06:06<25:20:16, 12.65s/it] 44%|████▍     | 5613/12825 [20:06:18<25:19:06, 12.64s/it] 44%|████▍     | 5614/12825 [20:06:31<25:17:45, 12.63s/it] 44%|████▍     | 5615/12825 [20:06:44<25:16:13, 12.62s/it] 44%|████▍     | 5616/12825 [20:06:56<25:16:12, 12.62s/it] 44%|████▍     | 5617/12825 [20:07:09<25:15:07, 12.61s/it] 44%|████▍     | 5618/12825 [20:07:21<25:14:36, 12.61s/it] 44%|████▍     | 5619/12825 [20:07:34<25:16:14, 12.62s/it] 44%|████▍     | 5620/12825 [20:07:47<25:14:53, 12.62s/it] 44%|████▍     | 5621/12825 [20:07:59<25:14:54, 12.62s/it] 44%|████▍     | 5622/12825 [20:08:12<25:12:58, 12.60s/it] 44%|████▍     | 5623/12825 [20:08:24<25:12:32, 12.60s/it] 44%|████▍     | 5624/12825 [20:08:37<25:13:20, 12.61s/it] 44%|████▍     | 5625/12825 [20:08:50<25:12:14, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120498.28lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103750.07lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5600] due to args.save_total_limit
 44%|████▍     | 5626/12825 [20:09:03<25:24:31, 12.71s/it] 44%|████▍     | 5627/12825 [20:09:15<25:19:10, 12.66s/it] 44%|████▍     | 5628/12825 [20:09:28<25:16:13, 12.64s/it] 44%|████▍     | 5629/12825 [20:09:40<25:13:54, 12.62s/it] 44%|████▍     | 5630/12825 [20:09:53<25:13:14, 12.62s/it] 44%|████▍     | 5631/12825 [20:10:06<25:12:38, 12.62s/it] 44%|████▍     | 5632/12825 [20:10:18<25:10:52, 12.60s/it] 44%|████▍     | 5633/12825 [20:10:31<25:12:00, 12.61s/it] 44%|████▍     | 5634/12825 [20:10:51<29:45:47, 14.90s/it] 44%|████▍     | 5635/12825 [20:11:04<28:21:59, 14.20s/it] 44%|████▍     | 5636/12825 [20:11:16<27:22:45, 13.71s/it] 44%|████▍     | 5637/12825 [20:11:29<26:41:23, 13.37s/it] 44%|████▍     | 5638/12825 [20:11:41<26:11:59, 13.12s/it] 44%|████▍     | 5639/12825 [20:11:54<25:51:34, 12.95s/it] 44%|████▍     | 5640/12825 [20:12:06<25:36:56, 12.83s/it] 44%|████▍     | 5641/12825 [20:12:19<25:26:59, 12.75s/it] 44%|████▍     | 5642/12825 [20:12:27<22:31:58, 11.29s/it] 44%|████▍     | 5643/12825 [20:12:28<16:15:47,  8.15s/it] 44%|████▍     | 5644/12825 [20:12:53<26:37:08, 13.34s/it] 44%|████▍     | 5645/12825 [20:13:06<26:10:29, 13.12s/it] 44%|████▍     | 5646/12825 [20:13:18<25:53:46, 12.99s/it] 44%|████▍     | 5647/12825 [20:13:31<25:39:41, 12.87s/it] 44%|████▍     | 5648/12825 [20:13:44<25:30:02, 12.79s/it] 44%|████▍     | 5649/12825 [20:13:56<25:22:23, 12.73s/it] 44%|████▍     | 5650/12825 [20:14:09<25:17:01, 12.69s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120543.42lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103755.68lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5625] due to args.save_total_limit
 44%|████▍     | 5651/12825 [20:14:22<25:27:57, 12.78s/it] 44%|████▍     | 5652/12825 [20:14:34<25:22:57, 12.74s/it] 44%|████▍     | 5653/12825 [20:14:47<25:17:50, 12.70s/it] 44%|████▍     | 5654/12825 [20:15:00<25:17:09, 12.69s/it] 44%|████▍     | 5655/12825 [20:15:12<25:14:14, 12.67s/it] 44%|████▍     | 5656/12825 [20:15:25<25:14:56, 12.68s/it] 44%|████▍     | 5657/12825 [20:15:38<25:14:07, 12.67s/it] 44%|████▍     | 5658/12825 [20:15:50<25:15:50, 12.69s/it] 44%|████▍     | 5659/12825 [20:16:03<25:14:23, 12.68s/it] 44%|████▍     | 5660/12825 [20:16:16<25:13:24, 12.67s/it] 44%|████▍     | 5661/12825 [20:16:28<25:11:19, 12.66s/it] 44%|████▍     | 5662/12825 [20:16:41<25:10:03, 12.65s/it] 44%|████▍     | 5663/12825 [20:16:54<25:08:33, 12.64s/it] 44%|████▍     | 5664/12825 [20:17:06<25:08:46, 12.64s/it] 44%|████▍     | 5665/12825 [20:17:19<25:08:30, 12.64s/it] 44%|████▍     | 5666/12825 [20:17:31<25:07:48, 12.64s/it] 44%|████▍     | 5667/12825 [20:17:51<29:32:45, 14.86s/it] 44%|████▍     | 5668/12825 [20:18:04<28:11:29, 14.18s/it] 44%|████▍     | 5669/12825 [20:18:17<27:14:34, 13.71s/it] 44%|████▍     | 5670/12825 [20:18:30<26:44:10, 13.45s/it] 44%|████▍     | 5671/12825 [20:18:42<26:15:41, 13.22s/it] 44%|████▍     | 5672/12825 [20:18:55<25:55:43, 13.05s/it] 44%|████▍     | 5673/12825 [20:19:08<25:40:55, 12.93s/it] 44%|████▍     | 5674/12825 [20:19:20<25:34:05, 12.87s/it] 44%|████▍     | 5675/12825 [20:19:33<25:25:57, 12.81s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120454.19lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103676.36lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5525] due to args.save_total_limit
 44%|████▍     | 5676/12825 [20:19:46<25:32:25, 12.86s/it] 44%|████▍     | 5677/12825 [20:19:59<25:24:16, 12.79s/it] 44%|████▍     | 5678/12825 [20:20:11<25:18:52, 12.75s/it] 44%|████▍     | 5679/12825 [20:20:24<25:15:22, 12.72s/it] 44%|████▍     | 5680/12825 [20:20:36<25:12:18, 12.70s/it] 44%|████▍     | 5681/12825 [20:20:49<25:11:13, 12.69s/it] 44%|████▍     | 5682/12825 [20:21:02<25:09:40, 12.68s/it] 44%|████▍     | 5683/12825 [20:21:14<25:09:33, 12.68s/it] 44%|████▍     | 5684/12825 [20:21:27<25:08:27, 12.67s/it] 44%|████▍     | 5685/12825 [20:21:40<25:08:10, 12.67s/it] 44%|████▍     | 5686/12825 [20:21:53<25:08:35, 12.68s/it] 44%|████▍     | 5687/12825 [20:22:05<25:07:49, 12.67s/it] 44%|████▍     | 5688/12825 [20:22:18<25:06:42, 12.67s/it] 44%|████▍     | 5689/12825 [20:22:30<25:06:14, 12.66s/it] 44%|████▍     | 5690/12825 [20:22:43<25:04:24, 12.65s/it] 44%|████▍     | 5691/12825 [20:22:56<25:03:03, 12.64s/it] 44%|████▍     | 5692/12825 [20:23:08<25:02:23, 12.64s/it] 44%|████▍     | 5693/12825 [20:23:21<25:02:01, 12.64s/it] 44%|████▍     | 5694/12825 [20:23:34<25:01:44, 12.64s/it] 44%|████▍     | 5695/12825 [20:23:46<25:04:04, 12.66s/it] 44%|████▍     | 5696/12825 [20:23:59<25:02:00, 12.64s/it] 44%|████▍     | 5697/12825 [20:24:12<25:01:57, 12.64s/it] 44%|████▍     | 5698/12825 [20:24:24<25:02:59, 12.65s/it] 44%|████▍     | 5699/12825 [20:24:45<29:36:39, 14.96s/it] 44%|████▍     | 5700/12825 [20:24:57<28:15:52, 14.28s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120471.74lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103685.00lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5650] due to args.save_total_limit
 44%|████▍     | 5701/12825 [20:25:10<27:28:10, 13.88s/it] 44%|████▍     | 5702/12825 [20:25:23<26:42:34, 13.50s/it] 44%|████▍     | 5703/12825 [20:25:35<26:10:41, 13.23s/it] 44%|████▍     | 5704/12825 [20:25:48<25:49:41, 13.06s/it] 44%|████▍     | 5705/12825 [20:26:01<25:34:14, 12.93s/it] 44%|████▍     | 5706/12825 [20:26:13<25:24:53, 12.85s/it] 44%|████▍     | 5707/12825 [20:26:26<25:16:30, 12.78s/it] 45%|████▍     | 5708/12825 [20:26:39<25:10:28, 12.73s/it] 45%|████▍     | 5709/12825 [20:26:51<25:07:42, 12.71s/it] 45%|████▍     | 5710/12825 [20:27:04<25:03:54, 12.68s/it] 45%|████▍     | 5711/12825 [20:27:17<25:02:23, 12.67s/it] 45%|████▍     | 5712/12825 [20:27:29<25:01:19, 12.66s/it] 45%|████▍     | 5713/12825 [20:27:42<24:59:06, 12.65s/it] 45%|████▍     | 5714/12825 [20:27:55<25:05:46, 12.71s/it] 45%|████▍     | 5715/12825 [20:28:07<25:03:26, 12.69s/it] 45%|████▍     | 5716/12825 [20:28:20<25:02:20, 12.68s/it] 45%|████▍     | 5717/12825 [20:28:33<25:00:21, 12.66s/it] 45%|████▍     | 5718/12825 [20:28:45<25:01:25, 12.68s/it] 45%|████▍     | 5719/12825 [20:28:58<24:59:17, 12.66s/it] 45%|████▍     | 5720/12825 [20:29:11<24:56:31, 12.64s/it] 45%|████▍     | 5721/12825 [20:29:23<24:58:53, 12.66s/it] 45%|████▍     | 5722/12825 [20:29:36<24:57:15, 12.65s/it] 45%|████▍     | 5723/12825 [20:29:48<24:56:17, 12.64s/it] 45%|████▍     | 5724/12825 [20:30:01<24:57:36, 12.65s/it] 45%|████▍     | 5725/12825 [20:30:14<24:57:32, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120499.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103711.40lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5725
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5725/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5725/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5700] due to args.save_total_limit
 45%|████▍     | 5726/12825 [20:30:27<25:08:03, 12.75s/it] 45%|████▍     | 5727/12825 [20:30:39<25:03:46, 12.71s/it] 45%|████▍     | 5728/12825 [20:30:52<24:59:43, 12.68s/it] 45%|████▍     | 5729/12825 [20:31:05<24:58:13, 12.67s/it] 45%|████▍     | 5730/12825 [20:31:17<24:55:57, 12.65s/it] 45%|████▍     | 5731/12825 [20:31:37<29:24:43, 14.93s/it] 45%|████▍     | 5732/12825 [20:31:50<28:03:02, 14.24s/it] 45%|████▍     | 5733/12825 [20:32:03<27:03:26, 13.73s/it] 45%|████▍     | 5734/12825 [20:32:15<26:23:14, 13.40s/it] 45%|████▍     | 5735/12825 [20:32:28<25:55:06, 13.16s/it] 45%|████▍     | 5736/12825 [20:32:41<25:37:10, 13.01s/it] 45%|████▍     | 5737/12825 [20:32:53<25:21:30, 12.88s/it] 45%|████▍     | 5738/12825 [20:33:07<25:42:53, 13.06s/it] 45%|████▍     | 5739/12825 [20:33:19<25:25:20, 12.92s/it] 45%|████▍     | 5740/12825 [20:33:32<25:14:56, 12.83s/it] 45%|████▍     | 5741/12825 [20:33:44<25:06:32, 12.76s/it] 45%|████▍     | 5742/12825 [20:33:57<25:04:12, 12.74s/it] 45%|████▍     | 5743/12825 [20:34:10<24:59:19, 12.70s/it] 45%|████▍     | 5744/12825 [20:34:22<24:59:34, 12.71s/it] 45%|████▍     | 5745/12825 [20:34:35<24:55:46, 12.68s/it] 45%|████▍     | 5746/12825 [20:34:48<24:51:57, 12.65s/it] 45%|████▍     | 5747/12825 [20:35:00<24:50:45, 12.64s/it] 45%|████▍     | 5748/12825 [20:35:13<24:49:52, 12.63s/it] 45%|████▍     | 5749/12825 [20:35:25<24:48:48, 12.62s/it] 45%|████▍     | 5750/12825 [20:35:38<24:48:49, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120385.81lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103591.96lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5750
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5750/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5750/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5725] due to args.save_total_limit
 45%|████▍     | 5751/12825 [20:35:51<24:59:45, 12.72s/it] 45%|████▍     | 5752/12825 [20:36:04<24:55:52, 12.69s/it] 45%|████▍     | 5753/12825 [20:36:16<24:53:45, 12.67s/it] 45%|████▍     | 5754/12825 [20:36:29<24:51:46, 12.66s/it] 45%|████▍     | 5755/12825 [20:36:42<24:49:09, 12.64s/it] 45%|████▍     | 5756/12825 [20:36:54<24:48:28, 12.63s/it] 45%|████▍     | 5757/12825 [20:37:07<24:51:13, 12.66s/it] 45%|████▍     | 5758/12825 [20:37:19<24:50:15, 12.65s/it] 45%|████▍     | 5759/12825 [20:37:32<24:48:07, 12.64s/it] 45%|████▍     | 5760/12825 [20:37:45<24:48:30, 12.64s/it] 45%|████▍     | 5761/12825 [20:37:57<24:46:31, 12.63s/it] 45%|████▍     | 5762/12825 [20:38:10<24:45:59, 12.62s/it] 45%|████▍     | 5763/12825 [20:38:31<29:35:18, 15.08s/it] 45%|████▍     | 5764/12825 [20:38:43<28:07:43, 14.34s/it] 45%|████▍     | 5765/12825 [20:38:56<27:05:49, 13.82s/it] 45%|████▍     | 5766/12825 [20:39:09<26:21:58, 13.45s/it] 45%|████▍     | 5767/12825 [20:39:21<25:50:39, 13.18s/it] 45%|████▍     | 5768/12825 [20:39:34<25:32:15, 13.03s/it] 45%|████▍     | 5769/12825 [20:39:46<25:17:33, 12.90s/it] 45%|████▍     | 5770/12825 [20:39:59<25:05:41, 12.81s/it] 45%|████▍     | 5771/12825 [20:40:12<24:57:53, 12.74s/it] 45%|████▌     | 5772/12825 [20:40:24<24:52:05, 12.69s/it] 45%|████▌     | 5773/12825 [20:40:37<24:48:30, 12.66s/it] 45%|████▌     | 5774/12825 [20:40:49<24:48:46, 12.67s/it] 45%|████▌     | 5775/12825 [20:41:02<24:45:09, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120354.08lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103697.72lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5775
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5775/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5775/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5750] due to args.save_total_limit
 45%|████▌     | 5776/12825 [20:41:15<24:55:35, 12.73s/it] 45%|████▌     | 5777/12825 [20:41:28<24:49:42, 12.68s/it] 45%|████▌     | 5778/12825 [20:41:40<24:47:01, 12.66s/it] 45%|████▌     | 5779/12825 [20:41:53<24:45:02, 12.65s/it] 45%|████▌     | 5780/12825 [20:42:05<24:42:45, 12.63s/it] 45%|████▌     | 5781/12825 [20:42:18<24:41:25, 12.62s/it] 45%|████▌     | 5782/12825 [20:42:31<24:41:29, 12.62s/it] 45%|████▌     | 5783/12825 [20:42:43<24:43:39, 12.64s/it] 45%|████▌     | 5784/12825 [20:42:56<24:42:00, 12.63s/it] 45%|████▌     | 5785/12825 [20:43:08<24:40:40, 12.62s/it] 45%|████▌     | 5786/12825 [20:43:21<24:42:37, 12.64s/it] 45%|████▌     | 5787/12825 [20:43:34<24:40:31, 12.62s/it] 45%|████▌     | 5788/12825 [20:43:46<24:39:39, 12.62s/it] 45%|████▌     | 5789/12825 [20:43:59<24:37:14, 12.60s/it] 45%|████▌     | 5790/12825 [20:44:11<24:37:45, 12.60s/it] 45%|████▌     | 5791/12825 [20:44:24<24:37:01, 12.60s/it] 45%|████▌     | 5792/12825 [20:44:37<24:37:26, 12.60s/it] 45%|████▌     | 5793/12825 [20:44:49<24:37:02, 12.60s/it] 45%|████▌     | 5794/12825 [20:45:02<24:37:34, 12.61s/it] 45%|████▌     | 5795/12825 [20:45:15<24:38:33, 12.62s/it] 45%|████▌     | 5796/12825 [20:45:35<29:08:16, 14.92s/it] 45%|████▌     | 5797/12825 [20:45:47<27:44:51, 14.21s/it] 45%|████▌     | 5798/12825 [20:46:00<26:46:23, 13.72s/it] 45%|████▌     | 5799/12825 [20:46:13<26:07:07, 13.38s/it] 45%|████▌     | 5800/12825 [20:46:25<25:37:36, 13.13s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120531.88lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103744.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5800
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5800/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5800/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5775] due to args.save_total_limit
 45%|████▌     | 5801/12825 [20:46:38<25:28:51, 13.06s/it] 45%|████▌     | 5802/12825 [20:46:51<25:10:15, 12.90s/it] 45%|████▌     | 5803/12825 [20:47:03<24:59:26, 12.81s/it] 45%|████▌     | 5804/12825 [20:47:16<24:51:56, 12.75s/it] 45%|████▌     | 5805/12825 [20:47:28<24:46:01, 12.70s/it] 45%|████▌     | 5806/12825 [20:47:41<24:42:07, 12.67s/it] 45%|████▌     | 5807/12825 [20:47:54<24:39:02, 12.65s/it] 45%|████▌     | 5808/12825 [20:48:06<24:38:00, 12.64s/it] 45%|████▌     | 5809/12825 [20:48:19<24:36:03, 12.62s/it] 45%|████▌     | 5810/12825 [20:48:31<24:34:21, 12.61s/it] 45%|████▌     | 5811/12825 [20:48:44<24:33:40, 12.61s/it] 45%|████▌     | 5812/12825 [20:48:56<24:31:34, 12.59s/it] 45%|████▌     | 5813/12825 [20:49:09<24:33:12, 12.61s/it] 45%|████▌     | 5814/12825 [20:49:22<24:31:44, 12.60s/it] 45%|████▌     | 5815/12825 [20:49:34<24:30:41, 12.59s/it] 45%|████▌     | 5816/12825 [20:49:47<24:30:59, 12.59s/it] 45%|████▌     | 5817/12825 [20:49:59<24:30:00, 12.59s/it] 45%|████▌     | 5818/12825 [20:50:12<24:30:59, 12.60s/it] 45%|████▌     | 5819/12825 [20:50:25<24:31:05, 12.60s/it] 45%|████▌     | 5820/12825 [20:50:37<24:30:35, 12.60s/it] 45%|████▌     | 5821/12825 [20:50:50<24:32:01, 12.61s/it] 45%|████▌     | 5822/12825 [20:51:02<24:32:01, 12.61s/it] 45%|████▌     | 5823/12825 [20:51:15<24:32:31, 12.62s/it] 45%|████▌     | 5824/12825 [20:51:28<24:29:52, 12.60s/it] 45%|████▌     | 5825/12825 [20:51:40<24:29:44, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120457.01lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103694.68lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5825
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5825/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5825/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5800] due to args.save_total_limit
 45%|████▌     | 5826/12825 [20:51:53<24:40:58, 12.70s/it] 45%|████▌     | 5827/12825 [20:52:06<24:38:35, 12.68s/it] 45%|████▌     | 5828/12825 [20:52:26<28:57:27, 14.90s/it] 45%|████▌     | 5829/12825 [20:52:38<27:35:57, 14.20s/it] 45%|████▌     | 5830/12825 [20:52:51<26:37:49, 13.71s/it] 45%|████▌     | 5831/12825 [20:53:04<25:58:32, 13.37s/it] 45%|████▌     | 5832/12825 [20:53:16<25:28:31, 13.11s/it] 45%|████▌     | 5833/12825 [20:53:29<25:08:09, 12.94s/it] 45%|████▌     | 5834/12825 [20:53:41<24:54:18, 12.82s/it] 45%|████▌     | 5835/12825 [20:53:54<24:43:46, 12.74s/it] 46%|████▌     | 5836/12825 [20:54:06<24:39:43, 12.70s/it] 46%|████▌     | 5837/12825 [20:54:19<24:35:05, 12.67s/it] 46%|████▌     | 5838/12825 [20:54:32<24:35:05, 12.67s/it] 46%|████▌     | 5839/12825 [20:54:44<24:31:30, 12.64s/it] 46%|████▌     | 5840/12825 [20:54:57<24:29:15, 12.62s/it] 46%|████▌     | 5841/12825 [20:55:09<24:29:38, 12.63s/it] 46%|████▌     | 5842/12825 [20:55:22<24:27:24, 12.61s/it] 46%|████▌     | 5843/12825 [20:55:35<24:25:06, 12.59s/it] 46%|████▌     | 5844/12825 [20:55:47<24:24:24, 12.59s/it] 46%|████▌     | 5845/12825 [20:56:00<24:23:47, 12.58s/it] 46%|████▌     | 5846/12825 [20:56:12<24:23:04, 12.58s/it] 46%|████▌     | 5847/12825 [20:56:25<24:22:33, 12.58s/it] 46%|████▌     | 5848/12825 [20:56:37<24:22:39, 12.58s/it] 46%|████▌     | 5849/12825 [20:56:50<24:23:04, 12.58s/it] 46%|████▌     | 5850/12825 [20:57:03<24:22:16, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120534.06lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103741.61lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5850
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5850/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5850/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5825] due to args.save_total_limit
 46%|████▌     | 5851/12825 [20:57:16<24:35:52, 12.70s/it] 46%|████▌     | 5852/12825 [20:57:28<24:35:05, 12.69s/it] 46%|████▌     | 5853/12825 [20:57:41<24:35:15, 12.70s/it] 46%|████▌     | 5854/12825 [20:57:54<24:32:08, 12.67s/it] 46%|████▌     | 5855/12825 [20:58:06<24:30:15, 12.66s/it] 46%|████▌     | 5856/12825 [20:58:19<24:29:03, 12.65s/it] 46%|████▌     | 5857/12825 [20:58:32<24:33:02, 12.68s/it] 46%|████▌     | 5858/12825 [20:58:44<24:30:09, 12.66s/it] 46%|████▌     | 5859/12825 [20:58:57<24:29:12, 12.65s/it] 46%|████▌     | 5860/12825 [20:59:09<24:28:11, 12.65s/it] 46%|████▌     | 5861/12825 [20:59:30<28:46:24, 14.87s/it] 46%|████▌     | 5862/12825 [20:59:42<27:29:07, 14.21s/it] 46%|████▌     | 5863/12825 [20:59:55<26:33:58, 13.74s/it] 46%|████▌     | 5864/12825 [21:00:07<25:53:06, 13.39s/it] 46%|████▌     | 5865/12825 [21:00:20<25:24:10, 13.14s/it] 46%|████▌     | 5866/12825 [21:00:33<25:07:28, 13.00s/it] 46%|████▌     | 5867/12825 [21:00:45<24:57:02, 12.91s/it] 46%|████▌     | 5868/12825 [21:00:58<24:46:59, 12.82s/it] 46%|████▌     | 5869/12825 [21:01:11<24:42:17, 12.79s/it] 46%|████▌     | 5870/12825 [21:01:23<24:38:31, 12.76s/it] 46%|████▌     | 5871/12825 [21:01:36<24:38:21, 12.76s/it] 46%|████▌     | 5872/12825 [21:01:49<24:31:37, 12.70s/it] 46%|████▌     | 5873/12825 [21:02:01<24:26:32, 12.66s/it] 46%|████▌     | 5874/12825 [21:02:14<24:24:46, 12.64s/it] 46%|████▌     | 5875/12825 [21:02:27<24:29:12, 12.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120527.39lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103749.78lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5875
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5875/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5875/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5675] due to args.save_total_limit
 46%|████▌     | 5876/12825 [21:02:39<24:35:58, 12.74s/it] 46%|████▌     | 5877/12825 [21:02:52<24:29:46, 12.69s/it] 46%|████▌     | 5878/12825 [21:03:05<24:24:35, 12.65s/it] 46%|████▌     | 5879/12825 [21:03:17<24:21:53, 12.63s/it] 46%|████▌     | 5880/12825 [21:03:30<24:20:20, 12.62s/it] 46%|████▌     | 5881/12825 [21:03:42<24:19:40, 12.61s/it] 46%|████▌     | 5882/12825 [21:03:55<24:17:31, 12.60s/it] 46%|████▌     | 5883/12825 [21:04:08<24:17:41, 12.60s/it] 46%|████▌     | 5884/12825 [21:04:20<24:15:52, 12.59s/it] 46%|████▌     | 5885/12825 [21:04:33<24:15:03, 12.58s/it] 46%|████▌     | 5886/12825 [21:04:45<24:14:02, 12.57s/it] 46%|████▌     | 5887/12825 [21:04:58<24:13:36, 12.57s/it] 46%|████▌     | 5888/12825 [21:05:10<24:11:36, 12.56s/it] 46%|████▌     | 5889/12825 [21:05:23<24:11:36, 12.56s/it] 46%|████▌     | 5890/12825 [21:05:35<24:10:37, 12.55s/it] 46%|████▌     | 5891/12825 [21:05:48<24:10:41, 12.55s/it] 46%|████▌     | 5892/12825 [21:06:00<24:10:08, 12.55s/it] 46%|████▌     | 5893/12825 [21:06:20<28:27:21, 14.78s/it] 46%|████▌     | 5894/12825 [21:06:33<27:13:22, 14.14s/it] 46%|████▌     | 5895/12825 [21:06:46<26:18:41, 13.67s/it] 46%|████▌     | 5896/12825 [21:06:58<25:40:47, 13.34s/it] 46%|████▌     | 5897/12825 [21:07:11<25:13:43, 13.11s/it] 46%|████▌     | 5898/12825 [21:07:23<24:54:54, 12.95s/it] 46%|████▌     | 5899/12825 [21:07:36<24:41:09, 12.83s/it] 46%|████▌     | 5900/12825 [21:07:49<24:34:18, 12.77s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120484.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103715.29lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5900
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5900/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5900/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5850] due to args.save_total_limit
 46%|████▌     | 5901/12825 [21:08:02<24:38:35, 12.81s/it] 46%|████▌     | 5902/12825 [21:08:14<24:35:35, 12.79s/it] 46%|████▌     | 5903/12825 [21:08:27<24:26:34, 12.71s/it] 46%|████▌     | 5904/12825 [21:08:39<24:21:31, 12.67s/it] 46%|████▌     | 5905/12825 [21:08:52<24:17:11, 12.63s/it] 46%|████▌     | 5906/12825 [21:09:04<24:14:40, 12.61s/it] 46%|████▌     | 5907/12825 [21:09:17<24:12:31, 12.60s/it] 46%|████▌     | 5908/12825 [21:09:30<24:10:09, 12.58s/it] 46%|████▌     | 5909/12825 [21:09:42<24:09:49, 12.58s/it] 46%|████▌     | 5910/12825 [21:09:55<24:09:47, 12.58s/it] 46%|████▌     | 5911/12825 [21:10:07<24:09:15, 12.58s/it] 46%|████▌     | 5912/12825 [21:10:20<24:08:53, 12.58s/it] 46%|████▌     | 5913/12825 [21:10:32<24:08:14, 12.57s/it] 46%|████▌     | 5914/12825 [21:10:45<24:08:22, 12.57s/it] 46%|████▌     | 5915/12825 [21:10:58<24:08:03, 12.57s/it] 46%|████▌     | 5916/12825 [21:11:10<24:08:43, 12.58s/it] 46%|████▌     | 5917/12825 [21:11:23<24:08:59, 12.59s/it] 46%|████▌     | 5918/12825 [21:11:35<24:09:14, 12.59s/it] 46%|████▌     | 5919/12825 [21:11:48<24:11:17, 12.61s/it] 46%|████▌     | 5920/12825 [21:12:01<24:10:24, 12.60s/it] 46%|████▌     | 5921/12825 [21:12:13<24:09:31, 12.60s/it] 46%|████▌     | 5922/12825 [21:12:26<24:09:48, 12.60s/it] 46%|████▌     | 5923/12825 [21:12:38<24:08:56, 12.60s/it] 46%|████▌     | 5924/12825 [21:12:51<24:07:56, 12.59s/it] 46%|████▌     | 5925/12825 [21:13:11<28:23:38, 14.81s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120405.14lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103726.12lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5925
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5925/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5925/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5900] due to args.save_total_limit
 46%|████▌     | 5926/12825 [21:13:24<27:16:39, 14.23s/it] 46%|████▌     | 5927/12825 [21:13:36<26:19:00, 13.73s/it] 46%|████▌     | 5928/12825 [21:13:49<25:42:38, 13.42s/it] 46%|████▌     | 5929/12825 [21:14:02<25:13:41, 13.17s/it] 46%|████▌     | 5930/12825 [21:14:14<24:54:53, 13.01s/it] 46%|████▌     | 5931/12825 [21:14:27<24:39:39, 12.88s/it] 46%|████▋     | 5932/12825 [21:14:39<24:29:11, 12.79s/it] 46%|████▋     | 5933/12825 [21:14:52<24:20:08, 12.71s/it] 46%|████▋     | 5934/12825 [21:15:05<24:14:51, 12.67s/it] 46%|████▋     | 5935/12825 [21:15:17<24:12:10, 12.65s/it] 46%|████▋     | 5936/12825 [21:15:30<24:08:51, 12.62s/it] 46%|████▋     | 5937/12825 [21:15:42<24:07:49, 12.61s/it] 46%|████▋     | 5938/12825 [21:15:55<24:04:32, 12.58s/it] 46%|████▋     | 5939/12825 [21:16:07<24:03:39, 12.58s/it] 46%|████▋     | 5940/12825 [21:16:20<24:06:22, 12.60s/it] 46%|████▋     | 5941/12825 [21:16:33<24:05:05, 12.60s/it] 46%|████▋     | 5942/12825 [21:16:45<24:05:14, 12.60s/it] 46%|████▋     | 5943/12825 [21:16:58<24:04:38, 12.60s/it] 46%|████▋     | 5944/12825 [21:17:10<24:03:00, 12.58s/it] 46%|████▋     | 5945/12825 [21:17:23<24:01:50, 12.57s/it] 46%|████▋     | 5946/12825 [21:17:36<24:01:15, 12.57s/it] 46%|████▋     | 5947/12825 [21:17:48<24:00:46, 12.57s/it] 46%|████▋     | 5948/12825 [21:18:01<24:00:29, 12.57s/it] 46%|████▋     | 5949/12825 [21:18:13<24:03:56, 12.60s/it] 46%|████▋     | 5950/12825 [21:18:26<24:03:42, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 78787.32lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 71241.19lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5950
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5950/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5950/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5925] due to args.save_total_limit
 46%|████▋     | 5951/12825 [21:18:39<24:19:33, 12.74s/it] 46%|████▋     | 5952/12825 [21:18:52<24:14:19, 12.70s/it] 46%|████▋     | 5953/12825 [21:19:04<24:11:21, 12.67s/it] 46%|████▋     | 5954/12825 [21:19:17<24:08:50, 12.65s/it] 46%|████▋     | 5955/12825 [21:19:29<24:06:20, 12.63s/it] 46%|████▋     | 5956/12825 [21:19:42<24:06:05, 12.63s/it] 46%|████▋     | 5957/12825 [21:19:55<24:04:23, 12.62s/it] 46%|████▋     | 5958/12825 [21:20:15<28:19:39, 14.85s/it] 46%|████▋     | 5959/12825 [21:20:27<26:59:21, 14.15s/it] 46%|████▋     | 5960/12825 [21:20:40<26:03:19, 13.66s/it] 46%|████▋     | 5961/12825 [21:20:52<25:24:20, 13.32s/it] 46%|████▋     | 5962/12825 [21:21:05<24:57:36, 13.09s/it] 46%|████▋     | 5963/12825 [21:21:17<24:38:30, 12.93s/it] 47%|████▋     | 5964/12825 [21:21:30<24:26:50, 12.83s/it] 47%|████▋     | 5965/12825 [21:21:42<24:17:25, 12.75s/it] 47%|████▋     | 5966/12825 [21:21:55<24:10:41, 12.69s/it] 47%|████▋     | 5967/12825 [21:22:08<24:06:28, 12.66s/it] 47%|████▋     | 5968/12825 [21:22:20<24:03:36, 12.63s/it] 47%|████▋     | 5969/12825 [21:22:33<24:00:39, 12.61s/it] 47%|████▋     | 5970/12825 [21:22:45<23:57:41, 12.58s/it] 47%|████▋     | 5971/12825 [21:22:58<23:56:49, 12.58s/it] 47%|████▋     | 5972/12825 [21:23:10<23:59:38, 12.60s/it] 47%|████▋     | 5973/12825 [21:23:23<23:55:52, 12.57s/it] 47%|████▋     | 5974/12825 [21:23:36<23:58:36, 12.60s/it] 47%|████▋     | 5975/12825 [21:23:48<23:57:13, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120493.40lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103737.71lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5975
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5975/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5975/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-5975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5950] due to args.save_total_limit
 47%|████▋     | 5976/12825 [21:24:01<24:08:08, 12.69s/it] 47%|████▋     | 5977/12825 [21:24:14<24:04:59, 12.66s/it] 47%|████▋     | 5978/12825 [21:24:26<24:04:29, 12.66s/it] 47%|████▋     | 5979/12825 [21:24:39<24:00:46, 12.63s/it] 47%|████▋     | 5980/12825 [21:24:52<23:58:17, 12.61s/it] 47%|████▋     | 5981/12825 [21:25:04<23:56:33, 12.59s/it] 47%|████▋     | 5982/12825 [21:25:17<23:58:12, 12.61s/it] 47%|████▋     | 5983/12825 [21:25:29<23:57:16, 12.60s/it] 47%|████▋     | 5984/12825 [21:25:42<23:57:10, 12.60s/it] 47%|████▋     | 5985/12825 [21:25:55<23:56:57, 12.60s/it] 47%|████▋     | 5986/12825 [21:26:07<24:00:39, 12.64s/it] 47%|████▋     | 5987/12825 [21:26:20<24:06:39, 12.69s/it] 47%|████▋     | 5988/12825 [21:26:33<24:03:49, 12.67s/it] 47%|████▋     | 5989/12825 [21:26:45<24:06:27, 12.70s/it] 47%|████▋     | 5990/12825 [21:27:06<28:26:38, 14.98s/it] 47%|████▋     | 5991/12825 [21:27:18<27:09:40, 14.31s/it] 47%|████▋     | 5992/12825 [21:27:31<26:17:40, 13.85s/it] 47%|████▋     | 5993/12825 [21:27:44<25:39:58, 13.52s/it] 47%|████▋     | 5994/12825 [21:27:57<25:13:20, 13.29s/it] 47%|████▋     | 5995/12825 [21:28:10<24:54:33, 13.13s/it] 47%|████▋     | 5996/12825 [21:28:22<24:42:13, 13.02s/it] 47%|████▋     | 5997/12825 [21:28:35<24:33:46, 12.95s/it] 47%|████▋     | 5998/12825 [21:28:48<24:23:09, 12.86s/it] 47%|████▋     | 5999/12825 [21:29:00<24:17:18, 12.81s/it] 47%|████▋     | 6000/12825 [21:29:13<24:11:03, 12.76s/it]                                                           47%|████▋     | 6000/12825 [21:29:13<24:11:03, 12.76s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120296.93lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103618.21lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6000
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6000/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6000/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5975] due to args.save_total_limit
 47%|████▋     | 6001/12825 [21:29:26<24:18:22, 12.82s/it] 47%|████▋     | 6002/12825 [21:29:39<24:11:11, 12.76s/it] 47%|████▋     | 6003/12825 [21:29:51<24:05:50, 12.72s/it] 47%|████▋     | 6004/12825 [21:30:04<24:02:13, 12.69s/it] 47%|████▋     | 6005/12825 [21:30:16<23:59:30, 12.66s/it] 47%|████▋     | 6006/12825 [21:30:29<23:59:40, 12.67s/it] 47%|████▋     | 6007/12825 [21:30:42<23:56:59, 12.65s/it] 47%|████▋     | 6008/12825 [21:30:54<23:56:46, 12.65s/it] 47%|████▋     | 6009/12825 [21:31:07<23:57:03, 12.65s/it] 47%|████▋     | 6010/12825 [21:31:20<23:55:45, 12.64s/it] 47%|████▋     | 6011/12825 [21:31:32<23:54:46, 12.63s/it] 47%|████▋     | 6012/12825 [21:31:45<23:54:00, 12.63s/it] 47%|████▋     | 6013/12825 [21:31:58<23:54:27, 12.63s/it] 47%|████▋     | 6014/12825 [21:32:10<23:54:04, 12.63s/it] 47%|████▋     | 6015/12825 [21:32:23<23:54:15, 12.64s/it] 47%|████▋     | 6016/12825 [21:32:35<23:53:56, 12.64s/it] 47%|████▋     | 6017/12825 [21:32:48<23:53:12, 12.63s/it] 47%|████▋     | 6018/12825 [21:33:01<23:53:28, 12.64s/it] 47%|████▋     | 6019/12825 [21:33:13<23:53:13, 12.63s/it] 47%|████▋     | 6020/12825 [21:33:26<23:52:32, 12.63s/it] 47%|████▋     | 6021/12825 [21:33:39<23:53:28, 12.64s/it] 47%|████▋     | 6022/12825 [21:33:59<28:02:29, 14.84s/it] 47%|████▋     | 6023/12825 [21:34:11<26:45:39, 14.16s/it] 47%|████▋     | 6024/12825 [21:34:24<25:53:37, 13.71s/it] 47%|████▋     | 6025/12825 [21:34:36<25:15:22, 13.37s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120372.76lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103706.74lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6025
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6025/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6025/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6000] due to args.save_total_limit
 47%|████▋     | 6026/12825 [21:34:49<25:01:36, 13.25s/it] 47%|████▋     | 6027/12825 [21:35:02<24:39:31, 13.06s/it] 47%|████▋     | 6028/12825 [21:35:15<24:29:50, 12.97s/it] 47%|████▋     | 6029/12825 [21:35:27<24:17:43, 12.87s/it] 47%|████▋     | 6030/12825 [21:35:40<24:10:46, 12.81s/it] 47%|████▋     | 6031/12825 [21:35:53<24:04:37, 12.76s/it] 47%|████▋     | 6032/12825 [21:36:05<23:59:56, 12.72s/it] 47%|████▋     | 6033/12825 [21:36:18<23:56:42, 12.69s/it] 47%|████▋     | 6034/12825 [21:36:31<23:53:06, 12.66s/it] 47%|████▋     | 6035/12825 [21:36:43<23:50:40, 12.64s/it] 47%|████▋     | 6036/12825 [21:36:56<23:50:10, 12.64s/it] 47%|████▋     | 6037/12825 [21:37:08<23:51:03, 12.65s/it] 47%|████▋     | 6038/12825 [21:37:21<23:48:51, 12.63s/it] 47%|████▋     | 6039/12825 [21:37:34<23:49:00, 12.63s/it] 47%|████▋     | 6040/12825 [21:37:46<23:49:21, 12.64s/it] 47%|████▋     | 6041/12825 [21:37:59<23:48:57, 12.64s/it] 47%|████▋     | 6042/12825 [21:38:12<23:50:50, 12.66s/it] 47%|████▋     | 6043/12825 [21:38:24<23:51:43, 12.67s/it] 47%|████▋     | 6044/12825 [21:38:37<23:50:56, 12.66s/it] 47%|████▋     | 6045/12825 [21:38:50<23:48:40, 12.64s/it] 47%|████▋     | 6046/12825 [21:39:02<23:47:52, 12.64s/it] 47%|████▋     | 6047/12825 [21:39:15<23:45:58, 12.62s/it] 47%|████▋     | 6048/12825 [21:39:27<23:45:48, 12.62s/it] 47%|████▋     | 6049/12825 [21:39:40<23:50:08, 12.66s/it] 47%|████▋     | 6050/12825 [21:39:53<23:49:05, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120492.51lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103724.13lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6050
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6050/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6050/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6025] due to args.save_total_limit
 47%|████▋     | 6051/12825 [21:40:06<23:58:11, 12.74s/it] 47%|████▋     | 6052/12825 [21:40:19<23:56:50, 12.73s/it] 47%|████▋     | 6053/12825 [21:40:31<23:52:43, 12.69s/it] 47%|████▋     | 6054/12825 [21:40:44<23:48:49, 12.66s/it] 47%|████▋     | 6055/12825 [21:41:04<28:00:44, 14.90s/it] 47%|████▋     | 6056/12825 [21:41:16<26:42:02, 14.20s/it] 47%|████▋     | 6057/12825 [21:41:29<25:48:06, 13.72s/it] 47%|████▋     | 6058/12825 [21:41:42<25:16:10, 13.44s/it] 47%|████▋     | 6059/12825 [21:41:54<24:47:36, 13.19s/it] 47%|████▋     | 6060/12825 [21:42:07<24:27:15, 13.01s/it] 47%|████▋     | 6061/12825 [21:42:20<24:13:45, 12.90s/it] 47%|████▋     | 6062/12825 [21:42:32<24:04:09, 12.81s/it] 47%|████▋     | 6063/12825 [21:42:45<24:02:45, 12.80s/it] 47%|████▋     | 6064/12825 [21:42:58<23:54:39, 12.73s/it] 47%|████▋     | 6065/12825 [21:43:10<23:49:43, 12.69s/it] 47%|████▋     | 6066/12825 [21:43:23<23:47:49, 12.67s/it] 47%|████▋     | 6067/12825 [21:43:35<23:44:14, 12.64s/it] 47%|████▋     | 6068/12825 [21:43:48<23:46:12, 12.66s/it] 47%|████▋     | 6069/12825 [21:44:01<23:43:09, 12.64s/it] 47%|████▋     | 6070/12825 [21:44:13<23:41:18, 12.62s/it] 47%|████▋     | 6071/12825 [21:44:26<23:43:15, 12.64s/it] 47%|████▋     | 6072/12825 [21:44:39<23:41:54, 12.63s/it] 47%|████▋     | 6073/12825 [21:44:51<23:40:36, 12.62s/it] 47%|████▋     | 6074/12825 [21:45:04<23:40:42, 12.63s/it] 47%|████▋     | 6075/12825 [21:45:16<23:39:58, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120392.59lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103729.45lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6075
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6075/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6075/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6050] due to args.save_total_limit
 47%|████▋     | 6076/12825 [21:45:30<23:56:04, 12.77s/it] 47%|████▋     | 6077/12825 [21:45:42<23:55:46, 12.77s/it] 47%|████▋     | 6078/12825 [21:45:55<23:55:43, 12.77s/it] 47%|████▋     | 6079/12825 [21:46:08<23:54:41, 12.76s/it] 47%|████▋     | 6080/12825 [21:46:21<23:54:41, 12.76s/it] 47%|████▋     | 6081/12825 [21:46:33<23:55:01, 12.77s/it] 47%|████▋     | 6082/12825 [21:46:46<23:54:25, 12.76s/it] 47%|████▋     | 6083/12825 [21:46:59<23:54:53, 12.77s/it] 47%|████▋     | 6084/12825 [21:47:12<23:56:23, 12.78s/it] 47%|████▋     | 6085/12825 [21:47:25<23:58:03, 12.80s/it] 47%|████▋     | 6086/12825 [21:47:37<23:57:07, 12.80s/it] 47%|████▋     | 6087/12825 [21:47:58<28:09:38, 15.05s/it] 47%|████▋     | 6088/12825 [21:48:10<26:51:45, 14.35s/it] 47%|████▋     | 6089/12825 [21:48:23<25:59:04, 13.89s/it] 47%|████▋     | 6090/12825 [21:48:36<25:20:35, 13.55s/it] 47%|████▋     | 6091/12825 [21:48:49<24:54:26, 13.32s/it] 48%|████▊     | 6092/12825 [21:49:01<24:35:08, 13.15s/it] 48%|████▊     | 6093/12825 [21:49:14<24:21:11, 13.02s/it] 48%|████▊     | 6094/12825 [21:49:27<24:12:56, 12.95s/it] 48%|████▊     | 6095/12825 [21:49:40<24:07:50, 12.91s/it] 48%|████▊     | 6096/12825 [21:49:53<24:02:30, 12.86s/it] 48%|████▊     | 6097/12825 [21:50:05<23:59:20, 12.84s/it] 48%|████▊     | 6098/12825 [21:50:18<24:00:53, 12.85s/it] 48%|████▊     | 6099/12825 [21:50:31<23:57:31, 12.82s/it] 48%|████▊     | 6100/12825 [21:50:44<23:56:04, 12.81s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120386.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103599.44lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6075] due to args.save_total_limit
 48%|████▊     | 6101/12825 [21:50:57<23:59:58, 12.85s/it] 48%|████▊     | 6102/12825 [21:51:09<23:51:58, 12.78s/it] 48%|████▊     | 6103/12825 [21:51:22<23:47:11, 12.74s/it] 48%|████▊     | 6104/12825 [21:51:35<23:42:35, 12.70s/it] 48%|████▊     | 6105/12825 [21:51:47<23:39:43, 12.68s/it] 48%|████▊     | 6106/12825 [21:52:00<23:37:05, 12.65s/it] 48%|████▊     | 6107/12825 [21:52:12<23:35:29, 12.64s/it] 48%|████▊     | 6108/12825 [21:52:25<23:34:45, 12.64s/it] 48%|████▊     | 6109/12825 [21:52:38<23:33:45, 12.63s/it] 48%|████▊     | 6110/12825 [21:52:50<23:33:49, 12.63s/it] 48%|████▊     | 6111/12825 [21:53:03<23:35:26, 12.65s/it] 48%|████▊     | 6112/12825 [21:53:16<23:34:10, 12.64s/it] 48%|████▊     | 6113/12825 [21:53:28<23:37:39, 12.67s/it] 48%|████▊     | 6114/12825 [21:53:41<23:35:31, 12.66s/it] 48%|████▊     | 6115/12825 [21:53:54<23:33:55, 12.64s/it] 48%|████▊     | 6116/12825 [21:54:06<23:31:53, 12.63s/it] 48%|████▊     | 6117/12825 [21:54:19<23:31:24, 12.62s/it] 48%|████▊     | 6118/12825 [21:54:31<23:30:55, 12.62s/it] 48%|████▊     | 6119/12825 [21:54:51<27:35:56, 14.82s/it] 48%|████▊     | 6120/12825 [21:55:04<26:20:31, 14.14s/it] 48%|████▊     | 6121/12825 [21:55:16<25:27:43, 13.67s/it] 48%|████▊     | 6122/12825 [21:55:29<24:50:23, 13.34s/it] 48%|████▊     | 6123/12825 [21:55:42<24:23:49, 13.10s/it] 48%|████▊     | 6124/12825 [21:55:54<24:04:38, 12.94s/it] 48%|████▊     | 6125/12825 [21:56:07<23:52:04, 12.82s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120495.84lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103712.44lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-5875] due to args.save_total_limit
 48%|████▊     | 6126/12825 [21:56:20<23:55:56, 12.86s/it] 48%|████▊     | 6127/12825 [21:56:32<23:47:02, 12.78s/it] 48%|████▊     | 6128/12825 [21:56:45<23:40:32, 12.73s/it] 48%|████▊     | 6129/12825 [21:56:57<23:36:32, 12.69s/it] 48%|████▊     | 6130/12825 [21:57:10<23:34:03, 12.67s/it] 48%|████▊     | 6131/12825 [21:57:23<23:33:02, 12.67s/it] 48%|████▊     | 6132/12825 [21:57:35<23:30:52, 12.65s/it] 48%|████▊     | 6133/12825 [21:57:48<23:29:28, 12.64s/it] 48%|████▊     | 6134/12825 [21:58:01<23:29:02, 12.64s/it] 48%|████▊     | 6135/12825 [21:58:13<23:28:49, 12.64s/it] 48%|████▊     | 6136/12825 [21:58:26<23:27:57, 12.63s/it] 48%|████▊     | 6137/12825 [21:58:38<23:29:22, 12.64s/it] 48%|████▊     | 6138/12825 [21:58:51<23:29:12, 12.64s/it] 48%|████▊     | 6139/12825 [21:59:04<23:28:40, 12.64s/it] 48%|████▊     | 6140/12825 [21:59:16<23:28:43, 12.64s/it] 48%|████▊     | 6141/12825 [21:59:29<23:28:39, 12.65s/it] 48%|████▊     | 6142/12825 [21:59:42<23:30:57, 12.67s/it] 48%|████▊     | 6143/12825 [21:59:54<23:31:18, 12.67s/it] 48%|████▊     | 6144/12825 [22:00:07<23:30:55, 12.67s/it] 48%|████▊     | 6145/12825 [22:00:20<23:30:11, 12.67s/it] 48%|████▊     | 6146/12825 [22:00:32<23:31:12, 12.68s/it] 48%|████▊     | 6147/12825 [22:00:45<23:30:04, 12.67s/it] 48%|████▊     | 6148/12825 [22:00:58<23:28:01, 12.65s/it] 48%|████▊     | 6149/12825 [22:01:11<23:30:48, 12.68s/it] 48%|████▊     | 6150/12825 [22:01:23<23:33:01, 12.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120385.17lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103715.67lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6100] due to args.save_total_limit
 48%|████▊     | 6151/12825 [22:01:36<23:41:56, 12.78s/it] 48%|████▊     | 6152/12825 [22:01:56<27:49:36, 15.01s/it] 48%|████▊     | 6153/12825 [22:02:09<26:28:35, 14.29s/it] 48%|████▊     | 6154/12825 [22:02:22<25:32:56, 13.79s/it] 48%|████▊     | 6155/12825 [22:02:30<22:17:36, 12.03s/it] 48%|████▊     | 6156/12825 [22:02:30<16:03:36,  8.67s/it] 48%|████▊     | 6157/12825 [22:02:56<25:26:03, 13.73s/it] 48%|████▊     | 6158/12825 [22:03:09<24:50:24, 13.41s/it] 48%|████▊     | 6159/12825 [22:03:21<24:24:43, 13.18s/it] 48%|████▊     | 6160/12825 [22:03:34<24:06:35, 13.02s/it] 48%|████▊     | 6161/12825 [22:03:47<23:54:39, 12.92s/it] 48%|████▊     | 6162/12825 [22:03:59<23:45:33, 12.84s/it] 48%|████▊     | 6163/12825 [22:04:12<23:40:52, 12.80s/it] 48%|████▊     | 6164/12825 [22:04:25<23:38:11, 12.77s/it] 48%|████▊     | 6165/12825 [22:04:37<23:33:12, 12.73s/it] 48%|████▊     | 6166/12825 [22:04:50<23:30:04, 12.71s/it] 48%|████▊     | 6167/12825 [22:05:03<23:27:48, 12.69s/it] 48%|████▊     | 6168/12825 [22:05:15<23:28:43, 12.70s/it] 48%|████▊     | 6169/12825 [22:05:28<23:25:57, 12.67s/it] 48%|████▊     | 6170/12825 [22:05:41<23:27:12, 12.69s/it] 48%|████▊     | 6171/12825 [22:05:53<23:26:16, 12.68s/it] 48%|████▊     | 6172/12825 [22:06:06<23:25:15, 12.67s/it] 48%|████▊     | 6173/12825 [22:06:19<23:26:05, 12.68s/it] 48%|████▊     | 6174/12825 [22:06:31<23:24:31, 12.67s/it] 48%|████▊     | 6175/12825 [22:06:44<23:23:25, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120452.65lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103687.94lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6150] due to args.save_total_limit
 48%|████▊     | 6176/12825 [22:06:57<23:40:01, 12.81s/it] 48%|████▊     | 6177/12825 [22:07:10<23:35:57, 12.78s/it] 48%|████▊     | 6178/12825 [22:07:23<23:32:23, 12.75s/it] 48%|████▊     | 6179/12825 [22:07:35<23:28:25, 12.72s/it] 48%|████▊     | 6180/12825 [22:07:48<23:26:47, 12.70s/it] 48%|████▊     | 6181/12825 [22:08:00<23:25:57, 12.70s/it] 48%|████▊     | 6182/12825 [22:08:13<23:25:02, 12.69s/it] 48%|████▊     | 6183/12825 [22:08:26<23:23:15, 12.68s/it] 48%|████▊     | 6184/12825 [22:08:38<23:23:09, 12.68s/it] 48%|████▊     | 6185/12825 [22:08:59<27:37:49, 14.98s/it] 48%|████▊     | 6186/12825 [22:09:11<26:18:45, 14.27s/it] 48%|████▊     | 6187/12825 [22:09:24<25:22:43, 13.76s/it] 48%|████▊     | 6188/12825 [22:09:37<24:45:06, 13.43s/it] 48%|████▊     | 6189/12825 [22:09:49<24:18:11, 13.18s/it] 48%|████▊     | 6190/12825 [22:10:02<24:02:19, 13.04s/it] 48%|████▊     | 6191/12825 [22:10:15<23:47:39, 12.91s/it] 48%|████▊     | 6192/12825 [22:10:27<23:37:54, 12.83s/it] 48%|████▊     | 6193/12825 [22:10:40<23:30:16, 12.76s/it] 48%|████▊     | 6194/12825 [22:10:52<23:25:42, 12.72s/it] 48%|████▊     | 6195/12825 [22:11:05<23:23:16, 12.70s/it] 48%|████▊     | 6196/12825 [22:11:18<23:22:33, 12.69s/it] 48%|████▊     | 6197/12825 [22:11:30<23:20:00, 12.67s/it] 48%|████▊     | 6198/12825 [22:11:43<23:18:37, 12.66s/it] 48%|████▊     | 6199/12825 [22:11:56<23:17:32, 12.66s/it] 48%|████▊     | 6200/12825 [22:12:08<23:16:15, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120271.00lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103562.11lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6175] due to args.save_total_limit
 48%|████▊     | 6201/12825 [22:12:21<23:27:12, 12.75s/it] 48%|████▊     | 6202/12825 [22:12:34<23:23:52, 12.72s/it] 48%|████▊     | 6203/12825 [22:12:47<23:24:28, 12.73s/it] 48%|████▊     | 6204/12825 [22:12:59<23:22:33, 12.71s/it] 48%|████▊     | 6205/12825 [22:13:12<23:20:23, 12.69s/it] 48%|████▊     | 6206/12825 [22:13:25<23:19:26, 12.69s/it] 48%|████▊     | 6207/12825 [22:13:37<23:18:56, 12.68s/it] 48%|████▊     | 6208/12825 [22:13:50<23:18:47, 12.68s/it] 48%|████▊     | 6209/12825 [22:14:03<23:18:10, 12.68s/it] 48%|████▊     | 6210/12825 [22:14:15<23:17:38, 12.68s/it] 48%|████▊     | 6211/12825 [22:14:28<23:14:59, 12.65s/it] 48%|████▊     | 6212/12825 [22:14:41<23:13:34, 12.64s/it] 48%|████▊     | 6213/12825 [22:14:53<23:14:23, 12.65s/it] 48%|████▊     | 6214/12825 [22:15:06<23:14:28, 12.66s/it] 48%|████▊     | 6215/12825 [22:15:19<23:13:48, 12.65s/it] 48%|████▊     | 6216/12825 [22:15:31<23:14:50, 12.66s/it] 48%|████▊     | 6217/12825 [22:15:51<27:22:23, 14.91s/it] 48%|████▊     | 6218/12825 [22:16:04<26:06:11, 14.22s/it] 48%|████▊     | 6219/12825 [22:16:17<25:13:09, 13.74s/it] 48%|████▊     | 6220/12825 [22:16:29<24:35:12, 13.40s/it] 49%|████▊     | 6221/12825 [22:16:42<24:08:42, 13.16s/it] 49%|████▊     | 6222/12825 [22:16:55<23:56:32, 13.05s/it] 49%|████▊     | 6223/12825 [22:17:07<23:41:56, 12.92s/it] 49%|████▊     | 6224/12825 [22:17:20<23:30:38, 12.82s/it] 49%|████▊     | 6225/12825 [22:17:33<23:24:20, 12.77s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120417.68lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103673.23lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6200] due to args.save_total_limit
 49%|████▊     | 6226/12825 [22:17:46<23:30:48, 12.83s/it] 49%|████▊     | 6227/12825 [22:17:58<23:24:48, 12.77s/it] 49%|████▊     | 6228/12825 [22:18:11<23:20:46, 12.74s/it] 49%|████▊     | 6229/12825 [22:18:24<23:18:18, 12.72s/it] 49%|████▊     | 6230/12825 [22:18:36<23:15:26, 12.70s/it] 49%|████▊     | 6231/12825 [22:18:49<23:17:42, 12.72s/it] 49%|████▊     | 6232/12825 [22:19:02<23:16:28, 12.71s/it] 49%|████▊     | 6233/12825 [22:19:14<23:15:37, 12.70s/it] 49%|████▊     | 6234/12825 [22:19:27<23:14:25, 12.69s/it] 49%|████▊     | 6235/12825 [22:19:40<23:14:42, 12.70s/it] 49%|████▊     | 6236/12825 [22:19:52<23:13:45, 12.69s/it] 49%|████▊     | 6237/12825 [22:20:05<23:12:53, 12.69s/it] 49%|████▊     | 6238/12825 [22:20:18<23:16:34, 12.72s/it] 49%|████▊     | 6239/12825 [22:20:31<23:16:23, 12.72s/it] 49%|████▊     | 6240/12825 [22:20:43<23:15:34, 12.72s/it] 49%|████▊     | 6241/12825 [22:20:56<23:17:16, 12.73s/it] 49%|████▊     | 6242/12825 [22:21:09<23:16:25, 12.73s/it] 49%|████▊     | 6243/12825 [22:21:22<23:17:27, 12.74s/it] 49%|████▊     | 6244/12825 [22:21:34<23:18:58, 12.75s/it] 49%|████▊     | 6245/12825 [22:21:47<23:15:14, 12.72s/it] 49%|████▊     | 6246/12825 [22:22:00<23:12:34, 12.70s/it] 49%|████▊     | 6247/12825 [22:22:12<23:10:57, 12.69s/it] 49%|████▊     | 6248/12825 [22:22:25<23:09:10, 12.67s/it] 49%|████▊     | 6249/12825 [22:22:44<26:32:29, 14.53s/it] 49%|████▊     | 6250/12825 [22:22:56<25:29:01, 13.95s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120333.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103584.09lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6225] due to args.save_total_limit
 49%|████▊     | 6251/12825 [22:23:09<24:56:03, 13.65s/it] 49%|████▊     | 6252/12825 [22:23:22<24:22:32, 13.35s/it] 49%|████▉     | 6253/12825 [22:23:35<23:58:18, 13.13s/it] 49%|████▉     | 6254/12825 [22:23:47<23:42:11, 12.99s/it] 49%|████▉     | 6255/12825 [22:24:00<23:30:49, 12.88s/it] 49%|████▉     | 6256/12825 [22:24:13<23:23:12, 12.82s/it] 49%|████▉     | 6257/12825 [22:24:25<23:16:55, 12.76s/it] 49%|████▉     | 6258/12825 [22:24:38<23:12:21, 12.72s/it] 49%|████▉     | 6259/12825 [22:24:50<23:09:11, 12.69s/it] 49%|████▉     | 6260/12825 [22:25:03<23:06:34, 12.67s/it] 49%|████▉     | 6261/12825 [22:25:16<23:04:25, 12.65s/it] 49%|████▉     | 6262/12825 [22:25:28<23:04:01, 12.65s/it] 49%|████▉     | 6263/12825 [22:25:41<23:03:23, 12.65s/it] 49%|████▉     | 6264/12825 [22:25:54<23:02:11, 12.64s/it] 49%|████▉     | 6265/12825 [22:26:06<23:01:38, 12.64s/it] 49%|████▉     | 6266/12825 [22:26:19<23:01:01, 12.63s/it] 49%|████▉     | 6267/12825 [22:26:31<23:01:11, 12.64s/it] 49%|████▉     | 6268/12825 [22:26:44<23:00:31, 12.63s/it] 49%|████▉     | 6269/12825 [22:26:57<22:59:56, 12.63s/it] 49%|████▉     | 6270/12825 [22:27:09<22:59:13, 12.62s/it] 49%|████▉     | 6271/12825 [22:27:22<22:57:46, 12.61s/it] 49%|████▉     | 6272/12825 [22:27:35<22:58:01, 12.62s/it] 49%|████▉     | 6273/12825 [22:27:47<22:57:22, 12.61s/it] 49%|████▉     | 6274/12825 [22:28:00<22:57:22, 12.62s/it] 49%|████▉     | 6275/12825 [22:28:12<22:58:23, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120334.51lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103602.66lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6250] due to args.save_total_limit
 49%|████▉     | 6276/12825 [22:28:25<23:08:32, 12.72s/it] 49%|████▉     | 6277/12825 [22:28:38<23:05:07, 12.69s/it] 49%|████▉     | 6278/12825 [22:28:51<23:05:51, 12.70s/it] 49%|████▉     | 6279/12825 [22:29:03<23:03:42, 12.68s/it] 49%|████▉     | 6280/12825 [22:29:16<23:01:57, 12.67s/it] 49%|████▉     | 6281/12825 [22:29:29<22:59:58, 12.65s/it] 49%|████▉     | 6282/12825 [22:29:48<26:27:05, 14.55s/it] 49%|████▉     | 6283/12825 [22:30:00<25:26:37, 14.00s/it] 49%|████▉     | 6284/12825 [22:30:13<24:41:07, 13.59s/it] 49%|████▉     | 6285/12825 [22:30:25<24:08:22, 13.29s/it] 49%|████▉     | 6286/12825 [22:30:38<23:44:36, 13.07s/it] 49%|████▉     | 6287/12825 [22:30:51<23:29:14, 12.93s/it] 49%|████▉     | 6288/12825 [22:31:03<23:18:25, 12.84s/it] 49%|████▉     | 6289/12825 [22:31:16<23:10:42, 12.77s/it] 49%|████▉     | 6290/12825 [22:31:29<23:07:48, 12.74s/it] 49%|████▉     | 6291/12825 [22:31:41<23:05:07, 12.72s/it] 49%|████▉     | 6292/12825 [22:31:54<23:03:20, 12.70s/it] 49%|████▉     | 6293/12825 [22:32:07<23:00:03, 12.68s/it] 49%|████▉     | 6294/12825 [22:32:19<22:59:07, 12.67s/it] 49%|████▉     | 6295/12825 [22:32:32<22:56:39, 12.65s/it] 49%|████▉     | 6296/12825 [22:32:44<22:54:11, 12.63s/it] 49%|████▉     | 6297/12825 [22:32:57<22:53:45, 12.63s/it] 49%|████▉     | 6298/12825 [22:33:10<22:53:19, 12.62s/it] 49%|████▉     | 6299/12825 [22:33:22<22:52:27, 12.62s/it] 49%|████▉     | 6300/12825 [22:33:35<22:51:47, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120443.81lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103681.11lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6275] due to args.save_total_limit
 49%|████▉     | 6301/12825 [22:33:48<23:02:40, 12.72s/it] 49%|████▉     | 6302/12825 [22:34:00<22:59:22, 12.69s/it] 49%|████▉     | 6303/12825 [22:34:13<22:57:06, 12.67s/it] 49%|████▉     | 6304/12825 [22:34:26<22:55:20, 12.65s/it] 49%|████▉     | 6305/12825 [22:34:38<22:54:47, 12.65s/it] 49%|████▉     | 6306/12825 [22:34:51<22:52:59, 12.64s/it] 49%|████▉     | 6307/12825 [22:35:04<22:53:00, 12.64s/it] 49%|████▉     | 6308/12825 [22:35:16<22:53:15, 12.64s/it] 49%|████▉     | 6309/12825 [22:35:29<22:51:45, 12.63s/it] 49%|████▉     | 6310/12825 [22:35:41<22:51:20, 12.63s/it] 49%|████▉     | 6311/12825 [22:35:54<22:49:25, 12.61s/it] 49%|████▉     | 6312/12825 [22:36:07<22:49:44, 12.62s/it] 49%|████▉     | 6313/12825 [22:36:19<22:49:36, 12.62s/it] 49%|████▉     | 6314/12825 [22:36:40<27:00:55, 14.94s/it] 49%|████▉     | 6315/12825 [22:36:52<25:45:55, 14.25s/it] 49%|████▉     | 6316/12825 [22:37:05<24:53:12, 13.76s/it] 49%|████▉     | 6317/12825 [22:37:17<24:15:58, 13.42s/it] 49%|████▉     | 6318/12825 [22:37:30<23:51:57, 13.20s/it] 49%|████▉     | 6319/12825 [22:37:43<23:31:39, 13.02s/it] 49%|████▉     | 6320/12825 [22:37:55<23:18:42, 12.90s/it] 49%|████▉     | 6321/12825 [22:38:08<23:09:18, 12.82s/it] 49%|████▉     | 6322/12825 [22:38:21<23:02:21, 12.75s/it] 49%|████▉     | 6323/12825 [22:38:33<22:58:13, 12.72s/it] 49%|████▉     | 6324/12825 [22:38:46<22:53:34, 12.68s/it] 49%|████▉     | 6325/12825 [22:38:58<22:50:27, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120401.68lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103741.99lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6300] due to args.save_total_limit
 49%|████▉     | 6326/12825 [22:39:11<23:00:16, 12.74s/it] 49%|████▉     | 6327/12825 [22:39:24<22:56:54, 12.71s/it] 49%|████▉     | 6328/12825 [22:39:37<22:54:47, 12.70s/it] 49%|████▉     | 6329/12825 [22:39:49<22:51:54, 12.67s/it] 49%|████▉     | 6330/12825 [22:40:02<22:49:40, 12.65s/it] 49%|████▉     | 6331/12825 [22:40:14<22:47:32, 12.64s/it] 49%|████▉     | 6332/12825 [22:40:27<22:45:53, 12.62s/it] 49%|████▉     | 6333/12825 [22:40:40<22:46:41, 12.63s/it] 49%|████▉     | 6334/12825 [22:40:52<22:50:01, 12.66s/it] 49%|████▉     | 6335/12825 [22:41:05<22:49:10, 12.66s/it] 49%|████▉     | 6336/12825 [22:41:18<22:48:11, 12.65s/it] 49%|████▉     | 6337/12825 [22:41:30<22:47:39, 12.65s/it] 49%|████▉     | 6338/12825 [22:41:43<22:46:47, 12.64s/it] 49%|████▉     | 6339/12825 [22:41:56<22:46:25, 12.64s/it] 49%|████▉     | 6340/12825 [22:42:08<22:45:19, 12.63s/it] 49%|████▉     | 6341/12825 [22:42:21<22:44:53, 12.63s/it] 49%|████▉     | 6342/12825 [22:42:34<22:44:49, 12.63s/it] 49%|████▉     | 6343/12825 [22:42:46<22:44:36, 12.63s/it] 49%|████▉     | 6344/12825 [22:42:59<22:44:12, 12.63s/it] 49%|████▉     | 6345/12825 [22:43:11<22:43:17, 12.62s/it] 49%|████▉     | 6346/12825 [22:43:32<26:47:40, 14.89s/it] 49%|████▉     | 6347/12825 [22:43:44<25:32:16, 14.19s/it] 49%|████▉     | 6348/12825 [22:43:57<24:40:12, 13.71s/it] 50%|████▉     | 6349/12825 [22:44:09<24:04:44, 13.39s/it] 50%|████▉     | 6350/12825 [22:44:22<23:39:45, 13.16s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120418.58lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103647.23lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6125] due to args.save_total_limit
 50%|████▉     | 6351/12825 [22:44:35<23:40:04, 13.16s/it] 50%|████▉     | 6352/12825 [22:44:48<23:23:33, 13.01s/it] 50%|████▉     | 6353/12825 [22:45:00<23:09:32, 12.88s/it] 50%|████▉     | 6354/12825 [22:45:13<22:59:35, 12.79s/it] 50%|████▉     | 6355/12825 [22:45:26<22:58:58, 12.79s/it] 50%|████▉     | 6356/12825 [22:45:39<22:57:48, 12.78s/it] 50%|████▉     | 6357/12825 [22:45:51<22:54:57, 12.75s/it] 50%|████▉     | 6358/12825 [22:46:04<22:50:24, 12.71s/it] 50%|████▉     | 6359/12825 [22:46:16<22:47:29, 12.69s/it] 50%|████▉     | 6360/12825 [22:46:29<22:45:12, 12.67s/it] 50%|████▉     | 6361/12825 [22:46:42<22:46:23, 12.68s/it] 50%|████▉     | 6362/12825 [22:46:54<22:44:20, 12.67s/it] 50%|████▉     | 6363/12825 [22:47:07<22:43:33, 12.66s/it] 50%|████▉     | 6364/12825 [22:47:20<22:41:27, 12.64s/it] 50%|████▉     | 6365/12825 [22:47:32<22:40:23, 12.64s/it] 50%|████▉     | 6366/12825 [22:47:45<22:42:18, 12.65s/it] 50%|████▉     | 6367/12825 [22:47:58<22:41:03, 12.65s/it] 50%|████▉     | 6368/12825 [22:48:10<22:40:25, 12.64s/it] 50%|████▉     | 6369/12825 [22:48:23<22:40:31, 12.64s/it] 50%|████▉     | 6370/12825 [22:48:36<22:39:32, 12.64s/it] 50%|████▉     | 6371/12825 [22:48:48<22:42:25, 12.67s/it] 50%|████▉     | 6372/12825 [22:49:01<22:45:15, 12.69s/it] 50%|████▉     | 6373/12825 [22:49:14<22:42:53, 12.67s/it] 50%|████▉     | 6374/12825 [22:49:26<22:41:18, 12.66s/it] 50%|████▉     | 6375/12825 [22:49:39<22:41:17, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120526.49lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103715.96lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6325] due to args.save_total_limit
 50%|████▉     | 6376/12825 [22:49:52<22:49:44, 12.74s/it] 50%|████▉     | 6377/12825 [22:50:04<22:44:27, 12.70s/it] 50%|████▉     | 6378/12825 [22:50:17<22:40:20, 12.66s/it] 50%|████▉     | 6379/12825 [22:50:37<26:43:44, 14.93s/it] 50%|████▉     | 6380/12825 [22:50:50<25:28:18, 14.23s/it] 50%|████▉     | 6381/12825 [22:51:03<24:38:08, 13.76s/it] 50%|████▉     | 6382/12825 [22:51:15<23:59:29, 13.41s/it] 50%|████▉     | 6383/12825 [22:51:28<23:32:22, 13.15s/it] 50%|████▉     | 6384/12825 [22:51:40<23:14:36, 12.99s/it] 50%|████▉     | 6385/12825 [22:51:53<23:00:52, 12.87s/it] 50%|████▉     | 6386/12825 [22:52:05<22:51:43, 12.78s/it] 50%|████▉     | 6387/12825 [22:52:18<22:47:28, 12.74s/it] 50%|████▉     | 6388/12825 [22:52:31<22:46:59, 12.74s/it] 50%|████▉     | 6389/12825 [22:52:43<22:42:16, 12.70s/it] 50%|████▉     | 6390/12825 [22:52:56<22:38:29, 12.67s/it] 50%|████▉     | 6391/12825 [22:53:09<22:36:56, 12.65s/it] 50%|████▉     | 6392/12825 [22:53:21<22:34:54, 12.64s/it] 50%|████▉     | 6393/12825 [22:53:34<22:34:27, 12.63s/it] 50%|████▉     | 6394/12825 [22:53:46<22:34:05, 12.63s/it] 50%|████▉     | 6395/12825 [22:53:59<22:33:49, 12.63s/it] 50%|████▉     | 6396/12825 [22:54:12<22:34:14, 12.64s/it] 50%|████▉     | 6397/12825 [22:54:24<22:31:50, 12.62s/it] 50%|████▉     | 6398/12825 [22:54:37<22:32:15, 12.62s/it] 50%|████▉     | 6399/12825 [22:54:50<22:31:32, 12.62s/it] 50%|████▉     | 6400/12825 [22:55:02<22:30:34, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120402.96lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103678.92lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6375] due to args.save_total_limit
 50%|████▉     | 6401/12825 [22:55:15<22:41:11, 12.71s/it] 50%|████▉     | 6402/12825 [22:55:28<22:38:36, 12.69s/it] 50%|████▉     | 6403/12825 [22:55:40<22:34:59, 12.66s/it] 50%|████▉     | 6404/12825 [22:55:53<22:33:12, 12.64s/it] 50%|████▉     | 6405/12825 [22:56:06<22:32:49, 12.64s/it] 50%|████▉     | 6406/12825 [22:56:18<22:31:24, 12.63s/it] 50%|████▉     | 6407/12825 [22:56:31<22:32:22, 12.64s/it] 50%|████▉     | 6408/12825 [22:56:44<22:31:04, 12.63s/it] 50%|████▉     | 6409/12825 [22:56:56<22:29:43, 12.62s/it] 50%|████▉     | 6410/12825 [22:57:09<22:29:40, 12.62s/it] 50%|████▉     | 6411/12825 [22:57:29<26:35:56, 14.93s/it] 50%|████▉     | 6412/12825 [22:57:42<25:20:52, 14.23s/it] 50%|█████     | 6413/12825 [22:57:54<24:29:42, 13.75s/it] 50%|█████     | 6414/12825 [22:58:07<23:52:33, 13.41s/it] 50%|█████     | 6415/12825 [22:58:19<23:27:03, 13.17s/it] 50%|█████     | 6416/12825 [22:58:32<23:10:13, 13.02s/it] 50%|█████     | 6417/12825 [22:58:45<22:56:03, 12.88s/it] 50%|█████     | 6418/12825 [22:58:57<22:47:11, 12.80s/it] 50%|█████     | 6419/12825 [22:59:10<22:41:19, 12.75s/it] 50%|█████     | 6420/12825 [22:59:23<22:37:45, 12.72s/it] 50%|█████     | 6421/12825 [22:59:35<22:34:50, 12.69s/it] 50%|█████     | 6422/12825 [22:59:48<22:31:34, 12.67s/it] 50%|█████     | 6423/12825 [23:00:00<22:30:19, 12.66s/it] 50%|█████     | 6424/12825 [23:00:13<22:28:26, 12.64s/it] 50%|█████     | 6425/12825 [23:00:26<22:27:45, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120371.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103599.06lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6400] due to args.save_total_limit
 50%|█████     | 6426/12825 [23:00:39<22:36:57, 12.72s/it] 50%|█████     | 6427/12825 [23:00:51<22:33:13, 12.69s/it] 50%|█████     | 6428/12825 [23:01:04<22:30:08, 12.66s/it] 50%|█████     | 6429/12825 [23:01:16<22:28:24, 12.65s/it] 50%|█████     | 6430/12825 [23:01:29<22:27:22, 12.64s/it] 50%|█████     | 6431/12825 [23:01:42<22:26:15, 12.63s/it] 50%|█████     | 6432/12825 [23:01:54<22:26:08, 12.63s/it] 50%|█████     | 6433/12825 [23:02:07<22:24:06, 12.62s/it] 50%|█████     | 6434/12825 [23:02:20<22:23:32, 12.61s/it] 50%|█████     | 6435/12825 [23:02:32<22:23:03, 12.61s/it] 50%|█████     | 6436/12825 [23:02:45<22:22:03, 12.60s/it] 50%|█████     | 6437/12825 [23:02:57<22:22:43, 12.61s/it] 50%|█████     | 6438/12825 [23:03:10<22:23:56, 12.63s/it] 50%|█████     | 6439/12825 [23:03:23<22:22:59, 12.62s/it] 50%|█████     | 6440/12825 [23:03:35<22:23:05, 12.62s/it] 50%|█████     | 6441/12825 [23:03:48<22:23:56, 12.63s/it] 50%|█████     | 6442/12825 [23:04:01<22:23:40, 12.63s/it] 50%|█████     | 6443/12825 [23:04:13<22:23:15, 12.63s/it] 50%|█████     | 6444/12825 [23:04:33<26:23:09, 14.89s/it] 50%|█████     | 6445/12825 [23:04:46<25:10:27, 14.20s/it] 50%|█████     | 6446/12825 [23:04:59<24:20:32, 13.74s/it] 50%|█████     | 6447/12825 [23:05:11<23:44:53, 13.40s/it] 50%|█████     | 6448/12825 [23:05:24<23:20:52, 13.18s/it] 50%|█████     | 6449/12825 [23:05:36<23:03:48, 13.02s/it] 50%|█████     | 6450/12825 [23:05:49<22:51:50, 12.91s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120429.08lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103665.54lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6425] due to args.save_total_limit
 50%|█████     | 6451/12825 [23:06:02<22:52:47, 12.92s/it] 50%|█████     | 6452/12825 [23:06:15<22:41:50, 12.82s/it] 50%|█████     | 6453/12825 [23:06:27<22:34:34, 12.75s/it] 50%|█████     | 6454/12825 [23:06:40<22:30:18, 12.72s/it] 50%|█████     | 6455/12825 [23:06:53<22:26:53, 12.69s/it] 50%|█████     | 6456/12825 [23:07:05<22:25:22, 12.67s/it] 50%|█████     | 6457/12825 [23:07:18<22:23:42, 12.66s/it] 50%|█████     | 6458/12825 [23:07:30<22:21:56, 12.65s/it] 50%|█████     | 6459/12825 [23:07:43<22:21:01, 12.64s/it] 50%|█████     | 6460/12825 [23:07:56<22:21:51, 12.65s/it] 50%|█████     | 6461/12825 [23:08:08<22:21:32, 12.65s/it] 50%|█████     | 6462/12825 [23:08:21<22:20:05, 12.64s/it] 50%|█████     | 6463/12825 [23:08:34<22:21:43, 12.65s/it] 50%|█████     | 6464/12825 [23:08:46<22:18:53, 12.63s/it] 50%|█████     | 6465/12825 [23:08:59<22:18:07, 12.62s/it] 50%|█████     | 6466/12825 [23:09:11<22:18:00, 12.62s/it] 50%|█████     | 6467/12825 [23:09:24<22:17:45, 12.62s/it] 50%|█████     | 6468/12825 [23:09:37<22:16:27, 12.61s/it] 50%|█████     | 6469/12825 [23:09:49<22:18:26, 12.63s/it] 50%|█████     | 6470/12825 [23:10:02<22:17:05, 12.62s/it] 50%|█████     | 6471/12825 [23:10:15<22:21:20, 12.67s/it] 50%|█████     | 6472/12825 [23:10:27<22:18:40, 12.64s/it] 50%|█████     | 6473/12825 [23:10:40<22:18:55, 12.65s/it] 50%|█████     | 6474/12825 [23:10:53<22:16:02, 12.62s/it] 50%|█████     | 6475/12825 [23:11:05<22:17:15, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120276.74lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103552.83lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6450] due to args.save_total_limit
 50%|█████     | 6476/12825 [23:11:28<27:27:56, 15.57s/it] 51%|█████     | 6477/12825 [23:11:40<25:53:15, 14.68s/it] 51%|█████     | 6478/12825 [23:11:53<24:48:13, 14.07s/it] 51%|█████     | 6479/12825 [23:12:05<24:01:49, 13.63s/it] 51%|█████     | 6480/12825 [23:12:18<23:28:48, 13.32s/it] 51%|█████     | 6481/12825 [23:12:31<23:07:13, 13.12s/it] 51%|█████     | 6482/12825 [23:12:43<22:51:34, 12.97s/it] 51%|█████     | 6483/12825 [23:12:56<22:39:51, 12.87s/it] 51%|█████     | 6484/12825 [23:13:09<22:31:36, 12.79s/it] 51%|█████     | 6485/12825 [23:13:21<22:27:01, 12.75s/it] 51%|█████     | 6486/12825 [23:13:34<22:23:07, 12.71s/it] 51%|█████     | 6487/12825 [23:13:47<22:21:07, 12.70s/it] 51%|█████     | 6488/12825 [23:13:59<22:21:05, 12.70s/it] 51%|█████     | 6489/12825 [23:14:12<22:17:35, 12.67s/it] 51%|█████     | 6490/12825 [23:14:24<22:15:23, 12.65s/it] 51%|█████     | 6491/12825 [23:14:37<22:13:10, 12.63s/it] 51%|█████     | 6492/12825 [23:14:50<22:12:52, 12.63s/it] 51%|█████     | 6493/12825 [23:15:02<22:12:45, 12.63s/it] 51%|█████     | 6494/12825 [23:15:15<22:12:19, 12.63s/it] 51%|█████     | 6495/12825 [23:15:27<22:11:50, 12.62s/it] 51%|█████     | 6496/12825 [23:15:40<22:10:55, 12.62s/it] 51%|█████     | 6497/12825 [23:15:53<22:10:02, 12.61s/it] 51%|█████     | 6498/12825 [23:16:05<22:08:40, 12.60s/it] 51%|█████     | 6499/12825 [23:16:18<22:08:35, 12.60s/it] 51%|█████     | 6500/12825 [23:16:30<22:07:58, 12.60s/it]                                                           51%|█████     | 6500/12825 [23:16:30<22:07:58, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120412.56lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103745.79lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6475] due to args.save_total_limit
 51%|█████     | 6501/12825 [23:16:43<22:20:06, 12.71s/it] 51%|█████     | 6502/12825 [23:16:56<22:16:36, 12.68s/it] 51%|█████     | 6503/12825 [23:17:09<22:14:14, 12.66s/it] 51%|█████     | 6504/12825 [23:17:21<22:11:55, 12.64s/it] 51%|█████     | 6505/12825 [23:17:34<22:10:47, 12.63s/it] 51%|█████     | 6506/12825 [23:17:47<22:10:12, 12.63s/it] 51%|█████     | 6507/12825 [23:17:59<22:09:30, 12.63s/it] 51%|█████     | 6508/12825 [23:18:19<25:57:39, 14.79s/it] 51%|█████     | 6509/12825 [23:18:32<24:47:22, 14.13s/it] 51%|█████     | 6510/12825 [23:18:44<23:58:42, 13.67s/it] 51%|█████     | 6511/12825 [23:18:57<23:25:03, 13.35s/it] 51%|█████     | 6512/12825 [23:19:09<23:02:25, 13.14s/it] 51%|█████     | 6513/12825 [23:19:22<22:46:09, 12.99s/it] 51%|█████     | 6514/12825 [23:19:35<22:34:03, 12.87s/it] 51%|█████     | 6515/12825 [23:19:47<22:24:40, 12.79s/it] 51%|█████     | 6516/12825 [23:20:00<22:18:46, 12.73s/it] 51%|█████     | 6517/12825 [23:20:12<22:14:53, 12.70s/it] 51%|█████     | 6518/12825 [23:20:25<22:12:28, 12.68s/it] 51%|█████     | 6519/12825 [23:20:38<22:09:43, 12.65s/it] 51%|█████     | 6520/12825 [23:20:50<22:09:51, 12.66s/it] 51%|█████     | 6521/12825 [23:21:03<22:08:42, 12.65s/it] 51%|█████     | 6522/12825 [23:21:16<22:09:15, 12.65s/it] 51%|█████     | 6523/12825 [23:21:28<22:08:11, 12.65s/it] 51%|█████     | 6524/12825 [23:21:41<22:07:01, 12.64s/it] 51%|█████     | 6525/12825 [23:21:54<22:06:31, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120534.19lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103744.37lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6500] due to args.save_total_limit
 51%|█████     | 6526/12825 [23:22:06<22:16:03, 12.73s/it] 51%|█████     | 6527/12825 [23:22:19<22:10:52, 12.68s/it] 51%|█████     | 6528/12825 [23:22:32<22:08:46, 12.66s/it] 51%|█████     | 6529/12825 [23:22:44<22:06:13, 12.64s/it] 51%|█████     | 6530/12825 [23:22:57<22:05:21, 12.63s/it] 51%|█████     | 6531/12825 [23:23:10<22:09:14, 12.67s/it] 51%|█████     | 6532/12825 [23:23:22<22:06:51, 12.65s/it] 51%|█████     | 6533/12825 [23:23:35<22:06:29, 12.65s/it] 51%|█████     | 6534/12825 [23:23:47<22:05:20, 12.64s/it] 51%|█████     | 6535/12825 [23:24:00<22:04:26, 12.63s/it] 51%|█████     | 6536/12825 [23:24:13<22:03:49, 12.63s/it] 51%|█████     | 6537/12825 [23:24:25<22:03:32, 12.63s/it] 51%|█████     | 6538/12825 [23:24:38<22:02:51, 12.62s/it] 51%|█████     | 6539/12825 [23:24:51<22:02:29, 12.62s/it] 51%|█████     | 6540/12825 [23:25:03<22:01:02, 12.61s/it] 51%|█████     | 6541/12825 [23:25:23<26:00:41, 14.90s/it] 51%|█████     | 6542/12825 [23:25:36<24:50:21, 14.23s/it] 51%|█████     | 6543/12825 [23:25:49<24:02:16, 13.78s/it] 51%|█████     | 6544/12825 [23:26:01<23:26:34, 13.44s/it] 51%|█████     | 6545/12825 [23:26:14<23:06:14, 13.24s/it] 51%|█████     | 6546/12825 [23:26:27<22:49:42, 13.09s/it] 51%|█████     | 6547/12825 [23:26:40<22:37:25, 12.97s/it] 51%|█████     | 6548/12825 [23:26:52<22:32:03, 12.92s/it] 51%|█████     | 6549/12825 [23:27:05<22:23:00, 12.84s/it] 51%|█████     | 6550/12825 [23:27:18<22:18:28, 12.80s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120451.75lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103682.15lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6350] due to args.save_total_limit
 51%|█████     | 6551/12825 [23:27:31<22:24:23, 12.86s/it] 51%|█████     | 6552/12825 [23:27:43<22:17:36, 12.79s/it] 51%|█████     | 6553/12825 [23:27:56<22:13:54, 12.76s/it] 51%|█████     | 6554/12825 [23:28:09<22:10:47, 12.73s/it] 51%|█████     | 6555/12825 [23:28:22<22:11:09, 12.74s/it] 51%|█████     | 6556/12825 [23:28:34<22:10:07, 12.73s/it] 51%|█████     | 6557/12825 [23:28:47<22:09:42, 12.73s/it] 51%|█████     | 6558/12825 [23:29:00<22:10:45, 12.74s/it] 51%|█████     | 6559/12825 [23:29:13<22:11:12, 12.75s/it] 51%|█████     | 6560/12825 [23:29:25<22:10:22, 12.74s/it] 51%|█████     | 6561/12825 [23:29:38<22:06:26, 12.71s/it] 51%|█████     | 6562/12825 [23:29:51<22:06:14, 12.71s/it] 51%|█████     | 6563/12825 [23:30:03<22:04:55, 12.69s/it] 51%|█████     | 6564/12825 [23:30:16<22:04:08, 12.69s/it] 51%|█████     | 6565/12825 [23:30:29<22:02:49, 12.68s/it] 51%|█████     | 6566/12825 [23:30:41<22:02:07, 12.67s/it] 51%|█████     | 6567/12825 [23:30:54<22:03:08, 12.69s/it] 51%|█████     | 6568/12825 [23:31:07<22:03:27, 12.69s/it] 51%|█████     | 6569/12825 [23:31:19<22:05:26, 12.71s/it] 51%|█████     | 6570/12825 [23:31:32<22:03:52, 12.70s/it] 51%|█████     | 6571/12825 [23:31:45<22:02:00, 12.68s/it] 51%|█████     | 6572/12825 [23:31:57<22:00:38, 12.67s/it] 51%|█████▏    | 6573/12825 [23:32:17<25:53:21, 14.91s/it] 51%|█████▏    | 6574/12825 [23:32:30<24:40:45, 14.21s/it] 51%|█████▏    | 6575/12825 [23:32:43<23:49:15, 13.72s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120550.10lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 100208.93lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6525] due to args.save_total_limit
 51%|█████▏    | 6576/12825 [23:32:56<23:33:25, 13.57s/it] 51%|█████▏    | 6577/12825 [23:33:08<23:02:15, 13.27s/it] 51%|█████▏    | 6578/12825 [23:33:21<22:42:02, 13.08s/it] 51%|█████▏    | 6579/12825 [23:33:34<22:28:15, 12.95s/it] 51%|█████▏    | 6580/12825 [23:33:47<22:22:11, 12.90s/it] 51%|█████▏    | 6581/12825 [23:33:59<22:13:19, 12.81s/it] 51%|█████▏    | 6582/12825 [23:34:12<22:07:02, 12.75s/it] 51%|█████▏    | 6583/12825 [23:34:24<22:02:42, 12.71s/it] 51%|█████▏    | 6584/12825 [23:34:37<21:58:43, 12.68s/it] 51%|█████▏    | 6585/12825 [23:34:50<21:56:41, 12.66s/it] 51%|█████▏    | 6586/12825 [23:35:02<21:54:17, 12.64s/it] 51%|█████▏    | 6587/12825 [23:35:15<21:51:59, 12.62s/it] 51%|█████▏    | 6588/12825 [23:35:27<21:49:39, 12.60s/it] 51%|█████▏    | 6589/12825 [23:35:40<21:48:58, 12.59s/it] 51%|█████▏    | 6590/12825 [23:35:52<21:49:02, 12.60s/it] 51%|█████▏    | 6591/12825 [23:36:05<21:50:32, 12.61s/it] 51%|█████▏    | 6592/12825 [23:36:18<21:50:28, 12.61s/it] 51%|█████▏    | 6593/12825 [23:36:30<21:50:54, 12.62s/it] 51%|█████▏    | 6594/12825 [23:36:43<21:50:45, 12.62s/it] 51%|█████▏    | 6595/12825 [23:36:56<21:48:55, 12.61s/it] 51%|█████▏    | 6596/12825 [23:37:08<21:48:08, 12.60s/it] 51%|█████▏    | 6597/12825 [23:37:21<21:48:11, 12.60s/it] 51%|█████▏    | 6598/12825 [23:37:33<21:48:49, 12.61s/it] 51%|█████▏    | 6599/12825 [23:37:46<21:51:02, 12.63s/it] 51%|█████▏    | 6600/12825 [23:37:59<21:48:53, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120493.40lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103370.97lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6575] due to args.save_total_limit
 51%|█████▏    | 6601/12825 [23:38:12<21:57:54, 12.70s/it] 51%|█████▏    | 6602/12825 [23:38:24<21:53:55, 12.67s/it] 51%|█████▏    | 6603/12825 [23:38:37<21:51:34, 12.65s/it] 51%|█████▏    | 6604/12825 [23:38:49<21:50:05, 12.64s/it] 52%|█████▏    | 6605/12825 [23:39:11<26:39:45, 15.43s/it] 52%|█████▏    | 6606/12825 [23:39:24<25:09:50, 14.57s/it] 52%|█████▏    | 6607/12825 [23:39:36<24:07:44, 13.97s/it] 52%|█████▏    | 6608/12825 [23:39:49<23:23:48, 13.55s/it] 52%|█████▏    | 6609/12825 [23:40:02<22:53:14, 13.26s/it] 52%|█████▏    | 6610/12825 [23:40:14<22:31:58, 13.05s/it] 52%|█████▏    | 6611/12825 [23:40:27<22:16:33, 12.91s/it] 52%|█████▏    | 6612/12825 [23:40:39<22:08:22, 12.83s/it] 52%|█████▏    | 6613/12825 [23:40:52<22:00:16, 12.75s/it] 52%|█████▏    | 6614/12825 [23:41:05<21:54:51, 12.70s/it] 52%|█████▏    | 6615/12825 [23:41:17<21:50:19, 12.66s/it] 52%|█████▏    | 6616/12825 [23:41:30<21:45:37, 12.62s/it] 52%|█████▏    | 6617/12825 [23:41:42<21:43:37, 12.60s/it] 52%|█████▏    | 6618/12825 [23:41:55<21:42:39, 12.59s/it] 52%|█████▏    | 6619/12825 [23:42:07<21:43:30, 12.60s/it] 52%|█████▏    | 6620/12825 [23:42:20<21:42:53, 12.60s/it] 52%|█████▏    | 6621/12825 [23:42:33<21:41:31, 12.59s/it] 52%|█████▏    | 6622/12825 [23:42:45<21:41:42, 12.59s/it] 52%|█████▏    | 6623/12825 [23:42:58<21:42:03, 12.60s/it] 52%|█████▏    | 6624/12825 [23:43:10<21:41:14, 12.59s/it] 52%|█████▏    | 6625/12825 [23:43:23<21:40:05, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120352.16lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103680.54lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6600] due to args.save_total_limit
 52%|█████▏    | 6626/12825 [23:43:36<21:50:30, 12.68s/it] 52%|█████▏    | 6627/12825 [23:43:48<21:47:03, 12.65s/it] 52%|█████▏    | 6628/12825 [23:44:01<21:44:35, 12.63s/it] 52%|█████▏    | 6629/12825 [23:44:14<21:42:27, 12.61s/it] 52%|█████▏    | 6630/12825 [23:44:26<21:41:46, 12.61s/it] 52%|█████▏    | 6631/12825 [23:44:39<21:41:06, 12.60s/it] 52%|█████▏    | 6632/12825 [23:44:51<21:40:20, 12.60s/it] 52%|█████▏    | 6633/12825 [23:45:04<21:41:53, 12.62s/it] 52%|█████▏    | 6634/12825 [23:45:17<21:40:23, 12.60s/it] 52%|█████▏    | 6635/12825 [23:45:29<21:38:58, 12.59s/it] 52%|█████▏    | 6636/12825 [23:45:42<21:39:21, 12.60s/it] 52%|█████▏    | 6637/12825 [23:45:54<21:38:46, 12.59s/it] 52%|█████▏    | 6638/12825 [23:46:15<25:41:49, 14.95s/it] 52%|█████▏    | 6639/12825 [23:46:27<24:28:03, 14.24s/it] 52%|█████▏    | 6640/12825 [23:46:40<23:38:17, 13.76s/it] 52%|█████▏    | 6641/12825 [23:46:53<23:02:23, 13.41s/it] 52%|█████▏    | 6642/12825 [23:47:05<22:37:59, 13.18s/it] 52%|█████▏    | 6643/12825 [23:47:18<22:20:04, 13.01s/it] 52%|█████▏    | 6644/12825 [23:47:30<22:07:56, 12.89s/it] 52%|█████▏    | 6645/12825 [23:47:43<21:59:28, 12.81s/it] 52%|█████▏    | 6646/12825 [23:47:56<21:53:17, 12.75s/it] 52%|█████▏    | 6647/12825 [23:48:08<21:48:28, 12.71s/it] 52%|█████▏    | 6648/12825 [23:48:21<21:44:55, 12.68s/it] 52%|█████▏    | 6649/12825 [23:48:33<21:42:46, 12.66s/it] 52%|█████▏    | 6650/12825 [23:48:46<21:40:26, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120550.10lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103750.35lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6625] due to args.save_total_limit
 52%|█████▏    | 6651/12825 [23:48:59<21:50:50, 12.74s/it] 52%|█████▏    | 6652/12825 [23:49:12<21:47:03, 12.70s/it] 52%|█████▏    | 6653/12825 [23:49:24<21:43:39, 12.67s/it] 52%|█████▏    | 6654/12825 [23:49:37<21:41:04, 12.65s/it] 52%|█████▏    | 6655/12825 [23:49:49<21:39:49, 12.64s/it] 52%|█████▏    | 6656/12825 [23:50:02<21:40:05, 12.64s/it] 52%|█████▏    | 6657/12825 [23:50:15<21:37:46, 12.62s/it] 52%|█████▏    | 6658/12825 [23:50:27<21:36:07, 12.61s/it] 52%|█████▏    | 6659/12825 [23:50:40<21:36:05, 12.61s/it] 52%|█████▏    | 6660/12825 [23:50:52<21:34:43, 12.60s/it] 52%|█████▏    | 6661/12825 [23:51:05<21:34:04, 12.60s/it] 52%|█████▏    | 6662/12825 [23:51:18<21:34:06, 12.60s/it] 52%|█████▏    | 6663/12825 [23:51:30<21:33:15, 12.59s/it] 52%|█████▏    | 6664/12825 [23:51:43<21:32:56, 12.59s/it] 52%|█████▏    | 6665/12825 [23:51:55<21:34:36, 12.61s/it] 52%|█████▏    | 6666/12825 [23:52:08<21:33:48, 12.60s/it] 52%|█████▏    | 6667/12825 [23:52:21<21:33:49, 12.61s/it] 52%|█████▏    | 6668/12825 [23:52:29<19:09:16, 11.20s/it] 52%|█████▏    | 6669/12825 [23:52:29<13:49:41,  8.09s/it] 52%|█████▏    | 6670/12825 [23:53:03<27:07:57, 15.87s/it] 52%|█████▏    | 6671/12825 [23:53:16<25:29:14, 14.91s/it] 52%|█████▏    | 6672/12825 [23:53:29<24:18:02, 14.22s/it] 52%|█████▏    | 6673/12825 [23:53:41<23:26:41, 13.72s/it] 52%|█████▏    | 6674/12825 [23:53:54<22:52:13, 13.39s/it] 52%|█████▏    | 6675/12825 [23:54:06<22:27:37, 13.15s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120544.58lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103756.53lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6550] due to args.save_total_limit
 52%|█████▏    | 6676/12825 [23:54:19<22:20:36, 13.08s/it] 52%|█████▏    | 6677/12825 [23:54:32<22:04:59, 12.93s/it] 52%|█████▏    | 6678/12825 [23:54:45<21:54:53, 12.83s/it] 52%|█████▏    | 6679/12825 [23:54:57<21:46:49, 12.76s/it] 52%|█████▏    | 6680/12825 [23:55:10<21:42:22, 12.72s/it] 52%|█████▏    | 6681/12825 [23:55:22<21:39:58, 12.70s/it] 52%|█████▏    | 6682/12825 [23:55:35<21:37:01, 12.67s/it] 52%|█████▏    | 6683/12825 [23:55:48<21:35:11, 12.65s/it] 52%|█████▏    | 6684/12825 [23:56:00<21:33:01, 12.63s/it] 52%|█████▏    | 6685/12825 [23:56:13<21:30:56, 12.62s/it] 52%|█████▏    | 6686/12825 [23:56:25<21:29:13, 12.60s/it] 52%|█████▏    | 6687/12825 [23:56:38<21:28:39, 12.60s/it] 52%|█████▏    | 6688/12825 [23:56:51<21:28:30, 12.60s/it] 52%|█████▏    | 6689/12825 [23:57:03<21:28:44, 12.60s/it] 52%|█████▏    | 6690/12825 [23:57:16<21:27:27, 12.59s/it] 52%|█████▏    | 6691/12825 [23:57:28<21:27:35, 12.59s/it] 52%|█████▏    | 6692/12825 [23:57:41<21:28:48, 12.61s/it] 52%|█████▏    | 6693/12825 [23:57:54<21:27:04, 12.59s/it] 52%|█████▏    | 6694/12825 [23:58:06<21:27:58, 12.60s/it] 52%|█████▏    | 6695/12825 [23:58:19<21:26:49, 12.60s/it] 52%|█████▏    | 6696/12825 [23:58:31<21:26:12, 12.59s/it] 52%|█████▏    | 6697/12825 [23:58:44<21:24:31, 12.58s/it] 52%|█████▏    | 6698/12825 [23:58:56<21:24:06, 12.57s/it] 52%|█████▏    | 6699/12825 [23:59:09<21:24:45, 12.58s/it] 52%|█████▏    | 6700/12825 [23:59:22<21:24:43, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120553.82lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103712.06lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6650] due to args.save_total_limit
 52%|█████▏    | 6701/12825 [23:59:35<21:35:18, 12.69s/it] 52%|█████▏    | 6702/12825 [23:59:47<21:31:42, 12.66s/it] 52%|█████▏    | 6703/12825 [24:00:08<25:44:58, 15.14s/it] 52%|█████▏    | 6704/12825 [24:00:21<24:26:11, 14.37s/it] 52%|█████▏    | 6705/12825 [24:00:33<23:31:10, 13.83s/it] 52%|█████▏    | 6706/12825 [24:00:46<22:52:45, 13.46s/it] 52%|█████▏    | 6707/12825 [24:00:58<22:25:15, 13.19s/it] 52%|█████▏    | 6708/12825 [24:01:11<22:05:38, 13.00s/it] 52%|█████▏    | 6709/12825 [24:01:24<21:52:15, 12.87s/it] 52%|█████▏    | 6710/12825 [24:01:36<21:42:18, 12.78s/it] 52%|█████▏    | 6711/12825 [24:01:49<21:36:04, 12.72s/it] 52%|█████▏    | 6712/12825 [24:02:01<21:32:07, 12.68s/it] 52%|█████▏    | 6713/12825 [24:02:14<21:29:16, 12.66s/it] 52%|█████▏    | 6714/12825 [24:02:26<21:26:27, 12.63s/it] 52%|█████▏    | 6715/12825 [24:02:39<21:23:43, 12.61s/it] 52%|█████▏    | 6716/12825 [24:02:52<21:22:44, 12.60s/it] 52%|█████▏    | 6717/12825 [24:03:04<21:21:50, 12.59s/it] 52%|█████▏    | 6718/12825 [24:03:17<21:21:59, 12.60s/it] 52%|█████▏    | 6719/12825 [24:03:29<21:20:13, 12.58s/it] 52%|█████▏    | 6720/12825 [24:03:42<21:20:48, 12.59s/it] 52%|█████▏    | 6721/12825 [24:03:55<21:20:55, 12.59s/it] 52%|█████▏    | 6722/12825 [24:04:07<21:21:40, 12.60s/it] 52%|█████▏    | 6723/12825 [24:04:20<21:20:34, 12.59s/it] 52%|█████▏    | 6724/12825 [24:04:32<21:20:06, 12.59s/it] 52%|█████▏    | 6725/12825 [24:04:45<21:19:56, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120377.24lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103695.06lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6725
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6725/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6725/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6675] due to args.save_total_limit
 52%|█████▏    | 6726/12825 [24:04:58<21:29:04, 12.68s/it] 52%|█████▏    | 6727/12825 [24:05:10<21:25:33, 12.65s/it] 52%|█████▏    | 6728/12825 [24:05:23<21:23:14, 12.63s/it] 52%|█████▏    | 6729/12825 [24:05:36<21:21:21, 12.61s/it] 52%|█████▏    | 6730/12825 [24:05:48<21:21:44, 12.62s/it] 52%|█████▏    | 6731/12825 [24:06:01<21:20:26, 12.61s/it] 52%|█████▏    | 6732/12825 [24:06:13<21:20:00, 12.60s/it] 52%|█████▏    | 6733/12825 [24:06:26<21:20:10, 12.61s/it] 53%|█████▎    | 6734/12825 [24:06:39<21:18:47, 12.60s/it] 53%|█████▎    | 6735/12825 [24:07:00<25:44:24, 15.22s/it] 53%|█████▎    | 6736/12825 [24:07:12<24:24:14, 14.43s/it] 53%|█████▎    | 6737/12825 [24:07:25<23:27:12, 13.87s/it] 53%|█████▎    | 6738/12825 [24:07:38<22:48:26, 13.49s/it] 53%|█████▎    | 6739/12825 [24:07:50<22:19:59, 13.21s/it] 53%|█████▎    | 6740/12825 [24:08:03<22:00:10, 13.02s/it] 53%|█████▎    | 6741/12825 [24:08:15<21:46:31, 12.88s/it] 53%|█████▎    | 6742/12825 [24:08:28<21:36:31, 12.79s/it] 53%|█████▎    | 6743/12825 [24:08:40<21:28:43, 12.71s/it] 53%|█████▎    | 6744/12825 [24:08:53<21:24:00, 12.67s/it] 53%|█████▎    | 6745/12825 [24:09:06<21:21:10, 12.64s/it] 53%|█████▎    | 6746/12825 [24:09:18<21:18:38, 12.62s/it] 53%|█████▎    | 6747/12825 [24:09:31<21:17:28, 12.61s/it] 53%|█████▎    | 6748/12825 [24:09:43<21:19:41, 12.63s/it] 53%|█████▎    | 6749/12825 [24:09:56<21:18:04, 12.62s/it] 53%|█████▎    | 6750/12825 [24:10:09<21:16:10, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120555.62lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103826.74lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6750
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6750/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6750/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6700] due to args.save_total_limit
 53%|█████▎    | 6751/12825 [24:10:21<21:25:32, 12.70s/it] 53%|█████▎    | 6752/12825 [24:10:34<21:21:09, 12.66s/it] 53%|█████▎    | 6753/12825 [24:10:47<21:18:39, 12.63s/it] 53%|█████▎    | 6754/12825 [24:10:59<21:17:03, 12.62s/it] 53%|█████▎    | 6755/12825 [24:11:12<21:16:03, 12.61s/it] 53%|█████▎    | 6756/12825 [24:11:24<21:14:43, 12.60s/it] 53%|█████▎    | 6757/12825 [24:11:37<21:12:56, 12.59s/it] 53%|█████▎    | 6758/12825 [24:11:50<21:12:44, 12.59s/it] 53%|█████▎    | 6759/12825 [24:12:02<21:16:27, 12.63s/it] 53%|█████▎    | 6760/12825 [24:12:15<21:13:48, 12.60s/it] 53%|█████▎    | 6761/12825 [24:12:27<21:12:51, 12.59s/it] 53%|█████▎    | 6762/12825 [24:12:40<21:11:44, 12.59s/it] 53%|█████▎    | 6763/12825 [24:12:52<21:11:24, 12.58s/it] 53%|█████▎    | 6764/12825 [24:13:05<21:12:03, 12.59s/it] 53%|█████▎    | 6765/12825 [24:13:18<21:11:46, 12.59s/it] 53%|█████▎    | 6766/12825 [24:13:30<21:11:30, 12.59s/it] 53%|█████▎    | 6767/12825 [24:13:43<21:11:47, 12.60s/it] 53%|█████▎    | 6768/12825 [24:14:04<25:38:52, 15.24s/it] 53%|█████▎    | 6769/12825 [24:14:17<24:18:42, 14.45s/it] 53%|█████▎    | 6770/12825 [24:14:29<23:21:41, 13.89s/it] 53%|█████▎    | 6771/12825 [24:14:42<22:42:12, 13.50s/it] 53%|█████▎    | 6772/12825 [24:14:55<22:13:00, 13.21s/it] 53%|█████▎    | 6773/12825 [24:15:07<21:54:01, 13.03s/it] 53%|█████▎    | 6774/12825 [24:15:20<21:39:31, 12.89s/it] 53%|█████▎    | 6775/12825 [24:15:32<21:29:54, 12.79s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120469.18lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103690.60lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6775
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6775/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6775/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6750] due to args.save_total_limit
 53%|█████▎    | 6776/12825 [24:15:45<21:34:17, 12.84s/it] 53%|█████▎    | 6777/12825 [24:15:58<21:26:50, 12.77s/it] 53%|█████▎    | 6778/12825 [24:16:10<21:21:18, 12.71s/it] 53%|█████▎    | 6779/12825 [24:16:23<21:18:07, 12.68s/it] 53%|█████▎    | 6780/12825 [24:16:36<21:16:00, 12.67s/it] 53%|█████▎    | 6781/12825 [24:16:48<21:14:01, 12.65s/it] 53%|█████▎    | 6782/12825 [24:17:01<21:15:19, 12.66s/it] 53%|█████▎    | 6783/12825 [24:17:14<21:13:41, 12.65s/it] 53%|█████▎    | 6784/12825 [24:17:26<21:12:13, 12.64s/it] 53%|█████▎    | 6785/12825 [24:17:39<21:11:36, 12.63s/it] 53%|█████▎    | 6786/12825 [24:17:51<21:09:21, 12.61s/it] 53%|█████▎    | 6787/12825 [24:18:04<21:07:51, 12.60s/it] 53%|█████▎    | 6788/12825 [24:18:17<21:07:02, 12.59s/it] 53%|█████▎    | 6789/12825 [24:18:29<21:13:42, 12.66s/it] 53%|█████▎    | 6790/12825 [24:18:42<21:11:56, 12.65s/it] 53%|█████▎    | 6791/12825 [24:18:55<21:09:24, 12.62s/it] 53%|█████▎    | 6792/12825 [24:19:07<21:08:24, 12.61s/it] 53%|█████▎    | 6793/12825 [24:19:20<21:08:50, 12.62s/it] 53%|█████▎    | 6794/12825 [24:19:32<21:08:41, 12.62s/it] 53%|█████▎    | 6795/12825 [24:19:45<21:07:37, 12.61s/it] 53%|█████▎    | 6796/12825 [24:19:58<21:06:07, 12.60s/it] 53%|█████▎    | 6797/12825 [24:20:10<21:05:36, 12.60s/it] 53%|█████▎    | 6798/12825 [24:20:23<21:04:04, 12.58s/it] 53%|█████▎    | 6799/12825 [24:20:35<21:03:36, 12.58s/it] 53%|█████▎    | 6800/12825 [24:20:56<24:54:49, 14.89s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120490.71lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103697.25lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6800
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6800/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6800/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6775] due to args.save_total_limit
 53%|█████▎    | 6801/12825 [24:21:08<23:55:05, 14.29s/it] 53%|█████▎    | 6802/12825 [24:21:21<23:05:24, 13.80s/it] 53%|█████▎    | 6803/12825 [24:21:34<22:28:42, 13.44s/it] 53%|█████▎    | 6804/12825 [24:21:46<22:03:29, 13.19s/it] 53%|█████▎    | 6805/12825 [24:21:59<21:44:29, 13.00s/it] 53%|█████▎    | 6806/12825 [24:22:11<21:31:19, 12.87s/it] 53%|█████▎    | 6807/12825 [24:22:24<21:22:48, 12.79s/it] 53%|█████▎    | 6808/12825 [24:22:37<21:16:17, 12.73s/it] 53%|█████▎    | 6809/12825 [24:22:49<21:11:25, 12.68s/it] 53%|█████▎    | 6810/12825 [24:23:02<21:07:49, 12.65s/it] 53%|█████▎    | 6811/12825 [24:23:14<21:05:32, 12.63s/it] 53%|█████▎    | 6812/12825 [24:23:27<21:04:15, 12.62s/it] 53%|█████▎    | 6813/12825 [24:23:40<21:01:58, 12.59s/it] 53%|█████▎    | 6814/12825 [24:23:52<21:01:12, 12.59s/it] 53%|█████▎    | 6815/12825 [24:24:05<21:01:55, 12.60s/it] 53%|█████▎    | 6816/12825 [24:24:17<21:00:49, 12.59s/it] 53%|█████▎    | 6817/12825 [24:24:30<21:01:00, 12.59s/it] 53%|█████▎    | 6818/12825 [24:24:42<21:00:38, 12.59s/it] 53%|█████▎    | 6819/12825 [24:24:55<21:00:18, 12.59s/it] 53%|█████▎    | 6820/12825 [24:25:08<21:00:03, 12.59s/it] 53%|█████▎    | 6821/12825 [24:25:20<21:00:08, 12.59s/it] 53%|█████▎    | 6822/12825 [24:25:33<21:00:49, 12.60s/it] 53%|█████▎    | 6823/12825 [24:25:45<21:00:32, 12.60s/it] 53%|█████▎    | 6824/12825 [24:25:58<21:03:11, 12.63s/it] 53%|█████▎    | 6825/12825 [24:26:11<21:02:00, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120303.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103582.76lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6825
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6825/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6825/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6800] due to args.save_total_limit
 53%|█████▎    | 6826/12825 [24:26:24<21:11:24, 12.72s/it] 53%|█████▎    | 6827/12825 [24:26:36<21:08:45, 12.69s/it] 53%|█████▎    | 6828/12825 [24:26:49<21:03:22, 12.64s/it] 53%|█████▎    | 6829/12825 [24:27:02<21:04:44, 12.66s/it] 53%|█████▎    | 6830/12825 [24:27:14<21:02:27, 12.64s/it] 53%|█████▎    | 6831/12825 [24:27:27<20:59:34, 12.61s/it] 53%|█████▎    | 6832/12825 [24:27:47<24:48:46, 14.91s/it] 53%|█████▎    | 6833/12825 [24:28:00<23:38:47, 14.21s/it] 53%|█████▎    | 6834/12825 [24:28:12<22:51:11, 13.73s/it] 53%|█████▎    | 6835/12825 [24:28:25<22:15:34, 13.38s/it] 53%|█████▎    | 6836/12825 [24:28:37<21:51:59, 13.14s/it] 53%|█████▎    | 6837/12825 [24:28:50<21:34:56, 12.98s/it] 53%|█████▎    | 6838/12825 [24:29:02<21:21:52, 12.85s/it] 53%|█████▎    | 6839/12825 [24:29:15<21:13:32, 12.77s/it] 53%|█████▎    | 6840/12825 [24:29:28<21:08:28, 12.72s/it] 53%|█████▎    | 6841/12825 [24:29:40<21:04:25, 12.68s/it] 53%|█████▎    | 6842/12825 [24:29:53<21:01:22, 12.65s/it] 53%|█████▎    | 6843/12825 [24:30:05<20:58:59, 12.63s/it] 53%|█████▎    | 6844/12825 [24:30:18<20:56:41, 12.61s/it] 53%|█████▎    | 6845/12825 [24:30:31<20:56:33, 12.61s/it] 53%|█████▎    | 6846/12825 [24:30:43<20:54:57, 12.59s/it] 53%|█████▎    | 6847/12825 [24:30:56<20:53:31, 12.58s/it] 53%|█████▎    | 6848/12825 [24:31:08<20:53:02, 12.58s/it] 53%|█████▎    | 6849/12825 [24:31:21<20:52:53, 12.58s/it] 53%|█████▎    | 6850/12825 [24:31:33<20:53:07, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120398.61lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103648.08lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6850
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6850/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6850/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6825] due to args.save_total_limit
 53%|█████▎    | 6851/12825 [24:31:46<21:02:46, 12.68s/it] 53%|█████▎    | 6852/12825 [24:31:59<20:59:54, 12.66s/it] 53%|█████▎    | 6853/12825 [24:32:11<20:57:25, 12.63s/it] 53%|█████▎    | 6854/12825 [24:32:24<20:56:44, 12.63s/it] 53%|█████▎    | 6855/12825 [24:32:37<20:55:41, 12.62s/it] 53%|█████▎    | 6856/12825 [24:32:49<20:54:11, 12.61s/it] 53%|█████▎    | 6857/12825 [24:33:02<20:52:40, 12.59s/it] 53%|█████▎    | 6858/12825 [24:33:14<20:52:53, 12.60s/it] 53%|█████▎    | 6859/12825 [24:33:27<20:52:04, 12.59s/it] 53%|█████▎    | 6860/12825 [24:33:40<20:51:34, 12.59s/it] 53%|█████▎    | 6861/12825 [24:33:52<20:51:29, 12.59s/it] 54%|█████▎    | 6862/12825 [24:34:05<20:52:08, 12.60s/it] 54%|█████▎    | 6863/12825 [24:34:17<20:51:24, 12.59s/it] 54%|█████▎    | 6864/12825 [24:34:30<20:53:20, 12.62s/it] 54%|█████▎    | 6865/12825 [24:34:51<25:05:40, 15.16s/it] 54%|█████▎    | 6866/12825 [24:35:04<23:48:42, 14.39s/it] 54%|█████▎    | 6867/12825 [24:35:16<22:55:04, 13.85s/it] 54%|█████▎    | 6868/12825 [24:35:29<22:17:41, 13.47s/it] 54%|█████▎    | 6869/12825 [24:35:41<21:50:48, 13.20s/it] 54%|█████▎    | 6870/12825 [24:35:54<21:32:08, 13.02s/it] 54%|█████▎    | 6871/12825 [24:36:07<21:19:32, 12.89s/it] 54%|█████▎    | 6872/12825 [24:36:19<21:09:38, 12.80s/it] 54%|█████▎    | 6873/12825 [24:36:32<21:02:35, 12.73s/it] 54%|█████▎    | 6874/12825 [24:36:44<20:57:37, 12.68s/it] 54%|█████▎    | 6875/12825 [24:36:57<20:54:12, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120539.45lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103766.23lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6875
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6875/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6875/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6850] due to args.save_total_limit
 54%|█████▎    | 6876/12825 [24:37:10<21:01:42, 12.73s/it] 54%|█████▎    | 6877/12825 [24:37:22<20:56:38, 12.68s/it] 54%|█████▎    | 6878/12825 [24:37:35<20:53:50, 12.65s/it] 54%|█████▎    | 6879/12825 [24:37:48<20:51:53, 12.63s/it] 54%|█████▎    | 6880/12825 [24:38:00<20:50:38, 12.62s/it] 54%|█████▎    | 6881/12825 [24:38:13<20:48:41, 12.60s/it] 54%|█████▎    | 6882/12825 [24:38:25<20:47:35, 12.60s/it] 54%|█████▎    | 6883/12825 [24:38:38<20:47:39, 12.60s/it] 54%|█████▎    | 6884/12825 [24:38:51<20:46:39, 12.59s/it] 54%|█████▎    | 6885/12825 [24:39:03<20:46:44, 12.59s/it] 54%|█████▎    | 6886/12825 [24:39:16<20:46:01, 12.59s/it] 54%|█████▎    | 6887/12825 [24:39:28<20:45:32, 12.59s/it] 54%|█████▎    | 6888/12825 [24:39:41<20:45:32, 12.59s/it] 54%|█████▎    | 6889/12825 [24:39:53<20:45:20, 12.59s/it] 54%|█████▎    | 6890/12825 [24:40:06<20:45:21, 12.59s/it] 54%|█████▎    | 6891/12825 [24:40:19<20:44:31, 12.58s/it] 54%|█████▎    | 6892/12825 [24:40:31<20:44:46, 12.59s/it] 54%|█████▎    | 6893/12825 [24:40:44<20:44:40, 12.59s/it] 54%|█████▍    | 6894/12825 [24:40:56<20:42:55, 12.57s/it] 54%|█████▍    | 6895/12825 [24:41:09<20:42:26, 12.57s/it] 54%|█████▍    | 6896/12825 [24:41:22<20:43:12, 12.58s/it] 54%|█████▍    | 6897/12825 [24:41:45<26:08:00, 15.87s/it] 54%|█████▍    | 6898/12825 [24:41:58<24:31:01, 14.89s/it] 54%|█████▍    | 6899/12825 [24:42:10<23:24:04, 14.22s/it] 54%|█████▍    | 6900/12825 [24:42:23<22:37:23, 13.75s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120507.51lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103745.89lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6900
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6900/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6900/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6725] due to args.save_total_limit
 54%|█████▍    | 6901/12825 [24:42:36<22:13:03, 13.50s/it] 54%|█████▍    | 6902/12825 [24:42:48<21:45:22, 13.22s/it] 54%|█████▍    | 6903/12825 [24:43:01<21:26:01, 13.03s/it] 54%|█████▍    | 6904/12825 [24:43:14<21:14:42, 12.92s/it] 54%|█████▍    | 6905/12825 [24:43:26<21:05:16, 12.82s/it] 54%|█████▍    | 6906/12825 [24:43:39<20:59:43, 12.77s/it] 54%|█████▍    | 6907/12825 [24:43:52<20:58:57, 12.76s/it] 54%|█████▍    | 6908/12825 [24:44:04<20:56:11, 12.74s/it] 54%|█████▍    | 6909/12825 [24:44:17<20:52:23, 12.70s/it] 54%|█████▍    | 6910/12825 [24:44:30<20:53:55, 12.72s/it] 54%|█████▍    | 6911/12825 [24:44:42<20:53:59, 12.72s/it] 54%|█████▍    | 6912/12825 [24:44:55<20:49:56, 12.68s/it] 54%|█████▍    | 6913/12825 [24:45:08<20:48:10, 12.67s/it] 54%|█████▍    | 6914/12825 [24:45:20<20:49:30, 12.68s/it] 54%|█████▍    | 6915/12825 [24:45:33<20:54:19, 12.73s/it] 54%|█████▍    | 6916/12825 [24:45:46<20:52:34, 12.72s/it] 54%|█████▍    | 6917/12825 [24:45:59<20:50:44, 12.70s/it] 54%|█████▍    | 6918/12825 [24:46:11<20:52:37, 12.72s/it] 54%|█████▍    | 6919/12825 [24:46:24<20:53:23, 12.73s/it] 54%|█████▍    | 6920/12825 [24:46:37<20:54:06, 12.74s/it] 54%|█████▍    | 6921/12825 [24:46:50<20:52:06, 12.72s/it] 54%|█████▍    | 6922/12825 [24:47:02<20:48:27, 12.69s/it] 54%|█████▍    | 6923/12825 [24:47:15<20:46:26, 12.67s/it] 54%|█████▍    | 6924/12825 [24:47:28<20:47:44, 12.69s/it] 54%|█████▍    | 6925/12825 [24:47:40<20:49:18, 12.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120434.20lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103664.78lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6925
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6925/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6925/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6875] due to args.save_total_limit
 54%|█████▍    | 6926/12825 [24:47:53<20:55:43, 12.77s/it] 54%|█████▍    | 6927/12825 [24:48:06<20:51:13, 12.73s/it] 54%|█████▍    | 6928/12825 [24:48:19<20:48:39, 12.70s/it] 54%|█████▍    | 6929/12825 [24:48:41<25:27:50, 15.55s/it] 54%|█████▍    | 6930/12825 [24:48:53<23:59:28, 14.65s/it] 54%|█████▍    | 6931/12825 [24:49:06<23:03:12, 14.08s/it] 54%|█████▍    | 6932/12825 [24:49:19<22:23:24, 13.68s/it] 54%|█████▍    | 6933/12825 [24:49:31<21:54:07, 13.38s/it] 54%|█████▍    | 6934/12825 [24:49:44<21:37:20, 13.21s/it] 54%|█████▍    | 6935/12825 [24:49:57<21:22:37, 13.07s/it] 54%|█████▍    | 6936/12825 [24:50:10<21:14:06, 12.98s/it] 54%|█████▍    | 6937/12825 [24:50:23<21:07:28, 12.92s/it] 54%|█████▍    | 6938/12825 [24:50:35<20:58:38, 12.83s/it] 54%|█████▍    | 6939/12825 [24:50:48<20:56:46, 12.81s/it] 54%|█████▍    | 6940/12825 [24:51:01<20:53:27, 12.78s/it] 54%|█████▍    | 6941/12825 [24:51:13<20:49:45, 12.74s/it] 54%|█████▍    | 6942/12825 [24:51:26<20:49:10, 12.74s/it] 54%|█████▍    | 6943/12825 [24:51:39<20:48:58, 12.74s/it] 54%|█████▍    | 6944/12825 [24:51:51<20:47:44, 12.73s/it] 54%|█████▍    | 6945/12825 [24:52:04<20:46:48, 12.72s/it] 54%|█████▍    | 6946/12825 [24:52:17<20:42:58, 12.69s/it] 54%|█████▍    | 6947/12825 [24:52:30<20:44:22, 12.70s/it] 54%|█████▍    | 6948/12825 [24:52:42<20:44:28, 12.71s/it] 54%|█████▍    | 6949/12825 [24:52:55<20:45:03, 12.71s/it] 54%|█████▍    | 6950/12825 [24:53:08<20:41:02, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120540.99lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103759.57lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6950
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6950/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6950/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6925] due to args.save_total_limit
 54%|█████▍    | 6951/12825 [24:53:20<20:48:49, 12.76s/it] 54%|█████▍    | 6952/12825 [24:53:33<20:45:51, 12.73s/it] 54%|█████▍    | 6953/12825 [24:53:46<20:42:07, 12.69s/it] 54%|█████▍    | 6954/12825 [24:53:58<20:38:41, 12.66s/it] 54%|█████▍    | 6955/12825 [24:54:11<20:37:24, 12.65s/it] 54%|█████▍    | 6956/12825 [24:54:24<20:36:18, 12.64s/it] 54%|█████▍    | 6957/12825 [24:54:36<20:37:33, 12.65s/it] 54%|█████▍    | 6958/12825 [24:54:49<20:39:55, 12.68s/it] 54%|█████▍    | 6959/12825 [24:55:02<20:40:43, 12.69s/it] 54%|█████▍    | 6960/12825 [24:55:14<20:41:51, 12.70s/it] 54%|█████▍    | 6961/12825 [24:55:27<20:40:05, 12.69s/it] 54%|█████▍    | 6962/12825 [24:55:49<24:59:51, 15.35s/it] 54%|█████▍    | 6963/12825 [24:56:01<23:43:56, 14.57s/it] 54%|█████▍    | 6964/12825 [24:56:14<22:46:18, 13.99s/it] 54%|█████▍    | 6965/12825 [24:56:27<22:08:36, 13.60s/it] 54%|█████▍    | 6966/12825 [24:56:39<21:42:06, 13.33s/it] 54%|█████▍    | 6967/12825 [24:56:52<21:21:50, 13.13s/it] 54%|█████▍    | 6968/12825 [24:57:05<21:06:06, 12.97s/it] 54%|█████▍    | 6969/12825 [24:57:17<20:58:45, 12.90s/it] 54%|█████▍    | 6970/12825 [24:57:30<20:49:43, 12.81s/it] 54%|█████▍    | 6971/12825 [24:57:43<20:43:20, 12.74s/it] 54%|█████▍    | 6972/12825 [24:57:55<20:42:47, 12.74s/it] 54%|█████▍    | 6973/12825 [24:58:08<20:42:41, 12.74s/it] 54%|█████▍    | 6974/12825 [24:58:21<20:38:26, 12.70s/it] 54%|█████▍    | 6975/12825 [24:58:33<20:36:40, 12.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120532.39lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103764.71lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6975
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6975/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6975/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-6975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6950] due to args.save_total_limit
 54%|█████▍    | 6976/12825 [24:58:46<20:44:50, 12.77s/it] 54%|█████▍    | 6977/12825 [24:58:59<20:45:06, 12.77s/it] 54%|█████▍    | 6978/12825 [24:59:12<20:43:57, 12.77s/it] 54%|█████▍    | 6979/12825 [24:59:25<20:44:17, 12.77s/it] 54%|█████▍    | 6980/12825 [24:59:37<20:40:16, 12.73s/it] 54%|█████▍    | 6981/12825 [24:59:50<20:35:58, 12.69s/it] 54%|█████▍    | 6982/12825 [25:00:03<20:34:13, 12.67s/it] 54%|█████▍    | 6983/12825 [25:00:15<20:35:54, 12.69s/it] 54%|█████▍    | 6984/12825 [25:00:28<20:33:33, 12.67s/it] 54%|█████▍    | 6985/12825 [25:00:41<20:32:49, 12.67s/it] 54%|█████▍    | 6986/12825 [25:00:53<20:34:14, 12.68s/it] 54%|█████▍    | 6987/12825 [25:01:06<20:34:54, 12.69s/it] 54%|█████▍    | 6988/12825 [25:01:19<20:36:10, 12.71s/it] 54%|█████▍    | 6989/12825 [25:01:31<20:35:25, 12.70s/it] 55%|█████▍    | 6990/12825 [25:01:44<20:36:07, 12.71s/it] 55%|█████▍    | 6991/12825 [25:01:57<20:37:10, 12.72s/it] 55%|█████▍    | 6992/12825 [25:02:10<20:36:21, 12.72s/it] 55%|█████▍    | 6993/12825 [25:02:22<20:34:30, 12.70s/it] 55%|█████▍    | 6994/12825 [25:02:43<24:38:56, 15.22s/it] 55%|█████▍    | 6995/12825 [25:02:56<23:26:03, 14.47s/it] 55%|█████▍    | 6996/12825 [25:03:09<22:35:43, 13.96s/it] 55%|█████▍    | 6997/12825 [25:03:21<21:56:02, 13.55s/it] 55%|█████▍    | 6998/12825 [25:03:34<21:29:30, 13.28s/it] 55%|█████▍    | 6999/12825 [25:03:47<21:14:57, 13.13s/it] 55%|█████▍    | 7000/12825 [25:04:00<21:01:53, 13.00s/it]                                                           55%|█████▍    | 7000/12825 [25:04:00<21:01:53, 13.00s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120440.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103683.67lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7000
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7000/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7000/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6975] due to args.save_total_limit
 55%|█████▍    | 7001/12825 [25:04:13<21:00:53, 12.99s/it] 55%|█████▍    | 7002/12825 [25:04:25<20:49:50, 12.88s/it] 55%|█████▍    | 7003/12825 [25:04:38<20:42:22, 12.80s/it] 55%|█████▍    | 7004/12825 [25:04:51<20:45:51, 12.84s/it] 55%|█████▍    | 7005/12825 [25:05:03<20:38:17, 12.77s/it] 55%|█████▍    | 7006/12825 [25:05:16<20:37:57, 12.76s/it] 55%|█████▍    | 7007/12825 [25:05:29<20:33:18, 12.72s/it] 55%|█████▍    | 7008/12825 [25:05:41<20:30:53, 12.70s/it] 55%|█████▍    | 7009/12825 [25:05:54<20:28:56, 12.68s/it] 55%|█████▍    | 7010/12825 [25:06:07<20:27:13, 12.66s/it] 55%|█████▍    | 7011/12825 [25:06:19<20:27:41, 12.67s/it] 55%|█████▍    | 7012/12825 [25:06:32<20:25:24, 12.65s/it] 55%|█████▍    | 7013/12825 [25:06:44<20:25:19, 12.65s/it] 55%|█████▍    | 7014/12825 [25:06:57<20:24:58, 12.65s/it] 55%|█████▍    | 7015/12825 [25:07:10<20:22:58, 12.63s/it] 55%|█████▍    | 7016/12825 [25:07:22<20:22:00, 12.62s/it] 55%|█████▍    | 7017/12825 [25:07:35<20:19:44, 12.60s/it] 55%|█████▍    | 7018/12825 [25:07:48<20:20:21, 12.61s/it] 55%|█████▍    | 7019/12825 [25:08:00<20:20:46, 12.62s/it] 55%|█████▍    | 7020/12825 [25:08:13<20:21:21, 12.62s/it] 55%|█████▍    | 7021/12825 [25:08:26<20:24:06, 12.65s/it] 55%|█████▍    | 7022/12825 [25:08:38<20:22:28, 12.64s/it] 55%|█████▍    | 7023/12825 [25:08:51<20:22:53, 12.65s/it] 55%|█████▍    | 7024/12825 [25:09:03<20:23:28, 12.65s/it] 55%|█████▍    | 7025/12825 [25:09:16<20:23:44, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120469.31lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103662.22lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7025
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7025/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7025/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7000] due to args.save_total_limit
 55%|█████▍    | 7026/12825 [25:09:38<24:51:28, 15.43s/it] 55%|█████▍    | 7027/12825 [25:09:51<23:28:51, 14.58s/it] 55%|█████▍    | 7028/12825 [25:10:03<22:39:05, 14.07s/it] 55%|█████▍    | 7029/12825 [25:10:16<21:58:30, 13.65s/it] 55%|█████▍    | 7030/12825 [25:10:29<21:28:09, 13.34s/it] 55%|█████▍    | 7031/12825 [25:10:41<21:09:46, 13.15s/it] 55%|█████▍    | 7032/12825 [25:10:54<20:58:08, 13.03s/it] 55%|█████▍    | 7033/12825 [25:11:07<20:49:51, 12.95s/it] 55%|█████▍    | 7034/12825 [25:11:20<20:43:38, 12.89s/it] 55%|█████▍    | 7035/12825 [25:11:33<20:40:36, 12.86s/it] 55%|█████▍    | 7036/12825 [25:11:45<20:37:59, 12.83s/it] 55%|█████▍    | 7037/12825 [25:11:58<20:35:09, 12.80s/it] 55%|█████▍    | 7038/12825 [25:12:11<20:33:44, 12.79s/it] 55%|█████▍    | 7039/12825 [25:12:23<20:27:50, 12.73s/it] 55%|█████▍    | 7040/12825 [25:12:36<20:27:27, 12.73s/it] 55%|█████▍    | 7041/12825 [25:12:49<20:26:21, 12.72s/it] 55%|█████▍    | 7042/12825 [25:13:02<20:26:42, 12.73s/it] 55%|█████▍    | 7043/12825 [25:13:14<20:26:20, 12.73s/it] 55%|█████▍    | 7044/12825 [25:13:27<20:27:26, 12.74s/it] 55%|█████▍    | 7045/12825 [25:13:40<20:27:15, 12.74s/it] 55%|█████▍    | 7046/12825 [25:13:52<20:26:24, 12.73s/it] 55%|█████▍    | 7047/12825 [25:14:05<20:26:17, 12.73s/it] 55%|█████▍    | 7048/12825 [25:14:18<20:27:29, 12.75s/it] 55%|█████▍    | 7049/12825 [25:14:31<20:23:37, 12.71s/it] 55%|█████▍    | 7050/12825 [25:14:43<20:27:19, 12.75s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120576.67lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103777.16lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7050
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7050/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7050/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7025] due to args.save_total_limit
 55%|█████▍    | 7051/12825 [25:14:56<20:34:19, 12.83s/it] 55%|█████▍    | 7052/12825 [25:15:09<20:32:57, 12.81s/it] 55%|█████▍    | 7053/12825 [25:15:22<20:29:50, 12.78s/it] 55%|█████▌    | 7054/12825 [25:15:35<20:28:16, 12.77s/it] 55%|█████▌    | 7055/12825 [25:15:47<20:27:11, 12.76s/it] 55%|█████▌    | 7056/12825 [25:16:00<20:25:26, 12.75s/it] 55%|█████▌    | 7057/12825 [25:16:13<20:24:04, 12.73s/it] 55%|█████▌    | 7058/12825 [25:16:26<20:23:55, 12.73s/it] 55%|█████▌    | 7059/12825 [25:16:48<24:54:58, 15.56s/it] 55%|█████▌    | 7060/12825 [25:17:00<23:31:00, 14.69s/it] 55%|█████▌    | 7061/12825 [25:17:13<22:32:34, 14.08s/it] 55%|█████▌    | 7062/12825 [25:17:26<21:55:04, 13.69s/it] 55%|█████▌    | 7063/12825 [25:17:39<21:26:26, 13.40s/it] 55%|█████▌    | 7064/12825 [25:17:51<21:03:16, 13.16s/it] 55%|█████▌    | 7065/12825 [25:18:04<20:51:22, 13.04s/it] 55%|█████▌    | 7066/12825 [25:18:16<20:37:48, 12.90s/it] 55%|█████▌    | 7067/12825 [25:18:29<20:28:13, 12.80s/it] 55%|█████▌    | 7068/12825 [25:18:42<20:26:48, 12.79s/it] 55%|█████▌    | 7069/12825 [25:18:54<20:22:36, 12.74s/it] 55%|█████▌    | 7070/12825 [25:19:07<20:20:58, 12.73s/it] 55%|█████▌    | 7071/12825 [25:19:20<20:19:21, 12.71s/it] 55%|█████▌    | 7072/12825 [25:19:33<20:17:48, 12.70s/it] 55%|█████▌    | 7073/12825 [25:19:45<20:19:48, 12.72s/it] 55%|█████▌    | 7074/12825 [25:19:58<20:17:12, 12.70s/it] 55%|█████▌    | 7075/12825 [25:20:11<20:18:09, 12.71s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120457.77lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103541.28lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7075
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7075/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7075/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7050] due to args.save_total_limit
 55%|█████▌    | 7076/12825 [25:20:24<20:28:14, 12.82s/it] 55%|█████▌    | 7077/12825 [25:20:36<20:23:10, 12.77s/it] 55%|█████▌    | 7078/12825 [25:20:49<20:21:40, 12.75s/it] 55%|█████▌    | 7079/12825 [25:21:02<20:17:23, 12.71s/it] 55%|█████▌    | 7080/12825 [25:21:14<20:18:12, 12.72s/it] 55%|█████▌    | 7081/12825 [25:21:27<20:20:07, 12.74s/it] 55%|█████▌    | 7082/12825 [25:21:40<20:19:35, 12.74s/it] 55%|█████▌    | 7083/12825 [25:21:53<20:15:50, 12.70s/it] 55%|█████▌    | 7084/12825 [25:22:05<20:13:12, 12.68s/it] 55%|█████▌    | 7085/12825 [25:22:18<20:11:14, 12.66s/it] 55%|█████▌    | 7086/12825 [25:22:31<20:12:49, 12.68s/it] 55%|█████▌    | 7087/12825 [25:22:43<20:10:06, 12.65s/it] 55%|█████▌    | 7088/12825 [25:22:56<20:11:12, 12.67s/it] 55%|█████▌    | 7089/12825 [25:23:08<20:08:53, 12.65s/it] 55%|█████▌    | 7090/12825 [25:23:21<20:11:42, 12.68s/it] 55%|█████▌    | 7091/12825 [25:23:42<24:16:26, 15.24s/it] 55%|█████▌    | 7092/12825 [25:23:55<22:59:30, 14.44s/it] 55%|█████▌    | 7093/12825 [25:24:08<22:09:54, 13.92s/it] 55%|█████▌    | 7094/12825 [25:24:20<21:35:36, 13.56s/it] 55%|█████▌    | 7095/12825 [25:24:33<21:10:58, 13.31s/it] 55%|█████▌    | 7096/12825 [25:24:46<20:54:23, 13.14s/it] 55%|█████▌    | 7097/12825 [25:24:59<20:41:30, 13.00s/it] 55%|█████▌    | 7098/12825 [25:25:11<20:33:56, 12.93s/it] 55%|█████▌    | 7099/12825 [25:25:24<20:28:50, 12.88s/it] 55%|█████▌    | 7100/12825 [25:25:37<20:25:24, 12.84s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120373.91lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103714.82lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7075] due to args.save_total_limit
 55%|█████▌    | 7101/12825 [25:25:50<20:26:50, 12.86s/it] 55%|█████▌    | 7102/12825 [25:26:02<20:22:18, 12.81s/it] 55%|█████▌    | 7103/12825 [25:26:15<20:17:05, 12.76s/it] 55%|█████▌    | 7104/12825 [25:26:28<20:11:35, 12.71s/it] 55%|█████▌    | 7105/12825 [25:26:40<20:10:56, 12.70s/it] 55%|█████▌    | 7106/12825 [25:26:53<20:09:56, 12.69s/it] 55%|█████▌    | 7107/12825 [25:27:06<20:09:14, 12.69s/it] 55%|█████▌    | 7108/12825 [25:27:18<20:06:23, 12.66s/it] 55%|█████▌    | 7109/12825 [25:27:31<20:08:34, 12.69s/it] 55%|█████▌    | 7110/12825 [25:27:44<20:10:25, 12.71s/it] 55%|█████▌    | 7111/12825 [25:27:57<20:11:01, 12.72s/it] 55%|█████▌    | 7112/12825 [25:28:09<20:07:38, 12.68s/it] 55%|█████▌    | 7113/12825 [25:28:22<20:08:30, 12.69s/it] 55%|█████▌    | 7114/12825 [25:28:35<20:08:44, 12.70s/it] 55%|█████▌    | 7115/12825 [25:28:47<20:07:17, 12.69s/it] 55%|█████▌    | 7116/12825 [25:29:00<20:07:11, 12.69s/it] 55%|█████▌    | 7117/12825 [25:29:13<20:05:50, 12.68s/it] 56%|█████▌    | 7118/12825 [25:29:25<20:07:45, 12.70s/it] 56%|█████▌    | 7119/12825 [25:29:38<20:07:22, 12.70s/it] 56%|█████▌    | 7120/12825 [25:29:51<20:06:18, 12.69s/it] 56%|█████▌    | 7121/12825 [25:30:03<20:08:19, 12.71s/it] 56%|█████▌    | 7122/12825 [25:30:16<20:09:13, 12.72s/it] 56%|█████▌    | 7123/12825 [25:30:39<25:09:52, 15.89s/it] 56%|█████▌    | 7124/12825 [25:30:52<23:36:20, 14.91s/it] 56%|█████▌    | 7125/12825 [25:31:05<22:30:25, 14.21s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120553.82lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103744.56lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7100] due to args.save_total_limit
 56%|█████▌    | 7126/12825 [25:31:18<21:54:29, 13.84s/it] 56%|█████▌    | 7127/12825 [25:31:30<21:18:29, 13.46s/it] 56%|█████▌    | 7128/12825 [25:31:43<20:53:17, 13.20s/it] 56%|█████▌    | 7129/12825 [25:31:55<20:34:53, 13.01s/it] 56%|█████▌    | 7130/12825 [25:32:08<20:22:31, 12.88s/it] 56%|█████▌    | 7131/12825 [25:32:21<20:12:42, 12.78s/it] 56%|█████▌    | 7132/12825 [25:32:33<20:05:56, 12.71s/it] 56%|█████▌    | 7133/12825 [25:32:46<20:04:23, 12.70s/it] 56%|█████▌    | 7134/12825 [25:32:58<20:01:13, 12.66s/it] 56%|█████▌    | 7135/12825 [25:33:11<19:58:23, 12.64s/it] 56%|█████▌    | 7136/12825 [25:33:23<19:56:41, 12.62s/it] 56%|█████▌    | 7137/12825 [25:33:36<19:56:27, 12.62s/it] 56%|█████▌    | 7138/12825 [25:33:49<19:55:18, 12.61s/it] 56%|█████▌    | 7139/12825 [25:34:01<19:57:29, 12.64s/it] 56%|█████▌    | 7140/12825 [25:34:14<19:55:25, 12.62s/it] 56%|█████▌    | 7141/12825 [25:34:27<19:54:01, 12.60s/it] 56%|█████▌    | 7142/12825 [25:34:39<19:52:05, 12.59s/it] 56%|█████▌    | 7143/12825 [25:34:52<19:52:09, 12.59s/it] 56%|█████▌    | 7144/12825 [25:35:04<19:52:23, 12.59s/it] 56%|█████▌    | 7145/12825 [25:35:17<19:51:57, 12.59s/it] 56%|█████▌    | 7146/12825 [25:35:29<19:52:00, 12.59s/it] 56%|█████▌    | 7147/12825 [25:35:42<19:52:19, 12.60s/it] 56%|█████▌    | 7148/12825 [25:35:55<19:52:03, 12.60s/it] 56%|█████▌    | 7149/12825 [25:36:07<19:51:33, 12.60s/it] 56%|█████▌    | 7150/12825 [25:36:20<19:50:11, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120442.78lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103660.70lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7125] due to args.save_total_limit
 56%|█████▌    | 7151/12825 [25:36:33<20:02:06, 12.71s/it] 56%|█████▌    | 7152/12825 [25:36:45<19:58:37, 12.68s/it] 56%|█████▌    | 7153/12825 [25:36:58<19:57:19, 12.67s/it] 56%|█████▌    | 7154/12825 [25:37:11<19:54:00, 12.63s/it] 56%|█████▌    | 7155/12825 [25:37:23<19:51:20, 12.61s/it] 56%|█████▌    | 7156/12825 [25:37:44<23:42:55, 15.06s/it] 56%|█████▌    | 7157/12825 [25:37:57<22:32:22, 14.32s/it] 56%|█████▌    | 7158/12825 [25:38:09<21:42:26, 13.79s/it] 56%|█████▌    | 7159/12825 [25:38:22<21:07:31, 13.42s/it] 56%|█████▌    | 7160/12825 [25:38:34<20:42:41, 13.16s/it] 56%|█████▌    | 7161/12825 [25:38:47<20:27:19, 13.00s/it] 56%|█████▌    | 7162/12825 [25:38:59<20:14:36, 12.87s/it] 56%|█████▌    | 7163/12825 [25:39:12<20:05:45, 12.78s/it] 56%|█████▌    | 7164/12825 [25:39:25<20:00:12, 12.72s/it] 56%|█████▌    | 7165/12825 [25:39:37<19:54:54, 12.67s/it] 56%|█████▌    | 7166/12825 [25:39:50<19:51:41, 12.63s/it] 56%|█████▌    | 7167/12825 [25:40:02<19:50:53, 12.63s/it] 56%|█████▌    | 7168/12825 [25:40:15<19:48:16, 12.60s/it] 56%|█████▌    | 7169/12825 [25:40:27<19:49:36, 12.62s/it] 56%|█████▌    | 7170/12825 [25:40:40<19:47:31, 12.60s/it] 56%|█████▌    | 7171/12825 [25:40:53<19:45:44, 12.58s/it] 56%|█████▌    | 7172/12825 [25:41:05<19:45:51, 12.59s/it] 56%|█████▌    | 7173/12825 [25:41:18<19:46:02, 12.59s/it] 56%|█████▌    | 7174/12825 [25:41:30<19:44:35, 12.58s/it] 56%|█████▌    | 7175/12825 [25:41:43<19:43:40, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120365.08lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103707.12lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7150] due to args.save_total_limit
 56%|█████▌    | 7176/12825 [25:41:56<19:53:36, 12.68s/it] 56%|█████▌    | 7177/12825 [25:42:08<19:50:46, 12.65s/it] 56%|█████▌    | 7178/12825 [25:42:21<19:48:05, 12.62s/it] 56%|█████▌    | 7179/12825 [25:42:34<19:46:47, 12.61s/it] 56%|█████▌    | 7180/12825 [25:42:46<19:45:29, 12.60s/it] 56%|█████▌    | 7181/12825 [25:42:54<17:32:15, 11.19s/it] 56%|█████▌    | 7182/12825 [25:42:55<12:39:39,  8.08s/it] 56%|█████▌    | 7183/12825 [25:43:20<20:50:44, 13.30s/it] 56%|█████▌    | 7184/12825 [25:43:33<20:31:25, 13.10s/it] 56%|█████▌    | 7185/12825 [25:43:46<20:16:52, 12.95s/it] 56%|█████▌    | 7186/12825 [25:43:58<20:06:33, 12.84s/it] 56%|█████▌    | 7187/12825 [25:44:11<19:59:53, 12.77s/it] 56%|█████▌    | 7188/12825 [25:44:31<23:44:30, 15.16s/it] 56%|█████▌    | 7189/12825 [25:44:44<22:30:39, 14.38s/it] 56%|█████▌    | 7190/12825 [25:44:57<21:40:53, 13.85s/it] 56%|█████▌    | 7191/12825 [25:45:09<21:04:38, 13.47s/it] 56%|█████▌    | 7192/12825 [25:45:22<20:39:18, 13.20s/it] 56%|█████▌    | 7193/12825 [25:45:34<20:21:31, 13.01s/it] 56%|█████▌    | 7194/12825 [25:45:47<20:08:16, 12.87s/it] 56%|█████▌    | 7195/12825 [25:45:59<19:59:33, 12.78s/it] 56%|█████▌    | 7196/12825 [25:46:12<19:56:04, 12.75s/it] 56%|█████▌    | 7197/12825 [25:46:25<19:51:06, 12.70s/it] 56%|█████▌    | 7198/12825 [25:46:37<19:47:51, 12.67s/it] 56%|█████▌    | 7199/12825 [25:46:50<19:45:22, 12.64s/it] 56%|█████▌    | 7200/12825 [25:47:02<19:44:08, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120420.12lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103676.84lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7175] due to args.save_total_limit
 56%|█████▌    | 7201/12825 [25:47:15<19:51:42, 12.71s/it] 56%|█████▌    | 7202/12825 [25:47:28<19:47:37, 12.67s/it] 56%|█████▌    | 7203/12825 [25:47:41<19:44:45, 12.64s/it] 56%|█████▌    | 7204/12825 [25:47:53<19:41:44, 12.61s/it] 56%|█████▌    | 7205/12825 [25:48:06<19:41:21, 12.61s/it] 56%|█████▌    | 7206/12825 [25:48:18<19:40:13, 12.60s/it] 56%|█████▌    | 7207/12825 [25:48:31<19:38:53, 12.59s/it] 56%|█████▌    | 7208/12825 [25:48:44<19:41:48, 12.62s/it] 56%|█████▌    | 7209/12825 [25:48:56<19:42:02, 12.63s/it] 56%|█████▌    | 7210/12825 [25:49:09<19:40:29, 12.61s/it] 56%|█████▌    | 7211/12825 [25:49:21<19:40:21, 12.62s/it] 56%|█████▌    | 7212/12825 [25:49:34<19:38:32, 12.60s/it] 56%|█████▌    | 7213/12825 [25:49:47<19:40:09, 12.62s/it] 56%|█████▌    | 7214/12825 [25:49:59<19:38:37, 12.60s/it] 56%|█████▋    | 7215/12825 [25:50:12<19:38:32, 12.60s/it] 56%|█████▋    | 7216/12825 [25:50:24<19:41:00, 12.63s/it] 56%|█████▋    | 7217/12825 [25:50:37<19:40:19, 12.63s/it] 56%|█████▋    | 7218/12825 [25:50:50<19:39:06, 12.62s/it] 56%|█████▋    | 7219/12825 [25:51:02<19:38:01, 12.61s/it] 56%|█████▋    | 7220/12825 [25:51:15<19:39:56, 12.63s/it] 56%|█████▋    | 7221/12825 [25:51:36<23:29:48, 15.09s/it] 56%|█████▋    | 7222/12825 [25:51:48<22:17:35, 14.32s/it] 56%|█████▋    | 7223/12825 [25:52:01<21:31:17, 13.83s/it] 56%|█████▋    | 7224/12825 [25:52:14<20:55:19, 13.45s/it] 56%|█████▋    | 7225/12825 [25:52:26<20:31:51, 13.20s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120487.12lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 100195.45lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7200] due to args.save_total_limit
 56%|█████▋    | 7226/12825 [25:52:39<20:29:26, 13.17s/it] 56%|█████▋    | 7227/12825 [25:52:52<20:15:42, 13.03s/it] 56%|█████▋    | 7228/12825 [25:53:05<20:02:45, 12.89s/it] 56%|█████▋    | 7229/12825 [25:53:17<19:52:22, 12.78s/it] 56%|█████▋    | 7230/12825 [25:53:30<19:49:27, 12.76s/it] 56%|█████▋    | 7231/12825 [25:53:43<19:49:09, 12.75s/it] 56%|█████▋    | 7232/12825 [25:53:55<19:47:57, 12.74s/it] 56%|█████▋    | 7233/12825 [25:54:08<19:43:12, 12.70s/it] 56%|█████▋    | 7234/12825 [25:54:21<19:44:52, 12.72s/it] 56%|█████▋    | 7235/12825 [25:54:33<19:45:07, 12.72s/it] 56%|█████▋    | 7236/12825 [25:54:46<19:41:23, 12.68s/it] 56%|█████▋    | 7237/12825 [25:54:59<19:39:37, 12.67s/it] 56%|█████▋    | 7238/12825 [25:55:11<19:38:07, 12.65s/it] 56%|█████▋    | 7239/12825 [25:55:24<19:36:23, 12.64s/it] 56%|█████▋    | 7240/12825 [25:55:36<19:35:16, 12.63s/it] 56%|█████▋    | 7241/12825 [25:55:49<19:34:24, 12.62s/it] 56%|█████▋    | 7242/12825 [25:56:02<19:33:26, 12.61s/it] 56%|█████▋    | 7243/12825 [25:56:14<19:32:54, 12.61s/it] 56%|█████▋    | 7244/12825 [25:56:27<19:35:09, 12.63s/it] 56%|█████▋    | 7245/12825 [25:56:39<19:33:45, 12.62s/it] 56%|█████▋    | 7246/12825 [25:56:52<19:34:01, 12.63s/it] 57%|█████▋    | 7247/12825 [25:57:05<19:35:30, 12.64s/it] 57%|█████▋    | 7248/12825 [25:57:17<19:32:41, 12.62s/it] 57%|█████▋    | 7249/12825 [25:57:30<19:31:08, 12.60s/it] 57%|█████▋    | 7250/12825 [25:57:42<19:29:58, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120542.65lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103539.01lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7225] due to args.save_total_limit
 57%|█████▋    | 7251/12825 [25:57:55<19:38:33, 12.69s/it] 57%|█████▋    | 7252/12825 [25:58:08<19:36:49, 12.67s/it] 57%|█████▋    | 7253/12825 [25:58:29<23:37:37, 15.27s/it] 57%|█████▋    | 7254/12825 [25:58:42<22:22:24, 14.46s/it] 57%|█████▋    | 7255/12825 [25:58:55<21:30:21, 13.90s/it] 57%|█████▋    | 7256/12825 [25:59:07<20:53:44, 13.51s/it] 57%|█████▋    | 7257/12825 [25:59:20<20:30:11, 13.26s/it] 57%|█████▋    | 7258/12825 [25:59:32<20:12:11, 13.06s/it] 57%|█████▋    | 7259/12825 [25:59:45<19:58:01, 12.91s/it] 57%|█████▋    | 7260/12825 [25:59:58<19:49:16, 12.82s/it] 57%|█████▋    | 7261/12825 [26:00:10<19:43:29, 12.76s/it] 57%|█████▋    | 7262/12825 [26:00:23<19:40:16, 12.73s/it] 57%|█████▋    | 7263/12825 [26:00:35<19:35:53, 12.68s/it] 57%|█████▋    | 7264/12825 [26:00:48<19:33:56, 12.67s/it] 57%|█████▋    | 7265/12825 [26:01:01<19:31:53, 12.65s/it] 57%|█████▋    | 7266/12825 [26:01:13<19:30:17, 12.63s/it] 57%|█████▋    | 7267/12825 [26:01:26<19:29:29, 12.62s/it] 57%|█████▋    | 7268/12825 [26:01:38<19:28:00, 12.61s/it] 57%|█████▋    | 7269/12825 [26:01:51<19:28:21, 12.62s/it] 57%|█████▋    | 7270/12825 [26:02:04<19:28:05, 12.62s/it] 57%|█████▋    | 7271/12825 [26:02:16<19:27:42, 12.61s/it] 57%|█████▋    | 7272/12825 [26:02:29<19:27:37, 12.62s/it] 57%|█████▋    | 7273/12825 [26:02:42<19:28:23, 12.63s/it] 57%|█████▋    | 7274/12825 [26:02:54<19:27:05, 12.61s/it] 57%|█████▋    | 7275/12825 [26:03:07<19:26:55, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120367.77lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103646.57lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7250] due to args.save_total_limit
 57%|█████▋    | 7276/12825 [26:03:20<19:35:25, 12.71s/it] 57%|█████▋    | 7277/12825 [26:03:32<19:31:17, 12.67s/it] 57%|█████▋    | 7278/12825 [26:03:45<19:28:59, 12.64s/it] 57%|█████▋    | 7279/12825 [26:03:57<19:27:00, 12.63s/it] 57%|█████▋    | 7280/12825 [26:04:10<19:26:28, 12.62s/it] 57%|█████▋    | 7281/12825 [26:04:23<19:29:20, 12.66s/it] 57%|█████▋    | 7282/12825 [26:04:35<19:29:21, 12.66s/it] 57%|█████▋    | 7283/12825 [26:04:48<19:27:48, 12.64s/it] 57%|█████▋    | 7284/12825 [26:05:01<19:27:05, 12.64s/it] 57%|█████▋    | 7285/12825 [26:05:13<19:26:35, 12.63s/it] 57%|█████▋    | 7286/12825 [26:05:35<23:45:17, 15.44s/it] 57%|█████▋    | 7287/12825 [26:05:48<22:27:34, 14.60s/it] 57%|█████▋    | 7288/12825 [26:06:01<21:31:42, 14.00s/it] 57%|█████▋    | 7289/12825 [26:06:13<20:53:22, 13.58s/it] 57%|█████▋    | 7290/12825 [26:06:26<20:27:21, 13.30s/it] 57%|█████▋    | 7291/12825 [26:06:39<20:12:03, 13.14s/it] 57%|█████▋    | 7292/12825 [26:06:51<20:02:14, 13.04s/it] 57%|█████▋    | 7293/12825 [26:07:04<19:50:28, 12.91s/it] 57%|█████▋    | 7294/12825 [26:07:17<19:45:14, 12.86s/it] 57%|█████▋    | 7295/12825 [26:07:29<19:42:09, 12.83s/it] 57%|█████▋    | 7296/12825 [26:07:42<19:36:43, 12.77s/it] 57%|█████▋    | 7297/12825 [26:07:55<19:32:12, 12.72s/it] 57%|█████▋    | 7298/12825 [26:08:07<19:30:56, 12.71s/it] 57%|█████▋    | 7299/12825 [26:08:20<19:28:35, 12.69s/it] 57%|█████▋    | 7300/12825 [26:08:33<19:26:19, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120581.93lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103808.18lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-6900] due to args.save_total_limit
 57%|█████▋    | 7301/12825 [26:08:46<19:33:22, 12.74s/it] 57%|█████▋    | 7302/12825 [26:08:58<19:34:19, 12.76s/it] 57%|█████▋    | 7303/12825 [26:09:11<19:34:32, 12.76s/it] 57%|█████▋    | 7304/12825 [26:09:24<19:31:18, 12.73s/it] 57%|█████▋    | 7305/12825 [26:09:36<19:28:02, 12.70s/it] 57%|█████▋    | 7306/12825 [26:09:49<19:25:46, 12.67s/it] 57%|█████▋    | 7307/12825 [26:10:02<19:28:51, 12.71s/it] 57%|█████▋    | 7308/12825 [26:10:14<19:26:43, 12.69s/it] 57%|█████▋    | 7309/12825 [26:10:27<19:31:37, 12.74s/it] 57%|█████▋    | 7310/12825 [26:10:40<19:27:39, 12.70s/it] 57%|█████▋    | 7311/12825 [26:10:53<19:25:10, 12.68s/it] 57%|█████▋    | 7312/12825 [26:11:05<19:22:59, 12.66s/it] 57%|█████▋    | 7313/12825 [26:11:18<19:24:38, 12.68s/it] 57%|█████▋    | 7314/12825 [26:11:31<19:23:23, 12.67s/it] 57%|█████▋    | 7315/12825 [26:11:43<19:22:53, 12.66s/it] 57%|█████▋    | 7316/12825 [26:11:56<19:21:21, 12.65s/it] 57%|█████▋    | 7317/12825 [26:12:08<19:20:44, 12.64s/it] 57%|█████▋    | 7318/12825 [26:12:30<23:15:50, 15.21s/it] 57%|█████▋    | 7319/12825 [26:12:42<22:04:47, 14.44s/it] 57%|█████▋    | 7320/12825 [26:12:55<21:15:17, 13.90s/it] 57%|█████▋    | 7321/12825 [26:13:08<20:39:37, 13.51s/it] 57%|█████▋    | 7322/12825 [26:13:20<20:15:06, 13.25s/it] 57%|█████▋    | 7323/12825 [26:13:33<19:57:48, 13.06s/it] 57%|█████▋    | 7324/12825 [26:13:45<19:46:13, 12.94s/it] 57%|█████▋    | 7325/12825 [26:13:58<19:37:37, 12.85s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120482.25lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103720.04lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7275] due to args.save_total_limit
 57%|█████▋    | 7326/12825 [26:14:11<19:41:31, 12.89s/it] 57%|█████▋    | 7327/12825 [26:14:24<19:33:10, 12.80s/it] 57%|█████▋    | 7328/12825 [26:14:36<19:29:53, 12.77s/it] 57%|█████▋    | 7329/12825 [26:14:49<19:24:58, 12.72s/it] 57%|█████▋    | 7330/12825 [26:15:02<19:23:04, 12.70s/it] 57%|█████▋    | 7331/12825 [26:15:14<19:21:47, 12.69s/it] 57%|█████▋    | 7332/12825 [26:15:27<19:20:08, 12.67s/it] 57%|█████▋    | 7333/12825 [26:15:40<19:19:20, 12.67s/it] 57%|█████▋    | 7334/12825 [26:15:52<19:19:26, 12.67s/it] 57%|█████▋    | 7335/12825 [26:16:05<19:20:33, 12.68s/it] 57%|█████▋    | 7336/12825 [26:16:18<19:18:36, 12.66s/it] 57%|█████▋    | 7337/12825 [26:16:30<19:18:19, 12.66s/it] 57%|█████▋    | 7338/12825 [26:16:43<19:19:16, 12.68s/it] 57%|█████▋    | 7339/12825 [26:16:56<19:17:46, 12.66s/it] 57%|█████▋    | 7340/12825 [26:17:08<19:17:29, 12.66s/it] 57%|█████▋    | 7341/12825 [26:17:21<19:17:12, 12.66s/it] 57%|█████▋    | 7342/12825 [26:17:34<19:16:35, 12.66s/it] 57%|█████▋    | 7343/12825 [26:17:46<19:17:16, 12.67s/it] 57%|█████▋    | 7344/12825 [26:17:59<19:17:06, 12.67s/it] 57%|█████▋    | 7345/12825 [26:18:11<19:15:13, 12.65s/it] 57%|█████▋    | 7346/12825 [26:18:24<19:16:03, 12.66s/it] 57%|█████▋    | 7347/12825 [26:18:37<19:15:46, 12.66s/it] 57%|█████▋    | 7348/12825 [26:18:50<19:16:07, 12.67s/it] 57%|█████▋    | 7349/12825 [26:19:02<19:15:26, 12.66s/it] 57%|█████▋    | 7350/12825 [26:19:23<22:49:44, 15.01s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120391.82lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103645.14lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7325] due to args.save_total_limit
 57%|█████▋    | 7351/12825 [26:19:36<21:52:40, 14.39s/it] 57%|█████▋    | 7352/12825 [26:19:48<21:05:08, 13.87s/it] 57%|█████▋    | 7353/12825 [26:20:01<20:33:09, 13.52s/it] 57%|█████▋    | 7354/12825 [26:20:14<20:08:57, 13.26s/it] 57%|█████▋    | 7355/12825 [26:20:26<19:51:19, 13.07s/it] 57%|█████▋    | 7356/12825 [26:20:39<19:39:24, 12.94s/it] 57%|█████▋    | 7357/12825 [26:20:52<19:31:18, 12.85s/it] 57%|█████▋    | 7358/12825 [26:21:04<19:28:38, 12.83s/it] 57%|█████▋    | 7359/12825 [26:21:17<19:23:32, 12.77s/it] 57%|█████▋    | 7360/12825 [26:21:30<19:20:29, 12.74s/it] 57%|█████▋    | 7361/12825 [26:21:42<19:18:34, 12.72s/it] 57%|█████▋    | 7362/12825 [26:21:55<19:16:12, 12.70s/it] 57%|█████▋    | 7363/12825 [26:22:08<19:14:02, 12.68s/it] 57%|█████▋    | 7364/12825 [26:22:20<19:12:14, 12.66s/it] 57%|█████▋    | 7365/12825 [26:22:33<19:12:38, 12.67s/it] 57%|█████▋    | 7366/12825 [26:22:46<19:16:26, 12.71s/it] 57%|█████▋    | 7367/12825 [26:22:58<19:16:31, 12.71s/it] 57%|█████▋    | 7368/12825 [26:23:11<19:15:09, 12.70s/it] 57%|█████▋    | 7369/12825 [26:23:24<19:15:53, 12.71s/it] 57%|█████▋    | 7370/12825 [26:23:36<19:14:37, 12.70s/it] 57%|█████▋    | 7371/12825 [26:23:49<19:15:41, 12.71s/it] 57%|█████▋    | 7372/12825 [26:24:02<19:13:11, 12.69s/it] 57%|█████▋    | 7373/12825 [26:24:14<19:10:34, 12.66s/it] 57%|█████▋    | 7374/12825 [26:24:27<19:08:41, 12.64s/it] 58%|█████▊    | 7375/12825 [26:24:40<19:07:23, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120531.62lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103749.97lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7300] due to args.save_total_limit
 58%|█████▊    | 7376/12825 [26:24:53<19:15:14, 12.72s/it] 58%|█████▊    | 7377/12825 [26:25:05<19:12:45, 12.70s/it] 58%|█████▊    | 7378/12825 [26:25:18<19:10:55, 12.68s/it] 58%|█████▊    | 7379/12825 [26:25:30<19:08:13, 12.65s/it] 58%|█████▊    | 7380/12825 [26:25:43<19:09:59, 12.67s/it] 58%|█████▊    | 7381/12825 [26:25:56<19:09:17, 12.67s/it] 58%|█████▊    | 7382/12825 [26:26:08<19:08:57, 12.67s/it] 58%|█████▊    | 7383/12825 [26:26:30<23:09:00, 15.31s/it] 58%|█████▊    | 7384/12825 [26:26:43<21:56:53, 14.52s/it] 58%|█████▊    | 7385/12825 [26:26:55<21:04:50, 13.95s/it] 58%|█████▊    | 7386/12825 [26:27:08<20:32:50, 13.60s/it] 58%|█████▊    | 7387/12825 [26:27:21<20:07:53, 13.33s/it] 58%|█████▊    | 7388/12825 [26:27:34<19:54:23, 13.18s/it] 58%|█████▊    | 7389/12825 [26:27:46<19:37:36, 13.00s/it] 58%|█████▊    | 7390/12825 [26:27:59<19:26:51, 12.88s/it] 58%|█████▊    | 7391/12825 [26:28:11<19:23:00, 12.84s/it] 58%|█████▊    | 7392/12825 [26:28:24<19:18:14, 12.79s/it] 58%|█████▊    | 7393/12825 [26:28:37<19:12:51, 12.73s/it] 58%|█████▊    | 7394/12825 [26:28:50<19:15:50, 12.77s/it] 58%|█████▊    | 7395/12825 [26:29:02<19:11:48, 12.73s/it] 58%|█████▊    | 7396/12825 [26:29:15<19:08:35, 12.69s/it] 58%|█████▊    | 7397/12825 [26:29:28<19:10:35, 12.72s/it] 58%|█████▊    | 7398/12825 [26:29:40<19:07:08, 12.68s/it] 58%|█████▊    | 7399/12825 [26:29:53<19:06:54, 12.68s/it] 58%|█████▊    | 7400/12825 [26:30:06<19:04:35, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120438.81lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103742.94lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7350] due to args.save_total_limit
 58%|█████▊    | 7401/12825 [26:30:18<19:11:31, 12.74s/it] 58%|█████▊    | 7402/12825 [26:30:31<19:07:27, 12.70s/it] 58%|█████▊    | 7403/12825 [26:30:44<19:04:50, 12.67s/it] 58%|█████▊    | 7404/12825 [26:30:56<19:02:38, 12.65s/it] 58%|█████▊    | 7405/12825 [26:31:09<19:03:19, 12.66s/it] 58%|█████▊    | 7406/12825 [26:31:22<19:04:01, 12.67s/it] 58%|█████▊    | 7407/12825 [26:31:34<19:08:13, 12.72s/it] 58%|█████▊    | 7408/12825 [26:31:47<19:07:30, 12.71s/it] 58%|█████▊    | 7409/12825 [26:32:00<19:03:21, 12.67s/it] 58%|█████▊    | 7410/12825 [26:32:12<19:03:53, 12.67s/it] 58%|█████▊    | 7411/12825 [26:32:25<19:01:40, 12.65s/it] 58%|█████▊    | 7412/12825 [26:32:38<19:02:13, 12.66s/it] 58%|█████▊    | 7413/12825 [26:32:50<19:01:08, 12.65s/it] 58%|█████▊    | 7414/12825 [26:33:03<19:00:06, 12.64s/it] 58%|█████▊    | 7415/12825 [26:33:24<22:54:08, 15.24s/it] 58%|█████▊    | 7416/12825 [26:33:37<21:43:02, 14.45s/it] 58%|█████▊    | 7417/12825 [26:33:49<20:52:50, 13.90s/it] 58%|█████▊    | 7418/12825 [26:34:02<20:18:07, 13.52s/it] 58%|█████▊    | 7419/12825 [26:34:15<19:53:17, 13.24s/it] 58%|█████▊    | 7420/12825 [26:34:27<19:37:49, 13.07s/it] 58%|█████▊    | 7421/12825 [26:34:40<19:28:04, 12.97s/it] 58%|█████▊    | 7422/12825 [26:34:53<19:17:55, 12.86s/it] 58%|█████▊    | 7423/12825 [26:35:05<19:10:01, 12.77s/it] 58%|█████▊    | 7424/12825 [26:35:18<19:06:06, 12.73s/it] 58%|█████▊    | 7425/12825 [26:35:31<19:04:05, 12.71s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120402.96lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103662.89lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7400] due to args.save_total_limit
 58%|█████▊    | 7426/12825 [26:35:44<19:10:18, 12.78s/it] 58%|█████▊    | 7427/12825 [26:35:56<19:08:31, 12.77s/it] 58%|█████▊    | 7428/12825 [26:36:09<19:03:48, 12.72s/it] 58%|█████▊    | 7429/12825 [26:36:22<19:04:16, 12.72s/it] 58%|█████▊    | 7430/12825 [26:36:34<19:01:04, 12.69s/it] 58%|█████▊    | 7431/12825 [26:36:47<18:59:29, 12.68s/it] 58%|█████▊    | 7432/12825 [26:37:00<18:59:59, 12.68s/it] 58%|█████▊    | 7433/12825 [26:37:12<18:57:21, 12.66s/it] 58%|█████▊    | 7434/12825 [26:37:25<18:57:15, 12.66s/it] 58%|█████▊    | 7435/12825 [26:37:37<18:54:38, 12.63s/it] 58%|█████▊    | 7436/12825 [26:37:50<18:56:57, 12.66s/it] 58%|█████▊    | 7437/12825 [26:38:03<18:55:49, 12.65s/it] 58%|█████▊    | 7438/12825 [26:38:15<18:55:36, 12.65s/it] 58%|█████▊    | 7439/12825 [26:38:28<18:55:31, 12.65s/it] 58%|█████▊    | 7440/12825 [26:38:41<18:54:36, 12.64s/it] 58%|█████▊    | 7441/12825 [26:38:53<18:53:40, 12.63s/it] 58%|█████▊    | 7442/12825 [26:39:06<18:53:41, 12.64s/it] 58%|█████▊    | 7443/12825 [26:39:19<18:55:13, 12.66s/it] 58%|█████▊    | 7444/12825 [26:39:31<18:53:21, 12.64s/it] 58%|█████▊    | 7445/12825 [26:39:44<18:52:23, 12.63s/it] 58%|█████▊    | 7446/12825 [26:39:56<18:51:35, 12.62s/it] 58%|█████▊    | 7447/12825 [26:40:09<18:50:42, 12.61s/it] 58%|█████▊    | 7448/12825 [26:40:29<22:19:41, 14.95s/it] 58%|█████▊    | 7449/12825 [26:40:42<21:16:22, 14.25s/it] 58%|█████▊    | 7450/12825 [26:40:55<20:37:09, 13.81s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120483.53lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 100818.78lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7425] due to args.save_total_limit
 58%|█████▊    | 7451/12825 [26:41:08<20:18:30, 13.60s/it] 58%|█████▊    | 7452/12825 [26:41:21<19:54:01, 13.33s/it] 58%|█████▊    | 7453/12825 [26:41:33<19:34:14, 13.12s/it] 58%|█████▊    | 7454/12825 [26:41:46<19:23:28, 13.00s/it] 58%|█████▊    | 7455/12825 [26:41:59<19:13:16, 12.89s/it] 58%|█████▊    | 7456/12825 [26:42:11<19:06:31, 12.81s/it] 58%|█████▊    | 7457/12825 [26:42:24<19:02:31, 12.77s/it] 58%|█████▊    | 7458/12825 [26:42:36<18:58:07, 12.72s/it] 58%|█████▊    | 7459/12825 [26:42:49<18:55:40, 12.70s/it] 58%|█████▊    | 7460/12825 [26:43:02<18:53:40, 12.68s/it] 58%|█████▊    | 7461/12825 [26:43:14<18:51:53, 12.66s/it] 58%|█████▊    | 7462/12825 [26:43:27<18:49:52, 12.64s/it] 58%|█████▊    | 7463/12825 [26:43:40<18:48:35, 12.63s/it] 58%|█████▊    | 7464/12825 [26:43:52<18:47:32, 12.62s/it] 58%|█████▊    | 7465/12825 [26:44:05<18:46:28, 12.61s/it] 58%|█████▊    | 7466/12825 [26:44:17<18:46:46, 12.62s/it] 58%|█████▊    | 7467/12825 [26:44:30<18:48:20, 12.64s/it] 58%|█████▊    | 7468/12825 [26:44:43<18:47:26, 12.63s/it] 58%|█████▊    | 7469/12825 [26:44:55<18:47:15, 12.63s/it] 58%|█████▊    | 7470/12825 [26:45:08<18:46:45, 12.62s/it] 58%|█████▊    | 7471/12825 [26:45:21<18:45:25, 12.61s/it] 58%|█████▊    | 7472/12825 [26:45:33<18:45:19, 12.61s/it] 58%|█████▊    | 7473/12825 [26:45:46<18:48:52, 12.66s/it] 58%|█████▊    | 7474/12825 [26:45:58<18:47:20, 12.64s/it] 58%|█████▊    | 7475/12825 [26:46:11<18:46:20, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120436.76lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103698.86lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7450] due to args.save_total_limit
 58%|█████▊    | 7476/12825 [26:46:24<18:54:43, 12.73s/it] 58%|█████▊    | 7477/12825 [26:46:37<18:50:49, 12.69s/it] 58%|█████▊    | 7478/12825 [26:46:49<18:48:36, 12.66s/it] 58%|█████▊    | 7479/12825 [26:47:02<18:47:02, 12.65s/it] 58%|█████▊    | 7480/12825 [26:47:24<22:47:04, 15.35s/it] 58%|█████▊    | 7481/12825 [26:47:36<21:34:44, 14.54s/it] 58%|█████▊    | 7482/12825 [26:47:49<20:42:29, 13.95s/it] 58%|█████▊    | 7483/12825 [26:48:01<20:05:53, 13.54s/it] 58%|█████▊    | 7484/12825 [26:48:14<19:42:02, 13.28s/it] 58%|█████▊    | 7485/12825 [26:48:27<19:24:37, 13.09s/it] 58%|█████▊    | 7486/12825 [26:48:39<19:14:46, 12.98s/it] 58%|█████▊    | 7487/12825 [26:48:52<19:06:52, 12.89s/it] 58%|█████▊    | 7488/12825 [26:49:05<18:59:28, 12.81s/it] 58%|█████▊    | 7489/12825 [26:49:17<18:53:46, 12.75s/it] 58%|█████▊    | 7490/12825 [26:49:30<18:54:30, 12.76s/it] 58%|█████▊    | 7491/12825 [26:49:43<18:50:42, 12.72s/it] 58%|█████▊    | 7492/12825 [26:49:55<18:48:24, 12.70s/it] 58%|█████▊    | 7493/12825 [26:50:08<18:45:47, 12.67s/it] 58%|█████▊    | 7494/12825 [26:50:21<18:45:44, 12.67s/it] 58%|█████▊    | 7495/12825 [26:50:33<18:43:54, 12.65s/it] 58%|█████▊    | 7496/12825 [26:50:46<18:43:49, 12.65s/it] 58%|█████▊    | 7497/12825 [26:50:58<18:42:32, 12.64s/it] 58%|█████▊    | 7498/12825 [26:51:11<18:42:25, 12.64s/it] 58%|█████▊    | 7499/12825 [26:51:24<18:41:11, 12.63s/it] 58%|█████▊    | 7500/12825 [26:51:36<18:40:13, 12.62s/it]                                                           58%|█████▊    | 7500/12825 [26:51:36<18:40:13, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120596.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103886.17lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7475] due to args.save_total_limit
 58%|█████▊    | 7501/12825 [26:51:49<18:49:09, 12.73s/it] 58%|█████▊    | 7502/12825 [26:52:02<18:46:46, 12.70s/it] 59%|█████▊    | 7503/12825 [26:52:15<18:43:58, 12.67s/it] 59%|█████▊    | 7504/12825 [26:52:27<18:42:14, 12.65s/it] 59%|█████▊    | 7505/12825 [26:52:40<18:39:56, 12.63s/it] 59%|█████▊    | 7506/12825 [26:52:52<18:39:52, 12.63s/it] 59%|█████▊    | 7507/12825 [26:53:05<18:39:41, 12.63s/it] 59%|█████▊    | 7508/12825 [26:53:18<18:39:21, 12.63s/it] 59%|█████▊    | 7509/12825 [26:53:30<18:38:43, 12.63s/it] 59%|█████▊    | 7510/12825 [26:53:43<18:39:18, 12.64s/it] 59%|█████▊    | 7511/12825 [26:53:56<18:40:17, 12.65s/it] 59%|█████▊    | 7512/12825 [26:54:17<22:26:45, 15.21s/it] 59%|█████▊    | 7513/12825 [26:54:29<21:17:32, 14.43s/it] 59%|█████▊    | 7514/12825 [26:54:42<20:28:26, 13.88s/it] 59%|█████▊    | 7515/12825 [26:54:55<19:55:38, 13.51s/it] 59%|█████▊    | 7516/12825 [26:55:07<19:32:01, 13.25s/it] 59%|█████▊    | 7517/12825 [26:55:20<19:14:26, 13.05s/it] 59%|█████▊    | 7518/12825 [26:55:32<19:01:32, 12.91s/it] 59%|█████▊    | 7519/12825 [26:55:45<18:59:16, 12.88s/it] 59%|█████▊    | 7520/12825 [26:55:58<18:53:16, 12.82s/it] 59%|█████▊    | 7521/12825 [26:56:11<18:50:46, 12.79s/it] 59%|█████▊    | 7522/12825 [26:56:23<18:45:22, 12.73s/it] 59%|█████▊    | 7523/12825 [26:56:36<18:45:07, 12.73s/it] 59%|█████▊    | 7524/12825 [26:56:49<18:44:47, 12.73s/it] 59%|█████▊    | 7525/12825 [26:57:01<18:41:40, 12.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120463.80lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103701.43lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7500] due to args.save_total_limit
 59%|█████▊    | 7526/12825 [26:57:14<18:47:53, 12.77s/it] 59%|█████▊    | 7527/12825 [26:57:27<18:42:52, 12.72s/it] 59%|█████▊    | 7528/12825 [26:57:39<18:39:38, 12.68s/it] 59%|█████▊    | 7529/12825 [26:57:52<18:37:08, 12.66s/it] 59%|█████▊    | 7530/12825 [26:58:05<18:35:41, 12.64s/it] 59%|█████▊    | 7531/12825 [26:58:17<18:34:39, 12.63s/it] 59%|█████▊    | 7532/12825 [26:58:30<18:32:51, 12.62s/it] 59%|█████▊    | 7533/12825 [26:58:42<18:32:30, 12.61s/it] 59%|█████▊    | 7534/12825 [26:58:55<18:31:41, 12.61s/it] 59%|█████▉    | 7535/12825 [26:59:08<18:32:34, 12.62s/it] 59%|█████▉    | 7536/12825 [26:59:20<18:31:55, 12.61s/it] 59%|█████▉    | 7537/12825 [26:59:33<18:33:33, 12.63s/it] 59%|█████▉    | 7538/12825 [26:59:46<18:31:58, 12.62s/it] 59%|█████▉    | 7539/12825 [26:59:58<18:31:46, 12.62s/it] 59%|█████▉    | 7540/12825 [27:00:11<18:31:37, 12.62s/it] 59%|█████▉    | 7541/12825 [27:00:23<18:32:29, 12.63s/it] 59%|█████▉    | 7542/12825 [27:00:36<18:31:07, 12.62s/it] 59%|█████▉    | 7543/12825 [27:00:49<18:29:30, 12.60s/it] 59%|█████▉    | 7544/12825 [27:01:01<18:28:35, 12.60s/it] 59%|█████▉    | 7545/12825 [27:01:22<22:07:31, 15.09s/it] 59%|█████▉    | 7546/12825 [27:01:35<21:02:16, 14.35s/it] 59%|█████▉    | 7547/12825 [27:01:47<20:16:09, 13.83s/it] 59%|█████▉    | 7548/12825 [27:02:00<19:44:25, 13.47s/it] 59%|█████▉    | 7549/12825 [27:02:13<19:21:34, 13.21s/it] 59%|█████▉    | 7550/12825 [27:02:25<19:05:42, 13.03s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120489.94lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103734.01lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7525] due to args.save_total_limit
 59%|█████▉    | 7551/12825 [27:02:38<19:02:25, 13.00s/it] 59%|█████▉    | 7552/12825 [27:02:51<18:51:58, 12.88s/it] 59%|█████▉    | 7553/12825 [27:03:03<18:43:47, 12.79s/it] 59%|█████▉    | 7554/12825 [27:03:16<18:38:46, 12.73s/it] 59%|█████▉    | 7555/12825 [27:03:28<18:35:14, 12.70s/it] 59%|█████▉    | 7556/12825 [27:03:41<18:32:18, 12.67s/it] 59%|█████▉    | 7557/12825 [27:03:54<18:29:47, 12.64s/it] 59%|█████▉    | 7558/12825 [27:04:06<18:27:59, 12.62s/it] 59%|█████▉    | 7559/12825 [27:04:19<18:26:43, 12.61s/it] 59%|█████▉    | 7560/12825 [27:04:31<18:26:07, 12.61s/it] 59%|█████▉    | 7561/12825 [27:04:44<18:26:14, 12.61s/it] 59%|█████▉    | 7562/12825 [27:04:57<18:26:29, 12.61s/it] 59%|█████▉    | 7563/12825 [27:05:09<18:26:35, 12.62s/it] 59%|█████▉    | 7564/12825 [27:05:22<18:27:06, 12.63s/it] 59%|█████▉    | 7565/12825 [27:05:35<18:25:51, 12.61s/it] 59%|█████▉    | 7566/12825 [27:05:47<18:25:19, 12.61s/it] 59%|█████▉    | 7567/12825 [27:06:00<18:25:07, 12.61s/it] 59%|█████▉    | 7568/12825 [27:06:12<18:24:53, 12.61s/it] 59%|█████▉    | 7569/12825 [27:06:25<18:25:57, 12.63s/it] 59%|█████▉    | 7570/12825 [27:06:38<18:26:22, 12.63s/it] 59%|█████▉    | 7571/12825 [27:06:50<18:25:17, 12.62s/it] 59%|█████▉    | 7572/12825 [27:07:03<18:23:42, 12.61s/it] 59%|█████▉    | 7573/12825 [27:07:15<18:24:57, 12.62s/it] 59%|█████▉    | 7574/12825 [27:07:28<18:24:44, 12.62s/it] 59%|█████▉    | 7575/12825 [27:07:41<18:23:42, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120467.26lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103704.08lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7375] due to args.save_total_limit
 59%|█████▉    | 7576/12825 [27:07:54<18:31:50, 12.71s/it] 59%|█████▉    | 7577/12825 [27:08:17<23:21:24, 16.02s/it] 59%|█████▉    | 7578/12825 [27:08:30<21:51:21, 15.00s/it] 59%|█████▉    | 7579/12825 [27:08:43<20:48:17, 14.28s/it] 59%|█████▉    | 7580/12825 [27:08:55<20:04:04, 13.77s/it] 59%|█████▉    | 7581/12825 [27:09:08<19:32:42, 13.42s/it] 59%|█████▉    | 7582/12825 [27:09:20<19:11:43, 13.18s/it] 59%|█████▉    | 7583/12825 [27:09:33<18:55:59, 13.00s/it] 59%|█████▉    | 7584/12825 [27:09:46<18:45:00, 12.88s/it] 59%|█████▉    | 7585/12825 [27:09:58<18:37:56, 12.80s/it] 59%|█████▉    | 7586/12825 [27:10:11<18:33:01, 12.75s/it] 59%|█████▉    | 7587/12825 [27:10:23<18:28:56, 12.70s/it] 59%|█████▉    | 7588/12825 [27:10:36<18:27:15, 12.69s/it] 59%|█████▉    | 7589/12825 [27:10:49<18:23:56, 12.65s/it] 59%|█████▉    | 7590/12825 [27:11:01<18:22:55, 12.64s/it] 59%|█████▉    | 7591/12825 [27:11:14<18:21:11, 12.62s/it] 59%|█████▉    | 7592/12825 [27:11:26<18:21:19, 12.63s/it] 59%|█████▉    | 7593/12825 [27:11:39<18:20:59, 12.63s/it] 59%|█████▉    | 7594/12825 [27:11:52<18:20:53, 12.63s/it] 59%|█████▉    | 7595/12825 [27:12:04<18:19:41, 12.62s/it] 59%|█████▉    | 7596/12825 [27:12:17<18:18:34, 12.61s/it] 59%|█████▉    | 7597/12825 [27:12:29<18:17:50, 12.60s/it] 59%|█████▉    | 7598/12825 [27:12:42<18:18:23, 12.61s/it] 59%|█████▉    | 7599/12825 [27:12:55<18:18:10, 12.61s/it] 59%|█████▉    | 7600/12825 [27:13:07<18:19:39, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120465.46lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103687.37lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7550] due to args.save_total_limit
 59%|█████▉    | 7601/12825 [27:13:20<18:27:11, 12.72s/it] 59%|█████▉    | 7602/12825 [27:13:33<18:23:54, 12.68s/it] 59%|█████▉    | 7603/12825 [27:13:45<18:20:25, 12.64s/it] 59%|█████▉    | 7604/12825 [27:13:58<18:18:35, 12.63s/it] 59%|█████▉    | 7605/12825 [27:14:11<18:17:26, 12.61s/it] 59%|█████▉    | 7606/12825 [27:14:23<18:16:18, 12.60s/it] 59%|█████▉    | 7607/12825 [27:14:36<18:15:50, 12.60s/it] 59%|█████▉    | 7608/12825 [27:14:48<18:14:19, 12.59s/it] 59%|█████▉    | 7609/12825 [27:15:10<22:16:37, 15.38s/it] 59%|█████▉    | 7610/12825 [27:15:23<21:04:35, 14.55s/it] 59%|█████▉    | 7611/12825 [27:15:35<20:13:08, 13.96s/it] 59%|█████▉    | 7612/12825 [27:15:48<19:36:23, 13.54s/it] 59%|█████▉    | 7613/12825 [27:16:01<19:11:31, 13.26s/it] 59%|█████▉    | 7614/12825 [27:16:13<18:54:09, 13.06s/it] 59%|█████▉    | 7615/12825 [27:16:26<18:42:20, 12.93s/it] 59%|█████▉    | 7616/12825 [27:16:38<18:32:37, 12.82s/it] 59%|█████▉    | 7617/12825 [27:16:51<18:29:25, 12.78s/it] 59%|█████▉    | 7618/12825 [27:17:04<18:23:09, 12.71s/it] 59%|█████▉    | 7619/12825 [27:17:16<18:19:57, 12.68s/it] 59%|█████▉    | 7620/12825 [27:17:29<18:17:27, 12.65s/it] 59%|█████▉    | 7621/12825 [27:17:41<18:15:22, 12.63s/it] 59%|█████▉    | 7622/12825 [27:17:54<18:14:15, 12.62s/it] 59%|█████▉    | 7623/12825 [27:18:07<18:13:36, 12.61s/it] 59%|█████▉    | 7624/12825 [27:18:19<18:12:34, 12.60s/it] 59%|█████▉    | 7625/12825 [27:18:32<18:11:32, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120359.84lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103675.03lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7600] due to args.save_total_limit
 59%|█████▉    | 7626/12825 [27:18:45<18:19:49, 12.69s/it] 59%|█████▉    | 7627/12825 [27:18:57<18:16:27, 12.66s/it] 59%|█████▉    | 7628/12825 [27:19:10<18:14:25, 12.64s/it] 59%|█████▉    | 7629/12825 [27:19:22<18:12:49, 12.62s/it] 59%|█████▉    | 7630/12825 [27:19:35<18:11:36, 12.61s/it] 60%|█████▉    | 7631/12825 [27:19:48<18:11:35, 12.61s/it] 60%|█████▉    | 7632/12825 [27:20:00<18:11:26, 12.61s/it] 60%|█████▉    | 7633/12825 [27:20:13<18:09:57, 12.60s/it] 60%|█████▉    | 7634/12825 [27:20:25<18:09:04, 12.59s/it] 60%|█████▉    | 7635/12825 [27:20:38<18:09:18, 12.59s/it] 60%|█████▉    | 7636/12825 [27:20:51<18:08:26, 12.59s/it] 60%|█████▉    | 7637/12825 [27:21:03<18:07:45, 12.58s/it] 60%|█████▉    | 7638/12825 [27:21:16<18:07:24, 12.58s/it] 60%|█████▉    | 7639/12825 [27:21:28<18:07:41, 12.58s/it] 60%|█████▉    | 7640/12825 [27:21:41<18:08:07, 12.59s/it] 60%|█████▉    | 7641/12825 [27:21:53<18:07:28, 12.59s/it] 60%|█████▉    | 7642/12825 [27:22:14<21:42:18, 15.08s/it] 60%|█████▉    | 7643/12825 [27:22:27<20:36:51, 14.32s/it] 60%|█████▉    | 7644/12825 [27:22:39<19:51:14, 13.80s/it] 60%|█████▉    | 7645/12825 [27:22:52<19:22:34, 13.47s/it] 60%|█████▉    | 7646/12825 [27:23:05<19:00:17, 13.21s/it] 60%|█████▉    | 7647/12825 [27:23:17<18:46:55, 13.06s/it] 60%|█████▉    | 7648/12825 [27:23:30<18:35:10, 12.92s/it] 60%|█████▉    | 7649/12825 [27:23:43<18:26:21, 12.82s/it] 60%|█████▉    | 7650/12825 [27:23:55<18:19:55, 12.75s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120433.69lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103741.89lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7625] due to args.save_total_limit
 60%|█████▉    | 7651/12825 [27:24:08<18:22:56, 12.79s/it] 60%|█████▉    | 7652/12825 [27:24:21<18:17:29, 12.73s/it] 60%|█████▉    | 7653/12825 [27:24:33<18:12:39, 12.68s/it] 60%|█████▉    | 7654/12825 [27:24:46<18:09:10, 12.64s/it] 60%|█████▉    | 7655/12825 [27:24:58<18:07:23, 12.62s/it] 60%|█████▉    | 7656/12825 [27:25:11<18:06:00, 12.61s/it] 60%|█████▉    | 7657/12825 [27:25:24<18:04:44, 12.59s/it] 60%|█████▉    | 7658/12825 [27:25:36<18:04:38, 12.60s/it] 60%|█████▉    | 7659/12825 [27:25:49<18:03:40, 12.59s/it] 60%|█████▉    | 7660/12825 [27:26:01<18:02:33, 12.58s/it] 60%|█████▉    | 7661/12825 [27:26:14<18:03:31, 12.59s/it] 60%|█████▉    | 7662/12825 [27:26:26<18:02:11, 12.58s/it] 60%|█████▉    | 7663/12825 [27:26:39<18:01:20, 12.57s/it] 60%|█████▉    | 7664/12825 [27:26:52<18:01:46, 12.58s/it] 60%|█████▉    | 7665/12825 [27:27:04<18:00:54, 12.57s/it] 60%|█████▉    | 7666/12825 [27:27:17<18:02:34, 12.59s/it] 60%|█████▉    | 7667/12825 [27:27:29<18:02:07, 12.59s/it] 60%|█████▉    | 7668/12825 [27:27:42<18:01:40, 12.58s/it] 60%|█████▉    | 7669/12825 [27:27:55<18:03:06, 12.60s/it] 60%|█████▉    | 7670/12825 [27:28:07<18:02:33, 12.60s/it] 60%|█████▉    | 7671/12825 [27:28:20<18:01:08, 12.59s/it] 60%|█████▉    | 7672/12825 [27:28:32<18:00:17, 12.58s/it] 60%|█████▉    | 7673/12825 [27:28:45<18:00:44, 12.59s/it] 60%|█████▉    | 7674/12825 [27:29:05<21:22:44, 14.94s/it] 60%|█████▉    | 7675/12825 [27:29:18<20:20:56, 14.22s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120468.92lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103704.75lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7650] due to args.save_total_limit
 60%|█████▉    | 7676/12825 [27:29:31<19:47:36, 13.84s/it] 60%|█████▉    | 7677/12825 [27:29:43<19:14:34, 13.46s/it] 60%|█████▉    | 7678/12825 [27:29:56<18:51:54, 13.19s/it] 60%|█████▉    | 7679/12825 [27:30:09<18:35:47, 13.01s/it] 60%|█████▉    | 7680/12825 [27:30:21<18:30:38, 12.95s/it] 60%|█████▉    | 7681/12825 [27:30:34<18:20:50, 12.84s/it] 60%|█████▉    | 7682/12825 [27:30:47<18:13:57, 12.76s/it] 60%|█████▉    | 7683/12825 [27:30:59<18:08:53, 12.71s/it] 60%|█████▉    | 7684/12825 [27:31:12<18:04:39, 12.66s/it] 60%|█████▉    | 7685/12825 [27:31:24<18:02:20, 12.63s/it] 60%|█████▉    | 7686/12825 [27:31:37<18:00:19, 12.61s/it] 60%|█████▉    | 7687/12825 [27:31:49<17:58:10, 12.59s/it] 60%|█████▉    | 7688/12825 [27:32:02<17:56:58, 12.58s/it] 60%|█████▉    | 7689/12825 [27:32:14<17:56:39, 12.58s/it] 60%|█████▉    | 7690/12825 [27:32:27<17:56:44, 12.58s/it] 60%|█████▉    | 7691/12825 [27:32:40<17:56:47, 12.58s/it] 60%|█████▉    | 7692/12825 [27:32:52<17:56:37, 12.58s/it] 60%|█████▉    | 7693/12825 [27:33:05<17:56:16, 12.58s/it] 60%|█████▉    | 7694/12825 [27:33:13<15:55:22, 11.17s/it] 60%|██████    | 7695/12825 [27:33:13<11:29:43,  8.07s/it] 60%|██████    | 7696/12825 [27:33:39<18:54:42, 13.27s/it] 60%|██████    | 7697/12825 [27:33:52<18:37:25, 13.07s/it] 60%|██████    | 7698/12825 [27:34:04<18:25:41, 12.94s/it] 60%|██████    | 7699/12825 [27:34:17<18:16:43, 12.84s/it] 60%|██████    | 7700/12825 [27:34:29<18:11:14, 12.78s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120408.98lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103657.29lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7675] due to args.save_total_limit
 60%|██████    | 7701/12825 [27:34:42<18:14:50, 12.82s/it] 60%|██████    | 7702/12825 [27:34:55<18:08:29, 12.75s/it] 60%|██████    | 7703/12825 [27:35:07<18:02:53, 12.69s/it] 60%|██████    | 7704/12825 [27:35:20<17:59:32, 12.65s/it] 60%|██████    | 7705/12825 [27:35:33<17:58:15, 12.64s/it] 60%|██████    | 7706/12825 [27:35:45<17:55:52, 12.61s/it] 60%|██████    | 7707/12825 [27:36:07<21:45:06, 15.30s/it] 60%|██████    | 7708/12825 [27:36:19<20:34:40, 14.48s/it] 60%|██████    | 7709/12825 [27:36:32<19:45:41, 13.91s/it] 60%|██████    | 7710/12825 [27:36:44<19:12:16, 13.52s/it] 60%|██████    | 7711/12825 [27:36:57<18:47:30, 13.23s/it] 60%|██████    | 7712/12825 [27:37:10<18:29:21, 13.02s/it] 60%|██████    | 7713/12825 [27:37:22<18:17:11, 12.88s/it] 60%|██████    | 7714/12825 [27:37:35<18:10:50, 12.81s/it] 60%|██████    | 7715/12825 [27:37:47<18:04:35, 12.73s/it] 60%|██████    | 7716/12825 [27:38:00<18:00:14, 12.69s/it] 60%|██████    | 7717/12825 [27:38:12<17:57:50, 12.66s/it] 60%|██████    | 7718/12825 [27:38:25<17:56:22, 12.65s/it] 60%|██████    | 7719/12825 [27:38:38<17:54:16, 12.62s/it] 60%|██████    | 7720/12825 [27:38:50<17:53:22, 12.62s/it] 60%|██████    | 7721/12825 [27:39:03<17:51:55, 12.60s/it] 60%|██████    | 7722/12825 [27:39:15<17:51:19, 12.60s/it] 60%|██████    | 7723/12825 [27:39:28<17:50:26, 12.59s/it] 60%|██████    | 7724/12825 [27:39:41<17:51:56, 12.61s/it] 60%|██████    | 7725/12825 [27:39:53<17:50:19, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120474.56lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103696.96lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7725
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7725/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7725/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7575] due to args.save_total_limit
 60%|██████    | 7726/12825 [27:40:06<17:58:50, 12.69s/it] 60%|██████    | 7727/12825 [27:40:19<17:55:58, 12.66s/it] 60%|██████    | 7728/12825 [27:40:31<17:52:48, 12.63s/it] 60%|██████    | 7729/12825 [27:40:44<17:50:23, 12.60s/it] 60%|██████    | 7730/12825 [27:40:56<17:49:57, 12.60s/it] 60%|██████    | 7731/12825 [27:41:09<17:49:25, 12.60s/it] 60%|██████    | 7732/12825 [27:41:22<17:50:03, 12.61s/it] 60%|██████    | 7733/12825 [27:41:34<17:50:46, 12.62s/it] 60%|██████    | 7734/12825 [27:41:47<17:49:26, 12.60s/it] 60%|██████    | 7735/12825 [27:41:59<17:47:11, 12.58s/it] 60%|██████    | 7736/12825 [27:42:12<17:47:05, 12.58s/it] 60%|██████    | 7737/12825 [27:42:24<17:46:17, 12.57s/it] 60%|██████    | 7738/12825 [27:42:37<17:45:39, 12.57s/it] 60%|██████    | 7739/12825 [27:42:58<21:22:22, 15.13s/it] 60%|██████    | 7740/12825 [27:43:11<20:16:36, 14.36s/it] 60%|██████    | 7741/12825 [27:43:23<19:31:00, 13.82s/it] 60%|██████    | 7742/12825 [27:43:36<18:59:08, 13.45s/it] 60%|██████    | 7743/12825 [27:43:48<18:37:00, 13.19s/it] 60%|██████    | 7744/12825 [27:44:01<18:24:03, 13.04s/it] 60%|██████    | 7745/12825 [27:44:14<18:14:42, 12.93s/it] 60%|██████    | 7746/12825 [27:44:26<18:05:40, 12.83s/it] 60%|██████    | 7747/12825 [27:44:39<17:58:47, 12.75s/it] 60%|██████    | 7748/12825 [27:44:52<17:56:36, 12.72s/it] 60%|██████    | 7749/12825 [27:45:04<17:53:27, 12.69s/it] 60%|██████    | 7750/12825 [27:45:17<17:50:58, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120533.67lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103828.26lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7750
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7750/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7750/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7700] due to args.save_total_limit
 60%|██████    | 7751/12825 [27:45:30<17:56:14, 12.73s/it] 60%|██████    | 7752/12825 [27:45:42<17:52:12, 12.68s/it] 60%|██████    | 7753/12825 [27:45:55<17:49:36, 12.65s/it] 60%|██████    | 7754/12825 [27:46:07<17:47:40, 12.63s/it] 60%|██████    | 7755/12825 [27:46:20<17:46:38, 12.62s/it] 60%|██████    | 7756/12825 [27:46:33<17:44:38, 12.60s/it] 60%|██████    | 7757/12825 [27:46:45<17:43:56, 12.60s/it] 60%|██████    | 7758/12825 [27:46:58<17:43:10, 12.59s/it] 60%|██████    | 7759/12825 [27:47:10<17:43:23, 12.59s/it] 61%|██████    | 7760/12825 [27:47:23<17:42:09, 12.58s/it] 61%|██████    | 7761/12825 [27:47:35<17:41:17, 12.57s/it] 61%|██████    | 7762/12825 [27:47:48<17:40:38, 12.57s/it] 61%|██████    | 7763/12825 [27:48:01<17:39:45, 12.56s/it] 61%|██████    | 7764/12825 [27:48:13<17:39:52, 12.57s/it] 61%|██████    | 7765/12825 [27:48:26<17:39:53, 12.57s/it] 61%|██████    | 7766/12825 [27:48:38<17:39:32, 12.57s/it] 61%|██████    | 7767/12825 [27:48:51<17:38:49, 12.56s/it] 61%|██████    | 7768/12825 [27:49:03<17:38:57, 12.56s/it] 61%|██████    | 7769/12825 [27:49:16<17:39:04, 12.57s/it] 61%|██████    | 7770/12825 [27:49:29<17:38:27, 12.56s/it] 61%|██████    | 7771/12825 [27:49:41<17:39:14, 12.58s/it] 61%|██████    | 7772/12825 [27:50:02<21:10:19, 15.08s/it] 61%|██████    | 7773/12825 [27:50:15<20:06:52, 14.33s/it] 61%|██████    | 7774/12825 [27:50:27<19:23:42, 13.82s/it] 61%|██████    | 7775/12825 [27:50:40<18:52:30, 13.46s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120322.11lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103687.37lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7775
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7775/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7775/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7750] due to args.save_total_limit
 61%|██████    | 7776/12825 [27:50:53<18:40:46, 13.32s/it] 61%|██████    | 7777/12825 [27:51:06<18:23:12, 13.11s/it] 61%|██████    | 7778/12825 [27:51:18<18:10:13, 12.96s/it] 61%|██████    | 7779/12825 [27:51:31<18:01:45, 12.86s/it] 61%|██████    | 7780/12825 [27:51:43<17:54:59, 12.78s/it] 61%|██████    | 7781/12825 [27:51:56<17:50:18, 12.73s/it] 61%|██████    | 7782/12825 [27:52:09<17:46:42, 12.69s/it] 61%|██████    | 7783/12825 [27:52:21<17:44:23, 12.67s/it] 61%|██████    | 7784/12825 [27:52:34<17:41:46, 12.64s/it] 61%|██████    | 7785/12825 [27:52:46<17:41:34, 12.64s/it] 61%|██████    | 7786/12825 [27:52:59<17:40:41, 12.63s/it] 61%|██████    | 7787/12825 [27:53:12<17:40:52, 12.63s/it] 61%|██████    | 7788/12825 [27:53:24<17:38:44, 12.61s/it] 61%|██████    | 7789/12825 [27:53:37<17:37:16, 12.60s/it] 61%|██████    | 7790/12825 [27:53:49<17:36:50, 12.59s/it] 61%|██████    | 7791/12825 [27:54:02<17:40:21, 12.64s/it] 61%|██████    | 7792/12825 [27:54:15<17:39:14, 12.63s/it] 61%|██████    | 7793/12825 [27:54:27<17:38:55, 12.63s/it] 61%|██████    | 7794/12825 [27:54:40<17:38:31, 12.62s/it] 61%|██████    | 7795/12825 [27:54:53<17:37:14, 12.61s/it] 61%|██████    | 7796/12825 [27:55:05<17:38:11, 12.63s/it] 61%|██████    | 7797/12825 [27:55:18<17:37:14, 12.62s/it] 61%|██████    | 7798/12825 [27:55:30<17:36:35, 12.61s/it] 61%|██████    | 7799/12825 [27:55:43<17:36:54, 12.62s/it] 61%|██████    | 7800/12825 [27:55:56<17:35:57, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120443.81lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103697.72lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7800
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7800/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7800/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7775] due to args.save_total_limit
 61%|██████    | 7801/12825 [27:56:08<17:42:58, 12.69s/it] 61%|██████    | 7802/12825 [27:56:21<17:39:42, 12.66s/it] 61%|██████    | 7803/12825 [27:56:34<17:37:57, 12.64s/it] 61%|██████    | 7804/12825 [27:56:55<21:05:24, 15.12s/it] 61%|██████    | 7805/12825 [27:57:07<20:02:53, 14.38s/it] 61%|██████    | 7806/12825 [27:57:20<19:19:23, 13.86s/it] 61%|██████    | 7807/12825 [27:57:32<18:48:27, 13.49s/it] 61%|██████    | 7808/12825 [27:57:45<18:26:23, 13.23s/it] 61%|██████    | 7809/12825 [27:57:58<18:10:17, 13.04s/it] 61%|██████    | 7810/12825 [27:58:10<17:59:05, 12.91s/it] 61%|██████    | 7811/12825 [27:58:23<17:54:06, 12.85s/it] 61%|██████    | 7812/12825 [27:58:36<17:50:33, 12.81s/it] 61%|██████    | 7813/12825 [27:58:48<17:45:22, 12.75s/it] 61%|██████    | 7814/12825 [27:59:01<17:41:36, 12.71s/it] 61%|██████    | 7815/12825 [27:59:14<17:38:29, 12.68s/it] 61%|██████    | 7816/12825 [27:59:26<17:35:21, 12.64s/it] 61%|██████    | 7817/12825 [27:59:39<17:33:19, 12.62s/it] 61%|██████    | 7818/12825 [27:59:51<17:32:31, 12.61s/it] 61%|██████    | 7819/12825 [28:00:04<17:32:30, 12.62s/it] 61%|██████    | 7820/12825 [28:00:16<17:31:18, 12.60s/it] 61%|██████    | 7821/12825 [28:00:29<17:30:56, 12.60s/it] 61%|██████    | 7822/12825 [28:00:42<17:30:06, 12.59s/it] 61%|██████    | 7823/12825 [28:00:54<17:29:57, 12.59s/it] 61%|██████    | 7824/12825 [28:01:07<17:29:04, 12.59s/it] 61%|██████    | 7825/12825 [28:01:19<17:27:39, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120477.12lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103713.49lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7825
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7825/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7825/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7800] due to args.save_total_limit
 61%|██████    | 7826/12825 [28:01:32<17:35:47, 12.67s/it] 61%|██████    | 7827/12825 [28:01:45<17:32:48, 12.64s/it] 61%|██████    | 7828/12825 [28:01:57<17:30:08, 12.61s/it] 61%|██████    | 7829/12825 [28:02:10<17:28:41, 12.59s/it] 61%|██████    | 7830/12825 [28:02:23<17:28:35, 12.60s/it] 61%|██████    | 7831/12825 [28:02:35<17:28:29, 12.60s/it] 61%|██████    | 7832/12825 [28:02:48<17:27:03, 12.58s/it] 61%|██████    | 7833/12825 [28:03:00<17:27:39, 12.59s/it] 61%|██████    | 7834/12825 [28:03:13<17:27:56, 12.60s/it] 61%|██████    | 7835/12825 [28:03:25<17:26:39, 12.58s/it] 61%|██████    | 7836/12825 [28:03:47<21:02:56, 15.19s/it] 61%|██████    | 7837/12825 [28:03:59<19:58:02, 14.41s/it] 61%|██████    | 7838/12825 [28:04:12<19:12:01, 13.86s/it] 61%|██████    | 7839/12825 [28:04:25<18:43:17, 13.52s/it] 61%|██████    | 7840/12825 [28:04:37<18:21:32, 13.26s/it] 61%|██████    | 7841/12825 [28:04:50<18:03:59, 13.05s/it] 61%|██████    | 7842/12825 [28:05:03<17:54:17, 12.94s/it] 61%|██████    | 7843/12825 [28:05:15<17:45:20, 12.83s/it] 61%|██████    | 7844/12825 [28:05:28<17:38:08, 12.75s/it] 61%|██████    | 7845/12825 [28:05:40<17:33:08, 12.69s/it] 61%|██████    | 7846/12825 [28:05:53<17:32:14, 12.68s/it] 61%|██████    | 7847/12825 [28:06:05<17:30:57, 12.67s/it] 61%|██████    | 7848/12825 [28:06:18<17:28:04, 12.64s/it] 61%|██████    | 7849/12825 [28:06:31<17:29:02, 12.65s/it] 61%|██████    | 7850/12825 [28:06:43<17:25:31, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120398.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103632.91lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7850
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7850/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7850/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7825] due to args.save_total_limit
 61%|██████    | 7851/12825 [28:06:56<17:32:21, 12.69s/it] 61%|██████    | 7852/12825 [28:07:09<17:29:44, 12.67s/it] 61%|██████    | 7853/12825 [28:07:21<17:25:55, 12.62s/it] 61%|██████    | 7854/12825 [28:07:34<17:24:11, 12.60s/it] 61%|██████    | 7855/12825 [28:07:46<17:23:04, 12.59s/it] 61%|██████▏   | 7856/12825 [28:07:59<17:21:57, 12.58s/it] 61%|██████▏   | 7857/12825 [28:08:12<17:22:21, 12.59s/it] 61%|██████▏   | 7858/12825 [28:08:24<17:21:50, 12.59s/it] 61%|██████▏   | 7859/12825 [28:08:37<17:20:40, 12.57s/it] 61%|██████▏   | 7860/12825 [28:08:49<17:19:59, 12.57s/it] 61%|██████▏   | 7861/12825 [28:09:02<17:18:42, 12.55s/it] 61%|██████▏   | 7862/12825 [28:09:14<17:18:15, 12.55s/it] 61%|██████▏   | 7863/12825 [28:09:27<17:21:03, 12.59s/it] 61%|██████▏   | 7864/12825 [28:09:40<17:19:34, 12.57s/it] 61%|██████▏   | 7865/12825 [28:09:52<17:19:05, 12.57s/it] 61%|██████▏   | 7866/12825 [28:10:05<17:18:31, 12.57s/it] 61%|██████▏   | 7867/12825 [28:10:17<17:18:11, 12.56s/it] 61%|██████▏   | 7868/12825 [28:10:30<17:18:37, 12.57s/it] 61%|██████▏   | 7869/12825 [28:10:52<21:06:38, 15.33s/it] 61%|██████▏   | 7870/12825 [28:11:04<19:57:21, 14.50s/it] 61%|██████▏   | 7871/12825 [28:11:17<19:08:47, 13.91s/it] 61%|██████▏   | 7872/12825 [28:11:29<18:34:53, 13.51s/it] 61%|██████▏   | 7873/12825 [28:11:42<18:10:11, 13.21s/it] 61%|██████▏   | 7874/12825 [28:11:54<17:54:10, 13.02s/it] 61%|██████▏   | 7875/12825 [28:12:07<17:42:28, 12.88s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120488.79lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103728.31lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7875
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7875/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7875/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7850] due to args.save_total_limit
 61%|██████▏   | 7876/12825 [28:12:20<17:42:21, 12.88s/it] 61%|██████▏   | 7877/12825 [28:12:32<17:34:04, 12.78s/it] 61%|██████▏   | 7878/12825 [28:12:45<17:28:59, 12.72s/it] 61%|██████▏   | 7879/12825 [28:12:57<17:24:34, 12.67s/it] 61%|██████▏   | 7880/12825 [28:13:10<17:21:40, 12.64s/it] 61%|██████▏   | 7881/12825 [28:13:23<17:19:54, 12.62s/it] 61%|██████▏   | 7882/12825 [28:13:35<17:18:30, 12.61s/it] 61%|██████▏   | 7883/12825 [28:13:48<17:17:32, 12.60s/it] 61%|██████▏   | 7884/12825 [28:14:00<17:16:46, 12.59s/it] 61%|██████▏   | 7885/12825 [28:14:13<17:16:22, 12.59s/it] 61%|██████▏   | 7886/12825 [28:14:25<17:15:35, 12.58s/it] 61%|██████▏   | 7887/12825 [28:14:38<17:14:33, 12.57s/it] 62%|██████▏   | 7888/12825 [28:14:51<17:14:19, 12.57s/it] 62%|██████▏   | 7889/12825 [28:15:03<17:13:46, 12.57s/it] 62%|██████▏   | 7890/12825 [28:15:16<17:16:34, 12.60s/it] 62%|██████▏   | 7891/12825 [28:15:28<17:16:26, 12.60s/it] 62%|██████▏   | 7892/12825 [28:15:41<17:16:16, 12.60s/it] 62%|██████▏   | 7893/12825 [28:15:54<17:14:29, 12.59s/it] 62%|██████▏   | 7894/12825 [28:16:06<17:13:30, 12.58s/it] 62%|██████▏   | 7895/12825 [28:16:19<17:13:38, 12.58s/it] 62%|██████▏   | 7896/12825 [28:16:31<17:13:17, 12.58s/it] 62%|██████▏   | 7897/12825 [28:16:44<17:12:04, 12.57s/it] 62%|██████▏   | 7898/12825 [28:16:56<17:14:49, 12.60s/it] 62%|██████▏   | 7899/12825 [28:17:09<17:14:35, 12.60s/it] 62%|██████▏   | 7900/12825 [28:17:22<17:12:49, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120433.05lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103764.90lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7900
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7900/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7900/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7875] due to args.save_total_limit
 62%|██████▏   | 7901/12825 [28:17:43<20:55:43, 15.30s/it] 62%|██████▏   | 7902/12825 [28:17:56<19:47:50, 14.48s/it] 62%|██████▏   | 7903/12825 [28:18:08<19:01:35, 13.92s/it] 62%|██████▏   | 7904/12825 [28:18:21<18:27:30, 13.50s/it] 62%|██████▏   | 7905/12825 [28:18:34<18:04:06, 13.22s/it] 62%|██████▏   | 7906/12825 [28:18:46<17:51:50, 13.07s/it] 62%|██████▏   | 7907/12825 [28:18:59<17:38:09, 12.91s/it] 62%|██████▏   | 7908/12825 [28:19:11<17:31:51, 12.84s/it] 62%|██████▏   | 7909/12825 [28:19:24<17:24:36, 12.75s/it] 62%|██████▏   | 7910/12825 [28:19:37<17:19:36, 12.69s/it] 62%|██████▏   | 7911/12825 [28:19:49<17:17:19, 12.67s/it] 62%|██████▏   | 7912/12825 [28:20:02<17:17:41, 12.67s/it] 62%|██████▏   | 7913/12825 [28:20:14<17:14:12, 12.63s/it] 62%|██████▏   | 7914/12825 [28:20:27<17:12:11, 12.61s/it] 62%|██████▏   | 7915/12825 [28:20:40<17:10:42, 12.60s/it] 62%|██████▏   | 7916/12825 [28:20:52<17:09:33, 12.58s/it] 62%|██████▏   | 7917/12825 [28:21:05<17:08:24, 12.57s/it] 62%|██████▏   | 7918/12825 [28:21:17<17:07:27, 12.56s/it] 62%|██████▏   | 7919/12825 [28:21:30<17:06:21, 12.55s/it] 62%|██████▏   | 7920/12825 [28:21:42<17:08:55, 12.59s/it] 62%|██████▏   | 7921/12825 [28:21:55<17:08:06, 12.58s/it] 62%|██████▏   | 7922/12825 [28:22:07<17:06:31, 12.56s/it] 62%|██████▏   | 7923/12825 [28:22:20<17:05:26, 12.55s/it] 62%|██████▏   | 7924/12825 [28:22:33<17:05:32, 12.56s/it] 62%|██████▏   | 7925/12825 [28:22:45<17:05:59, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120433.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103173.11lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7925
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7925/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7925/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7900] due to args.save_total_limit
 62%|██████▏   | 7926/12825 [28:22:58<17:13:56, 12.66s/it] 62%|██████▏   | 7927/12825 [28:23:11<17:11:55, 12.64s/it] 62%|██████▏   | 7928/12825 [28:23:23<17:09:51, 12.62s/it] 62%|██████▏   | 7929/12825 [28:23:36<17:08:56, 12.61s/it] 62%|██████▏   | 7930/12825 [28:23:48<17:07:05, 12.59s/it] 62%|██████▏   | 7931/12825 [28:24:01<17:06:14, 12.58s/it] 62%|██████▏   | 7932/12825 [28:24:13<17:05:37, 12.58s/it] 62%|██████▏   | 7933/12825 [28:24:34<20:25:18, 15.03s/it] 62%|██████▏   | 7934/12825 [28:24:47<19:24:40, 14.29s/it] 62%|██████▏   | 7935/12825 [28:24:59<18:42:37, 13.77s/it] 62%|██████▏   | 7936/12825 [28:25:12<18:12:59, 13.41s/it] 62%|██████▏   | 7937/12825 [28:25:24<17:51:14, 13.15s/it] 62%|██████▏   | 7938/12825 [28:25:37<17:36:56, 12.98s/it] 62%|██████▏   | 7939/12825 [28:25:49<17:25:41, 12.84s/it] 62%|██████▏   | 7940/12825 [28:26:02<17:18:44, 12.76s/it] 62%|██████▏   | 7941/12825 [28:26:15<17:12:42, 12.69s/it] 62%|██████▏   | 7942/12825 [28:26:27<17:09:39, 12.65s/it] 62%|██████▏   | 7943/12825 [28:26:40<17:07:52, 12.63s/it] 62%|██████▏   | 7944/12825 [28:26:52<17:05:28, 12.61s/it] 62%|██████▏   | 7945/12825 [28:27:05<17:03:50, 12.59s/it] 62%|██████▏   | 7946/12825 [28:27:17<17:04:34, 12.60s/it] 62%|██████▏   | 7947/12825 [28:27:30<17:09:07, 12.66s/it] 62%|██████▏   | 7948/12825 [28:27:43<17:06:02, 12.62s/it] 62%|██████▏   | 7949/12825 [28:27:55<17:03:25, 12.59s/it] 62%|██████▏   | 7950/12825 [28:28:08<17:02:13, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120434.72lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103651.69lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7950
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7950/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7950/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7925] due to args.save_total_limit
 62%|██████▏   | 7951/12825 [28:28:21<17:12:08, 12.71s/it] 62%|██████▏   | 7952/12825 [28:28:33<17:08:30, 12.66s/it] 62%|██████▏   | 7953/12825 [28:28:46<17:07:35, 12.66s/it] 62%|██████▏   | 7954/12825 [28:28:59<17:05:29, 12.63s/it] 62%|██████▏   | 7955/12825 [28:29:11<17:04:10, 12.62s/it] 62%|██████▏   | 7956/12825 [28:29:24<17:01:31, 12.59s/it] 62%|██████▏   | 7957/12825 [28:29:36<17:01:36, 12.59s/it] 62%|██████▏   | 7958/12825 [28:29:49<16:59:55, 12.57s/it] 62%|██████▏   | 7959/12825 [28:30:01<16:59:13, 12.57s/it] 62%|██████▏   | 7960/12825 [28:30:14<16:57:40, 12.55s/it] 62%|██████▏   | 7961/12825 [28:30:27<16:57:54, 12.56s/it] 62%|██████▏   | 7962/12825 [28:30:39<16:57:40, 12.56s/it] 62%|██████▏   | 7963/12825 [28:30:52<16:56:53, 12.55s/it] 62%|██████▏   | 7964/12825 [28:31:04<16:55:48, 12.54s/it] 62%|██████▏   | 7965/12825 [28:31:17<16:55:33, 12.54s/it] 62%|██████▏   | 7966/12825 [28:31:38<20:18:53, 15.05s/it] 62%|██████▏   | 7967/12825 [28:31:50<19:18:12, 14.30s/it] 62%|██████▏   | 7968/12825 [28:32:03<18:35:54, 13.79s/it] 62%|██████▏   | 7969/12825 [28:32:15<18:06:15, 13.42s/it] 62%|██████▏   | 7970/12825 [28:32:28<17:44:36, 13.16s/it] 62%|██████▏   | 7971/12825 [28:32:40<17:30:27, 12.98s/it] 62%|██████▏   | 7972/12825 [28:32:53<17:19:58, 12.86s/it] 62%|██████▏   | 7973/12825 [28:33:06<17:12:41, 12.77s/it] 62%|██████▏   | 7974/12825 [28:33:18<17:08:47, 12.72s/it] 62%|██████▏   | 7975/12825 [28:33:31<17:06:13, 12.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120491.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103699.34lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7975
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7975/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7975/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-7975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7950] due to args.save_total_limit
 62%|██████▏   | 7976/12825 [28:33:44<17:10:48, 12.75s/it] 62%|██████▏   | 7977/12825 [28:33:56<17:05:46, 12.70s/it] 62%|██████▏   | 7978/12825 [28:34:09<17:02:07, 12.65s/it] 62%|██████▏   | 7979/12825 [28:34:21<17:00:15, 12.63s/it] 62%|██████▏   | 7980/12825 [28:34:34<16:58:42, 12.62s/it] 62%|██████▏   | 7981/12825 [28:34:46<16:56:56, 12.60s/it] 62%|██████▏   | 7982/12825 [28:34:59<16:55:48, 12.58s/it] 62%|██████▏   | 7983/12825 [28:35:12<16:55:10, 12.58s/it] 62%|██████▏   | 7984/12825 [28:35:24<16:56:07, 12.59s/it] 62%|██████▏   | 7985/12825 [28:35:37<16:55:09, 12.58s/it] 62%|██████▏   | 7986/12825 [28:35:49<16:54:37, 12.58s/it] 62%|██████▏   | 7987/12825 [28:36:02<16:55:42, 12.60s/it] 62%|██████▏   | 7988/12825 [28:36:15<16:54:51, 12.59s/it] 62%|██████▏   | 7989/12825 [28:36:27<16:54:01, 12.58s/it] 62%|██████▏   | 7990/12825 [28:36:40<16:53:13, 12.57s/it] 62%|██████▏   | 7991/12825 [28:36:52<16:52:42, 12.57s/it] 62%|██████▏   | 7992/12825 [28:37:05<16:52:28, 12.57s/it] 62%|██████▏   | 7993/12825 [28:37:17<16:52:01, 12.57s/it] 62%|██████▏   | 7994/12825 [28:37:30<16:52:01, 12.57s/it] 62%|██████▏   | 7995/12825 [28:37:43<16:51:31, 12.57s/it] 62%|██████▏   | 7996/12825 [28:37:55<16:51:25, 12.57s/it] 62%|██████▏   | 7997/12825 [28:38:08<16:51:36, 12.57s/it] 62%|██████▏   | 7998/12825 [28:38:29<20:12:36, 15.07s/it] 62%|██████▏   | 7999/12825 [28:38:41<19:10:44, 14.31s/it] 62%|██████▏   | 8000/12825 [28:38:54<18:28:53, 13.79s/it]                                                           62%|██████▏   | 8000/12825 [28:38:54<18:28:53, 13.79s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120483.53lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103701.90lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8000
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8000/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8000/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7975] due to args.save_total_limit
 62%|██████▏   | 8001/12825 [28:39:07<18:06:34, 13.51s/it] 62%|██████▏   | 8002/12825 [28:39:19<17:43:14, 13.23s/it] 62%|██████▏   | 8003/12825 [28:39:32<17:26:16, 13.02s/it] 62%|██████▏   | 8004/12825 [28:39:44<17:14:23, 12.87s/it] 62%|██████▏   | 8005/12825 [28:39:57<17:07:01, 12.78s/it] 62%|██████▏   | 8006/12825 [28:40:09<17:05:13, 12.76s/it] 62%|██████▏   | 8007/12825 [28:40:22<17:01:15, 12.72s/it] 62%|██████▏   | 8008/12825 [28:40:35<16:57:12, 12.67s/it] 62%|██████▏   | 8009/12825 [28:40:47<16:53:52, 12.63s/it] 62%|██████▏   | 8010/12825 [28:41:00<16:52:05, 12.61s/it] 62%|██████▏   | 8011/12825 [28:41:12<16:49:58, 12.59s/it] 62%|██████▏   | 8012/12825 [28:41:25<16:48:55, 12.58s/it] 62%|██████▏   | 8013/12825 [28:41:37<16:48:46, 12.58s/it] 62%|██████▏   | 8014/12825 [28:41:50<16:47:43, 12.57s/it] 62%|██████▏   | 8015/12825 [28:42:03<16:47:26, 12.57s/it] 63%|██████▎   | 8016/12825 [28:42:15<16:46:26, 12.56s/it] 63%|██████▎   | 8017/12825 [28:42:28<16:47:06, 12.57s/it] 63%|██████▎   | 8018/12825 [28:42:40<16:47:24, 12.57s/it] 63%|██████▎   | 8019/12825 [28:42:53<16:47:20, 12.58s/it] 63%|██████▎   | 8020/12825 [28:43:05<16:48:02, 12.59s/it] 63%|██████▎   | 8021/12825 [28:43:18<16:48:17, 12.59s/it] 63%|██████▎   | 8022/12825 [28:43:31<16:47:09, 12.58s/it] 63%|██████▎   | 8023/12825 [28:43:43<16:46:26, 12.58s/it] 63%|██████▎   | 8024/12825 [28:43:56<16:45:55, 12.57s/it] 63%|██████▎   | 8025/12825 [28:44:08<16:45:58, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120330.29lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103682.34lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8025
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8025/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8025/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8000] due to args.save_total_limit
 63%|██████▎   | 8026/12825 [28:44:21<16:52:56, 12.66s/it] 63%|██████▎   | 8027/12825 [28:44:34<16:52:14, 12.66s/it] 63%|██████▎   | 8028/12825 [28:44:46<16:49:12, 12.62s/it] 63%|██████▎   | 8029/12825 [28:44:59<16:46:49, 12.60s/it] 63%|██████▎   | 8030/12825 [28:45:18<19:13:37, 14.44s/it] 63%|██████▎   | 8031/12825 [28:45:30<18:28:56, 13.88s/it] 63%|██████▎   | 8032/12825 [28:45:43<17:56:52, 13.48s/it] 63%|██████▎   | 8033/12825 [28:45:55<17:34:54, 13.21s/it] 63%|██████▎   | 8034/12825 [28:46:08<17:19:54, 13.02s/it] 63%|██████▎   | 8035/12825 [28:46:20<17:08:08, 12.88s/it] 63%|██████▎   | 8036/12825 [28:46:33<17:01:14, 12.79s/it] 63%|██████▎   | 8037/12825 [28:46:46<16:57:00, 12.74s/it] 63%|██████▎   | 8038/12825 [28:46:58<16:54:27, 12.72s/it] 63%|██████▎   | 8039/12825 [28:47:11<16:51:07, 12.68s/it] 63%|██████▎   | 8040/12825 [28:47:24<16:50:25, 12.67s/it] 63%|██████▎   | 8041/12825 [28:47:36<16:47:34, 12.64s/it] 63%|██████▎   | 8042/12825 [28:47:49<16:44:45, 12.60s/it] 63%|██████▎   | 8043/12825 [28:48:01<16:43:37, 12.59s/it] 63%|██████▎   | 8044/12825 [28:48:14<16:42:28, 12.58s/it] 63%|██████▎   | 8045/12825 [28:48:26<16:41:19, 12.57s/it] 63%|██████▎   | 8046/12825 [28:48:39<16:41:04, 12.57s/it] 63%|██████▎   | 8047/12825 [28:48:51<16:41:01, 12.57s/it] 63%|██████▎   | 8048/12825 [28:49:04<16:41:48, 12.58s/it] 63%|██████▎   | 8049/12825 [28:49:17<16:41:30, 12.58s/it] 63%|██████▎   | 8050/12825 [28:49:29<16:40:12, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120491.87lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103735.53lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8050
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8050/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8050/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8025] due to args.save_total_limit
 63%|██████▎   | 8051/12825 [28:49:42<16:47:25, 12.66s/it] 63%|██████▎   | 8052/12825 [28:49:55<16:44:36, 12.63s/it] 63%|██████▎   | 8053/12825 [28:50:07<16:42:16, 12.60s/it] 63%|██████▎   | 8054/12825 [28:50:20<16:41:05, 12.59s/it] 63%|██████▎   | 8055/12825 [28:50:32<16:40:23, 12.58s/it] 63%|██████▎   | 8056/12825 [28:50:45<16:39:09, 12.57s/it] 63%|██████▎   | 8057/12825 [28:50:57<16:39:20, 12.58s/it] 63%|██████▎   | 8058/12825 [28:51:10<16:38:27, 12.57s/it] 63%|██████▎   | 8059/12825 [28:51:23<16:38:01, 12.56s/it] 63%|██████▎   | 8060/12825 [28:51:35<16:37:10, 12.56s/it] 63%|██████▎   | 8061/12825 [28:51:48<16:36:47, 12.55s/it] 63%|██████▎   | 8062/12825 [28:52:00<16:36:38, 12.55s/it] 63%|██████▎   | 8063/12825 [28:52:21<20:01:48, 15.14s/it] 63%|██████▎   | 8064/12825 [28:52:34<19:00:40, 14.38s/it] 63%|██████▎   | 8065/12825 [28:52:47<18:17:50, 13.84s/it] 63%|██████▎   | 8066/12825 [28:52:59<17:47:59, 13.47s/it] 63%|██████▎   | 8067/12825 [28:53:12<17:26:39, 13.20s/it] 63%|██████▎   | 8068/12825 [28:53:24<17:11:41, 13.01s/it] 63%|██████▎   | 8069/12825 [28:53:37<17:01:47, 12.89s/it] 63%|██████▎   | 8070/12825 [28:53:49<16:54:00, 12.79s/it] 63%|██████▎   | 8071/12825 [28:54:02<16:48:31, 12.73s/it] 63%|██████▎   | 8072/12825 [28:54:15<16:44:17, 12.68s/it] 63%|██████▎   | 8073/12825 [28:54:27<16:41:44, 12.65s/it] 63%|██████▎   | 8074/12825 [28:54:40<16:39:34, 12.62s/it] 63%|██████▎   | 8075/12825 [28:54:52<16:37:41, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120438.30lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103694.68lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8075
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8075/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8075/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8050] due to args.save_total_limit
 63%|██████▎   | 8076/12825 [28:55:05<16:44:14, 12.69s/it] 63%|██████▎   | 8077/12825 [28:55:18<16:40:37, 12.64s/it] 63%|██████▎   | 8078/12825 [28:55:30<16:37:49, 12.61s/it] 63%|██████▎   | 8079/12825 [28:55:43<16:36:54, 12.60s/it] 63%|██████▎   | 8080/12825 [28:55:55<16:36:20, 12.60s/it] 63%|██████▎   | 8081/12825 [28:56:08<16:34:19, 12.58s/it] 63%|██████▎   | 8082/12825 [28:56:20<16:33:37, 12.57s/it] 63%|██████▎   | 8083/12825 [28:56:33<16:33:24, 12.57s/it] 63%|██████▎   | 8084/12825 [28:56:46<16:32:34, 12.56s/it] 63%|██████▎   | 8085/12825 [28:56:58<16:32:41, 12.57s/it] 63%|██████▎   | 8086/12825 [28:57:11<16:32:10, 12.56s/it] 63%|██████▎   | 8087/12825 [28:57:23<16:32:06, 12.56s/it] 63%|██████▎   | 8088/12825 [28:57:36<16:32:11, 12.57s/it] 63%|██████▎   | 8089/12825 [28:57:48<16:32:24, 12.57s/it] 63%|██████▎   | 8090/12825 [28:58:01<16:31:57, 12.57s/it] 63%|██████▎   | 8091/12825 [28:58:14<16:31:07, 12.56s/it] 63%|██████▎   | 8092/12825 [28:58:26<16:30:57, 12.56s/it] 63%|██████▎   | 8093/12825 [28:58:39<16:30:02, 12.55s/it] 63%|██████▎   | 8094/12825 [28:58:51<16:29:04, 12.54s/it] 63%|██████▎   | 8095/12825 [28:59:12<19:40:32, 14.98s/it] 63%|██████▎   | 8096/12825 [28:59:24<18:42:10, 14.24s/it] 63%|██████▎   | 8097/12825 [28:59:37<18:02:42, 13.74s/it] 63%|██████▎   | 8098/12825 [28:59:50<17:35:38, 13.40s/it] 63%|██████▎   | 8099/12825 [29:00:02<17:15:20, 13.14s/it] 63%|██████▎   | 8100/12825 [29:00:15<17:03:13, 12.99s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120428.44lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103667.35lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8075] due to args.save_total_limit
 63%|██████▎   | 8101/12825 [29:00:28<17:00:09, 12.96s/it] 63%|██████▎   | 8102/12825 [29:00:40<16:49:51, 12.83s/it] 63%|██████▎   | 8103/12825 [29:00:53<16:42:38, 12.74s/it] 63%|██████▎   | 8104/12825 [29:01:05<16:38:51, 12.69s/it] 63%|██████▎   | 8105/12825 [29:01:18<16:36:14, 12.66s/it] 63%|██████▎   | 8106/12825 [29:01:30<16:33:18, 12.63s/it] 63%|██████▎   | 8107/12825 [29:01:43<16:30:56, 12.60s/it] 63%|██████▎   | 8108/12825 [29:01:56<16:30:25, 12.60s/it] 63%|██████▎   | 8109/12825 [29:02:08<16:29:07, 12.58s/it] 63%|██████▎   | 8110/12825 [29:02:21<16:29:42, 12.59s/it] 63%|██████▎   | 8111/12825 [29:02:33<16:28:21, 12.58s/it] 63%|██████▎   | 8112/12825 [29:02:46<16:27:36, 12.57s/it] 63%|██████▎   | 8113/12825 [29:02:58<16:27:15, 12.57s/it] 63%|██████▎   | 8114/12825 [29:03:11<16:28:13, 12.59s/it] 63%|██████▎   | 8115/12825 [29:03:24<16:27:17, 12.58s/it] 63%|██████▎   | 8116/12825 [29:03:36<16:26:31, 12.57s/it] 63%|██████▎   | 8117/12825 [29:03:49<16:27:58, 12.59s/it] 63%|██████▎   | 8118/12825 [29:04:01<16:27:13, 12.58s/it] 63%|██████▎   | 8119/12825 [29:04:14<16:26:26, 12.58s/it] 63%|██████▎   | 8120/12825 [29:04:26<16:25:48, 12.57s/it] 63%|██████▎   | 8121/12825 [29:04:39<16:26:09, 12.58s/it] 63%|██████▎   | 8122/12825 [29:04:52<16:26:34, 12.59s/it] 63%|██████▎   | 8123/12825 [29:05:04<16:26:52, 12.59s/it] 63%|██████▎   | 8124/12825 [29:05:17<16:26:33, 12.59s/it] 63%|██████▎   | 8125/12825 [29:05:29<16:25:23, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120175.40lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 99852.58lines/s] 
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8100] due to args.save_total_limit
 63%|██████▎   | 8126/12825 [29:05:42<16:36:57, 12.73s/it] 63%|██████▎   | 8127/12825 [29:05:55<16:33:33, 12.69s/it] 63%|██████▎   | 8128/12825 [29:06:17<19:59:39, 15.32s/it] 63%|██████▎   | 8129/12825 [29:06:29<18:55:34, 14.51s/it] 63%|██████▎   | 8130/12825 [29:06:42<18:13:10, 13.97s/it] 63%|██████▎   | 8131/12825 [29:06:54<17:41:03, 13.56s/it] 63%|██████▎   | 8132/12825 [29:07:07<17:17:13, 13.26s/it] 63%|██████▎   | 8133/12825 [29:07:20<17:00:50, 13.05s/it] 63%|██████▎   | 8134/12825 [29:07:32<16:49:53, 12.92s/it] 63%|██████▎   | 8135/12825 [29:07:45<16:41:29, 12.81s/it] 63%|██████▎   | 8136/12825 [29:07:57<16:35:43, 12.74s/it] 63%|██████▎   | 8137/12825 [29:08:10<16:31:27, 12.69s/it] 63%|██████▎   | 8138/12825 [29:08:23<16:34:21, 12.73s/it] 63%|██████▎   | 8139/12825 [29:08:35<16:31:22, 12.69s/it] 63%|██████▎   | 8140/12825 [29:08:48<16:28:11, 12.66s/it] 63%|██████▎   | 8141/12825 [29:09:00<16:26:26, 12.64s/it] 63%|██████▎   | 8142/12825 [29:09:13<16:25:16, 12.62s/it] 63%|██████▎   | 8143/12825 [29:09:26<16:23:36, 12.60s/it] 64%|██████▎   | 8144/12825 [29:09:38<16:22:44, 12.60s/it] 64%|██████▎   | 8145/12825 [29:09:51<16:21:25, 12.58s/it] 64%|██████▎   | 8146/12825 [29:10:03<16:21:46, 12.59s/it] 64%|██████▎   | 8147/12825 [29:10:16<16:21:50, 12.59s/it] 64%|██████▎   | 8148/12825 [29:10:29<16:21:49, 12.60s/it] 64%|██████▎   | 8149/12825 [29:10:41<16:21:38, 12.60s/it] 64%|██████▎   | 8150/12825 [29:10:54<16:21:26, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120444.58lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103677.69lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8125] due to args.save_total_limit
 64%|██████▎   | 8151/12825 [29:11:07<16:29:37, 12.70s/it] 64%|██████▎   | 8152/12825 [29:11:19<16:25:48, 12.66s/it] 64%|██████▎   | 8153/12825 [29:11:32<16:22:47, 12.62s/it] 64%|██████▎   | 8154/12825 [29:11:44<16:21:03, 12.60s/it] 64%|██████▎   | 8155/12825 [29:11:57<16:19:10, 12.58s/it] 64%|██████▎   | 8156/12825 [29:12:09<16:18:30, 12.57s/it] 64%|██████▎   | 8157/12825 [29:12:22<16:18:07, 12.57s/it] 64%|██████▎   | 8158/12825 [29:12:35<16:18:01, 12.57s/it] 64%|██████▎   | 8159/12825 [29:12:47<16:18:21, 12.58s/it] 64%|██████▎   | 8160/12825 [29:13:08<19:28:28, 15.03s/it] 64%|██████▎   | 8161/12825 [29:13:20<18:30:46, 14.29s/it] 64%|██████▎   | 8162/12825 [29:13:33<17:50:18, 13.77s/it] 64%|██████▎   | 8163/12825 [29:13:46<17:21:42, 13.41s/it] 64%|██████▎   | 8164/12825 [29:13:58<17:01:55, 13.15s/it] 64%|██████▎   | 8165/12825 [29:14:11<16:47:58, 12.98s/it] 64%|██████▎   | 8166/12825 [29:14:23<16:37:51, 12.85s/it] 64%|██████▎   | 8167/12825 [29:14:36<16:31:29, 12.77s/it] 64%|██████▎   | 8168/12825 [29:14:48<16:26:32, 12.71s/it] 64%|██████▎   | 8169/12825 [29:15:01<16:23:28, 12.67s/it] 64%|██████▎   | 8170/12825 [29:15:14<16:21:38, 12.65s/it] 64%|██████▎   | 8171/12825 [29:15:26<16:20:19, 12.64s/it] 64%|██████▎   | 8172/12825 [29:15:39<16:20:52, 12.65s/it] 64%|██████▎   | 8173/12825 [29:15:51<16:18:43, 12.62s/it] 64%|██████▎   | 8174/12825 [29:16:04<16:18:40, 12.63s/it] 64%|██████▎   | 8175/12825 [29:16:17<16:19:56, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120431.39lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103672.09lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-7725] due to args.save_total_limit
 64%|██████▍   | 8176/12825 [29:16:30<16:25:05, 12.71s/it] 64%|██████▍   | 8177/12825 [29:16:42<16:21:23, 12.67s/it] 64%|██████▍   | 8178/12825 [29:16:55<16:18:51, 12.64s/it] 64%|██████▍   | 8179/12825 [29:17:07<16:16:37, 12.61s/it] 64%|██████▍   | 8180/12825 [29:17:20<16:16:40, 12.62s/it] 64%|██████▍   | 8181/12825 [29:17:33<16:15:09, 12.60s/it] 64%|██████▍   | 8182/12825 [29:17:45<16:13:49, 12.58s/it] 64%|██████▍   | 8183/12825 [29:17:58<16:12:31, 12.57s/it] 64%|██████▍   | 8184/12825 [29:18:10<16:11:56, 12.57s/it] 64%|██████▍   | 8185/12825 [29:18:23<16:14:44, 12.60s/it] 64%|██████▍   | 8186/12825 [29:18:35<16:13:02, 12.59s/it] 64%|██████▍   | 8187/12825 [29:18:48<16:13:07, 12.59s/it] 64%|██████▍   | 8188/12825 [29:19:01<16:12:53, 12.59s/it] 64%|██████▍   | 8189/12825 [29:19:13<16:12:20, 12.58s/it] 64%|██████▍   | 8190/12825 [29:19:26<16:12:22, 12.59s/it] 64%|██████▍   | 8191/12825 [29:19:38<16:11:05, 12.57s/it] 64%|██████▍   | 8192/12825 [29:20:00<19:39:30, 15.28s/it] 64%|██████▍   | 8193/12825 [29:20:12<18:36:24, 14.46s/it] 64%|██████▍   | 8194/12825 [29:20:25<17:52:09, 13.89s/it] 64%|██████▍   | 8195/12825 [29:20:38<17:20:32, 13.48s/it] 64%|██████▍   | 8196/12825 [29:20:50<16:58:49, 13.21s/it] 64%|██████▍   | 8197/12825 [29:21:03<16:42:49, 13.00s/it] 64%|██████▍   | 8198/12825 [29:21:15<16:31:44, 12.86s/it] 64%|██████▍   | 8199/12825 [29:21:28<16:24:52, 12.77s/it] 64%|██████▍   | 8200/12825 [29:21:40<16:20:37, 12.72s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120507.38lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103723.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8150] due to args.save_total_limit
 64%|██████▍   | 8201/12825 [29:21:53<16:24:12, 12.77s/it] 64%|██████▍   | 8202/12825 [29:22:06<16:21:43, 12.74s/it] 64%|██████▍   | 8203/12825 [29:22:18<16:16:46, 12.68s/it] 64%|██████▍   | 8204/12825 [29:22:31<16:13:03, 12.63s/it] 64%|██████▍   | 8205/12825 [29:22:43<16:10:21, 12.60s/it] 64%|██████▍   | 8206/12825 [29:22:56<16:09:29, 12.59s/it] 64%|██████▍   | 8207/12825 [29:23:04<14:20:50, 11.18s/it] 64%|██████▍   | 8208/12825 [29:23:05<10:21:27,  8.08s/it] 64%|██████▍   | 8209/12825 [29:23:30<17:01:30, 13.28s/it] 64%|██████▍   | 8210/12825 [29:23:43<16:45:10, 13.07s/it] 64%|██████▍   | 8211/12825 [29:23:55<16:34:33, 12.93s/it] 64%|██████▍   | 8212/12825 [29:24:08<16:25:59, 12.82s/it] 64%|██████▍   | 8213/12825 [29:24:21<16:22:54, 12.79s/it] 64%|██████▍   | 8214/12825 [29:24:33<16:18:47, 12.74s/it] 64%|██████▍   | 8215/12825 [29:24:46<16:15:29, 12.70s/it] 64%|██████▍   | 8216/12825 [29:24:59<16:14:18, 12.68s/it] 64%|██████▍   | 8217/12825 [29:25:11<16:14:15, 12.69s/it] 64%|██████▍   | 8218/12825 [29:25:24<16:11:49, 12.66s/it] 64%|██████▍   | 8219/12825 [29:25:36<16:09:28, 12.63s/it] 64%|██████▍   | 8220/12825 [29:25:49<16:08:30, 12.62s/it] 64%|██████▍   | 8221/12825 [29:26:02<16:07:53, 12.61s/it] 64%|██████▍   | 8222/12825 [29:26:14<16:07:26, 12.61s/it] 64%|██████▍   | 8223/12825 [29:26:27<16:07:08, 12.61s/it] 64%|██████▍   | 8224/12825 [29:26:39<16:06:41, 12.61s/it] 64%|██████▍   | 8225/12825 [29:27:00<19:13:14, 15.04s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120509.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103679.11lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8200] due to args.save_total_limit
 64%|██████▍   | 8226/12825 [29:27:13<18:23:48, 14.40s/it] 64%|██████▍   | 8227/12825 [29:27:26<17:41:54, 13.86s/it] 64%|██████▍   | 8228/12825 [29:27:38<17:11:31, 13.46s/it] 64%|██████▍   | 8229/12825 [29:27:51<16:50:08, 13.19s/it] 64%|██████▍   | 8230/12825 [29:28:03<16:35:48, 13.00s/it] 64%|██████▍   | 8231/12825 [29:28:16<16:26:59, 12.89s/it] 64%|██████▍   | 8232/12825 [29:28:29<16:20:52, 12.81s/it] 64%|██████▍   | 8233/12825 [29:28:41<16:15:48, 12.75s/it] 64%|██████▍   | 8234/12825 [29:28:54<16:14:52, 12.74s/it] 64%|██████▍   | 8235/12825 [29:29:06<16:10:45, 12.69s/it] 64%|██████▍   | 8236/12825 [29:29:19<16:08:22, 12.66s/it] 64%|██████▍   | 8237/12825 [29:29:32<16:05:47, 12.63s/it] 64%|██████▍   | 8238/12825 [29:29:44<16:04:50, 12.62s/it] 64%|██████▍   | 8239/12825 [29:29:57<16:03:35, 12.61s/it] 64%|██████▍   | 8240/12825 [29:30:09<16:03:24, 12.61s/it] 64%|██████▍   | 8241/12825 [29:30:22<16:04:55, 12.63s/it] 64%|██████▍   | 8242/12825 [29:30:35<16:03:27, 12.61s/it] 64%|██████▍   | 8243/12825 [29:30:47<16:04:26, 12.63s/it] 64%|██████▍   | 8244/12825 [29:31:00<16:04:35, 12.63s/it] 64%|██████▍   | 8245/12825 [29:31:13<16:04:30, 12.64s/it] 64%|██████▍   | 8246/12825 [29:31:25<16:03:20, 12.62s/it] 64%|██████▍   | 8247/12825 [29:31:38<16:03:53, 12.63s/it] 64%|██████▍   | 8248/12825 [29:31:50<16:02:27, 12.62s/it] 64%|██████▍   | 8249/12825 [29:32:03<16:01:37, 12.61s/it] 64%|██████▍   | 8250/12825 [29:32:16<16:01:00, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120534.06lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103578.60lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8225] due to args.save_total_limit
 64%|██████▍   | 8251/12825 [29:32:28<16:08:10, 12.70s/it] 64%|██████▍   | 8252/12825 [29:32:41<16:06:08, 12.68s/it] 64%|██████▍   | 8253/12825 [29:32:54<16:03:03, 12.64s/it] 64%|██████▍   | 8254/12825 [29:33:06<16:01:52, 12.63s/it] 64%|██████▍   | 8255/12825 [29:33:19<16:02:42, 12.64s/it] 64%|██████▍   | 8256/12825 [29:33:32<16:02:03, 12.63s/it] 64%|██████▍   | 8257/12825 [29:33:44<16:00:12, 12.61s/it] 64%|██████▍   | 8258/12825 [29:34:06<19:22:57, 15.28s/it] 64%|██████▍   | 8259/12825 [29:34:18<18:23:29, 14.50s/it] 64%|██████▍   | 8260/12825 [29:34:31<17:40:23, 13.94s/it] 64%|██████▍   | 8261/12825 [29:34:44<17:09:21, 13.53s/it] 64%|██████▍   | 8262/12825 [29:34:56<16:47:17, 13.25s/it] 64%|██████▍   | 8263/12825 [29:35:09<16:31:15, 13.04s/it] 64%|██████▍   | 8264/12825 [29:35:21<16:21:05, 12.91s/it] 64%|██████▍   | 8265/12825 [29:35:34<16:14:16, 12.82s/it] 64%|██████▍   | 8266/12825 [29:35:46<16:09:06, 12.75s/it] 64%|██████▍   | 8267/12825 [29:35:59<16:05:03, 12.70s/it] 64%|██████▍   | 8268/12825 [29:36:12<16:02:17, 12.67s/it] 64%|██████▍   | 8269/12825 [29:36:24<16:00:41, 12.65s/it] 64%|██████▍   | 8270/12825 [29:36:37<15:59:17, 12.64s/it] 64%|██████▍   | 8271/12825 [29:36:49<15:58:14, 12.63s/it] 64%|██████▍   | 8272/12825 [29:37:02<15:56:47, 12.61s/it] 65%|██████▍   | 8273/12825 [29:37:15<15:56:32, 12.61s/it] 65%|██████▍   | 8274/12825 [29:37:27<15:55:05, 12.59s/it] 65%|██████▍   | 8275/12825 [29:37:40<15:55:20, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 118045.22lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101889.23lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8250] due to args.save_total_limit
 65%|██████▍   | 8276/12825 [29:37:53<16:02:16, 12.69s/it] 65%|██████▍   | 8277/12825 [29:38:05<16:00:11, 12.67s/it] 65%|██████▍   | 8278/12825 [29:38:18<15:57:05, 12.63s/it] 65%|██████▍   | 8279/12825 [29:38:30<15:55:27, 12.61s/it] 65%|██████▍   | 8280/12825 [29:38:43<15:55:14, 12.61s/it] 65%|██████▍   | 8281/12825 [29:38:56<15:55:19, 12.61s/it] 65%|██████▍   | 8282/12825 [29:39:08<15:55:29, 12.62s/it] 65%|██████▍   | 8283/12825 [29:39:21<15:55:01, 12.62s/it] 65%|██████▍   | 8284/12825 [29:39:33<15:53:51, 12.60s/it] 65%|██████▍   | 8285/12825 [29:39:46<15:52:52, 12.59s/it] 65%|██████▍   | 8286/12825 [29:39:59<15:52:33, 12.59s/it] 65%|██████▍   | 8287/12825 [29:40:11<15:53:07, 12.60s/it] 65%|██████▍   | 8288/12825 [29:40:24<15:52:39, 12.60s/it] 65%|██████▍   | 8289/12825 [29:40:36<15:52:11, 12.60s/it] 65%|██████▍   | 8290/12825 [29:40:58<19:16:06, 15.30s/it] 65%|██████▍   | 8291/12825 [29:41:11<18:14:20, 14.48s/it] 65%|██████▍   | 8292/12825 [29:41:23<17:31:23, 13.92s/it] 65%|██████▍   | 8293/12825 [29:41:36<17:01:49, 13.53s/it] 65%|██████▍   | 8294/12825 [29:41:48<16:40:42, 13.25s/it] 65%|██████▍   | 8295/12825 [29:42:01<16:24:53, 13.04s/it] 65%|██████▍   | 8296/12825 [29:42:14<16:15:29, 12.92s/it] 65%|██████▍   | 8297/12825 [29:42:26<16:06:59, 12.81s/it] 65%|██████▍   | 8298/12825 [29:42:39<16:01:17, 12.74s/it] 65%|██████▍   | 8299/12825 [29:42:52<16:01:41, 12.75s/it] 65%|██████▍   | 8300/12825 [29:43:04<15:58:24, 12.71s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120488.40lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103718.62lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8275] due to args.save_total_limit
 65%|██████▍   | 8301/12825 [29:43:17<16:02:43, 12.77s/it] 65%|██████▍   | 8302/12825 [29:43:30<15:57:55, 12.71s/it] 65%|██████▍   | 8303/12825 [29:43:42<15:54:29, 12.66s/it] 65%|██████▍   | 8304/12825 [29:43:55<15:51:22, 12.63s/it] 65%|██████▍   | 8305/12825 [29:44:07<15:52:34, 12.64s/it] 65%|██████▍   | 8306/12825 [29:44:20<15:50:20, 12.62s/it] 65%|██████▍   | 8307/12825 [29:44:33<15:49:14, 12.61s/it] 65%|██████▍   | 8308/12825 [29:44:45<15:48:34, 12.60s/it] 65%|██████▍   | 8309/12825 [29:44:58<15:47:18, 12.59s/it] 65%|██████▍   | 8310/12825 [29:45:10<15:46:08, 12.57s/it] 65%|██████▍   | 8311/12825 [29:45:23<15:46:42, 12.58s/it] 65%|██████▍   | 8312/12825 [29:45:35<15:45:51, 12.58s/it] 65%|██████▍   | 8313/12825 [29:45:48<15:44:53, 12.57s/it] 65%|██████▍   | 8314/12825 [29:46:01<15:45:00, 12.57s/it] 65%|██████▍   | 8315/12825 [29:46:13<15:45:42, 12.58s/it] 65%|██████▍   | 8316/12825 [29:46:26<15:46:01, 12.59s/it] 65%|██████▍   | 8317/12825 [29:46:38<15:45:46, 12.59s/it] 65%|██████▍   | 8318/12825 [29:46:51<15:44:37, 12.58s/it] 65%|██████▍   | 8319/12825 [29:47:03<15:45:15, 12.59s/it] 65%|██████▍   | 8320/12825 [29:47:16<15:44:59, 12.59s/it] 65%|██████▍   | 8321/12825 [29:47:29<15:44:33, 12.58s/it] 65%|██████▍   | 8322/12825 [29:47:50<19:02:04, 15.22s/it] 65%|██████▍   | 8323/12825 [29:48:03<18:04:02, 14.45s/it] 65%|██████▍   | 8324/12825 [29:48:15<17:22:23, 13.90s/it] 65%|██████▍   | 8325/12825 [29:48:28<16:52:12, 13.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120486.74lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103718.24lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8300] due to args.save_total_limit
 65%|██████▍   | 8326/12825 [29:48:41<16:39:05, 13.32s/it] 65%|██████▍   | 8327/12825 [29:48:53<16:22:41, 13.11s/it] 65%|██████▍   | 8328/12825 [29:49:06<16:10:19, 12.95s/it] 65%|██████▍   | 8329/12825 [29:49:19<16:04:16, 12.87s/it] 65%|██████▍   | 8330/12825 [29:49:31<15:58:09, 12.79s/it] 65%|██████▍   | 8331/12825 [29:49:44<15:52:57, 12.72s/it] 65%|██████▍   | 8332/12825 [29:49:56<15:49:33, 12.68s/it] 65%|██████▍   | 8333/12825 [29:50:09<15:46:52, 12.65s/it] 65%|██████▍   | 8334/12825 [29:50:22<15:48:49, 12.68s/it] 65%|██████▍   | 8335/12825 [29:50:34<15:46:59, 12.65s/it] 65%|██████▍   | 8336/12825 [29:50:47<15:45:27, 12.64s/it] 65%|██████▌   | 8337/12825 [29:51:00<15:47:24, 12.67s/it] 65%|██████▌   | 8338/12825 [29:51:12<15:51:18, 12.72s/it] 65%|██████▌   | 8339/12825 [29:51:25<15:49:05, 12.69s/it] 65%|██████▌   | 8340/12825 [29:51:38<15:47:12, 12.67s/it] 65%|██████▌   | 8341/12825 [29:51:50<15:45:24, 12.65s/it] 65%|██████▌   | 8342/12825 [29:52:03<15:46:21, 12.67s/it] 65%|██████▌   | 8343/12825 [29:52:16<15:44:15, 12.64s/it] 65%|██████▌   | 8344/12825 [29:52:28<15:43:11, 12.63s/it] 65%|██████▌   | 8345/12825 [29:52:41<15:42:12, 12.62s/it] 65%|██████▌   | 8346/12825 [29:52:53<15:41:23, 12.61s/it] 65%|██████▌   | 8347/12825 [29:53:06<15:41:21, 12.61s/it] 65%|██████▌   | 8348/12825 [29:53:19<15:41:01, 12.61s/it] 65%|██████▌   | 8349/12825 [29:53:31<15:40:54, 12.61s/it] 65%|██████▌   | 8350/12825 [29:53:44<15:40:23, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120392.34lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103743.89lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8325] due to args.save_total_limit
 65%|██████▌   | 8351/12825 [29:53:57<15:47:29, 12.71s/it] 65%|██████▌   | 8352/12825 [29:54:09<15:45:12, 12.68s/it] 65%|██████▌   | 8353/12825 [29:54:22<15:45:05, 12.68s/it] 65%|██████▌   | 8354/12825 [29:54:35<15:45:35, 12.69s/it] 65%|██████▌   | 8355/12825 [29:54:56<18:54:05, 15.22s/it] 65%|██████▌   | 8356/12825 [29:55:09<17:55:29, 14.44s/it] 65%|██████▌   | 8357/12825 [29:55:21<17:13:37, 13.88s/it] 65%|██████▌   | 8358/12825 [29:55:34<16:45:03, 13.50s/it] 65%|██████▌   | 8359/12825 [29:55:46<16:24:35, 13.23s/it] 65%|██████▌   | 8360/12825 [29:55:59<16:11:02, 13.05s/it] 65%|██████▌   | 8361/12825 [29:56:11<16:00:11, 12.91s/it] 65%|██████▌   | 8362/12825 [29:56:24<15:56:52, 12.86s/it] 65%|██████▌   | 8363/12825 [29:56:37<15:51:33, 12.80s/it] 65%|██████▌   | 8364/12825 [29:56:50<15:47:18, 12.74s/it] 65%|██████▌   | 8365/12825 [29:57:02<15:50:58, 12.79s/it] 65%|██████▌   | 8366/12825 [29:57:15<15:51:38, 12.81s/it] 65%|██████▌   | 8367/12825 [29:57:28<15:47:07, 12.75s/it] 65%|██████▌   | 8368/12825 [29:57:40<15:42:49, 12.69s/it] 65%|██████▌   | 8369/12825 [29:57:53<15:42:59, 12.70s/it] 65%|██████▌   | 8370/12825 [29:58:06<15:44:12, 12.72s/it] 65%|██████▌   | 8371/12825 [29:58:19<15:41:58, 12.69s/it] 65%|██████▌   | 8372/12825 [29:58:31<15:38:57, 12.65s/it] 65%|██████▌   | 8373/12825 [29:58:44<15:38:29, 12.65s/it] 65%|██████▌   | 8374/12825 [29:58:56<15:40:42, 12.68s/it] 65%|██████▌   | 8375/12825 [29:59:09<15:38:40, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120480.84lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103678.45lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8350] due to args.save_total_limit
 65%|██████▌   | 8376/12825 [29:59:22<15:44:30, 12.74s/it] 65%|██████▌   | 8377/12825 [29:59:35<15:42:06, 12.71s/it] 65%|██████▌   | 8378/12825 [29:59:47<15:41:25, 12.70s/it] 65%|██████▌   | 8379/12825 [30:00:00<15:38:30, 12.67s/it] 65%|██████▌   | 8380/12825 [30:00:13<15:38:58, 12.67s/it] 65%|██████▌   | 8381/12825 [30:00:25<15:37:20, 12.66s/it] 65%|██████▌   | 8382/12825 [30:00:38<15:36:09, 12.64s/it] 65%|██████▌   | 8383/12825 [30:00:50<15:34:33, 12.62s/it] 65%|██████▌   | 8384/12825 [30:01:03<15:34:49, 12.63s/it] 65%|██████▌   | 8385/12825 [30:01:16<15:34:20, 12.63s/it] 65%|██████▌   | 8386/12825 [30:01:28<15:33:35, 12.62s/it] 65%|██████▌   | 8387/12825 [30:01:49<18:31:31, 15.03s/it] 65%|██████▌   | 8388/12825 [30:02:02<17:39:18, 14.32s/it] 65%|██████▌   | 8389/12825 [30:02:14<17:01:19, 13.81s/it] 65%|██████▌   | 8390/12825 [30:02:27<16:35:06, 13.46s/it] 65%|██████▌   | 8391/12825 [30:02:39<16:15:36, 13.20s/it] 65%|██████▌   | 8392/12825 [30:02:52<16:02:09, 13.02s/it] 65%|██████▌   | 8393/12825 [30:03:05<15:53:52, 12.91s/it] 65%|██████▌   | 8394/12825 [30:03:17<15:47:27, 12.83s/it] 65%|██████▌   | 8395/12825 [30:03:30<15:42:18, 12.76s/it] 65%|██████▌   | 8396/12825 [30:03:43<15:39:21, 12.73s/it] 65%|██████▌   | 8397/12825 [30:03:55<15:37:00, 12.70s/it] 65%|██████▌   | 8398/12825 [30:04:08<15:40:04, 12.74s/it] 65%|██████▌   | 8399/12825 [30:04:21<15:40:37, 12.75s/it] 65%|██████▌   | 8400/12825 [30:04:34<15:38:17, 12.72s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120483.02lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103675.32lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8375] due to args.save_total_limit
 66%|██████▌   | 8401/12825 [30:04:46<15:42:24, 12.78s/it] 66%|██████▌   | 8402/12825 [30:04:59<15:38:12, 12.73s/it] 66%|██████▌   | 8403/12825 [30:05:12<15:34:45, 12.68s/it] 66%|██████▌   | 8404/12825 [30:05:24<15:34:40, 12.68s/it] 66%|██████▌   | 8405/12825 [30:05:37<15:32:38, 12.66s/it] 66%|██████▌   | 8406/12825 [30:05:50<15:31:36, 12.65s/it] 66%|██████▌   | 8407/12825 [30:06:02<15:31:06, 12.65s/it] 66%|██████▌   | 8408/12825 [30:06:15<15:29:08, 12.62s/it] 66%|██████▌   | 8409/12825 [30:06:27<15:30:17, 12.64s/it] 66%|██████▌   | 8410/12825 [30:06:40<15:28:40, 12.62s/it] 66%|██████▌   | 8411/12825 [30:06:53<15:28:14, 12.62s/it] 66%|██████▌   | 8412/12825 [30:07:05<15:28:03, 12.62s/it] 66%|██████▌   | 8413/12825 [30:07:18<15:27:27, 12.61s/it] 66%|██████▌   | 8414/12825 [30:07:30<15:27:49, 12.62s/it] 66%|██████▌   | 8415/12825 [30:07:43<15:26:20, 12.60s/it] 66%|██████▌   | 8416/12825 [30:07:56<15:25:51, 12.60s/it] 66%|██████▌   | 8417/12825 [30:08:08<15:25:36, 12.60s/it] 66%|██████▌   | 8418/12825 [30:08:21<15:26:07, 12.61s/it] 66%|██████▌   | 8419/12825 [30:08:41<18:21:55, 15.01s/it] 66%|██████▌   | 8420/12825 [30:08:54<17:27:33, 14.27s/it] 66%|██████▌   | 8421/12825 [30:09:07<16:50:21, 13.77s/it] 66%|██████▌   | 8422/12825 [30:09:19<16:25:03, 13.42s/it] 66%|██████▌   | 8423/12825 [30:09:32<16:07:34, 13.19s/it] 66%|██████▌   | 8424/12825 [30:09:44<15:54:27, 13.01s/it] 66%|██████▌   | 8425/12825 [30:09:57<15:45:45, 12.90s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120459.18lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103689.75lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8400] due to args.save_total_limit
 66%|██████▌   | 8426/12825 [30:10:10<15:47:06, 12.92s/it] 66%|██████▌   | 8427/12825 [30:10:23<15:39:38, 12.82s/it] 66%|██████▌   | 8428/12825 [30:10:35<15:34:46, 12.76s/it] 66%|██████▌   | 8429/12825 [30:10:48<15:30:17, 12.70s/it] 66%|██████▌   | 8430/12825 [30:11:00<15:28:30, 12.68s/it] 66%|██████▌   | 8431/12825 [30:11:13<15:26:21, 12.65s/it] 66%|██████▌   | 8432/12825 [30:11:26<15:25:44, 12.64s/it] 66%|██████▌   | 8433/12825 [30:11:38<15:24:22, 12.63s/it] 66%|██████▌   | 8434/12825 [30:11:51<15:23:54, 12.62s/it] 66%|██████▌   | 8435/12825 [30:12:03<15:22:49, 12.61s/it] 66%|██████▌   | 8436/12825 [30:12:16<15:22:20, 12.61s/it] 66%|██████▌   | 8437/12825 [30:12:29<15:21:46, 12.60s/it] 66%|██████▌   | 8438/12825 [30:12:41<15:21:52, 12.61s/it] 66%|██████▌   | 8439/12825 [30:12:54<15:23:12, 12.63s/it] 66%|██████▌   | 8440/12825 [30:13:07<15:23:05, 12.63s/it] 66%|██████▌   | 8441/12825 [30:13:19<15:22:22, 12.62s/it] 66%|██████▌   | 8442/12825 [30:13:32<15:21:43, 12.62s/it] 66%|██████▌   | 8443/12825 [30:13:44<15:21:05, 12.61s/it] 66%|██████▌   | 8444/12825 [30:13:57<15:21:26, 12.62s/it] 66%|██████▌   | 8445/12825 [30:14:10<15:20:32, 12.61s/it] 66%|██████▌   | 8446/12825 [30:14:22<15:20:08, 12.61s/it] 66%|██████▌   | 8447/12825 [30:14:35<15:20:15, 12.61s/it] 66%|██████▌   | 8448/12825 [30:14:47<15:20:30, 12.62s/it] 66%|██████▌   | 8449/12825 [30:15:00<15:20:28, 12.62s/it] 66%|██████▌   | 8450/12825 [30:15:13<15:19:49, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120465.08lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103668.67lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8425] due to args.save_total_limit
 66%|██████▌   | 8451/12825 [30:15:26<15:27:22, 12.72s/it] 66%|██████▌   | 8452/12825 [30:15:47<18:35:08, 15.30s/it] 66%|██████▌   | 8453/12825 [30:16:00<17:36:14, 14.50s/it] 66%|██████▌   | 8454/12825 [30:16:12<16:56:30, 13.95s/it] 66%|██████▌   | 8455/12825 [30:16:25<16:27:06, 13.55s/it] 66%|██████▌   | 8456/12825 [30:16:37<16:05:33, 13.26s/it] 66%|██████▌   | 8457/12825 [30:16:50<15:51:02, 13.06s/it] 66%|██████▌   | 8458/12825 [30:17:03<15:41:23, 12.93s/it] 66%|██████▌   | 8459/12825 [30:17:15<15:33:41, 12.83s/it] 66%|██████▌   | 8460/12825 [30:17:28<15:28:30, 12.76s/it] 66%|██████▌   | 8461/12825 [30:17:40<15:24:17, 12.71s/it] 66%|██████▌   | 8462/12825 [30:17:53<15:21:21, 12.67s/it] 66%|██████▌   | 8463/12825 [30:18:06<15:19:32, 12.65s/it] 66%|██████▌   | 8464/12825 [30:18:18<15:18:41, 12.64s/it] 66%|██████▌   | 8465/12825 [30:18:31<15:18:10, 12.64s/it] 66%|██████▌   | 8466/12825 [30:18:44<15:17:01, 12.62s/it] 66%|██████▌   | 8467/12825 [30:18:56<15:17:45, 12.64s/it] 66%|██████▌   | 8468/12825 [30:19:09<15:16:49, 12.63s/it] 66%|██████▌   | 8469/12825 [30:19:21<15:15:25, 12.61s/it] 66%|██████▌   | 8470/12825 [30:19:34<15:14:45, 12.60s/it] 66%|██████▌   | 8471/12825 [30:19:47<15:16:34, 12.63s/it] 66%|██████▌   | 8472/12825 [30:19:59<15:16:09, 12.63s/it] 66%|██████▌   | 8473/12825 [30:20:12<15:15:58, 12.63s/it] 66%|██████▌   | 8474/12825 [30:20:24<15:14:23, 12.61s/it] 66%|██████▌   | 8475/12825 [30:20:37<15:13:25, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120408.34lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103731.35lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8450] due to args.save_total_limit
 66%|██████▌   | 8476/12825 [30:20:50<15:20:18, 12.70s/it] 66%|██████▌   | 8477/12825 [30:21:03<15:17:22, 12.66s/it] 66%|██████▌   | 8478/12825 [30:21:15<15:15:32, 12.64s/it] 66%|██████▌   | 8479/12825 [30:21:28<15:14:45, 12.63s/it] 66%|██████▌   | 8480/12825 [30:21:40<15:12:56, 12.61s/it] 66%|██████▌   | 8481/12825 [30:21:53<15:12:12, 12.60s/it] 66%|██████▌   | 8482/12825 [30:22:05<15:11:39, 12.59s/it] 66%|██████▌   | 8483/12825 [30:22:18<15:10:37, 12.58s/it] 66%|██████▌   | 8484/12825 [30:22:40<18:41:12, 15.50s/it] 66%|██████▌   | 8485/12825 [30:22:53<17:37:13, 14.62s/it] 66%|██████▌   | 8486/12825 [30:23:05<16:52:03, 13.99s/it] 66%|██████▌   | 8487/12825 [30:23:18<16:20:48, 13.57s/it] 66%|██████▌   | 8488/12825 [30:23:31<15:59:24, 13.27s/it] 66%|██████▌   | 8489/12825 [30:23:43<15:44:09, 13.06s/it] 66%|██████▌   | 8490/12825 [30:23:56<15:33:17, 12.92s/it] 66%|██████▌   | 8491/12825 [30:24:08<15:25:39, 12.81s/it] 66%|██████▌   | 8492/12825 [30:24:21<15:23:03, 12.78s/it] 66%|██████▌   | 8493/12825 [30:24:34<15:18:33, 12.72s/it] 66%|██████▌   | 8494/12825 [30:24:46<15:15:35, 12.68s/it] 66%|██████▌   | 8495/12825 [30:24:59<15:12:52, 12.65s/it] 66%|██████▌   | 8496/12825 [30:25:11<15:11:22, 12.63s/it] 66%|██████▋   | 8497/12825 [30:25:24<15:10:43, 12.63s/it] 66%|██████▋   | 8498/12825 [30:25:37<15:09:44, 12.61s/it] 66%|██████▋   | 8499/12825 [30:25:49<15:08:40, 12.60s/it] 66%|██████▋   | 8500/12825 [30:26:02<15:07:51, 12.59s/it]                                                           66%|██████▋   | 8500/12825 [30:26:02<15:07:51, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120384.53lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103714.34lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8475] due to args.save_total_limit
 66%|██████▋   | 8501/12825 [30:26:15<15:13:46, 12.68s/it] 66%|██████▋   | 8502/12825 [30:26:27<15:11:51, 12.66s/it] 66%|██████▋   | 8503/12825 [30:26:40<15:11:33, 12.65s/it] 66%|██████▋   | 8504/12825 [30:26:52<15:09:39, 12.63s/it] 66%|██████▋   | 8505/12825 [30:27:05<15:08:06, 12.61s/it] 66%|██████▋   | 8506/12825 [30:27:18<15:07:35, 12.61s/it] 66%|██████▋   | 8507/12825 [30:27:30<15:06:09, 12.59s/it] 66%|██████▋   | 8508/12825 [30:27:43<15:06:08, 12.59s/it] 66%|██████▋   | 8509/12825 [30:27:55<15:05:21, 12.59s/it] 66%|██████▋   | 8510/12825 [30:28:08<15:04:29, 12.58s/it] 66%|██████▋   | 8511/12825 [30:28:20<15:04:13, 12.58s/it] 66%|██████▋   | 8512/12825 [30:28:33<15:05:53, 12.60s/it] 66%|██████▋   | 8513/12825 [30:28:46<15:06:07, 12.61s/it] 66%|██████▋   | 8514/12825 [30:28:58<15:05:30, 12.60s/it] 66%|██████▋   | 8515/12825 [30:29:11<15:06:02, 12.61s/it] 66%|██████▋   | 8516/12825 [30:29:24<15:07:21, 12.63s/it] 66%|██████▋   | 8517/12825 [30:29:45<18:18:42, 15.30s/it] 66%|██████▋   | 8518/12825 [30:29:58<17:19:58, 14.49s/it] 66%|██████▋   | 8519/12825 [30:30:10<16:39:06, 13.92s/it] 66%|██████▋   | 8520/12825 [30:30:23<16:11:26, 13.54s/it] 66%|██████▋   | 8521/12825 [30:30:36<15:51:12, 13.26s/it] 66%|██████▋   | 8522/12825 [30:30:48<15:36:58, 13.07s/it] 66%|██████▋   | 8523/12825 [30:31:01<15:29:07, 12.96s/it] 66%|██████▋   | 8524/12825 [30:31:14<15:22:00, 12.86s/it] 66%|██████▋   | 8525/12825 [30:31:26<15:15:47, 12.78s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120478.15lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103151.68lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8500] due to args.save_total_limit
 66%|██████▋   | 8526/12825 [30:31:39<15:19:00, 12.83s/it] 66%|██████▋   | 8527/12825 [30:31:52<15:15:37, 12.78s/it] 66%|██████▋   | 8528/12825 [30:32:04<15:11:21, 12.73s/it] 67%|██████▋   | 8529/12825 [30:32:17<15:08:00, 12.68s/it] 67%|██████▋   | 8530/12825 [30:32:29<15:06:05, 12.66s/it] 67%|██████▋   | 8531/12825 [30:32:42<15:04:46, 12.64s/it] 67%|██████▋   | 8532/12825 [30:32:55<15:03:22, 12.63s/it] 67%|██████▋   | 8533/12825 [30:33:07<15:02:27, 12.62s/it] 67%|██████▋   | 8534/12825 [30:33:20<15:02:13, 12.62s/it] 67%|██████▋   | 8535/12825 [30:33:33<15:02:25, 12.62s/it] 67%|██████▋   | 8536/12825 [30:33:45<15:01:55, 12.62s/it] 67%|██████▋   | 8537/12825 [30:33:58<15:01:37, 12.62s/it] 67%|██████▋   | 8538/12825 [30:34:10<15:00:30, 12.60s/it] 67%|██████▋   | 8539/12825 [30:34:23<15:00:25, 12.61s/it] 67%|██████▋   | 8540/12825 [30:34:36<15:00:17, 12.61s/it] 67%|██████▋   | 8541/12825 [30:34:48<15:00:03, 12.61s/it] 67%|██████▋   | 8542/12825 [30:35:01<14:59:07, 12.60s/it] 67%|██████▋   | 8543/12825 [30:35:13<14:58:53, 12.60s/it] 67%|██████▋   | 8544/12825 [30:35:26<14:59:05, 12.60s/it] 67%|██████▋   | 8545/12825 [30:35:39<14:58:41, 12.60s/it] 67%|██████▋   | 8546/12825 [30:35:51<14:57:59, 12.59s/it] 67%|██████▋   | 8547/12825 [30:36:04<14:58:28, 12.60s/it] 67%|██████▋   | 8548/12825 [30:36:16<14:58:14, 12.60s/it] 67%|██████▋   | 8549/12825 [30:36:37<17:42:37, 14.91s/it] 67%|██████▋   | 8550/12825 [30:36:49<16:53:08, 14.22s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120546.25lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 100106.17lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8525] due to args.save_total_limit
 67%|██████▋   | 8551/12825 [30:37:02<16:29:40, 13.89s/it] 67%|██████▋   | 8552/12825 [30:37:15<16:01:42, 13.50s/it] 67%|██████▋   | 8553/12825 [30:37:28<15:41:19, 13.22s/it] 67%|██████▋   | 8554/12825 [30:37:40<15:27:41, 13.03s/it] 67%|██████▋   | 8555/12825 [30:37:53<15:18:47, 12.91s/it] 67%|██████▋   | 8556/12825 [30:38:05<15:11:57, 12.82s/it] 67%|██████▋   | 8557/12825 [30:38:18<15:07:28, 12.76s/it] 67%|██████▋   | 8558/12825 [30:38:31<15:04:29, 12.72s/it] 67%|██████▋   | 8559/12825 [30:38:43<15:01:48, 12.68s/it] 67%|██████▋   | 8560/12825 [30:38:56<15:00:20, 12.67s/it] 67%|██████▋   | 8561/12825 [30:39:08<14:59:29, 12.66s/it] 67%|██████▋   | 8562/12825 [30:39:21<14:58:25, 12.64s/it] 67%|██████▋   | 8563/12825 [30:39:34<14:57:26, 12.63s/it] 67%|██████▋   | 8564/12825 [30:39:46<14:56:14, 12.62s/it] 67%|██████▋   | 8565/12825 [30:39:59<14:55:49, 12.62s/it] 67%|██████▋   | 8566/12825 [30:40:11<14:55:59, 12.62s/it] 67%|██████▋   | 8567/12825 [30:40:24<14:55:27, 12.62s/it] 67%|██████▋   | 8568/12825 [30:40:37<14:56:22, 12.63s/it] 67%|██████▋   | 8569/12825 [30:40:49<14:55:46, 12.63s/it] 67%|██████▋   | 8570/12825 [30:41:02<14:54:36, 12.61s/it] 67%|██████▋   | 8571/12825 [30:41:15<14:53:46, 12.61s/it] 67%|██████▋   | 8572/12825 [30:41:27<14:53:44, 12.61s/it] 67%|██████▋   | 8573/12825 [30:41:40<14:53:16, 12.60s/it] 67%|██████▋   | 8574/12825 [30:41:52<14:52:47, 12.60s/it] 67%|██████▋   | 8575/12825 [30:42:05<14:53:04, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120502.76lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103778.50lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8550] due to args.save_total_limit
 67%|██████▋   | 8576/12825 [30:42:18<14:59:26, 12.70s/it] 67%|██████▋   | 8577/12825 [30:42:30<14:56:26, 12.66s/it] 67%|██████▋   | 8578/12825 [30:42:43<14:54:36, 12.64s/it] 67%|██████▋   | 8579/12825 [30:42:56<14:53:11, 12.62s/it] 67%|██████▋   | 8580/12825 [30:43:08<14:52:04, 12.61s/it] 67%|██████▋   | 8581/12825 [30:43:28<17:33:45, 14.90s/it] 67%|██████▋   | 8582/12825 [30:43:41<16:45:07, 14.21s/it] 67%|██████▋   | 8583/12825 [30:43:54<16:11:09, 13.74s/it] 67%|██████▋   | 8584/12825 [30:44:06<15:47:02, 13.40s/it] 67%|██████▋   | 8585/12825 [30:44:19<15:30:35, 13.17s/it] 67%|██████▋   | 8586/12825 [30:44:32<15:19:01, 13.01s/it] 67%|██████▋   | 8587/12825 [30:44:44<15:09:54, 12.88s/it] 67%|██████▋   | 8588/12825 [30:44:57<15:03:49, 12.80s/it] 67%|██████▋   | 8589/12825 [30:45:09<14:59:09, 12.74s/it] 67%|██████▋   | 8590/12825 [30:45:22<14:56:11, 12.70s/it] 67%|██████▋   | 8591/12825 [30:45:35<14:54:18, 12.67s/it] 67%|██████▋   | 8592/12825 [30:45:47<14:53:05, 12.66s/it] 67%|██████▋   | 8593/12825 [30:46:00<14:52:23, 12.65s/it] 67%|██████▋   | 8594/12825 [30:46:12<14:51:22, 12.64s/it] 67%|██████▋   | 8595/12825 [30:46:25<14:50:23, 12.63s/it] 67%|██████▋   | 8596/12825 [30:46:38<14:50:15, 12.63s/it] 67%|██████▋   | 8597/12825 [30:46:50<14:49:15, 12.62s/it] 67%|██████▋   | 8598/12825 [30:47:03<14:48:22, 12.61s/it] 67%|██████▋   | 8599/12825 [30:47:15<14:47:51, 12.61s/it] 67%|██████▋   | 8600/12825 [30:47:28<14:47:34, 12.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120335.92lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103689.75lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8175] due to args.save_total_limit
 67%|██████▋   | 8601/12825 [30:47:41<14:53:40, 12.69s/it] 67%|██████▋   | 8602/12825 [30:47:54<14:50:39, 12.65s/it] 67%|██████▋   | 8603/12825 [30:48:06<14:48:49, 12.63s/it] 67%|██████▋   | 8604/12825 [30:48:19<14:48:01, 12.62s/it] 67%|██████▋   | 8605/12825 [30:48:31<14:48:08, 12.63s/it] 67%|██████▋   | 8606/12825 [30:48:44<14:47:43, 12.62s/it] 67%|██████▋   | 8607/12825 [30:48:57<14:46:41, 12.61s/it] 67%|██████▋   | 8608/12825 [30:49:09<14:45:46, 12.60s/it] 67%|██████▋   | 8609/12825 [30:49:22<14:46:19, 12.61s/it] 67%|██████▋   | 8610/12825 [30:49:34<14:45:41, 12.61s/it] 67%|██████▋   | 8611/12825 [30:49:47<14:45:18, 12.61s/it] 67%|██████▋   | 8612/12825 [30:50:00<14:45:35, 12.61s/it] 67%|██████▋   | 8613/12825 [30:50:12<14:45:03, 12.61s/it] 67%|██████▋   | 8614/12825 [30:50:32<17:23:05, 14.86s/it] 67%|██████▋   | 8615/12825 [30:50:45<16:35:05, 14.18s/it] 67%|██████▋   | 8616/12825 [30:50:58<16:01:57, 13.71s/it] 67%|██████▋   | 8617/12825 [30:51:10<15:38:23, 13.38s/it] 67%|██████▋   | 8618/12825 [30:51:23<15:22:07, 13.15s/it] 67%|██████▋   | 8619/12825 [30:51:35<15:10:40, 12.99s/it] 67%|██████▋   | 8620/12825 [30:51:48<15:02:49, 12.88s/it] 67%|██████▋   | 8621/12825 [30:52:01<14:56:58, 12.80s/it] 67%|██████▋   | 8622/12825 [30:52:13<14:55:31, 12.78s/it] 67%|██████▋   | 8623/12825 [30:52:26<14:52:01, 12.74s/it] 67%|██████▋   | 8624/12825 [30:52:39<14:48:34, 12.69s/it] 67%|██████▋   | 8625/12825 [30:52:51<14:46:18, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120612.88lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103860.54lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8575] due to args.save_total_limit
 67%|██████▋   | 8626/12825 [30:53:04<14:51:54, 12.74s/it] 67%|██████▋   | 8627/12825 [30:53:17<14:49:12, 12.71s/it] 67%|██████▋   | 8628/12825 [30:53:29<14:46:57, 12.68s/it] 67%|██████▋   | 8629/12825 [30:53:42<14:46:31, 12.68s/it] 67%|██████▋   | 8630/12825 [30:53:55<14:44:55, 12.66s/it] 67%|██████▋   | 8631/12825 [30:54:07<14:44:03, 12.65s/it] 67%|██████▋   | 8632/12825 [30:54:20<14:42:50, 12.63s/it] 67%|██████▋   | 8633/12825 [30:54:32<14:42:20, 12.63s/it] 67%|██████▋   | 8634/12825 [30:54:45<14:41:59, 12.63s/it] 67%|██████▋   | 8635/12825 [30:54:58<14:42:21, 12.64s/it] 67%|██████▋   | 8636/12825 [30:55:10<14:43:01, 12.65s/it] 67%|██████▋   | 8637/12825 [30:55:23<14:41:45, 12.63s/it] 67%|██████▋   | 8638/12825 [30:55:36<14:40:54, 12.62s/it] 67%|██████▋   | 8639/12825 [30:55:48<14:40:24, 12.62s/it] 67%|██████▋   | 8640/12825 [30:56:01<14:40:45, 12.63s/it] 67%|██████▋   | 8641/12825 [30:56:13<14:40:19, 12.62s/it] 67%|██████▋   | 8642/12825 [30:56:26<14:40:00, 12.62s/it] 67%|██████▋   | 8643/12825 [30:56:39<14:39:51, 12.62s/it] 67%|██████▋   | 8644/12825 [30:56:51<14:39:12, 12.62s/it] 67%|██████▋   | 8645/12825 [30:57:04<14:39:16, 12.62s/it] 67%|██████▋   | 8646/12825 [30:57:24<17:15:17, 14.86s/it] 67%|██████▋   | 8647/12825 [30:57:37<16:27:58, 14.19s/it] 67%|██████▋   | 8648/12825 [30:57:49<15:55:16, 13.72s/it] 67%|██████▋   | 8649/12825 [30:58:02<15:31:48, 13.39s/it] 67%|██████▋   | 8650/12825 [30:58:14<15:14:16, 13.14s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120472.51lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103695.82lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8625] due to args.save_total_limit
 67%|██████▋   | 8651/12825 [30:58:27<15:08:59, 13.07s/it] 67%|██████▋   | 8652/12825 [30:58:40<15:01:15, 12.96s/it] 67%|██████▋   | 8653/12825 [30:58:53<14:53:06, 12.84s/it] 67%|██████▋   | 8654/12825 [30:59:05<14:47:40, 12.77s/it] 67%|██████▋   | 8655/12825 [30:59:18<14:43:43, 12.72s/it] 67%|██████▋   | 8656/12825 [30:59:30<14:40:16, 12.67s/it] 68%|██████▊   | 8657/12825 [30:59:43<14:38:32, 12.65s/it] 68%|██████▊   | 8658/12825 [30:59:56<14:37:21, 12.63s/it] 68%|██████▊   | 8659/12825 [31:00:08<14:36:50, 12.63s/it] 68%|██████▊   | 8660/12825 [31:00:21<14:35:44, 12.62s/it] 68%|██████▊   | 8661/12825 [31:00:33<14:34:44, 12.60s/it] 68%|██████▊   | 8662/12825 [31:00:46<14:33:30, 12.59s/it] 68%|██████▊   | 8663/12825 [31:00:59<14:33:19, 12.59s/it] 68%|██████▊   | 8664/12825 [31:01:11<14:33:25, 12.59s/it] 68%|██████▊   | 8665/12825 [31:01:24<14:33:12, 12.59s/it] 68%|██████▊   | 8666/12825 [31:01:36<14:33:31, 12.60s/it] 68%|██████▊   | 8667/12825 [31:01:49<14:33:20, 12.60s/it] 68%|██████▊   | 8668/12825 [31:02:02<14:33:12, 12.60s/it] 68%|██████▊   | 8669/12825 [31:02:14<14:33:23, 12.61s/it] 68%|██████▊   | 8670/12825 [31:02:27<14:34:51, 12.63s/it] 68%|██████▊   | 8671/12825 [31:02:39<14:34:17, 12.63s/it] 68%|██████▊   | 8672/12825 [31:02:52<14:34:09, 12.63s/it] 68%|██████▊   | 8673/12825 [31:03:05<14:33:59, 12.63s/it] 68%|██████▊   | 8674/12825 [31:03:17<14:33:36, 12.63s/it] 68%|██████▊   | 8675/12825 [31:03:30<14:33:26, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120516.74lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103769.46lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8650] due to args.save_total_limit
 68%|██████▊   | 8676/12825 [31:03:43<14:39:43, 12.72s/it] 68%|██████▊   | 8677/12825 [31:03:55<14:36:11, 12.67s/it] 68%|██████▊   | 8678/12825 [31:04:16<17:12:25, 14.94s/it] 68%|██████▊   | 8679/12825 [31:04:28<16:23:51, 14.24s/it] 68%|██████▊   | 8680/12825 [31:04:41<15:49:43, 13.75s/it] 68%|██████▊   | 8681/12825 [31:04:54<15:25:09, 13.40s/it] 68%|██████▊   | 8682/12825 [31:05:06<15:08:06, 13.15s/it] 68%|██████▊   | 8683/12825 [31:05:19<14:56:19, 12.98s/it] 68%|██████▊   | 8684/12825 [31:05:31<14:47:40, 12.86s/it] 68%|██████▊   | 8685/12825 [31:05:44<14:41:33, 12.78s/it] 68%|██████▊   | 8686/12825 [31:05:56<14:38:01, 12.73s/it] 68%|██████▊   | 8687/12825 [31:06:09<14:35:57, 12.70s/it] 68%|██████▊   | 8688/12825 [31:06:22<14:35:04, 12.69s/it] 68%|██████▊   | 8689/12825 [31:06:34<14:32:25, 12.66s/it] 68%|██████▊   | 8690/12825 [31:06:47<14:31:19, 12.64s/it] 68%|██████▊   | 8691/12825 [31:07:00<14:30:05, 12.63s/it] 68%|██████▊   | 8692/12825 [31:07:12<14:29:19, 12.62s/it] 68%|██████▊   | 8693/12825 [31:07:25<14:28:24, 12.61s/it] 68%|██████▊   | 8694/12825 [31:07:37<14:27:36, 12.60s/it] 68%|██████▊   | 8695/12825 [31:07:50<14:27:17, 12.60s/it] 68%|██████▊   | 8696/12825 [31:08:03<14:27:09, 12.60s/it] 68%|██████▊   | 8697/12825 [31:08:15<14:26:43, 12.60s/it] 68%|██████▊   | 8698/12825 [31:08:28<14:26:32, 12.60s/it] 68%|██████▊   | 8699/12825 [31:08:40<14:26:14, 12.60s/it] 68%|██████▊   | 8700/12825 [31:08:53<14:25:35, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120416.91lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103721.37lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8675] due to args.save_total_limit
 68%|██████▊   | 8701/12825 [31:09:06<14:32:09, 12.69s/it] 68%|██████▊   | 8702/12825 [31:09:18<14:29:48, 12.66s/it] 68%|██████▊   | 8703/12825 [31:09:31<14:28:04, 12.64s/it] 68%|██████▊   | 8704/12825 [31:09:44<14:26:59, 12.62s/it] 68%|██████▊   | 8705/12825 [31:09:56<14:27:10, 12.63s/it] 68%|██████▊   | 8706/12825 [31:10:09<14:26:47, 12.63s/it] 68%|██████▊   | 8707/12825 [31:10:21<14:26:54, 12.63s/it] 68%|██████▊   | 8708/12825 [31:10:34<14:26:45, 12.63s/it] 68%|██████▊   | 8709/12825 [31:10:47<14:25:09, 12.61s/it] 68%|██████▊   | 8710/12825 [31:10:59<14:24:33, 12.61s/it] 68%|██████▊   | 8711/12825 [31:11:19<16:59:19, 14.87s/it] 68%|██████▊   | 8712/12825 [31:11:32<16:12:34, 14.19s/it] 68%|██████▊   | 8713/12825 [31:11:45<15:39:59, 13.72s/it] 68%|██████▊   | 8714/12825 [31:11:57<15:17:39, 13.39s/it] 68%|██████▊   | 8715/12825 [31:12:10<15:01:12, 13.16s/it] 68%|██████▊   | 8716/12825 [31:12:23<14:50:47, 13.01s/it] 68%|██████▊   | 8717/12825 [31:12:35<14:42:50, 12.89s/it] 68%|██████▊   | 8718/12825 [31:12:48<14:37:47, 12.82s/it] 68%|██████▊   | 8719/12825 [31:13:00<14:34:51, 12.78s/it] 68%|██████▊   | 8720/12825 [31:13:08<12:53:40, 11.31s/it] 68%|██████▊   | 8721/12825 [31:13:09<9:18:19,  8.16s/it]  68%|██████▊   | 8722/12825 [31:13:35<15:14:46, 13.38s/it] 68%|██████▊   | 8723/12825 [31:13:47<14:59:28, 13.16s/it] 68%|██████▊   | 8724/12825 [31:14:00<14:47:45, 12.99s/it] 68%|██████▊   | 8725/12825 [31:14:13<14:39:28, 12.87s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120462.00lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103678.16lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8725
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8725/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8725/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8700] due to args.save_total_limit
 68%|██████▊   | 8726/12825 [31:14:25<14:40:41, 12.89s/it] 68%|██████▊   | 8727/12825 [31:14:38<14:34:27, 12.80s/it] 68%|██████▊   | 8728/12825 [31:14:51<14:30:42, 12.75s/it] 68%|██████▊   | 8729/12825 [31:15:03<14:28:46, 12.73s/it] 68%|██████▊   | 8730/12825 [31:15:16<14:25:46, 12.69s/it] 68%|██████▊   | 8731/12825 [31:15:29<14:24:05, 12.66s/it] 68%|██████▊   | 8732/12825 [31:15:41<14:22:22, 12.64s/it] 68%|██████▊   | 8733/12825 [31:15:54<14:21:15, 12.63s/it] 68%|██████▊   | 8734/12825 [31:16:06<14:20:29, 12.62s/it] 68%|██████▊   | 8735/12825 [31:16:19<14:19:41, 12.61s/it] 68%|██████▊   | 8736/12825 [31:16:32<14:19:11, 12.61s/it] 68%|██████▊   | 8737/12825 [31:16:44<14:19:00, 12.61s/it] 68%|██████▊   | 8738/12825 [31:16:57<14:18:15, 12.60s/it] 68%|██████▊   | 8739/12825 [31:17:09<14:18:02, 12.60s/it] 68%|██████▊   | 8740/12825 [31:17:22<14:17:52, 12.60s/it] 68%|██████▊   | 8741/12825 [31:17:35<14:18:46, 12.62s/it] 68%|██████▊   | 8742/12825 [31:17:47<14:18:08, 12.61s/it] 68%|██████▊   | 8743/12825 [31:18:07<16:50:49, 14.86s/it] 68%|██████▊   | 8744/12825 [31:18:20<16:04:39, 14.18s/it] 68%|██████▊   | 8745/12825 [31:18:32<15:31:29, 13.70s/it] 68%|██████▊   | 8746/12825 [31:18:45<15:08:39, 13.37s/it] 68%|██████▊   | 8747/12825 [31:18:58<14:51:39, 13.12s/it] 68%|██████▊   | 8748/12825 [31:19:10<14:40:55, 12.96s/it] 68%|██████▊   | 8749/12825 [31:19:23<14:33:18, 12.86s/it] 68%|██████▊   | 8750/12825 [31:19:35<14:28:22, 12.79s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120442.02lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103692.40lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8750
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8750/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8750/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8725] due to args.save_total_limit
 68%|██████▊   | 8751/12825 [31:19:48<14:30:32, 12.82s/it] 68%|██████▊   | 8752/12825 [31:20:01<14:25:27, 12.75s/it] 68%|██████▊   | 8753/12825 [31:20:14<14:22:04, 12.70s/it] 68%|██████▊   | 8754/12825 [31:20:26<14:19:11, 12.66s/it] 68%|██████▊   | 8755/12825 [31:20:39<14:17:16, 12.64s/it] 68%|██████▊   | 8756/12825 [31:20:51<14:15:47, 12.62s/it] 68%|██████▊   | 8757/12825 [31:21:04<14:15:30, 12.62s/it] 68%|██████▊   | 8758/12825 [31:21:16<14:15:22, 12.62s/it] 68%|██████▊   | 8759/12825 [31:21:29<14:14:35, 12.61s/it] 68%|██████▊   | 8760/12825 [31:21:42<14:13:54, 12.60s/it] 68%|██████▊   | 8761/12825 [31:21:54<14:13:10, 12.60s/it] 68%|██████▊   | 8762/12825 [31:22:07<14:13:14, 12.60s/it] 68%|██████▊   | 8763/12825 [31:22:19<14:12:50, 12.60s/it] 68%|██████▊   | 8764/12825 [31:22:32<14:12:08, 12.59s/it] 68%|██████▊   | 8765/12825 [31:22:45<14:11:48, 12.59s/it] 68%|██████▊   | 8766/12825 [31:22:57<14:11:50, 12.59s/it] 68%|██████▊   | 8767/12825 [31:23:10<14:11:05, 12.58s/it] 68%|██████▊   | 8768/12825 [31:23:22<14:10:02, 12.57s/it] 68%|██████▊   | 8769/12825 [31:23:35<14:09:59, 12.57s/it] 68%|██████▊   | 8770/12825 [31:23:47<14:09:15, 12.57s/it] 68%|██████▊   | 8771/12825 [31:24:00<14:09:11, 12.57s/it] 68%|██████▊   | 8772/12825 [31:24:13<14:09:51, 12.58s/it] 68%|██████▊   | 8773/12825 [31:24:25<14:09:09, 12.57s/it] 68%|██████▊   | 8774/12825 [31:24:38<14:10:49, 12.60s/it] 68%|██████▊   | 8775/12825 [31:24:51<14:14:41, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 118186.28lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101999.99lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8775
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8775/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8775/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8750] due to args.save_total_limit
 68%|██████▊   | 8776/12825 [31:25:11<16:51:21, 14.99s/it] 68%|██████▊   | 8777/12825 [31:25:24<16:02:19, 14.26s/it] 68%|██████▊   | 8778/12825 [31:25:36<15:29:26, 13.78s/it] 68%|██████▊   | 8779/12825 [31:25:49<15:05:11, 13.42s/it] 68%|██████▊   | 8780/12825 [31:26:01<14:47:43, 13.17s/it] 68%|██████▊   | 8781/12825 [31:26:14<14:35:54, 13.00s/it] 68%|██████▊   | 8782/12825 [31:26:27<14:27:20, 12.87s/it] 68%|██████▊   | 8783/12825 [31:26:39<14:23:18, 12.82s/it] 68%|██████▊   | 8784/12825 [31:26:52<14:19:24, 12.76s/it] 68%|██████▊   | 8785/12825 [31:27:05<14:15:19, 12.70s/it] 69%|██████▊   | 8786/12825 [31:27:17<14:12:39, 12.67s/it] 69%|██████▊   | 8787/12825 [31:27:30<14:10:47, 12.64s/it] 69%|██████▊   | 8788/12825 [31:27:42<14:10:18, 12.64s/it] 69%|██████▊   | 8789/12825 [31:27:55<14:09:04, 12.62s/it] 69%|██████▊   | 8790/12825 [31:28:08<14:08:58, 12.62s/it] 69%|██████▊   | 8791/12825 [31:28:20<14:08:11, 12.62s/it] 69%|██████▊   | 8792/12825 [31:28:33<14:08:35, 12.62s/it] 69%|██████▊   | 8793/12825 [31:28:45<14:08:02, 12.62s/it] 69%|██████▊   | 8794/12825 [31:28:58<14:07:01, 12.61s/it] 69%|██████▊   | 8795/12825 [31:29:11<14:06:42, 12.61s/it] 69%|██████▊   | 8796/12825 [31:29:23<14:06:24, 12.60s/it] 69%|██████▊   | 8797/12825 [31:29:36<14:05:43, 12.60s/it] 69%|██████▊   | 8798/12825 [31:29:48<14:05:20, 12.60s/it] 69%|██████▊   | 8799/12825 [31:30:01<14:04:58, 12.59s/it] 69%|██████▊   | 8800/12825 [31:30:14<14:04:52, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120440.99lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103666.11lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8800
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8800/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8800/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8775] due to args.save_total_limit
 69%|██████▊   | 8801/12825 [31:30:26<14:11:04, 12.69s/it] 69%|██████▊   | 8802/12825 [31:30:39<14:08:32, 12.66s/it] 69%|██████▊   | 8803/12825 [31:30:52<14:07:05, 12.64s/it] 69%|██████▊   | 8804/12825 [31:31:04<14:06:24, 12.63s/it] 69%|██████▊   | 8805/12825 [31:31:17<14:07:06, 12.64s/it] 69%|██████▊   | 8806/12825 [31:31:29<14:06:20, 12.64s/it] 69%|██████▊   | 8807/12825 [31:31:42<14:04:48, 12.62s/it] 69%|██████▊   | 8808/12825 [31:32:02<16:31:17, 14.81s/it] 69%|██████▊   | 8809/12825 [31:32:15<15:45:46, 14.13s/it] 69%|██████▊   | 8810/12825 [31:32:27<15:14:22, 13.66s/it] 69%|██████▊   | 8811/12825 [31:32:40<14:52:17, 13.34s/it] 69%|██████▊   | 8812/12825 [31:32:52<14:37:21, 13.12s/it] 69%|██████▊   | 8813/12825 [31:33:05<14:27:10, 12.97s/it] 69%|██████▊   | 8814/12825 [31:33:18<14:19:51, 12.86s/it] 69%|██████▊   | 8815/12825 [31:33:30<14:13:52, 12.78s/it] 69%|██████▊   | 8816/12825 [31:33:43<14:09:58, 12.72s/it] 69%|██████▊   | 8817/12825 [31:33:55<14:07:08, 12.68s/it] 69%|██████▉   | 8818/12825 [31:34:08<14:05:19, 12.66s/it] 69%|██████▉   | 8819/12825 [31:34:20<14:03:23, 12.63s/it] 69%|██████▉   | 8820/12825 [31:34:33<14:04:50, 12.66s/it] 69%|██████▉   | 8821/12825 [31:34:46<14:03:52, 12.65s/it] 69%|██████▉   | 8822/12825 [31:34:58<14:02:16, 12.62s/it] 69%|██████▉   | 8823/12825 [31:35:11<14:01:28, 12.62s/it] 69%|██████▉   | 8824/12825 [31:35:24<14:01:33, 12.62s/it] 69%|██████▉   | 8825/12825 [31:35:36<14:01:11, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120424.34lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103682.72lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8825
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8825/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8825/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8800] due to args.save_total_limit
 69%|██████▉   | 8826/12825 [31:35:49<14:07:16, 12.71s/it] 69%|██████▉   | 8827/12825 [31:36:02<14:05:26, 12.69s/it] 69%|██████▉   | 8828/12825 [31:36:14<14:03:36, 12.66s/it] 69%|██████▉   | 8829/12825 [31:36:27<14:02:11, 12.65s/it] 69%|██████▉   | 8830/12825 [31:36:40<14:01:08, 12.63s/it] 69%|██████▉   | 8831/12825 [31:36:52<14:00:01, 12.62s/it] 69%|██████▉   | 8832/12825 [31:37:05<13:58:44, 12.60s/it] 69%|██████▉   | 8833/12825 [31:37:17<13:58:16, 12.60s/it] 69%|██████▉   | 8834/12825 [31:37:30<13:58:37, 12.61s/it] 69%|██████▉   | 8835/12825 [31:37:43<13:58:39, 12.61s/it] 69%|██████▉   | 8836/12825 [31:37:55<13:58:43, 12.62s/it] 69%|██████▉   | 8837/12825 [31:38:08<13:57:56, 12.61s/it] 69%|██████▉   | 8838/12825 [31:38:20<13:57:53, 12.61s/it] 69%|██████▉   | 8839/12825 [31:38:33<13:57:25, 12.61s/it] 69%|██████▉   | 8840/12825 [31:38:53<16:27:59, 14.88s/it] 69%|██████▉   | 8841/12825 [31:39:06<15:42:06, 14.19s/it] 69%|██████▉   | 8842/12825 [31:39:18<15:10:00, 13.71s/it] 69%|██████▉   | 8843/12825 [31:39:31<14:48:17, 13.38s/it] 69%|██████▉   | 8844/12825 [31:39:44<14:32:00, 13.14s/it] 69%|██████▉   | 8845/12825 [31:39:56<14:20:34, 12.97s/it] 69%|██████▉   | 8846/12825 [31:40:09<14:12:25, 12.85s/it] 69%|██████▉   | 8847/12825 [31:40:21<14:07:55, 12.79s/it] 69%|██████▉   | 8848/12825 [31:40:34<14:04:27, 12.74s/it] 69%|██████▉   | 8849/12825 [31:40:47<14:01:17, 12.70s/it] 69%|██████▉   | 8850/12825 [31:40:59<14:01:35, 12.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120454.44lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103430.26lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8850
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8850/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8850/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8825] due to args.save_total_limit
 69%|██████▉   | 8851/12825 [31:41:12<14:05:48, 12.77s/it] 69%|██████▉   | 8852/12825 [31:41:25<14:03:48, 12.74s/it] 69%|██████▉   | 8853/12825 [31:41:37<14:00:16, 12.69s/it] 69%|██████▉   | 8854/12825 [31:41:50<13:57:20, 12.65s/it] 69%|██████▉   | 8855/12825 [31:42:03<13:56:01, 12.64s/it] 69%|██████▉   | 8856/12825 [31:42:15<13:54:53, 12.62s/it] 69%|██████▉   | 8857/12825 [31:42:28<13:55:15, 12.63s/it] 69%|██████▉   | 8858/12825 [31:42:40<13:54:00, 12.61s/it] 69%|██████▉   | 8859/12825 [31:42:53<13:52:29, 12.59s/it] 69%|██████▉   | 8860/12825 [31:43:06<13:52:01, 12.59s/it] 69%|██████▉   | 8861/12825 [31:43:18<13:51:25, 12.58s/it] 69%|██████▉   | 8862/12825 [31:43:31<13:51:34, 12.59s/it] 69%|██████▉   | 8863/12825 [31:43:43<13:51:28, 12.59s/it] 69%|██████▉   | 8864/12825 [31:43:56<13:50:36, 12.58s/it] 69%|██████▉   | 8865/12825 [31:44:08<13:50:02, 12.58s/it] 69%|██████▉   | 8866/12825 [31:44:21<13:50:27, 12.59s/it] 69%|██████▉   | 8867/12825 [31:44:34<13:50:14, 12.59s/it] 69%|██████▉   | 8868/12825 [31:44:46<13:50:17, 12.59s/it] 69%|██████▉   | 8869/12825 [31:44:59<13:49:38, 12.58s/it] 69%|██████▉   | 8870/12825 [31:45:11<13:49:28, 12.58s/it] 69%|██████▉   | 8871/12825 [31:45:24<13:49:43, 12.59s/it] 69%|██████▉   | 8872/12825 [31:45:37<13:49:02, 12.58s/it] 69%|██████▉   | 8873/12825 [31:45:57<16:18:40, 14.86s/it] 69%|██████▉   | 8874/12825 [31:46:09<15:33:24, 14.17s/it] 69%|██████▉   | 8875/12825 [31:46:22<15:01:29, 13.69s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120494.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103694.30lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8875
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8875/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8875/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8850] due to args.save_total_limit
 69%|██████▉   | 8876/12825 [31:46:35<14:45:37, 13.46s/it] 69%|██████▉   | 8877/12825 [31:46:47<14:30:04, 13.22s/it] 69%|██████▉   | 8878/12825 [31:47:00<14:17:34, 13.04s/it] 69%|██████▉   | 8879/12825 [31:47:13<14:08:18, 12.90s/it] 69%|██████▉   | 8880/12825 [31:47:25<14:01:34, 12.80s/it] 69%|██████▉   | 8881/12825 [31:47:38<13:56:41, 12.73s/it] 69%|██████▉   | 8882/12825 [31:47:50<13:53:05, 12.68s/it] 69%|██████▉   | 8883/12825 [31:48:03<13:50:55, 12.65s/it] 69%|██████▉   | 8884/12825 [31:48:15<13:49:18, 12.63s/it] 69%|██████▉   | 8885/12825 [31:48:28<13:48:21, 12.61s/it] 69%|██████▉   | 8886/12825 [31:48:41<13:46:52, 12.60s/it] 69%|██████▉   | 8887/12825 [31:48:53<13:46:19, 12.59s/it] 69%|██████▉   | 8888/12825 [31:49:06<13:45:32, 12.58s/it] 69%|██████▉   | 8889/12825 [31:49:18<13:45:00, 12.58s/it] 69%|██████▉   | 8890/12825 [31:49:31<13:44:03, 12.57s/it] 69%|██████▉   | 8891/12825 [31:49:43<13:43:54, 12.57s/it] 69%|██████▉   | 8892/12825 [31:49:56<13:43:46, 12.57s/it] 69%|██████▉   | 8893/12825 [31:50:09<13:43:35, 12.57s/it] 69%|██████▉   | 8894/12825 [31:50:21<13:43:52, 12.58s/it] 69%|██████▉   | 8895/12825 [31:50:34<13:44:35, 12.59s/it] 69%|██████▉   | 8896/12825 [31:50:46<13:44:16, 12.59s/it] 69%|██████▉   | 8897/12825 [31:50:59<13:43:43, 12.58s/it] 69%|██████▉   | 8898/12825 [31:51:11<13:42:39, 12.57s/it] 69%|██████▉   | 8899/12825 [31:51:24<13:42:49, 12.57s/it] 69%|██████▉   | 8900/12825 [31:51:37<13:42:23, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120503.53lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103723.94lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8900
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8900/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8900/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8875] due to args.save_total_limit
 69%|██████▉   | 8901/12825 [31:51:50<13:48:20, 12.67s/it] 69%|██████▉   | 8902/12825 [31:52:02<13:45:57, 12.63s/it] 69%|██████▉   | 8903/12825 [31:52:15<13:44:39, 12.62s/it] 69%|██████▉   | 8904/12825 [31:52:27<13:43:07, 12.60s/it] 69%|██████▉   | 8905/12825 [31:52:47<16:06:59, 14.80s/it] 69%|██████▉   | 8906/12825 [31:53:00<15:23:20, 14.14s/it] 69%|██████▉   | 8907/12825 [31:53:12<14:52:18, 13.66s/it] 69%|██████▉   | 8908/12825 [31:53:25<14:30:14, 13.33s/it] 69%|██████▉   | 8909/12825 [31:53:37<14:14:43, 13.10s/it] 69%|██████▉   | 8910/12825 [31:53:50<14:04:21, 12.94s/it] 69%|██████▉   | 8911/12825 [31:54:03<13:56:36, 12.82s/it] 69%|██████▉   | 8912/12825 [31:54:15<13:52:16, 12.76s/it] 69%|██████▉   | 8913/12825 [31:54:28<13:49:17, 12.72s/it] 70%|██████▉   | 8914/12825 [31:54:40<13:47:00, 12.69s/it] 70%|██████▉   | 8915/12825 [31:54:53<13:44:31, 12.65s/it] 70%|██████▉   | 8916/12825 [31:55:06<13:43:16, 12.64s/it] 70%|██████▉   | 8917/12825 [31:55:18<13:41:26, 12.61s/it] 70%|██████▉   | 8918/12825 [31:55:31<13:41:50, 12.62s/it] 70%|██████▉   | 8919/12825 [31:55:43<13:40:18, 12.60s/it] 70%|██████▉   | 8920/12825 [31:55:56<13:39:15, 12.59s/it] 70%|██████▉   | 8921/12825 [31:56:08<13:38:33, 12.58s/it] 70%|██████▉   | 8922/12825 [31:56:21<13:38:07, 12.58s/it] 70%|██████▉   | 8923/12825 [31:56:34<13:37:03, 12.56s/it] 70%|██████▉   | 8924/12825 [31:56:46<13:36:22, 12.56s/it] 70%|██████▉   | 8925/12825 [31:56:59<13:36:24, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120416.53lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103648.94lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8925
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8925/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8925/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8900] due to args.save_total_limit
 70%|██████▉   | 8926/12825 [31:57:12<13:43:51, 12.68s/it] 70%|██████▉   | 8927/12825 [31:57:24<13:41:09, 12.64s/it] 70%|██████▉   | 8928/12825 [31:57:37<13:39:40, 12.62s/it] 70%|██████▉   | 8929/12825 [31:57:49<13:38:27, 12.60s/it] 70%|██████▉   | 8930/12825 [31:58:02<13:37:07, 12.59s/it] 70%|██████▉   | 8931/12825 [31:58:14<13:37:19, 12.59s/it] 70%|██████▉   | 8932/12825 [31:58:27<13:36:35, 12.59s/it] 70%|██████▉   | 8933/12825 [31:58:40<13:35:42, 12.58s/it] 70%|██████▉   | 8934/12825 [31:58:52<13:35:19, 12.57s/it] 70%|██████▉   | 8935/12825 [31:59:05<13:34:56, 12.57s/it] 70%|██████▉   | 8936/12825 [31:59:17<13:33:37, 12.55s/it] 70%|██████▉   | 8937/12825 [31:59:30<13:34:04, 12.56s/it] 70%|██████▉   | 8938/12825 [31:59:50<15:59:30, 14.81s/it] 70%|██████▉   | 8939/12825 [32:00:02<15:15:39, 14.14s/it] 70%|██████▉   | 8940/12825 [32:00:15<14:45:16, 13.67s/it] 70%|██████▉   | 8941/12825 [32:00:28<14:23:30, 13.34s/it] 70%|██████▉   | 8942/12825 [32:00:40<14:08:44, 13.11s/it] 70%|██████▉   | 8943/12825 [32:00:53<13:58:14, 12.96s/it] 70%|██████▉   | 8944/12825 [32:01:05<13:50:30, 12.84s/it] 70%|██████▉   | 8945/12825 [32:01:18<13:47:44, 12.80s/it] 70%|██████▉   | 8946/12825 [32:01:31<13:46:13, 12.78s/it] 70%|██████▉   | 8947/12825 [32:01:43<13:44:04, 12.75s/it] 70%|██████▉   | 8948/12825 [32:01:56<13:40:23, 12.70s/it] 70%|██████▉   | 8949/12825 [32:02:09<13:38:02, 12.66s/it] 70%|██████▉   | 8950/12825 [32:02:21<13:36:33, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120451.75lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103667.35lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8950
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8950/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8950/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8925] due to args.save_total_limit
 70%|██████▉   | 8951/12825 [32:02:34<13:41:44, 12.73s/it] 70%|██████▉   | 8952/12825 [32:02:47<13:38:29, 12.68s/it] 70%|██████▉   | 8953/12825 [32:02:59<13:36:31, 12.65s/it] 70%|██████▉   | 8954/12825 [32:03:12<13:34:22, 12.62s/it] 70%|██████▉   | 8955/12825 [32:03:24<13:33:13, 12.61s/it] 70%|██████▉   | 8956/12825 [32:03:37<13:31:58, 12.59s/it] 70%|██████▉   | 8957/12825 [32:03:49<13:31:03, 12.58s/it] 70%|██████▉   | 8958/12825 [32:04:02<13:31:07, 12.59s/it] 70%|██████▉   | 8959/12825 [32:04:15<13:30:29, 12.58s/it] 70%|██████▉   | 8960/12825 [32:04:27<13:30:04, 12.58s/it] 70%|██████▉   | 8961/12825 [32:04:40<13:31:09, 12.60s/it] 70%|██████▉   | 8962/12825 [32:04:52<13:30:51, 12.59s/it] 70%|██████▉   | 8963/12825 [32:05:05<13:30:27, 12.59s/it] 70%|██████▉   | 8964/12825 [32:05:18<13:30:11, 12.59s/it] 70%|██████▉   | 8965/12825 [32:05:30<13:30:05, 12.59s/it] 70%|██████▉   | 8966/12825 [32:05:43<13:29:43, 12.59s/it] 70%|██████▉   | 8967/12825 [32:05:55<13:29:40, 12.59s/it] 70%|██████▉   | 8968/12825 [32:06:08<13:29:32, 12.59s/it] 70%|██████▉   | 8969/12825 [32:06:21<13:29:03, 12.59s/it] 70%|██████▉   | 8970/12825 [32:06:41<15:52:54, 14.83s/it] 70%|██████▉   | 8971/12825 [32:06:53<15:09:16, 14.16s/it] 70%|██████▉   | 8972/12825 [32:07:06<14:38:43, 13.68s/it] 70%|██████▉   | 8973/12825 [32:07:18<14:16:58, 13.35s/it] 70%|██████▉   | 8974/12825 [32:07:31<14:00:51, 13.10s/it] 70%|██████▉   | 8975/12825 [32:07:43<13:50:40, 12.95s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120498.53lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103815.22lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8975
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8975/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8975/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-8975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8950] due to args.save_total_limit
 70%|██████▉   | 8976/12825 [32:07:56<13:49:16, 12.93s/it] 70%|██████▉   | 8977/12825 [32:08:09<13:41:52, 12.82s/it] 70%|███████   | 8978/12825 [32:08:21<13:36:20, 12.73s/it] 70%|███████   | 8979/12825 [32:08:34<13:32:49, 12.68s/it] 70%|███████   | 8980/12825 [32:08:47<13:30:17, 12.64s/it] 70%|███████   | 8981/12825 [32:08:59<13:28:53, 12.63s/it] 70%|███████   | 8982/12825 [32:09:12<13:27:16, 12.60s/it] 70%|███████   | 8983/12825 [32:09:24<13:26:41, 12.60s/it] 70%|███████   | 8984/12825 [32:09:37<13:25:24, 12.58s/it] 70%|███████   | 8985/12825 [32:09:49<13:24:31, 12.57s/it] 70%|███████   | 8986/12825 [32:10:02<13:24:08, 12.57s/it] 70%|███████   | 8987/12825 [32:10:14<13:23:43, 12.56s/it] 70%|███████   | 8988/12825 [32:10:27<13:24:11, 12.58s/it] 70%|███████   | 8989/12825 [32:10:40<13:24:45, 12.59s/it] 70%|███████   | 8990/12825 [32:10:52<13:24:23, 12.58s/it] 70%|███████   | 8991/12825 [32:11:05<13:23:37, 12.58s/it] 70%|███████   | 8992/12825 [32:11:17<13:23:08, 12.57s/it] 70%|███████   | 8993/12825 [32:11:30<13:22:27, 12.56s/it] 70%|███████   | 8994/12825 [32:11:43<13:22:12, 12.56s/it] 70%|███████   | 8995/12825 [32:11:55<13:22:25, 12.57s/it] 70%|███████   | 8996/12825 [32:12:08<13:21:54, 12.57s/it] 70%|███████   | 8997/12825 [32:12:20<13:21:55, 12.57s/it] 70%|███████   | 8998/12825 [32:12:33<13:21:10, 12.56s/it] 70%|███████   | 8999/12825 [32:12:45<13:21:15, 12.57s/it] 70%|███████   | 9000/12825 [32:12:58<13:20:23, 12.56s/it]                                                           70%|███████   | 9000/12825 [32:12:58<13:20:23, 12.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120415.89lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103591.01lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9000
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9000/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9000/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8975] due to args.save_total_limit
 70%|███████   | 9001/12825 [32:13:11<13:31:16, 12.73s/it] 70%|███████   | 9002/12825 [32:13:31<15:51:37, 14.94s/it] 70%|███████   | 9003/12825 [32:13:44<15:06:15, 14.23s/it] 70%|███████   | 9004/12825 [32:13:56<14:34:17, 13.73s/it] 70%|███████   | 9005/12825 [32:14:09<14:12:00, 13.38s/it] 70%|███████   | 9006/12825 [32:14:21<13:55:50, 13.13s/it] 70%|███████   | 9007/12825 [32:14:34<13:44:35, 12.96s/it] 70%|███████   | 9008/12825 [32:14:46<13:36:14, 12.83s/it] 70%|███████   | 9009/12825 [32:14:59<13:30:18, 12.74s/it] 70%|███████   | 9010/12825 [32:15:12<13:26:24, 12.68s/it] 70%|███████   | 9011/12825 [32:15:24<13:24:22, 12.65s/it] 70%|███████   | 9012/12825 [32:15:37<13:22:13, 12.62s/it] 70%|███████   | 9013/12825 [32:15:49<13:20:45, 12.60s/it] 70%|███████   | 9014/12825 [32:16:02<13:19:48, 12.59s/it] 70%|███████   | 9015/12825 [32:16:14<13:19:17, 12.59s/it] 70%|███████   | 9016/12825 [32:16:27<13:18:35, 12.58s/it] 70%|███████   | 9017/12825 [32:16:40<13:18:39, 12.58s/it] 70%|███████   | 9018/12825 [32:16:52<13:17:14, 12.56s/it] 70%|███████   | 9019/12825 [32:17:05<13:16:38, 12.56s/it] 70%|███████   | 9020/12825 [32:17:17<13:17:12, 12.57s/it] 70%|███████   | 9021/12825 [32:17:30<13:17:33, 12.58s/it] 70%|███████   | 9022/12825 [32:17:42<13:17:04, 12.58s/it] 70%|███████   | 9023/12825 [32:17:55<13:17:03, 12.58s/it] 70%|███████   | 9024/12825 [32:18:08<13:16:53, 12.58s/it] 70%|███████   | 9025/12825 [32:18:20<13:17:18, 12.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120433.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103688.70lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9025
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9025/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9025/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9000] due to args.save_total_limit
 70%|███████   | 9026/12825 [32:18:33<13:22:57, 12.68s/it] 70%|███████   | 9027/12825 [32:18:46<13:20:25, 12.64s/it] 70%|███████   | 9028/12825 [32:18:58<13:19:00, 12.63s/it] 70%|███████   | 9029/12825 [32:19:11<13:18:24, 12.62s/it] 70%|███████   | 9030/12825 [32:19:23<13:17:35, 12.61s/it] 70%|███████   | 9031/12825 [32:19:36<13:16:50, 12.60s/it] 70%|███████   | 9032/12825 [32:19:49<13:16:03, 12.59s/it] 70%|███████   | 9033/12825 [32:20:01<13:15:10, 12.58s/it] 70%|███████   | 9034/12825 [32:20:21<15:35:51, 14.81s/it] 70%|███████   | 9035/12825 [32:20:34<14:54:47, 14.17s/it] 70%|███████   | 9036/12825 [32:20:46<14:25:21, 13.70s/it] 70%|███████   | 9037/12825 [32:20:59<14:04:48, 13.38s/it] 70%|███████   | 9038/12825 [32:21:12<13:49:54, 13.15s/it] 70%|███████   | 9039/12825 [32:21:24<13:40:18, 13.00s/it] 70%|███████   | 9040/12825 [32:21:37<13:33:16, 12.89s/it] 70%|███████   | 9041/12825 [32:21:50<13:30:21, 12.85s/it] 71%|███████   | 9042/12825 [32:22:02<13:25:08, 12.77s/it] 71%|███████   | 9043/12825 [32:22:15<13:21:48, 12.72s/it] 71%|███████   | 9044/12825 [32:22:27<13:19:13, 12.68s/it] 71%|███████   | 9045/12825 [32:22:40<13:18:43, 12.68s/it] 71%|███████   | 9046/12825 [32:22:53<13:16:40, 12.65s/it] 71%|███████   | 9047/12825 [32:23:05<13:15:13, 12.63s/it] 71%|███████   | 9048/12825 [32:23:18<13:14:45, 12.63s/it] 71%|███████   | 9049/12825 [32:23:31<13:14:45, 12.63s/it] 71%|███████   | 9050/12825 [32:23:43<13:14:17, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120590.28lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103821.79lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9050
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9050/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9050/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9025] due to args.save_total_limit
 71%|███████   | 9051/12825 [32:23:56<13:20:35, 12.73s/it] 71%|███████   | 9052/12825 [32:24:09<13:18:19, 12.70s/it] 71%|███████   | 9053/12825 [32:24:21<13:16:34, 12.67s/it] 71%|███████   | 9054/12825 [32:24:34<13:15:01, 12.65s/it] 71%|███████   | 9055/12825 [32:24:46<13:13:09, 12.62s/it] 71%|███████   | 9056/12825 [32:24:59<13:12:07, 12.61s/it] 71%|███████   | 9057/12825 [32:25:12<13:11:59, 12.61s/it] 71%|███████   | 9058/12825 [32:25:24<13:12:25, 12.62s/it] 71%|███████   | 9059/12825 [32:25:37<13:12:19, 12.62s/it] 71%|███████   | 9060/12825 [32:25:50<13:11:59, 12.62s/it] 71%|███████   | 9061/12825 [32:26:02<13:12:15, 12.63s/it] 71%|███████   | 9062/12825 [32:26:15<13:12:04, 12.63s/it] 71%|███████   | 9063/12825 [32:26:27<13:10:57, 12.61s/it] 71%|███████   | 9064/12825 [32:26:40<13:10:32, 12.61s/it] 71%|███████   | 9065/12825 [32:26:53<13:10:10, 12.61s/it] 71%|███████   | 9066/12825 [32:27:05<13:11:25, 12.63s/it] 71%|███████   | 9067/12825 [32:27:25<15:30:43, 14.86s/it] 71%|███████   | 9068/12825 [32:27:38<14:50:01, 14.21s/it] 71%|███████   | 9069/12825 [32:27:51<14:19:42, 13.73s/it] 71%|███████   | 9070/12825 [32:28:03<13:58:01, 13.39s/it] 71%|███████   | 9071/12825 [32:28:16<13:42:26, 13.15s/it] 71%|███████   | 9072/12825 [32:28:28<13:31:35, 12.98s/it] 71%|███████   | 9073/12825 [32:28:41<13:23:54, 12.86s/it] 71%|███████   | 9074/12825 [32:28:54<13:19:06, 12.78s/it] 71%|███████   | 9075/12825 [32:29:06<13:16:08, 12.74s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120172.98lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103551.79lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9075
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9075/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9075/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9050] due to args.save_total_limit
 71%|███████   | 9076/12825 [32:29:19<13:19:11, 12.79s/it] 71%|███████   | 9077/12825 [32:29:32<13:15:53, 12.74s/it] 71%|███████   | 9078/12825 [32:29:44<13:12:57, 12.70s/it] 71%|███████   | 9079/12825 [32:29:57<13:12:40, 12.70s/it] 71%|███████   | 9080/12825 [32:30:10<13:11:32, 12.68s/it] 71%|███████   | 9081/12825 [32:30:22<13:10:00, 12.66s/it] 71%|███████   | 9082/12825 [32:30:35<13:08:46, 12.64s/it] 71%|███████   | 9083/12825 [32:30:48<13:07:26, 12.63s/it] 71%|███████   | 9084/12825 [32:31:00<13:07:35, 12.63s/it] 71%|███████   | 9085/12825 [32:31:13<13:06:30, 12.62s/it] 71%|███████   | 9086/12825 [32:31:25<13:05:27, 12.60s/it] 71%|███████   | 9087/12825 [32:31:38<13:05:19, 12.61s/it] 71%|███████   | 9088/12825 [32:31:51<13:05:05, 12.61s/it] 71%|███████   | 9089/12825 [32:32:03<13:05:18, 12.61s/it] 71%|███████   | 9090/12825 [32:32:16<13:05:14, 12.61s/it] 71%|███████   | 9091/12825 [32:32:28<13:04:49, 12.61s/it] 71%|███████   | 9092/12825 [32:32:41<13:06:22, 12.64s/it] 71%|███████   | 9093/12825 [32:32:54<13:05:55, 12.64s/it] 71%|███████   | 9094/12825 [32:33:06<13:05:27, 12.63s/it] 71%|███████   | 9095/12825 [32:33:19<13:06:40, 12.65s/it] 71%|███████   | 9096/12825 [32:33:32<13:07:55, 12.68s/it] 71%|███████   | 9097/12825 [32:33:44<13:05:52, 12.65s/it] 71%|███████   | 9098/12825 [32:33:57<13:06:13, 12.66s/it] 71%|███████   | 9099/12825 [32:34:17<15:23:09, 14.87s/it] 71%|███████   | 9100/12825 [32:34:30<14:41:09, 14.19s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120504.05lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103728.02lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9100
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9100/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9100/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9075] due to args.save_total_limit
 71%|███████   | 9101/12825 [32:34:43<14:17:29, 13.82s/it] 71%|███████   | 9102/12825 [32:34:55<13:54:42, 13.45s/it] 71%|███████   | 9103/12825 [32:35:08<13:39:05, 13.20s/it] 71%|███████   | 9104/12825 [32:35:20<13:27:18, 13.02s/it] 71%|███████   | 9105/12825 [32:35:33<13:19:45, 12.90s/it] 71%|███████   | 9106/12825 [32:35:46<13:14:21, 12.82s/it] 71%|███████   | 9107/12825 [32:35:58<13:10:13, 12.75s/it] 71%|███████   | 9108/12825 [32:36:11<13:07:12, 12.71s/it] 71%|███████   | 9109/12825 [32:36:24<13:05:18, 12.68s/it] 71%|███████   | 9110/12825 [32:36:36<13:05:57, 12.69s/it] 71%|███████   | 9111/12825 [32:36:49<13:04:38, 12.68s/it] 71%|███████   | 9112/12825 [32:37:02<13:04:08, 12.67s/it] 71%|███████   | 9113/12825 [32:37:14<13:03:01, 12.66s/it] 71%|███████   | 9114/12825 [32:37:27<13:01:44, 12.64s/it] 71%|███████   | 9115/12825 [32:37:39<13:01:22, 12.64s/it] 71%|███████   | 9116/12825 [32:37:52<13:00:24, 12.62s/it] 71%|███████   | 9117/12825 [32:38:05<12:59:57, 12.62s/it] 71%|███████   | 9118/12825 [32:38:17<12:59:39, 12.62s/it] 71%|███████   | 9119/12825 [32:38:30<12:59:31, 12.62s/it] 71%|███████   | 9120/12825 [32:38:42<12:59:11, 12.62s/it] 71%|███████   | 9121/12825 [32:38:55<12:59:22, 12.62s/it] 71%|███████   | 9122/12825 [32:39:08<12:58:35, 12.62s/it] 71%|███████   | 9123/12825 [32:39:20<12:58:12, 12.61s/it] 71%|███████   | 9124/12825 [32:39:33<12:57:48, 12.61s/it] 71%|███████   | 9125/12825 [32:39:46<12:57:55, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120486.74lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103125.47lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9125
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9125/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9125/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9100] due to args.save_total_limit
 71%|███████   | 9126/12825 [32:39:58<13:04:14, 12.72s/it] 71%|███████   | 9127/12825 [32:40:11<13:02:02, 12.69s/it] 71%|███████   | 9128/12825 [32:40:24<13:02:17, 12.70s/it] 71%|███████   | 9129/12825 [32:40:36<13:00:11, 12.67s/it] 71%|███████   | 9130/12825 [32:40:49<12:58:26, 12.64s/it] 71%|███████   | 9131/12825 [32:41:02<12:57:12, 12.62s/it] 71%|███████   | 9132/12825 [32:41:22<15:12:28, 14.83s/it] 71%|███████   | 9133/12825 [32:41:34<14:31:20, 14.16s/it] 71%|███████   | 9134/12825 [32:41:47<14:02:13, 13.69s/it] 71%|███████   | 9135/12825 [32:41:59<13:42:11, 13.37s/it] 71%|███████   | 9136/12825 [32:42:12<13:27:24, 13.13s/it] 71%|███████   | 9137/12825 [32:42:25<13:17:28, 12.97s/it] 71%|███████▏  | 9138/12825 [32:42:37<13:10:58, 12.87s/it] 71%|███████▏  | 9139/12825 [32:42:50<13:07:03, 12.81s/it] 71%|███████▏  | 9140/12825 [32:43:02<13:02:15, 12.74s/it] 71%|███████▏  | 9141/12825 [32:43:15<12:59:32, 12.70s/it] 71%|███████▏  | 9142/12825 [32:43:28<12:57:13, 12.66s/it] 71%|███████▏  | 9143/12825 [32:43:40<12:55:56, 12.64s/it] 71%|███████▏  | 9144/12825 [32:43:53<12:55:21, 12.64s/it] 71%|███████▏  | 9145/12825 [32:44:05<12:54:34, 12.63s/it] 71%|███████▏  | 9146/12825 [32:44:18<12:54:15, 12.63s/it] 71%|███████▏  | 9147/12825 [32:44:31<12:54:06, 12.63s/it] 71%|███████▏  | 9148/12825 [32:44:43<12:52:50, 12.61s/it] 71%|███████▏  | 9149/12825 [32:44:56<12:52:52, 12.61s/it] 71%|███████▏  | 9150/12825 [32:45:08<12:52:26, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120435.10lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103655.20lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9150
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9150/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9150/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9125] due to args.save_total_limit
 71%|███████▏  | 9151/12825 [32:45:22<13:01:10, 12.76s/it] 71%|███████▏  | 9152/12825 [32:45:34<12:58:14, 12.71s/it] 71%|███████▏  | 9153/12825 [32:45:47<12:56:18, 12.68s/it] 71%|███████▏  | 9154/12825 [32:45:59<12:54:43, 12.66s/it] 71%|███████▏  | 9155/12825 [32:46:12<12:53:33, 12.65s/it] 71%|███████▏  | 9156/12825 [32:46:25<12:53:03, 12.64s/it] 71%|███████▏  | 9157/12825 [32:46:37<12:53:09, 12.65s/it] 71%|███████▏  | 9158/12825 [32:46:50<12:52:54, 12.65s/it] 71%|███████▏  | 9159/12825 [32:47:03<12:52:44, 12.65s/it] 71%|███████▏  | 9160/12825 [32:47:15<12:52:17, 12.64s/it] 71%|███████▏  | 9161/12825 [32:47:28<12:51:45, 12.64s/it] 71%|███████▏  | 9162/12825 [32:47:40<12:51:07, 12.63s/it] 71%|███████▏  | 9163/12825 [32:47:53<12:51:07, 12.63s/it] 71%|███████▏  | 9164/12825 [32:48:14<15:12:35, 14.96s/it] 71%|███████▏  | 9165/12825 [32:48:26<14:29:55, 14.26s/it] 71%|███████▏  | 9166/12825 [32:48:39<13:59:48, 13.77s/it] 71%|███████▏  | 9167/12825 [32:48:51<13:38:37, 13.43s/it] 71%|███████▏  | 9168/12825 [32:49:04<13:24:07, 13.19s/it] 71%|███████▏  | 9169/12825 [32:49:17<13:13:52, 13.03s/it] 72%|███████▏  | 9170/12825 [32:49:29<13:07:00, 12.92s/it] 72%|███████▏  | 9171/12825 [32:49:42<13:02:00, 12.84s/it] 72%|███████▏  | 9172/12825 [32:49:55<12:58:01, 12.78s/it] 72%|███████▏  | 9173/12825 [32:50:07<12:54:34, 12.73s/it] 72%|███████▏  | 9174/12825 [32:50:20<12:52:13, 12.69s/it] 72%|███████▏  | 9175/12825 [32:50:32<12:50:29, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120440.61lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103695.54lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9175
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9175/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9175/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9150] due to args.save_total_limit
 72%|███████▏  | 9176/12825 [32:50:45<12:55:43, 12.76s/it] 72%|███████▏  | 9177/12825 [32:50:58<12:53:08, 12.72s/it] 72%|███████▏  | 9178/12825 [32:51:11<12:51:21, 12.69s/it] 72%|███████▏  | 9179/12825 [32:51:23<12:49:16, 12.66s/it] 72%|███████▏  | 9180/12825 [32:51:36<12:48:15, 12.65s/it] 72%|███████▏  | 9181/12825 [32:51:48<12:47:22, 12.64s/it] 72%|███████▏  | 9182/12825 [32:52:01<12:46:54, 12.63s/it] 72%|███████▏  | 9183/12825 [32:52:14<12:48:34, 12.66s/it] 72%|███████▏  | 9184/12825 [32:52:26<12:47:43, 12.65s/it] 72%|███████▏  | 9185/12825 [32:52:39<12:46:59, 12.64s/it] 72%|███████▏  | 9186/12825 [32:52:52<12:46:56, 12.65s/it] 72%|███████▏  | 9187/12825 [32:53:04<12:46:43, 12.65s/it] 72%|███████▏  | 9188/12825 [32:53:17<12:46:19, 12.64s/it] 72%|███████▏  | 9189/12825 [32:53:30<12:46:42, 12.65s/it] 72%|███████▏  | 9190/12825 [32:53:42<12:46:09, 12.65s/it] 72%|███████▏  | 9191/12825 [32:53:55<12:45:52, 12.65s/it] 72%|███████▏  | 9192/12825 [32:54:08<12:45:26, 12.64s/it] 72%|███████▏  | 9193/12825 [32:54:20<12:45:07, 12.64s/it] 72%|███████▏  | 9194/12825 [32:54:33<12:44:03, 12.63s/it] 72%|███████▏  | 9195/12825 [32:54:45<12:44:15, 12.63s/it] 72%|███████▏  | 9196/12825 [32:55:06<15:01:22, 14.90s/it] 72%|███████▏  | 9197/12825 [32:55:18<14:19:43, 14.22s/it] 72%|███████▏  | 9198/12825 [32:55:31<13:50:01, 13.73s/it] 72%|███████▏  | 9199/12825 [32:55:44<13:29:43, 13.40s/it] 72%|███████▏  | 9200/12825 [32:55:56<13:14:45, 13.15s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120558.82lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103811.03lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9200
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9200/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9200/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9175] due to args.save_total_limit
 72%|███████▏  | 9201/12825 [32:56:09<13:10:37, 13.09s/it] 72%|███████▏  | 9202/12825 [32:56:22<13:02:18, 12.96s/it] 72%|███████▏  | 9203/12825 [32:56:34<12:55:47, 12.85s/it] 72%|███████▏  | 9204/12825 [32:56:47<12:50:52, 12.77s/it] 72%|███████▏  | 9205/12825 [32:57:00<12:50:47, 12.78s/it] 72%|███████▏  | 9206/12825 [32:57:12<12:47:14, 12.72s/it] 72%|███████▏  | 9207/12825 [32:57:25<12:44:58, 12.69s/it] 72%|███████▏  | 9208/12825 [32:57:37<12:43:19, 12.66s/it] 72%|███████▏  | 9209/12825 [32:57:50<12:41:46, 12.64s/it] 72%|███████▏  | 9210/12825 [32:58:03<12:41:01, 12.63s/it] 72%|███████▏  | 9211/12825 [32:58:15<12:39:46, 12.61s/it] 72%|███████▏  | 9212/12825 [32:58:28<12:39:18, 12.61s/it] 72%|███████▏  | 9213/12825 [32:58:40<12:38:51, 12.61s/it] 72%|███████▏  | 9214/12825 [32:58:53<12:38:01, 12.60s/it] 72%|███████▏  | 9215/12825 [32:59:06<12:38:01, 12.60s/it] 72%|███████▏  | 9216/12825 [32:59:18<12:36:56, 12.58s/it] 72%|███████▏  | 9217/12825 [32:59:31<12:36:41, 12.58s/it] 72%|███████▏  | 9218/12825 [32:59:43<12:37:21, 12.60s/it] 72%|███████▏  | 9219/12825 [32:59:56<12:36:33, 12.59s/it] 72%|███████▏  | 9220/12825 [33:00:09<12:36:51, 12.60s/it] 72%|███████▏  | 9221/12825 [33:00:21<12:36:47, 12.60s/it] 72%|███████▏  | 9222/12825 [33:00:34<12:36:48, 12.60s/it] 72%|███████▏  | 9223/12825 [33:00:46<12:36:56, 12.61s/it] 72%|███████▏  | 9224/12825 [33:00:59<12:36:54, 12.61s/it] 72%|███████▏  | 9225/12825 [33:01:12<12:36:30, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120375.96lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103693.54lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9225
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9225/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9225/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9200] due to args.save_total_limit
 72%|███████▏  | 9226/12825 [33:01:25<12:44:17, 12.74s/it] 72%|███████▏  | 9227/12825 [33:01:37<12:40:46, 12.69s/it] 72%|███████▏  | 9228/12825 [33:01:50<12:39:50, 12.67s/it] 72%|███████▏  | 9229/12825 [33:02:10<14:54:33, 14.93s/it] 72%|███████▏  | 9230/12825 [33:02:23<14:12:12, 14.22s/it] 72%|███████▏  | 9231/12825 [33:02:35<13:42:36, 13.73s/it] 72%|███████▏  | 9232/12825 [33:02:48<13:22:14, 13.40s/it] 72%|███████▏  | 9233/12825 [33:02:56<11:43:41, 11.75s/it] 72%|███████▏  | 9234/12825 [33:02:57<8:27:13,  8.47s/it]  72%|███████▏  | 9235/12825 [33:03:22<13:33:57, 13.60s/it] 72%|███████▏  | 9236/12825 [33:03:35<13:16:20, 13.31s/it] 72%|███████▏  | 9237/12825 [33:03:47<13:03:53, 13.11s/it] 72%|███████▏  | 9238/12825 [33:04:00<12:55:04, 12.96s/it] 72%|███████▏  | 9239/12825 [33:04:13<12:49:08, 12.87s/it] 72%|███████▏  | 9240/12825 [33:04:25<12:44:14, 12.79s/it] 72%|███████▏  | 9241/12825 [33:04:38<12:40:53, 12.74s/it] 72%|███████▏  | 9242/12825 [33:04:51<12:38:35, 12.70s/it] 72%|███████▏  | 9243/12825 [33:05:03<12:36:38, 12.67s/it] 72%|███████▏  | 9244/12825 [33:05:16<12:35:19, 12.66s/it] 72%|███████▏  | 9245/12825 [33:05:28<12:34:48, 12.65s/it] 72%|███████▏  | 9246/12825 [33:05:41<12:34:02, 12.64s/it] 72%|███████▏  | 9247/12825 [33:05:54<12:33:06, 12.63s/it] 72%|███████▏  | 9248/12825 [33:06:06<12:32:06, 12.62s/it] 72%|███████▏  | 9249/12825 [33:06:19<12:32:01, 12.62s/it] 72%|███████▏  | 9250/12825 [33:06:31<12:32:08, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120404.75lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103677.98lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9250
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9250/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9250/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9225] due to args.save_total_limit
 72%|███████▏  | 9251/12825 [33:06:44<12:37:56, 12.72s/it] 72%|███████▏  | 9252/12825 [33:06:57<12:35:25, 12.69s/it] 72%|███████▏  | 9253/12825 [33:07:10<12:34:31, 12.67s/it] 72%|███████▏  | 9254/12825 [33:07:22<12:33:40, 12.66s/it] 72%|███████▏  | 9255/12825 [33:07:35<12:32:46, 12.65s/it] 72%|███████▏  | 9256/12825 [33:07:48<12:32:21, 12.65s/it] 72%|███████▏  | 9257/12825 [33:08:00<12:32:20, 12.65s/it] 72%|███████▏  | 9258/12825 [33:08:13<12:32:44, 12.66s/it] 72%|███████▏  | 9259/12825 [33:08:26<12:33:19, 12.68s/it] 72%|███████▏  | 9260/12825 [33:08:38<12:33:31, 12.68s/it] 72%|███████▏  | 9261/12825 [33:08:51<12:32:30, 12.67s/it] 72%|███████▏  | 9262/12825 [33:09:11<14:44:36, 14.90s/it] 72%|███████▏  | 9263/12825 [33:09:24<14:04:32, 14.23s/it] 72%|███████▏  | 9264/12825 [33:09:36<13:35:44, 13.74s/it] 72%|███████▏  | 9265/12825 [33:09:49<13:15:41, 13.41s/it] 72%|███████▏  | 9266/12825 [33:10:02<13:01:20, 13.17s/it] 72%|███████▏  | 9267/12825 [33:10:14<12:51:06, 13.00s/it] 72%|███████▏  | 9268/12825 [33:10:27<12:44:37, 12.90s/it] 72%|███████▏  | 9269/12825 [33:10:39<12:39:02, 12.81s/it] 72%|███████▏  | 9270/12825 [33:10:52<12:35:53, 12.76s/it] 72%|███████▏  | 9271/12825 [33:11:05<12:33:21, 12.72s/it] 72%|███████▏  | 9272/12825 [33:11:17<12:32:13, 12.70s/it] 72%|███████▏  | 9273/12825 [33:11:30<12:30:39, 12.68s/it] 72%|███████▏  | 9274/12825 [33:11:43<12:29:51, 12.67s/it] 72%|███████▏  | 9275/12825 [33:11:55<12:29:01, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 118003.40lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101910.68lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9275
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9275/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9275/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9250] due to args.save_total_limit
 72%|███████▏  | 9276/12825 [33:12:08<12:34:34, 12.76s/it] 72%|███████▏  | 9277/12825 [33:12:21<12:31:55, 12.72s/it] 72%|███████▏  | 9278/12825 [33:12:34<12:30:14, 12.69s/it] 72%|███████▏  | 9279/12825 [33:12:46<12:28:56, 12.67s/it] 72%|███████▏  | 9280/12825 [33:12:59<12:27:57, 12.66s/it] 72%|███████▏  | 9281/12825 [33:13:11<12:26:49, 12.64s/it] 72%|███████▏  | 9282/12825 [33:13:24<12:26:07, 12.64s/it] 72%|███████▏  | 9283/12825 [33:13:37<12:25:59, 12.64s/it] 72%|███████▏  | 9284/12825 [33:13:49<12:25:34, 12.63s/it] 72%|███████▏  | 9285/12825 [33:14:02<12:24:46, 12.62s/it] 72%|███████▏  | 9286/12825 [33:14:15<12:24:42, 12.63s/it] 72%|███████▏  | 9287/12825 [33:14:27<12:25:00, 12.63s/it] 72%|███████▏  | 9288/12825 [33:14:40<12:24:39, 12.63s/it] 72%|███████▏  | 9289/12825 [33:14:52<12:24:05, 12.63s/it] 72%|███████▏  | 9290/12825 [33:15:05<12:23:10, 12.61s/it] 72%|███████▏  | 9291/12825 [33:15:18<12:22:39, 12.61s/it] 72%|███████▏  | 9292/12825 [33:15:30<12:23:22, 12.62s/it] 72%|███████▏  | 9293/12825 [33:15:43<12:22:58, 12.62s/it] 72%|███████▏  | 9294/12825 [33:16:03<14:35:26, 14.88s/it] 72%|███████▏  | 9295/12825 [33:16:16<13:55:31, 14.20s/it] 72%|███████▏  | 9296/12825 [33:16:28<13:26:50, 13.72s/it] 72%|███████▏  | 9297/12825 [33:16:41<13:07:23, 13.39s/it] 72%|███████▏  | 9298/12825 [33:16:53<12:53:46, 13.16s/it] 73%|███████▎  | 9299/12825 [33:17:06<12:44:12, 13.00s/it] 73%|███████▎  | 9300/12825 [33:17:19<12:38:25, 12.91s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120439.20lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103680.35lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9300
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9300/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9300/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9275] due to args.save_total_limit
 73%|███████▎  | 9301/12825 [33:17:32<12:38:24, 12.91s/it] 73%|███████▎  | 9302/12825 [33:17:44<12:32:35, 12.82s/it] 73%|███████▎  | 9303/12825 [33:17:57<12:28:53, 12.76s/it] 73%|███████▎  | 9304/12825 [33:18:10<12:26:05, 12.71s/it] 73%|███████▎  | 9305/12825 [33:18:22<12:24:16, 12.69s/it] 73%|███████▎  | 9306/12825 [33:18:35<12:22:46, 12.66s/it] 73%|███████▎  | 9307/12825 [33:18:47<12:23:01, 12.67s/it] 73%|███████▎  | 9308/12825 [33:19:00<12:22:46, 12.67s/it] 73%|███████▎  | 9309/12825 [33:19:13<12:21:15, 12.65s/it] 73%|███████▎  | 9310/12825 [33:19:25<12:20:13, 12.64s/it] 73%|███████▎  | 9311/12825 [33:19:38<12:19:55, 12.63s/it] 73%|███████▎  | 9312/12825 [33:19:51<12:19:20, 12.63s/it] 73%|███████▎  | 9313/12825 [33:20:03<12:20:03, 12.64s/it] 73%|███████▎  | 9314/12825 [33:20:16<12:19:35, 12.64s/it] 73%|███████▎  | 9315/12825 [33:20:29<12:18:52, 12.63s/it] 73%|███████▎  | 9316/12825 [33:20:41<12:18:50, 12.63s/it] 73%|███████▎  | 9317/12825 [33:20:54<12:18:35, 12.63s/it] 73%|███████▎  | 9318/12825 [33:21:06<12:18:49, 12.64s/it] 73%|███████▎  | 9319/12825 [33:21:19<12:17:27, 12.62s/it] 73%|███████▎  | 9320/12825 [33:21:32<12:17:09, 12.62s/it] 73%|███████▎  | 9321/12825 [33:21:44<12:17:00, 12.62s/it] 73%|███████▎  | 9322/12825 [33:21:57<12:16:30, 12.62s/it] 73%|███████▎  | 9323/12825 [33:22:10<12:17:11, 12.63s/it] 73%|███████▎  | 9324/12825 [33:22:22<12:16:30, 12.62s/it] 73%|███████▎  | 9325/12825 [33:22:35<12:16:34, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120324.54lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103576.23lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9325
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9325/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9325/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9300] due to args.save_total_limit
 73%|███████▎  | 9326/12825 [33:22:55<14:31:55, 14.95s/it] 73%|███████▎  | 9327/12825 [33:23:08<13:50:32, 14.25s/it] 73%|███████▎  | 9328/12825 [33:23:20<13:21:18, 13.75s/it] 73%|███████▎  | 9329/12825 [33:23:33<13:00:12, 13.39s/it] 73%|███████▎  | 9330/12825 [33:23:45<12:45:34, 13.14s/it] 73%|███████▎  | 9331/12825 [33:23:58<12:35:16, 12.97s/it] 73%|███████▎  | 9332/12825 [33:24:11<12:27:58, 12.85s/it] 73%|███████▎  | 9333/12825 [33:24:23<12:23:07, 12.77s/it] 73%|███████▎  | 9334/12825 [33:24:36<12:19:51, 12.72s/it] 73%|███████▎  | 9335/12825 [33:24:48<12:18:03, 12.69s/it] 73%|███████▎  | 9336/12825 [33:25:01<12:16:35, 12.67s/it] 73%|███████▎  | 9337/12825 [33:25:14<12:15:12, 12.65s/it] 73%|███████▎  | 9338/12825 [33:25:26<12:13:42, 12.62s/it] 73%|███████▎  | 9339/12825 [33:25:39<12:13:01, 12.62s/it] 73%|███████▎  | 9340/12825 [33:25:51<12:12:05, 12.60s/it] 73%|███████▎  | 9341/12825 [33:26:04<12:11:30, 12.60s/it] 73%|███████▎  | 9342/12825 [33:26:17<12:12:56, 12.63s/it] 73%|███████▎  | 9343/12825 [33:26:29<12:12:07, 12.62s/it] 73%|███████▎  | 9344/12825 [33:26:42<12:10:28, 12.59s/it] 73%|███████▎  | 9345/12825 [33:26:54<12:09:11, 12.57s/it] 73%|███████▎  | 9346/12825 [33:27:07<12:08:37, 12.57s/it] 73%|███████▎  | 9347/12825 [33:27:19<12:08:39, 12.57s/it] 73%|███████▎  | 9348/12825 [33:27:32<12:08:48, 12.58s/it] 73%|███████▎  | 9349/12825 [33:27:45<12:08:50, 12.58s/it] 73%|███████▎  | 9350/12825 [33:27:57<12:08:36, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120438.56lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103789.72lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9350
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9350/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9350/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9325] due to args.save_total_limit
 73%|███████▎  | 9351/12825 [33:28:10<12:14:34, 12.69s/it] 73%|███████▎  | 9352/12825 [33:28:23<12:12:30, 12.66s/it] 73%|███████▎  | 9353/12825 [33:28:35<12:11:23, 12.64s/it] 73%|███████▎  | 9354/12825 [33:28:48<12:10:22, 12.63s/it] 73%|███████▎  | 9355/12825 [33:29:00<12:08:50, 12.60s/it] 73%|███████▎  | 9356/12825 [33:29:13<12:08:33, 12.60s/it] 73%|███████▎  | 9357/12825 [33:29:26<12:08:06, 12.60s/it] 73%|███████▎  | 9358/12825 [33:29:38<12:07:14, 12.59s/it] 73%|███████▎  | 9359/12825 [33:29:58<14:15:20, 14.81s/it] 73%|███████▎  | 9360/12825 [33:30:11<13:37:34, 14.16s/it] 73%|███████▎  | 9361/12825 [33:30:23<13:10:30, 13.69s/it] 73%|███████▎  | 9362/12825 [33:30:36<12:51:51, 13.37s/it] 73%|███████▎  | 9363/12825 [33:30:49<12:38:22, 13.14s/it] 73%|███████▎  | 9364/12825 [33:31:01<12:29:06, 12.99s/it] 73%|███████▎  | 9365/12825 [33:31:14<12:21:55, 12.87s/it] 73%|███████▎  | 9366/12825 [33:31:26<12:17:36, 12.79s/it] 73%|███████▎  | 9367/12825 [33:31:39<12:14:37, 12.75s/it] 73%|███████▎  | 9368/12825 [33:31:52<12:13:58, 12.74s/it] 73%|███████▎  | 9369/12825 [33:32:04<12:11:05, 12.69s/it] 73%|███████▎  | 9370/12825 [33:32:17<12:09:29, 12.67s/it] 73%|███████▎  | 9371/12825 [33:32:30<12:09:27, 12.67s/it] 73%|███████▎  | 9372/12825 [33:32:42<12:07:57, 12.65s/it] 73%|███████▎  | 9373/12825 [33:32:55<12:06:55, 12.63s/it] 73%|███████▎  | 9374/12825 [33:33:08<12:06:17, 12.63s/it] 73%|███████▎  | 9375/12825 [33:33:20<12:05:45, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120482.64lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103705.51lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9375
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9375/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9375/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9350] due to args.save_total_limit
 73%|███████▎  | 9376/12825 [33:33:33<12:10:52, 12.71s/it] 73%|███████▎  | 9377/12825 [33:33:46<12:08:43, 12.68s/it] 73%|███████▎  | 9378/12825 [33:33:58<12:07:40, 12.67s/it] 73%|███████▎  | 9379/12825 [33:34:11<12:06:06, 12.64s/it] 73%|███████▎  | 9380/12825 [33:34:23<12:05:25, 12.63s/it] 73%|███████▎  | 9381/12825 [33:34:36<12:04:58, 12.63s/it] 73%|███████▎  | 9382/12825 [33:34:49<12:04:09, 12.62s/it] 73%|███████▎  | 9383/12825 [33:35:01<12:03:34, 12.61s/it] 73%|███████▎  | 9384/12825 [33:35:14<12:03:32, 12.62s/it] 73%|███████▎  | 9385/12825 [33:35:27<12:03:19, 12.62s/it] 73%|███████▎  | 9386/12825 [33:35:39<12:02:48, 12.61s/it] 73%|███████▎  | 9387/12825 [33:35:52<12:02:48, 12.61s/it] 73%|███████▎  | 9388/12825 [33:36:04<12:02:32, 12.61s/it] 73%|███████▎  | 9389/12825 [33:36:17<12:02:25, 12.62s/it] 73%|███████▎  | 9390/12825 [33:36:30<12:01:38, 12.61s/it] 73%|███████▎  | 9391/12825 [33:36:50<14:13:04, 14.91s/it] 73%|███████▎  | 9392/12825 [33:37:02<13:34:10, 14.23s/it] 73%|███████▎  | 9393/12825 [33:37:15<13:06:38, 13.75s/it] 73%|███████▎  | 9394/12825 [33:37:28<12:47:20, 13.42s/it] 73%|███████▎  | 9395/12825 [33:37:40<12:32:53, 13.17s/it] 73%|███████▎  | 9396/12825 [33:37:53<12:23:30, 13.01s/it] 73%|███████▎  | 9397/12825 [33:38:06<12:16:18, 12.89s/it] 73%|███████▎  | 9398/12825 [33:38:18<12:11:17, 12.80s/it] 73%|███████▎  | 9399/12825 [33:38:31<12:07:31, 12.74s/it] 73%|███████▎  | 9400/12825 [33:38:43<12:05:22, 12.71s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120436.12lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103636.23lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9400
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9400/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9400/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9375] due to args.save_total_limit
 73%|███████▎  | 9401/12825 [33:38:56<12:08:29, 12.77s/it] 73%|███████▎  | 9402/12825 [33:39:09<12:05:15, 12.71s/it] 73%|███████▎  | 9403/12825 [33:39:22<12:02:55, 12.68s/it] 73%|███████▎  | 9404/12825 [33:39:34<12:01:52, 12.66s/it] 73%|███████▎  | 9405/12825 [33:39:47<12:00:05, 12.63s/it] 73%|███████▎  | 9406/12825 [33:39:59<11:59:46, 12.63s/it] 73%|███████▎  | 9407/12825 [33:40:12<11:59:42, 12.63s/it] 73%|███████▎  | 9408/12825 [33:40:25<11:59:27, 12.63s/it] 73%|███████▎  | 9409/12825 [33:40:37<11:59:54, 12.64s/it] 73%|███████▎  | 9410/12825 [33:40:50<11:59:14, 12.64s/it] 73%|███████▎  | 9411/12825 [33:41:03<11:59:39, 12.65s/it] 73%|███████▎  | 9412/12825 [33:41:15<11:59:23, 12.65s/it] 73%|███████▎  | 9413/12825 [33:41:28<11:58:59, 12.64s/it] 73%|███████▎  | 9414/12825 [33:41:41<11:59:25, 12.65s/it] 73%|███████▎  | 9415/12825 [33:41:53<11:59:10, 12.65s/it] 73%|███████▎  | 9416/12825 [33:42:06<11:58:53, 12.65s/it] 73%|███████▎  | 9417/12825 [33:42:18<11:58:17, 12.65s/it] 73%|███████▎  | 9418/12825 [33:42:31<11:58:58, 12.66s/it] 73%|███████▎  | 9419/12825 [33:42:44<11:58:58, 12.67s/it] 73%|███████▎  | 9420/12825 [33:42:57<11:59:30, 12.68s/it] 73%|███████▎  | 9421/12825 [33:43:09<11:59:43, 12.69s/it] 73%|███████▎  | 9422/12825 [33:43:22<11:59:25, 12.68s/it] 73%|███████▎  | 9423/12825 [33:43:42<14:06:11, 14.92s/it] 73%|███████▎  | 9424/12825 [33:43:55<13:27:06, 14.24s/it] 73%|███████▎  | 9425/12825 [33:44:07<12:59:51, 13.76s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120486.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103702.47lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9425
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9425/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9425/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9400] due to args.save_total_limit
 73%|███████▎  | 9426/12825 [33:44:20<12:45:59, 13.52s/it] 74%|███████▎  | 9427/12825 [33:44:33<12:30:45, 13.26s/it] 74%|███████▎  | 9428/12825 [33:44:46<12:20:02, 13.07s/it] 74%|███████▎  | 9429/12825 [33:44:58<12:12:41, 12.94s/it] 74%|███████▎  | 9430/12825 [33:45:11<12:07:25, 12.86s/it] 74%|███████▎  | 9431/12825 [33:45:24<12:03:30, 12.79s/it] 74%|███████▎  | 9432/12825 [33:45:36<12:00:54, 12.75s/it] 74%|███████▎  | 9433/12825 [33:45:49<12:01:58, 12.77s/it] 74%|███████▎  | 9434/12825 [33:46:02<11:59:13, 12.73s/it] 74%|███████▎  | 9435/12825 [33:46:14<11:57:24, 12.70s/it] 74%|███████▎  | 9436/12825 [33:46:27<11:55:08, 12.66s/it] 74%|███████▎  | 9437/12825 [33:46:39<11:54:37, 12.66s/it] 74%|███████▎  | 9438/12825 [33:46:52<11:53:08, 12.63s/it] 74%|███████▎  | 9439/12825 [33:47:05<11:52:45, 12.63s/it] 74%|███████▎  | 9440/12825 [33:47:17<11:52:48, 12.63s/it] 74%|███████▎  | 9441/12825 [33:47:30<11:53:25, 12.65s/it] 74%|███████▎  | 9442/12825 [33:47:43<11:53:10, 12.65s/it] 74%|███████▎  | 9443/12825 [33:47:55<11:54:47, 12.68s/it] 74%|███████▎  | 9444/12825 [33:48:08<11:54:04, 12.67s/it] 74%|███████▎  | 9445/12825 [33:48:21<11:53:22, 12.66s/it] 74%|███████▎  | 9446/12825 [33:48:33<11:52:23, 12.65s/it] 74%|███████▎  | 9447/12825 [33:48:46<11:51:42, 12.64s/it] 74%|███████▎  | 9448/12825 [33:48:59<11:51:32, 12.64s/it] 74%|███████▎  | 9449/12825 [33:49:11<11:50:38, 12.63s/it] 74%|███████▎  | 9450/12825 [33:49:24<11:50:21, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120228.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103561.74lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9450
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9450/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9450/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-8600] due to args.save_total_limit
 74%|███████▎  | 9451/12825 [33:49:37<11:55:44, 12.73s/it] 74%|███████▎  | 9452/12825 [33:49:49<11:54:07, 12.70s/it] 74%|███████▎  | 9453/12825 [33:50:02<11:52:28, 12.68s/it] 74%|███████▎  | 9454/12825 [33:50:15<11:51:49, 12.67s/it] 74%|███████▎  | 9455/12825 [33:50:35<14:06:09, 15.07s/it] 74%|███████▎  | 9456/12825 [33:50:48<13:24:29, 14.33s/it] 74%|███████▎  | 9457/12825 [33:51:01<12:54:29, 13.80s/it] 74%|███████▎  | 9458/12825 [33:51:13<12:34:02, 13.44s/it] 74%|███████▍  | 9459/12825 [33:51:26<12:20:07, 13.19s/it] 74%|███████▍  | 9460/12825 [33:51:38<12:10:07, 13.02s/it] 74%|███████▍  | 9461/12825 [33:51:51<12:03:10, 12.90s/it] 74%|███████▍  | 9462/12825 [33:52:04<11:58:10, 12.81s/it] 74%|███████▍  | 9463/12825 [33:52:16<11:55:09, 12.76s/it] 74%|███████▍  | 9464/12825 [33:52:29<11:52:23, 12.72s/it] 74%|███████▍  | 9465/12825 [33:52:41<11:50:52, 12.69s/it] 74%|███████▍  | 9466/12825 [33:52:54<11:49:32, 12.67s/it] 74%|███████▍  | 9467/12825 [33:53:07<11:48:29, 12.66s/it] 74%|███████▍  | 9468/12825 [33:53:19<11:47:54, 12.65s/it] 74%|███████▍  | 9469/12825 [33:53:32<11:48:10, 12.66s/it] 74%|███████▍  | 9470/12825 [33:53:45<11:47:34, 12.65s/it] 74%|███████▍  | 9471/12825 [33:53:57<11:47:44, 12.66s/it] 74%|███████▍  | 9472/12825 [33:54:10<11:46:26, 12.64s/it] 74%|███████▍  | 9473/12825 [33:54:23<11:45:58, 12.64s/it] 74%|███████▍  | 9474/12825 [33:54:35<11:45:14, 12.63s/it] 74%|███████▍  | 9475/12825 [33:54:48<11:45:02, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120212.91lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103521.69lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9475
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9475/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9475/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9425] due to args.save_total_limit
 74%|███████▍  | 9476/12825 [33:55:01<11:50:22, 12.73s/it] 74%|███████▍  | 9477/12825 [33:55:13<11:48:08, 12.69s/it] 74%|███████▍  | 9478/12825 [33:55:26<11:46:21, 12.66s/it] 74%|███████▍  | 9479/12825 [33:55:39<11:46:10, 12.66s/it] 74%|███████▍  | 9480/12825 [33:55:51<11:45:37, 12.66s/it] 74%|███████▍  | 9481/12825 [33:56:04<11:44:58, 12.65s/it] 74%|███████▍  | 9482/12825 [33:56:17<11:44:24, 12.64s/it] 74%|███████▍  | 9483/12825 [33:56:29<11:44:04, 12.64s/it] 74%|███████▍  | 9484/12825 [33:56:42<11:43:52, 12.64s/it] 74%|███████▍  | 9485/12825 [33:56:54<11:43:22, 12.64s/it] 74%|███████▍  | 9486/12825 [33:57:07<11:43:01, 12.63s/it] 74%|███████▍  | 9487/12825 [33:57:20<11:42:50, 12.63s/it] 74%|███████▍  | 9488/12825 [33:57:40<13:47:53, 14.89s/it] 74%|███████▍  | 9489/12825 [33:57:52<13:09:19, 14.20s/it] 74%|███████▍  | 9490/12825 [33:58:05<12:41:44, 13.70s/it] 74%|███████▍  | 9491/12825 [33:58:18<12:22:54, 13.37s/it] 74%|███████▍  | 9492/12825 [33:58:30<12:10:05, 13.14s/it] 74%|███████▍  | 9493/12825 [33:58:43<12:01:00, 12.98s/it] 74%|███████▍  | 9494/12825 [33:58:55<11:54:44, 12.87s/it] 74%|███████▍  | 9495/12825 [33:59:08<11:50:27, 12.80s/it] 74%|███████▍  | 9496/12825 [33:59:21<11:47:24, 12.75s/it] 74%|███████▍  | 9497/12825 [33:59:33<11:45:05, 12.71s/it] 74%|███████▍  | 9498/12825 [33:59:46<11:44:01, 12.70s/it] 74%|███████▍  | 9499/12825 [33:59:59<11:42:00, 12.66s/it] 74%|███████▍  | 9500/12825 [34:00:11<11:41:24, 12.66s/it]                                                           74%|███████▍  | 9500/12825 [34:00:11<11:41:24, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120148.12lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103328.81lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9500
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9500/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9500/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9475] due to args.save_total_limit
 74%|███████▍  | 9501/12825 [34:00:24<11:46:57, 12.76s/it] 74%|███████▍  | 9502/12825 [34:00:37<11:44:33, 12.72s/it] 74%|███████▍  | 9503/12825 [34:00:49<11:42:50, 12.69s/it] 74%|███████▍  | 9504/12825 [34:01:02<11:41:29, 12.67s/it] 74%|███████▍  | 9505/12825 [34:01:15<11:40:49, 12.67s/it] 74%|███████▍  | 9506/12825 [34:01:27<11:39:36, 12.65s/it] 74%|███████▍  | 9507/12825 [34:01:40<11:38:56, 12.64s/it] 74%|███████▍  | 9508/12825 [34:01:53<11:38:00, 12.63s/it] 74%|███████▍  | 9509/12825 [34:02:05<11:37:57, 12.63s/it] 74%|███████▍  | 9510/12825 [34:02:18<11:37:43, 12.63s/it] 74%|███████▍  | 9511/12825 [34:02:30<11:37:07, 12.62s/it] 74%|███████▍  | 9512/12825 [34:02:43<11:36:56, 12.62s/it] 74%|███████▍  | 9513/12825 [34:02:56<11:37:05, 12.63s/it] 74%|███████▍  | 9514/12825 [34:03:08<11:37:03, 12.63s/it] 74%|███████▍  | 9515/12825 [34:03:21<11:36:40, 12.63s/it] 74%|███████▍  | 9516/12825 [34:03:34<11:36:39, 12.63s/it] 74%|███████▍  | 9517/12825 [34:03:46<11:35:28, 12.61s/it] 74%|███████▍  | 9518/12825 [34:03:59<11:35:28, 12.62s/it] 74%|███████▍  | 9519/12825 [34:04:11<11:35:22, 12.62s/it] 74%|███████▍  | 9520/12825 [34:04:32<13:39:12, 14.87s/it] 74%|███████▍  | 9521/12825 [34:04:44<13:01:29, 14.19s/it] 74%|███████▍  | 9522/12825 [34:04:57<12:35:30, 13.72s/it] 74%|███████▍  | 9523/12825 [34:05:09<12:16:44, 13.39s/it] 74%|███████▍  | 9524/12825 [34:05:22<12:04:06, 13.16s/it] 74%|███████▍  | 9525/12825 [34:05:35<11:54:36, 12.99s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120316.10lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103556.91lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9525
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9525/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9525/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9500] due to args.save_total_limit
 74%|███████▍  | 9526/12825 [34:05:48<11:53:59, 12.99s/it] 74%|███████▍  | 9527/12825 [34:06:00<11:47:28, 12.87s/it] 74%|███████▍  | 9528/12825 [34:06:13<11:43:10, 12.80s/it] 74%|███████▍  | 9529/12825 [34:06:25<11:39:51, 12.74s/it] 74%|███████▍  | 9530/12825 [34:06:38<11:37:53, 12.71s/it] 74%|███████▍  | 9531/12825 [34:06:51<11:36:10, 12.68s/it] 74%|███████▍  | 9532/12825 [34:07:03<11:35:56, 12.68s/it] 74%|███████▍  | 9533/12825 [34:07:16<11:35:10, 12.67s/it] 74%|███████▍  | 9534/12825 [34:07:29<11:34:25, 12.66s/it] 74%|███████▍  | 9535/12825 [34:07:41<11:34:17, 12.66s/it] 74%|███████▍  | 9536/12825 [34:07:54<11:33:40, 12.65s/it] 74%|███████▍  | 9537/12825 [34:08:07<11:33:04, 12.65s/it] 74%|███████▍  | 9538/12825 [34:08:19<11:32:55, 12.65s/it] 74%|███████▍  | 9539/12825 [34:08:32<11:31:57, 12.63s/it] 74%|███████▍  | 9540/12825 [34:08:45<11:33:04, 12.66s/it] 74%|███████▍  | 9541/12825 [34:08:57<11:31:54, 12.64s/it] 74%|███████▍  | 9542/12825 [34:09:10<11:31:31, 12.64s/it] 74%|███████▍  | 9543/12825 [34:09:22<11:30:41, 12.63s/it] 74%|███████▍  | 9544/12825 [34:09:35<11:32:00, 12.65s/it] 74%|███████▍  | 9545/12825 [34:09:48<11:31:15, 12.64s/it] 74%|███████▍  | 9546/12825 [34:10:00<11:30:45, 12.64s/it] 74%|███████▍  | 9547/12825 [34:10:13<11:30:14, 12.63s/it] 74%|███████▍  | 9548/12825 [34:10:26<11:30:06, 12.64s/it] 74%|███████▍  | 9549/12825 [34:10:38<11:30:23, 12.64s/it] 74%|███████▍  | 9550/12825 [34:10:51<11:30:17, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120318.53lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103452.37lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9550
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9550/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9550/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9525] due to args.save_total_limit
 74%|███████▍  | 9551/12825 [34:11:04<11:35:03, 12.74s/it] 74%|███████▍  | 9552/12825 [34:11:16<11:33:04, 12.71s/it] 74%|███████▍  | 9553/12825 [34:11:37<13:34:35, 14.94s/it] 74%|███████▍  | 9554/12825 [34:11:49<12:56:22, 14.24s/it] 75%|███████▍  | 9555/12825 [34:12:02<12:30:34, 13.77s/it] 75%|███████▍  | 9556/12825 [34:12:15<12:12:09, 13.44s/it] 75%|███████▍  | 9557/12825 [34:12:27<11:59:40, 13.21s/it] 75%|███████▍  | 9558/12825 [34:12:40<11:50:13, 13.04s/it] 75%|███████▍  | 9559/12825 [34:12:53<11:43:09, 12.92s/it] 75%|███████▍  | 9560/12825 [34:13:05<11:38:17, 12.83s/it] 75%|███████▍  | 9561/12825 [34:13:18<11:35:00, 12.78s/it] 75%|███████▍  | 9562/12825 [34:13:30<11:32:41, 12.74s/it] 75%|███████▍  | 9563/12825 [34:13:43<11:30:47, 12.71s/it] 75%|███████▍  | 9564/12825 [34:13:56<11:29:09, 12.68s/it] 75%|███████▍  | 9565/12825 [34:14:08<11:28:39, 12.67s/it] 75%|███████▍  | 9566/12825 [34:14:21<11:27:12, 12.65s/it] 75%|███████▍  | 9567/12825 [34:14:34<11:26:23, 12.64s/it] 75%|███████▍  | 9568/12825 [34:14:46<11:26:12, 12.64s/it] 75%|███████▍  | 9569/12825 [34:14:59<11:25:28, 12.63s/it] 75%|███████▍  | 9570/12825 [34:15:11<11:25:07, 12.63s/it] 75%|███████▍  | 9571/12825 [34:15:24<11:24:45, 12.63s/it] 75%|███████▍  | 9572/12825 [34:15:37<11:24:29, 12.63s/it] 75%|███████▍  | 9573/12825 [34:15:49<11:24:21, 12.63s/it] 75%|███████▍  | 9574/12825 [34:16:02<11:23:48, 12.62s/it] 75%|███████▍  | 9575/12825 [34:16:15<11:23:27, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120182.80lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103498.79lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9575
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9575/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9575/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9550] due to args.save_total_limit
 75%|███████▍  | 9576/12825 [34:16:28<11:28:56, 12.72s/it] 75%|███████▍  | 9577/12825 [34:16:40<11:26:54, 12.69s/it] 75%|███████▍  | 9578/12825 [34:16:53<11:25:52, 12.67s/it] 75%|███████▍  | 9579/12825 [34:17:05<11:24:41, 12.66s/it] 75%|███████▍  | 9580/12825 [34:17:18<11:24:28, 12.66s/it] 75%|███████▍  | 9581/12825 [34:17:31<11:24:35, 12.66s/it] 75%|███████▍  | 9582/12825 [34:17:43<11:23:51, 12.65s/it] 75%|███████▍  | 9583/12825 [34:17:56<11:23:17, 12.65s/it] 75%|███████▍  | 9584/12825 [34:18:09<11:22:53, 12.64s/it] 75%|███████▍  | 9585/12825 [34:18:29<13:22:05, 14.85s/it] 75%|███████▍  | 9586/12825 [34:18:41<12:46:00, 14.19s/it] 75%|███████▍  | 9587/12825 [34:18:54<12:20:26, 13.72s/it] 75%|███████▍  | 9588/12825 [34:19:07<12:02:31, 13.39s/it] 75%|███████▍  | 9589/12825 [34:19:19<11:49:42, 13.16s/it] 75%|███████▍  | 9590/12825 [34:19:32<11:40:24, 12.99s/it] 75%|███████▍  | 9591/12825 [34:19:44<11:34:21, 12.88s/it] 75%|███████▍  | 9592/12825 [34:19:57<11:29:21, 12.79s/it] 75%|███████▍  | 9593/12825 [34:20:10<11:26:38, 12.75s/it] 75%|███████▍  | 9594/12825 [34:20:22<11:24:32, 12.71s/it] 75%|███████▍  | 9595/12825 [34:20:35<11:22:55, 12.69s/it] 75%|███████▍  | 9596/12825 [34:20:47<11:21:18, 12.66s/it] 75%|███████▍  | 9597/12825 [34:21:00<11:21:02, 12.66s/it] 75%|███████▍  | 9598/12825 [34:21:13<11:20:20, 12.65s/it] 75%|███████▍  | 9599/12825 [34:21:25<11:19:53, 12.65s/it] 75%|███████▍  | 9600/12825 [34:21:38<11:19:22, 12.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120208.44lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103507.12lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9600
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9600/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9600/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9575] due to args.save_total_limit
 75%|███████▍  | 9601/12825 [34:21:51<11:24:13, 12.73s/it] 75%|███████▍  | 9602/12825 [34:22:04<11:22:15, 12.70s/it] 75%|███████▍  | 9603/12825 [34:22:16<11:21:14, 12.69s/it] 75%|███████▍  | 9604/12825 [34:22:29<11:20:23, 12.67s/it] 75%|███████▍  | 9605/12825 [34:22:42<11:20:43, 12.68s/it] 75%|███████▍  | 9606/12825 [34:22:54<11:19:48, 12.67s/it] 75%|███████▍  | 9607/12825 [34:23:07<11:19:03, 12.66s/it] 75%|███████▍  | 9608/12825 [34:23:20<11:18:33, 12.66s/it] 75%|███████▍  | 9609/12825 [34:23:32<11:19:15, 12.67s/it] 75%|███████▍  | 9610/12825 [34:23:45<11:18:36, 12.66s/it] 75%|███████▍  | 9611/12825 [34:23:57<11:17:36, 12.65s/it] 75%|███████▍  | 9612/12825 [34:24:10<11:17:36, 12.65s/it] 75%|███████▍  | 9613/12825 [34:24:23<11:17:08, 12.65s/it] 75%|███████▍  | 9614/12825 [34:24:35<11:16:44, 12.65s/it] 75%|███████▍  | 9615/12825 [34:24:48<11:16:08, 12.64s/it] 75%|███████▍  | 9616/12825 [34:25:01<11:15:30, 12.63s/it] 75%|███████▍  | 9617/12825 [34:25:23<13:49:41, 15.52s/it] 75%|███████▍  | 9618/12825 [34:25:36<13:03:20, 14.66s/it] 75%|███████▌  | 9619/12825 [34:25:48<12:30:29, 14.05s/it] 75%|███████▌  | 9620/12825 [34:26:01<12:07:29, 13.62s/it] 75%|███████▌  | 9621/12825 [34:26:13<11:51:21, 13.32s/it] 75%|███████▌  | 9622/12825 [34:26:26<11:40:40, 13.13s/it] 75%|███████▌  | 9623/12825 [34:26:39<11:32:38, 12.98s/it] 75%|███████▌  | 9624/12825 [34:26:51<11:26:07, 12.86s/it] 75%|███████▌  | 9625/12825 [34:27:04<11:22:37, 12.80s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120248.52lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103313.82lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9625
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9625/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9625/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9600] due to args.save_total_limit
 75%|███████▌  | 9626/12825 [34:27:17<11:25:31, 12.86s/it] 75%|███████▌  | 9627/12825 [34:27:30<11:21:22, 12.78s/it] 75%|███████▌  | 9628/12825 [34:27:42<11:18:22, 12.73s/it] 75%|███████▌  | 9629/12825 [34:27:55<11:16:29, 12.70s/it] 75%|███████▌  | 9630/12825 [34:28:07<11:15:44, 12.69s/it] 75%|███████▌  | 9631/12825 [34:28:20<11:14:16, 12.67s/it] 75%|███████▌  | 9632/12825 [34:28:33<11:13:21, 12.65s/it] 75%|███████▌  | 9633/12825 [34:28:45<11:12:34, 12.64s/it] 75%|███████▌  | 9634/12825 [34:28:58<11:12:35, 12.65s/it] 75%|███████▌  | 9635/12825 [34:29:11<11:11:52, 12.64s/it] 75%|███████▌  | 9636/12825 [34:29:23<11:10:49, 12.62s/it] 75%|███████▌  | 9637/12825 [34:29:36<11:10:06, 12.61s/it] 75%|███████▌  | 9638/12825 [34:29:48<11:11:29, 12.64s/it] 75%|███████▌  | 9639/12825 [34:30:01<11:10:50, 12.63s/it] 75%|███████▌  | 9640/12825 [34:30:14<11:11:01, 12.64s/it] 75%|███████▌  | 9641/12825 [34:30:26<11:10:18, 12.63s/it] 75%|███████▌  | 9642/12825 [34:30:39<11:09:26, 12.62s/it] 75%|███████▌  | 9643/12825 [34:30:52<11:10:31, 12.64s/it] 75%|███████▌  | 9644/12825 [34:31:04<11:09:40, 12.63s/it] 75%|███████▌  | 9645/12825 [34:31:17<11:08:23, 12.61s/it] 75%|███████▌  | 9646/12825 [34:31:29<11:07:53, 12.61s/it] 75%|███████▌  | 9647/12825 [34:31:42<11:07:01, 12.59s/it] 75%|███████▌  | 9648/12825 [34:31:55<11:06:22, 12.58s/it] 75%|███████▌  | 9649/12825 [34:32:07<11:05:49, 12.58s/it] 75%|███████▌  | 9650/12825 [34:32:26<12:51:58, 14.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120234.35lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103539.58lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9650
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9650/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9650/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9625] due to args.save_total_limit
 75%|███████▌  | 9651/12825 [34:32:39<12:26:30, 14.11s/it] 75%|███████▌  | 9652/12825 [34:32:52<12:03:19, 13.68s/it] 75%|███████▌  | 9653/12825 [34:33:05<11:46:49, 13.37s/it] 75%|███████▌  | 9654/12825 [34:33:17<11:35:21, 13.16s/it] 75%|███████▌  | 9655/12825 [34:33:30<11:27:01, 13.00s/it] 75%|███████▌  | 9656/12825 [34:33:43<11:21:23, 12.90s/it] 75%|███████▌  | 9657/12825 [34:33:55<11:17:16, 12.83s/it] 75%|███████▌  | 9658/12825 [34:34:08<11:14:30, 12.78s/it] 75%|███████▌  | 9659/12825 [34:34:21<11:12:44, 12.75s/it] 75%|███████▌  | 9660/12825 [34:34:33<11:11:19, 12.73s/it] 75%|███████▌  | 9661/12825 [34:34:46<11:09:50, 12.70s/it] 75%|███████▌  | 9662/12825 [34:34:59<11:08:48, 12.69s/it] 75%|███████▌  | 9663/12825 [34:35:11<11:08:18, 12.68s/it] 75%|███████▌  | 9664/12825 [34:35:24<11:07:34, 12.67s/it] 75%|███████▌  | 9665/12825 [34:35:37<11:07:09, 12.67s/it] 75%|███████▌  | 9666/12825 [34:35:49<11:06:29, 12.66s/it] 75%|███████▌  | 9667/12825 [34:36:02<11:06:13, 12.66s/it] 75%|███████▌  | 9668/12825 [34:36:15<11:06:06, 12.66s/it] 75%|███████▌  | 9669/12825 [34:36:27<11:07:35, 12.69s/it] 75%|███████▌  | 9670/12825 [34:36:40<11:07:55, 12.70s/it] 75%|███████▌  | 9671/12825 [34:36:53<11:07:27, 12.70s/it] 75%|███████▌  | 9672/12825 [34:37:05<11:06:25, 12.68s/it] 75%|███████▌  | 9673/12825 [34:37:18<11:05:34, 12.67s/it] 75%|███████▌  | 9674/12825 [34:37:31<11:05:00, 12.66s/it] 75%|███████▌  | 9675/12825 [34:37:43<11:04:45, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120252.73lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103524.91lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9675
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9675/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9675/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9650] due to args.save_total_limit
 75%|███████▌  | 9676/12825 [34:37:56<11:10:21, 12.77s/it] 75%|███████▌  | 9677/12825 [34:38:09<11:08:50, 12.75s/it] 75%|███████▌  | 9678/12825 [34:38:22<11:07:26, 12.73s/it] 75%|███████▌  | 9679/12825 [34:38:34<11:05:49, 12.70s/it] 75%|███████▌  | 9680/12825 [34:38:47<11:05:04, 12.69s/it] 75%|███████▌  | 9681/12825 [34:39:00<11:04:55, 12.69s/it] 75%|███████▌  | 9682/12825 [34:39:20<13:06:20, 15.01s/it] 76%|███████▌  | 9683/12825 [34:39:33<12:29:21, 14.31s/it] 76%|███████▌  | 9684/12825 [34:39:46<12:03:52, 13.83s/it] 76%|███████▌  | 9685/12825 [34:39:58<11:47:23, 13.52s/it] 76%|███████▌  | 9686/12825 [34:40:11<11:34:09, 13.27s/it] 76%|███████▌  | 9687/12825 [34:40:24<11:24:34, 13.09s/it] 76%|███████▌  | 9688/12825 [34:40:36<11:18:02, 12.97s/it] 76%|███████▌  | 9689/12825 [34:40:49<11:12:47, 12.87s/it] 76%|███████▌  | 9690/12825 [34:41:02<11:09:11, 12.81s/it] 76%|███████▌  | 9691/12825 [34:41:14<11:07:08, 12.77s/it] 76%|███████▌  | 9692/12825 [34:41:27<11:04:28, 12.73s/it] 76%|███████▌  | 9693/12825 [34:41:40<11:03:12, 12.71s/it] 76%|███████▌  | 9694/12825 [34:41:52<11:01:41, 12.68s/it] 76%|███████▌  | 9695/12825 [34:42:05<11:01:08, 12.67s/it] 76%|███████▌  | 9696/12825 [34:42:18<11:00:43, 12.67s/it] 76%|███████▌  | 9697/12825 [34:42:30<11:00:35, 12.67s/it] 76%|███████▌  | 9698/12825 [34:42:43<11:00:40, 12.68s/it] 76%|███████▌  | 9699/12825 [34:42:56<11:01:22, 12.69s/it] 76%|███████▌  | 9700/12825 [34:43:08<11:02:40, 12.72s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120220.82lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103394.38lines/s]
Saving model checkpoint to final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9700
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9700/config.json
Configuration saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9700/generation_config.json
Model weights saved in final-anticlk-microGPT-200k-2223-eval-either-22-or-23/tmp-checkpoint-9700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-200k-2223-eval-either-22-or-23/checkpoint-9675] due to args.save_total_limit
 76%|███████▌  | 9701/12825 [34:43:22<11:07:06, 12.81s/it] 76%|███████▌  | 9702/12825 [34:43:34<11:04:47, 12.77s/it] 76%|███████▌  | 9703/12825 [34:43:47<11:03:22, 12.75s/it] 76%|███████▌  | 9704/12825 [34:44:00<11:01:47, 12.72s/it] 76%|███████▌  | 9705/12825 [34:44:12<11:00:28, 12.70s/it] 76%|███████▌  | 9706/12825 [34:44:25<10:59:35, 12.69s/it] 76%|███████▌  | 9707/12825 [34:44:38<10:59:18, 12.69s/it] 76%|███████▌  | 9708/12825 [34:44:50<10:58:52, 12.68s/it] 76%|███████▌  | 9709/12825 [34:45:03<10:58:26, 12.68s/it]slurmstepd: error: *** JOB 52507686 ON gpu-q-12 CANCELLED AT 2024-05-17T07:22:07 DUE TO TIME LIMIT ***
