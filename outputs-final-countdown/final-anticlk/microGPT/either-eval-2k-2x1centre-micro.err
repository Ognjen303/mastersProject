Map (num_proc=32):   0%|          | 0/33392720 [00:00<?, ? examples/s]Map (num_proc=32):   0%|          | 4000/33392720 [00:04<10:02:02, 924.32 examples/s]Map (num_proc=32):   0%|          | 29000/33392720 [00:04<1:02:49, 8851.82 examples/s]Map (num_proc=32):   0%|          | 44000/33392720 [00:04<38:16, 14522.49 examples/s] Map (num_proc=32):   0%|          | 59000/33392720 [00:04<26:05, 21298.17 examples/s]Map (num_proc=32):   0%|          | 74000/33392720 [00:04<19:07, 29041.72 examples/s]Map (num_proc=32):   0%|          | 84000/33392720 [00:05<15:55, 34855.89 examples/s]Map (num_proc=32):   0%|          | 94000/33392720 [00:05<13:24, 41376.31 examples/s]Map (num_proc=32):   0%|          | 104000/33392720 [00:05<11:29, 48257.48 examples/s]Map (num_proc=32):   0%|          | 114000/33392720 [00:05<10:04, 55042.44 examples/s]Map (num_proc=32):   0%|          | 123000/33392720 [00:05<09:11, 60340.07 examples/s]Map (num_proc=32):   0%|          | 133000/33392720 [00:05<08:22, 66238.58 examples/s]Map (num_proc=32):   0%|          | 143000/33392720 [00:05<07:46, 71272.34 examples/s]Map (num_proc=32):   0%|          | 153000/33392720 [00:05<07:21, 75273.98 examples/s]Map (num_proc=32):   0%|          | 163000/33392720 [00:07<23:50, 23234.02 examples/s]Map (num_proc=32):   1%|          | 178000/33392720 [00:07<17:39, 31347.96 examples/s]Map (num_proc=32):   1%|          | 298000/33392720 [00:07<03:36, 152719.99 examples/s]Map (num_proc=32):   1%|          | 338000/33392720 [00:07<03:29, 157650.75 examples/s]Map (num_proc=32):   1%|          | 373000/33392720 [00:07<03:22, 163012.54 examples/s]Map (num_proc=32):   1%|          | 403000/33392720 [00:07<03:19, 164961.47 examples/s]Map (num_proc=32):   1%|▏         | 428000/33392720 [00:08<03:20, 164174.98 examples/s]Map (num_proc=32):   1%|▏         | 453000/33392720 [00:08<03:15, 168429.60 examples/s]Map (num_proc=32):   1%|▏         | 478000/33392720 [00:08<03:17, 166728.68 examples/s]Map (num_proc=32):   2%|▏         | 502000/33392720 [00:08<03:12, 171275.08 examples/s]Map (num_proc=32):   2%|▏         | 522000/33392720 [00:08<03:11, 171573.56 examples/s]Map (num_proc=32):   2%|▏         | 542000/33392720 [00:08<03:11, 171498.07 examples/s]Map (num_proc=32):   2%|▏         | 562000/33392720 [00:08<03:11, 171548.21 examples/s]Map (num_proc=32):   2%|▏         | 582000/33392720 [00:08<03:11, 171543.12 examples/s]Map (num_proc=32):   2%|▏         | 602000/33392720 [00:09<03:11, 171463.04 examples/s]Map (num_proc=32):   2%|▏         | 622000/33392720 [00:10<14:21, 38020.62 examples/s] Map (num_proc=32):   2%|▏         | 637000/33392720 [00:10<12:49, 42582.40 examples/s]Map (num_proc=32):   2%|▏         | 797000/33392720 [00:10<03:02, 178194.02 examples/s]Map (num_proc=32):   3%|▎         | 966000/33392720 [00:11<01:33, 345445.95 examples/s]Map (num_proc=32):   3%|▎         | 1056000/33392720 [00:11<01:42, 314667.97 examples/s]Map (num_proc=32):   3%|▎         | 1131000/33392720 [00:11<01:48, 297740.42 examples/s]Map (num_proc=32):   4%|▎         | 1191000/33392720 [00:11<01:51, 287749.17 examples/s]Map (num_proc=32):   4%|▎         | 1240000/33392720 [00:12<01:55, 278675.03 examples/s]Map (num_proc=32):   4%|▍         | 1285000/33392720 [00:12<01:57, 273862.28 examples/s]Map (num_proc=32):   4%|▍         | 1325000/33392720 [00:12<01:57, 272260.96 examples/s]Map (num_proc=32):   4%|▍         | 1359000/33392720 [00:12<02:02, 261640.57 examples/s]Map (num_proc=32):   4%|▍         | 1394000/33392720 [00:14<07:05, 75261.10 examples/s] Map (num_proc=32):   4%|▍         | 1419000/33392720 [00:14<06:53, 77271.15 examples/s]Map (num_proc=32):   6%|▌         | 1888000/33392720 [00:14<01:12, 437323.53 examples/s]Map (num_proc=32):   6%|▌         | 2038000/33392720 [00:14<01:18, 400550.08 examples/s]Map (num_proc=32):   6%|▋         | 2156000/33392720 [00:15<01:21, 382467.09 examples/s]Map (num_proc=32):   7%|▋         | 2250000/33392720 [00:15<01:22, 376067.78 examples/s]Map (num_proc=32):   7%|▋         | 2325000/33392720 [00:15<01:24, 367241.80 examples/s]Map (num_proc=32):   7%|▋         | 2390000/33392720 [00:16<01:25, 363396.76 examples/s]Map (num_proc=32):   7%|▋         | 2445000/33392720 [00:17<04:13, 122078.87 examples/s]Map (num_proc=32):   8%|▊         | 2743523/33392720 [00:18<02:49, 180879.79 examples/s]Map (num_proc=32):  10%|▉         | 3209523/33392720 [00:18<01:15, 400435.61 examples/s]Map (num_proc=32):  10%|█         | 3373523/33392720 [00:19<01:34, 317114.95 examples/s]Map (num_proc=32):  10%|█         | 3493046/33392720 [00:20<02:08, 233552.57 examples/s]Map (num_proc=32):  11%|█         | 3694046/33392720 [00:22<02:17, 215737.77 examples/s]Map (num_proc=32):  12%|█▏        | 4105046/33392720 [00:22<01:14, 391833.39 examples/s]Map (num_proc=32):  13%|█▎        | 4269046/33392720 [00:22<01:17, 377215.34 examples/s]Map (num_proc=32):  13%|█▎        | 4392046/33392720 [00:24<02:26, 197871.50 examples/s]Map (num_proc=32):  15%|█▍        | 4843569/33392720 [00:25<01:46, 266919.06 examples/s]Map (num_proc=32):  15%|█▌        | 5168569/33392720 [00:25<01:13, 384403.31 examples/s]Map (num_proc=32):  16%|█▌        | 5309569/33392720 [00:26<01:14, 376188.50 examples/s]Map (num_proc=32):  16%|█▌        | 5416569/33392720 [00:27<02:03, 226752.07 examples/s]Map (num_proc=32):  17%|█▋        | 5842092/33392720 [00:27<01:07, 408730.23 examples/s]Map (num_proc=32):  18%|█▊        | 6018092/33392720 [00:28<01:10, 388729.07 examples/s]Map (num_proc=32):  18%|█▊        | 6149092/33392720 [00:28<01:16, 356794.33 examples/s]Map (num_proc=32):  19%|█▊        | 6249092/33392720 [00:31<03:01, 149543.05 examples/s]Map (num_proc=32):  21%|██        | 6981615/33392720 [00:31<01:05, 401542.80 examples/s]Map (num_proc=32):  22%|██▏       | 7251615/33392720 [00:34<01:58, 219749.06 examples/s]Map (num_proc=32):  24%|██▎       | 7921138/33392720 [00:34<01:03, 403444.63 examples/s]Map (num_proc=32):  25%|██▍       | 8243138/33392720 [00:37<01:50, 227373.86 examples/s]Map (num_proc=32):  27%|██▋       | 9051661/33392720 [00:37<00:58, 416356.77 examples/s]Map (num_proc=32):  28%|██▊       | 9444661/33392720 [00:41<01:41, 236468.64 examples/s]Map (num_proc=32):  31%|███       | 10190184/33392720 [00:42<01:12, 321243.17 examples/s]Map (num_proc=32):  32%|███▏      | 10537184/33392720 [00:42<00:57, 396085.47 examples/s]Map (num_proc=32):  32%|███▏      | 10786184/33392720 [00:44<01:17, 292169.98 examples/s]Map (num_proc=32):  33%|███▎      | 11185707/33392720 [00:44<00:56, 395491.96 examples/s]Map (num_proc=32):  34%|███▍      | 11405707/33392720 [00:46<01:11, 305473.38 examples/s]Map (num_proc=32):  35%|███▍      | 11622707/33392720 [00:46<00:58, 371470.61 examples/s]Map (num_proc=32):  35%|███▌      | 11800707/33392720 [00:48<01:34, 227841.54 examples/s]Map (num_proc=32):  36%|███▋      | 12188230/33392720 [00:49<01:20, 264314.65 examples/s]Map (num_proc=32):  38%|███▊      | 12528230/33392720 [00:49<00:55, 375314.54 examples/s]Map (num_proc=32):  38%|███▊      | 12701230/33392720 [00:50<00:56, 366596.38 examples/s]Map (num_proc=32):  38%|███▊      | 12831230/33392720 [00:50<00:58, 353305.40 examples/s]Map (num_proc=32):  39%|███▊      | 12930753/33392720 [00:52<01:45, 193204.97 examples/s]Map (num_proc=32):  39%|███▉      | 13137753/33392720 [00:53<01:43, 194821.52 examples/s]Map (num_proc=32):  41%|████      | 13653753/33392720 [00:53<00:49, 396645.16 examples/s]Map (num_proc=32):  41%|████▏     | 13839753/33392720 [00:54<00:51, 383276.03 examples/s]Map (num_proc=32):  42%|████▏     | 13984276/33392720 [00:55<01:24, 228530.21 examples/s]Map (num_proc=32):  43%|████▎     | 14265276/33392720 [00:56<01:19, 240085.76 examples/s]Map (num_proc=32):  44%|████▍     | 14652276/33392720 [00:56<00:48, 386127.08 examples/s]Map (num_proc=32):  44%|████▍     | 14811276/33392720 [00:57<00:49, 377113.91 examples/s]Map (num_proc=32):  45%|████▍     | 14936276/33392720 [00:58<01:15, 244346.64 examples/s]Map (num_proc=32):  45%|████▌     | 15028799/33392720 [00:59<01:31, 201325.89 examples/s]Map (num_proc=32):  46%|████▌     | 15319799/33392720 [01:00<01:19, 226877.28 examples/s]Map (num_proc=32):  47%|████▋     | 15774799/33392720 [01:00<00:42, 417974.08 examples/s]Map (num_proc=32):  48%|████▊     | 15948322/33392720 [01:01<00:44, 392920.80 examples/s]Map (num_proc=32):  48%|████▊     | 16079322/33392720 [01:02<01:14, 231252.62 examples/s]Map (num_proc=32):  48%|████▊     | 16184322/33392720 [01:04<01:31, 188790.18 examples/s]Map (num_proc=32):  50%|████▉     | 16696322/33392720 [01:04<00:41, 398749.26 examples/s]Map (num_proc=32):  51%|█████     | 16900322/33392720 [01:04<00:43, 382587.16 examples/s]Map (num_proc=32):  51%|█████     | 17055322/33392720 [01:06<01:12, 224068.44 examples/s]Map (num_proc=32):  52%|█████▏    | 17378845/33392720 [01:07<01:04, 249058.63 examples/s]Map (num_proc=32):  53%|█████▎    | 17747845/33392720 [01:07<00:40, 383112.12 examples/s]Map (num_proc=32):  54%|█████▎    | 17898845/33392720 [01:08<00:41, 375209.16 examples/s]Map (num_proc=32):  54%|█████▍    | 18013845/33392720 [01:08<00:41, 366867.57 examples/s]Map (num_proc=32):  54%|█████▍    | 18108368/33392720 [01:09<01:14, 206162.05 examples/s]Map (num_proc=32):  55%|█████▍    | 18304368/33392720 [01:11<01:15, 198949.00 examples/s]Map (num_proc=32):  56%|█████▌    | 18718368/33392720 [01:11<00:39, 376007.02 examples/s]Map (num_proc=32):  57%|█████▋    | 18879368/33392720 [01:11<00:40, 361463.35 examples/s]Map (num_proc=32):  57%|█████▋    | 18999368/33392720 [01:13<01:10, 205387.18 examples/s]Map (num_proc=32):  58%|█████▊    | 19437890/33392720 [01:13<00:36, 385112.22 examples/s]Map (num_proc=32):  59%|█████▊    | 19610890/33392720 [01:14<00:51, 266211.14 examples/s]Map (num_proc=32):  60%|█████▉    | 19868890/33392720 [01:14<00:36, 371385.73 examples/s]Map (num_proc=32):  60%|█████▉    | 20032890/33392720 [01:16<01:00, 219932.49 examples/s]Map (num_proc=32):  61%|██████▏   | 20498412/33392720 [01:16<00:32, 401151.86 examples/s]Map (num_proc=32):  62%|██████▏   | 20713412/33392720 [01:18<00:48, 263860.46 examples/s]Map (num_proc=32):  63%|██████▎   | 21031412/33392720 [01:18<00:32, 377908.87 examples/s]Map (num_proc=32):  64%|██████▎   | 21219412/33392720 [01:20<00:52, 230402.31 examples/s]Map (num_proc=32):  65%|██████▍   | 21687934/33392720 [01:20<00:29, 394396.72 examples/s]Map (num_proc=32):  66%|██████▌   | 21910934/33392720 [01:21<00:36, 315463.67 examples/s]Map (num_proc=32):  66%|██████▌   | 22074934/33392720 [01:22<00:31, 356993.94 examples/s]Map (num_proc=32):  67%|██████▋   | 22209934/33392720 [01:22<00:31, 358767.60 examples/s]Map (num_proc=32):  67%|██████▋   | 22319934/33392720 [01:24<00:59, 185987.71 examples/s]Map (num_proc=32):  67%|██████▋   | 22397456/33392720 [01:24<00:56, 193318.86 examples/s]Map (num_proc=32):  68%|██████▊   | 22641456/33392720 [01:25<00:52, 206580.36 examples/s]Map (num_proc=32):  69%|██████▉   | 23150456/33392720 [01:25<00:23, 434871.73 examples/s]Map (num_proc=32):  70%|██████▉   | 23334978/33392720 [01:26<00:24, 402931.88 examples/s]Map (num_proc=32):  70%|███████   | 23473978/33392720 [01:28<00:50, 196227.75 examples/s]Map (num_proc=32):  71%|███████   | 23576978/33392720 [01:29<00:58, 167240.19 examples/s]Map (num_proc=32):  73%|███████▎  | 24233500/33392720 [01:29<00:22, 407857.92 examples/s]Map (num_proc=32):  73%|███████▎  | 24473500/33392720 [01:32<00:40, 220890.33 examples/s]Map (num_proc=32):  75%|███████▍  | 24922500/33392720 [01:32<00:24, 350474.31 examples/s]Map (num_proc=32):  75%|███████▌  | 25162500/33392720 [01:33<00:24, 341954.30 examples/s]Map (num_proc=32):  76%|███████▌  | 25341022/33392720 [01:33<00:24, 332432.52 examples/s]Map (num_proc=32):  76%|███████▋  | 25479022/33392720 [01:35<00:37, 212014.59 examples/s]Map (num_proc=32):  77%|███████▋  | 25588022/33392720 [01:36<00:43, 180603.74 examples/s]Map (num_proc=32):  78%|███████▊  | 26118022/33392720 [01:36<00:19, 375617.63 examples/s]Map (num_proc=32):  79%|███████▉  | 26328022/33392720 [01:37<00:19, 370167.54 examples/s]Map (num_proc=32):  79%|███████▉  | 26485544/33392720 [01:39<00:28, 238751.44 examples/s]Map (num_proc=32):  80%|███████▉  | 26654544/33392720 [01:40<00:31, 214747.90 examples/s]Map (num_proc=32):  81%|████████  | 27092544/33392720 [01:40<00:16, 379976.97 examples/s]Map (num_proc=32):  82%|████████▏ | 27251544/33392720 [01:41<00:25, 245072.20 examples/s]Map (num_proc=32):  82%|████████▏ | 27369544/33392720 [01:42<00:22, 263983.31 examples/s]Map (num_proc=32):  83%|████████▎ | 27773066/33392720 [01:42<00:12, 456581.46 examples/s]Map (num_proc=32):  84%|████████▎ | 27948066/33392720 [01:42<00:12, 423602.11 examples/s]Map (num_proc=32):  84%|████████▍ | 28080066/33392720 [01:45<00:31, 170778.54 examples/s]Map (num_proc=32):  86%|████████▋ | 28829588/33392720 [01:45<00:10, 420544.79 examples/s]Map (num_proc=32):  87%|████████▋ | 29111588/33392720 [01:47<00:13, 310181.47 examples/s]Map (num_proc=32):  88%|████████▊ | 29337588/33392720 [01:47<00:10, 380371.52 examples/s]Map (num_proc=32):  88%|████████▊ | 29540588/33392720 [01:49<00:16, 237347.11 examples/s]Map (num_proc=32):  90%|████████▉ | 30010110/33392720 [01:49<00:08, 392934.54 examples/s]Map (num_proc=32):  91%|█████████ | 30229110/33392720 [01:50<00:10, 304055.14 examples/s]Map (num_proc=32):  91%|█████████ | 30415110/33392720 [01:50<00:08, 367831.73 examples/s]Map (num_proc=32):  92%|█████████▏| 30582110/33392720 [01:51<00:07, 357129.04 examples/s]Map (num_proc=32):  92%|█████████▏| 30707110/33392720 [01:51<00:07, 355714.78 examples/s]Map (num_proc=32):  92%|█████████▏| 30805110/33392720 [01:51<00:07, 352350.70 examples/s]Map (num_proc=32):  92%|█████████▏| 30886632/33392720 [01:52<00:07, 350403.28 examples/s]Map (num_proc=32):  93%|█████████▎| 30951632/33392720 [01:52<00:06, 351022.97 examples/s]Map (num_proc=32):  93%|█████████▎| 31011632/33392720 [01:52<00:06, 349540.14 examples/s]Map (num_proc=32):  93%|█████████▎| 31061632/33392720 [01:52<00:06, 342075.36 examples/s]Map (num_proc=32):  93%|█████████▎| 31105632/33392720 [01:52<00:06, 346579.90 examples/s]Map (num_proc=32):  93%|█████████▎| 31150632/33392720 [01:54<00:16, 133387.74 examples/s]Map (num_proc=32):  94%|█████████▍| 31479632/33392720 [01:54<00:04, 384477.64 examples/s]Map (num_proc=32):  95%|█████████▍| 31594632/33392720 [01:54<00:04, 378131.44 examples/s]Map (num_proc=32):  95%|█████████▍| 31684632/33392720 [01:54<00:04, 366025.83 examples/s]Map (num_proc=32):  95%|█████████▌| 31759154/33392720 [01:54<00:04, 360686.83 examples/s]Map (num_proc=32):  95%|█████████▌| 31824154/33392720 [01:55<00:04, 334537.47 examples/s]Map (num_proc=32):  95%|█████████▌| 31879154/33392720 [01:55<00:04, 322861.92 examples/s]Map (num_proc=32):  96%|█████████▌| 31924154/33392720 [01:55<00:04, 308092.44 examples/s]Map (num_proc=32):  96%|█████████▌| 31964154/33392720 [01:55<00:04, 289682.41 examples/s]Map (num_proc=32):  96%|█████████▌| 32001154/33392720 [01:55<00:05, 271004.29 examples/s]Map (num_proc=32):  96%|█████████▌| 32035154/33392720 [01:56<00:12, 107472.67 examples/s]Map (num_proc=32):  97%|█████████▋| 32257154/33392720 [01:57<00:03, 289412.16 examples/s]Map (num_proc=32):  97%|█████████▋| 32337154/33392720 [01:57<00:03, 283052.18 examples/s]Map (num_proc=32):  97%|█████████▋| 32402154/33392720 [01:57<00:03, 282095.95 examples/s]Map (num_proc=32):  97%|█████████▋| 32457154/33392720 [01:57<00:03, 270967.49 examples/s]Map (num_proc=32):  97%|█████████▋| 32502154/33392720 [01:57<00:03, 268066.15 examples/s]Map (num_proc=32):  97%|█████████▋| 32544676/33392720 [01:58<00:03, 245853.85 examples/s]Map (num_proc=32):  98%|█████████▊| 32579676/33392720 [01:58<00:03, 232960.36 examples/s]Map (num_proc=32):  98%|█████████▊| 32609676/33392720 [01:58<00:03, 217642.26 examples/s]Map (num_proc=32):  98%|█████████▊| 32639676/33392720 [01:58<00:03, 205621.01 examples/s]Map (num_proc=32):  98%|█████████▊| 32664676/33392720 [01:58<00:03, 189621.33 examples/s]Map (num_proc=32):  98%|█████████▊| 32687676/33392720 [01:59<00:10, 70039.64 examples/s] Map (num_proc=32):  98%|█████████▊| 32846676/33392720 [02:00<00:02, 192727.17 examples/s]Map (num_proc=32):  98%|█████████▊| 32891676/33392720 [02:00<00:02, 191209.24 examples/s]Map (num_proc=32):  99%|█████████▊| 32931676/33392720 [02:00<00:02, 186776.64 examples/s]Map (num_proc=32):  99%|█████████▊| 32966676/33392720 [02:00<00:02, 173085.17 examples/s]Map (num_proc=32):  99%|█████████▉| 32996676/33392720 [02:01<00:02, 172728.69 examples/s]Map (num_proc=32):  99%|█████████▉| 33021676/33392720 [02:01<00:02, 171682.33 examples/s]Map (num_proc=32):  99%|█████████▉| 33046676/33392720 [02:01<00:02, 172473.88 examples/s]Map (num_proc=32):  99%|█████████▉| 33071676/33392720 [02:01<00:01, 171485.76 examples/s]Map (num_proc=32):  99%|█████████▉| 33091676/33392720 [02:01<00:01, 171429.38 examples/s]Map (num_proc=32):  99%|█████████▉| 33111676/33392720 [02:01<00:01, 171603.99 examples/s]Map (num_proc=32):  99%|█████████▉| 33131676/33392720 [02:01<00:01, 171657.92 examples/s]Map (num_proc=32):  99%|█████████▉| 33151676/33392720 [02:01<00:01, 171699.05 examples/s]Map (num_proc=32):  99%|█████████▉| 33174198/33392720 [02:02<00:01, 156317.08 examples/s]Map (num_proc=32):  99%|█████████▉| 33194198/33392720 [02:02<00:01, 127720.19 examples/s]Map (num_proc=32):  99%|█████████▉| 33209198/33392720 [02:02<00:01, 115011.91 examples/s]Map (num_proc=32):  99%|█████████▉| 33224198/33392720 [02:02<00:01, 106139.01 examples/s]Map (num_proc=32): 100%|█████████▉| 33239198/33392720 [02:02<00:01, 99842.95 examples/s] Map (num_proc=32): 100%|█████████▉| 33252198/33392720 [02:03<00:03, 35399.59 examples/s]Map (num_proc=32): 100%|█████████▉| 33328198/33392720 [02:04<00:00, 96599.76 examples/s]Map (num_proc=32): 100%|█████████▉| 33353198/33392720 [02:04<00:00, 93885.51 examples/s]Map (num_proc=32): 100%|█████████▉| 33378198/33392720 [02:04<00:00, 91713.27 examples/s]Map (num_proc=32): 100%|██████████| 33392720/33392720 [02:07<00:00, 262926.48 examples/s]
Map (num_proc=32):   0%|          | 0/27000 [00:00<?, ? examples/s]Map (num_proc=32):   3%|▎         | 844/27000 [00:00<00:03, 7883.26 examples/s]Map (num_proc=32):  41%|████      | 10972/27000 [00:00<00:00, 59691.07 examples/s]Map (num_proc=32):  88%|████████▊ | 23628/27000 [00:00<00:00, 88689.27 examples/s]Map (num_proc=32): 100%|██████████| 27000/27000 [00:00<00:00, 52499.41 examples/s]
wandb: Currently logged in as: os415. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /rds/user/os415/hpc-work/tspGPT/wandb/run-20240516_102107-u3n1qqz8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run final-anticlk-microGPT-2k-2223-eval-either-22-or-23
wandb: ⭐️ View project at https://wandb.ai/os415/Final-countdown
wandb: 🚀 View run at https://wandb.ai/os415/Final-countdown/runs/u3n1qqz8
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Using auto half precision backend
***** Running training *****
  Num examples = 33,392,720
  Num Epochs = 25
  Instantaneous batch size per device = 65,536
  Total train batch size (w. parallel, distributed & accumulation) = 65,536
  Gradient Accumulation steps = 1
  Total optimization steps = 12,750
  Number of trainable parameters = 926,080
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/12750 [00:00<?, ?it/s]  0%|          | 1/12750 [00:24<88:11:24, 24.90s/it]  0%|          | 2/12750 [00:36<60:20:04, 17.04s/it]  0%|          | 3/12750 [00:47<51:23:56, 14.52s/it]  0%|          | 4/12750 [00:59<47:12:05, 13.33s/it]  0%|          | 5/12750 [01:10<44:49:52, 12.66s/it]  0%|          | 6/12750 [01:22<43:27:14, 12.28s/it]  0%|          | 7/12750 [01:33<42:34:21, 12.03s/it]  0%|          | 8/12750 [01:45<42:00:02, 11.87s/it]  0%|          | 9/12750 [01:57<41:38:23, 11.77s/it]  0%|          | 10/12750 [02:08<41:24:20, 11.70s/it]  0%|          | 11/12750 [02:20<41:12:16, 11.64s/it]  0%|          | 12/12750 [02:31<41:02:33, 11.60s/it]  0%|          | 13/12750 [02:43<40:58:31, 11.58s/it]  0%|          | 14/12750 [02:54<40:55:04, 11.57s/it]  0%|          | 15/12750 [03:06<40:53:09, 11.56s/it]  0%|          | 16/12750 [03:17<40:49:38, 11.54s/it]  0%|          | 17/12750 [03:29<40:46:53, 11.53s/it]  0%|          | 18/12750 [03:40<40:46:27, 11.53s/it]  0%|          | 19/12750 [03:52<40:45:31, 11.53s/it]  0%|          | 20/12750 [04:03<40:44:16, 11.52s/it]  0%|          | 21/12750 [04:15<40:43:35, 11.52s/it]  0%|          | 22/12750 [04:26<40:44:48, 11.52s/it]  0%|          | 23/12750 [04:38<40:45:13, 11.53s/it]  0%|          | 24/12750 [04:49<40:45:57, 11.53s/it]  0%|          | 25/12750 [05:01<40:45:33, 11.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120210.23lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 95955.99lines/s] 
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-25
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-25/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-25/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-25/pytorch_model.bin
  0%|          | 26/12750 [05:13<41:08:04, 11.64s/it]  0%|          | 27/12750 [05:24<40:59:03, 11.60s/it]  0%|          | 28/12750 [05:36<40:54:35, 11.58s/it]  0%|          | 29/12750 [05:47<40:49:58, 11.56s/it]  0%|          | 30/12750 [05:59<40:47:54, 11.55s/it]  0%|          | 31/12750 [06:18<49:07:26, 13.90s/it]  0%|          | 32/12750 [06:30<46:35:02, 13.19s/it]  0%|          | 33/12750 [06:41<44:47:41, 12.68s/it]  0%|          | 34/12750 [06:53<43:31:43, 12.32s/it]  0%|          | 35/12750 [07:04<42:39:14, 12.08s/it]  0%|          | 36/12750 [07:16<42:03:19, 11.91s/it]  0%|          | 37/12750 [07:27<41:36:22, 11.78s/it]  0%|          | 38/12750 [07:39<41:19:12, 11.70s/it]  0%|          | 39/12750 [07:50<41:06:35, 11.64s/it]  0%|          | 40/12750 [08:02<40:58:23, 11.61s/it]  0%|          | 41/12750 [08:13<40:51:04, 11.57s/it]  0%|          | 42/12750 [08:25<40:45:42, 11.55s/it]  0%|          | 43/12750 [08:36<40:43:33, 11.54s/it]  0%|          | 44/12750 [08:48<40:38:53, 11.52s/it]  0%|          | 45/12750 [08:59<40:34:39, 11.50s/it]  0%|          | 46/12750 [09:11<40:35:03, 11.50s/it]  0%|          | 47/12750 [09:22<40:32:36, 11.49s/it]  0%|          | 48/12750 [09:34<40:32:44, 11.49s/it]  0%|          | 49/12750 [09:45<40:29:55, 11.48s/it]  0%|          | 50/12750 [09:57<40:31:47, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120623.16lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104865.08lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-50
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-50/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-50/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-50/pytorch_model.bin
  0%|          | 51/12750 [10:09<40:53:28, 11.59s/it]  0%|          | 52/12750 [10:20<40:45:54, 11.56s/it]  0%|          | 53/12750 [10:31<40:40:19, 11.53s/it]  0%|          | 54/12750 [10:43<40:35:54, 11.51s/it]  0%|          | 55/12750 [10:54<40:34:37, 11.51s/it]  0%|          | 56/12750 [11:06<40:34:01, 11.50s/it]  0%|          | 57/12750 [11:17<40:32:40, 11.50s/it]  0%|          | 58/12750 [11:29<40:32:17, 11.50s/it]  0%|          | 59/12750 [11:40<40:31:24, 11.50s/it]  0%|          | 60/12750 [11:52<40:30:44, 11.49s/it]  0%|          | 61/12750 [12:03<40:28:06, 11.48s/it]  0%|          | 62/12750 [12:15<40:28:25, 11.48s/it]  0%|          | 63/12750 [12:34<48:40:10, 13.81s/it]  1%|          | 64/12750 [12:46<46:14:02, 13.12s/it]  1%|          | 65/12750 [12:57<44:31:32, 12.64s/it]  1%|          | 66/12750 [13:09<43:18:18, 12.29s/it]  1%|          | 67/12750 [13:20<42:27:19, 12.05s/it]  1%|          | 68/12750 [13:32<41:51:06, 11.88s/it]  1%|          | 69/12750 [13:43<41:26:47, 11.77s/it]  1%|          | 70/12750 [13:55<41:09:33, 11.69s/it]  1%|          | 71/12750 [14:06<40:57:10, 11.63s/it]  1%|          | 72/12750 [14:18<40:48:51, 11.59s/it]  1%|          | 73/12750 [14:29<40:42:56, 11.56s/it]  1%|          | 74/12750 [14:41<40:36:57, 11.53s/it]  1%|          | 75/12750 [14:52<40:33:20, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120534.83lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104807.33lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-75
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-75/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-75/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-75/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-50] due to args.save_total_limit
  1%|          | 76/12750 [15:04<40:54:22, 11.62s/it]  1%|          | 77/12750 [15:15<40:46:14, 11.58s/it]  1%|          | 78/12750 [15:27<40:39:55, 11.55s/it]  1%|          | 79/12750 [15:38<40:35:05, 11.53s/it]  1%|          | 80/12750 [15:50<40:32:24, 11.52s/it]  1%|          | 81/12750 [16:01<40:29:57, 11.51s/it]  1%|          | 82/12750 [16:13<40:26:20, 11.49s/it]  1%|          | 83/12750 [16:24<40:26:40, 11.49s/it]  1%|          | 84/12750 [16:36<40:25:32, 11.49s/it]  1%|          | 85/12750 [16:47<40:24:59, 11.49s/it]  1%|          | 86/12750 [16:59<40:24:07, 11.49s/it]  1%|          | 87/12750 [17:10<40:20:59, 11.47s/it]  1%|          | 88/12750 [17:22<40:20:08, 11.47s/it]  1%|          | 89/12750 [17:33<40:18:18, 11.46s/it]  1%|          | 90/12750 [17:44<40:19:03, 11.46s/it]  1%|          | 91/12750 [17:56<40:16:18, 11.45s/it]  1%|          | 92/12750 [18:07<40:14:38, 11.45s/it]  1%|          | 93/12750 [18:19<40:15:20, 11.45s/it]  1%|          | 94/12750 [18:30<40:14:58, 11.45s/it]  1%|          | 95/12750 [18:50<48:29:51, 13.80s/it]  1%|          | 96/12750 [19:01<46:02:39, 13.10s/it]  1%|          | 97/12750 [19:12<44:18:43, 12.61s/it]  1%|          | 98/12750 [19:24<43:04:14, 12.26s/it]  1%|          | 99/12750 [19:35<42:13:36, 12.02s/it]  1%|          | 100/12750 [19:47<41:36:32, 11.84s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120171.58lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104574.47lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-100
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-100/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-100/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-75] due to args.save_total_limit
  1%|          | 101/12750 [19:59<41:30:41, 11.81s/it]  1%|          | 102/12750 [20:10<41:08:41, 11.71s/it]  1%|          | 103/12750 [20:21<40:50:39, 11.63s/it]  1%|          | 104/12750 [20:33<40:39:55, 11.58s/it]  1%|          | 105/12750 [20:44<40:31:12, 11.54s/it]  1%|          | 106/12750 [20:56<40:25:52, 11.51s/it]  1%|          | 107/12750 [21:07<40:20:51, 11.49s/it]  1%|          | 108/12750 [21:19<40:18:17, 11.48s/it]  1%|          | 109/12750 [21:30<40:15:28, 11.46s/it]  1%|          | 110/12750 [21:42<40:15:35, 11.47s/it]  1%|          | 111/12750 [21:53<40:14:35, 11.46s/it]  1%|          | 112/12750 [22:04<40:12:22, 11.45s/it]  1%|          | 113/12750 [22:16<40:12:52, 11.46s/it]  1%|          | 114/12750 [22:27<40:11:53, 11.45s/it]  1%|          | 115/12750 [22:39<40:12:22, 11.46s/it]  1%|          | 116/12750 [22:50<40:12:01, 11.45s/it]  1%|          | 117/12750 [23:02<40:12:12, 11.46s/it]  1%|          | 118/12750 [23:13<40:12:43, 11.46s/it]  1%|          | 119/12750 [23:25<40:13:00, 11.46s/it]  1%|          | 120/12750 [23:36<40:11:13, 11.45s/it]  1%|          | 121/12750 [23:48<40:13:16, 11.47s/it]  1%|          | 122/12750 [23:59<40:12:16, 11.46s/it]  1%|          | 123/12750 [24:11<40:12:58, 11.47s/it]  1%|          | 124/12750 [24:22<40:11:25, 11.46s/it]  1%|          | 125/12750 [24:33<40:12:08, 11.46s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120591.69lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104759.05lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-125
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-125/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-125/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-100] due to args.save_total_limit
  1%|          | 126/12750 [24:45<40:30:31, 11.55s/it]  1%|          | 127/12750 [24:57<40:24:36, 11.52s/it]  1%|          | 128/12750 [25:15<47:36:29, 13.58s/it]  1%|          | 129/12750 [25:26<45:21:51, 12.94s/it]  1%|          | 130/12750 [25:38<43:47:46, 12.49s/it]  1%|          | 131/12750 [25:49<42:42:11, 12.18s/it]  1%|          | 132/12750 [26:01<41:55:59, 11.96s/it]  1%|          | 133/12750 [26:12<41:21:19, 11.80s/it]  1%|          | 134/12750 [26:24<41:03:51, 11.72s/it]  1%|          | 135/12750 [26:35<40:46:48, 11.64s/it]  1%|          | 136/12750 [26:47<40:33:48, 11.58s/it]  1%|          | 137/12750 [26:58<40:26:20, 11.54s/it]  1%|          | 138/12750 [27:10<40:22:18, 11.52s/it]  1%|          | 139/12750 [27:21<40:18:38, 11.51s/it]  1%|          | 140/12750 [27:33<40:15:27, 11.49s/it]  1%|          | 141/12750 [27:44<40:13:35, 11.49s/it]  1%|          | 142/12750 [27:55<40:11:26, 11.48s/it]  1%|          | 143/12750 [28:07<40:09:05, 11.47s/it]  1%|          | 144/12750 [28:18<40:08:59, 11.47s/it]  1%|          | 145/12750 [28:30<40:07:17, 11.46s/it]  1%|          | 146/12750 [28:41<40:05:24, 11.45s/it]  1%|          | 147/12750 [28:53<40:04:52, 11.45s/it]  1%|          | 148/12750 [29:04<40:06:25, 11.46s/it]  1%|          | 149/12750 [29:16<40:05:42, 11.45s/it]  1%|          | 150/12750 [29:27<40:05:38, 11.46s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120625.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104732.60lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-150
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-150/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-150/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-125] due to args.save_total_limit
  1%|          | 151/12750 [29:39<40:24:49, 11.55s/it]  1%|          | 152/12750 [29:50<40:17:51, 11.52s/it]  1%|          | 153/12750 [30:02<40:12:48, 11.49s/it]  1%|          | 154/12750 [30:13<40:10:05, 11.48s/it]  1%|          | 155/12750 [30:25<40:07:51, 11.47s/it]  1%|          | 156/12750 [30:36<40:05:12, 11.46s/it]  1%|          | 157/12750 [30:48<40:04:38, 11.46s/it]  1%|          | 158/12750 [30:59<40:01:56, 11.45s/it]  1%|          | 159/12750 [31:10<40:01:17, 11.44s/it]  1%|▏         | 160/12750 [31:29<48:04:40, 13.75s/it]  1%|▏         | 161/12750 [31:41<45:41:17, 13.07s/it]  1%|▏         | 162/12750 [31:52<43:56:43, 12.57s/it]  1%|▏         | 163/12750 [32:04<42:43:47, 12.22s/it]  1%|▏         | 164/12750 [32:15<41:55:19, 11.99s/it]  1%|▏         | 165/12750 [32:27<41:20:20, 11.83s/it]  1%|▏         | 166/12750 [32:38<40:56:09, 11.71s/it]  1%|▏         | 167/12750 [32:50<40:35:52, 11.62s/it]  1%|▏         | 168/12750 [33:01<40:24:10, 11.56s/it]  1%|▏         | 169/12750 [33:12<40:16:53, 11.53s/it]  1%|▏         | 170/12750 [33:24<40:10:15, 11.50s/it]  1%|▏         | 171/12750 [33:35<40:06:12, 11.48s/it]  1%|▏         | 172/12750 [33:47<40:04:07, 11.47s/it]  1%|▏         | 173/12750 [33:58<40:00:28, 11.45s/it]  1%|▏         | 174/12750 [34:10<39:59:04, 11.45s/it]  1%|▏         | 175/12750 [34:21<39:58:00, 11.44s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120591.30lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104901.79lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-175
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-175/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-175/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-150] due to args.save_total_limit
  1%|▏         | 176/12750 [34:34<41:43:44, 11.95s/it]  1%|▏         | 177/12750 [34:46<41:10:32, 11.79s/it]  1%|▏         | 178/12750 [34:57<40:48:19, 11.68s/it]  1%|▏         | 179/12750 [35:08<40:33:28, 11.61s/it]  1%|▏         | 180/12750 [35:20<40:22:45, 11.56s/it]  1%|▏         | 181/12750 [35:31<40:14:01, 11.52s/it]  1%|▏         | 182/12750 [35:43<40:08:01, 11.50s/it]  1%|▏         | 183/12750 [35:54<40:06:09, 11.49s/it]  1%|▏         | 184/12750 [36:06<40:01:53, 11.47s/it]  1%|▏         | 185/12750 [36:17<40:02:16, 11.47s/it]  1%|▏         | 186/12750 [36:29<39:59:44, 11.46s/it]  1%|▏         | 187/12750 [36:40<39:58:53, 11.46s/it]  1%|▏         | 188/12750 [36:51<39:59:51, 11.46s/it]  1%|▏         | 189/12750 [37:03<39:59:52, 11.46s/it]  1%|▏         | 190/12750 [37:14<39:57:43, 11.45s/it]  1%|▏         | 191/12750 [37:26<39:56:23, 11.45s/it]  2%|▏         | 192/12750 [37:45<48:04:11, 13.78s/it]  2%|▏         | 193/12750 [37:56<45:37:35, 13.08s/it]  2%|▏         | 194/12750 [38:08<43:55:39, 12.59s/it]  2%|▏         | 195/12750 [38:19<42:41:42, 12.24s/it]  2%|▏         | 196/12750 [38:31<41:52:49, 12.01s/it]  2%|▏         | 197/12750 [38:42<41:17:29, 11.84s/it]  2%|▏         | 198/12750 [38:54<40:51:46, 11.72s/it]  2%|▏         | 199/12750 [39:05<40:34:14, 11.64s/it]  2%|▏         | 200/12750 [39:17<40:22:09, 11.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120662.61lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104889.84lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-200
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-200/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-200/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-175] due to args.save_total_limit
  2%|▏         | 201/12750 [39:28<40:33:55, 11.64s/it]  2%|▏         | 202/12750 [39:40<40:18:54, 11.57s/it]  2%|▏         | 203/12750 [39:51<40:09:08, 11.52s/it]  2%|▏         | 204/12750 [40:03<40:03:31, 11.49s/it]  2%|▏         | 205/12750 [40:14<39:59:38, 11.48s/it]  2%|▏         | 206/12750 [40:25<39:56:52, 11.46s/it]  2%|▏         | 207/12750 [40:37<39:53:21, 11.45s/it]  2%|▏         | 208/12750 [40:48<39:52:22, 11.44s/it]  2%|▏         | 209/12750 [41:00<39:51:11, 11.44s/it]  2%|▏         | 210/12750 [41:11<39:48:27, 11.43s/it]  2%|▏         | 211/12750 [41:23<39:47:44, 11.43s/it]  2%|▏         | 212/12750 [41:34<39:46:32, 11.42s/it]  2%|▏         | 213/12750 [41:45<39:47:53, 11.43s/it]  2%|▏         | 214/12750 [41:57<39:49:07, 11.43s/it]  2%|▏         | 215/12750 [42:08<39:49:09, 11.44s/it]  2%|▏         | 216/12750 [42:20<39:49:30, 11.44s/it]  2%|▏         | 217/12750 [42:31<39:48:49, 11.44s/it]  2%|▏         | 218/12750 [42:43<39:48:17, 11.43s/it]  2%|▏         | 219/12750 [42:54<39:47:37, 11.43s/it]  2%|▏         | 220/12750 [43:05<39:45:14, 11.42s/it]  2%|▏         | 221/12750 [43:17<39:45:30, 11.42s/it]  2%|▏         | 222/12750 [43:28<39:45:26, 11.42s/it]  2%|▏         | 223/12750 [43:40<39:46:09, 11.43s/it]  2%|▏         | 224/12750 [43:59<47:50:47, 13.75s/it]  2%|▏         | 225/12750 [44:10<45:24:05, 13.05s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120551.00lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104821.40lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-225
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-225/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-225/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-200] due to args.save_total_limit
  2%|▏         | 226/12750 [44:22<44:03:38, 12.67s/it]  2%|▏         | 227/12750 [44:34<42:47:00, 12.30s/it]  2%|▏         | 228/12750 [44:45<41:51:57, 12.04s/it]  2%|▏         | 229/12750 [44:56<41:14:05, 11.86s/it]  2%|▏         | 230/12750 [45:08<40:48:39, 11.73s/it]  2%|▏         | 231/12750 [45:19<40:28:07, 11.64s/it]  2%|▏         | 232/12750 [45:31<40:13:05, 11.57s/it]  2%|▏         | 233/12750 [45:42<40:04:21, 11.53s/it]  2%|▏         | 234/12750 [45:54<39:57:58, 11.50s/it]  2%|▏         | 235/12750 [46:05<39:52:23, 11.47s/it]  2%|▏         | 236/12750 [46:16<39:47:45, 11.45s/it]  2%|▏         | 237/12750 [46:28<39:45:41, 11.44s/it]  2%|▏         | 238/12750 [46:39<39:42:42, 11.43s/it]  2%|▏         | 239/12750 [46:51<39:42:47, 11.43s/it]  2%|▏         | 240/12750 [47:02<39:44:56, 11.44s/it]  2%|▏         | 241/12750 [47:13<39:43:52, 11.43s/it]  2%|▏         | 242/12750 [47:25<39:40:19, 11.42s/it]  2%|▏         | 243/12750 [47:36<39:38:49, 11.41s/it]  2%|▏         | 244/12750 [47:48<39:38:31, 11.41s/it]  2%|▏         | 245/12750 [47:59<39:40:47, 11.42s/it]  2%|▏         | 246/12750 [48:10<39:37:59, 11.41s/it]  2%|▏         | 247/12750 [48:22<39:37:39, 11.41s/it]  2%|▏         | 248/12750 [48:33<39:36:42, 11.41s/it]  2%|▏         | 249/12750 [48:45<39:36:39, 11.41s/it]  2%|▏         | 250/12750 [48:56<39:37:39, 11.41s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120599.27lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104901.60lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-250
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-250/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-250/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-225] due to args.save_total_limit
  2%|▏         | 251/12750 [49:08<39:57:23, 11.51s/it]  2%|▏         | 252/12750 [49:19<39:52:55, 11.49s/it]  2%|▏         | 253/12750 [49:31<39:46:55, 11.46s/it]  2%|▏         | 254/12750 [49:42<39:44:31, 11.45s/it]  2%|▏         | 255/12750 [49:54<39:44:24, 11.45s/it]  2%|▏         | 256/12750 [50:12<46:42:26, 13.46s/it]  2%|▏         | 257/12750 [50:23<44:34:27, 12.84s/it]  2%|▏         | 258/12750 [50:34<43:02:19, 12.40s/it]  2%|▏         | 259/12750 [50:46<42:01:39, 12.11s/it]  2%|▏         | 260/12750 [50:57<41:20:28, 11.92s/it]  2%|▏         | 261/12750 [51:09<40:51:43, 11.78s/it]  2%|▏         | 262/12750 [51:20<40:31:25, 11.68s/it]  2%|▏         | 263/12750 [51:32<40:16:13, 11.61s/it]  2%|▏         | 264/12750 [51:43<40:04:54, 11.56s/it]  2%|▏         | 265/12750 [51:55<39:58:04, 11.52s/it]  2%|▏         | 266/12750 [52:06<39:53:42, 11.50s/it]  2%|▏         | 267/12750 [52:18<39:51:22, 11.49s/it]  2%|▏         | 268/12750 [52:29<40:06:04, 11.57s/it]  2%|▏         | 269/12750 [52:41<40:03:05, 11.55s/it]  2%|▏         | 270/12750 [52:52<40:03:53, 11.56s/it]  2%|▏         | 271/12750 [53:04<40:00:00, 11.54s/it]  2%|▏         | 272/12750 [53:15<40:01:14, 11.55s/it]  2%|▏         | 273/12750 [53:27<39:59:56, 11.54s/it]  2%|▏         | 274/12750 [53:39<40:01:00, 11.55s/it]  2%|▏         | 275/12750 [53:50<40:00:18, 11.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 112179.49lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 98439.70lines/s] 
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-275
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-275/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-275/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-250] due to args.save_total_limit
  2%|▏         | 276/12750 [54:02<40:27:22, 11.68s/it]  2%|▏         | 277/12750 [54:14<40:17:40, 11.63s/it]  2%|▏         | 278/12750 [54:25<40:12:43, 11.61s/it]  2%|▏         | 279/12750 [54:37<40:05:35, 11.57s/it]  2%|▏         | 280/12750 [54:48<40:04:23, 11.57s/it]  2%|▏         | 281/12750 [55:00<40:02:20, 11.56s/it]  2%|▏         | 282/12750 [55:11<40:00:33, 11.55s/it]  2%|▏         | 283/12750 [55:23<39:57:25, 11.54s/it]  2%|▏         | 284/12750 [55:34<39:55:12, 11.53s/it]  2%|▏         | 285/12750 [55:46<39:55:15, 11.53s/it]  2%|▏         | 286/12750 [55:57<39:54:33, 11.53s/it]  2%|▏         | 287/12750 [56:09<39:55:21, 11.53s/it]  2%|▏         | 288/12750 [56:27<47:09:16, 13.62s/it]  2%|▏         | 289/12750 [56:39<44:57:25, 12.99s/it]  2%|▏         | 290/12750 [56:50<43:25:14, 12.55s/it]  2%|▏         | 291/12750 [57:02<42:21:50, 12.24s/it]  2%|▏         | 292/12750 [57:13<41:36:56, 12.03s/it]  2%|▏         | 293/12750 [57:25<41:06:29, 11.88s/it]  2%|▏         | 294/12750 [57:36<40:44:32, 11.78s/it]  2%|▏         | 295/12750 [57:48<40:28:03, 11.70s/it]  2%|▏         | 296/12750 [58:00<40:18:19, 11.65s/it]  2%|▏         | 297/12750 [58:11<40:10:57, 11.62s/it]  2%|▏         | 298/12750 [58:23<40:06:12, 11.59s/it]  2%|▏         | 299/12750 [58:34<40:02:45, 11.58s/it]  2%|▏         | 300/12750 [58:46<39:59:12, 11.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120520.46lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104862.55lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-300
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-300/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-300/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-275] due to args.save_total_limit
  2%|▏         | 301/12750 [58:58<40:17:29, 11.65s/it]  2%|▏         | 302/12750 [59:09<40:11:30, 11.62s/it]  2%|▏         | 303/12750 [59:21<40:04:14, 11.59s/it]  2%|▏         | 304/12750 [59:32<39:59:55, 11.57s/it]  2%|▏         | 305/12750 [59:44<39:55:35, 11.55s/it]  2%|▏         | 306/12750 [59:55<39:54:23, 11.54s/it]  2%|▏         | 307/12750 [1:00:07<39:52:34, 11.54s/it]  2%|▏         | 308/12750 [1:00:18<39:52:09, 11.54s/it]  2%|▏         | 309/12750 [1:00:30<39:49:58, 11.53s/it]  2%|▏         | 310/12750 [1:00:41<39:49:59, 11.53s/it]  2%|▏         | 311/12750 [1:00:53<39:47:42, 11.52s/it]  2%|▏         | 312/12750 [1:01:04<39:48:03, 11.52s/it]  2%|▏         | 313/12750 [1:01:16<39:47:50, 11.52s/it]  2%|▏         | 314/12750 [1:01:27<39:48:55, 11.53s/it]  2%|▏         | 315/12750 [1:01:39<39:48:22, 11.52s/it]  2%|▏         | 316/12750 [1:01:50<39:46:25, 11.52s/it]  2%|▏         | 317/12750 [1:02:02<39:46:26, 11.52s/it]  2%|▏         | 318/12750 [1:02:13<39:45:44, 11.51s/it]  3%|▎         | 319/12750 [1:02:25<39:46:06, 11.52s/it]  3%|▎         | 320/12750 [1:02:44<47:47:07, 13.84s/it]  3%|▎         | 321/12750 [1:02:56<45:22:09, 13.14s/it]  3%|▎         | 322/12750 [1:03:07<43:51:38, 12.71s/it]  3%|▎         | 323/12750 [1:03:19<42:40:32, 12.36s/it]  3%|▎         | 324/12750 [1:03:30<41:47:24, 12.11s/it]  3%|▎         | 325/12750 [1:03:42<41:10:23, 11.93s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120321.60lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104463.06lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-325
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-325/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-325/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-300] due to args.save_total_limit
  3%|▎         | 326/12750 [1:03:54<41:04:14, 11.90s/it]  3%|▎         | 327/12750 [1:04:05<40:40:13, 11.79s/it]  3%|▎         | 328/12750 [1:04:17<40:22:24, 11.70s/it]  3%|▎         | 329/12750 [1:04:28<40:09:47, 11.64s/it]  3%|▎         | 330/12750 [1:04:40<40:01:21, 11.60s/it]  3%|▎         | 331/12750 [1:04:51<39:57:57, 11.59s/it]  3%|▎         | 332/12750 [1:05:03<39:54:26, 11.57s/it]  3%|▎         | 333/12750 [1:05:14<39:52:55, 11.56s/it]  3%|▎         | 334/12750 [1:05:26<39:51:38, 11.56s/it]  3%|▎         | 335/12750 [1:05:38<39:52:29, 11.56s/it]  3%|▎         | 336/12750 [1:05:49<39:49:12, 11.55s/it]  3%|▎         | 337/12750 [1:06:01<39:47:09, 11.54s/it]  3%|▎         | 338/12750 [1:06:12<39:46:11, 11.53s/it]  3%|▎         | 339/12750 [1:06:24<39:44:51, 11.53s/it]  3%|▎         | 340/12750 [1:06:35<39:45:13, 11.53s/it]  3%|▎         | 341/12750 [1:06:47<39:45:22, 11.53s/it]  3%|▎         | 342/12750 [1:06:58<39:44:28, 11.53s/it]  3%|▎         | 343/12750 [1:07:10<39:43:31, 11.53s/it]  3%|▎         | 344/12750 [1:07:21<39:44:23, 11.53s/it]  3%|▎         | 345/12750 [1:07:33<39:42:44, 11.52s/it]  3%|▎         | 346/12750 [1:07:44<39:43:35, 11.53s/it]  3%|▎         | 347/12750 [1:07:56<39:42:00, 11.52s/it]  3%|▎         | 348/12750 [1:08:07<39:43:32, 11.53s/it]  3%|▎         | 349/12750 [1:08:19<39:43:43, 11.53s/it]  3%|▎         | 350/12750 [1:08:31<39:44:55, 11.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120369.56lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104695.03lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-350
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-350/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-350/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-325] due to args.save_total_limit
  3%|▎         | 351/12750 [1:08:42<40:07:38, 11.65s/it]  3%|▎         | 352/12750 [1:08:54<40:01:06, 11.62s/it]  3%|▎         | 353/12750 [1:09:13<47:49:27, 13.89s/it]  3%|▎         | 354/12750 [1:09:25<45:24:58, 13.19s/it]  3%|▎         | 355/12750 [1:09:36<43:41:42, 12.69s/it]  3%|▎         | 356/12750 [1:09:48<42:30:51, 12.35s/it]  3%|▎         | 357/12750 [1:09:59<41:39:24, 12.10s/it]  3%|▎         | 358/12750 [1:10:11<41:06:20, 11.94s/it]  3%|▎         | 359/12750 [1:10:22<40:42:29, 11.83s/it]  3%|▎         | 360/12750 [1:10:34<40:24:00, 11.74s/it]  3%|▎         | 361/12750 [1:10:46<40:12:29, 11.68s/it]  3%|▎         | 362/12750 [1:10:57<40:05:54, 11.65s/it]  3%|▎         | 363/12750 [1:11:09<39:59:30, 11.62s/it]  3%|▎         | 364/12750 [1:11:20<39:53:42, 11.60s/it]  3%|▎         | 365/12750 [1:11:32<39:49:11, 11.57s/it]  3%|▎         | 366/12750 [1:11:43<39:49:18, 11.58s/it]  3%|▎         | 367/12750 [1:11:55<39:48:28, 11.57s/it]  3%|▎         | 368/12750 [1:12:06<39:47:00, 11.57s/it]  3%|▎         | 369/12750 [1:12:18<39:44:50, 11.56s/it]  3%|▎         | 370/12750 [1:12:30<39:44:54, 11.56s/it]  3%|▎         | 371/12750 [1:12:41<39:44:14, 11.56s/it]  3%|▎         | 372/12750 [1:12:53<39:43:53, 11.56s/it]  3%|▎         | 373/12750 [1:13:04<39:43:41, 11.56s/it]  3%|▎         | 374/12750 [1:13:16<39:45:17, 11.56s/it]  3%|▎         | 375/12750 [1:13:27<39:45:43, 11.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120309.07lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104559.99lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-375
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-375/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-375/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-350] due to args.save_total_limit
  3%|▎         | 376/12750 [1:13:39<40:04:36, 11.66s/it]  3%|▎         | 377/12750 [1:13:51<39:58:25, 11.63s/it]  3%|▎         | 378/12750 [1:14:02<39:53:12, 11.61s/it]  3%|▎         | 379/12750 [1:14:14<39:50:42, 11.60s/it]  3%|▎         | 380/12750 [1:14:25<39:47:44, 11.58s/it]  3%|▎         | 381/12750 [1:14:37<39:46:52, 11.58s/it]  3%|▎         | 382/12750 [1:14:49<39:44:48, 11.57s/it]  3%|▎         | 383/12750 [1:15:00<39:43:50, 11.57s/it]  3%|▎         | 384/12750 [1:15:12<39:42:52, 11.56s/it]  3%|▎         | 385/12750 [1:15:30<46:28:22, 13.53s/it]  3%|▎         | 386/12750 [1:15:41<44:27:38, 12.95s/it]  3%|▎         | 387/12750 [1:15:53<43:01:16, 12.53s/it]  3%|▎         | 388/12750 [1:16:04<42:02:18, 12.24s/it]  3%|▎         | 389/12750 [1:16:16<41:20:50, 12.04s/it]  3%|▎         | 390/12750 [1:16:28<40:52:17, 11.90s/it]  3%|▎         | 391/12750 [1:16:39<40:30:18, 11.80s/it]  3%|▎         | 392/12750 [1:16:51<40:15:32, 11.73s/it]  3%|▎         | 393/12750 [1:17:02<40:04:57, 11.68s/it]  3%|▎         | 394/12750 [1:17:14<39:59:14, 11.65s/it]  3%|▎         | 395/12750 [1:17:26<40:31:31, 11.81s/it]  3%|▎         | 396/12750 [1:17:38<41:08:03, 11.99s/it]  3%|▎         | 397/12750 [1:17:51<41:23:15, 12.06s/it]  3%|▎         | 398/12750 [1:18:02<41:00:50, 11.95s/it]  3%|▎         | 399/12750 [1:18:14<40:42:33, 11.87s/it]  3%|▎         | 400/12750 [1:18:26<40:29:36, 11.80s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120411.41lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104656.81lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-400
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-400/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-400/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-375] due to args.save_total_limit
  3%|▎         | 401/12750 [1:18:38<40:33:36, 11.82s/it]  3%|▎         | 402/12750 [1:18:49<40:17:33, 11.75s/it]  3%|▎         | 403/12750 [1:19:01<40:05:30, 11.69s/it]  3%|▎         | 404/12750 [1:19:12<39:59:42, 11.66s/it]  3%|▎         | 405/12750 [1:19:24<39:55:03, 11.64s/it]  3%|▎         | 406/12750 [1:19:36<39:51:51, 11.63s/it]  3%|▎         | 407/12750 [1:19:47<39:47:46, 11.61s/it]  3%|▎         | 408/12750 [1:19:59<39:46:09, 11.60s/it]  3%|▎         | 409/12750 [1:20:10<39:45:22, 11.60s/it]  3%|▎         | 410/12750 [1:20:22<39:42:15, 11.58s/it]  3%|▎         | 411/12750 [1:20:33<39:41:06, 11.58s/it]  3%|▎         | 412/12750 [1:20:45<39:42:11, 11.58s/it]  3%|▎         | 413/12750 [1:20:57<39:42:29, 11.59s/it]  3%|▎         | 414/12750 [1:21:08<39:42:40, 11.59s/it]  3%|▎         | 415/12750 [1:21:20<39:41:18, 11.58s/it]  3%|▎         | 416/12750 [1:21:31<39:42:00, 11.59s/it]  3%|▎         | 417/12750 [1:21:50<47:27:03, 13.85s/it]  3%|▎         | 418/12750 [1:22:02<45:06:33, 13.17s/it]  3%|▎         | 419/12750 [1:22:14<43:28:30, 12.69s/it]  3%|▎         | 420/12750 [1:22:25<42:16:16, 12.34s/it]  3%|▎         | 421/12750 [1:22:37<41:29:04, 12.11s/it]  3%|▎         | 422/12750 [1:22:48<40:55:39, 11.95s/it]  3%|▎         | 423/12750 [1:23:00<40:31:46, 11.84s/it]  3%|▎         | 424/12750 [1:23:11<40:15:00, 11.76s/it]  3%|▎         | 425/12750 [1:23:23<40:04:49, 11.71s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120624.19lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104972.97lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-425
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-425/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-425/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-400] due to args.save_total_limit
  3%|▎         | 426/12750 [1:23:35<40:16:40, 11.77s/it]  3%|▎         | 427/12750 [1:23:47<40:04:19, 11.71s/it]  3%|▎         | 428/12750 [1:23:58<39:55:20, 11.66s/it]  3%|▎         | 429/12750 [1:24:10<39:47:18, 11.63s/it]  3%|▎         | 430/12750 [1:24:21<39:41:29, 11.60s/it]  3%|▎         | 431/12750 [1:24:33<39:39:44, 11.59s/it]  3%|▎         | 432/12750 [1:24:44<39:37:33, 11.58s/it]  3%|▎         | 433/12750 [1:24:56<39:38:36, 11.59s/it]  3%|▎         | 434/12750 [1:25:07<39:37:16, 11.58s/it]  3%|▎         | 435/12750 [1:25:19<39:36:02, 11.58s/it]  3%|▎         | 436/12750 [1:25:31<39:35:36, 11.58s/it]  3%|▎         | 437/12750 [1:25:42<39:34:19, 11.57s/it]  3%|▎         | 438/12750 [1:25:54<39:32:15, 11.56s/it]  3%|▎         | 439/12750 [1:26:05<39:33:27, 11.57s/it]  3%|▎         | 440/12750 [1:26:17<39:33:46, 11.57s/it]  3%|▎         | 441/12750 [1:26:28<39:34:06, 11.57s/it]  3%|▎         | 442/12750 [1:26:40<39:31:30, 11.56s/it]  3%|▎         | 443/12750 [1:26:52<39:33:37, 11.57s/it]  3%|▎         | 444/12750 [1:27:03<39:34:09, 11.58s/it]  3%|▎         | 445/12750 [1:27:15<39:33:57, 11.58s/it]  3%|▎         | 446/12750 [1:27:26<39:33:54, 11.58s/it]  4%|▎         | 447/12750 [1:27:38<39:32:29, 11.57s/it]  4%|▎         | 448/12750 [1:27:49<39:33:23, 11.58s/it]  4%|▎         | 449/12750 [1:28:09<47:19:46, 13.85s/it]  4%|▎         | 450/12750 [1:28:20<45:01:21, 13.18s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120382.99lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104724.66lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-450
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-450/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-450/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-425] due to args.save_total_limit
  4%|▎         | 451/12750 [1:28:32<43:35:40, 12.76s/it]  4%|▎         | 452/12750 [1:28:43<42:16:22, 12.37s/it]  4%|▎         | 453/12750 [1:28:55<41:17:46, 12.09s/it]  4%|▎         | 454/12750 [1:29:06<40:40:47, 11.91s/it]  4%|▎         | 455/12750 [1:29:18<40:12:59, 11.78s/it]  4%|▎         | 456/12750 [1:29:29<39:53:02, 11.68s/it]  4%|▎         | 457/12750 [1:29:41<39:40:09, 11.62s/it]  4%|▎         | 458/12750 [1:29:52<39:31:41, 11.58s/it]  4%|▎         | 459/12750 [1:30:04<39:25:30, 11.55s/it]  4%|▎         | 460/12750 [1:30:15<39:20:00, 11.52s/it]  4%|▎         | 461/12750 [1:30:27<39:18:14, 11.51s/it]  4%|▎         | 462/12750 [1:30:38<39:14:28, 11.50s/it]  4%|▎         | 463/12750 [1:30:50<39:12:42, 11.49s/it]  4%|▎         | 464/12750 [1:31:01<39:08:41, 11.47s/it]  4%|▎         | 465/12750 [1:31:12<39:08:25, 11.47s/it]  4%|▎         | 466/12750 [1:31:24<39:06:56, 11.46s/it]  4%|▎         | 467/12750 [1:31:35<39:05:04, 11.46s/it]  4%|▎         | 468/12750 [1:31:47<39:04:20, 11.45s/it]  4%|▎         | 469/12750 [1:31:58<39:09:25, 11.48s/it]  4%|▎         | 470/12750 [1:32:10<39:28:10, 11.57s/it]  4%|▎         | 471/12750 [1:32:22<39:51:00, 11.68s/it]  4%|▎         | 472/12750 [1:32:34<40:01:45, 11.74s/it]  4%|▎         | 473/12750 [1:32:46<40:09:58, 11.78s/it]  4%|▎         | 474/12750 [1:32:58<40:16:07, 11.81s/it]  4%|▎         | 475/12750 [1:33:10<40:22:05, 11.84s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120503.92lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104658.85lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-475
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-475/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-475/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-450] due to args.save_total_limit
  4%|▎         | 476/12750 [1:33:22<40:39:20, 11.92s/it]  4%|▎         | 477/12750 [1:33:34<40:39:21, 11.93s/it]  4%|▎         | 478/12750 [1:33:45<40:27:03, 11.87s/it]  4%|▍         | 479/12750 [1:33:57<40:17:57, 11.82s/it]  4%|▍         | 480/12750 [1:34:09<40:37:17, 11.92s/it]  4%|▍         | 481/12750 [1:34:28<48:03:58, 14.10s/it]  4%|▍         | 482/12750 [1:34:40<45:33:39, 13.37s/it]  4%|▍         | 483/12750 [1:34:52<43:37:22, 12.80s/it]  4%|▍         | 484/12750 [1:35:03<42:16:37, 12.41s/it]  4%|▍         | 485/12750 [1:35:15<41:21:49, 12.14s/it]  4%|▍         | 486/12750 [1:35:26<40:39:43, 11.94s/it]  4%|▍         | 487/12750 [1:35:38<40:12:48, 11.81s/it]  4%|▍         | 488/12750 [1:35:49<39:54:54, 11.72s/it]  4%|▍         | 489/12750 [1:36:01<39:39:21, 11.64s/it]  4%|▍         | 490/12750 [1:36:12<39:29:41, 11.60s/it]  4%|▍         | 491/12750 [1:36:24<39:22:54, 11.56s/it]  4%|▍         | 492/12750 [1:36:35<39:19:24, 11.55s/it]  4%|▍         | 493/12750 [1:36:47<39:15:46, 11.53s/it]  4%|▍         | 494/12750 [1:36:58<39:11:39, 11.51s/it]  4%|▍         | 495/12750 [1:37:10<39:11:38, 11.51s/it]  4%|▍         | 496/12750 [1:37:21<39:09:09, 11.50s/it]  4%|▍         | 497/12750 [1:37:32<39:07:07, 11.49s/it]  4%|▍         | 498/12750 [1:37:44<39:04:55, 11.48s/it]  4%|▍         | 499/12750 [1:37:55<39:03:34, 11.48s/it]  4%|▍         | 500/12750 [1:38:07<39:02:28, 11.47s/it]                                                          4%|▍         | 500/12750 [1:38:07<39:02:28, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120516.61lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104832.17lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-500
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-500/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-500/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-475] due to args.save_total_limit
  4%|▍         | 501/12750 [1:38:19<39:33:05, 11.62s/it]  4%|▍         | 502/12750 [1:38:30<39:21:39, 11.57s/it]  4%|▍         | 503/12750 [1:38:42<39:13:29, 11.53s/it]  4%|▍         | 504/12750 [1:38:53<39:07:43, 11.50s/it]  4%|▍         | 505/12750 [1:39:05<39:03:33, 11.48s/it]  4%|▍         | 506/12750 [1:39:16<39:02:45, 11.48s/it]  4%|▍         | 507/12750 [1:39:28<39:01:29, 11.48s/it]  4%|▍         | 508/12750 [1:39:39<39:00:31, 11.47s/it]  4%|▍         | 509/12750 [1:39:46<34:27:24, 10.13s/it]  4%|▍         | 510/12750 [1:39:47<24:55:25,  7.33s/it]  4%|▍         | 511/12750 [1:40:10<41:05:09, 12.09s/it]  4%|▍         | 512/12750 [1:40:22<40:31:19, 11.92s/it]  4%|▍         | 513/12750 [1:40:33<40:04:56, 11.79s/it]  4%|▍         | 514/12750 [1:40:52<47:23:49, 13.94s/it]  4%|▍         | 515/12750 [1:41:03<44:53:47, 13.21s/it]  4%|▍         | 516/12750 [1:41:15<43:10:26, 12.70s/it]  4%|▍         | 517/12750 [1:41:26<41:56:31, 12.34s/it]  4%|▍         | 518/12750 [1:41:38<41:05:26, 12.09s/it]  4%|▍         | 519/12750 [1:41:49<40:27:29, 11.91s/it]  4%|▍         | 520/12750 [1:42:01<39:59:39, 11.77s/it]  4%|▍         | 521/12750 [1:42:12<39:41:55, 11.69s/it]  4%|▍         | 522/12750 [1:42:24<39:28:46, 11.62s/it]  4%|▍         | 523/12750 [1:42:35<39:18:48, 11.58s/it]  4%|▍         | 524/12750 [1:42:47<39:13:53, 11.55s/it]  4%|▍         | 525/12750 [1:42:58<39:08:53, 11.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120441.63lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104770.00lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-525
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-525/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-525/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-500] due to args.save_total_limit
  4%|▍         | 526/12750 [1:43:10<39:26:32, 11.62s/it]  4%|▍         | 527/12750 [1:43:22<39:17:39, 11.57s/it]  4%|▍         | 528/12750 [1:43:33<39:13:14, 11.55s/it]  4%|▍         | 529/12750 [1:43:45<39:09:30, 11.54s/it]  4%|▍         | 530/12750 [1:43:56<39:07:25, 11.53s/it]  4%|▍         | 531/12750 [1:44:08<39:07:15, 11.53s/it]  4%|▍         | 532/12750 [1:44:19<39:06:16, 11.52s/it]  4%|▍         | 533/12750 [1:44:31<39:02:54, 11.51s/it]  4%|▍         | 534/12750 [1:44:42<39:02:51, 11.51s/it]  4%|▍         | 535/12750 [1:44:54<39:00:06, 11.49s/it]  4%|▍         | 536/12750 [1:45:05<39:02:02, 11.51s/it]  4%|▍         | 537/12750 [1:45:17<39:01:21, 11.50s/it]  4%|▍         | 538/12750 [1:45:28<39:01:28, 11.50s/it]  4%|▍         | 539/12750 [1:45:40<39:01:16, 11.50s/it]  4%|▍         | 540/12750 [1:45:51<38:59:43, 11.50s/it]  4%|▍         | 541/12750 [1:46:03<38:58:35, 11.49s/it]  4%|▍         | 542/12750 [1:46:14<38:58:58, 11.50s/it]  4%|▍         | 543/12750 [1:46:26<38:59:31, 11.50s/it]  4%|▍         | 544/12750 [1:46:37<38:59:23, 11.50s/it]  4%|▍         | 545/12750 [1:46:49<38:57:34, 11.49s/it]  4%|▍         | 546/12750 [1:47:07<46:11:13, 13.62s/it]  4%|▍         | 547/12750 [1:47:19<43:59:18, 12.98s/it]  4%|▍         | 548/12750 [1:47:30<42:27:41, 12.53s/it]  4%|▍         | 549/12750 [1:47:42<41:20:38, 12.20s/it]  4%|▍         | 550/12750 [1:47:53<40:35:31, 11.98s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120362.39lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104655.65lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-550
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-550/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-550/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-525] due to args.save_total_limit
  4%|▍         | 551/12750 [1:48:05<40:24:50, 11.93s/it]  4%|▍         | 552/12750 [1:48:16<39:57:25, 11.79s/it]  4%|▍         | 553/12750 [1:48:28<39:39:36, 11.71s/it]  4%|▍         | 554/12750 [1:48:39<39:25:19, 11.64s/it]  4%|▍         | 555/12750 [1:48:51<39:18:22, 11.60s/it]  4%|▍         | 556/12750 [1:49:02<39:11:40, 11.57s/it]  4%|▍         | 557/12750 [1:49:14<39:05:49, 11.54s/it]  4%|▍         | 558/12750 [1:49:25<39:02:12, 11.53s/it]  4%|▍         | 559/12750 [1:49:37<38:59:07, 11.51s/it]  4%|▍         | 560/12750 [1:49:48<38:55:52, 11.50s/it]  4%|▍         | 561/12750 [1:50:00<38:51:58, 11.48s/it]  4%|▍         | 562/12750 [1:50:11<38:52:48, 11.48s/it]  4%|▍         | 563/12750 [1:50:23<38:51:12, 11.48s/it]  4%|▍         | 564/12750 [1:50:34<38:49:39, 11.47s/it]  4%|▍         | 565/12750 [1:50:46<38:52:44, 11.49s/it]  4%|▍         | 566/12750 [1:50:57<38:51:32, 11.48s/it]  4%|▍         | 567/12750 [1:51:09<38:50:41, 11.48s/it]  4%|▍         | 568/12750 [1:51:20<38:49:10, 11.47s/it]  4%|▍         | 569/12750 [1:51:31<38:50:30, 11.48s/it]  4%|▍         | 570/12750 [1:51:43<38:48:08, 11.47s/it]  4%|▍         | 571/12750 [1:51:54<38:49:10, 11.47s/it]  4%|▍         | 572/12750 [1:52:06<38:50:34, 11.48s/it]  4%|▍         | 573/12750 [1:52:17<38:53:09, 11.50s/it]  5%|▍         | 574/12750 [1:52:29<38:48:34, 11.47s/it]  5%|▍         | 575/12750 [1:52:40<38:49:03, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120276.87lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104616.79lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-575
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-575/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-575/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-550] due to args.save_total_limit
  5%|▍         | 576/12750 [1:52:52<39:07:32, 11.57s/it]  5%|▍         | 577/12750 [1:53:04<39:03:13, 11.55s/it]  5%|▍         | 578/12750 [1:53:23<46:36:58, 13.79s/it]  5%|▍         | 579/12750 [1:53:34<44:17:19, 13.10s/it]  5%|▍         | 580/12750 [1:53:46<42:40:33, 12.62s/it]  5%|▍         | 581/12750 [1:53:57<41:30:42, 12.28s/it]  5%|▍         | 582/12750 [1:54:09<40:42:44, 12.05s/it]  5%|▍         | 583/12750 [1:54:20<40:06:40, 11.87s/it]  5%|▍         | 584/12750 [1:54:32<39:40:24, 11.74s/it]  5%|▍         | 585/12750 [1:54:43<39:22:49, 11.65s/it]  5%|▍         | 586/12750 [1:54:54<39:12:04, 11.60s/it]  5%|▍         | 587/12750 [1:55:06<39:03:59, 11.56s/it]  5%|▍         | 588/12750 [1:55:17<38:57:25, 11.53s/it]  5%|▍         | 589/12750 [1:55:29<38:53:13, 11.51s/it]  5%|▍         | 590/12750 [1:55:40<38:54:08, 11.52s/it]  5%|▍         | 591/12750 [1:55:52<38:52:05, 11.51s/it]  5%|▍         | 592/12750 [1:56:03<38:50:15, 11.50s/it]  5%|▍         | 593/12750 [1:56:15<38:49:50, 11.50s/it]  5%|▍         | 594/12750 [1:56:26<38:49:59, 11.50s/it]  5%|▍         | 595/12750 [1:56:38<38:51:51, 11.51s/it]  5%|▍         | 596/12750 [1:56:49<38:52:00, 11.51s/it]  5%|▍         | 597/12750 [1:57:01<38:53:40, 11.52s/it]  5%|▍         | 598/12750 [1:57:12<38:54:10, 11.52s/it]  5%|▍         | 599/12750 [1:57:24<38:51:36, 11.51s/it]  5%|▍         | 600/12750 [1:57:35<38:49:46, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120350.24lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104686.13lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-600
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-600/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-600/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-575] due to args.save_total_limit
  5%|▍         | 601/12750 [1:57:47<39:08:13, 11.60s/it]  5%|▍         | 602/12750 [1:57:59<39:00:15, 11.56s/it]  5%|▍         | 603/12750 [1:58:10<38:52:25, 11.52s/it]  5%|▍         | 604/12750 [1:58:22<38:50:13, 11.51s/it]  5%|▍         | 605/12750 [1:58:33<38:46:47, 11.50s/it]  5%|▍         | 606/12750 [1:58:45<38:46:55, 11.50s/it]  5%|▍         | 607/12750 [1:58:56<38:44:43, 11.49s/it]  5%|▍         | 608/12750 [1:59:08<38:43:17, 11.48s/it]  5%|▍         | 609/12750 [1:59:19<38:41:40, 11.47s/it]  5%|▍         | 610/12750 [1:59:38<46:17:13, 13.73s/it]  5%|▍         | 611/12750 [1:59:49<43:59:38, 13.05s/it]  5%|▍         | 612/12750 [2:00:01<42:23:15, 12.57s/it]  5%|▍         | 613/12750 [2:00:12<41:16:34, 12.24s/it]  5%|▍         | 614/12750 [2:00:24<40:29:23, 12.01s/it]  5%|▍         | 615/12750 [2:00:35<39:55:00, 11.84s/it]  5%|▍         | 616/12750 [2:00:47<39:31:48, 11.73s/it]  5%|▍         | 617/12750 [2:00:58<39:14:31, 11.64s/it]  5%|▍         | 618/12750 [2:01:10<39:03:56, 11.59s/it]  5%|▍         | 619/12750 [2:01:21<38:55:28, 11.55s/it]  5%|▍         | 620/12750 [2:01:33<38:49:02, 11.52s/it]  5%|▍         | 621/12750 [2:01:44<38:43:41, 11.49s/it]  5%|▍         | 622/12750 [2:01:56<38:42:29, 11.49s/it]  5%|▍         | 623/12750 [2:02:07<38:41:18, 11.48s/it]  5%|▍         | 624/12750 [2:02:18<38:40:10, 11.48s/it]  5%|▍         | 625/12750 [2:02:30<38:39:45, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120508.02lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104820.33lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-625
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-625/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-625/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-600] due to args.save_total_limit
  5%|▍         | 626/12750 [2:02:42<38:57:52, 11.57s/it]  5%|▍         | 627/12750 [2:02:53<38:51:35, 11.54s/it]  5%|▍         | 628/12750 [2:03:05<38:47:39, 11.52s/it]  5%|▍         | 629/12750 [2:03:16<38:45:00, 11.51s/it]  5%|▍         | 630/12750 [2:03:28<38:41:13, 11.49s/it]  5%|▍         | 631/12750 [2:03:39<38:38:35, 11.48s/it]  5%|▍         | 632/12750 [2:03:51<38:38:47, 11.48s/it]  5%|▍         | 633/12750 [2:04:02<38:35:30, 11.47s/it]  5%|▍         | 634/12750 [2:04:13<38:34:46, 11.46s/it]  5%|▍         | 635/12750 [2:04:25<38:32:50, 11.45s/it]  5%|▍         | 636/12750 [2:04:36<38:31:53, 11.45s/it]  5%|▍         | 637/12750 [2:04:48<38:31:46, 11.45s/it]  5%|▌         | 638/12750 [2:04:59<38:31:40, 11.45s/it]  5%|▌         | 639/12750 [2:05:11<38:34:27, 11.47s/it]  5%|▌         | 640/12750 [2:05:22<38:34:42, 11.47s/it]  5%|▌         | 641/12750 [2:05:34<38:33:45, 11.46s/it]  5%|▌         | 642/12750 [2:05:45<38:35:19, 11.47s/it]  5%|▌         | 643/12750 [2:06:03<45:16:17, 13.46s/it]  5%|▌         | 644/12750 [2:06:15<43:17:13, 12.87s/it]  5%|▌         | 645/12750 [2:06:26<41:53:40, 12.46s/it]  5%|▌         | 646/12750 [2:06:38<40:53:57, 12.16s/it]  5%|▌         | 647/12750 [2:06:49<40:12:51, 11.96s/it]  5%|▌         | 648/12750 [2:07:01<39:44:01, 11.82s/it]  5%|▌         | 649/12750 [2:07:12<39:24:43, 11.72s/it]  5%|▌         | 650/12750 [2:07:24<39:10:59, 11.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120286.96lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104646.66lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-650
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-650/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-650/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-625] due to args.save_total_limit
  5%|▌         | 651/12750 [2:07:35<39:18:37, 11.70s/it]  5%|▌         | 652/12750 [2:07:47<39:03:26, 11.62s/it]  5%|▌         | 653/12750 [2:07:58<38:54:35, 11.58s/it]  5%|▌         | 654/12750 [2:08:10<38:45:43, 11.54s/it]  5%|▌         | 655/12750 [2:08:21<38:40:31, 11.51s/it]  5%|▌         | 656/12750 [2:08:33<38:37:20, 11.50s/it]  5%|▌         | 657/12750 [2:08:44<38:34:47, 11.48s/it]  5%|▌         | 658/12750 [2:08:56<38:32:51, 11.48s/it]  5%|▌         | 659/12750 [2:09:07<38:31:43, 11.47s/it]  5%|▌         | 660/12750 [2:09:19<38:31:36, 11.47s/it]  5%|▌         | 661/12750 [2:09:30<38:30:37, 11.47s/it]  5%|▌         | 662/12750 [2:09:41<38:28:08, 11.46s/it]  5%|▌         | 663/12750 [2:09:53<38:26:53, 11.45s/it]  5%|▌         | 664/12750 [2:10:04<38:25:26, 11.45s/it]  5%|▌         | 665/12750 [2:10:16<38:23:38, 11.44s/it]  5%|▌         | 666/12750 [2:10:27<38:26:47, 11.45s/it]  5%|▌         | 667/12750 [2:10:39<38:26:49, 11.45s/it]  5%|▌         | 668/12750 [2:10:50<38:28:16, 11.46s/it]  5%|▌         | 669/12750 [2:11:02<38:26:28, 11.46s/it]  5%|▌         | 670/12750 [2:11:13<38:26:29, 11.46s/it]  5%|▌         | 671/12750 [2:11:25<38:25:57, 11.45s/it]  5%|▌         | 672/12750 [2:11:36<38:26:07, 11.46s/it]  5%|▌         | 673/12750 [2:11:48<38:28:47, 11.47s/it]  5%|▌         | 674/12750 [2:11:59<38:28:50, 11.47s/it]  5%|▌         | 675/12750 [2:12:18<45:58:01, 13.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120437.79lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104728.24lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-675
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-675/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-675/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-650] due to args.save_total_limit
  5%|▌         | 676/12750 [2:12:30<44:00:53, 13.12s/it]  5%|▌         | 677/12750 [2:12:41<42:19:03, 12.62s/it]  5%|▌         | 678/12750 [2:12:53<41:08:12, 12.27s/it]  5%|▌         | 679/12750 [2:13:04<40:20:47, 12.03s/it]  5%|▌         | 680/12750 [2:13:16<39:46:40, 11.86s/it]  5%|▌         | 681/12750 [2:13:27<39:22:26, 11.74s/it]  5%|▌         | 682/12750 [2:13:38<39:05:47, 11.66s/it]  5%|▌         | 683/12750 [2:13:50<38:51:42, 11.59s/it]  5%|▌         | 684/12750 [2:14:01<38:43:03, 11.55s/it]  5%|▌         | 685/12750 [2:14:13<38:36:39, 11.52s/it]  5%|▌         | 686/12750 [2:14:24<38:32:48, 11.50s/it]  5%|▌         | 687/12750 [2:14:36<38:28:53, 11.48s/it]  5%|▌         | 688/12750 [2:14:47<38:27:07, 11.48s/it]  5%|▌         | 689/12750 [2:14:59<38:23:30, 11.46s/it]  5%|▌         | 690/12750 [2:15:10<38:22:42, 11.46s/it]  5%|▌         | 691/12750 [2:15:21<38:22:14, 11.45s/it]  5%|▌         | 692/12750 [2:15:33<38:23:23, 11.46s/it]  5%|▌         | 693/12750 [2:15:45<38:31:01, 11.50s/it]  5%|▌         | 694/12750 [2:15:56<38:29:04, 11.49s/it]  5%|▌         | 695/12750 [2:16:07<38:25:52, 11.48s/it]  5%|▌         | 696/12750 [2:16:19<38:25:21, 11.48s/it]  5%|▌         | 697/12750 [2:16:30<38:23:50, 11.47s/it]  5%|▌         | 698/12750 [2:16:42<38:24:11, 11.47s/it]  5%|▌         | 699/12750 [2:16:53<38:21:49, 11.46s/it]  5%|▌         | 700/12750 [2:17:05<38:22:31, 11.46s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120369.69lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104529.69lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-700
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-700/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-700/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-675] due to args.save_total_limit
  5%|▌         | 701/12750 [2:17:17<38:39:53, 11.55s/it]  6%|▌         | 702/12750 [2:17:28<38:34:03, 11.52s/it]  6%|▌         | 703/12750 [2:17:39<38:29:30, 11.50s/it]  6%|▌         | 704/12750 [2:17:51<38:27:03, 11.49s/it]  6%|▌         | 705/12750 [2:18:02<38:22:58, 11.47s/it]  6%|▌         | 706/12750 [2:18:14<38:22:37, 11.47s/it]  6%|▌         | 707/12750 [2:18:33<45:55:35, 13.73s/it]  6%|▌         | 708/12750 [2:18:44<43:42:18, 13.07s/it]  6%|▌         | 709/12750 [2:18:56<42:05:05, 12.58s/it]  6%|▌         | 710/12750 [2:19:07<40:55:44, 12.24s/it]  6%|▌         | 711/12750 [2:19:19<40:07:42, 12.00s/it]  6%|▌         | 712/12750 [2:19:30<39:34:55, 11.84s/it]  6%|▌         | 713/12750 [2:19:42<39:10:42, 11.72s/it]  6%|▌         | 714/12750 [2:19:53<38:54:33, 11.64s/it]  6%|▌         | 715/12750 [2:20:04<38:41:58, 11.58s/it]  6%|▌         | 716/12750 [2:20:16<38:36:28, 11.55s/it]  6%|▌         | 717/12750 [2:20:27<38:29:18, 11.51s/it]  6%|▌         | 718/12750 [2:20:39<38:25:59, 11.50s/it]  6%|▌         | 719/12750 [2:20:50<38:23:56, 11.49s/it]  6%|▌         | 720/12750 [2:21:02<38:22:33, 11.48s/it]  6%|▌         | 721/12750 [2:21:13<38:21:33, 11.48s/it]  6%|▌         | 722/12750 [2:21:25<38:21:10, 11.48s/it]  6%|▌         | 723/12750 [2:21:36<38:19:19, 11.47s/it]  6%|▌         | 724/12750 [2:21:48<38:17:30, 11.46s/it]  6%|▌         | 725/12750 [2:21:59<38:16:30, 11.46s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120376.98lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104691.64lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-725
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-725/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-725/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-700] due to args.save_total_limit
  6%|▌         | 726/12750 [2:22:11<38:36:02, 11.56s/it]  6%|▌         | 727/12750 [2:22:22<38:28:22, 11.52s/it]  6%|▌         | 728/12750 [2:22:34<38:29:48, 11.53s/it]  6%|▌         | 729/12750 [2:22:45<38:27:01, 11.51s/it]  6%|▌         | 730/12750 [2:22:57<38:24:09, 11.50s/it]  6%|▌         | 731/12750 [2:23:08<38:22:30, 11.49s/it]  6%|▌         | 732/12750 [2:23:20<38:21:04, 11.49s/it]  6%|▌         | 733/12750 [2:23:31<38:19:53, 11.48s/it]  6%|▌         | 734/12750 [2:23:43<38:18:01, 11.47s/it]  6%|▌         | 735/12750 [2:23:54<38:16:03, 11.47s/it]  6%|▌         | 736/12750 [2:24:06<38:14:20, 11.46s/it]  6%|▌         | 737/12750 [2:24:17<38:12:17, 11.45s/it]  6%|▌         | 738/12750 [2:24:28<38:11:56, 11.45s/it]  6%|▌         | 739/12750 [2:24:47<45:40:21, 13.69s/it]  6%|▌         | 740/12750 [2:24:59<43:29:10, 13.04s/it]  6%|▌         | 741/12750 [2:25:10<41:55:06, 12.57s/it]  6%|▌         | 742/12750 [2:25:22<40:47:14, 12.23s/it]  6%|▌         | 743/12750 [2:25:33<40:01:27, 12.00s/it]  6%|▌         | 744/12750 [2:25:45<39:28:00, 11.83s/it]  6%|▌         | 745/12750 [2:25:56<39:06:12, 11.73s/it]  6%|▌         | 746/12750 [2:26:08<38:50:44, 11.65s/it]  6%|▌         | 747/12750 [2:26:19<38:38:20, 11.59s/it]  6%|▌         | 748/12750 [2:26:31<38:33:08, 11.56s/it]  6%|▌         | 749/12750 [2:26:42<38:27:04, 11.53s/it]  6%|▌         | 750/12750 [2:26:53<38:21:28, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120085.82lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104438.40lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-750
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-750/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-750/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-725] due to args.save_total_limit
  6%|▌         | 751/12750 [2:27:05<38:35:44, 11.58s/it]  6%|▌         | 752/12750 [2:27:17<38:28:08, 11.54s/it]  6%|▌         | 753/12750 [2:27:28<38:25:07, 11.53s/it]  6%|▌         | 754/12750 [2:27:40<38:21:03, 11.51s/it]  6%|▌         | 755/12750 [2:27:51<38:18:58, 11.50s/it]  6%|▌         | 756/12750 [2:28:03<38:15:16, 11.48s/it]  6%|▌         | 757/12750 [2:28:14<38:14:17, 11.48s/it]  6%|▌         | 758/12750 [2:28:25<38:12:17, 11.47s/it]  6%|▌         | 759/12750 [2:28:37<38:10:10, 11.46s/it]  6%|▌         | 760/12750 [2:28:48<38:08:51, 11.45s/it]  6%|▌         | 761/12750 [2:29:00<38:09:11, 11.46s/it]  6%|▌         | 762/12750 [2:29:11<38:08:52, 11.46s/it]  6%|▌         | 763/12750 [2:29:23<38:08:08, 11.45s/it]  6%|▌         | 764/12750 [2:29:34<38:08:23, 11.46s/it]  6%|▌         | 765/12750 [2:29:46<38:10:46, 11.47s/it]  6%|▌         | 766/12750 [2:29:57<38:09:13, 11.46s/it]  6%|▌         | 767/12750 [2:30:09<38:09:21, 11.46s/it]  6%|▌         | 768/12750 [2:30:20<38:11:47, 11.48s/it]  6%|▌         | 769/12750 [2:30:32<38:11:47, 11.48s/it]  6%|▌         | 770/12750 [2:30:43<38:10:42, 11.47s/it]  6%|▌         | 771/12750 [2:31:02<45:42:33, 13.74s/it]  6%|▌         | 772/12750 [2:31:13<43:25:33, 13.05s/it]  6%|▌         | 773/12750 [2:31:25<41:50:27, 12.58s/it]  6%|▌         | 774/12750 [2:31:36<40:43:43, 12.24s/it]  6%|▌         | 775/12750 [2:31:48<39:55:47, 12.00s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120373.65lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104677.52lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-775
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-775/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-775/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-750] due to args.save_total_limit
  6%|▌         | 776/12750 [2:32:00<39:41:51, 11.94s/it]  6%|▌         | 777/12750 [2:32:11<39:13:28, 11.79s/it]  6%|▌         | 778/12750 [2:32:23<38:51:43, 11.69s/it]  6%|▌         | 779/12750 [2:32:34<38:39:02, 11.62s/it]  6%|▌         | 780/12750 [2:32:45<38:29:11, 11.57s/it]  6%|▌         | 781/12750 [2:32:57<38:21:30, 11.54s/it]  6%|▌         | 782/12750 [2:33:08<38:17:45, 11.52s/it]  6%|▌         | 783/12750 [2:33:20<38:14:37, 11.50s/it]  6%|▌         | 784/12750 [2:33:31<38:13:15, 11.50s/it]  6%|▌         | 785/12750 [2:33:43<38:10:25, 11.49s/it]  6%|▌         | 786/12750 [2:33:54<38:07:54, 11.47s/it]  6%|▌         | 787/12750 [2:34:06<38:08:29, 11.48s/it]  6%|▌         | 788/12750 [2:34:17<38:08:27, 11.48s/it]  6%|▌         | 789/12750 [2:34:29<38:07:45, 11.48s/it]  6%|▌         | 790/12750 [2:34:40<38:08:13, 11.48s/it]  6%|▌         | 791/12750 [2:34:52<38:08:35, 11.48s/it]  6%|▌         | 792/12750 [2:35:03<38:05:25, 11.47s/it]  6%|▌         | 793/12750 [2:35:15<38:06:13, 11.47s/it]  6%|▌         | 794/12750 [2:35:26<38:05:12, 11.47s/it]  6%|▌         | 795/12750 [2:35:38<38:05:20, 11.47s/it]  6%|▌         | 796/12750 [2:35:49<38:05:01, 11.47s/it]  6%|▋         | 797/12750 [2:36:00<38:03:44, 11.46s/it]  6%|▋         | 798/12750 [2:36:12<38:04:34, 11.47s/it]  6%|▋         | 799/12750 [2:36:23<38:03:02, 11.46s/it]  6%|▋         | 800/12750 [2:36:35<38:03:35, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120310.61lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104721.56lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-800
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-800/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-800/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-775] due to args.save_total_limit
  6%|▋         | 801/12750 [2:36:47<38:23:26, 11.57s/it]  6%|▋         | 802/12750 [2:36:58<38:17:41, 11.54s/it]  6%|▋         | 803/12750 [2:37:17<45:28:27, 13.70s/it]  6%|▋         | 804/12750 [2:37:28<43:13:41, 13.03s/it]  6%|▋         | 805/12750 [2:37:40<41:39:44, 12.56s/it]  6%|▋         | 806/12750 [2:37:51<40:36:06, 12.24s/it]  6%|▋         | 807/12750 [2:38:03<39:50:19, 12.01s/it]  6%|▋         | 808/12750 [2:38:14<39:18:22, 11.85s/it]  6%|▋         | 809/12750 [2:38:26<38:54:51, 11.73s/it]  6%|▋         | 810/12750 [2:38:37<38:38:22, 11.65s/it]  6%|▋         | 811/12750 [2:38:49<38:28:26, 11.60s/it]  6%|▋         | 812/12750 [2:39:00<38:21:31, 11.57s/it]  6%|▋         | 813/12750 [2:39:12<38:18:29, 11.55s/it]  6%|▋         | 814/12750 [2:39:23<38:13:57, 11.53s/it]  6%|▋         | 815/12750 [2:39:35<38:12:24, 11.52s/it]  6%|▋         | 816/12750 [2:39:46<38:08:56, 11.51s/it]  6%|▋         | 817/12750 [2:39:58<38:05:29, 11.49s/it]  6%|▋         | 818/12750 [2:40:09<38:02:58, 11.48s/it]  6%|▋         | 819/12750 [2:40:20<38:01:31, 11.47s/it]  6%|▋         | 820/12750 [2:40:32<37:59:32, 11.46s/it]  6%|▋         | 821/12750 [2:40:43<37:57:01, 11.45s/it]  6%|▋         | 822/12750 [2:40:55<37:57:53, 11.46s/it]  6%|▋         | 823/12750 [2:41:06<37:54:33, 11.44s/it]  6%|▋         | 824/12750 [2:41:18<37:55:43, 11.45s/it]  6%|▋         | 825/12750 [2:41:29<37:55:43, 11.45s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120504.30lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104781.15lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-825
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-825/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-825/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-800] due to args.save_total_limit
  6%|▋         | 826/12750 [2:41:41<38:19:18, 11.57s/it]  6%|▋         | 827/12750 [2:41:52<38:13:58, 11.54s/it]  6%|▋         | 828/12750 [2:42:04<38:10:39, 11.53s/it]  7%|▋         | 829/12750 [2:42:15<38:06:00, 11.51s/it]  7%|▋         | 830/12750 [2:42:27<38:02:06, 11.49s/it]  7%|▋         | 831/12750 [2:42:38<37:59:16, 11.47s/it]  7%|▋         | 832/12750 [2:42:50<37:57:00, 11.46s/it]  7%|▋         | 833/12750 [2:43:01<37:56:06, 11.46s/it]  7%|▋         | 834/12750 [2:43:13<37:57:01, 11.47s/it]  7%|▋         | 835/12750 [2:43:32<45:23:56, 13.72s/it]  7%|▋         | 836/12750 [2:43:43<43:08:42, 13.04s/it]  7%|▋         | 837/12750 [2:43:55<41:34:52, 12.57s/it]  7%|▋         | 838/12750 [2:44:06<40:29:05, 12.24s/it]  7%|▋         | 839/12750 [2:44:17<39:43:03, 12.00s/it]  7%|▋         | 840/12750 [2:44:29<39:11:55, 11.85s/it]  7%|▋         | 841/12750 [2:44:40<38:47:50, 11.73s/it]  7%|▋         | 842/12750 [2:44:52<38:33:20, 11.66s/it]  7%|▋         | 843/12750 [2:45:03<38:22:39, 11.60s/it]  7%|▋         | 844/12750 [2:45:15<38:16:30, 11.57s/it]  7%|▋         | 845/12750 [2:45:26<38:11:17, 11.55s/it]  7%|▋         | 846/12750 [2:45:38<38:06:24, 11.52s/it]  7%|▋         | 847/12750 [2:45:49<38:05:09, 11.52s/it]  7%|▋         | 848/12750 [2:46:01<38:02:26, 11.51s/it]  7%|▋         | 849/12750 [2:46:12<38:01:02, 11.50s/it]  7%|▋         | 850/12750 [2:46:24<37:57:33, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120261.67lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104598.72lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-850
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-850/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-850/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-825] due to args.save_total_limit
  7%|▋         | 851/12750 [2:46:36<38:16:11, 11.58s/it]  7%|▋         | 852/12750 [2:46:47<38:10:19, 11.55s/it]  7%|▋         | 853/12750 [2:46:58<38:03:32, 11.52s/it]  7%|▋         | 854/12750 [2:47:10<38:00:08, 11.50s/it]  7%|▋         | 855/12750 [2:47:21<37:58:35, 11.49s/it]  7%|▋         | 856/12750 [2:47:33<37:56:44, 11.49s/it]  7%|▋         | 857/12750 [2:47:44<37:56:06, 11.48s/it]  7%|▋         | 858/12750 [2:47:56<37:54:12, 11.47s/it]  7%|▋         | 859/12750 [2:48:07<37:52:09, 11.46s/it]  7%|▋         | 860/12750 [2:48:19<37:51:53, 11.46s/it]  7%|▋         | 861/12750 [2:48:30<37:50:44, 11.46s/it]  7%|▋         | 862/12750 [2:48:42<37:49:18, 11.45s/it]  7%|▋         | 863/12750 [2:48:53<37:50:41, 11.46s/it]  7%|▋         | 864/12750 [2:49:05<37:49:36, 11.46s/it]  7%|▋         | 865/12750 [2:49:16<37:50:22, 11.46s/it]  7%|▋         | 866/12750 [2:49:27<37:51:14, 11.47s/it]  7%|▋         | 867/12750 [2:49:39<37:50:25, 11.46s/it]  7%|▋         | 868/12750 [2:49:58<45:16:17, 13.72s/it]  7%|▋         | 869/12750 [2:50:09<43:02:39, 13.04s/it]  7%|▋         | 870/12750 [2:50:21<41:28:06, 12.57s/it]  7%|▋         | 871/12750 [2:50:32<40:22:55, 12.24s/it]  7%|▋         | 872/12750 [2:50:44<39:35:41, 12.00s/it]  7%|▋         | 873/12750 [2:50:55<39:04:27, 11.84s/it]  7%|▋         | 874/12750 [2:51:07<38:42:19, 11.73s/it]  7%|▋         | 875/12750 [2:51:18<38:27:12, 11.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120529.57lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104827.12lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-875
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-875/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-875/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-850] due to args.save_total_limit
  7%|▋         | 876/12750 [2:51:30<38:36:22, 11.70s/it]  7%|▋         | 877/12750 [2:51:42<38:33:18, 11.69s/it]  7%|▋         | 878/12750 [2:51:53<38:20:52, 11.63s/it]  7%|▋         | 879/12750 [2:52:05<38:11:56, 11.58s/it]  7%|▋         | 880/12750 [2:52:16<38:04:42, 11.55s/it]  7%|▋         | 881/12750 [2:52:28<38:01:12, 11.53s/it]  7%|▋         | 882/12750 [2:52:39<37:57:15, 11.51s/it]  7%|▋         | 883/12750 [2:52:51<37:55:16, 11.50s/it]  7%|▋         | 884/12750 [2:53:02<37:52:39, 11.49s/it]  7%|▋         | 885/12750 [2:53:13<37:53:23, 11.50s/it]  7%|▋         | 886/12750 [2:53:25<37:53:23, 11.50s/it]  7%|▋         | 887/12750 [2:53:36<37:53:24, 11.50s/it]  7%|▋         | 888/12750 [2:53:48<37:51:05, 11.49s/it]  7%|▋         | 889/12750 [2:53:59<37:50:05, 11.48s/it]  7%|▋         | 890/12750 [2:54:11<37:49:45, 11.48s/it]  7%|▋         | 891/12750 [2:54:22<37:49:19, 11.48s/it]  7%|▋         | 892/12750 [2:54:34<37:47:46, 11.47s/it]  7%|▋         | 893/12750 [2:54:45<37:46:02, 11.47s/it]  7%|▋         | 894/12750 [2:54:57<37:46:31, 11.47s/it]  7%|▋         | 895/12750 [2:55:08<37:46:08, 11.47s/it]  7%|▋         | 896/12750 [2:55:20<37:45:47, 11.47s/it]  7%|▋         | 897/12750 [2:55:31<37:45:20, 11.47s/it]  7%|▋         | 898/12750 [2:55:43<37:46:16, 11.47s/it]  7%|▋         | 899/12750 [2:55:54<37:46:26, 11.47s/it]  7%|▋         | 900/12750 [2:56:14<46:31:49, 14.14s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120558.95lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104835.08lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-900
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-900/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-900/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-875] due to args.save_total_limit
  7%|▋         | 901/12750 [2:56:26<44:12:21, 13.43s/it]  7%|▋         | 902/12750 [2:56:38<42:14:25, 12.83s/it]  7%|▋         | 903/12750 [2:56:49<40:54:01, 12.43s/it]  7%|▋         | 904/12750 [2:57:01<39:56:11, 12.14s/it]  7%|▋         | 905/12750 [2:57:12<39:15:28, 11.93s/it]  7%|▋         | 906/12750 [2:57:24<38:49:16, 11.80s/it]  7%|▋         | 907/12750 [2:57:35<38:30:10, 11.70s/it]  7%|▋         | 908/12750 [2:57:47<38:17:24, 11.64s/it]  7%|▋         | 909/12750 [2:57:58<38:08:15, 11.59s/it]  7%|▋         | 910/12750 [2:58:10<38:01:45, 11.56s/it]  7%|▋         | 911/12750 [2:58:21<37:55:31, 11.53s/it]  7%|▋         | 912/12750 [2:58:32<37:51:24, 11.51s/it]  7%|▋         | 913/12750 [2:58:44<37:49:08, 11.50s/it]  7%|▋         | 914/12750 [2:58:55<37:48:22, 11.50s/it]  7%|▋         | 915/12750 [2:59:07<37:47:03, 11.49s/it]  7%|▋         | 916/12750 [2:59:18<37:47:45, 11.50s/it]  7%|▋         | 917/12750 [2:59:30<37:47:06, 11.50s/it]  7%|▋         | 918/12750 [2:59:41<37:45:24, 11.49s/it]  7%|▋         | 919/12750 [2:59:53<37:46:01, 11.49s/it]  7%|▋         | 920/12750 [3:00:04<37:45:47, 11.49s/it]  7%|▋         | 921/12750 [3:00:16<37:45:27, 11.49s/it]  7%|▋         | 922/12750 [3:00:27<37:46:52, 11.50s/it]  7%|▋         | 923/12750 [3:00:39<37:44:39, 11.49s/it]  7%|▋         | 924/12750 [3:00:50<37:43:11, 11.48s/it]  7%|▋         | 925/12750 [3:01:02<37:42:19, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120323.90lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104648.50lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-925
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-925/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-925/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-900] due to args.save_total_limit
  7%|▋         | 926/12750 [3:01:14<38:01:01, 11.57s/it]  7%|▋         | 927/12750 [3:01:25<37:55:56, 11.55s/it]  7%|▋         | 928/12750 [3:01:37<37:51:55, 11.53s/it]  7%|▋         | 929/12750 [3:01:48<37:48:36, 11.51s/it]  7%|▋         | 930/12750 [3:02:00<37:46:47, 11.51s/it]  7%|▋         | 931/12750 [3:02:11<37:46:19, 11.51s/it]  7%|▋         | 932/12750 [3:02:30<45:05:31, 13.74s/it]  7%|▋         | 933/12750 [3:02:41<42:50:27, 13.05s/it]  7%|▋         | 934/12750 [3:02:53<41:17:39, 12.58s/it]  7%|▋         | 935/12750 [3:03:04<40:13:22, 12.26s/it]  7%|▋         | 936/12750 [3:03:16<39:25:24, 12.01s/it]  7%|▋         | 937/12750 [3:03:27<38:53:56, 11.85s/it]  7%|▋         | 938/12750 [3:03:39<38:31:30, 11.74s/it]  7%|▋         | 939/12750 [3:03:50<38:16:00, 11.66s/it]  7%|▋         | 940/12750 [3:04:02<38:05:34, 11.61s/it]  7%|▋         | 941/12750 [3:04:13<37:58:20, 11.58s/it]  7%|▋         | 942/12750 [3:04:25<37:51:53, 11.54s/it]  7%|▋         | 943/12750 [3:04:36<37:49:09, 11.53s/it]  7%|▋         | 944/12750 [3:04:48<37:46:29, 11.52s/it]  7%|▋         | 945/12750 [3:04:59<37:44:02, 11.51s/it]  7%|▋         | 946/12750 [3:05:11<37:41:07, 11.49s/it]  7%|▋         | 947/12750 [3:05:22<37:42:23, 11.50s/it]  7%|▋         | 948/12750 [3:05:34<37:40:22, 11.49s/it]  7%|▋         | 949/12750 [3:05:45<37:37:40, 11.48s/it]  7%|▋         | 950/12750 [3:05:57<37:36:02, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120337.07lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104693.58lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-950
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-950/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-950/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-925] due to args.save_total_limit
  7%|▋         | 951/12750 [3:06:08<37:55:49, 11.57s/it]  7%|▋         | 952/12750 [3:06:20<37:49:33, 11.54s/it]  7%|▋         | 953/12750 [3:06:31<37:45:20, 11.52s/it]  7%|▋         | 954/12750 [3:06:43<37:41:58, 11.51s/it]  7%|▋         | 955/12750 [3:06:54<37:40:36, 11.50s/it]  7%|▋         | 956/12750 [3:07:06<37:38:36, 11.49s/it]  8%|▊         | 957/12750 [3:07:17<37:36:57, 11.48s/it]  8%|▊         | 958/12750 [3:07:29<37:35:13, 11.48s/it]  8%|▊         | 959/12750 [3:07:40<37:35:06, 11.48s/it]  8%|▊         | 960/12750 [3:07:52<37:35:10, 11.48s/it]  8%|▊         | 961/12750 [3:08:03<37:34:53, 11.48s/it]  8%|▊         | 962/12750 [3:08:15<37:33:57, 11.47s/it]  8%|▊         | 963/12750 [3:08:26<37:33:22, 11.47s/it]  8%|▊         | 964/12750 [3:08:45<45:00:18, 13.75s/it]  8%|▊         | 965/12750 [3:08:57<42:45:41, 13.06s/it]  8%|▊         | 966/12750 [3:09:08<41:10:32, 12.58s/it]  8%|▊         | 967/12750 [3:09:19<40:05:26, 12.25s/it]  8%|▊         | 968/12750 [3:09:31<39:19:04, 12.01s/it]  8%|▊         | 969/12750 [3:09:42<38:45:56, 11.85s/it]  8%|▊         | 970/12750 [3:09:54<38:22:25, 11.73s/it]  8%|▊         | 971/12750 [3:10:05<38:07:59, 11.65s/it]  8%|▊         | 972/12750 [3:10:17<37:58:37, 11.61s/it]  8%|▊         | 973/12750 [3:10:28<37:50:02, 11.57s/it]  8%|▊         | 974/12750 [3:10:40<37:44:04, 11.54s/it]  8%|▊         | 975/12750 [3:10:51<37:41:33, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120362.78lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104720.49lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-975
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-975/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-975/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-950] due to args.save_total_limit
  8%|▊         | 976/12750 [3:11:03<37:56:15, 11.60s/it]  8%|▊         | 977/12750 [3:11:15<37:48:23, 11.56s/it]  8%|▊         | 978/12750 [3:11:26<37:41:09, 11.52s/it]  8%|▊         | 979/12750 [3:11:37<37:36:43, 11.50s/it]  8%|▊         | 980/12750 [3:11:49<37:33:43, 11.49s/it]  8%|▊         | 981/12750 [3:12:00<37:31:37, 11.48s/it]  8%|▊         | 982/12750 [3:12:12<37:29:44, 11.47s/it]  8%|▊         | 983/12750 [3:12:23<37:30:40, 11.48s/it]  8%|▊         | 984/12750 [3:12:35<37:30:04, 11.47s/it]  8%|▊         | 985/12750 [3:12:46<37:30:02, 11.47s/it]  8%|▊         | 986/12750 [3:12:58<37:28:50, 11.47s/it]  8%|▊         | 987/12750 [3:13:09<37:27:41, 11.46s/it]  8%|▊         | 988/12750 [3:13:21<37:25:45, 11.46s/it]  8%|▊         | 989/12750 [3:13:32<37:25:18, 11.45s/it]  8%|▊         | 990/12750 [3:13:43<37:25:10, 11.45s/it]  8%|▊         | 991/12750 [3:13:55<37:25:21, 11.46s/it]  8%|▊         | 992/12750 [3:14:06<37:25:43, 11.46s/it]  8%|▊         | 993/12750 [3:14:18<37:27:49, 11.47s/it]  8%|▊         | 994/12750 [3:14:29<37:26:55, 11.47s/it]  8%|▊         | 995/12750 [3:14:41<37:27:32, 11.47s/it]  8%|▊         | 996/12750 [3:15:00<44:51:12, 13.74s/it]  8%|▊         | 997/12750 [3:15:11<42:38:06, 13.06s/it]  8%|▊         | 998/12750 [3:15:23<41:05:09, 12.59s/it]  8%|▊         | 999/12750 [3:15:34<40:02:21, 12.27s/it]  8%|▊         | 1000/12750 [3:15:46<39:16:13, 12.03s/it]                                                           8%|▊         | 1000/12750 [3:15:46<39:16:13, 12.03s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120432.28lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104728.34lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1000
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1000/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1000/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-975] due to args.save_total_limit
  8%|▊         | 1001/12750 [3:15:58<39:03:28, 11.97s/it]  8%|▊         | 1002/12750 [3:16:09<38:33:21, 11.81s/it]  8%|▊         | 1003/12750 [3:16:21<38:12:52, 11.71s/it]  8%|▊         | 1004/12750 [3:16:32<37:56:32, 11.63s/it]  8%|▊         | 1005/12750 [3:16:43<37:47:14, 11.58s/it]  8%|▊         | 1006/12750 [3:16:55<37:41:01, 11.55s/it]  8%|▊         | 1007/12750 [3:17:06<37:34:10, 11.52s/it]  8%|▊         | 1008/12750 [3:17:18<37:31:31, 11.50s/it]  8%|▊         | 1009/12750 [3:17:29<37:28:48, 11.49s/it]  8%|▊         | 1010/12750 [3:17:41<37:26:21, 11.48s/it]  8%|▊         | 1011/12750 [3:17:52<37:25:23, 11.48s/it]  8%|▊         | 1012/12750 [3:18:04<37:24:30, 11.47s/it]  8%|▊         | 1013/12750 [3:18:15<37:24:58, 11.48s/it]  8%|▊         | 1014/12750 [3:18:27<37:24:02, 11.47s/it]  8%|▊         | 1015/12750 [3:18:38<37:22:56, 11.47s/it]  8%|▊         | 1016/12750 [3:18:50<37:21:14, 11.46s/it]  8%|▊         | 1017/12750 [3:19:01<37:20:43, 11.46s/it]  8%|▊         | 1018/12750 [3:19:12<37:21:02, 11.46s/it]  8%|▊         | 1019/12750 [3:19:19<32:59:29, 10.12s/it]  8%|▊         | 1020/12750 [3:19:20<23:51:52,  7.32s/it]  8%|▊         | 1021/12750 [3:19:43<39:22:57, 12.09s/it]  8%|▊         | 1022/12750 [3:19:55<38:47:58, 11.91s/it]  8%|▊         | 1023/12750 [3:20:06<38:24:28, 11.79s/it]  8%|▊         | 1024/12750 [3:20:18<38:06:10, 11.70s/it]  8%|▊         | 1025/12750 [3:20:29<37:54:10, 11.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120141.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104506.73lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1025
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1025/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1025/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1000] due to args.save_total_limit
  8%|▊         | 1026/12750 [3:20:41<38:04:27, 11.69s/it]  8%|▊         | 1027/12750 [3:20:53<37:51:14, 11.62s/it]  8%|▊         | 1028/12750 [3:21:04<37:44:55, 11.59s/it]  8%|▊         | 1029/12750 [3:21:23<44:59:38, 13.82s/it]  8%|▊         | 1030/12750 [3:21:35<42:42:47, 13.12s/it]  8%|▊         | 1031/12750 [3:21:46<41:08:53, 12.64s/it]  8%|▊         | 1032/12750 [3:21:58<40:02:55, 12.30s/it]  8%|▊         | 1033/12750 [3:22:09<39:15:22, 12.06s/it]  8%|▊         | 1034/12750 [3:22:21<38:42:13, 11.89s/it]  8%|▊         | 1035/12750 [3:22:32<38:18:25, 11.77s/it]  8%|▊         | 1036/12750 [3:22:44<38:00:50, 11.68s/it]  8%|▊         | 1037/12750 [3:22:55<37:50:55, 11.63s/it]  8%|▊         | 1038/12750 [3:23:07<37:43:09, 11.59s/it]  8%|▊         | 1039/12750 [3:23:18<37:39:25, 11.58s/it]  8%|▊         | 1040/12750 [3:23:30<37:33:45, 11.55s/it]  8%|▊         | 1041/12750 [3:23:41<37:31:12, 11.54s/it]  8%|▊         | 1042/12750 [3:23:53<37:29:34, 11.53s/it]  8%|▊         | 1043/12750 [3:24:04<37:27:34, 11.52s/it]  8%|▊         | 1044/12750 [3:24:16<37:27:16, 11.52s/it]  8%|▊         | 1045/12750 [3:24:27<37:26:30, 11.52s/it]  8%|▊         | 1046/12750 [3:24:39<37:26:32, 11.52s/it]  8%|▊         | 1047/12750 [3:24:50<37:25:18, 11.51s/it]  8%|▊         | 1048/12750 [3:25:02<37:23:59, 11.51s/it]  8%|▊         | 1049/12750 [3:25:13<37:22:23, 11.50s/it]  8%|▊         | 1050/12750 [3:25:25<37:22:30, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120526.11lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104798.80lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1050
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1050/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1050/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1025] due to args.save_total_limit
  8%|▊         | 1051/12750 [3:25:37<37:42:07, 11.60s/it]  8%|▊         | 1052/12750 [3:25:48<37:35:53, 11.57s/it]  8%|▊         | 1053/12750 [3:26:00<37:29:12, 11.54s/it]  8%|▊         | 1054/12750 [3:26:11<37:27:17, 11.53s/it]  8%|▊         | 1055/12750 [3:26:23<37:26:11, 11.52s/it]  8%|▊         | 1056/12750 [3:26:34<37:22:27, 11.51s/it]  8%|▊         | 1057/12750 [3:26:46<37:20:57, 11.50s/it]  8%|▊         | 1058/12750 [3:26:57<37:22:27, 11.51s/it]  8%|▊         | 1059/12750 [3:27:09<37:22:11, 11.51s/it]  8%|▊         | 1060/12750 [3:27:20<37:24:44, 11.52s/it]  8%|▊         | 1061/12750 [3:27:39<44:09:19, 13.60s/it]  8%|▊         | 1062/12750 [3:27:50<42:05:47, 12.97s/it]  8%|▊         | 1063/12750 [3:28:02<40:39:47, 12.53s/it]  8%|▊         | 1064/12750 [3:28:13<39:39:45, 12.22s/it]  8%|▊         | 1065/12750 [3:28:25<38:58:26, 12.01s/it]  8%|▊         | 1066/12750 [3:28:36<38:25:55, 11.84s/it]  8%|▊         | 1067/12750 [3:28:48<38:06:36, 11.74s/it]  8%|▊         | 1068/12750 [3:28:59<37:51:42, 11.67s/it]  8%|▊         | 1069/12750 [3:29:11<37:40:37, 11.61s/it]  8%|▊         | 1070/12750 [3:29:22<37:34:59, 11.58s/it]  8%|▊         | 1071/12750 [3:29:34<37:30:30, 11.56s/it]  8%|▊         | 1072/12750 [3:29:45<37:25:34, 11.54s/it]  8%|▊         | 1073/12750 [3:29:57<37:24:25, 11.53s/it]  8%|▊         | 1074/12750 [3:30:08<37:19:59, 11.51s/it]  8%|▊         | 1075/12750 [3:30:20<37:18:11, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 116944.58lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101894.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1075
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1075/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1075/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1050] due to args.save_total_limit
  8%|▊         | 1076/12750 [3:30:31<37:37:09, 11.60s/it]  8%|▊         | 1077/12750 [3:30:43<37:29:55, 11.56s/it]  8%|▊         | 1078/12750 [3:30:54<37:25:10, 11.54s/it]  8%|▊         | 1079/12750 [3:31:06<37:22:17, 11.53s/it]  8%|▊         | 1080/12750 [3:31:17<37:20:16, 11.52s/it]  8%|▊         | 1081/12750 [3:31:29<37:17:25, 11.50s/it]  8%|▊         | 1082/12750 [3:31:40<37:16:25, 11.50s/it]  8%|▊         | 1083/12750 [3:31:52<37:16:00, 11.50s/it]  9%|▊         | 1084/12750 [3:32:03<37:16:48, 11.50s/it]  9%|▊         | 1085/12750 [3:32:15<37:15:19, 11.50s/it]  9%|▊         | 1086/12750 [3:32:26<37:14:30, 11.49s/it]  9%|▊         | 1087/12750 [3:32:38<37:14:36, 11.50s/it]  9%|▊         | 1088/12750 [3:32:49<37:14:23, 11.50s/it]  9%|▊         | 1089/12750 [3:33:01<37:12:03, 11.48s/it]  9%|▊         | 1090/12750 [3:33:12<37:12:03, 11.49s/it]  9%|▊         | 1091/12750 [3:33:24<37:12:57, 11.49s/it]  9%|▊         | 1092/12750 [3:33:35<37:12:28, 11.49s/it]  9%|▊         | 1093/12750 [3:33:55<44:46:24, 13.83s/it]  9%|▊         | 1094/12750 [3:34:06<42:29:03, 13.12s/it]  9%|▊         | 1095/12750 [3:34:17<40:52:33, 12.63s/it]  9%|▊         | 1096/12750 [3:34:29<39:45:09, 12.28s/it]  9%|▊         | 1097/12750 [3:34:40<38:57:11, 12.03s/it]  9%|▊         | 1098/12750 [3:34:52<38:24:27, 11.87s/it]  9%|▊         | 1099/12750 [3:35:03<38:01:23, 11.75s/it]  9%|▊         | 1100/12750 [3:35:15<37:47:33, 11.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120325.05lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104650.43lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1100
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1100/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1100/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1075] due to args.save_total_limit
  9%|▊         | 1101/12750 [3:35:27<37:54:33, 11.72s/it]  9%|▊         | 1102/12750 [3:35:38<37:38:48, 11.64s/it]  9%|▊         | 1103/12750 [3:35:50<37:30:19, 11.59s/it]  9%|▊         | 1104/12750 [3:36:01<37:21:57, 11.55s/it]  9%|▊         | 1105/12750 [3:36:13<37:19:28, 11.54s/it]  9%|▊         | 1106/12750 [3:36:24<37:15:08, 11.52s/it]  9%|▊         | 1107/12750 [3:36:35<37:10:50, 11.50s/it]  9%|▊         | 1108/12750 [3:36:47<37:08:08, 11.48s/it]  9%|▊         | 1109/12750 [3:36:58<37:07:42, 11.48s/it]  9%|▊         | 1110/12750 [3:37:10<37:06:08, 11.47s/it]  9%|▊         | 1111/12750 [3:37:21<37:06:57, 11.48s/it]  9%|▊         | 1112/12750 [3:37:33<37:07:40, 11.48s/it]  9%|▊         | 1113/12750 [3:37:44<37:05:12, 11.47s/it]  9%|▊         | 1114/12750 [3:37:56<37:05:50, 11.48s/it]  9%|▊         | 1115/12750 [3:38:07<37:03:49, 11.47s/it]  9%|▉         | 1116/12750 [3:38:19<37:05:06, 11.48s/it]  9%|▉         | 1117/12750 [3:38:30<37:03:34, 11.47s/it]  9%|▉         | 1118/12750 [3:38:42<37:03:54, 11.47s/it]  9%|▉         | 1119/12750 [3:38:53<37:03:01, 11.47s/it]  9%|▉         | 1120/12750 [3:39:05<37:01:37, 11.46s/it]  9%|▉         | 1121/12750 [3:39:16<37:00:53, 11.46s/it]  9%|▉         | 1122/12750 [3:39:27<37:01:21, 11.46s/it]  9%|▉         | 1123/12750 [3:39:39<37:00:23, 11.46s/it]  9%|▉         | 1124/12750 [3:39:50<37:00:53, 11.46s/it]  9%|▉         | 1125/12750 [3:40:02<37:02:31, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120270.23lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104583.94lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1125
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1125/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1125/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1100] due to args.save_total_limit
  9%|▉         | 1126/12750 [3:40:21<44:36:40, 13.82s/it]  9%|▉         | 1127/12750 [3:40:33<42:22:27, 13.12s/it]  9%|▉         | 1128/12750 [3:40:44<40:48:57, 12.64s/it]  9%|▉         | 1129/12750 [3:40:56<39:43:11, 12.30s/it]  9%|▉         | 1130/12750 [3:41:07<38:59:24, 12.08s/it]  9%|▉         | 1131/12750 [3:41:19<38:27:22, 11.92s/it]  9%|▉         | 1132/12750 [3:41:30<38:04:25, 11.80s/it]  9%|▉         | 1133/12750 [3:41:42<37:46:09, 11.70s/it]  9%|▉         | 1134/12750 [3:41:53<37:34:34, 11.65s/it]  9%|▉         | 1135/12750 [3:42:05<37:28:04, 11.61s/it]  9%|▉         | 1136/12750 [3:42:16<37:23:24, 11.59s/it]  9%|▉         | 1137/12750 [3:42:28<37:20:03, 11.57s/it]  9%|▉         | 1138/12750 [3:42:39<37:15:46, 11.55s/it]  9%|▉         | 1139/12750 [3:42:51<37:11:54, 11.53s/it]  9%|▉         | 1140/12750 [3:43:02<37:10:16, 11.53s/it]  9%|▉         | 1141/12750 [3:43:14<37:08:49, 11.52s/it]  9%|▉         | 1142/12750 [3:43:25<37:06:35, 11.51s/it]  9%|▉         | 1143/12750 [3:43:37<37:05:19, 11.50s/it]  9%|▉         | 1144/12750 [3:43:48<37:05:21, 11.50s/it]  9%|▉         | 1145/12750 [3:44:00<37:05:38, 11.51s/it]  9%|▉         | 1146/12750 [3:44:11<37:05:13, 11.51s/it]  9%|▉         | 1147/12750 [3:44:23<37:02:27, 11.49s/it]  9%|▉         | 1148/12750 [3:44:34<37:04:22, 11.50s/it]  9%|▉         | 1149/12750 [3:44:46<37:04:02, 11.50s/it]  9%|▉         | 1150/12750 [3:44:57<37:03:56, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120318.28lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104563.85lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1150
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1150/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1150/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1125] due to args.save_total_limit
  9%|▉         | 1151/12750 [3:45:09<37:22:39, 11.60s/it]  9%|▉         | 1152/12750 [3:45:21<37:18:53, 11.58s/it]  9%|▉         | 1153/12750 [3:45:32<37:14:34, 11.56s/it]  9%|▉         | 1154/12750 [3:45:44<37:11:38, 11.55s/it]  9%|▉         | 1155/12750 [3:45:55<37:09:16, 11.54s/it]  9%|▉         | 1156/12750 [3:46:07<37:05:35, 11.52s/it]  9%|▉         | 1157/12750 [3:46:18<37:04:49, 11.51s/it]  9%|▉         | 1158/12750 [3:46:37<44:18:20, 13.76s/it]  9%|▉         | 1159/12750 [3:46:49<42:07:01, 13.08s/it]  9%|▉         | 1160/12750 [3:47:00<40:37:35, 12.62s/it]  9%|▉         | 1161/12750 [3:47:12<39:31:58, 12.28s/it]  9%|▉         | 1162/12750 [3:47:23<38:45:51, 12.04s/it]  9%|▉         | 1163/12750 [3:47:35<38:13:58, 11.88s/it]  9%|▉         | 1164/12750 [3:47:46<37:52:21, 11.77s/it]  9%|▉         | 1165/12750 [3:47:58<37:37:24, 11.69s/it]  9%|▉         | 1166/12750 [3:48:09<37:25:57, 11.63s/it]  9%|▉         | 1167/12750 [3:48:21<37:18:15, 11.59s/it]  9%|▉         | 1168/12750 [3:48:32<37:12:42, 11.57s/it]  9%|▉         | 1169/12750 [3:48:44<37:07:30, 11.54s/it]  9%|▉         | 1170/12750 [3:48:55<37:02:46, 11.52s/it]  9%|▉         | 1171/12750 [3:49:07<37:04:13, 11.53s/it]  9%|▉         | 1172/12750 [3:49:18<37:03:22, 11.52s/it]  9%|▉         | 1173/12750 [3:49:30<37:01:06, 11.51s/it]  9%|▉         | 1174/12750 [3:49:41<37:01:25, 11.51s/it]  9%|▉         | 1175/12750 [3:49:53<37:01:18, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120289.65lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104506.92lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1175
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1175/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1175/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1150] due to args.save_total_limit
  9%|▉         | 1176/12750 [3:50:05<37:21:34, 11.62s/it]  9%|▉         | 1177/12750 [3:50:16<37:12:09, 11.57s/it]  9%|▉         | 1178/12750 [3:50:28<37:06:34, 11.54s/it]  9%|▉         | 1179/12750 [3:50:39<37:03:01, 11.53s/it]  9%|▉         | 1180/12750 [3:50:51<37:00:12, 11.51s/it]  9%|▉         | 1181/12750 [3:51:02<36:59:09, 11.51s/it]  9%|▉         | 1182/12750 [3:51:14<36:59:21, 11.51s/it]  9%|▉         | 1183/12750 [3:51:25<36:58:22, 11.51s/it]  9%|▉         | 1184/12750 [3:51:37<36:58:20, 11.51s/it]  9%|▉         | 1185/12750 [3:51:48<36:56:34, 11.50s/it]  9%|▉         | 1186/12750 [3:52:00<36:56:03, 11.50s/it]  9%|▉         | 1187/12750 [3:52:11<36:52:27, 11.48s/it]  9%|▉         | 1188/12750 [3:52:23<36:53:10, 11.49s/it]  9%|▉         | 1189/12750 [3:52:34<36:51:08, 11.48s/it]  9%|▉         | 1190/12750 [3:52:53<44:02:27, 13.72s/it]  9%|▉         | 1191/12750 [3:53:04<41:52:29, 13.04s/it]  9%|▉         | 1192/12750 [3:53:16<40:22:18, 12.57s/it]  9%|▉         | 1193/12750 [3:53:27<39:19:01, 12.25s/it]  9%|▉         | 1194/12750 [3:53:39<38:35:30, 12.02s/it]  9%|▉         | 1195/12750 [3:53:50<38:04:20, 11.86s/it]  9%|▉         | 1196/12750 [3:54:02<37:42:50, 11.75s/it]  9%|▉         | 1197/12750 [3:54:13<37:28:03, 11.68s/it]  9%|▉         | 1198/12750 [3:54:25<37:18:08, 11.62s/it]  9%|▉         | 1199/12750 [3:54:36<37:08:53, 11.58s/it]  9%|▉         | 1200/12750 [3:54:48<37:04:34, 11.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120436.12lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104675.10lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1200
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1200/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1200/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1175] due to args.save_total_limit
  9%|▉         | 1201/12750 [3:55:00<37:18:30, 11.63s/it]  9%|▉         | 1202/12750 [3:55:11<37:09:23, 11.58s/it]  9%|▉         | 1203/12750 [3:55:23<37:05:18, 11.56s/it]  9%|▉         | 1204/12750 [3:55:34<36:59:32, 11.53s/it]  9%|▉         | 1205/12750 [3:55:46<36:56:04, 11.52s/it]  9%|▉         | 1206/12750 [3:55:57<36:54:41, 11.51s/it]  9%|▉         | 1207/12750 [3:56:09<36:50:32, 11.49s/it]  9%|▉         | 1208/12750 [3:56:20<36:49:27, 11.49s/it]  9%|▉         | 1209/12750 [3:56:31<36:48:01, 11.48s/it]  9%|▉         | 1210/12750 [3:56:43<36:48:07, 11.48s/it]  9%|▉         | 1211/12750 [3:56:54<36:49:03, 11.49s/it] 10%|▉         | 1212/12750 [3:57:06<36:48:48, 11.49s/it] 10%|▉         | 1213/12750 [3:57:17<36:47:07, 11.48s/it] 10%|▉         | 1214/12750 [3:57:29<36:47:36, 11.48s/it] 10%|▉         | 1215/12750 [3:57:40<36:48:14, 11.49s/it] 10%|▉         | 1216/12750 [3:57:52<36:47:35, 11.48s/it] 10%|▉         | 1217/12750 [3:58:03<36:47:24, 11.48s/it] 10%|▉         | 1218/12750 [3:58:15<36:46:55, 11.48s/it] 10%|▉         | 1219/12750 [3:58:26<36:46:09, 11.48s/it] 10%|▉         | 1220/12750 [3:58:38<36:46:31, 11.48s/it] 10%|▉         | 1221/12750 [3:58:49<36:44:36, 11.47s/it] 10%|▉         | 1222/12750 [3:59:09<44:13:26, 13.81s/it] 10%|▉         | 1223/12750 [3:59:20<41:59:47, 13.12s/it] 10%|▉         | 1224/12750 [3:59:32<40:26:13, 12.63s/it] 10%|▉         | 1225/12750 [3:59:43<39:18:49, 12.28s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120709.95lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 105001.39lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1225
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1225/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1225/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1200] due to args.save_total_limit
 10%|▉         | 1226/12750 [3:59:55<38:49:45, 12.13s/it] 10%|▉         | 1227/12750 [4:00:06<38:12:27, 11.94s/it] 10%|▉         | 1228/12750 [4:00:18<37:46:21, 11.80s/it] 10%|▉         | 1229/12750 [4:00:29<37:27:10, 11.70s/it] 10%|▉         | 1230/12750 [4:00:41<37:14:45, 11.64s/it] 10%|▉         | 1231/12750 [4:00:52<37:05:18, 11.59s/it] 10%|▉         | 1232/12750 [4:01:04<36:58:49, 11.56s/it] 10%|▉         | 1233/12750 [4:01:15<36:54:32, 11.54s/it] 10%|▉         | 1234/12750 [4:01:27<36:50:24, 11.52s/it] 10%|▉         | 1235/12750 [4:01:38<36:48:22, 11.51s/it] 10%|▉         | 1236/12750 [4:01:50<36:48:16, 11.51s/it] 10%|▉         | 1237/12750 [4:02:01<36:46:17, 11.50s/it] 10%|▉         | 1238/12750 [4:02:13<36:46:27, 11.50s/it] 10%|▉         | 1239/12750 [4:02:24<36:46:40, 11.50s/it] 10%|▉         | 1240/12750 [4:02:36<36:45:09, 11.50s/it] 10%|▉         | 1241/12750 [4:02:47<36:43:33, 11.49s/it] 10%|▉         | 1242/12750 [4:02:59<36:41:56, 11.48s/it] 10%|▉         | 1243/12750 [4:03:10<36:39:28, 11.47s/it] 10%|▉         | 1244/12750 [4:03:21<36:40:57, 11.48s/it] 10%|▉         | 1245/12750 [4:03:33<36:42:41, 11.49s/it] 10%|▉         | 1246/12750 [4:03:44<36:42:15, 11.49s/it] 10%|▉         | 1247/12750 [4:03:56<36:41:47, 11.48s/it] 10%|▉         | 1248/12750 [4:04:07<36:40:53, 11.48s/it] 10%|▉         | 1249/12750 [4:04:19<36:40:45, 11.48s/it] 10%|▉         | 1250/12750 [4:04:30<36:39:44, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120680.49lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104626.55lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1250
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1250/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1250/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1225] due to args.save_total_limit
 10%|▉         | 1251/12750 [4:04:42<36:57:39, 11.57s/it] 10%|▉         | 1252/12750 [4:04:54<36:51:05, 11.54s/it] 10%|▉         | 1253/12750 [4:05:05<36:47:13, 11.52s/it] 10%|▉         | 1254/12750 [4:05:24<44:21:05, 13.89s/it] 10%|▉         | 1255/12750 [4:05:36<42:03:18, 13.17s/it] 10%|▉         | 1256/12750 [4:05:47<40:27:11, 12.67s/it] 10%|▉         | 1257/12750 [4:05:59<39:18:23, 12.31s/it] 10%|▉         | 1258/12750 [4:06:10<38:31:27, 12.07s/it] 10%|▉         | 1259/12750 [4:06:22<37:59:23, 11.90s/it] 10%|▉         | 1260/12750 [4:06:33<37:33:28, 11.77s/it] 10%|▉         | 1261/12750 [4:06:45<37:16:42, 11.68s/it] 10%|▉         | 1262/12750 [4:06:56<37:05:59, 11.63s/it] 10%|▉         | 1263/12750 [4:07:08<36:57:37, 11.58s/it] 10%|▉         | 1264/12750 [4:07:19<36:53:53, 11.56s/it] 10%|▉         | 1265/12750 [4:07:31<36:51:54, 11.56s/it] 10%|▉         | 1266/12750 [4:07:42<36:47:22, 11.53s/it] 10%|▉         | 1267/12750 [4:07:54<36:44:13, 11.52s/it] 10%|▉         | 1268/12750 [4:08:05<36:41:41, 11.51s/it] 10%|▉         | 1269/12750 [4:08:17<36:41:05, 11.50s/it] 10%|▉         | 1270/12750 [4:08:28<36:39:42, 11.50s/it] 10%|▉         | 1271/12750 [4:08:40<36:38:00, 11.49s/it] 10%|▉         | 1272/12750 [4:08:51<36:37:37, 11.49s/it] 10%|▉         | 1273/12750 [4:09:03<36:36:40, 11.48s/it] 10%|▉         | 1274/12750 [4:09:14<36:36:40, 11.48s/it] 10%|█         | 1275/12750 [4:09:26<36:36:40, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120527.90lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104805.20lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1275
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1275/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1275/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1250] due to args.save_total_limit
 10%|█         | 1276/12750 [4:09:38<37:00:09, 11.61s/it] 10%|█         | 1277/12750 [4:09:49<36:52:49, 11.57s/it] 10%|█         | 1278/12750 [4:10:01<36:45:56, 11.54s/it] 10%|█         | 1279/12750 [4:10:12<36:40:54, 11.51s/it] 10%|█         | 1280/12750 [4:10:24<36:39:24, 11.51s/it] 10%|█         | 1281/12750 [4:10:35<36:38:33, 11.50s/it] 10%|█         | 1282/12750 [4:10:47<36:37:09, 11.50s/it] 10%|█         | 1283/12750 [4:10:58<36:35:11, 11.49s/it] 10%|█         | 1284/12750 [4:11:09<36:32:06, 11.47s/it] 10%|█         | 1285/12750 [4:11:21<36:32:35, 11.47s/it] 10%|█         | 1286/12750 [4:11:40<43:54:45, 13.79s/it] 10%|█         | 1287/12750 [4:11:52<41:42:56, 13.10s/it] 10%|█         | 1288/12750 [4:12:03<40:08:30, 12.61s/it] 10%|█         | 1289/12750 [4:12:15<39:03:44, 12.27s/it] 10%|█         | 1290/12750 [4:12:26<38:19:51, 12.04s/it] 10%|█         | 1291/12750 [4:12:38<37:48:04, 11.88s/it] 10%|█         | 1292/12750 [4:12:49<37:26:18, 11.76s/it] 10%|█         | 1293/12750 [4:13:01<37:09:03, 11.67s/it] 10%|█         | 1294/12750 [4:13:12<36:56:45, 11.61s/it] 10%|█         | 1295/12750 [4:13:23<36:49:41, 11.57s/it] 10%|█         | 1296/12750 [4:13:35<36:44:02, 11.55s/it] 10%|█         | 1297/12750 [4:13:46<36:42:16, 11.54s/it] 10%|█         | 1298/12750 [4:13:58<36:38:39, 11.52s/it] 10%|█         | 1299/12750 [4:14:09<36:37:04, 11.51s/it] 10%|█         | 1300/12750 [4:14:21<36:35:21, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120523.92lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104786.38lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1300
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1300/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1300/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1275] due to args.save_total_limit
 10%|█         | 1301/12750 [4:14:33<36:50:32, 11.58s/it] 10%|█         | 1302/12750 [4:14:44<36:43:54, 11.55s/it] 10%|█         | 1303/12750 [4:14:56<36:38:39, 11.52s/it] 10%|█         | 1304/12750 [4:15:07<36:35:44, 11.51s/it] 10%|█         | 1305/12750 [4:15:19<36:32:31, 11.49s/it] 10%|█         | 1306/12750 [4:15:30<36:30:37, 11.49s/it] 10%|█         | 1307/12750 [4:15:41<36:29:28, 11.48s/it] 10%|█         | 1308/12750 [4:15:53<36:29:14, 11.48s/it] 10%|█         | 1309/12750 [4:16:04<36:29:00, 11.48s/it] 10%|█         | 1310/12750 [4:16:16<36:29:30, 11.48s/it] 10%|█         | 1311/12750 [4:16:27<36:29:19, 11.48s/it] 10%|█         | 1312/12750 [4:16:39<36:27:17, 11.47s/it] 10%|█         | 1313/12750 [4:16:50<36:26:58, 11.47s/it] 10%|█         | 1314/12750 [4:17:02<36:28:27, 11.48s/it] 10%|█         | 1315/12750 [4:17:13<36:28:29, 11.48s/it] 10%|█         | 1316/12750 [4:17:25<36:29:10, 11.49s/it] 10%|█         | 1317/12750 [4:17:36<36:28:30, 11.49s/it] 10%|█         | 1318/12750 [4:17:55<43:48:50, 13.80s/it] 10%|█         | 1319/12750 [4:18:07<41:36:43, 13.11s/it] 10%|█         | 1320/12750 [4:18:18<40:04:03, 12.62s/it] 10%|█         | 1321/12750 [4:18:30<38:59:14, 12.28s/it] 10%|█         | 1322/12750 [4:18:41<38:13:59, 12.04s/it] 10%|█         | 1323/12750 [4:18:53<37:42:23, 11.88s/it] 10%|█         | 1324/12750 [4:19:04<37:20:38, 11.77s/it] 10%|█         | 1325/12750 [4:19:16<37:04:58, 11.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120713.68lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104956.82lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1325
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1325/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1325/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-25] due to args.save_total_limit
 10%|█         | 1326/12750 [4:19:28<37:14:18, 11.73s/it] 10%|█         | 1327/12750 [4:19:39<37:04:46, 11.69s/it] 10%|█         | 1328/12750 [4:19:51<36:57:15, 11.65s/it] 10%|█         | 1329/12750 [4:20:02<36:52:41, 11.62s/it] 10%|█         | 1330/12750 [4:20:14<36:46:52, 11.59s/it] 10%|█         | 1331/12750 [4:20:26<36:43:45, 11.58s/it] 10%|█         | 1332/12750 [4:20:37<36:43:38, 11.58s/it] 10%|█         | 1333/12750 [4:20:49<36:41:32, 11.57s/it] 10%|█         | 1334/12750 [4:21:00<36:39:30, 11.56s/it] 10%|█         | 1335/12750 [4:21:12<36:38:59, 11.56s/it] 10%|█         | 1336/12750 [4:21:23<36:38:19, 11.56s/it] 10%|█         | 1337/12750 [4:21:35<36:39:25, 11.56s/it] 10%|█         | 1338/12750 [4:21:46<36:40:20, 11.57s/it] 11%|█         | 1339/12750 [4:21:58<36:38:50, 11.56s/it] 11%|█         | 1340/12750 [4:22:10<36:38:45, 11.56s/it] 11%|█         | 1341/12750 [4:22:21<36:37:28, 11.56s/it] 11%|█         | 1342/12750 [4:22:33<36:37:39, 11.56s/it] 11%|█         | 1343/12750 [4:22:44<36:37:13, 11.56s/it] 11%|█         | 1344/12750 [4:22:56<36:38:01, 11.56s/it] 11%|█         | 1345/12750 [4:23:07<36:36:22, 11.55s/it] 11%|█         | 1346/12750 [4:23:19<36:35:34, 11.55s/it] 11%|█         | 1347/12750 [4:23:31<36:37:39, 11.56s/it] 11%|█         | 1348/12750 [4:23:42<36:37:53, 11.57s/it] 11%|█         | 1349/12750 [4:23:54<36:37:23, 11.56s/it] 11%|█         | 1350/12750 [4:24:12<43:26:56, 13.72s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120577.31lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104836.34lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1350
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1350/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1350/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1300] due to args.save_total_limit
 11%|█         | 1351/12750 [4:24:24<41:40:03, 13.16s/it] 11%|█         | 1352/12750 [4:24:36<40:09:26, 12.68s/it] 11%|█         | 1353/12750 [4:24:47<39:05:20, 12.35s/it] 11%|█         | 1354/12750 [4:24:59<38:19:59, 12.11s/it] 11%|█         | 1355/12750 [4:25:11<37:49:10, 11.95s/it] 11%|█         | 1356/12750 [4:25:22<37:25:39, 11.83s/it] 11%|█         | 1357/12750 [4:25:34<37:09:06, 11.74s/it] 11%|█         | 1358/12750 [4:25:45<36:58:05, 11.68s/it] 11%|█         | 1359/12750 [4:25:57<36:50:50, 11.65s/it] 11%|█         | 1360/12750 [4:26:08<36:44:38, 11.61s/it] 11%|█         | 1361/12750 [4:26:20<36:41:18, 11.60s/it] 11%|█         | 1362/12750 [4:26:31<36:37:46, 11.58s/it] 11%|█         | 1363/12750 [4:26:43<36:34:54, 11.57s/it] 11%|█         | 1364/12750 [4:26:54<36:33:29, 11.56s/it] 11%|█         | 1365/12750 [4:27:06<36:30:45, 11.55s/it] 11%|█         | 1366/12750 [4:27:17<36:29:39, 11.54s/it] 11%|█         | 1367/12750 [4:27:29<36:29:19, 11.54s/it] 11%|█         | 1368/12750 [4:27:41<36:28:31, 11.54s/it] 11%|█         | 1369/12750 [4:27:52<36:28:49, 11.54s/it] 11%|█         | 1370/12750 [4:28:04<36:28:22, 11.54s/it] 11%|█         | 1371/12750 [4:28:15<36:28:01, 11.54s/it] 11%|█         | 1372/12750 [4:28:27<36:29:04, 11.54s/it] 11%|█         | 1373/12750 [4:28:38<36:28:52, 11.54s/it] 11%|█         | 1374/12750 [4:28:50<36:29:04, 11.55s/it] 11%|█         | 1375/12750 [4:29:01<36:28:22, 11.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120541.12lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104792.30lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1375
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1375/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1375/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1325] due to args.save_total_limit
 11%|█         | 1376/12750 [4:29:13<36:45:42, 11.64s/it] 11%|█         | 1377/12750 [4:29:25<36:38:55, 11.60s/it] 11%|█         | 1378/12750 [4:29:36<36:34:38, 11.58s/it] 11%|█         | 1379/12750 [4:29:48<36:31:55, 11.57s/it] 11%|█         | 1380/12750 [4:29:59<36:30:14, 11.56s/it] 11%|█         | 1381/12750 [4:30:11<36:29:08, 11.55s/it] 11%|█         | 1382/12750 [4:30:22<36:26:59, 11.54s/it] 11%|█         | 1383/12750 [4:30:41<43:30:13, 13.78s/it] 11%|█         | 1384/12750 [4:30:53<41:23:33, 13.11s/it] 11%|█         | 1385/12750 [4:31:04<39:57:03, 12.65s/it] 11%|█         | 1386/12750 [4:31:16<38:54:04, 12.32s/it] 11%|█         | 1387/12750 [4:31:28<38:09:18, 12.09s/it] 11%|█         | 1388/12750 [4:31:39<37:40:58, 11.94s/it] 11%|█         | 1389/12750 [4:31:51<37:18:56, 11.82s/it] 11%|█         | 1390/12750 [4:32:02<37:04:28, 11.75s/it] 11%|█         | 1391/12750 [4:32:14<36:55:38, 11.70s/it] 11%|█         | 1392/12750 [4:32:25<36:47:48, 11.66s/it] 11%|█         | 1393/12750 [4:32:37<36:44:47, 11.65s/it] 11%|█         | 1394/12750 [4:32:49<36:41:06, 11.63s/it] 11%|█         | 1395/12750 [4:33:00<36:36:12, 11.60s/it] 11%|█         | 1396/12750 [4:33:12<36:59:35, 11.73s/it] 11%|█         | 1397/12750 [4:33:24<36:49:55, 11.68s/it] 11%|█         | 1398/12750 [4:33:35<36:42:02, 11.64s/it] 11%|█         | 1399/12750 [4:33:47<36:37:40, 11.62s/it] 11%|█         | 1400/12750 [4:33:58<36:33:45, 11.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120406.67lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104718.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1400
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1400/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1400/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1350] due to args.save_total_limit
 11%|█         | 1401/12750 [4:34:10<36:49:17, 11.68s/it] 11%|█         | 1402/12750 [4:34:22<36:39:26, 11.63s/it] 11%|█         | 1403/12750 [4:34:33<36:32:17, 11.59s/it] 11%|█         | 1404/12750 [4:34:45<36:25:56, 11.56s/it] 11%|█         | 1405/12750 [4:34:56<36:22:24, 11.54s/it] 11%|█         | 1406/12750 [4:35:08<36:18:58, 11.52s/it] 11%|█         | 1407/12750 [4:35:19<36:18:25, 11.52s/it] 11%|█         | 1408/12750 [4:35:31<36:15:19, 11.51s/it] 11%|█         | 1409/12750 [4:35:42<36:13:44, 11.50s/it] 11%|█         | 1410/12750 [4:35:54<36:13:57, 11.50s/it] 11%|█         | 1411/12750 [4:36:05<36:13:50, 11.50s/it] 11%|█         | 1412/12750 [4:36:17<36:12:55, 11.50s/it] 11%|█         | 1413/12750 [4:36:28<36:13:28, 11.50s/it] 11%|█         | 1414/12750 [4:36:40<36:12:44, 11.50s/it] 11%|█         | 1415/12750 [4:36:58<42:33:21, 13.52s/it] 11%|█         | 1416/12750 [4:37:10<40:38:07, 12.91s/it] 11%|█         | 1417/12750 [4:37:21<39:18:22, 12.49s/it] 11%|█         | 1418/12750 [4:37:33<38:21:40, 12.19s/it] 11%|█         | 1419/12750 [4:37:44<37:44:15, 11.99s/it] 11%|█         | 1420/12750 [4:37:55<37:14:03, 11.83s/it] 11%|█         | 1421/12750 [4:38:07<36:53:23, 11.72s/it] 11%|█         | 1422/12750 [4:38:18<36:40:21, 11.65s/it] 11%|█         | 1423/12750 [4:38:30<36:30:26, 11.60s/it] 11%|█         | 1424/12750 [4:38:41<36:24:43, 11.57s/it] 11%|█         | 1425/12750 [4:38:53<36:20:36, 11.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120609.93lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104863.62lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1425
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1425/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1425/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1375] due to args.save_total_limit
 11%|█         | 1426/12750 [4:39:05<36:35:50, 11.63s/it] 11%|█         | 1427/12750 [4:39:16<36:27:51, 11.59s/it] 11%|█         | 1428/12750 [4:39:28<36:20:51, 11.56s/it] 11%|█         | 1429/12750 [4:39:39<36:16:19, 11.53s/it] 11%|█         | 1430/12750 [4:39:51<36:14:05, 11.52s/it] 11%|█         | 1431/12750 [4:40:02<36:12:03, 11.51s/it] 11%|█         | 1432/12750 [4:40:14<36:10:53, 11.51s/it] 11%|█         | 1433/12750 [4:40:25<36:08:53, 11.50s/it] 11%|█         | 1434/12750 [4:40:37<36:07:08, 11.49s/it] 11%|█▏        | 1435/12750 [4:40:48<36:07:15, 11.49s/it] 11%|█▏        | 1436/12750 [4:41:00<36:05:20, 11.48s/it] 11%|█▏        | 1437/12750 [4:41:11<36:07:04, 11.49s/it] 11%|█▏        | 1438/12750 [4:41:23<36:07:36, 11.50s/it] 11%|█▏        | 1439/12750 [4:41:34<36:07:49, 11.50s/it] 11%|█▏        | 1440/12750 [4:41:46<36:08:55, 11.51s/it] 11%|█▏        | 1441/12750 [4:41:57<36:07:45, 11.50s/it] 11%|█▏        | 1442/12750 [4:42:09<36:06:30, 11.50s/it] 11%|█▏        | 1443/12750 [4:42:20<36:04:00, 11.48s/it] 11%|█▏        | 1444/12750 [4:42:32<36:03:28, 11.48s/it] 11%|█▏        | 1445/12750 [4:42:43<36:04:00, 11.49s/it] 11%|█▏        | 1446/12750 [4:42:55<36:02:43, 11.48s/it] 11%|█▏        | 1447/12750 [4:43:13<43:05:38, 13.73s/it] 11%|█▏        | 1448/12750 [4:43:25<41:00:44, 13.06s/it] 11%|█▏        | 1449/12750 [4:43:36<39:29:44, 12.58s/it] 11%|█▏        | 1450/12750 [4:43:48<38:29:22, 12.26s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120437.15lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104583.36lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1450
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1450/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1450/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1400] due to args.save_total_limit
 11%|█▏        | 1451/12750 [4:44:00<38:02:42, 12.12s/it] 11%|█▏        | 1452/12750 [4:44:11<37:27:01, 11.93s/it] 11%|█▏        | 1453/12750 [4:44:23<37:00:02, 11.79s/it] 11%|█▏        | 1454/12750 [4:44:34<36:42:33, 11.70s/it] 11%|█▏        | 1455/12750 [4:44:46<36:29:57, 11.63s/it] 11%|█▏        | 1456/12750 [4:44:57<36:21:06, 11.59s/it] 11%|█▏        | 1457/12750 [4:45:09<36:13:18, 11.55s/it] 11%|█▏        | 1458/12750 [4:45:20<36:08:13, 11.52s/it] 11%|█▏        | 1459/12750 [4:45:32<36:04:17, 11.50s/it] 11%|█▏        | 1460/12750 [4:45:43<36:03:28, 11.50s/it] 11%|█▏        | 1461/12750 [4:45:55<36:03:03, 11.50s/it] 11%|█▏        | 1462/12750 [4:46:06<36:02:16, 11.49s/it] 11%|█▏        | 1463/12750 [4:46:18<36:01:25, 11.49s/it] 11%|█▏        | 1464/12750 [4:46:29<36:01:20, 11.49s/it] 11%|█▏        | 1465/12750 [4:46:40<36:01:54, 11.49s/it] 11%|█▏        | 1466/12750 [4:46:52<36:02:18, 11.50s/it] 12%|█▏        | 1467/12750 [4:47:04<36:02:41, 11.50s/it] 12%|█▏        | 1468/12750 [4:47:15<36:01:15, 11.49s/it] 12%|█▏        | 1469/12750 [4:47:26<35:59:29, 11.49s/it] 12%|█▏        | 1470/12750 [4:47:38<36:00:04, 11.49s/it] 12%|█▏        | 1471/12750 [4:47:49<35:59:15, 11.49s/it] 12%|█▏        | 1472/12750 [4:48:01<35:58:33, 11.48s/it] 12%|█▏        | 1473/12750 [4:48:12<35:59:26, 11.49s/it] 12%|█▏        | 1474/12750 [4:48:24<36:00:42, 11.50s/it] 12%|█▏        | 1475/12750 [4:48:35<36:00:32, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120372.37lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104696.58lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1475
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1475/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1475/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1425] due to args.save_total_limit
 12%|█▏        | 1476/12750 [4:48:47<36:19:36, 11.60s/it] 12%|█▏        | 1477/12750 [4:48:59<36:11:24, 11.56s/it] 12%|█▏        | 1478/12750 [4:49:10<36:08:20, 11.54s/it] 12%|█▏        | 1479/12750 [4:49:29<43:08:44, 13.78s/it] 12%|█▏        | 1480/12750 [4:49:41<41:00:03, 13.10s/it] 12%|█▏        | 1481/12750 [4:49:52<39:26:43, 12.60s/it] 12%|█▏        | 1482/12750 [4:50:04<38:24:38, 12.27s/it] 12%|█▏        | 1483/12750 [4:50:15<37:44:14, 12.06s/it] 12%|█▏        | 1484/12750 [4:50:27<37:11:54, 11.89s/it] 12%|█▏        | 1485/12750 [4:50:38<36:47:51, 11.76s/it] 12%|█▏        | 1486/12750 [4:50:50<36:30:53, 11.67s/it] 12%|█▏        | 1487/12750 [4:51:01<36:20:32, 11.62s/it] 12%|█▏        | 1488/12750 [4:51:13<36:09:57, 11.56s/it] 12%|█▏        | 1489/12750 [4:51:24<36:04:15, 11.53s/it] 12%|█▏        | 1490/12750 [4:51:36<36:00:49, 11.51s/it] 12%|█▏        | 1491/12750 [4:51:47<35:58:40, 11.50s/it] 12%|█▏        | 1492/12750 [4:51:58<35:56:28, 11.49s/it] 12%|█▏        | 1493/12750 [4:52:10<35:55:20, 11.49s/it] 12%|█▏        | 1494/12750 [4:52:21<35:56:05, 11.49s/it] 12%|█▏        | 1495/12750 [4:52:33<35:55:12, 11.49s/it] 12%|█▏        | 1496/12750 [4:52:44<35:54:26, 11.49s/it] 12%|█▏        | 1497/12750 [4:52:56<35:52:54, 11.48s/it] 12%|█▏        | 1498/12750 [4:53:07<35:50:53, 11.47s/it] 12%|█▏        | 1499/12750 [4:53:19<35:50:59, 11.47s/it] 12%|█▏        | 1500/12750 [4:53:30<35:49:24, 11.46s/it]                                                          12%|█▏        | 1500/12750 [4:53:30<35:49:24, 11.46s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120495.71lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104747.52lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1500
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1500/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1500/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1450] due to args.save_total_limit
 12%|█▏        | 1501/12750 [4:53:42<36:07:52, 11.56s/it] 12%|█▏        | 1502/12750 [4:53:53<36:01:04, 11.53s/it] 12%|█▏        | 1503/12750 [4:54:05<35:57:21, 11.51s/it] 12%|█▏        | 1504/12750 [4:54:16<35:54:48, 11.50s/it] 12%|█▏        | 1505/12750 [4:54:28<35:51:05, 11.48s/it] 12%|█▏        | 1506/12750 [4:54:39<35:50:13, 11.47s/it] 12%|█▏        | 1507/12750 [4:54:51<35:47:40, 11.46s/it] 12%|█▏        | 1508/12750 [4:55:02<35:47:22, 11.46s/it] 12%|█▏        | 1509/12750 [4:55:14<35:48:44, 11.47s/it] 12%|█▏        | 1510/12750 [4:55:25<35:48:43, 11.47s/it] 12%|█▏        | 1511/12750 [4:55:44<42:49:12, 13.72s/it] 12%|█▏        | 1512/12750 [4:55:56<40:43:01, 13.04s/it] 12%|█▏        | 1513/12750 [4:56:07<39:15:04, 12.57s/it] 12%|█▏        | 1514/12750 [4:56:19<38:13:36, 12.25s/it] 12%|█▏        | 1515/12750 [4:56:30<37:29:11, 12.01s/it] 12%|█▏        | 1516/12750 [4:56:41<36:59:08, 11.85s/it] 12%|█▏        | 1517/12750 [4:56:53<36:39:09, 11.75s/it] 12%|█▏        | 1518/12750 [4:57:04<36:23:57, 11.67s/it] 12%|█▏        | 1519/12750 [4:57:16<36:14:18, 11.62s/it] 12%|█▏        | 1520/12750 [4:57:27<36:07:20, 11.58s/it] 12%|█▏        | 1521/12750 [4:57:39<36:01:40, 11.55s/it] 12%|█▏        | 1522/12750 [4:57:50<35:58:57, 11.54s/it] 12%|█▏        | 1523/12750 [4:58:02<35:56:40, 11.53s/it] 12%|█▏        | 1524/12750 [4:58:13<35:53:43, 11.51s/it] 12%|█▏        | 1525/12750 [4:58:25<35:52:36, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120430.49lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104697.94lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1525
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1525/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1525/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1475] due to args.save_total_limit
 12%|█▏        | 1526/12750 [4:58:37<36:07:55, 11.59s/it] 12%|█▏        | 1527/12750 [4:58:48<35:59:32, 11.55s/it] 12%|█▏        | 1528/12750 [4:59:00<35:53:37, 11.51s/it] 12%|█▏        | 1529/12750 [4:59:07<31:40:19, 10.16s/it] 12%|█▏        | 1530/12750 [4:59:07<22:54:25,  7.35s/it] 12%|█▏        | 1531/12750 [4:59:31<37:49:27, 12.14s/it] 12%|█▏        | 1532/12750 [4:59:43<37:36:02, 12.07s/it] 12%|█▏        | 1533/12750 [4:59:54<37:03:55, 11.90s/it] 12%|█▏        | 1534/12750 [5:00:06<36:41:13, 11.78s/it] 12%|█▏        | 1535/12750 [5:00:17<36:26:14, 11.70s/it] 12%|█▏        | 1536/12750 [5:00:29<36:16:00, 11.64s/it] 12%|█▏        | 1537/12750 [5:00:40<36:06:21, 11.59s/it] 12%|█▏        | 1538/12750 [5:00:52<36:01:31, 11.57s/it] 12%|█▏        | 1539/12750 [5:01:03<35:56:42, 11.54s/it] 12%|█▏        | 1540/12750 [5:01:15<35:55:32, 11.54s/it] 12%|█▏        | 1541/12750 [5:01:26<35:52:46, 11.52s/it] 12%|█▏        | 1542/12750 [5:01:38<35:51:42, 11.52s/it] 12%|█▏        | 1543/12750 [5:01:49<35:52:15, 11.52s/it] 12%|█▏        | 1544/12750 [5:02:08<42:51:51, 13.77s/it] 12%|█▏        | 1545/12750 [5:02:20<40:45:19, 13.09s/it] 12%|█▏        | 1546/12750 [5:02:31<39:22:00, 12.65s/it] 12%|█▏        | 1547/12750 [5:02:43<38:19:32, 12.32s/it] 12%|█▏        | 1548/12750 [5:02:54<37:33:58, 12.07s/it] 12%|█▏        | 1549/12750 [5:03:06<37:02:33, 11.91s/it] 12%|█▏        | 1550/12750 [5:03:17<36:39:44, 11.78s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120436.25lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104760.60lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1550
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1550/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1550/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1500] due to args.save_total_limit
 12%|█▏        | 1551/12750 [5:03:29<36:42:33, 11.80s/it] 12%|█▏        | 1552/12750 [5:03:41<36:25:33, 11.71s/it] 12%|█▏        | 1553/12750 [5:03:52<36:12:26, 11.64s/it] 12%|█▏        | 1554/12750 [5:04:04<36:03:28, 11.59s/it] 12%|█▏        | 1555/12750 [5:04:15<35:57:19, 11.56s/it] 12%|█▏        | 1556/12750 [5:04:27<35:54:38, 11.55s/it] 12%|█▏        | 1557/12750 [5:04:38<35:52:43, 11.54s/it] 12%|█▏        | 1558/12750 [5:04:50<35:52:38, 11.54s/it] 12%|█▏        | 1559/12750 [5:05:01<35:52:27, 11.54s/it] 12%|█▏        | 1560/12750 [5:05:13<35:49:31, 11.53s/it] 12%|█▏        | 1561/12750 [5:05:24<35:47:34, 11.52s/it] 12%|█▏        | 1562/12750 [5:05:36<35:45:21, 11.51s/it] 12%|█▏        | 1563/12750 [5:05:47<35:44:25, 11.50s/it] 12%|█▏        | 1564/12750 [5:05:59<35:44:56, 11.51s/it] 12%|█▏        | 1565/12750 [5:06:10<35:47:24, 11.52s/it] 12%|█▏        | 1566/12750 [5:06:22<35:47:10, 11.52s/it] 12%|█▏        | 1567/12750 [5:06:33<35:44:21, 11.51s/it] 12%|█▏        | 1568/12750 [5:06:45<35:44:11, 11.51s/it] 12%|█▏        | 1569/12750 [5:06:56<35:43:15, 11.50s/it] 12%|█▏        | 1570/12750 [5:07:08<35:43:41, 11.50s/it] 12%|█▏        | 1571/12750 [5:07:19<35:45:35, 11.52s/it] 12%|█▏        | 1572/12750 [5:07:31<35:46:20, 11.52s/it] 12%|█▏        | 1573/12750 [5:07:42<35:44:26, 11.51s/it] 12%|█▏        | 1574/12750 [5:07:54<35:43:06, 11.51s/it] 12%|█▏        | 1575/12750 [5:08:05<35:43:54, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120341.03lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104702.87lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1575
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1575/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1575/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1525] due to args.save_total_limit
 12%|█▏        | 1576/12750 [5:08:24<42:16:46, 13.62s/it] 12%|█▏        | 1577/12750 [5:08:35<40:18:29, 12.99s/it] 12%|█▏        | 1578/12750 [5:08:47<38:53:07, 12.53s/it] 12%|█▏        | 1579/12750 [5:08:58<37:54:43, 12.22s/it] 12%|█▏        | 1580/12750 [5:09:10<37:13:54, 12.00s/it] 12%|█▏        | 1581/12750 [5:09:21<36:46:06, 11.85s/it] 12%|█▏        | 1582/12750 [5:09:33<36:25:31, 11.74s/it] 12%|█▏        | 1583/12750 [5:09:44<36:13:10, 11.68s/it] 12%|█▏        | 1584/12750 [5:09:56<36:03:47, 11.63s/it] 12%|█▏        | 1585/12750 [5:10:07<35:56:39, 11.59s/it] 12%|█▏        | 1586/12750 [5:10:19<35:52:52, 11.57s/it] 12%|█▏        | 1587/12750 [5:10:30<35:50:35, 11.56s/it] 12%|█▏        | 1588/12750 [5:10:42<35:46:18, 11.54s/it] 12%|█▏        | 1589/12750 [5:10:53<35:44:08, 11.53s/it] 12%|█▏        | 1590/12750 [5:11:05<35:42:47, 11.52s/it] 12%|█▏        | 1591/12750 [5:11:16<35:40:02, 11.51s/it] 12%|█▏        | 1592/12750 [5:11:28<35:39:07, 11.50s/it] 12%|█▏        | 1593/12750 [5:11:39<35:40:02, 11.51s/it] 13%|█▎        | 1594/12750 [5:11:51<35:38:11, 11.50s/it] 13%|█▎        | 1595/12750 [5:12:02<35:37:40, 11.50s/it] 13%|█▎        | 1596/12750 [5:12:14<35:39:42, 11.51s/it] 13%|█▎        | 1597/12750 [5:12:25<35:39:31, 11.51s/it] 13%|█▎        | 1598/12750 [5:12:37<35:38:09, 11.50s/it] 13%|█▎        | 1599/12750 [5:12:48<35:37:50, 11.50s/it] 13%|█▎        | 1600/12750 [5:13:00<35:38:12, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120317.89lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104657.20lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1600
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1600/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1600/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1550] due to args.save_total_limit
 13%|█▎        | 1601/12750 [5:13:12<35:54:32, 11.60s/it] 13%|█▎        | 1602/12750 [5:13:23<35:47:15, 11.56s/it] 13%|█▎        | 1603/12750 [5:13:35<35:42:47, 11.53s/it] 13%|█▎        | 1604/12750 [5:13:46<35:41:42, 11.53s/it] 13%|█▎        | 1605/12750 [5:13:58<35:42:15, 11.53s/it] 13%|█▎        | 1606/12750 [5:14:09<35:40:35, 11.53s/it] 13%|█▎        | 1607/12750 [5:14:21<35:40:52, 11.53s/it] 13%|█▎        | 1608/12750 [5:14:40<42:38:37, 13.78s/it] 13%|█▎        | 1609/12750 [5:14:51<40:31:55, 13.10s/it] 13%|█▎        | 1610/12750 [5:15:03<39:02:22, 12.62s/it] 13%|█▎        | 1611/12750 [5:15:14<38:00:11, 12.28s/it] 13%|█▎        | 1612/12750 [5:15:26<37:18:00, 12.06s/it] 13%|█▎        | 1613/12750 [5:15:37<36:46:30, 11.89s/it] 13%|█▎        | 1614/12750 [5:15:49<36:25:42, 11.78s/it] 13%|█▎        | 1615/12750 [5:16:00<36:10:52, 11.70s/it] 13%|█▎        | 1616/12750 [5:16:12<35:59:42, 11.64s/it] 13%|█▎        | 1617/12750 [5:16:23<35:52:46, 11.60s/it] 13%|█▎        | 1618/12750 [5:16:35<35:48:02, 11.58s/it] 13%|█▎        | 1619/12750 [5:16:46<35:44:34, 11.56s/it] 13%|█▎        | 1620/12750 [5:16:58<35:41:55, 11.55s/it] 13%|█▎        | 1621/12750 [5:17:09<35:39:01, 11.53s/it] 13%|█▎        | 1622/12750 [5:17:21<35:37:19, 11.52s/it] 13%|█▎        | 1623/12750 [5:17:32<35:36:30, 11.52s/it] 13%|█▎        | 1624/12750 [5:17:44<35:47:06, 11.58s/it] 13%|█▎        | 1625/12750 [5:17:56<35:42:57, 11.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120435.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104564.82lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1625
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1625/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1625/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1575] due to args.save_total_limit
 13%|█▎        | 1626/12750 [5:18:07<35:56:16, 11.63s/it] 13%|█▎        | 1627/12750 [5:18:19<35:47:29, 11.58s/it] 13%|█▎        | 1628/12750 [5:18:30<35:43:07, 11.56s/it] 13%|█▎        | 1629/12750 [5:18:42<35:39:20, 11.54s/it] 13%|█▎        | 1630/12750 [5:18:53<35:37:38, 11.53s/it] 13%|█▎        | 1631/12750 [5:19:05<35:36:34, 11.53s/it] 13%|█▎        | 1632/12750 [5:19:17<35:34:29, 11.52s/it] 13%|█▎        | 1633/12750 [5:19:28<35:33:42, 11.52s/it] 13%|█▎        | 1634/12750 [5:19:40<35:32:27, 11.51s/it] 13%|█▎        | 1635/12750 [5:19:51<35:30:00, 11.50s/it] 13%|█▎        | 1636/12750 [5:20:02<35:27:32, 11.49s/it] 13%|█▎        | 1637/12750 [5:20:14<35:28:51, 11.49s/it] 13%|█▎        | 1638/12750 [5:20:25<35:29:32, 11.50s/it] 13%|█▎        | 1639/12750 [5:20:37<35:29:19, 11.50s/it] 13%|█▎        | 1640/12750 [5:20:56<42:23:56, 13.74s/it] 13%|█▎        | 1641/12750 [5:21:07<40:18:17, 13.06s/it] 13%|█▎        | 1642/12750 [5:21:19<38:51:28, 12.59s/it] 13%|█▎        | 1643/12750 [5:21:30<37:49:27, 12.26s/it] 13%|█▎        | 1644/12750 [5:21:42<37:06:01, 12.03s/it] 13%|█▎        | 1645/12750 [5:21:53<36:37:37, 11.87s/it] 13%|█▎        | 1646/12750 [5:22:05<36:13:12, 11.74s/it] 13%|█▎        | 1647/12750 [5:22:16<35:57:46, 11.66s/it] 13%|█▎        | 1648/12750 [5:22:28<35:46:51, 11.60s/it] 13%|█▎        | 1649/12750 [5:22:39<35:40:19, 11.57s/it] 13%|█▎        | 1650/12750 [5:22:51<35:34:43, 11.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120365.46lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104693.10lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1650
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1650/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1650/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1600] due to args.save_total_limit
 13%|█▎        | 1651/12750 [5:23:03<35:49:58, 11.62s/it] 13%|█▎        | 1652/12750 [5:23:14<35:41:37, 11.58s/it] 13%|█▎        | 1653/12750 [5:23:25<35:34:41, 11.54s/it] 13%|█▎        | 1654/12750 [5:23:37<35:30:35, 11.52s/it] 13%|█▎        | 1655/12750 [5:23:48<35:29:43, 11.52s/it] 13%|█▎        | 1656/12750 [5:24:00<35:26:23, 11.50s/it] 13%|█▎        | 1657/12750 [5:24:11<35:23:56, 11.49s/it] 13%|█▎        | 1658/12750 [5:24:23<35:22:38, 11.48s/it] 13%|█▎        | 1659/12750 [5:24:34<35:20:54, 11.47s/it] 13%|█▎        | 1660/12750 [5:24:46<35:21:11, 11.48s/it] 13%|█▎        | 1661/12750 [5:24:57<35:21:30, 11.48s/it] 13%|█▎        | 1662/12750 [5:25:09<35:20:53, 11.48s/it] 13%|█▎        | 1663/12750 [5:25:20<35:22:27, 11.49s/it] 13%|█▎        | 1664/12750 [5:25:32<35:21:46, 11.48s/it] 13%|█▎        | 1665/12750 [5:25:43<35:20:19, 11.48s/it] 13%|█▎        | 1666/12750 [5:25:55<35:17:29, 11.46s/it] 13%|█▎        | 1667/12750 [5:26:06<35:17:03, 11.46s/it] 13%|█▎        | 1668/12750 [5:26:18<35:18:28, 11.47s/it] 13%|█▎        | 1669/12750 [5:26:29<35:17:42, 11.47s/it] 13%|█▎        | 1670/12750 [5:26:41<35:22:06, 11.49s/it] 13%|█▎        | 1671/12750 [5:26:52<35:22:20, 11.49s/it] 13%|█▎        | 1672/12750 [5:27:10<41:28:38, 13.48s/it] 13%|█▎        | 1673/12750 [5:27:22<39:36:26, 12.87s/it] 13%|█▎        | 1674/12750 [5:27:33<38:20:09, 12.46s/it] 13%|█▎        | 1675/12750 [5:27:45<37:26:59, 12.17s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120303.58lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104629.64lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1675
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1675/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1675/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1625] due to args.save_total_limit
 13%|█▎        | 1676/12750 [5:27:56<37:05:22, 12.06s/it] 13%|█▎        | 1677/12750 [5:28:08<36:32:56, 11.88s/it] 13%|█▎        | 1678/12750 [5:28:19<36:11:18, 11.77s/it] 13%|█▎        | 1679/12750 [5:28:31<35:56:49, 11.69s/it] 13%|█▎        | 1680/12750 [5:28:42<35:45:30, 11.63s/it] 13%|█▎        | 1681/12750 [5:28:54<35:38:22, 11.59s/it] 13%|█▎        | 1682/12750 [5:29:05<35:30:45, 11.55s/it] 13%|█▎        | 1683/12750 [5:29:17<35:27:14, 11.53s/it] 13%|█▎        | 1684/12750 [5:29:28<35:25:36, 11.53s/it] 13%|█▎        | 1685/12750 [5:29:40<35:22:52, 11.51s/it] 13%|█▎        | 1686/12750 [5:29:51<35:23:42, 11.52s/it] 13%|█▎        | 1687/12750 [5:30:03<35:22:03, 11.51s/it] 13%|█▎        | 1688/12750 [5:30:14<35:20:33, 11.50s/it] 13%|█▎        | 1689/12750 [5:30:26<35:18:48, 11.49s/it] 13%|█▎        | 1690/12750 [5:30:37<35:18:17, 11.49s/it] 13%|█▎        | 1691/12750 [5:30:49<35:20:07, 11.50s/it] 13%|█▎        | 1692/12750 [5:31:00<35:19:23, 11.50s/it] 13%|█▎        | 1693/12750 [5:31:12<35:19:46, 11.50s/it] 13%|█▎        | 1694/12750 [5:31:23<35:18:32, 11.50s/it] 13%|█▎        | 1695/12750 [5:31:35<35:18:00, 11.50s/it] 13%|█▎        | 1696/12750 [5:31:46<35:19:27, 11.50s/it] 13%|█▎        | 1697/12750 [5:31:58<35:19:26, 11.51s/it] 13%|█▎        | 1698/12750 [5:32:09<35:20:06, 11.51s/it] 13%|█▎        | 1699/12750 [5:32:21<35:19:32, 11.51s/it] 13%|█▎        | 1700/12750 [5:32:32<35:19:12, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120357.28lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104680.13lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1700
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1700/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1700/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1650] due to args.save_total_limit
 13%|█▎        | 1701/12750 [5:32:44<35:36:14, 11.60s/it] 13%|█▎        | 1702/12750 [5:32:56<35:30:42, 11.57s/it] 13%|█▎        | 1703/12750 [5:33:07<35:26:03, 11.55s/it] 13%|█▎        | 1704/12750 [5:33:19<35:22:12, 11.53s/it] 13%|█▎        | 1705/12750 [5:33:38<42:20:24, 13.80s/it] 13%|█▎        | 1706/12750 [5:33:49<40:12:45, 13.11s/it] 13%|█▎        | 1707/12750 [5:34:01<38:44:23, 12.63s/it] 13%|█▎        | 1708/12750 [5:34:12<37:41:39, 12.29s/it] 13%|█▎        | 1709/12750 [5:34:24<36:57:55, 12.05s/it] 13%|█▎        | 1710/12750 [5:34:35<36:27:02, 11.89s/it] 13%|█▎        | 1711/12750 [5:34:47<36:05:36, 11.77s/it] 13%|█▎        | 1712/12750 [5:34:58<35:49:38, 11.68s/it] 13%|█▎        | 1713/12750 [5:35:10<35:37:57, 11.62s/it] 13%|█▎        | 1714/12750 [5:35:21<35:31:31, 11.59s/it] 13%|█▎        | 1715/12750 [5:35:33<35:28:25, 11.57s/it] 13%|█▎        | 1716/12750 [5:35:44<35:25:08, 11.56s/it] 13%|█▎        | 1717/12750 [5:35:56<35:22:27, 11.54s/it] 13%|█▎        | 1718/12750 [5:36:07<35:18:40, 11.52s/it] 13%|█▎        | 1719/12750 [5:36:19<35:17:46, 11.52s/it] 13%|█▎        | 1720/12750 [5:36:30<35:18:44, 11.53s/it] 13%|█▎        | 1721/12750 [5:36:42<35:16:54, 11.52s/it] 14%|█▎        | 1722/12750 [5:36:53<35:14:03, 11.50s/it] 14%|█▎        | 1723/12750 [5:37:05<35:13:02, 11.50s/it] 14%|█▎        | 1724/12750 [5:37:16<35:12:35, 11.50s/it] 14%|█▎        | 1725/12750 [5:37:28<35:11:58, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120366.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104685.26lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1725
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1725/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1725/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1675] due to args.save_total_limit
 14%|█▎        | 1726/12750 [5:37:40<35:28:47, 11.59s/it] 14%|█▎        | 1727/12750 [5:37:51<35:23:18, 11.56s/it] 14%|█▎        | 1728/12750 [5:38:03<35:18:22, 11.53s/it] 14%|█▎        | 1729/12750 [5:38:14<35:16:07, 11.52s/it] 14%|█▎        | 1730/12750 [5:38:26<35:15:41, 11.52s/it] 14%|█▎        | 1731/12750 [5:38:37<35:15:26, 11.52s/it] 14%|█▎        | 1732/12750 [5:38:49<35:16:46, 11.53s/it] 14%|█▎        | 1733/12750 [5:39:00<35:15:29, 11.52s/it] 14%|█▎        | 1734/12750 [5:39:12<35:15:57, 11.52s/it] 14%|█▎        | 1735/12750 [5:39:23<35:14:50, 11.52s/it] 14%|█▎        | 1736/12750 [5:39:35<35:13:32, 11.51s/it] 14%|█▎        | 1737/12750 [5:39:54<42:05:14, 13.76s/it] 14%|█▎        | 1738/12750 [5:40:05<39:59:18, 13.07s/it] 14%|█▎        | 1739/12750 [5:40:17<38:33:09, 12.60s/it] 14%|█▎        | 1740/12750 [5:40:28<37:31:22, 12.27s/it] 14%|█▎        | 1741/12750 [5:40:40<36:49:30, 12.04s/it] 14%|█▎        | 1742/12750 [5:40:51<36:19:11, 11.88s/it] 14%|█▎        | 1743/12750 [5:41:03<35:57:56, 11.76s/it] 14%|█▎        | 1744/12750 [5:41:14<35:41:33, 11.67s/it] 14%|█▎        | 1745/12750 [5:41:26<35:31:50, 11.62s/it] 14%|█▎        | 1746/12750 [5:41:37<35:25:15, 11.59s/it] 14%|█▎        | 1747/12750 [5:41:49<35:18:52, 11.55s/it] 14%|█▎        | 1748/12750 [5:42:00<35:15:33, 11.54s/it] 14%|█▎        | 1749/12750 [5:42:12<35:11:12, 11.51s/it] 14%|█▎        | 1750/12750 [5:42:23<35:09:48, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120417.94lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104763.22lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1750
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1750/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1750/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1700] due to args.save_total_limit
 14%|█▎        | 1751/12750 [5:42:35<35:27:06, 11.60s/it] 14%|█▎        | 1752/12750 [5:42:46<35:21:14, 11.57s/it] 14%|█▎        | 1753/12750 [5:42:58<35:14:14, 11.54s/it] 14%|█▍        | 1754/12750 [5:43:09<35:10:26, 11.52s/it] 14%|█▍        | 1755/12750 [5:43:21<35:10:23, 11.52s/it] 14%|█▍        | 1756/12750 [5:43:32<35:08:55, 11.51s/it] 14%|█▍        | 1757/12750 [5:43:44<35:06:44, 11.50s/it] 14%|█▍        | 1758/12750 [5:43:55<35:07:00, 11.50s/it] 14%|█▍        | 1759/12750 [5:44:07<35:07:57, 11.51s/it] 14%|█▍        | 1760/12750 [5:44:18<35:07:16, 11.50s/it] 14%|█▍        | 1761/12750 [5:44:30<35:07:30, 11.51s/it] 14%|█▍        | 1762/12750 [5:44:41<35:06:47, 11.50s/it] 14%|█▍        | 1763/12750 [5:44:53<35:06:08, 11.50s/it] 14%|█▍        | 1764/12750 [5:45:04<35:04:57, 11.50s/it] 14%|█▍        | 1765/12750 [5:45:16<35:05:46, 11.50s/it] 14%|█▍        | 1766/12750 [5:45:27<35:05:40, 11.50s/it] 14%|█▍        | 1767/12750 [5:45:39<35:03:39, 11.49s/it] 14%|█▍        | 1768/12750 [5:45:50<35:03:24, 11.49s/it] 14%|█▍        | 1769/12750 [5:46:09<41:55:32, 13.74s/it] 14%|█▍        | 1770/12750 [5:46:21<39:51:42, 13.07s/it] 14%|█▍        | 1771/12750 [5:46:32<38:26:52, 12.61s/it] 14%|█▍        | 1772/12750 [5:46:44<37:26:08, 12.28s/it] 14%|█▍        | 1773/12750 [5:46:55<36:42:15, 12.04s/it] 14%|█▍        | 1774/12750 [5:47:07<36:11:28, 11.87s/it] 14%|█▍        | 1775/12750 [5:47:18<35:49:34, 11.75s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120351.01lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104783.96lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1775
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1775/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1775/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1725] due to args.save_total_limit
 14%|█▍        | 1776/12750 [5:47:30<35:52:17, 11.77s/it] 14%|█▍        | 1777/12750 [5:47:41<35:36:08, 11.68s/it] 14%|█▍        | 1778/12750 [5:47:53<35:26:12, 11.63s/it] 14%|█▍        | 1779/12750 [5:48:04<35:17:28, 11.58s/it] 14%|█▍        | 1780/12750 [5:48:16<35:14:41, 11.57s/it] 14%|█▍        | 1781/12750 [5:48:27<35:09:21, 11.54s/it] 14%|█▍        | 1782/12750 [5:48:39<35:05:12, 11.52s/it] 14%|█▍        | 1783/12750 [5:48:50<35:04:35, 11.51s/it] 14%|█▍        | 1784/12750 [5:49:02<35:03:46, 11.51s/it] 14%|█▍        | 1785/12750 [5:49:14<35:11:26, 11.55s/it] 14%|█▍        | 1786/12750 [5:49:25<35:14:26, 11.57s/it] 14%|█▍        | 1787/12750 [5:49:37<35:15:01, 11.58s/it] 14%|█▍        | 1788/12750 [5:49:48<35:16:37, 11.59s/it] 14%|█▍        | 1789/12750 [5:50:00<35:17:42, 11.59s/it] 14%|█▍        | 1790/12750 [5:50:12<35:17:52, 11.59s/it] 14%|█▍        | 1791/12750 [5:50:23<35:17:36, 11.59s/it] 14%|█▍        | 1792/12750 [5:50:35<35:18:29, 11.60s/it] 14%|█▍        | 1793/12750 [5:50:46<35:18:58, 11.60s/it] 14%|█▍        | 1794/12750 [5:50:58<35:15:43, 11.59s/it] 14%|█▍        | 1795/12750 [5:51:10<35:17:43, 11.60s/it] 14%|█▍        | 1796/12750 [5:51:21<35:17:29, 11.60s/it] 14%|█▍        | 1797/12750 [5:51:33<35:18:14, 11.60s/it] 14%|█▍        | 1798/12750 [5:51:44<35:18:00, 11.60s/it] 14%|█▍        | 1799/12750 [5:51:56<35:15:38, 11.59s/it] 14%|█▍        | 1800/12750 [5:52:08<35:15:29, 11.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120328.12lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104645.50lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1800
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1800/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1800/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1750] due to args.save_total_limit
 14%|█▍        | 1801/12750 [5:52:27<42:23:06, 13.94s/it] 14%|█▍        | 1802/12750 [5:52:39<40:14:02, 13.23s/it] 14%|█▍        | 1803/12750 [5:52:50<38:45:10, 12.74s/it] 14%|█▍        | 1804/12750 [5:53:02<37:40:44, 12.39s/it] 14%|█▍        | 1805/12750 [5:53:13<36:55:49, 12.15s/it] 14%|█▍        | 1806/12750 [5:53:25<36:26:00, 11.98s/it] 14%|█▍        | 1807/12750 [5:53:37<36:07:23, 11.88s/it] 14%|█▍        | 1808/12750 [5:53:48<35:49:14, 11.79s/it] 14%|█▍        | 1809/12750 [5:54:00<35:39:16, 11.73s/it] 14%|█▍        | 1810/12750 [5:54:11<35:32:30, 11.70s/it] 14%|█▍        | 1811/12750 [5:54:23<35:25:18, 11.66s/it] 14%|█▍        | 1812/12750 [5:54:35<35:21:16, 11.64s/it] 14%|█▍        | 1813/12750 [5:54:46<35:18:45, 11.62s/it] 14%|█▍        | 1814/12750 [5:54:58<35:15:19, 11.61s/it] 14%|█▍        | 1815/12750 [5:55:09<35:12:17, 11.59s/it] 14%|█▍        | 1816/12750 [5:55:21<35:06:22, 11.56s/it] 14%|█▍        | 1817/12750 [5:55:32<35:00:40, 11.53s/it] 14%|█▍        | 1818/12750 [5:55:44<34:55:16, 11.50s/it] 14%|█▍        | 1819/12750 [5:55:55<34:53:55, 11.49s/it] 14%|█▍        | 1820/12750 [5:56:07<34:53:54, 11.49s/it] 14%|█▍        | 1821/12750 [5:56:18<34:51:25, 11.48s/it] 14%|█▍        | 1822/12750 [5:56:29<34:49:55, 11.47s/it] 14%|█▍        | 1823/12750 [5:56:41<34:49:42, 11.47s/it] 14%|█▍        | 1824/12750 [5:56:52<34:50:27, 11.48s/it] 14%|█▍        | 1825/12750 [5:57:04<34:49:21, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120578.21lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104623.36lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1825
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1825/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1825/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1775] due to args.save_total_limit
 14%|█▍        | 1826/12750 [5:57:16<35:06:04, 11.57s/it] 14%|█▍        | 1827/12750 [5:57:27<35:00:59, 11.54s/it] 14%|█▍        | 1828/12750 [5:57:39<34:57:28, 11.52s/it] 14%|█▍        | 1829/12750 [5:57:50<34:53:38, 11.50s/it] 14%|█▍        | 1830/12750 [5:58:02<34:53:22, 11.50s/it] 14%|█▍        | 1831/12750 [5:58:13<34:51:14, 11.49s/it] 14%|█▍        | 1832/12750 [5:58:25<34:48:25, 11.48s/it] 14%|█▍        | 1833/12750 [5:58:44<41:47:17, 13.78s/it] 14%|█▍        | 1834/12750 [5:58:55<39:41:09, 13.09s/it] 14%|█▍        | 1835/12750 [5:59:07<38:13:16, 12.61s/it] 14%|█▍        | 1836/12750 [5:59:18<37:13:25, 12.28s/it] 14%|█▍        | 1837/12750 [5:59:30<36:29:54, 12.04s/it] 14%|█▍        | 1838/12750 [5:59:41<35:59:35, 11.87s/it] 14%|█▍        | 1839/12750 [5:59:53<35:36:01, 11.75s/it] 14%|█▍        | 1840/12750 [6:00:04<35:23:37, 11.68s/it] 14%|█▍        | 1841/12750 [6:00:16<35:13:37, 11.63s/it] 14%|█▍        | 1842/12750 [6:00:27<35:04:07, 11.57s/it] 14%|█▍        | 1843/12750 [6:00:39<34:59:36, 11.55s/it] 14%|█▍        | 1844/12750 [6:00:50<34:53:53, 11.52s/it] 14%|█▍        | 1845/12750 [6:01:01<34:50:17, 11.50s/it] 14%|█▍        | 1846/12750 [6:01:13<34:47:43, 11.49s/it] 14%|█▍        | 1847/12750 [6:01:24<34:47:40, 11.49s/it] 14%|█▍        | 1848/12750 [6:01:36<34:48:04, 11.49s/it] 15%|█▍        | 1849/12750 [6:01:47<34:48:33, 11.50s/it] 15%|█▍        | 1850/12750 [6:01:59<34:47:23, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120347.68lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104662.42lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1850
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1850/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1850/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1800] due to args.save_total_limit
 15%|█▍        | 1851/12750 [6:02:11<35:05:05, 11.59s/it] 15%|█▍        | 1852/12750 [6:02:22<34:58:30, 11.55s/it] 15%|█▍        | 1853/12750 [6:02:34<34:52:51, 11.52s/it] 15%|█▍        | 1854/12750 [6:02:45<34:50:37, 11.51s/it] 15%|█▍        | 1855/12750 [6:02:57<34:49:36, 11.51s/it] 15%|█▍        | 1856/12750 [6:03:08<34:48:09, 11.50s/it] 15%|█▍        | 1857/12750 [6:03:20<34:47:26, 11.50s/it] 15%|█▍        | 1858/12750 [6:03:31<34:49:37, 11.51s/it] 15%|█▍        | 1859/12750 [6:03:43<34:47:15, 11.50s/it] 15%|█▍        | 1860/12750 [6:03:54<34:46:39, 11.50s/it] 15%|█▍        | 1861/12750 [6:04:06<34:45:32, 11.49s/it] 15%|█▍        | 1862/12750 [6:04:17<34:46:11, 11.50s/it] 15%|█▍        | 1863/12750 [6:04:29<34:46:42, 11.50s/it] 15%|█▍        | 1864/12750 [6:04:40<34:47:08, 11.50s/it] 15%|█▍        | 1865/12750 [6:04:59<41:32:33, 13.74s/it] 15%|█▍        | 1866/12750 [6:05:11<39:29:40, 13.06s/it] 15%|█▍        | 1867/12750 [6:05:22<38:04:57, 12.60s/it] 15%|█▍        | 1868/12750 [6:05:34<37:03:39, 12.26s/it] 15%|█▍        | 1869/12750 [6:05:45<36:19:43, 12.02s/it] 15%|█▍        | 1870/12750 [6:05:56<35:49:41, 11.85s/it] 15%|█▍        | 1871/12750 [6:06:08<35:28:26, 11.74s/it] 15%|█▍        | 1872/12750 [6:06:19<35:13:17, 11.66s/it] 15%|█▍        | 1873/12750 [6:06:31<35:01:52, 11.59s/it] 15%|█▍        | 1874/12750 [6:06:42<34:55:16, 11.56s/it] 15%|█▍        | 1875/12750 [6:06:54<34:56:49, 11.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 99062.45lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 88155.83lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1875
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1875/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1875/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1825] due to args.save_total_limit
 15%|█▍        | 1876/12750 [6:07:06<35:15:46, 11.67s/it] 15%|█▍        | 1877/12750 [6:07:17<35:11:06, 11.65s/it] 15%|█▍        | 1878/12750 [6:07:29<35:08:01, 11.63s/it] 15%|█▍        | 1879/12750 [6:07:41<35:04:39, 11.62s/it] 15%|█▍        | 1880/12750 [6:07:52<35:03:26, 11.61s/it] 15%|█▍        | 1881/12750 [6:08:04<35:04:03, 11.61s/it] 15%|█▍        | 1882/12750 [6:08:15<35:01:53, 11.60s/it] 15%|█▍        | 1883/12750 [6:08:27<35:01:07, 11.60s/it] 15%|█▍        | 1884/12750 [6:08:39<35:02:11, 11.61s/it] 15%|█▍        | 1885/12750 [6:08:50<35:00:42, 11.60s/it] 15%|█▍        | 1886/12750 [6:09:02<34:58:53, 11.59s/it] 15%|█▍        | 1887/12750 [6:09:13<34:59:35, 11.60s/it] 15%|█▍        | 1888/12750 [6:09:25<34:57:52, 11.59s/it] 15%|█▍        | 1889/12750 [6:09:36<34:56:50, 11.58s/it] 15%|█▍        | 1890/12750 [6:09:48<34:58:05, 11.59s/it] 15%|█▍        | 1891/12750 [6:10:00<34:58:23, 11.59s/it] 15%|█▍        | 1892/12750 [6:10:11<34:58:10, 11.59s/it] 15%|█▍        | 1893/12750 [6:10:23<34:58:41, 11.60s/it] 15%|█▍        | 1894/12750 [6:10:34<34:58:24, 11.60s/it] 15%|█▍        | 1895/12750 [6:10:46<34:57:39, 11.59s/it] 15%|█▍        | 1896/12750 [6:10:58<34:57:37, 11.60s/it] 15%|█▍        | 1897/12750 [6:11:17<41:50:00, 13.88s/it] 15%|█▍        | 1898/12750 [6:11:28<39:46:24, 13.19s/it] 15%|█▍        | 1899/12750 [6:11:40<38:19:41, 12.72s/it] 15%|█▍        | 1900/12750 [6:11:52<37:20:41, 12.39s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120240.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104624.62lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1900
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1900/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1900/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1850] due to args.save_total_limit
 15%|█▍        | 1901/12750 [6:12:04<36:53:13, 12.24s/it] 15%|█▍        | 1902/12750 [6:12:15<36:16:45, 12.04s/it] 15%|█▍        | 1903/12750 [6:12:27<35:51:33, 11.90s/it] 15%|█▍        | 1904/12750 [6:12:38<35:32:21, 11.80s/it] 15%|█▍        | 1905/12750 [6:12:50<35:20:30, 11.73s/it] 15%|█▍        | 1906/12750 [6:13:02<35:13:57, 11.70s/it] 15%|█▍        | 1907/12750 [6:13:13<35:07:41, 11.66s/it] 15%|█▍        | 1908/12750 [6:13:25<35:03:34, 11.64s/it] 15%|█▍        | 1909/12750 [6:13:36<35:00:48, 11.63s/it] 15%|█▍        | 1910/12750 [6:13:48<34:58:13, 11.61s/it] 15%|█▍        | 1911/12750 [6:13:59<34:53:23, 11.59s/it] 15%|█▍        | 1912/12750 [6:14:11<34:45:04, 11.54s/it] 15%|█▌        | 1913/12750 [6:14:22<34:41:20, 11.52s/it] 15%|█▌        | 1914/12750 [6:14:34<34:37:07, 11.50s/it] 15%|█▌        | 1915/12750 [6:14:45<34:34:48, 11.49s/it] 15%|█▌        | 1916/12750 [6:14:57<34:32:54, 11.48s/it] 15%|█▌        | 1917/12750 [6:15:08<34:32:54, 11.48s/it] 15%|█▌        | 1918/12750 [6:15:20<34:33:24, 11.48s/it] 15%|█▌        | 1919/12750 [6:15:31<34:33:57, 11.49s/it] 15%|█▌        | 1920/12750 [6:15:43<34:33:30, 11.49s/it] 15%|█▌        | 1921/12750 [6:15:54<34:32:10, 11.48s/it] 15%|█▌        | 1922/12750 [6:16:06<34:31:51, 11.48s/it] 15%|█▌        | 1923/12750 [6:16:17<34:31:12, 11.48s/it] 15%|█▌        | 1924/12750 [6:16:29<34:32:16, 11.48s/it] 15%|█▌        | 1925/12750 [6:16:40<34:32:29, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120284.92lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104738.41lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1925
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1925/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1925/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1875] due to args.save_total_limit
 15%|█▌        | 1926/12750 [6:16:52<34:50:15, 11.59s/it] 15%|█▌        | 1927/12750 [6:17:03<34:42:34, 11.55s/it] 15%|█▌        | 1928/12750 [6:17:15<34:37:39, 11.52s/it] 15%|█▌        | 1929/12750 [6:17:26<34:33:59, 11.50s/it] 15%|█▌        | 1930/12750 [6:17:45<41:24:01, 13.77s/it] 15%|█▌        | 1931/12750 [6:17:57<39:20:57, 13.09s/it] 15%|█▌        | 1932/12750 [6:18:08<37:54:03, 12.61s/it] 15%|█▌        | 1933/12750 [6:18:20<36:53:24, 12.28s/it] 15%|█▌        | 1934/12750 [6:18:31<36:11:15, 12.04s/it] 15%|█▌        | 1935/12750 [6:18:43<35:41:10, 11.88s/it] 15%|█▌        | 1936/12750 [6:18:54<35:20:01, 11.76s/it] 15%|█▌        | 1937/12750 [6:19:06<35:06:29, 11.69s/it] 15%|█▌        | 1938/12750 [6:19:17<34:56:02, 11.63s/it] 15%|█▌        | 1939/12750 [6:19:29<34:48:55, 11.59s/it] 15%|█▌        | 1940/12750 [6:19:40<34:42:54, 11.56s/it] 15%|█▌        | 1941/12750 [6:19:52<34:37:33, 11.53s/it] 15%|█▌        | 1942/12750 [6:20:03<34:34:45, 11.52s/it] 15%|█▌        | 1943/12750 [6:20:15<34:34:28, 11.52s/it] 15%|█▌        | 1944/12750 [6:20:26<34:33:25, 11.51s/it] 15%|█▌        | 1945/12750 [6:20:38<34:33:36, 11.51s/it] 15%|█▌        | 1946/12750 [6:20:49<34:32:36, 11.51s/it] 15%|█▌        | 1947/12750 [6:21:01<34:32:15, 11.51s/it] 15%|█▌        | 1948/12750 [6:21:12<34:31:49, 11.51s/it] 15%|█▌        | 1949/12750 [6:21:24<34:33:07, 11.52s/it] 15%|█▌        | 1950/12750 [6:21:35<34:32:49, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 116676.14lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101895.64lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1950
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1950/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1950/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1900] due to args.save_total_limit
 15%|█▌        | 1951/12750 [6:21:47<34:51:29, 11.62s/it] 15%|█▌        | 1952/12750 [6:21:59<34:42:40, 11.57s/it] 15%|█▌        | 1953/12750 [6:22:10<34:36:36, 11.54s/it] 15%|█▌        | 1954/12750 [6:22:22<34:32:45, 11.52s/it] 15%|█▌        | 1955/12750 [6:22:33<34:32:32, 11.52s/it] 15%|█▌        | 1956/12750 [6:22:45<34:33:27, 11.53s/it] 15%|█▌        | 1957/12750 [6:22:56<34:32:16, 11.52s/it] 15%|█▌        | 1958/12750 [6:23:08<34:32:52, 11.52s/it] 15%|█▌        | 1959/12750 [6:23:19<34:31:00, 11.52s/it] 15%|█▌        | 1960/12750 [6:23:31<34:28:36, 11.50s/it] 15%|█▌        | 1961/12750 [6:23:42<34:29:43, 11.51s/it] 15%|█▌        | 1962/12750 [6:24:01<41:16:08, 13.77s/it] 15%|█▌        | 1963/12750 [6:24:13<39:12:29, 13.09s/it] 15%|█▌        | 1964/12750 [6:24:24<37:46:44, 12.61s/it] 15%|█▌        | 1965/12750 [6:24:36<36:44:15, 12.26s/it] 15%|█▌        | 1966/12750 [6:24:47<36:02:01, 12.03s/it] 15%|█▌        | 1967/12750 [6:24:59<35:32:56, 11.87s/it] 15%|█▌        | 1968/12750 [6:25:10<35:13:08, 11.76s/it] 15%|█▌        | 1969/12750 [6:25:22<34:58:27, 11.68s/it] 15%|█▌        | 1970/12750 [6:25:33<34:48:33, 11.62s/it] 15%|█▌        | 1971/12750 [6:25:45<34:41:25, 11.59s/it] 15%|█▌        | 1972/12750 [6:25:56<34:35:06, 11.55s/it] 15%|█▌        | 1973/12750 [6:26:08<34:30:54, 11.53s/it] 15%|█▌        | 1974/12750 [6:26:19<34:28:20, 11.52s/it] 15%|█▌        | 1975/12750 [6:26:31<34:24:47, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120345.89lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104698.13lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1975
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1975/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1975/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-1975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1925] due to args.save_total_limit
 15%|█▌        | 1976/12750 [6:26:42<34:40:34, 11.59s/it] 16%|█▌        | 1977/12750 [6:26:54<34:34:53, 11.56s/it] 16%|█▌        | 1978/12750 [6:27:05<34:32:38, 11.54s/it] 16%|█▌        | 1979/12750 [6:27:17<34:31:22, 11.54s/it] 16%|█▌        | 1980/12750 [6:27:28<34:31:47, 11.54s/it] 16%|█▌        | 1981/12750 [6:27:40<34:29:43, 11.53s/it] 16%|█▌        | 1982/12750 [6:27:51<34:27:28, 11.52s/it] 16%|█▌        | 1983/12750 [6:28:03<34:26:08, 11.51s/it] 16%|█▌        | 1984/12750 [6:28:14<34:26:24, 11.52s/it] 16%|█▌        | 1985/12750 [6:28:26<34:25:10, 11.51s/it] 16%|█▌        | 1986/12750 [6:28:37<34:23:40, 11.50s/it] 16%|█▌        | 1987/12750 [6:28:49<34:22:23, 11.50s/it] 16%|█▌        | 1988/12750 [6:29:00<34:22:06, 11.50s/it] 16%|█▌        | 1989/12750 [6:29:12<34:19:30, 11.48s/it] 16%|█▌        | 1990/12750 [6:29:23<34:18:59, 11.48s/it] 16%|█▌        | 1991/12750 [6:29:35<34:18:53, 11.48s/it] 16%|█▌        | 1992/12750 [6:29:46<34:19:42, 11.49s/it] 16%|█▌        | 1993/12750 [6:29:58<34:20:15, 11.49s/it] 16%|█▌        | 1994/12750 [6:30:17<40:53:40, 13.69s/it] 16%|█▌        | 1995/12750 [6:30:28<38:55:50, 13.03s/it] 16%|█▌        | 1996/12750 [6:30:40<37:30:53, 12.56s/it] 16%|█▌        | 1997/12750 [6:30:51<36:33:57, 12.24s/it] 16%|█▌        | 1998/12750 [6:31:03<35:53:19, 12.02s/it] 16%|█▌        | 1999/12750 [6:31:14<35:23:53, 11.85s/it] 16%|█▌        | 2000/12750 [6:31:26<35:03:45, 11.74s/it]                                                          16%|█▌        | 2000/12750 [6:31:26<35:03:45, 11.74s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120546.63lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101530.87lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2000
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2000/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2000/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1950] due to args.save_total_limit
 16%|█▌        | 2001/12750 [6:31:38<35:18:37, 11.83s/it] 16%|█▌        | 2002/12750 [6:31:49<35:01:06, 11.73s/it] 16%|█▌        | 2003/12750 [6:32:01<34:48:36, 11.66s/it] 16%|█▌        | 2004/12750 [6:32:12<34:39:44, 11.61s/it] 16%|█▌        | 2005/12750 [6:32:24<34:34:32, 11.58s/it] 16%|█▌        | 2006/12750 [6:32:35<34:29:08, 11.56s/it] 16%|█▌        | 2007/12750 [6:32:47<34:25:04, 11.53s/it] 16%|█▌        | 2008/12750 [6:32:58<34:23:28, 11.53s/it] 16%|█▌        | 2009/12750 [6:33:10<34:20:55, 11.51s/it] 16%|█▌        | 2010/12750 [6:33:21<34:20:37, 11.51s/it] 16%|█▌        | 2011/12750 [6:33:33<34:19:45, 11.51s/it] 16%|█▌        | 2012/12750 [6:33:44<34:20:25, 11.51s/it] 16%|█▌        | 2013/12750 [6:33:56<34:19:18, 11.51s/it] 16%|█▌        | 2014/12750 [6:34:07<34:18:06, 11.50s/it] 16%|█▌        | 2015/12750 [6:34:19<34:19:37, 11.51s/it] 16%|█▌        | 2016/12750 [6:34:30<34:17:43, 11.50s/it] 16%|█▌        | 2017/12750 [6:34:42<34:18:24, 11.51s/it] 16%|█▌        | 2018/12750 [6:34:53<34:17:41, 11.50s/it] 16%|█▌        | 2019/12750 [6:35:05<34:17:48, 11.51s/it] 16%|█▌        | 2020/12750 [6:35:16<34:17:49, 11.51s/it] 16%|█▌        | 2021/12750 [6:35:28<34:16:24, 11.50s/it] 16%|█▌        | 2022/12750 [6:35:39<34:14:24, 11.49s/it] 16%|█▌        | 2023/12750 [6:35:51<34:15:07, 11.50s/it] 16%|█▌        | 2024/12750 [6:36:02<34:14:30, 11.49s/it] 16%|█▌        | 2025/12750 [6:36:14<34:14:55, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120481.74lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104850.22lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2025
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2025/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2025/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-1975] due to args.save_total_limit
 16%|█▌        | 2026/12750 [6:36:33<41:19:49, 13.87s/it] 16%|█▌        | 2027/12750 [6:36:44<39:11:30, 13.16s/it] 16%|█▌        | 2028/12750 [6:36:56<37:43:05, 12.66s/it] 16%|█▌        | 2029/12750 [6:37:07<36:39:48, 12.31s/it] 16%|█▌        | 2030/12750 [6:37:19<35:57:08, 12.07s/it] 16%|█▌        | 2031/12750 [6:37:30<35:26:09, 11.90s/it] 16%|█▌        | 2032/12750 [6:37:42<35:04:30, 11.78s/it] 16%|█▌        | 2033/12750 [6:37:53<34:46:52, 11.68s/it] 16%|█▌        | 2034/12750 [6:38:05<34:37:47, 11.63s/it] 16%|█▌        | 2035/12750 [6:38:16<34:31:12, 11.60s/it] 16%|█▌        | 2036/12750 [6:38:28<34:27:12, 11.58s/it] 16%|█▌        | 2037/12750 [6:38:39<34:22:36, 11.55s/it] 16%|█▌        | 2038/12750 [6:38:51<34:18:23, 11.53s/it] 16%|█▌        | 2039/12750 [6:38:58<30:17:25, 10.18s/it] 16%|█▌        | 2040/12750 [6:38:59<21:54:23,  7.36s/it] 16%|█▌        | 2041/12750 [6:39:22<36:08:05, 12.15s/it] 16%|█▌        | 2042/12750 [6:39:34<35:33:45, 11.96s/it] 16%|█▌        | 2043/12750 [6:39:45<35:09:20, 11.82s/it] 16%|█▌        | 2044/12750 [6:39:57<34:55:25, 11.74s/it] 16%|█▌        | 2045/12750 [6:40:08<34:41:26, 11.67s/it] 16%|█▌        | 2046/12750 [6:40:20<34:34:27, 11.63s/it] 16%|█▌        | 2047/12750 [6:40:31<34:29:11, 11.60s/it] 16%|█▌        | 2048/12750 [6:40:43<34:22:54, 11.57s/it] 16%|█▌        | 2049/12750 [6:40:54<34:20:52, 11.56s/it] 16%|█▌        | 2050/12750 [6:41:06<34:19:14, 11.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120373.14lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104704.81lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2050
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2050/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2050/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2025] due to args.save_total_limit
 16%|█▌        | 2051/12750 [6:41:18<34:34:06, 11.63s/it] 16%|█▌        | 2052/12750 [6:41:29<34:26:42, 11.59s/it] 16%|█▌        | 2053/12750 [6:41:41<34:23:03, 11.57s/it] 16%|█▌        | 2054/12750 [6:41:52<34:19:52, 11.56s/it] 16%|█▌        | 2055/12750 [6:42:04<34:16:00, 11.53s/it] 16%|█▌        | 2056/12750 [6:42:15<34:14:24, 11.53s/it] 16%|█▌        | 2057/12750 [6:42:27<34:14:04, 11.53s/it] 16%|█▌        | 2058/12750 [6:42:46<40:55:47, 13.78s/it] 16%|█▌        | 2059/12750 [6:42:57<38:53:10, 13.09s/it] 16%|█▌        | 2060/12750 [6:43:09<37:29:54, 12.63s/it] 16%|█▌        | 2061/12750 [6:43:20<36:32:30, 12.31s/it] 16%|█▌        | 2062/12750 [6:43:32<35:52:21, 12.08s/it] 16%|█▌        | 2063/12750 [6:43:43<35:23:34, 11.92s/it] 16%|█▌        | 2064/12750 [6:43:55<35:02:43, 11.81s/it] 16%|█▌        | 2065/12750 [6:44:06<34:46:55, 11.72s/it] 16%|█▌        | 2066/12750 [6:44:18<34:36:39, 11.66s/it] 16%|█▌        | 2067/12750 [6:44:29<34:29:12, 11.62s/it] 16%|█▌        | 2068/12750 [6:44:41<34:23:19, 11.59s/it] 16%|█▌        | 2069/12750 [6:44:53<34:19:40, 11.57s/it] 16%|█▌        | 2070/12750 [6:45:04<34:15:36, 11.55s/it] 16%|█▌        | 2071/12750 [6:45:16<34:13:05, 11.54s/it] 16%|█▋        | 2072/12750 [6:45:27<34:12:24, 11.53s/it] 16%|█▋        | 2073/12750 [6:45:39<34:09:38, 11.52s/it] 16%|█▋        | 2074/12750 [6:45:50<34:09:03, 11.52s/it] 16%|█▋        | 2075/12750 [6:46:02<34:08:16, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120475.46lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104796.95lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2075
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2075/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2075/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2000] due to args.save_total_limit
 16%|█▋        | 2076/12750 [6:46:13<34:21:35, 11.59s/it] 16%|█▋        | 2077/12750 [6:46:25<34:15:49, 11.56s/it] 16%|█▋        | 2078/12750 [6:46:36<34:13:15, 11.54s/it] 16%|█▋        | 2079/12750 [6:46:48<34:10:11, 11.53s/it] 16%|█▋        | 2080/12750 [6:46:59<34:08:55, 11.52s/it] 16%|█▋        | 2081/12750 [6:47:11<34:07:52, 11.52s/it] 16%|█▋        | 2082/12750 [6:47:22<34:05:19, 11.50s/it] 16%|█▋        | 2083/12750 [6:47:34<34:04:40, 11.50s/it] 16%|█▋        | 2084/12750 [6:47:45<34:04:47, 11.50s/it] 16%|█▋        | 2085/12750 [6:47:57<34:05:17, 11.51s/it] 16%|█▋        | 2086/12750 [6:48:08<34:05:10, 11.51s/it] 16%|█▋        | 2087/12750 [6:48:20<34:04:48, 11.51s/it] 16%|█▋        | 2088/12750 [6:48:31<34:04:56, 11.51s/it] 16%|█▋        | 2089/12750 [6:48:43<34:03:16, 11.50s/it] 16%|█▋        | 2090/12750 [6:48:54<34:02:56, 11.50s/it] 16%|█▋        | 2091/12750 [6:49:13<40:43:35, 13.76s/it] 16%|█▋        | 2092/12750 [6:49:25<38:43:59, 13.08s/it] 16%|█▋        | 2093/12750 [6:49:36<37:21:32, 12.62s/it] 16%|█▋        | 2094/12750 [6:49:48<36:23:10, 12.29s/it] 16%|█▋        | 2095/12750 [6:49:59<35:41:28, 12.06s/it] 16%|█▋        | 2096/12750 [6:50:11<35:12:40, 11.90s/it] 16%|█▋        | 2097/12750 [6:50:22<34:53:09, 11.79s/it] 16%|█▋        | 2098/12750 [6:50:34<34:38:26, 11.71s/it] 16%|█▋        | 2099/12750 [6:50:46<34:28:27, 11.65s/it] 16%|█▋        | 2100/12750 [6:50:57<34:20:20, 11.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120534.57lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104833.33lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2100
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2100/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2100/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2050] due to args.save_total_limit
 16%|█▋        | 2101/12750 [6:51:09<34:33:47, 11.68s/it] 16%|█▋        | 2102/12750 [6:51:20<34:25:56, 11.64s/it] 16%|█▋        | 2103/12750 [6:51:32<34:17:57, 11.60s/it] 17%|█▋        | 2104/12750 [6:51:43<34:13:22, 11.57s/it] 17%|█▋        | 2105/12750 [6:51:55<34:12:54, 11.57s/it] 17%|█▋        | 2106/12750 [6:52:07<34:10:44, 11.56s/it] 17%|█▋        | 2107/12750 [6:52:18<34:08:23, 11.55s/it] 17%|█▋        | 2108/12750 [6:52:30<34:05:32, 11.53s/it] 17%|█▋        | 2109/12750 [6:52:41<34:04:24, 11.53s/it] 17%|█▋        | 2110/12750 [6:52:53<34:04:28, 11.53s/it] 17%|█▋        | 2111/12750 [6:53:04<34:02:23, 11.52s/it] 17%|█▋        | 2112/12750 [6:53:16<33:59:32, 11.50s/it] 17%|█▋        | 2113/12750 [6:53:27<33:57:10, 11.49s/it] 17%|█▋        | 2114/12750 [6:53:39<33:55:25, 11.48s/it] 17%|█▋        | 2115/12750 [6:53:50<33:56:45, 11.49s/it] 17%|█▋        | 2116/12750 [6:54:02<33:57:59, 11.50s/it] 17%|█▋        | 2117/12750 [6:54:13<33:58:24, 11.50s/it] 17%|█▋        | 2118/12750 [6:54:25<33:59:03, 11.51s/it] 17%|█▋        | 2119/12750 [6:54:36<33:57:33, 11.50s/it] 17%|█▋        | 2120/12750 [6:54:48<33:56:30, 11.49s/it] 17%|█▋        | 2121/12750 [6:54:59<33:57:00, 11.50s/it] 17%|█▋        | 2122/12750 [6:55:11<33:57:49, 11.50s/it] 17%|█▋        | 2123/12750 [6:55:30<40:34:25, 13.74s/it] 17%|█▋        | 2124/12750 [6:55:41<38:36:03, 13.08s/it] 17%|█▋        | 2125/12750 [6:55:53<37:12:09, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120393.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104732.79lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2125
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2125/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2125/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2075] due to args.save_total_limit
 17%|█▋        | 2126/12750 [6:56:05<36:38:44, 12.42s/it] 17%|█▋        | 2127/12750 [6:56:16<35:53:08, 12.16s/it] 17%|█▋        | 2128/12750 [6:56:28<35:19:33, 11.97s/it] 17%|█▋        | 2129/12750 [6:56:39<34:54:25, 11.83s/it] 17%|█▋        | 2130/12750 [6:56:51<34:35:36, 11.73s/it] 17%|█▋        | 2131/12750 [6:57:02<34:24:01, 11.66s/it] 17%|█▋        | 2132/12750 [6:57:14<34:14:00, 11.61s/it] 17%|█▋        | 2133/12750 [6:57:25<34:09:11, 11.58s/it] 17%|█▋        | 2134/12750 [6:57:37<34:07:18, 11.57s/it] 17%|█▋        | 2135/12750 [6:57:48<34:03:42, 11.55s/it] 17%|█▋        | 2136/12750 [6:58:00<34:00:45, 11.54s/it] 17%|█▋        | 2137/12750 [6:58:11<34:00:05, 11.53s/it] 17%|█▋        | 2138/12750 [6:58:23<33:58:57, 11.53s/it] 17%|█▋        | 2139/12750 [6:58:34<33:57:07, 11.52s/it] 17%|█▋        | 2140/12750 [6:58:46<33:57:00, 11.52s/it] 17%|█▋        | 2141/12750 [6:58:57<33:53:25, 11.50s/it] 17%|█▋        | 2142/12750 [6:59:09<33:53:15, 11.50s/it] 17%|█▋        | 2143/12750 [6:59:20<33:53:45, 11.50s/it] 17%|█▋        | 2144/12750 [6:59:32<33:55:11, 11.51s/it] 17%|█▋        | 2145/12750 [6:59:43<33:53:02, 11.50s/it] 17%|█▋        | 2146/12750 [6:59:55<33:54:32, 11.51s/it] 17%|█▋        | 2147/12750 [7:00:06<33:55:03, 11.52s/it] 17%|█▋        | 2148/12750 [7:00:18<33:55:00, 11.52s/it] 17%|█▋        | 2149/12750 [7:00:29<33:55:11, 11.52s/it] 17%|█▋        | 2150/12750 [7:00:41<33:54:19, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120511.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104821.01lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2150
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2150/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2150/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2100] due to args.save_total_limit
 17%|█▋        | 2151/12750 [7:00:53<34:10:14, 11.61s/it] 17%|█▋        | 2152/12750 [7:01:04<34:05:14, 11.58s/it] 17%|█▋        | 2153/12750 [7:01:16<34:01:29, 11.56s/it] 17%|█▋        | 2154/12750 [7:01:27<33:58:00, 11.54s/it] 17%|█▋        | 2155/12750 [7:01:46<40:15:17, 13.68s/it] 17%|█▋        | 2156/12750 [7:01:57<38:21:00, 13.03s/it] 17%|█▋        | 2157/12750 [7:02:09<37:00:40, 12.58s/it] 17%|█▋        | 2158/12750 [7:02:20<36:03:21, 12.25s/it] 17%|█▋        | 2159/12750 [7:02:32<35:25:07, 12.04s/it] 17%|█▋        | 2160/12750 [7:02:43<34:58:24, 11.89s/it] 17%|█▋        | 2161/12750 [7:02:55<34:39:33, 11.78s/it] 17%|█▋        | 2162/12750 [7:03:07<34:25:24, 11.70s/it] 17%|█▋        | 2163/12750 [7:03:18<34:15:08, 11.65s/it] 17%|█▋        | 2164/12750 [7:03:30<34:08:38, 11.61s/it] 17%|█▋        | 2165/12750 [7:03:41<34:03:30, 11.58s/it] 17%|█▋        | 2166/12750 [7:03:53<34:40:07, 11.79s/it] 17%|█▋        | 2167/12750 [7:04:05<34:23:37, 11.70s/it] 17%|█▋        | 2168/12750 [7:04:16<34:15:09, 11.65s/it] 17%|█▋        | 2169/12750 [7:04:28<34:07:12, 11.61s/it] 17%|█▋        | 2170/12750 [7:04:39<34:00:56, 11.57s/it] 17%|█▋        | 2171/12750 [7:04:51<33:57:59, 11.56s/it] 17%|█▋        | 2172/12750 [7:05:02<33:56:01, 11.55s/it] 17%|█▋        | 2173/12750 [7:05:14<33:54:59, 11.54s/it] 17%|█▋        | 2174/12750 [7:05:25<33:52:34, 11.53s/it] 17%|█▋        | 2175/12750 [7:05:37<33:50:19, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120547.66lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104822.85lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2175
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2175/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2175/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2125] due to args.save_total_limit
 17%|█▋        | 2176/12750 [7:05:49<34:04:44, 11.60s/it] 17%|█▋        | 2177/12750 [7:06:00<33:58:01, 11.57s/it] 17%|█▋        | 2178/12750 [7:06:12<34:00:54, 11.58s/it] 17%|█▋        | 2179/12750 [7:06:23<33:57:44, 11.57s/it] 17%|█▋        | 2180/12750 [7:06:35<33:53:58, 11.55s/it] 17%|█▋        | 2181/12750 [7:06:46<33:50:47, 11.53s/it] 17%|█▋        | 2182/12750 [7:06:58<33:49:08, 11.52s/it] 17%|█▋        | 2183/12750 [7:07:09<33:48:38, 11.52s/it] 17%|█▋        | 2184/12750 [7:07:21<33:48:07, 11.52s/it] 17%|█▋        | 2185/12750 [7:07:32<33:46:42, 11.51s/it] 17%|█▋        | 2186/12750 [7:07:44<33:46:35, 11.51s/it] 17%|█▋        | 2187/12750 [7:08:02<39:33:08, 13.48s/it] 17%|█▋        | 2188/12750 [7:08:13<37:48:38, 12.89s/it] 17%|█▋        | 2189/12750 [7:08:25<36:35:22, 12.47s/it] 17%|█▋        | 2190/12750 [7:08:37<35:45:14, 12.19s/it] 17%|█▋        | 2191/12750 [7:08:48<35:09:35, 11.99s/it] 17%|█▋        | 2192/12750 [7:09:00<34:44:26, 11.85s/it] 17%|█▋        | 2193/12750 [7:09:11<34:27:52, 11.75s/it] 17%|█▋        | 2194/12750 [7:09:23<34:15:06, 11.68s/it] 17%|█▋        | 2195/12750 [7:09:34<34:06:35, 11.63s/it] 17%|█▋        | 2196/12750 [7:09:46<34:00:37, 11.60s/it] 17%|█▋        | 2197/12750 [7:09:57<33:54:13, 11.57s/it] 17%|█▋        | 2198/12750 [7:10:09<33:53:10, 11.56s/it] 17%|█▋        | 2199/12750 [7:10:20<33:50:03, 11.54s/it] 17%|█▋        | 2200/12750 [7:10:32<33:49:18, 11.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120510.46lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104746.16lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2200
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2200/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2200/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2150] due to args.save_total_limit
 17%|█▋        | 2201/12750 [7:10:44<34:04:46, 11.63s/it] 17%|█▋        | 2202/12750 [7:10:55<33:55:54, 11.58s/it] 17%|█▋        | 2203/12750 [7:11:06<33:50:42, 11.55s/it] 17%|█▋        | 2204/12750 [7:11:18<33:49:24, 11.55s/it] 17%|█▋        | 2205/12750 [7:11:30<33:45:58, 11.53s/it] 17%|█▋        | 2206/12750 [7:11:41<33:44:20, 11.52s/it] 17%|█▋        | 2207/12750 [7:11:53<33:44:36, 11.52s/it] 17%|█▋        | 2208/12750 [7:12:04<33:42:18, 11.51s/it] 17%|█▋        | 2209/12750 [7:12:16<33:43:24, 11.52s/it] 17%|█▋        | 2210/12750 [7:12:27<33:41:45, 11.51s/it] 17%|█▋        | 2211/12750 [7:12:39<33:40:06, 11.50s/it] 17%|█▋        | 2212/12750 [7:12:50<33:40:18, 11.50s/it] 17%|█▋        | 2213/12750 [7:13:02<33:40:01, 11.50s/it] 17%|█▋        | 2214/12750 [7:13:13<33:40:40, 11.51s/it] 17%|█▋        | 2215/12750 [7:13:25<33:39:47, 11.50s/it] 17%|█▋        | 2216/12750 [7:13:36<33:41:29, 11.51s/it] 17%|█▋        | 2217/12750 [7:13:48<33:42:11, 11.52s/it] 17%|█▋        | 2218/12750 [7:13:59<33:42:28, 11.52s/it] 17%|█▋        | 2219/12750 [7:14:18<40:16:03, 13.77s/it] 17%|█▋        | 2220/12750 [7:14:30<38:16:02, 13.08s/it] 17%|█▋        | 2221/12750 [7:14:41<36:52:25, 12.61s/it] 17%|█▋        | 2222/12750 [7:14:53<35:54:03, 12.28s/it] 17%|█▋        | 2223/12750 [7:15:04<35:12:01, 12.04s/it] 17%|█▋        | 2224/12750 [7:15:16<34:46:01, 11.89s/it] 17%|█▋        | 2225/12750 [7:15:27<34:23:54, 11.77s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120421.27lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104738.99lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2225
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2225/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2225/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2175] due to args.save_total_limit
 17%|█▋        | 2226/12750 [7:15:39<34:25:29, 11.78s/it] 17%|█▋        | 2227/12750 [7:15:50<34:13:14, 11.71s/it] 17%|█▋        | 2228/12750 [7:16:02<34:02:24, 11.65s/it] 17%|█▋        | 2229/12750 [7:16:13<33:53:51, 11.60s/it] 17%|█▋        | 2230/12750 [7:16:25<33:47:34, 11.56s/it] 17%|█▋        | 2231/12750 [7:16:36<33:41:53, 11.53s/it] 18%|█▊        | 2232/12750 [7:16:48<33:38:51, 11.52s/it] 18%|█▊        | 2233/12750 [7:16:59<33:37:46, 11.51s/it] 18%|█▊        | 2234/12750 [7:17:11<33:38:30, 11.52s/it] 18%|█▊        | 2235/12750 [7:17:22<33:36:38, 11.51s/it] 18%|█▊        | 2236/12750 [7:17:34<33:35:00, 11.50s/it] 18%|█▊        | 2237/12750 [7:17:45<33:34:20, 11.50s/it] 18%|█▊        | 2238/12750 [7:17:57<33:32:34, 11.49s/it] 18%|█▊        | 2239/12750 [7:18:08<33:34:54, 11.50s/it] 18%|█▊        | 2240/12750 [7:18:20<33:36:08, 11.51s/it] 18%|█▊        | 2241/12750 [7:18:31<33:37:20, 11.52s/it] 18%|█▊        | 2242/12750 [7:18:43<33:36:35, 11.51s/it] 18%|█▊        | 2243/12750 [7:18:54<33:34:15, 11.50s/it] 18%|█▊        | 2244/12750 [7:19:06<33:33:41, 11.50s/it] 18%|█▊        | 2245/12750 [7:19:17<33:34:58, 11.51s/it] 18%|█▊        | 2246/12750 [7:19:29<33:34:56, 11.51s/it] 18%|█▊        | 2247/12750 [7:19:40<33:35:12, 11.51s/it] 18%|█▊        | 2248/12750 [7:19:52<33:36:14, 11.52s/it] 18%|█▊        | 2249/12750 [7:20:04<33:34:09, 11.51s/it] 18%|█▊        | 2250/12750 [7:20:15<33:34:27, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120391.44lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104719.72lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2250
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2250/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2250/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2225] due to args.save_total_limit
 18%|█▊        | 2251/12750 [7:20:34<40:25:00, 13.86s/it] 18%|█▊        | 2252/12750 [7:20:46<38:21:08, 13.15s/it] 18%|█▊        | 2253/12750 [7:20:57<36:54:11, 12.66s/it] 18%|█▊        | 2254/12750 [7:21:09<35:51:47, 12.30s/it] 18%|█▊        | 2255/12750 [7:21:20<35:10:07, 12.06s/it] 18%|█▊        | 2256/12750 [7:21:32<34:42:04, 11.90s/it] 18%|█▊        | 2257/12750 [7:21:43<34:22:16, 11.79s/it] 18%|█▊        | 2258/12750 [7:21:55<34:06:50, 11.71s/it] 18%|█▊        | 2259/12750 [7:22:06<33:54:17, 11.63s/it] 18%|█▊        | 2260/12750 [7:22:18<33:47:55, 11.60s/it] 18%|█▊        | 2261/12750 [7:22:30<34:00:40, 11.67s/it] 18%|█▊        | 2262/12750 [7:22:41<33:51:27, 11.62s/it] 18%|█▊        | 2263/12750 [7:22:53<33:44:31, 11.58s/it] 18%|█▊        | 2264/12750 [7:23:04<33:38:44, 11.55s/it] 18%|█▊        | 2265/12750 [7:23:16<33:35:56, 11.54s/it] 18%|█▊        | 2266/12750 [7:23:27<33:31:45, 11.51s/it] 18%|█▊        | 2267/12750 [7:23:39<33:31:26, 11.51s/it] 18%|█▊        | 2268/12750 [7:23:50<33:31:51, 11.52s/it] 18%|█▊        | 2269/12750 [7:24:02<33:30:53, 11.51s/it] 18%|█▊        | 2270/12750 [7:24:13<33:30:02, 11.51s/it] 18%|█▊        | 2271/12750 [7:24:25<33:28:15, 11.50s/it] 18%|█▊        | 2272/12750 [7:24:36<33:29:07, 11.50s/it] 18%|█▊        | 2273/12750 [7:24:48<33:29:28, 11.51s/it] 18%|█▊        | 2274/12750 [7:24:59<33:29:06, 11.51s/it] 18%|█▊        | 2275/12750 [7:25:11<33:27:15, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120350.11lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104686.90lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2275
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2275/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2275/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2250] due to args.save_total_limit
 18%|█▊        | 2276/12750 [7:25:23<33:43:17, 11.59s/it] 18%|█▊        | 2277/12750 [7:25:34<33:38:55, 11.57s/it] 18%|█▊        | 2278/12750 [7:25:46<33:35:39, 11.55s/it] 18%|█▊        | 2279/12750 [7:25:57<33:32:00, 11.53s/it] 18%|█▊        | 2280/12750 [7:26:09<33:30:07, 11.52s/it] 18%|█▊        | 2281/12750 [7:26:20<33:29:23, 11.52s/it] 18%|█▊        | 2282/12750 [7:26:32<33:28:24, 11.51s/it] 18%|█▊        | 2283/12750 [7:26:51<40:03:49, 13.78s/it] 18%|█▊        | 2284/12750 [7:27:02<38:05:03, 13.10s/it] 18%|█▊        | 2285/12750 [7:27:14<36:42:42, 12.63s/it] 18%|█▊        | 2286/12750 [7:27:25<35:43:52, 12.29s/it] 18%|█▊        | 2287/12750 [7:27:37<35:01:22, 12.05s/it] 18%|█▊        | 2288/12750 [7:27:48<34:30:32, 11.87s/it] 18%|█▊        | 2289/12750 [7:28:00<34:11:10, 11.76s/it] 18%|█▊        | 2290/12750 [7:28:11<33:58:20, 11.69s/it] 18%|█▊        | 2291/12750 [7:28:23<33:49:00, 11.64s/it] 18%|█▊        | 2292/12750 [7:28:34<33:43:21, 11.61s/it] 18%|█▊        | 2293/12750 [7:28:46<33:39:18, 11.59s/it] 18%|█▊        | 2294/12750 [7:28:57<33:36:58, 11.57s/it] 18%|█▊        | 2295/12750 [7:29:09<33:34:55, 11.56s/it] 18%|█▊        | 2296/12750 [7:29:20<33:31:55, 11.55s/it] 18%|█▊        | 2297/12750 [7:29:32<33:28:41, 11.53s/it] 18%|█▊        | 2298/12750 [7:29:43<33:28:48, 11.53s/it] 18%|█▊        | 2299/12750 [7:29:55<33:27:50, 11.53s/it] 18%|█▊        | 2300/12750 [7:30:06<33:28:39, 11.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120286.71lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104646.85lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2300
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2300/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2300/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2275] due to args.save_total_limit
 18%|█▊        | 2301/12750 [7:30:18<33:43:22, 11.62s/it] 18%|█▊        | 2302/12750 [7:30:30<33:38:00, 11.59s/it] 18%|█▊        | 2303/12750 [7:30:41<33:33:13, 11.56s/it] 18%|█▊        | 2304/12750 [7:30:53<33:29:38, 11.54s/it] 18%|█▊        | 2305/12750 [7:31:04<33:28:01, 11.53s/it] 18%|█▊        | 2306/12750 [7:31:16<33:27:16, 11.53s/it] 18%|█▊        | 2307/12750 [7:31:27<33:26:16, 11.53s/it] 18%|█▊        | 2308/12750 [7:31:39<33:25:39, 11.52s/it] 18%|█▊        | 2309/12750 [7:31:50<33:23:38, 11.51s/it] 18%|█▊        | 2310/12750 [7:32:02<33:21:39, 11.50s/it] 18%|█▊        | 2311/12750 [7:32:13<33:20:49, 11.50s/it] 18%|█▊        | 2312/12750 [7:32:25<33:21:10, 11.50s/it] 18%|█▊        | 2313/12750 [7:32:36<33:20:29, 11.50s/it] 18%|█▊        | 2314/12750 [7:32:48<33:18:50, 11.49s/it] 18%|█▊        | 2315/12750 [7:33:07<39:49:56, 13.74s/it] 18%|█▊        | 2316/12750 [7:33:18<37:53:16, 13.07s/it] 18%|█▊        | 2317/12750 [7:33:30<36:31:12, 12.60s/it] 18%|█▊        | 2318/12750 [7:33:41<35:33:23, 12.27s/it] 18%|█▊        | 2319/12750 [7:33:53<34:53:39, 12.04s/it] 18%|█▊        | 2320/12750 [7:34:04<34:26:03, 11.89s/it] 18%|█▊        | 2321/12750 [7:34:16<34:07:44, 11.78s/it] 18%|█▊        | 2322/12750 [7:34:27<33:52:42, 11.70s/it] 18%|█▊        | 2323/12750 [7:34:39<33:41:12, 11.63s/it] 18%|█▊        | 2324/12750 [7:34:50<33:34:43, 11.59s/it] 18%|█▊        | 2325/12750 [7:35:02<33:28:51, 11.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120499.94lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104888.19lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2325
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2325/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2325/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2300] due to args.save_total_limit
 18%|█▊        | 2326/12750 [7:35:14<33:41:18, 11.63s/it] 18%|█▊        | 2327/12750 [7:35:25<33:34:59, 11.60s/it] 18%|█▊        | 2328/12750 [7:35:37<33:29:39, 11.57s/it] 18%|█▊        | 2329/12750 [7:35:48<33:25:41, 11.55s/it] 18%|█▊        | 2330/12750 [7:36:00<33:23:49, 11.54s/it] 18%|█▊        | 2331/12750 [7:36:11<33:21:56, 11.53s/it] 18%|█▊        | 2332/12750 [7:36:23<33:21:26, 11.53s/it] 18%|█▊        | 2333/12750 [7:36:35<33:58:22, 11.74s/it] 18%|█▊        | 2334/12750 [7:36:46<33:45:07, 11.67s/it] 18%|█▊        | 2335/12750 [7:36:58<33:37:05, 11.62s/it] 18%|█▊        | 2336/12750 [7:37:09<33:30:53, 11.59s/it] 18%|█▊        | 2337/12750 [7:37:21<33:27:35, 11.57s/it] 18%|█▊        | 2338/12750 [7:37:32<33:22:14, 11.54s/it] 18%|█▊        | 2339/12750 [7:37:44<33:19:59, 11.53s/it] 18%|█▊        | 2340/12750 [7:37:55<33:18:34, 11.52s/it] 18%|█▊        | 2341/12750 [7:38:07<33:16:49, 11.51s/it] 18%|█▊        | 2342/12750 [7:38:18<33:15:51, 11.51s/it] 18%|█▊        | 2343/12750 [7:38:30<33:14:37, 11.50s/it] 18%|█▊        | 2344/12750 [7:38:41<33:14:55, 11.50s/it] 18%|█▊        | 2345/12750 [7:38:53<33:17:10, 11.52s/it] 18%|█▊        | 2346/12750 [7:39:04<33:14:42, 11.50s/it] 18%|█▊        | 2347/12750 [7:39:16<33:13:25, 11.50s/it] 18%|█▊        | 2348/12750 [7:39:35<39:45:28, 13.76s/it] 18%|█▊        | 2349/12750 [7:39:46<37:49:32, 13.09s/it] 18%|█▊        | 2350/12750 [7:39:58<36:28:37, 12.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120309.46lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104622.97lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2350
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2350/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2350/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2200] due to args.save_total_limit
 18%|█▊        | 2351/12750 [7:40:10<35:45:21, 12.38s/it] 18%|█▊        | 2352/12750 [7:40:21<35:01:58, 12.13s/it] 18%|█▊        | 2353/12750 [7:40:33<34:28:49, 11.94s/it] 18%|█▊        | 2354/12750 [7:40:44<34:08:34, 11.82s/it] 18%|█▊        | 2355/12750 [7:40:56<33:53:26, 11.74s/it] 18%|█▊        | 2356/12750 [7:41:07<33:41:53, 11.67s/it] 18%|█▊        | 2357/12750 [7:41:19<33:34:48, 11.63s/it] 18%|█▊        | 2358/12750 [7:41:30<33:27:43, 11.59s/it] 19%|█▊        | 2359/12750 [7:41:42<33:22:17, 11.56s/it] 19%|█▊        | 2360/12750 [7:41:53<33:20:13, 11.55s/it] 19%|█▊        | 2361/12750 [7:42:05<33:16:55, 11.53s/it] 19%|█▊        | 2362/12750 [7:42:17<33:16:08, 11.53s/it] 19%|█▊        | 2363/12750 [7:42:28<33:13:43, 11.52s/it] 19%|█▊        | 2364/12750 [7:42:40<33:13:15, 11.52s/it] 19%|█▊        | 2365/12750 [7:42:51<33:13:20, 11.52s/it] 19%|█▊        | 2366/12750 [7:43:03<33:12:26, 11.51s/it] 19%|█▊        | 2367/12750 [7:43:14<33:10:31, 11.50s/it] 19%|█▊        | 2368/12750 [7:43:26<33:11:07, 11.51s/it] 19%|█▊        | 2369/12750 [7:43:37<33:11:10, 11.51s/it] 19%|█▊        | 2370/12750 [7:43:49<33:10:27, 11.51s/it] 19%|█▊        | 2371/12750 [7:44:00<33:11:51, 11.51s/it] 19%|█▊        | 2372/12750 [7:44:12<33:12:04, 11.52s/it] 19%|█▊        | 2373/12750 [7:44:23<33:11:04, 11.51s/it] 19%|█▊        | 2374/12750 [7:44:35<33:11:22, 11.52s/it] 19%|█▊        | 2375/12750 [7:44:46<33:11:09, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120261.54lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101171.76lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2375
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2375/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2375/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2325] due to args.save_total_limit
 19%|█▊        | 2376/12750 [7:44:58<33:38:29, 11.67s/it] 19%|█▊        | 2377/12750 [7:45:10<33:28:45, 11.62s/it] 19%|█▊        | 2378/12750 [7:45:21<33:22:17, 11.58s/it] 19%|█▊        | 2379/12750 [7:45:33<33:18:39, 11.56s/it] 19%|█▊        | 2380/12750 [7:45:51<39:06:57, 13.58s/it] 19%|█▊        | 2381/12750 [7:46:02<37:18:34, 12.95s/it] 19%|█▊        | 2382/12750 [7:46:14<36:05:09, 12.53s/it] 19%|█▊        | 2383/12750 [7:46:25<35:09:32, 12.21s/it] 19%|█▊        | 2384/12750 [7:46:37<34:35:03, 12.01s/it] 19%|█▊        | 2385/12750 [7:46:49<34:10:10, 11.87s/it] 19%|█▊        | 2386/12750 [7:47:00<33:51:11, 11.76s/it] 19%|█▊        | 2387/12750 [7:47:12<33:38:13, 11.69s/it] 19%|█▊        | 2388/12750 [7:47:23<33:27:44, 11.63s/it] 19%|█▊        | 2389/12750 [7:47:35<33:20:11, 11.58s/it] 19%|█▊        | 2390/12750 [7:47:46<33:17:15, 11.57s/it] 19%|█▉        | 2391/12750 [7:47:58<33:14:45, 11.55s/it] 19%|█▉        | 2392/12750 [7:48:09<33:10:35, 11.53s/it] 19%|█▉        | 2393/12750 [7:48:21<33:08:21, 11.52s/it] 19%|█▉        | 2394/12750 [7:48:32<33:07:30, 11.52s/it] 19%|█▉        | 2395/12750 [7:48:44<33:05:08, 11.50s/it] 19%|█▉        | 2396/12750 [7:48:55<33:04:05, 11.50s/it] 19%|█▉        | 2397/12750 [7:49:06<33:02:58, 11.49s/it] 19%|█▉        | 2398/12750 [7:49:18<33:02:34, 11.49s/it] 19%|█▉        | 2399/12750 [7:49:29<33:02:35, 11.49s/it] 19%|█▉        | 2400/12750 [7:49:41<33:02:45, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120390.42lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104658.85lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2400
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2400/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2400/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2350] due to args.save_total_limit
 19%|█▉        | 2401/12750 [7:49:53<33:19:39, 11.59s/it] 19%|█▉        | 2402/12750 [7:50:04<33:15:00, 11.57s/it] 19%|█▉        | 2403/12750 [7:50:16<33:12:07, 11.55s/it] 19%|█▉        | 2404/12750 [7:50:27<33:10:15, 11.54s/it] 19%|█▉        | 2405/12750 [7:50:39<33:08:21, 11.53s/it] 19%|█▉        | 2406/12750 [7:50:50<33:06:33, 11.52s/it] 19%|█▉        | 2407/12750 [7:51:02<33:08:03, 11.53s/it] 19%|█▉        | 2408/12750 [7:51:13<33:07:31, 11.53s/it] 19%|█▉        | 2409/12750 [7:51:25<33:07:17, 11.53s/it] 19%|█▉        | 2410/12750 [7:51:36<33:06:00, 11.52s/it] 19%|█▉        | 2411/12750 [7:51:48<33:04:25, 11.52s/it] 19%|█▉        | 2412/12750 [7:52:07<39:29:12, 13.75s/it] 19%|█▉        | 2413/12750 [7:52:18<37:33:30, 13.08s/it] 19%|█▉        | 2414/12750 [7:52:30<36:11:12, 12.60s/it] 19%|█▉        | 2415/12750 [7:52:41<35:14:25, 12.28s/it] 19%|█▉        | 2416/12750 [7:52:53<34:33:42, 12.04s/it] 19%|█▉        | 2417/12750 [7:53:04<34:04:24, 11.87s/it] 19%|█▉        | 2418/12750 [7:53:16<33:44:14, 11.76s/it] 19%|█▉        | 2419/12750 [7:53:27<33:32:59, 11.69s/it] 19%|█▉        | 2420/12750 [7:53:39<33:22:42, 11.63s/it] 19%|█▉        | 2421/12750 [7:53:50<33:14:14, 11.58s/it] 19%|█▉        | 2422/12750 [7:54:02<33:10:40, 11.56s/it] 19%|█▉        | 2423/12750 [7:54:13<33:08:11, 11.55s/it] 19%|█▉        | 2424/12750 [7:54:25<33:06:12, 11.54s/it] 19%|█▉        | 2425/12750 [7:54:36<33:03:56, 11.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120560.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104859.44lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2425
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2425/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2425/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2375] due to args.save_total_limit
 19%|█▉        | 2426/12750 [7:54:48<33:17:16, 11.61s/it] 19%|█▉        | 2427/12750 [7:55:00<33:11:15, 11.57s/it] 19%|█▉        | 2428/12750 [7:55:11<33:07:43, 11.55s/it] 19%|█▉        | 2429/12750 [7:55:23<33:05:03, 11.54s/it] 19%|█▉        | 2430/12750 [7:55:34<33:02:03, 11.52s/it] 19%|█▉        | 2431/12750 [7:55:46<33:02:26, 11.53s/it] 19%|█▉        | 2432/12750 [7:55:57<33:01:34, 11.52s/it] 19%|█▉        | 2433/12750 [7:56:09<32:59:33, 11.51s/it] 19%|█▉        | 2434/12750 [7:56:20<32:58:29, 11.51s/it] 19%|█▉        | 2435/12750 [7:56:32<32:57:38, 11.50s/it] 19%|█▉        | 2436/12750 [7:56:43<32:57:19, 11.50s/it] 19%|█▉        | 2437/12750 [7:56:55<32:56:05, 11.50s/it] 19%|█▉        | 2438/12750 [7:57:06<32:55:51, 11.50s/it] 19%|█▉        | 2439/12750 [7:57:18<32:54:59, 11.49s/it] 19%|█▉        | 2440/12750 [7:57:29<32:55:05, 11.49s/it] 19%|█▉        | 2441/12750 [7:57:41<32:55:24, 11.50s/it] 19%|█▉        | 2442/12750 [7:57:52<32:55:18, 11.50s/it] 19%|█▉        | 2443/12750 [7:58:04<32:55:58, 11.50s/it] 19%|█▉        | 2444/12750 [7:58:23<39:22:14, 13.75s/it] 19%|█▉        | 2445/12750 [7:58:34<37:25:47, 13.08s/it] 19%|█▉        | 2446/12750 [7:58:46<36:09:28, 12.63s/it] 19%|█▉        | 2447/12750 [7:58:57<35:16:32, 12.33s/it] 19%|█▉        | 2448/12750 [7:59:09<34:37:22, 12.10s/it] 19%|█▉        | 2449/12750 [7:59:21<34:10:36, 11.94s/it] 19%|█▉        | 2450/12750 [7:59:32<33:53:14, 11.84s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120338.35lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104629.35lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2450
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2450/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2450/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2425] due to args.save_total_limit
 19%|█▉        | 2451/12750 [7:59:44<33:56:30, 11.86s/it] 19%|█▉        | 2452/12750 [7:59:56<33:41:03, 11.78s/it] 19%|█▉        | 2453/12750 [8:00:07<33:31:43, 11.72s/it] 19%|█▉        | 2454/12750 [8:00:19<33:23:25, 11.67s/it] 19%|█▉        | 2455/12750 [8:00:30<33:17:51, 11.64s/it] 19%|█▉        | 2456/12750 [8:00:42<33:15:12, 11.63s/it] 19%|█▉        | 2457/12750 [8:00:54<33:14:05, 11.62s/it] 19%|█▉        | 2458/12750 [8:01:05<33:12:02, 11.61s/it] 19%|█▉        | 2459/12750 [8:01:17<33:09:10, 11.60s/it] 19%|█▉        | 2460/12750 [8:01:28<33:07:32, 11.59s/it] 19%|█▉        | 2461/12750 [8:01:40<33:06:13, 11.58s/it] 19%|█▉        | 2462/12750 [8:01:52<33:06:24, 11.58s/it] 19%|█▉        | 2463/12750 [8:02:03<33:05:29, 11.58s/it] 19%|█▉        | 2464/12750 [8:02:15<33:04:36, 11.58s/it] 19%|█▉        | 2465/12750 [8:02:26<33:05:11, 11.58s/it] 19%|█▉        | 2466/12750 [8:02:38<33:04:45, 11.58s/it] 19%|█▉        | 2467/12750 [8:02:49<33:04:23, 11.58s/it] 19%|█▉        | 2468/12750 [8:03:01<33:03:18, 11.57s/it] 19%|█▉        | 2469/12750 [8:03:13<33:03:55, 11.58s/it] 19%|█▉        | 2470/12750 [8:03:24<33:03:53, 11.58s/it] 19%|█▉        | 2471/12750 [8:03:36<33:04:03, 11.58s/it] 19%|█▉        | 2472/12750 [8:03:47<33:04:30, 11.58s/it] 19%|█▉        | 2473/12750 [8:03:59<33:05:00, 11.59s/it] 19%|█▉        | 2474/12750 [8:04:11<33:04:27, 11.59s/it] 19%|█▉        | 2475/12750 [8:04:22<33:04:46, 11.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120420.88lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104812.47lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2475
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2475/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2475/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2450] due to args.save_total_limit
 19%|█▉        | 2476/12750 [8:04:42<39:48:13, 13.95s/it] 19%|█▉        | 2477/12750 [8:04:53<37:46:18, 13.24s/it] 19%|█▉        | 2478/12750 [8:05:05<36:20:01, 12.73s/it] 19%|█▉        | 2479/12750 [8:05:16<35:18:47, 12.38s/it] 19%|█▉        | 2480/12750 [8:05:28<34:37:37, 12.14s/it] 19%|█▉        | 2481/12750 [8:05:39<34:09:00, 11.97s/it] 19%|█▉        | 2482/12750 [8:05:51<33:47:42, 11.85s/it] 19%|█▉        | 2483/12750 [8:06:03<33:34:20, 11.77s/it] 19%|█▉        | 2484/12750 [8:06:14<33:24:30, 11.72s/it] 19%|█▉        | 2485/12750 [8:06:26<33:17:07, 11.67s/it] 19%|█▉        | 2486/12750 [8:06:37<33:12:02, 11.64s/it] 20%|█▉        | 2487/12750 [8:06:49<33:08:35, 11.63s/it] 20%|█▉        | 2488/12750 [8:07:00<33:04:47, 11.60s/it] 20%|█▉        | 2489/12750 [8:07:12<33:03:02, 11.60s/it] 20%|█▉        | 2490/12750 [8:07:24<33:02:40, 11.59s/it] 20%|█▉        | 2491/12750 [8:07:35<33:01:30, 11.59s/it] 20%|█▉        | 2492/12750 [8:07:47<33:00:45, 11.59s/it] 20%|█▉        | 2493/12750 [8:07:58<32:59:46, 11.58s/it] 20%|█▉        | 2494/12750 [8:08:10<32:58:39, 11.58s/it] 20%|█▉        | 2495/12750 [8:08:21<32:57:24, 11.57s/it] 20%|█▉        | 2496/12750 [8:08:33<32:57:52, 11.57s/it] 20%|█▉        | 2497/12750 [8:08:45<32:58:05, 11.58s/it] 20%|█▉        | 2498/12750 [8:08:56<32:56:11, 11.57s/it] 20%|█▉        | 2499/12750 [8:09:08<32:55:27, 11.56s/it] 20%|█▉        | 2500/12750 [8:09:19<32:56:50, 11.57s/it]                                                          20%|█▉        | 2500/12750 [8:09:19<32:56:50, 11.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120400.78lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104483.49lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2500
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2500/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2500/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2475] due to args.save_total_limit
 20%|█▉        | 2501/12750 [8:09:31<33:12:08, 11.66s/it] 20%|█▉        | 2502/12750 [8:09:43<33:06:34, 11.63s/it] 20%|█▉        | 2503/12750 [8:09:54<33:03:52, 11.62s/it] 20%|█▉        | 2504/12750 [8:10:06<33:01:55, 11.61s/it] 20%|█▉        | 2505/12750 [8:10:17<32:59:09, 11.59s/it] 20%|█▉        | 2506/12750 [8:10:29<32:57:00, 11.58s/it] 20%|█▉        | 2507/12750 [8:10:41<32:56:21, 11.58s/it] 20%|█▉        | 2508/12750 [8:11:00<39:19:50, 13.82s/it] 20%|█▉        | 2509/12750 [8:11:11<37:23:58, 13.15s/it] 20%|█▉        | 2510/12750 [8:11:23<36:02:20, 12.67s/it] 20%|█▉        | 2511/12750 [8:11:34<35:06:17, 12.34s/it] 20%|█▉        | 2512/12750 [8:11:46<34:25:36, 12.11s/it] 20%|█▉        | 2513/12750 [8:11:57<33:58:10, 11.95s/it] 20%|█▉        | 2514/12750 [8:12:09<33:40:00, 11.84s/it] 20%|█▉        | 2515/12750 [8:12:21<33:27:46, 11.77s/it] 20%|█▉        | 2516/12750 [8:12:32<33:18:17, 11.72s/it] 20%|█▉        | 2517/12750 [8:12:44<33:11:25, 11.68s/it] 20%|█▉        | 2518/12750 [8:12:55<33:05:25, 11.64s/it] 20%|█▉        | 2519/12750 [8:13:07<33:01:00, 11.62s/it] 20%|█▉        | 2520/12750 [8:13:19<32:59:52, 11.61s/it] 20%|█▉        | 2521/12750 [8:13:30<32:58:02, 11.60s/it] 20%|█▉        | 2522/12750 [8:13:42<32:55:01, 11.59s/it] 20%|█▉        | 2523/12750 [8:13:53<32:55:02, 11.59s/it] 20%|█▉        | 2524/12750 [8:14:05<32:52:41, 11.57s/it] 20%|█▉        | 2525/12750 [8:14:16<32:52:13, 11.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120414.74lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104754.98lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2525
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2525/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2525/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2400] due to args.save_total_limit
 20%|█▉        | 2526/12750 [8:14:28<33:07:59, 11.67s/it] 20%|█▉        | 2527/12750 [8:14:40<33:02:52, 11.64s/it] 20%|█▉        | 2528/12750 [8:14:51<32:59:20, 11.62s/it] 20%|█▉        | 2529/12750 [8:15:03<32:56:32, 11.60s/it] 20%|█▉        | 2530/12750 [8:15:15<32:53:43, 11.59s/it] 20%|█▉        | 2531/12750 [8:15:26<32:53:11, 11.59s/it] 20%|█▉        | 2532/12750 [8:15:38<32:52:59, 11.59s/it] 20%|█▉        | 2533/12750 [8:15:49<32:52:20, 11.58s/it] 20%|█▉        | 2534/12750 [8:16:01<32:50:59, 11.58s/it] 20%|█▉        | 2535/12750 [8:16:12<32:51:20, 11.58s/it] 20%|█▉        | 2536/12750 [8:16:24<32:51:41, 11.58s/it] 20%|█▉        | 2537/12750 [8:16:36<32:50:12, 11.57s/it] 20%|█▉        | 2538/12750 [8:16:47<32:51:01, 11.58s/it] 20%|█▉        | 2539/12750 [8:16:59<32:51:14, 11.58s/it] 20%|█▉        | 2540/12750 [8:17:17<38:29:05, 13.57s/it] 20%|█▉        | 2541/12750 [8:17:29<36:46:35, 12.97s/it] 20%|█▉        | 2542/12750 [8:17:40<35:34:49, 12.55s/it] 20%|█▉        | 2543/12750 [8:17:52<34:43:54, 12.25s/it] 20%|█▉        | 2544/12750 [8:18:03<34:09:27, 12.05s/it] 20%|█▉        | 2545/12750 [8:18:15<33:44:08, 11.90s/it] 20%|█▉        | 2546/12750 [8:18:26<33:27:00, 11.80s/it] 20%|█▉        | 2547/12750 [8:18:38<33:15:54, 11.74s/it] 20%|█▉        | 2548/12750 [8:18:50<33:09:00, 11.70s/it] 20%|█▉        | 2549/12750 [8:18:57<29:12:10, 10.31s/it] 20%|██        | 2550/12750 [8:18:57<21:06:41,  7.45s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120399.89lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104707.91lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2550
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2550/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2550/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2500] due to args.save_total_limit
 20%|██        | 2551/12750 [8:19:21<34:57:02, 12.34s/it] 20%|██        | 2552/12750 [8:19:33<34:20:46, 12.12s/it] 20%|██        | 2553/12750 [8:19:44<33:56:24, 11.98s/it] 20%|██        | 2554/12750 [8:19:56<33:38:03, 11.88s/it] 20%|██        | 2555/12750 [8:20:08<33:23:18, 11.79s/it] 20%|██        | 2556/12750 [8:20:19<33:14:18, 11.74s/it] 20%|██        | 2557/12750 [8:20:31<33:06:07, 11.69s/it] 20%|██        | 2558/12750 [8:20:42<33:01:18, 11.66s/it] 20%|██        | 2559/12750 [8:20:54<32:57:24, 11.64s/it] 20%|██        | 2560/12750 [8:21:06<32:55:30, 11.63s/it] 20%|██        | 2561/12750 [8:21:17<32:53:28, 11.62s/it] 20%|██        | 2562/12750 [8:21:29<32:53:39, 11.62s/it] 20%|██        | 2563/12750 [8:21:41<32:54:50, 11.63s/it] 20%|██        | 2564/12750 [8:21:52<32:53:34, 11.63s/it] 20%|██        | 2565/12750 [8:22:04<32:51:01, 11.61s/it] 20%|██        | 2566/12750 [8:22:15<32:51:29, 11.62s/it] 20%|██        | 2567/12750 [8:22:27<32:51:06, 11.61s/it] 20%|██        | 2568/12750 [8:22:39<32:50:47, 11.61s/it] 20%|██        | 2569/12750 [8:22:50<32:50:38, 11.61s/it] 20%|██        | 2570/12750 [8:23:02<32:48:22, 11.60s/it] 20%|██        | 2571/12750 [8:23:13<32:47:10, 11.60s/it] 20%|██        | 2572/12750 [8:23:25<32:46:22, 11.59s/it] 20%|██        | 2573/12750 [8:23:44<39:09:01, 13.85s/it] 20%|██        | 2574/12750 [8:23:56<37:14:54, 13.18s/it] 20%|██        | 2575/12750 [8:24:07<35:52:39, 12.69s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120331.32lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104663.00lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2575
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2575/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2575/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2525] due to args.save_total_limit
 20%|██        | 2576/12750 [8:24:19<35:12:33, 12.46s/it] 20%|██        | 2577/12750 [8:24:31<34:27:55, 12.20s/it] 20%|██        | 2578/12750 [8:24:42<33:57:34, 12.02s/it] 20%|██        | 2579/12750 [8:24:54<33:36:46, 11.90s/it] 20%|██        | 2580/12750 [8:25:05<33:21:05, 11.81s/it] 20%|██        | 2581/12750 [8:25:17<33:10:02, 11.74s/it] 20%|██        | 2582/12750 [8:25:29<33:02:47, 11.70s/it] 20%|██        | 2583/12750 [8:25:40<32:57:35, 11.67s/it] 20%|██        | 2584/12750 [8:25:52<32:54:36, 11.65s/it] 20%|██        | 2585/12750 [8:26:04<32:52:33, 11.64s/it] 20%|██        | 2586/12750 [8:26:15<32:50:09, 11.63s/it] 20%|██        | 2587/12750 [8:26:27<32:50:14, 11.63s/it] 20%|██        | 2588/12750 [8:26:38<32:47:19, 11.62s/it] 20%|██        | 2589/12750 [8:26:50<32:48:11, 11.62s/it] 20%|██        | 2590/12750 [8:27:02<32:46:32, 11.61s/it] 20%|██        | 2591/12750 [8:27:13<32:45:45, 11.61s/it] 20%|██        | 2592/12750 [8:27:25<32:46:59, 11.62s/it] 20%|██        | 2593/12750 [8:27:37<32:59:23, 11.69s/it] 20%|██        | 2594/12750 [8:27:48<32:55:25, 11.67s/it] 20%|██        | 2595/12750 [8:28:00<32:52:08, 11.65s/it] 20%|██        | 2596/12750 [8:28:11<32:49:20, 11.64s/it] 20%|██        | 2597/12750 [8:28:23<32:47:51, 11.63s/it] 20%|██        | 2598/12750 [8:28:35<32:45:24, 11.62s/it] 20%|██        | 2599/12750 [8:28:46<32:43:31, 11.61s/it] 20%|██        | 2600/12750 [8:28:58<32:42:46, 11.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120522.64lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104642.98lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2600
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2600/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2600/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2550] due to args.save_total_limit
 20%|██        | 2601/12750 [8:29:10<32:56:46, 11.69s/it] 20%|██        | 2602/12750 [8:29:21<32:50:42, 11.65s/it] 20%|██        | 2603/12750 [8:29:33<32:48:39, 11.64s/it] 20%|██        | 2604/12750 [8:29:45<32:45:02, 11.62s/it] 20%|██        | 2605/12750 [8:30:04<39:03:51, 13.86s/it] 20%|██        | 2606/12750 [8:30:15<37:04:23, 13.16s/it] 20%|██        | 2607/12750 [8:30:27<35:40:31, 12.66s/it] 20%|██        | 2608/12750 [8:30:38<34:40:55, 12.31s/it] 20%|██        | 2609/12750 [8:30:50<33:59:46, 12.07s/it] 20%|██        | 2610/12750 [8:31:01<33:32:15, 11.91s/it] 20%|██        | 2611/12750 [8:31:13<33:11:23, 11.78s/it] 20%|██        | 2612/12750 [8:31:24<32:58:43, 11.71s/it] 20%|██        | 2613/12750 [8:31:36<32:50:14, 11.66s/it] 21%|██        | 2614/12750 [8:31:47<32:43:41, 11.62s/it] 21%|██        | 2615/12750 [8:31:59<32:38:17, 11.59s/it] 21%|██        | 2616/12750 [8:32:10<32:32:51, 11.56s/it] 21%|██        | 2617/12750 [8:32:22<32:30:13, 11.55s/it] 21%|██        | 2618/12750 [8:32:33<32:27:50, 11.53s/it] 21%|██        | 2619/12750 [8:32:45<32:27:06, 11.53s/it] 21%|██        | 2620/12750 [8:32:56<32:24:14, 11.52s/it] 21%|██        | 2621/12750 [8:33:08<32:24:56, 11.52s/it] 21%|██        | 2622/12750 [8:33:19<32:25:45, 11.53s/it] 21%|██        | 2623/12750 [8:33:31<32:23:59, 11.52s/it] 21%|██        | 2624/12750 [8:33:42<32:24:24, 11.52s/it] 21%|██        | 2625/12750 [8:33:54<32:23:43, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120285.82lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104264.16lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2625
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2625/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2625/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2575] due to args.save_total_limit
 21%|██        | 2626/12750 [8:34:06<32:36:52, 11.60s/it] 21%|██        | 2627/12750 [8:34:17<32:32:40, 11.57s/it] 21%|██        | 2628/12750 [8:34:29<32:30:37, 11.56s/it] 21%|██        | 2629/12750 [8:34:40<32:26:51, 11.54s/it] 21%|██        | 2630/12750 [8:34:52<32:24:58, 11.53s/it] 21%|██        | 2631/12750 [8:35:03<32:24:15, 11.53s/it] 21%|██        | 2632/12750 [8:35:15<32:22:33, 11.52s/it] 21%|██        | 2633/12750 [8:35:26<32:22:56, 11.52s/it] 21%|██        | 2634/12750 [8:35:38<32:23:55, 11.53s/it] 21%|██        | 2635/12750 [8:35:49<32:23:39, 11.53s/it] 21%|██        | 2636/12750 [8:36:01<32:21:29, 11.52s/it] 21%|██        | 2637/12750 [8:36:12<32:19:52, 11.51s/it] 21%|██        | 2638/12750 [8:36:31<38:35:45, 13.74s/it] 21%|██        | 2639/12750 [8:36:43<36:42:44, 13.07s/it] 21%|██        | 2640/12750 [8:36:54<35:22:49, 12.60s/it] 21%|██        | 2641/12750 [8:37:06<34:29:24, 12.28s/it] 21%|██        | 2642/12750 [8:37:17<33:50:56, 12.06s/it] 21%|██        | 2643/12750 [8:37:29<33:25:37, 11.91s/it] 21%|██        | 2644/12750 [8:37:40<33:04:09, 11.78s/it] 21%|██        | 2645/12750 [8:37:52<32:50:17, 11.70s/it] 21%|██        | 2646/12750 [8:38:03<32:41:13, 11.65s/it] 21%|██        | 2647/12750 [8:38:15<32:37:01, 11.62s/it] 21%|██        | 2648/12750 [8:38:27<32:32:36, 11.60s/it] 21%|██        | 2649/12750 [8:38:38<32:30:28, 11.59s/it] 21%|██        | 2650/12750 [8:38:50<32:28:36, 11.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120371.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104647.92lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2650
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2650/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2650/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2600] due to args.save_total_limit
 21%|██        | 2651/12750 [8:39:02<32:42:17, 11.66s/it] 21%|██        | 2652/12750 [8:39:13<32:36:06, 11.62s/it] 21%|██        | 2653/12750 [8:39:25<32:31:28, 11.60s/it] 21%|██        | 2654/12750 [8:39:36<32:26:03, 11.57s/it] 21%|██        | 2655/12750 [8:39:48<32:23:56, 11.55s/it] 21%|██        | 2656/12750 [8:39:59<32:21:08, 11.54s/it] 21%|██        | 2657/12750 [8:40:11<32:20:52, 11.54s/it] 21%|██        | 2658/12750 [8:40:22<32:20:10, 11.53s/it] 21%|██        | 2659/12750 [8:40:34<32:18:58, 11.53s/it] 21%|██        | 2660/12750 [8:40:45<32:16:50, 11.52s/it] 21%|██        | 2661/12750 [8:40:57<32:17:55, 11.52s/it] 21%|██        | 2662/12750 [8:41:08<32:17:13, 11.52s/it] 21%|██        | 2663/12750 [8:41:20<32:16:38, 11.52s/it] 21%|██        | 2664/12750 [8:41:31<32:15:13, 11.51s/it] 21%|██        | 2665/12750 [8:41:43<32:15:06, 11.51s/it] 21%|██        | 2666/12750 [8:41:54<32:16:05, 11.52s/it] 21%|██        | 2667/12750 [8:42:06<32:17:34, 11.53s/it] 21%|██        | 2668/12750 [8:42:17<32:17:33, 11.53s/it] 21%|██        | 2669/12750 [8:42:29<32:16:39, 11.53s/it] 21%|██        | 2670/12750 [8:42:47<37:48:43, 13.50s/it] 21%|██        | 2671/12750 [8:42:59<36:09:31, 12.92s/it] 21%|██        | 2672/12750 [8:43:10<34:58:52, 12.50s/it] 21%|██        | 2673/12750 [8:43:22<34:07:01, 12.19s/it] 21%|██        | 2674/12750 [8:43:33<33:31:30, 11.98s/it] 21%|██        | 2675/12750 [8:43:45<33:08:43, 11.84s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120251.07lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104627.42lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2675
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2675/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2675/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2625] due to args.save_total_limit
 21%|██        | 2676/12750 [8:43:56<33:11:14, 11.86s/it] 21%|██        | 2677/12750 [8:44:08<32:52:06, 11.75s/it] 21%|██        | 2678/12750 [8:44:19<32:41:01, 11.68s/it] 21%|██        | 2679/12750 [8:44:31<32:33:41, 11.64s/it] 21%|██        | 2680/12750 [8:44:43<32:25:22, 11.59s/it] 21%|██        | 2681/12750 [8:44:54<32:21:48, 11.57s/it] 21%|██        | 2682/12750 [8:45:06<32:19:19, 11.56s/it] 21%|██        | 2683/12750 [8:45:17<32:18:30, 11.55s/it] 21%|██        | 2684/12750 [8:45:29<32:19:06, 11.56s/it] 21%|██        | 2685/12750 [8:45:40<32:16:32, 11.54s/it] 21%|██        | 2686/12750 [8:45:52<32:13:54, 11.53s/it] 21%|██        | 2687/12750 [8:46:03<32:12:02, 11.52s/it] 21%|██        | 2688/12750 [8:46:15<32:11:38, 11.52s/it] 21%|██        | 2689/12750 [8:46:26<32:09:39, 11.51s/it] 21%|██        | 2690/12750 [8:46:38<32:10:24, 11.51s/it] 21%|██        | 2691/12750 [8:46:49<32:10:16, 11.51s/it] 21%|██        | 2692/12750 [8:47:01<32:10:59, 11.52s/it] 21%|██        | 2693/12750 [8:47:12<32:12:02, 11.53s/it] 21%|██        | 2694/12750 [8:47:24<32:10:58, 11.52s/it] 21%|██        | 2695/12750 [8:47:35<32:09:58, 11.52s/it] 21%|██        | 2696/12750 [8:47:47<32:10:20, 11.52s/it] 21%|██        | 2697/12750 [8:47:58<32:09:31, 11.52s/it] 21%|██        | 2698/12750 [8:48:10<32:07:37, 11.51s/it] 21%|██        | 2699/12750 [8:48:21<32:09:15, 11.52s/it] 21%|██        | 2700/12750 [8:48:33<32:10:09, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120489.94lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104895.96lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2700
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2700/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2700/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2650] due to args.save_total_limit
 21%|██        | 2701/12750 [8:48:45<32:24:01, 11.61s/it] 21%|██        | 2702/12750 [8:49:04<38:29:00, 13.79s/it] 21%|██        | 2703/12750 [8:49:15<36:34:25, 13.10s/it] 21%|██        | 2704/12750 [8:49:27<35:14:05, 12.63s/it] 21%|██        | 2705/12750 [8:49:38<34:17:32, 12.29s/it] 21%|██        | 2706/12750 [8:49:50<33:38:33, 12.06s/it] 21%|██        | 2707/12750 [8:50:01<33:10:37, 11.89s/it] 21%|██        | 2708/12750 [8:50:13<32:50:58, 11.78s/it] 21%|██        | 2709/12750 [8:50:24<32:39:14, 11.71s/it] 21%|██▏       | 2710/12750 [8:50:36<32:29:51, 11.65s/it] 21%|██▏       | 2711/12750 [8:50:47<32:22:28, 11.61s/it] 21%|██▏       | 2712/12750 [8:50:59<32:14:54, 11.57s/it] 21%|██▏       | 2713/12750 [8:51:10<32:13:12, 11.56s/it] 21%|██▏       | 2714/12750 [8:51:22<32:09:51, 11.54s/it] 21%|██▏       | 2715/12750 [8:51:33<32:07:32, 11.52s/it] 21%|██▏       | 2716/12750 [8:51:45<32:09:08, 11.54s/it] 21%|██▏       | 2717/12750 [8:51:56<32:07:41, 11.53s/it] 21%|██▏       | 2718/12750 [8:52:08<32:05:46, 11.52s/it] 21%|██▏       | 2719/12750 [8:52:19<32:07:29, 11.53s/it] 21%|██▏       | 2720/12750 [8:52:31<32:05:58, 11.52s/it] 21%|██▏       | 2721/12750 [8:52:42<32:05:30, 11.52s/it] 21%|██▏       | 2722/12750 [8:52:54<32:04:20, 11.51s/it] 21%|██▏       | 2723/12750 [8:53:05<32:01:44, 11.50s/it] 21%|██▏       | 2724/12750 [8:53:17<32:04:26, 11.52s/it] 21%|██▏       | 2725/12750 [8:53:28<32:00:57, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120461.49lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104805.88lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2725
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2725/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2725/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2700] due to args.save_total_limit
 21%|██▏       | 2726/12750 [8:53:40<32:14:09, 11.58s/it] 21%|██▏       | 2727/12750 [8:53:52<32:08:55, 11.55s/it] 21%|██▏       | 2728/12750 [8:54:03<32:05:58, 11.53s/it] 21%|██▏       | 2729/12750 [8:54:15<32:03:21, 11.52s/it] 21%|██▏       | 2730/12750 [8:54:26<32:01:14, 11.50s/it] 21%|██▏       | 2731/12750 [8:54:37<31:59:45, 11.50s/it] 21%|██▏       | 2732/12750 [8:54:49<31:59:03, 11.49s/it] 21%|██▏       | 2733/12750 [8:55:00<31:56:11, 11.48s/it] 21%|██▏       | 2734/12750 [8:55:19<37:33:54, 13.50s/it] 21%|██▏       | 2735/12750 [8:55:30<35:49:33, 12.88s/it] 21%|██▏       | 2736/12750 [8:55:42<34:38:21, 12.45s/it] 21%|██▏       | 2737/12750 [8:55:53<33:48:13, 12.15s/it] 21%|██▏       | 2738/12750 [8:56:04<33:13:32, 11.95s/it] 21%|██▏       | 2739/12750 [8:56:16<32:48:56, 11.80s/it] 21%|██▏       | 2740/12750 [8:56:27<32:33:46, 11.71s/it] 21%|██▏       | 2741/12750 [8:56:39<32:21:05, 11.64s/it] 22%|██▏       | 2742/12750 [8:56:50<32:12:58, 11.59s/it] 22%|██▏       | 2743/12750 [8:57:02<32:06:41, 11.55s/it] 22%|██▏       | 2744/12750 [8:57:13<32:04:00, 11.54s/it] 22%|██▏       | 2745/12750 [8:57:25<31:59:00, 11.51s/it] 22%|██▏       | 2746/12750 [8:57:36<31:58:56, 11.51s/it] 22%|██▏       | 2747/12750 [8:57:48<31:56:36, 11.50s/it] 22%|██▏       | 2748/12750 [8:57:59<31:54:54, 11.49s/it] 22%|██▏       | 2749/12750 [8:58:11<31:53:08, 11.48s/it] 22%|██▏       | 2750/12750 [8:58:22<31:52:05, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120332.08lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104680.71lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2750
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2750/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2750/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2675] due to args.save_total_limit
 22%|██▏       | 2751/12750 [8:58:34<32:08:42, 11.57s/it] 22%|██▏       | 2752/12750 [8:58:45<32:02:40, 11.54s/it] 22%|██▏       | 2753/12750 [8:58:57<31:58:17, 11.51s/it] 22%|██▏       | 2754/12750 [8:59:08<31:57:05, 11.51s/it] 22%|██▏       | 2755/12750 [8:59:20<31:55:31, 11.50s/it] 22%|██▏       | 2756/12750 [8:59:31<31:54:42, 11.50s/it] 22%|██▏       | 2757/12750 [8:59:43<31:52:38, 11.48s/it] 22%|██▏       | 2758/12750 [8:59:54<31:51:57, 11.48s/it] 22%|██▏       | 2759/12750 [9:00:06<31:51:22, 11.48s/it] 22%|██▏       | 2760/12750 [9:00:17<31:51:29, 11.48s/it] 22%|██▏       | 2761/12750 [9:00:29<31:51:38, 11.48s/it] 22%|██▏       | 2762/12750 [9:00:40<31:51:33, 11.48s/it] 22%|██▏       | 2763/12750 [9:00:52<31:52:23, 11.49s/it] 22%|██▏       | 2764/12750 [9:01:03<31:50:25, 11.48s/it] 22%|██▏       | 2765/12750 [9:01:15<31:49:50, 11.48s/it] 22%|██▏       | 2766/12750 [9:01:34<38:08:27, 13.75s/it] 22%|██▏       | 2767/12750 [9:01:45<36:12:37, 13.06s/it] 22%|██▏       | 2768/12750 [9:01:57<34:52:25, 12.58s/it] 22%|██▏       | 2769/12750 [9:02:08<33:57:47, 12.25s/it] 22%|██▏       | 2770/12750 [9:02:20<33:22:37, 12.04s/it] 22%|██▏       | 2771/12750 [9:02:31<32:53:17, 11.86s/it] 22%|██▏       | 2772/12750 [9:02:43<32:34:15, 11.75s/it] 22%|██▏       | 2773/12750 [9:02:54<32:20:42, 11.67s/it] 22%|██▏       | 2774/12750 [9:03:05<32:11:02, 11.61s/it] 22%|██▏       | 2775/12750 [9:03:17<32:03:31, 11.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120379.67lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104746.45lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2775
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2775/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2775/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2725] due to args.save_total_limit
 22%|██▏       | 2776/12750 [9:03:29<32:14:04, 11.63s/it] 22%|██▏       | 2777/12750 [9:03:40<32:06:17, 11.59s/it] 22%|██▏       | 2778/12750 [9:03:52<32:01:17, 11.56s/it] 22%|██▏       | 2779/12750 [9:04:03<31:56:08, 11.53s/it] 22%|██▏       | 2780/12750 [9:04:15<31:53:16, 11.51s/it] 22%|██▏       | 2781/12750 [9:04:26<31:50:00, 11.50s/it] 22%|██▏       | 2782/12750 [9:04:38<31:49:10, 11.49s/it] 22%|██▏       | 2783/12750 [9:04:49<31:48:39, 11.49s/it] 22%|██▏       | 2784/12750 [9:05:01<31:46:14, 11.48s/it] 22%|██▏       | 2785/12750 [9:05:12<31:43:33, 11.46s/it] 22%|██▏       | 2786/12750 [9:05:23<31:44:17, 11.47s/it] 22%|██▏       | 2787/12750 [9:05:35<31:53:22, 11.52s/it] 22%|██▏       | 2788/12750 [9:05:47<31:49:57, 11.50s/it] 22%|██▏       | 2789/12750 [9:05:58<31:47:02, 11.49s/it] 22%|██▏       | 2790/12750 [9:06:09<31:46:06, 11.48s/it] 22%|██▏       | 2791/12750 [9:06:21<31:45:32, 11.48s/it] 22%|██▏       | 2792/12750 [9:06:32<31:44:05, 11.47s/it] 22%|██▏       | 2793/12750 [9:06:44<31:42:31, 11.46s/it] 22%|██▏       | 2794/12750 [9:06:55<31:42:41, 11.47s/it] 22%|██▏       | 2795/12750 [9:07:07<31:42:47, 11.47s/it] 22%|██▏       | 2796/12750 [9:07:18<31:41:38, 11.46s/it] 22%|██▏       | 2797/12750 [9:07:30<31:40:29, 11.46s/it] 22%|██▏       | 2798/12750 [9:07:49<38:32:30, 13.94s/it] 22%|██▏       | 2799/12750 [9:08:01<36:27:44, 13.19s/it] 22%|██▏       | 2800/12750 [9:08:12<35:00:41, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120400.02lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104587.90lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2800
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2800/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2800/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2775] due to args.save_total_limit
 22%|██▏       | 2801/12750 [9:08:24<34:16:42, 12.40s/it] 22%|██▏       | 2802/12750 [9:08:36<33:29:47, 12.12s/it] 22%|██▏       | 2803/12750 [9:08:47<32:58:51, 11.94s/it] 22%|██▏       | 2804/12750 [9:08:59<32:36:04, 11.80s/it] 22%|██▏       | 2805/12750 [9:09:10<32:21:15, 11.71s/it] 22%|██▏       | 2806/12750 [9:09:22<32:11:03, 11.65s/it] 22%|██▏       | 2807/12750 [9:09:33<32:02:26, 11.60s/it] 22%|██▏       | 2808/12750 [9:09:45<31:57:41, 11.57s/it] 22%|██▏       | 2809/12750 [9:09:56<31:52:18, 11.54s/it] 22%|██▏       | 2810/12750 [9:10:07<31:49:10, 11.52s/it] 22%|██▏       | 2811/12750 [9:10:19<31:49:29, 11.53s/it] 22%|██▏       | 2812/12750 [9:10:31<31:49:39, 11.53s/it] 22%|██▏       | 2813/12750 [9:10:42<31:46:30, 11.51s/it] 22%|██▏       | 2814/12750 [9:10:54<31:45:29, 11.51s/it] 22%|██▏       | 2815/12750 [9:11:05<31:45:47, 11.51s/it] 22%|██▏       | 2816/12750 [9:11:17<31:46:00, 11.51s/it] 22%|██▏       | 2817/12750 [9:11:28<31:45:54, 11.51s/it] 22%|██▏       | 2818/12750 [9:11:40<31:42:58, 11.50s/it] 22%|██▏       | 2819/12750 [9:11:51<31:41:15, 11.49s/it] 22%|██▏       | 2820/12750 [9:12:02<31:41:40, 11.49s/it] 22%|██▏       | 2821/12750 [9:12:14<31:39:54, 11.48s/it] 22%|██▏       | 2822/12750 [9:12:25<31:39:56, 11.48s/it] 22%|██▏       | 2823/12750 [9:12:37<31:39:59, 11.48s/it] 22%|██▏       | 2824/12750 [9:12:48<31:40:50, 11.49s/it] 22%|██▏       | 2825/12750 [9:13:00<31:39:17, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120389.26lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104281.45lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2825
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2825/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2825/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2800] due to args.save_total_limit
 22%|██▏       | 2826/12750 [9:13:12<31:54:03, 11.57s/it] 22%|██▏       | 2827/12750 [9:13:23<31:49:44, 11.55s/it] 22%|██▏       | 2828/12750 [9:13:35<31:46:02, 11.53s/it] 22%|██▏       | 2829/12750 [9:13:46<31:44:04, 11.52s/it] 22%|██▏       | 2830/12750 [9:14:04<37:21:31, 13.56s/it] 22%|██▏       | 2831/12750 [9:14:16<35:38:22, 12.94s/it] 22%|██▏       | 2832/12750 [9:14:28<35:06:03, 12.74s/it] 22%|██▏       | 2833/12750 [9:14:40<34:05:19, 12.37s/it] 22%|██▏       | 2834/12750 [9:14:51<33:21:45, 12.11s/it] 22%|██▏       | 2835/12750 [9:15:03<32:50:25, 11.92s/it] 22%|██▏       | 2836/12750 [9:15:14<32:27:42, 11.79s/it] 22%|██▏       | 2837/12750 [9:15:26<32:11:41, 11.69s/it] 22%|██▏       | 2838/12750 [9:15:37<32:01:34, 11.63s/it] 22%|██▏       | 2839/12750 [9:15:49<31:55:33, 11.60s/it] 22%|██▏       | 2840/12750 [9:16:00<31:49:21, 11.56s/it] 22%|██▏       | 2841/12750 [9:16:12<31:46:02, 11.54s/it] 22%|██▏       | 2842/12750 [9:16:23<31:43:38, 11.53s/it] 22%|██▏       | 2843/12750 [9:16:35<31:38:39, 11.50s/it] 22%|██▏       | 2844/12750 [9:16:46<31:37:54, 11.50s/it] 22%|██▏       | 2845/12750 [9:16:58<31:36:07, 11.49s/it] 22%|██▏       | 2846/12750 [9:17:09<31:36:25, 11.49s/it] 22%|██▏       | 2847/12750 [9:17:20<31:35:22, 11.48s/it] 22%|██▏       | 2848/12750 [9:17:32<31:33:51, 11.48s/it] 22%|██▏       | 2849/12750 [9:17:43<31:32:21, 11.47s/it] 22%|██▏       | 2850/12750 [9:17:55<31:30:59, 11.46s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120345.64lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104568.20lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2850
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2850/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2850/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2750] due to args.save_total_limit
 22%|██▏       | 2851/12750 [9:18:07<31:46:14, 11.55s/it] 22%|██▏       | 2852/12750 [9:18:18<31:42:07, 11.53s/it] 22%|██▏       | 2853/12750 [9:18:30<31:38:20, 11.51s/it] 22%|██▏       | 2854/12750 [9:18:41<31:35:55, 11.50s/it] 22%|██▏       | 2855/12750 [9:18:52<31:35:13, 11.49s/it] 22%|██▏       | 2856/12750 [9:19:04<31:34:15, 11.49s/it] 22%|██▏       | 2857/12750 [9:19:15<31:32:25, 11.48s/it] 22%|██▏       | 2858/12750 [9:19:27<31:33:03, 11.48s/it] 22%|██▏       | 2859/12750 [9:19:38<31:34:12, 11.49s/it] 22%|██▏       | 2860/12750 [9:19:50<31:34:10, 11.49s/it] 22%|██▏       | 2861/12750 [9:20:01<31:34:50, 11.50s/it] 22%|██▏       | 2862/12750 [9:20:13<31:35:37, 11.50s/it] 22%|██▏       | 2863/12750 [9:20:32<37:44:46, 13.74s/it] 22%|██▏       | 2864/12750 [9:20:43<35:55:00, 13.08s/it] 22%|██▏       | 2865/12750 [9:20:55<34:37:18, 12.61s/it] 22%|██▏       | 2866/12750 [9:21:06<33:43:17, 12.28s/it] 22%|██▏       | 2867/12750 [9:21:18<33:04:56, 12.05s/it] 22%|██▏       | 2868/12750 [9:21:29<32:37:30, 11.89s/it] 23%|██▎       | 2869/12750 [9:21:41<32:18:22, 11.77s/it] 23%|██▎       | 2870/12750 [9:21:53<32:06:01, 11.70s/it] 23%|██▎       | 2871/12750 [9:22:04<31:55:14, 11.63s/it] 23%|██▎       | 2872/12750 [9:22:16<31:49:05, 11.60s/it] 23%|██▎       | 2873/12750 [9:22:27<31:45:47, 11.58s/it] 23%|██▎       | 2874/12750 [9:22:39<31:41:14, 11.55s/it] 23%|██▎       | 2875/12750 [9:22:50<31:39:03, 11.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120406.93lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104763.31lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2875
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2875/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2875/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2825] due to args.save_total_limit
 23%|██▎       | 2876/12750 [9:23:02<31:52:51, 11.62s/it] 23%|██▎       | 2877/12750 [9:23:13<31:45:44, 11.58s/it] 23%|██▎       | 2878/12750 [9:23:25<31:43:20, 11.57s/it] 23%|██▎       | 2879/12750 [9:23:36<31:39:19, 11.54s/it] 23%|██▎       | 2880/12750 [9:23:48<31:36:31, 11.53s/it] 23%|██▎       | 2881/12750 [9:23:59<31:34:46, 11.52s/it] 23%|██▎       | 2882/12750 [9:24:11<31:33:57, 11.52s/it] 23%|██▎       | 2883/12750 [9:24:22<31:32:17, 11.51s/it] 23%|██▎       | 2884/12750 [9:24:34<31:31:48, 11.51s/it] 23%|██▎       | 2885/12750 [9:24:45<31:30:59, 11.50s/it] 23%|██▎       | 2886/12750 [9:24:57<31:30:04, 11.50s/it] 23%|██▎       | 2887/12750 [9:25:08<31:28:58, 11.49s/it] 23%|██▎       | 2888/12750 [9:25:20<31:29:54, 11.50s/it] 23%|██▎       | 2889/12750 [9:25:31<31:27:48, 11.49s/it] 23%|██▎       | 2890/12750 [9:25:43<31:27:43, 11.49s/it] 23%|██▎       | 2891/12750 [9:25:54<31:25:20, 11.47s/it] 23%|██▎       | 2892/12750 [9:26:06<31:24:41, 11.47s/it] 23%|██▎       | 2893/12750 [9:26:17<31:25:06, 11.47s/it] 23%|██▎       | 2894/12750 [9:26:29<31:24:25, 11.47s/it] 23%|██▎       | 2895/12750 [9:26:48<37:32:14, 13.71s/it] 23%|██▎       | 2896/12750 [9:26:59<35:42:10, 13.04s/it] 23%|██▎       | 2897/12750 [9:27:11<34:23:18, 12.56s/it] 23%|██▎       | 2898/12750 [9:27:22<33:28:21, 12.23s/it] 23%|██▎       | 2899/12750 [9:27:33<32:50:20, 12.00s/it] 23%|██▎       | 2900/12750 [9:27:45<32:23:39, 11.84s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120463.41lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104752.75lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2900
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2900/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2900/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2875] due to args.save_total_limit
 23%|██▎       | 2901/12750 [9:27:57<32:19:51, 11.82s/it] 23%|██▎       | 2902/12750 [9:28:08<32:02:07, 11.71s/it] 23%|██▎       | 2903/12750 [9:28:20<31:50:04, 11.64s/it] 23%|██▎       | 2904/12750 [9:28:31<31:39:34, 11.58s/it] 23%|██▎       | 2905/12750 [9:28:42<31:32:57, 11.54s/it] 23%|██▎       | 2906/12750 [9:28:54<31:28:52, 11.51s/it] 23%|██▎       | 2907/12750 [9:29:05<31:26:15, 11.50s/it] 23%|██▎       | 2908/12750 [9:29:17<31:23:06, 11.48s/it] 23%|██▎       | 2909/12750 [9:29:28<31:21:53, 11.47s/it] 23%|██▎       | 2910/12750 [9:29:40<31:20:16, 11.47s/it] 23%|██▎       | 2911/12750 [9:29:51<31:19:52, 11.46s/it] 23%|██▎       | 2912/12750 [9:30:03<31:19:03, 11.46s/it] 23%|██▎       | 2913/12750 [9:30:14<31:18:42, 11.46s/it] 23%|██▎       | 2914/12750 [9:30:26<31:17:36, 11.45s/it] 23%|██▎       | 2915/12750 [9:30:37<31:16:46, 11.45s/it] 23%|██▎       | 2916/12750 [9:30:48<31:17:19, 11.45s/it] 23%|██▎       | 2917/12750 [9:31:00<31:16:45, 11.45s/it] 23%|██▎       | 2918/12750 [9:31:11<31:17:11, 11.46s/it] 23%|██▎       | 2919/12750 [9:31:23<31:16:35, 11.45s/it] 23%|██▎       | 2920/12750 [9:31:34<31:16:50, 11.46s/it] 23%|██▎       | 2921/12750 [9:31:46<31:17:34, 11.46s/it] 23%|██▎       | 2922/12750 [9:31:57<31:17:23, 11.46s/it] 23%|██▎       | 2923/12750 [9:32:09<31:16:20, 11.46s/it] 23%|██▎       | 2924/12750 [9:32:20<31:16:56, 11.46s/it] 23%|██▎       | 2925/12750 [9:32:32<31:17:29, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120419.22lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104781.63lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2925
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2925/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2925/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2900] due to args.save_total_limit
 23%|██▎       | 2926/12750 [9:32:43<31:39:25, 11.60s/it] 23%|██▎       | 2927/12750 [9:33:02<37:41:04, 13.81s/it] 23%|██▎       | 2928/12750 [9:33:14<35:45:22, 13.11s/it] 23%|██▎       | 2929/12750 [9:33:25<34:24:07, 12.61s/it] 23%|██▎       | 2930/12750 [9:33:37<33:27:34, 12.27s/it] 23%|██▎       | 2931/12750 [9:33:48<32:49:59, 12.04s/it] 23%|██▎       | 2932/12750 [9:34:00<32:22:28, 11.87s/it] 23%|██▎       | 2933/12750 [9:34:11<32:02:23, 11.75s/it] 23%|██▎       | 2934/12750 [9:34:23<31:48:42, 11.67s/it] 23%|██▎       | 2935/12750 [9:34:34<31:40:07, 11.62s/it] 23%|██▎       | 2936/12750 [9:34:46<31:32:13, 11.57s/it] 23%|██▎       | 2937/12750 [9:34:57<31:26:49, 11.54s/it] 23%|██▎       | 2938/12750 [9:35:09<31:23:02, 11.51s/it] 23%|██▎       | 2939/12750 [9:35:20<31:26:34, 11.54s/it] 23%|██▎       | 2940/12750 [9:35:32<31:22:09, 11.51s/it] 23%|██▎       | 2941/12750 [9:35:43<31:19:10, 11.49s/it] 23%|██▎       | 2942/12750 [9:35:55<31:16:54, 11.48s/it] 23%|██▎       | 2943/12750 [9:36:06<31:16:07, 11.48s/it] 23%|██▎       | 2944/12750 [9:36:18<31:15:00, 11.47s/it] 23%|██▎       | 2945/12750 [9:36:29<31:13:44, 11.47s/it] 23%|██▎       | 2946/12750 [9:36:40<31:13:51, 11.47s/it] 23%|██▎       | 2947/12750 [9:36:52<31:13:55, 11.47s/it] 23%|██▎       | 2948/12750 [9:37:03<31:11:07, 11.45s/it] 23%|██▎       | 2949/12750 [9:37:15<31:12:29, 11.46s/it] 23%|██▎       | 2950/12750 [9:37:26<31:12:10, 11.46s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120331.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104702.58lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2950
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2950/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2950/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2925] due to args.save_total_limit
 23%|██▎       | 2951/12750 [9:37:38<31:25:58, 11.55s/it] 23%|██▎       | 2952/12750 [9:37:49<31:21:19, 11.52s/it] 23%|██▎       | 2953/12750 [9:38:01<31:17:50, 11.50s/it] 23%|██▎       | 2954/12750 [9:38:12<31:16:08, 11.49s/it] 23%|██▎       | 2955/12750 [9:38:24<31:11:55, 11.47s/it] 23%|██▎       | 2956/12750 [9:38:35<31:11:11, 11.46s/it] 23%|██▎       | 2957/12750 [9:38:47<31:10:21, 11.46s/it] 23%|██▎       | 2958/12750 [9:38:58<31:10:10, 11.46s/it] 23%|██▎       | 2959/12750 [9:39:17<37:21:16, 13.73s/it] 23%|██▎       | 2960/12750 [9:39:29<35:28:46, 13.05s/it] 23%|██▎       | 2961/12750 [9:39:40<34:09:10, 12.56s/it] 23%|██▎       | 2962/12750 [9:39:52<33:14:55, 12.23s/it] 23%|██▎       | 2963/12750 [9:40:03<32:36:48, 12.00s/it] 23%|██▎       | 2964/12750 [9:40:14<32:10:31, 11.84s/it] 23%|██▎       | 2965/12750 [9:40:26<31:50:43, 11.72s/it] 23%|██▎       | 2966/12750 [9:40:37<31:36:34, 11.63s/it] 23%|██▎       | 2967/12750 [9:40:49<31:27:42, 11.58s/it] 23%|██▎       | 2968/12750 [9:41:00<31:20:58, 11.54s/it] 23%|██▎       | 2969/12750 [9:41:12<31:17:10, 11.52s/it] 23%|██▎       | 2970/12750 [9:41:23<31:13:20, 11.49s/it] 23%|██▎       | 2971/12750 [9:41:35<31:13:19, 11.49s/it] 23%|██▎       | 2972/12750 [9:41:46<31:10:46, 11.48s/it] 23%|██▎       | 2973/12750 [9:41:58<31:07:42, 11.46s/it] 23%|██▎       | 2974/12750 [9:42:09<31:07:40, 11.46s/it] 23%|██▎       | 2975/12750 [9:42:20<31:05:50, 11.45s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120521.62lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104895.96lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2975
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2975/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2975/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-2975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2950] due to args.save_total_limit
 23%|██▎       | 2976/12750 [9:42:32<31:21:21, 11.55s/it] 23%|██▎       | 2977/12750 [9:42:44<31:16:11, 11.52s/it] 23%|██▎       | 2978/12750 [9:42:55<31:13:19, 11.50s/it] 23%|██▎       | 2979/12750 [9:43:07<31:10:02, 11.48s/it] 23%|██▎       | 2980/12750 [9:43:18<31:09:16, 11.48s/it] 23%|██▎       | 2981/12750 [9:43:29<31:08:55, 11.48s/it] 23%|██▎       | 2982/12750 [9:43:41<31:08:30, 11.48s/it] 23%|██▎       | 2983/12750 [9:43:52<31:06:49, 11.47s/it] 23%|██▎       | 2984/12750 [9:44:04<31:03:51, 11.45s/it] 23%|██▎       | 2985/12750 [9:44:15<31:02:26, 11.44s/it] 23%|██▎       | 2986/12750 [9:44:27<31:02:12, 11.44s/it] 23%|██▎       | 2987/12750 [9:44:38<31:02:28, 11.45s/it] 23%|██▎       | 2988/12750 [9:44:50<31:03:01, 11.45s/it] 23%|██▎       | 2989/12750 [9:45:01<31:03:15, 11.45s/it] 23%|██▎       | 2990/12750 [9:45:12<31:02:21, 11.45s/it] 23%|██▎       | 2991/12750 [9:45:31<36:27:22, 13.45s/it] 23%|██▎       | 2992/12750 [9:45:42<34:50:45, 12.86s/it] 23%|██▎       | 2993/12750 [9:45:54<33:43:27, 12.44s/it] 23%|██▎       | 2994/12750 [9:46:05<32:53:18, 12.14s/it] 23%|██▎       | 2995/12750 [9:46:16<32:18:59, 11.93s/it] 23%|██▎       | 2996/12750 [9:46:28<31:55:11, 11.78s/it] 24%|██▎       | 2997/12750 [9:46:39<31:38:47, 11.68s/it] 24%|██▎       | 2998/12750 [9:46:51<31:27:25, 11.61s/it] 24%|██▎       | 2999/12750 [9:47:02<31:21:06, 11.57s/it] 24%|██▎       | 3000/12750 [9:47:14<31:16:03, 11.54s/it]                                                          24%|██▎       | 3000/12750 [9:47:14<31:16:03, 11.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120546.12lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104722.33lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3000
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3000/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3000/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2975] due to args.save_total_limit
 24%|██▎       | 3001/12750 [9:47:26<31:35:16, 11.66s/it] 24%|██▎       | 3002/12750 [9:47:37<31:30:04, 11.63s/it] 24%|██▎       | 3003/12750 [9:47:49<31:27:08, 11.62s/it] 24%|██▎       | 3004/12750 [9:48:00<31:24:56, 11.60s/it] 24%|██▎       | 3005/12750 [9:48:12<31:23:42, 11.60s/it] 24%|██▎       | 3006/12750 [9:48:24<31:22:39, 11.59s/it] 24%|██▎       | 3007/12750 [9:48:35<31:20:46, 11.58s/it] 24%|██▎       | 3008/12750 [9:48:47<31:20:12, 11.58s/it] 24%|██▎       | 3009/12750 [9:48:58<31:19:17, 11.58s/it] 24%|██▎       | 3010/12750 [9:49:10<31:19:57, 11.58s/it] 24%|██▎       | 3011/12750 [9:49:21<31:19:14, 11.58s/it] 24%|██▎       | 3012/12750 [9:49:33<31:17:58, 11.57s/it] 24%|██▎       | 3013/12750 [9:49:44<31:16:25, 11.56s/it] 24%|██▎       | 3014/12750 [9:49:56<31:17:07, 11.57s/it] 24%|██▎       | 3015/12750 [9:50:08<31:16:32, 11.57s/it] 24%|██▎       | 3016/12750 [9:50:19<31:15:01, 11.56s/it] 24%|██▎       | 3017/12750 [9:50:31<31:16:18, 11.57s/it] 24%|██▎       | 3018/12750 [9:50:42<31:15:13, 11.56s/it] 24%|██▎       | 3019/12750 [9:50:54<31:15:21, 11.56s/it] 24%|██▎       | 3020/12750 [9:51:05<31:17:18, 11.58s/it] 24%|██▎       | 3021/12750 [9:51:17<31:15:56, 11.57s/it] 24%|██▎       | 3022/12750 [9:51:29<31:14:30, 11.56s/it] 24%|██▎       | 3023/12750 [9:51:48<37:24:06, 13.84s/it] 24%|██▎       | 3024/12750 [9:51:59<35:31:55, 13.15s/it] 24%|██▎       | 3025/12750 [9:52:11<34:12:30, 12.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120368.02lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104726.50lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3025
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3025/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3025/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-2850] due to args.save_total_limit
 24%|██▎       | 3026/12750 [9:52:23<33:35:11, 12.43s/it] 24%|██▎       | 3027/12750 [9:52:34<32:52:23, 12.17s/it] 24%|██▎       | 3028/12750 [9:52:46<32:22:20, 11.99s/it] 24%|██▍       | 3029/12750 [9:52:57<32:00:08, 11.85s/it] 24%|██▍       | 3030/12750 [9:53:09<31:45:46, 11.76s/it] 24%|██▍       | 3031/12750 [9:53:21<31:36:49, 11.71s/it] 24%|██▍       | 3032/12750 [9:53:32<31:29:26, 11.67s/it] 24%|██▍       | 3033/12750 [9:53:44<31:24:26, 11.64s/it] 24%|██▍       | 3034/12750 [9:53:55<31:20:40, 11.61s/it] 24%|██▍       | 3035/12750 [9:54:07<31:16:23, 11.59s/it] 24%|██▍       | 3036/12750 [9:54:18<31:14:59, 11.58s/it] 24%|██▍       | 3037/12750 [9:54:30<31:15:14, 11.58s/it] 24%|██▍       | 3038/12750 [9:54:41<31:13:26, 11.57s/it] 24%|██▍       | 3039/12750 [9:54:53<31:12:37, 11.57s/it] 24%|██▍       | 3040/12750 [9:55:05<31:10:14, 11.56s/it] 24%|██▍       | 3041/12750 [9:55:16<31:11:36, 11.57s/it] 24%|██▍       | 3042/12750 [9:55:28<31:09:34, 11.55s/it] 24%|██▍       | 3043/12750 [9:55:39<31:08:36, 11.55s/it] 24%|██▍       | 3044/12750 [9:55:51<31:07:10, 11.54s/it] 24%|██▍       | 3045/12750 [9:56:02<31:06:21, 11.54s/it] 24%|██▍       | 3046/12750 [9:56:14<31:07:41, 11.55s/it] 24%|██▍       | 3047/12750 [9:56:25<31:08:25, 11.55s/it] 24%|██▍       | 3048/12750 [9:56:37<31:07:40, 11.55s/it] 24%|██▍       | 3049/12750 [9:56:48<31:07:21, 11.55s/it] 24%|██▍       | 3050/12750 [9:57:00<31:08:05, 11.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120329.78lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104678.00lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3050
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3050/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3050/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3000] due to args.save_total_limit
 24%|██▍       | 3051/12750 [9:57:12<31:22:49, 11.65s/it] 24%|██▍       | 3052/12750 [9:57:23<31:16:27, 11.61s/it] 24%|██▍       | 3053/12750 [9:57:35<31:14:41, 11.60s/it] 24%|██▍       | 3054/12750 [9:57:47<31:12:01, 11.58s/it] 24%|██▍       | 3055/12750 [9:57:58<31:11:38, 11.58s/it] 24%|██▍       | 3056/12750 [9:58:17<36:53:58, 13.70s/it] 24%|██▍       | 3057/12750 [9:58:28<35:12:19, 13.08s/it] 24%|██▍       | 3058/12750 [9:58:40<34:01:02, 12.64s/it] 24%|██▍       | 3059/12750 [9:58:47<29:31:58, 10.97s/it] 24%|██▍       | 3060/12750 [9:58:48<21:18:32,  7.92s/it] 24%|██▍       | 3061/12750 [9:59:11<33:50:36, 12.57s/it] 24%|██▍       | 3062/12750 [9:59:23<32:59:28, 12.26s/it] 24%|██▍       | 3063/12750 [9:59:34<32:21:13, 12.02s/it] 24%|██▍       | 3064/12750 [9:59:46<31:56:17, 11.87s/it] 24%|██▍       | 3065/12750 [9:59:57<31:37:50, 11.76s/it] 24%|██▍       | 3066/12750 [10:00:09<31:25:51, 11.68s/it] 24%|██▍       | 3067/12750 [10:00:20<31:17:06, 11.63s/it] 24%|██▍       | 3068/12750 [10:00:32<31:09:08, 11.58s/it] 24%|██▍       | 3069/12750 [10:00:43<31:04:40, 11.56s/it] 24%|██▍       | 3070/12750 [10:00:55<31:02:58, 11.55s/it] 24%|██▍       | 3071/12750 [10:01:06<30:59:17, 11.53s/it] 24%|██▍       | 3072/12750 [10:01:18<30:58:49, 11.52s/it] 24%|██▍       | 3073/12750 [10:01:29<30:58:29, 11.52s/it] 24%|██▍       | 3074/12750 [10:01:41<30:57:30, 11.52s/it] 24%|██▍       | 3075/12750 [10:01:52<30:56:04, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120384.40lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104529.78lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3075
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3075/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3075/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3050] due to args.save_total_limit
 24%|██▍       | 3076/12750 [10:02:04<31:08:47, 11.59s/it] 24%|██▍       | 3077/12750 [10:02:16<31:03:24, 11.56s/it] 24%|██▍       | 3078/12750 [10:02:27<30:59:37, 11.54s/it] 24%|██▍       | 3079/12750 [10:02:39<30:57:52, 11.53s/it] 24%|██▍       | 3080/12750 [10:02:50<30:54:57, 11.51s/it] 24%|██▍       | 3081/12750 [10:03:01<30:51:44, 11.49s/it] 24%|██▍       | 3082/12750 [10:03:13<30:51:07, 11.49s/it] 24%|██▍       | 3083/12750 [10:03:24<30:51:01, 11.49s/it] 24%|██▍       | 3084/12750 [10:03:36<30:50:26, 11.49s/it] 24%|██▍       | 3085/12750 [10:03:47<30:50:30, 11.49s/it] 24%|██▍       | 3086/12750 [10:03:59<30:48:41, 11.48s/it] 24%|██▍       | 3087/12750 [10:04:10<30:48:12, 11.48s/it] 24%|██▍       | 3088/12750 [10:04:29<36:56:20, 13.76s/it] 24%|██▍       | 3089/12750 [10:04:41<35:06:15, 13.08s/it] 24%|██▍       | 3090/12750 [10:04:52<33:50:10, 12.61s/it] 24%|██▍       | 3091/12750 [10:05:04<32:55:36, 12.27s/it] 24%|██▍       | 3092/12750 [10:05:15<32:17:23, 12.04s/it] 24%|██▍       | 3093/12750 [10:05:27<31:51:10, 11.87s/it] 24%|██▍       | 3094/12750 [10:05:38<31:33:36, 11.77s/it] 24%|██▍       | 3095/12750 [10:05:50<31:21:03, 11.69s/it] 24%|██▍       | 3096/12750 [10:06:01<31:10:31, 11.63s/it] 24%|██▍       | 3097/12750 [10:06:13<31:03:48, 11.58s/it] 24%|██▍       | 3098/12750 [10:06:24<30:59:04, 11.56s/it] 24%|██▍       | 3099/12750 [10:06:36<30:54:27, 11.53s/it] 24%|██▍       | 3100/12750 [10:06:47<30:52:03, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120401.94lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104739.96lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3100
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3100/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3100/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3025] due to args.save_total_limit
 24%|██▍       | 3101/12750 [10:06:59<31:04:57, 11.60s/it] 24%|██▍       | 3102/12750 [10:07:11<30:57:21, 11.55s/it] 24%|██▍       | 3103/12750 [10:07:22<30:54:23, 11.53s/it] 24%|██▍       | 3104/12750 [10:07:34<30:51:19, 11.52s/it] 24%|██▍       | 3105/12750 [10:07:45<30:50:41, 11.51s/it] 24%|██▍       | 3106/12750 [10:07:57<30:49:27, 11.51s/it] 24%|██▍       | 3107/12750 [10:08:08<30:47:24, 11.49s/it] 24%|██▍       | 3108/12750 [10:08:19<30:45:54, 11.49s/it] 24%|██▍       | 3109/12750 [10:08:31<30:44:58, 11.48s/it] 24%|██▍       | 3110/12750 [10:08:42<30:45:45, 11.49s/it] 24%|██▍       | 3111/12750 [10:08:54<30:46:09, 11.49s/it] 24%|██▍       | 3112/12750 [10:09:05<30:47:28, 11.50s/it] 24%|██▍       | 3113/12750 [10:09:17<30:46:19, 11.50s/it] 24%|██▍       | 3114/12750 [10:09:28<30:46:16, 11.50s/it] 24%|██▍       | 3115/12750 [10:09:40<30:47:00, 11.50s/it] 24%|██▍       | 3116/12750 [10:09:51<30:45:49, 11.50s/it] 24%|██▍       | 3117/12750 [10:10:03<30:45:20, 11.49s/it] 24%|██▍       | 3118/12750 [10:10:14<30:45:02, 11.49s/it] 24%|██▍       | 3119/12750 [10:10:26<30:43:46, 11.49s/it] 24%|██▍       | 3120/12750 [10:10:45<36:42:56, 13.73s/it] 24%|██▍       | 3121/12750 [10:10:56<34:54:07, 13.05s/it] 24%|██▍       | 3122/12750 [10:11:08<33:37:48, 12.57s/it] 24%|██▍       | 3123/12750 [10:11:19<32:44:54, 12.25s/it] 25%|██▍       | 3124/12750 [10:11:31<32:08:27, 12.02s/it] 25%|██▍       | 3125/12750 [10:11:42<31:40:55, 11.85s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120389.52lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104714.88lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3125
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3125/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3125/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3075] due to args.save_total_limit
 25%|██▍       | 3126/12750 [10:11:54<31:37:19, 11.83s/it] 25%|██▍       | 3127/12750 [10:12:05<31:19:56, 11.72s/it] 25%|██▍       | 3128/12750 [10:12:17<31:07:47, 11.65s/it] 25%|██▍       | 3129/12750 [10:12:28<30:59:30, 11.60s/it] 25%|██▍       | 3130/12750 [10:12:40<30:53:48, 11.56s/it] 25%|██▍       | 3131/12750 [10:12:51<30:48:11, 11.53s/it] 25%|██▍       | 3132/12750 [10:13:03<30:45:04, 11.51s/it] 25%|██▍       | 3133/12750 [10:13:14<30:44:06, 11.51s/it] 25%|██▍       | 3134/12750 [10:13:26<30:41:44, 11.49s/it] 25%|██▍       | 3135/12750 [10:13:37<30:39:39, 11.48s/it] 25%|██▍       | 3136/12750 [10:13:49<30:39:20, 11.48s/it] 25%|██▍       | 3137/12750 [10:14:00<30:38:09, 11.47s/it] 25%|██▍       | 3138/12750 [10:14:12<30:37:55, 11.47s/it] 25%|██▍       | 3139/12750 [10:14:23<30:37:08, 11.47s/it] 25%|██▍       | 3140/12750 [10:14:35<30:36:41, 11.47s/it] 25%|██▍       | 3141/12750 [10:14:46<30:36:42, 11.47s/it] 25%|██▍       | 3142/12750 [10:14:58<30:38:49, 11.48s/it] 25%|██▍       | 3143/12750 [10:15:09<30:36:07, 11.47s/it] 25%|██▍       | 3144/12750 [10:15:20<30:35:11, 11.46s/it] 25%|██▍       | 3145/12750 [10:15:32<30:39:24, 11.49s/it] 25%|██▍       | 3146/12750 [10:15:43<30:37:44, 11.48s/it] 25%|██▍       | 3147/12750 [10:15:55<30:34:15, 11.46s/it] 25%|██▍       | 3148/12750 [10:16:06<30:34:25, 11.46s/it] 25%|██▍       | 3149/12750 [10:16:18<30:34:27, 11.46s/it] 25%|██▍       | 3150/12750 [10:16:29<30:34:08, 11.46s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120417.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104715.07lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3150
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3150/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3150/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3100] due to args.save_total_limit
 25%|██▍       | 3151/12750 [10:16:41<30:48:28, 11.55s/it] 25%|██▍       | 3152/12750 [10:16:52<30:43:32, 11.52s/it] 25%|██▍       | 3153/12750 [10:17:13<37:35:47, 14.10s/it] 25%|██▍       | 3154/12750 [10:17:24<35:27:43, 13.30s/it] 25%|██▍       | 3155/12750 [10:17:36<34:04:35, 12.79s/it] 25%|██▍       | 3156/12750 [10:17:47<33:05:18, 12.42s/it] 25%|██▍       | 3157/12750 [10:17:59<32:24:18, 12.16s/it] 25%|██▍       | 3158/12750 [10:18:10<31:53:51, 11.97s/it] 25%|██▍       | 3159/12750 [10:18:22<31:33:09, 11.84s/it] 25%|██▍       | 3160/12750 [10:18:33<31:18:32, 11.75s/it] 25%|██▍       | 3161/12750 [10:18:45<31:09:58, 11.70s/it] 25%|██▍       | 3162/12750 [10:18:57<31:10:02, 11.70s/it] 25%|██▍       | 3163/12750 [10:19:08<31:05:22, 11.67s/it] 25%|██▍       | 3164/12750 [10:19:20<31:01:17, 11.65s/it] 25%|██▍       | 3165/12750 [10:19:31<30:55:33, 11.62s/it] 25%|██▍       | 3166/12750 [10:19:43<30:53:00, 11.60s/it] 25%|██▍       | 3167/12750 [10:19:54<30:49:48, 11.58s/it] 25%|██▍       | 3168/12750 [10:20:06<30:50:04, 11.58s/it] 25%|██▍       | 3169/12750 [10:20:18<30:49:24, 11.58s/it] 25%|██▍       | 3170/12750 [10:20:29<30:47:33, 11.57s/it] 25%|██▍       | 3171/12750 [10:20:41<30:48:11, 11.58s/it] 25%|██▍       | 3172/12750 [10:20:52<30:48:20, 11.58s/it] 25%|██▍       | 3173/12750 [10:21:04<30:47:12, 11.57s/it] 25%|██▍       | 3174/12750 [10:21:15<30:45:48, 11.57s/it] 25%|██▍       | 3175/12750 [10:21:27<30:47:17, 11.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120251.46lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 100787.20lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3175
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3175/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3175/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3125] due to args.save_total_limit
 25%|██▍       | 3176/12750 [10:21:39<31:09:12, 11.71s/it] 25%|██▍       | 3177/12750 [10:21:51<30:58:54, 11.65s/it] 25%|██▍       | 3178/12750 [10:22:02<30:52:01, 11.61s/it] 25%|██▍       | 3179/12750 [10:22:14<30:45:48, 11.57s/it] 25%|██▍       | 3180/12750 [10:22:25<30:42:04, 11.55s/it] 25%|██▍       | 3181/12750 [10:22:37<30:38:36, 11.53s/it] 25%|██▍       | 3182/12750 [10:22:48<30:35:52, 11.51s/it] 25%|██▍       | 3183/12750 [10:23:00<30:33:43, 11.50s/it] 25%|██▍       | 3184/12750 [10:23:11<30:32:15, 11.49s/it] 25%|██▍       | 3185/12750 [10:23:30<36:34:21, 13.76s/it] 25%|██▍       | 3186/12750 [10:23:42<34:43:23, 13.07s/it] 25%|██▍       | 3187/12750 [10:23:53<33:29:21, 12.61s/it] 25%|██▌       | 3188/12750 [10:24:05<32:35:06, 12.27s/it] 25%|██▌       | 3189/12750 [10:24:16<31:59:34, 12.05s/it] 25%|██▌       | 3190/12750 [10:24:28<31:32:05, 11.88s/it] 25%|██▌       | 3191/12750 [10:24:39<31:13:03, 11.76s/it] 25%|██▌       | 3192/12750 [10:24:51<31:00:56, 11.68s/it] 25%|██▌       | 3193/12750 [10:25:02<30:52:49, 11.63s/it] 25%|██▌       | 3194/12750 [10:25:14<30:46:58, 11.60s/it] 25%|██▌       | 3195/12750 [10:25:25<30:44:35, 11.58s/it] 25%|██▌       | 3196/12750 [10:25:37<30:40:17, 11.56s/it] 25%|██▌       | 3197/12750 [10:25:48<30:39:41, 11.55s/it] 25%|██▌       | 3198/12750 [10:26:00<30:37:04, 11.54s/it] 25%|██▌       | 3199/12750 [10:26:11<30:34:11, 11.52s/it] 25%|██▌       | 3200/12750 [10:26:23<30:34:35, 11.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120496.99lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104821.40lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3200
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3200/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3200/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3150] due to args.save_total_limit
 25%|██▌       | 3201/12750 [10:26:35<30:50:26, 11.63s/it] 25%|██▌       | 3202/12750 [10:26:46<30:44:21, 11.59s/it] 25%|██▌       | 3203/12750 [10:26:58<30:41:12, 11.57s/it] 25%|██▌       | 3204/12750 [10:27:09<30:36:28, 11.54s/it] 25%|██▌       | 3205/12750 [10:27:21<30:34:50, 11.53s/it] 25%|██▌       | 3206/12750 [10:27:32<30:32:53, 11.52s/it] 25%|██▌       | 3207/12750 [10:27:44<30:33:39, 11.53s/it] 25%|██▌       | 3208/12750 [10:27:55<30:33:16, 11.53s/it] 25%|██▌       | 3209/12750 [10:28:07<30:32:20, 11.52s/it] 25%|██▌       | 3210/12750 [10:28:18<30:31:01, 11.52s/it] 25%|██▌       | 3211/12750 [10:28:30<30:29:57, 11.51s/it] 25%|██▌       | 3212/12750 [10:28:41<30:28:44, 11.50s/it] 25%|██▌       | 3213/12750 [10:28:53<30:30:05, 11.51s/it] 25%|██▌       | 3214/12750 [10:29:04<30:28:00, 11.50s/it] 25%|██▌       | 3215/12750 [10:29:16<30:29:40, 11.51s/it] 25%|██▌       | 3216/12750 [10:29:27<30:27:23, 11.50s/it] 25%|██▌       | 3217/12750 [10:29:46<36:24:39, 13.75s/it] 25%|██▌       | 3218/12750 [10:29:58<34:39:17, 13.09s/it] 25%|██▌       | 3219/12750 [10:30:09<33:24:20, 12.62s/it] 25%|██▌       | 3220/12750 [10:30:21<32:31:59, 12.29s/it] 25%|██▌       | 3221/12750 [10:30:32<31:55:21, 12.06s/it] 25%|██▌       | 3222/12750 [10:30:44<31:28:47, 11.89s/it] 25%|██▌       | 3223/12750 [10:30:55<31:09:36, 11.77s/it] 25%|██▌       | 3224/12750 [10:31:07<30:56:56, 11.70s/it] 25%|██▌       | 3225/12750 [10:31:18<30:48:41, 11.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120375.83lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104689.13lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3225
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3225/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3225/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3175] due to args.save_total_limit
 25%|██▌       | 3226/12750 [10:31:30<30:59:32, 11.71s/it] 25%|██▌       | 3227/12750 [10:31:42<30:50:05, 11.66s/it] 25%|██▌       | 3228/12750 [10:31:53<30:44:24, 11.62s/it] 25%|██▌       | 3229/12750 [10:32:05<30:39:36, 11.59s/it] 25%|██▌       | 3230/12750 [10:32:16<30:37:09, 11.58s/it] 25%|██▌       | 3231/12750 [10:32:28<30:33:31, 11.56s/it] 25%|██▌       | 3232/12750 [10:32:39<30:29:42, 11.53s/it] 25%|██▌       | 3233/12750 [10:32:51<30:28:22, 11.53s/it] 25%|██▌       | 3234/12750 [10:33:02<30:27:47, 11.52s/it] 25%|██▌       | 3235/12750 [10:33:14<30:25:57, 11.51s/it] 25%|██▌       | 3236/12750 [10:33:25<30:23:48, 11.50s/it] 25%|██▌       | 3237/12750 [10:33:37<30:23:09, 11.50s/it] 25%|██▌       | 3238/12750 [10:33:48<30:22:34, 11.50s/it] 25%|██▌       | 3239/12750 [10:34:00<30:20:49, 11.49s/it] 25%|██▌       | 3240/12750 [10:34:11<30:19:37, 11.48s/it] 25%|██▌       | 3241/12750 [10:34:23<30:20:01, 11.48s/it] 25%|██▌       | 3242/12750 [10:34:34<30:19:03, 11.48s/it] 25%|██▌       | 3243/12750 [10:34:46<30:18:46, 11.48s/it] 25%|██▌       | 3244/12750 [10:34:57<30:19:36, 11.49s/it] 25%|██▌       | 3245/12750 [10:35:09<30:19:41, 11.49s/it] 25%|██▌       | 3246/12750 [10:35:20<30:18:27, 11.48s/it] 25%|██▌       | 3247/12750 [10:35:32<30:18:18, 11.48s/it] 25%|██▌       | 3248/12750 [10:35:43<30:18:16, 11.48s/it] 25%|██▌       | 3249/12750 [10:36:02<36:16:18, 13.74s/it] 25%|██▌       | 3250/12750 [10:36:14<34:28:19, 13.06s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120395.66lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104745.48lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3250
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3250/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3250/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3200] due to args.save_total_limit
 25%|██▌       | 3251/12750 [10:36:25<33:29:19, 12.69s/it] 26%|██▌       | 3252/12750 [10:36:37<32:29:56, 12.32s/it] 26%|██▌       | 3253/12750 [10:36:48<31:48:07, 12.06s/it] 26%|██▌       | 3254/12750 [10:37:00<31:19:11, 11.87s/it] 26%|██▌       | 3255/12750 [10:37:11<31:01:34, 11.76s/it] 26%|██▌       | 3256/12750 [10:37:23<30:47:23, 11.68s/it] 26%|██▌       | 3257/12750 [10:37:34<30:40:31, 11.63s/it] 26%|██▌       | 3258/12750 [10:37:46<30:35:31, 11.60s/it] 26%|██▌       | 3259/12750 [10:37:57<30:30:43, 11.57s/it] 26%|██▌       | 3260/12750 [10:38:09<30:25:52, 11.54s/it] 26%|██▌       | 3261/12750 [10:38:20<30:22:32, 11.52s/it] 26%|██▌       | 3262/12750 [10:38:32<30:19:35, 11.51s/it] 26%|██▌       | 3263/12750 [10:38:43<30:17:22, 11.49s/it] 26%|██▌       | 3264/12750 [10:38:55<30:18:04, 11.50s/it] 26%|██▌       | 3265/12750 [10:39:06<30:18:50, 11.51s/it] 26%|██▌       | 3266/12750 [10:39:18<30:18:26, 11.50s/it] 26%|██▌       | 3267/12750 [10:39:29<30:16:53, 11.50s/it] 26%|██▌       | 3268/12750 [10:39:41<30:14:47, 11.48s/it] 26%|██▌       | 3269/12750 [10:39:52<30:14:46, 11.48s/it] 26%|██▌       | 3270/12750 [10:40:04<30:13:51, 11.48s/it] 26%|██▌       | 3271/12750 [10:40:15<30:13:27, 11.48s/it] 26%|██▌       | 3272/12750 [10:40:27<30:13:02, 11.48s/it] 26%|██▌       | 3273/12750 [10:40:38<30:12:20, 11.47s/it] 26%|██▌       | 3274/12750 [10:40:49<30:12:18, 11.48s/it] 26%|██▌       | 3275/12750 [10:41:01<30:12:30, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120386.96lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104655.46lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3275
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3275/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3275/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3250] due to args.save_total_limit
 26%|██▌       | 3276/12750 [10:41:13<30:26:55, 11.57s/it] 26%|██▌       | 3277/12750 [10:41:24<30:21:41, 11.54s/it] 26%|██▌       | 3278/12750 [10:41:36<30:17:36, 11.51s/it] 26%|██▌       | 3279/12750 [10:41:47<30:15:44, 11.50s/it] 26%|██▌       | 3280/12750 [10:41:59<30:13:15, 11.49s/it] 26%|██▌       | 3281/12750 [10:42:18<36:07:55, 13.74s/it] 26%|██▌       | 3282/12750 [10:42:29<34:20:03, 13.05s/it] 26%|██▌       | 3283/12750 [10:42:41<33:05:34, 12.58s/it] 26%|██▌       | 3284/12750 [10:42:52<32:12:22, 12.25s/it] 26%|██▌       | 3285/12750 [10:43:03<31:35:00, 12.01s/it] 26%|██▌       | 3286/12750 [10:43:15<31:08:37, 11.85s/it] 26%|██▌       | 3287/12750 [10:43:26<30:51:09, 11.74s/it] 26%|██▌       | 3288/12750 [10:43:38<30:36:46, 11.65s/it] 26%|██▌       | 3289/12750 [10:43:49<30:29:22, 11.60s/it] 26%|██▌       | 3290/12750 [10:44:01<30:24:45, 11.57s/it] 26%|██▌       | 3291/12750 [10:44:12<30:21:12, 11.55s/it] 26%|██▌       | 3292/12750 [10:44:24<30:17:40, 11.53s/it] 26%|██▌       | 3293/12750 [10:44:35<30:13:30, 11.51s/it] 26%|██▌       | 3294/12750 [10:44:47<30:11:47, 11.50s/it] 26%|██▌       | 3295/12750 [10:44:58<30:10:11, 11.49s/it] 26%|██▌       | 3296/12750 [10:45:10<30:09:44, 11.49s/it] 26%|██▌       | 3297/12750 [10:45:21<30:10:26, 11.49s/it] 26%|██▌       | 3298/12750 [10:45:33<30:08:39, 11.48s/it] 26%|██▌       | 3299/12750 [10:45:44<30:09:17, 11.49s/it] 26%|██▌       | 3300/12750 [10:45:56<30:09:50, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120334.77lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104697.74lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3300
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3300/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3300/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3275] due to args.save_total_limit
 26%|██▌       | 3301/12750 [10:46:07<30:23:50, 11.58s/it] 26%|██▌       | 3302/12750 [10:46:19<30:19:46, 11.56s/it] 26%|██▌       | 3303/12750 [10:46:30<30:16:38, 11.54s/it] 26%|██▌       | 3304/12750 [10:46:42<30:14:36, 11.53s/it] 26%|██▌       | 3305/12750 [10:46:53<30:12:09, 11.51s/it] 26%|██▌       | 3306/12750 [10:47:05<30:10:18, 11.50s/it] 26%|██▌       | 3307/12750 [10:47:16<30:09:49, 11.50s/it] 26%|██▌       | 3308/12750 [10:47:28<30:09:17, 11.50s/it] 26%|██▌       | 3309/12750 [10:47:39<30:09:22, 11.50s/it] 26%|██▌       | 3310/12750 [10:47:51<30:07:11, 11.49s/it] 26%|██▌       | 3311/12750 [10:48:02<30:08:15, 11.49s/it] 26%|██▌       | 3312/12750 [10:48:14<30:08:09, 11.50s/it] 26%|██▌       | 3313/12750 [10:48:33<36:02:39, 13.75s/it] 26%|██▌       | 3314/12750 [10:48:44<34:17:54, 13.09s/it] 26%|██▌       | 3315/12750 [10:48:56<33:02:01, 12.60s/it] 26%|██▌       | 3316/12750 [10:49:07<32:10:10, 12.28s/it] 26%|██▌       | 3317/12750 [10:49:19<31:33:02, 12.04s/it] 26%|██▌       | 3318/12750 [10:49:30<31:08:47, 11.89s/it] 26%|██▌       | 3319/12750 [10:49:42<30:49:17, 11.77s/it] 26%|██▌       | 3320/12750 [10:49:53<30:34:39, 11.67s/it] 26%|██▌       | 3321/12750 [10:50:05<30:26:21, 11.62s/it] 26%|██▌       | 3322/12750 [10:50:16<30:20:22, 11.58s/it] 26%|██▌       | 3323/12750 [10:50:28<30:17:04, 11.57s/it] 26%|██▌       | 3324/12750 [10:50:39<30:12:29, 11.54s/it] 26%|██▌       | 3325/12750 [10:50:51<30:10:04, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120411.03lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104764.28lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3325
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3325/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3325/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3300] due to args.save_total_limit
 26%|██▌       | 3326/12750 [10:51:03<30:22:35, 11.60s/it] 26%|██▌       | 3327/12750 [10:51:14<30:16:07, 11.56s/it] 26%|██▌       | 3328/12750 [10:51:26<30:13:18, 11.55s/it] 26%|██▌       | 3329/12750 [10:51:37<30:09:52, 11.53s/it] 26%|██▌       | 3330/12750 [10:51:49<30:08:00, 11.52s/it] 26%|██▌       | 3331/12750 [10:52:00<30:06:27, 11.51s/it] 26%|██▌       | 3332/12750 [10:52:12<30:06:17, 11.51s/it] 26%|██▌       | 3333/12750 [10:52:24<30:29:09, 11.65s/it] 26%|██▌       | 3334/12750 [10:52:35<30:24:11, 11.62s/it] 26%|██▌       | 3335/12750 [10:52:47<30:17:50, 11.58s/it] 26%|██▌       | 3336/12750 [10:52:58<30:12:58, 11.55s/it] 26%|██▌       | 3337/12750 [10:53:10<30:09:09, 11.53s/it] 26%|██▌       | 3338/12750 [10:53:21<30:07:24, 11.52s/it] 26%|██▌       | 3339/12750 [10:53:33<30:06:15, 11.52s/it] 26%|██▌       | 3340/12750 [10:53:44<30:04:23, 11.51s/it] 26%|██▌       | 3341/12750 [10:53:56<30:03:17, 11.50s/it] 26%|██▌       | 3342/12750 [10:54:07<30:02:55, 11.50s/it] 26%|██▌       | 3343/12750 [10:54:18<30:01:23, 11.49s/it] 26%|██▌       | 3344/12750 [10:54:30<30:01:41, 11.49s/it] 26%|██▌       | 3345/12750 [10:54:48<35:21:01, 13.53s/it] 26%|██▌       | 3346/12750 [10:55:00<33:43:11, 12.91s/it] 26%|██▋       | 3347/12750 [10:55:11<32:35:08, 12.48s/it] 26%|██▋       | 3348/12750 [10:55:23<31:48:24, 12.18s/it] 26%|██▋       | 3349/12750 [10:55:34<31:15:58, 11.97s/it] 26%|██▋       | 3350/12750 [10:55:46<30:52:47, 11.83s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120268.19lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104561.63lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3350
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3350/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3350/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3325] due to args.save_total_limit
 26%|██▋       | 3351/12750 [10:55:57<30:50:10, 11.81s/it] 26%|██▋       | 3352/12750 [10:56:09<30:34:19, 11.71s/it] 26%|██▋       | 3353/12750 [10:56:20<30:22:29, 11.64s/it] 26%|██▋       | 3354/12750 [10:56:32<30:14:54, 11.59s/it] 26%|██▋       | 3355/12750 [10:56:43<30:09:35, 11.56s/it] 26%|██▋       | 3356/12750 [10:56:55<30:05:36, 11.53s/it] 26%|██▋       | 3357/12750 [10:57:06<30:03:14, 11.52s/it] 26%|██▋       | 3358/12750 [10:57:18<30:01:12, 11.51s/it] 26%|██▋       | 3359/12750 [10:57:29<29:58:08, 11.49s/it] 26%|██▋       | 3360/12750 [10:57:41<29:55:57, 11.48s/it] 26%|██▋       | 3361/12750 [10:57:52<29:56:07, 11.48s/it] 26%|██▋       | 3362/12750 [10:58:04<29:54:15, 11.47s/it] 26%|██▋       | 3363/12750 [10:58:15<29:54:41, 11.47s/it] 26%|██▋       | 3364/12750 [10:58:27<29:54:54, 11.47s/it] 26%|██▋       | 3365/12750 [10:58:38<29:54:10, 11.47s/it] 26%|██▋       | 3366/12750 [10:58:49<29:53:23, 11.47s/it] 26%|██▋       | 3367/12750 [10:59:01<29:54:34, 11.48s/it] 26%|██▋       | 3368/12750 [10:59:12<29:53:52, 11.47s/it] 26%|██▋       | 3369/12750 [10:59:24<29:56:08, 11.49s/it] 26%|██▋       | 3370/12750 [10:59:35<29:56:23, 11.49s/it] 26%|██▋       | 3371/12750 [10:59:47<29:55:16, 11.48s/it] 26%|██▋       | 3372/12750 [10:59:58<29:52:32, 11.47s/it] 26%|██▋       | 3373/12750 [11:00:10<29:51:37, 11.46s/it] 26%|██▋       | 3374/12750 [11:00:22<30:02:08, 11.53s/it] 26%|██▋       | 3375/12750 [11:00:33<29:59:31, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120482.64lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104695.32lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3375
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3375/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3375/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3225] due to args.save_total_limit
 26%|██▋       | 3376/12750 [11:00:45<30:11:08, 11.59s/it] 26%|██▋       | 3377/12750 [11:01:04<35:57:40, 13.81s/it] 26%|██▋       | 3378/12750 [11:01:15<34:07:45, 13.11s/it] 27%|██▋       | 3379/12750 [11:01:27<32:51:51, 12.63s/it] 27%|██▋       | 3380/12750 [11:01:38<31:58:37, 12.29s/it] 27%|██▋       | 3381/12750 [11:01:50<31:20:58, 12.05s/it] 27%|██▋       | 3382/12750 [11:02:01<30:54:19, 11.88s/it] 27%|██▋       | 3383/12750 [11:02:13<30:36:32, 11.76s/it] 27%|██▋       | 3384/12750 [11:02:24<30:24:53, 11.69s/it] 27%|██▋       | 3385/12750 [11:02:36<30:15:16, 11.63s/it] 27%|██▋       | 3386/12750 [11:02:47<30:08:45, 11.59s/it] 27%|██▋       | 3387/12750 [11:02:59<30:03:36, 11.56s/it] 27%|██▋       | 3388/12750 [11:03:10<30:01:31, 11.55s/it] 27%|██▋       | 3389/12750 [11:03:22<30:04:25, 11.57s/it] 27%|██▋       | 3390/12750 [11:03:33<29:59:38, 11.54s/it] 27%|██▋       | 3391/12750 [11:03:45<29:58:25, 11.53s/it] 27%|██▋       | 3392/12750 [11:03:56<29:54:44, 11.51s/it] 27%|██▋       | 3393/12750 [11:04:08<29:53:24, 11.50s/it] 27%|██▋       | 3394/12750 [11:04:19<29:52:37, 11.50s/it] 27%|██▋       | 3395/12750 [11:04:31<29:51:49, 11.49s/it] 27%|██▋       | 3396/12750 [11:04:42<29:52:05, 11.50s/it] 27%|██▋       | 3397/12750 [11:04:54<29:52:15, 11.50s/it] 27%|██▋       | 3398/12750 [11:05:05<29:50:41, 11.49s/it] 27%|██▋       | 3399/12750 [11:05:17<29:50:55, 11.49s/it] 27%|██▋       | 3400/12750 [11:05:28<29:49:58, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120279.17lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104623.07lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3400
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3400/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3400/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3350] due to args.save_total_limit
 27%|██▋       | 3401/12750 [11:05:40<30:04:49, 11.58s/it] 27%|██▋       | 3402/12750 [11:05:51<29:59:35, 11.55s/it] 27%|██▋       | 3403/12750 [11:06:03<29:56:07, 11.53s/it] 27%|██▋       | 3404/12750 [11:06:14<29:54:42, 11.52s/it] 27%|██▋       | 3405/12750 [11:06:26<29:51:20, 11.50s/it] 27%|██▋       | 3406/12750 [11:06:37<29:50:31, 11.50s/it] 27%|██▋       | 3407/12750 [11:06:49<29:47:38, 11.48s/it] 27%|██▋       | 3408/12750 [11:07:00<29:48:09, 11.48s/it] 27%|██▋       | 3409/12750 [11:07:12<29:47:37, 11.48s/it] 27%|██▋       | 3410/12750 [11:07:31<35:38:31, 13.74s/it] 27%|██▋       | 3411/12750 [11:07:42<33:53:17, 13.06s/it] 27%|██▋       | 3412/12750 [11:07:54<32:38:10, 12.58s/it] 27%|██▋       | 3413/12750 [11:08:05<31:46:38, 12.25s/it] 27%|██▋       | 3414/12750 [11:08:17<31:11:07, 12.03s/it] 27%|██▋       | 3415/12750 [11:08:28<30:45:38, 11.86s/it] 27%|██▋       | 3416/12750 [11:08:40<30:27:41, 11.75s/it] 27%|██▋       | 3417/12750 [11:08:51<30:15:07, 11.67s/it] 27%|██▋       | 3418/12750 [11:09:03<30:06:28, 11.61s/it] 27%|██▋       | 3419/12750 [11:09:14<29:59:13, 11.57s/it] 27%|██▋       | 3420/12750 [11:09:26<29:56:40, 11.55s/it] 27%|██▋       | 3421/12750 [11:09:37<29:54:09, 11.54s/it] 27%|██▋       | 3422/12750 [11:09:49<29:50:43, 11.52s/it] 27%|██▋       | 3423/12750 [11:10:00<29:49:45, 11.51s/it] 27%|██▋       | 3424/12750 [11:10:12<29:47:44, 11.50s/it] 27%|██▋       | 3425/12750 [11:10:23<29:46:35, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120329.53lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104665.71lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3425
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3425/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3425/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3375] due to args.save_total_limit
 27%|██▋       | 3426/12750 [11:10:35<30:03:01, 11.60s/it] 27%|██▋       | 3427/12750 [11:10:46<29:57:34, 11.57s/it] 27%|██▋       | 3428/12750 [11:10:58<29:54:17, 11.55s/it] 27%|██▋       | 3429/12750 [11:11:09<29:51:15, 11.53s/it] 27%|██▋       | 3430/12750 [11:11:21<29:48:05, 11.51s/it] 27%|██▋       | 3431/12750 [11:11:32<29:46:51, 11.50s/it] 27%|██▋       | 3432/12750 [11:11:44<29:44:56, 11.49s/it] 27%|██▋       | 3433/12750 [11:11:55<29:43:58, 11.49s/it] 27%|██▋       | 3434/12750 [11:12:07<29:42:09, 11.48s/it] 27%|██▋       | 3435/12750 [11:12:18<29:39:55, 11.46s/it] 27%|██▋       | 3436/12750 [11:12:30<29:40:39, 11.47s/it] 27%|██▋       | 3437/12750 [11:12:41<29:39:20, 11.46s/it] 27%|██▋       | 3438/12750 [11:12:53<29:39:53, 11.47s/it] 27%|██▋       | 3439/12750 [11:13:04<29:40:37, 11.47s/it] 27%|██▋       | 3440/12750 [11:13:15<29:38:12, 11.46s/it] 27%|██▋       | 3441/12750 [11:13:27<29:38:15, 11.46s/it] 27%|██▋       | 3442/12750 [11:13:46<35:34:00, 13.76s/it] 27%|██▋       | 3443/12750 [11:13:58<33:48:35, 13.08s/it] 27%|██▋       | 3444/12750 [11:14:09<32:33:15, 12.59s/it] 27%|██▋       | 3445/12750 [11:14:20<31:40:36, 12.26s/it] 27%|██▋       | 3446/12750 [11:14:32<31:05:42, 12.03s/it] 27%|██▋       | 3447/12750 [11:14:43<30:41:21, 11.88s/it] 27%|██▋       | 3448/12750 [11:14:55<30:22:35, 11.76s/it] 27%|██▋       | 3449/12750 [11:15:06<30:09:35, 11.67s/it] 27%|██▋       | 3450/12750 [11:15:18<30:06:04, 11.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120390.54lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104759.44lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3450
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3450/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3450/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3400] due to args.save_total_limit
 27%|██▋       | 3451/12750 [11:15:30<30:14:43, 11.71s/it] 27%|██▋       | 3452/12750 [11:15:41<30:03:04, 11.64s/it] 27%|██▋       | 3453/12750 [11:15:53<29:55:48, 11.59s/it] 27%|██▋       | 3454/12750 [11:16:04<29:50:48, 11.56s/it] 27%|██▋       | 3455/12750 [11:16:16<29:45:59, 11.53s/it] 27%|██▋       | 3456/12750 [11:16:27<29:41:55, 11.50s/it] 27%|██▋       | 3457/12750 [11:16:39<29:39:44, 11.49s/it] 27%|██▋       | 3458/12750 [11:16:50<29:40:06, 11.49s/it] 27%|██▋       | 3459/12750 [11:17:02<29:37:58, 11.48s/it] 27%|██▋       | 3460/12750 [11:17:13<29:37:36, 11.48s/it] 27%|██▋       | 3461/12750 [11:17:25<29:36:44, 11.48s/it] 27%|██▋       | 3462/12750 [11:17:36<29:34:36, 11.46s/it] 27%|██▋       | 3463/12750 [11:17:48<29:35:31, 11.47s/it] 27%|██▋       | 3464/12750 [11:17:59<29:34:36, 11.47s/it] 27%|██▋       | 3465/12750 [11:18:10<29:35:06, 11.47s/it] 27%|██▋       | 3466/12750 [11:18:22<29:37:07, 11.49s/it] 27%|██▋       | 3467/12750 [11:18:33<29:35:45, 11.48s/it] 27%|██▋       | 3468/12750 [11:18:45<29:36:36, 11.48s/it] 27%|██▋       | 3469/12750 [11:18:56<29:34:37, 11.47s/it] 27%|██▋       | 3470/12750 [11:19:08<29:34:06, 11.47s/it] 27%|██▋       | 3471/12750 [11:19:19<29:34:15, 11.47s/it] 27%|██▋       | 3472/12750 [11:19:31<29:34:29, 11.48s/it] 27%|██▋       | 3473/12750 [11:19:42<29:36:33, 11.49s/it] 27%|██▋       | 3474/12750 [11:20:01<35:26:18, 13.75s/it] 27%|██▋       | 3475/12750 [11:20:13<33:39:05, 13.06s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120344.87lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104632.83lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3475
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3475/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3475/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3425] due to args.save_total_limit
 27%|██▋       | 3476/12750 [11:20:25<32:40:27, 12.68s/it] 27%|██▋       | 3477/12750 [11:20:36<31:44:53, 12.33s/it] 27%|██▋       | 3478/12750 [11:20:48<31:05:16, 12.07s/it] 27%|██▋       | 3479/12750 [11:20:59<30:37:43, 11.89s/it] 27%|██▋       | 3480/12750 [11:21:11<30:18:45, 11.77s/it] 27%|██▋       | 3481/12750 [11:21:22<30:05:16, 11.69s/it] 27%|██▋       | 3482/12750 [11:21:33<29:54:43, 11.62s/it] 27%|██▋       | 3483/12750 [11:21:45<29:47:21, 11.57s/it] 27%|██▋       | 3484/12750 [11:21:56<29:42:06, 11.54s/it] 27%|██▋       | 3485/12750 [11:22:08<29:39:19, 11.52s/it] 27%|██▋       | 3486/12750 [11:22:19<29:36:15, 11.50s/it] 27%|██▋       | 3487/12750 [11:22:31<29:36:34, 11.51s/it] 27%|██▋       | 3488/12750 [11:22:42<29:35:00, 11.50s/it] 27%|██▋       | 3489/12750 [11:22:54<29:34:26, 11.50s/it] 27%|██▋       | 3490/12750 [11:23:05<29:35:07, 11.50s/it] 27%|██▋       | 3491/12750 [11:23:17<29:34:46, 11.50s/it] 27%|██▋       | 3492/12750 [11:23:28<29:33:01, 11.49s/it] 27%|██▋       | 3493/12750 [11:23:40<29:32:27, 11.49s/it] 27%|██▋       | 3494/12750 [11:23:51<29:30:20, 11.48s/it] 27%|██▋       | 3495/12750 [11:24:03<29:28:35, 11.47s/it] 27%|██▋       | 3496/12750 [11:24:14<29:31:47, 11.49s/it] 27%|██▋       | 3497/12750 [11:24:26<29:31:18, 11.49s/it] 27%|██▋       | 3498/12750 [11:24:37<29:31:18, 11.49s/it] 27%|██▋       | 3499/12750 [11:24:49<29:31:05, 11.49s/it] 27%|██▋       | 3500/12750 [11:25:00<29:29:35, 11.48s/it]                                                           27%|██▋       | 3500/12750 [11:25:00<29:29:35, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120027.90lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104437.24lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3500
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3500/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3500/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3450] due to args.save_total_limit
 27%|██▋       | 3501/12750 [11:25:12<29:44:02, 11.57s/it] 27%|██▋       | 3502/12750 [11:25:23<29:40:06, 11.55s/it] 27%|██▋       | 3503/12750 [11:25:35<29:36:25, 11.53s/it] 27%|██▋       | 3504/12750 [11:25:46<29:36:09, 11.53s/it] 27%|██▋       | 3505/12750 [11:25:58<29:33:36, 11.51s/it] 27%|██▋       | 3506/12750 [11:26:17<35:16:09, 13.74s/it] 28%|██▊       | 3507/12750 [11:26:28<33:31:07, 13.06s/it] 28%|██▊       | 3508/12750 [11:26:40<32:16:56, 12.57s/it] 28%|██▊       | 3509/12750 [11:26:51<31:26:04, 12.25s/it] 28%|██▊       | 3510/12750 [11:27:03<30:49:29, 12.01s/it] 28%|██▊       | 3511/12750 [11:27:14<30:29:41, 11.88s/it] 28%|██▊       | 3512/12750 [11:27:26<30:11:20, 11.76s/it] 28%|██▊       | 3513/12750 [11:27:37<29:57:06, 11.67s/it] 28%|██▊       | 3514/12750 [11:27:49<29:51:49, 11.64s/it] 28%|██▊       | 3515/12750 [11:28:00<29:49:58, 11.63s/it] 28%|██▊       | 3516/12750 [11:28:12<29:42:30, 11.58s/it] 28%|██▊       | 3517/12750 [11:28:23<29:38:10, 11.56s/it] 28%|██▊       | 3518/12750 [11:28:35<29:34:12, 11.53s/it] 28%|██▊       | 3519/12750 [11:28:46<29:30:56, 11.51s/it] 28%|██▊       | 3520/12750 [11:28:58<29:29:05, 11.50s/it] 28%|██▊       | 3521/12750 [11:29:09<29:28:10, 11.50s/it] 28%|██▊       | 3522/12750 [11:29:21<29:27:37, 11.49s/it] 28%|██▊       | 3523/12750 [11:29:32<29:26:38, 11.49s/it] 28%|██▊       | 3524/12750 [11:29:44<29:24:47, 11.48s/it] 28%|██▊       | 3525/12750 [11:29:55<29:25:06, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120355.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104686.81lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3525
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3525/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3525/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3500] due to args.save_total_limit
 28%|██▊       | 3526/12750 [11:30:07<29:39:32, 11.58s/it] 28%|██▊       | 3527/12750 [11:30:18<29:33:55, 11.54s/it] 28%|██▊       | 3528/12750 [11:30:30<29:30:16, 11.52s/it] 28%|██▊       | 3529/12750 [11:30:41<29:26:45, 11.50s/it] 28%|██▊       | 3530/12750 [11:30:53<29:25:31, 11.49s/it] 28%|██▊       | 3531/12750 [11:31:04<29:24:49, 11.49s/it] 28%|██▊       | 3532/12750 [11:31:16<29:25:09, 11.49s/it] 28%|██▊       | 3533/12750 [11:31:27<29:23:38, 11.48s/it] 28%|██▊       | 3534/12750 [11:31:39<29:21:47, 11.47s/it] 28%|██▊       | 3535/12750 [11:31:50<29:21:16, 11.47s/it] 28%|██▊       | 3536/12750 [11:32:02<29:20:10, 11.46s/it] 28%|██▊       | 3537/12750 [11:32:13<29:20:06, 11.46s/it] 28%|██▊       | 3538/12750 [11:32:32<35:23:28, 13.83s/it] 28%|██▊       | 3539/12750 [11:32:44<33:33:38, 13.12s/it] 28%|██▊       | 3540/12750 [11:32:55<32:19:13, 12.63s/it] 28%|██▊       | 3541/12750 [11:33:07<31:31:48, 12.33s/it] 28%|██▊       | 3542/12750 [11:33:18<30:52:23, 12.07s/it] 28%|██▊       | 3543/12750 [11:33:30<30:24:37, 11.89s/it] 28%|██▊       | 3544/12750 [11:33:41<30:03:58, 11.76s/it] 28%|██▊       | 3545/12750 [11:33:53<29:52:32, 11.68s/it] 28%|██▊       | 3546/12750 [11:34:04<29:42:10, 11.62s/it] 28%|██▊       | 3547/12750 [11:34:16<29:35:46, 11.58s/it] 28%|██▊       | 3548/12750 [11:34:27<29:30:27, 11.54s/it] 28%|██▊       | 3549/12750 [11:34:39<29:28:09, 11.53s/it] 28%|██▊       | 3550/12750 [11:34:50<29:25:24, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120424.09lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104607.90lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3550
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3550/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3550/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3525] due to args.save_total_limit
 28%|██▊       | 3551/12750 [11:35:02<29:41:10, 11.62s/it] 28%|██▊       | 3552/12750 [11:35:14<29:37:26, 11.59s/it] 28%|██▊       | 3553/12750 [11:35:25<29:31:47, 11.56s/it] 28%|██▊       | 3554/12750 [11:35:37<29:30:26, 11.55s/it] 28%|██▊       | 3555/12750 [11:35:48<29:27:43, 11.53s/it] 28%|██▊       | 3556/12750 [11:36:00<29:25:20, 11.52s/it] 28%|██▊       | 3557/12750 [11:36:11<29:24:29, 11.52s/it] 28%|██▊       | 3558/12750 [11:36:23<29:24:27, 11.52s/it] 28%|██▊       | 3559/12750 [11:36:34<29:23:02, 11.51s/it] 28%|██▊       | 3560/12750 [11:36:46<29:20:16, 11.49s/it] 28%|██▊       | 3561/12750 [11:36:57<29:19:32, 11.49s/it] 28%|██▊       | 3562/12750 [11:37:09<29:18:34, 11.48s/it] 28%|██▊       | 3563/12750 [11:37:20<29:17:37, 11.48s/it] 28%|██▊       | 3564/12750 [11:37:32<29:17:49, 11.48s/it] 28%|██▊       | 3565/12750 [11:37:43<29:17:33, 11.48s/it] 28%|██▊       | 3566/12750 [11:37:55<29:28:36, 11.55s/it] 28%|██▊       | 3567/12750 [11:38:06<29:25:17, 11.53s/it] 28%|██▊       | 3568/12750 [11:38:18<29:21:55, 11.51s/it] 28%|██▊       | 3569/12750 [11:38:25<25:55:29, 10.17s/it] 28%|██▊       | 3570/12750 [11:38:26<18:44:59,  7.35s/it] 28%|██▊       | 3571/12750 [11:38:56<36:44:14, 14.41s/it] 28%|██▊       | 3572/12750 [11:39:08<34:31:31, 13.54s/it] 28%|██▊       | 3573/12750 [11:39:19<32:57:19, 12.93s/it] 28%|██▊       | 3574/12750 [11:39:31<31:49:55, 12.49s/it] 28%|██▊       | 3575/12750 [11:39:42<31:06:10, 12.20s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120375.44lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104716.04lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3575
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3575/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3575/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3475] due to args.save_total_limit
 28%|██▊       | 3576/12750 [11:39:54<30:51:34, 12.11s/it] 28%|██▊       | 3577/12750 [11:40:06<30:23:35, 11.93s/it] 28%|██▊       | 3578/12750 [11:40:17<30:06:04, 11.81s/it] 28%|██▊       | 3579/12750 [11:40:29<29:51:06, 11.72s/it] 28%|██▊       | 3580/12750 [11:40:40<29:44:06, 11.67s/it] 28%|██▊       | 3581/12750 [11:40:52<29:37:01, 11.63s/it] 28%|██▊       | 3582/12750 [11:41:04<29:34:15, 11.61s/it] 28%|██▊       | 3583/12750 [11:41:15<29:31:03, 11.59s/it] 28%|██▊       | 3584/12750 [11:41:27<29:28:53, 11.58s/it] 28%|██▊       | 3585/12750 [11:41:38<29:32:22, 11.60s/it] 28%|██▊       | 3586/12750 [11:41:50<29:27:34, 11.57s/it] 28%|██▊       | 3587/12750 [11:42:01<29:25:21, 11.56s/it] 28%|██▊       | 3588/12750 [11:42:13<29:22:25, 11.54s/it] 28%|██▊       | 3589/12750 [11:42:24<29:19:33, 11.52s/it] 28%|██▊       | 3590/12750 [11:42:36<29:19:53, 11.53s/it] 28%|██▊       | 3591/12750 [11:42:47<29:20:35, 11.53s/it] 28%|██▊       | 3592/12750 [11:42:59<29:17:38, 11.52s/it] 28%|██▊       | 3593/12750 [11:43:10<29:14:29, 11.50s/it] 28%|██▊       | 3594/12750 [11:43:22<29:12:31, 11.48s/it] 28%|██▊       | 3595/12750 [11:43:33<29:12:02, 11.48s/it] 28%|██▊       | 3596/12750 [11:43:45<29:11:44, 11.48s/it] 28%|██▊       | 3597/12750 [11:43:56<29:12:33, 11.49s/it] 28%|██▊       | 3598/12750 [11:44:08<29:11:54, 11.49s/it] 28%|██▊       | 3599/12750 [11:44:19<29:16:13, 11.51s/it] 28%|██▊       | 3600/12750 [11:44:31<29:14:06, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120271.51lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104656.62lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3600
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3600/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3600/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3550] due to args.save_total_limit
 28%|██▊       | 3601/12750 [11:44:43<29:26:03, 11.58s/it] 28%|██▊       | 3602/12750 [11:44:54<29:19:29, 11.54s/it] 28%|██▊       | 3603/12750 [11:45:13<35:03:23, 13.80s/it] 28%|██▊       | 3604/12750 [11:45:25<33:18:14, 13.11s/it] 28%|██▊       | 3605/12750 [11:45:36<32:04:06, 12.62s/it] 28%|██▊       | 3606/12750 [11:45:48<31:13:00, 12.29s/it] 28%|██▊       | 3607/12750 [11:45:59<30:41:18, 12.08s/it] 28%|██▊       | 3608/12750 [11:46:11<30:13:20, 11.90s/it] 28%|██▊       | 3609/12750 [11:46:22<29:54:27, 11.78s/it] 28%|██▊       | 3610/12750 [11:46:34<29:40:13, 11.69s/it] 28%|██▊       | 3611/12750 [11:46:45<29:30:23, 11.62s/it] 28%|██▊       | 3612/12750 [11:46:57<29:24:02, 11.58s/it] 28%|██▊       | 3613/12750 [11:47:08<29:18:55, 11.55s/it] 28%|██▊       | 3614/12750 [11:47:20<29:16:35, 11.54s/it] 28%|██▊       | 3615/12750 [11:47:31<29:14:37, 11.52s/it] 28%|██▊       | 3616/12750 [11:47:42<29:12:20, 11.51s/it] 28%|██▊       | 3617/12750 [11:47:54<29:12:33, 11.51s/it] 28%|██▊       | 3618/12750 [11:48:06<29:11:49, 11.51s/it] 28%|██▊       | 3619/12750 [11:48:17<29:10:37, 11.50s/it] 28%|██▊       | 3620/12750 [11:48:29<29:10:51, 11.51s/it] 28%|██▊       | 3621/12750 [11:48:40<29:08:09, 11.49s/it] 28%|██▊       | 3622/12750 [11:48:51<29:08:14, 11.49s/it] 28%|██▊       | 3623/12750 [11:49:03<29:07:30, 11.49s/it] 28%|██▊       | 3624/12750 [11:49:15<29:34:18, 11.67s/it] 28%|██▊       | 3625/12750 [11:49:26<29:25:57, 11.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 80673.83lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 73333.55lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3625
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3625/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3625/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3600] due to args.save_total_limit
 28%|██▊       | 3626/12750 [11:49:38<29:39:36, 11.70s/it] 28%|██▊       | 3627/12750 [11:49:50<29:30:33, 11.64s/it] 28%|██▊       | 3628/12750 [11:50:01<29:23:17, 11.60s/it] 28%|██▊       | 3629/12750 [11:50:13<29:21:01, 11.58s/it] 28%|██▊       | 3630/12750 [11:50:24<29:15:40, 11.55s/it] 28%|██▊       | 3631/12750 [11:50:36<29:11:06, 11.52s/it] 28%|██▊       | 3632/12750 [11:50:47<29:07:20, 11.50s/it] 28%|██▊       | 3633/12750 [11:50:59<29:06:12, 11.49s/it] 29%|██▊       | 3634/12750 [11:51:10<29:04:23, 11.48s/it] 29%|██▊       | 3635/12750 [11:51:22<29:04:19, 11.48s/it] 29%|██▊       | 3636/12750 [11:51:41<34:46:15, 13.73s/it] 29%|██▊       | 3637/12750 [11:51:52<33:03:12, 13.06s/it] 29%|██▊       | 3638/12750 [11:52:04<31:50:39, 12.58s/it] 29%|██▊       | 3639/12750 [11:52:15<30:58:48, 12.24s/it] 29%|██▊       | 3640/12750 [11:52:27<30:26:12, 12.03s/it] 29%|██▊       | 3641/12750 [11:52:38<30:01:49, 11.87s/it] 29%|██▊       | 3642/12750 [11:52:50<29:44:40, 11.76s/it] 29%|██▊       | 3643/12750 [11:53:01<29:32:00, 11.67s/it] 29%|██▊       | 3644/12750 [11:53:13<29:22:08, 11.61s/it] 29%|██▊       | 3645/12750 [11:53:24<29:16:27, 11.57s/it] 29%|██▊       | 3646/12750 [11:53:36<29:12:08, 11.55s/it] 29%|██▊       | 3647/12750 [11:53:47<29:09:59, 11.53s/it] 29%|██▊       | 3648/12750 [11:53:59<29:05:34, 11.51s/it] 29%|██▊       | 3649/12750 [11:54:10<29:04:10, 11.50s/it] 29%|██▊       | 3650/12750 [11:54:21<29:02:15, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120257.59lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104636.51lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3650
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3650/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3650/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3625] due to args.save_total_limit
 29%|██▊       | 3651/12750 [11:54:33<29:14:36, 11.57s/it] 29%|██▊       | 3652/12750 [11:54:45<29:13:17, 11.56s/it] 29%|██▊       | 3653/12750 [11:54:56<29:07:46, 11.53s/it] 29%|██▊       | 3654/12750 [11:55:08<29:05:58, 11.52s/it] 29%|██▊       | 3655/12750 [11:55:19<29:04:28, 11.51s/it] 29%|██▊       | 3656/12750 [11:55:31<29:02:58, 11.50s/it] 29%|██▊       | 3657/12750 [11:55:42<29:02:21, 11.50s/it] 29%|██▊       | 3658/12750 [11:55:54<29:00:00, 11.48s/it] 29%|██▊       | 3659/12750 [11:56:05<29:00:14, 11.49s/it] 29%|██▊       | 3660/12750 [11:56:17<29:00:08, 11.49s/it] 29%|██▊       | 3661/12750 [11:56:28<28:58:44, 11.48s/it] 29%|██▊       | 3662/12750 [11:56:40<29:00:55, 11.49s/it] 29%|██▊       | 3663/12750 [11:56:51<28:59:49, 11.49s/it] 29%|██▊       | 3664/12750 [11:57:03<28:57:30, 11.47s/it] 29%|██▊       | 3665/12750 [11:57:14<28:57:51, 11.48s/it] 29%|██▉       | 3666/12750 [11:57:25<28:57:59, 11.48s/it] 29%|██▉       | 3667/12750 [11:57:37<28:58:03, 11.48s/it] 29%|██▉       | 3668/12750 [11:57:56<34:39:13, 13.74s/it] 29%|██▉       | 3669/12750 [11:58:07<32:55:11, 13.05s/it] 29%|██▉       | 3670/12750 [11:58:19<31:44:21, 12.58s/it] 29%|██▉       | 3671/12750 [11:58:30<30:53:16, 12.25s/it] 29%|██▉       | 3672/12750 [11:58:42<30:18:52, 12.02s/it] 29%|██▉       | 3673/12750 [11:58:53<29:54:10, 11.86s/it] 29%|██▉       | 3674/12750 [11:59:05<29:37:58, 11.75s/it] 29%|██▉       | 3675/12750 [11:59:16<29:27:02, 11.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120261.67lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104581.14lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3675
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3675/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3675/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3650] due to args.save_total_limit
 29%|██▉       | 3676/12750 [11:59:28<29:30:52, 11.71s/it] 29%|██▉       | 3677/12750 [11:59:40<29:20:43, 11.64s/it] 29%|██▉       | 3678/12750 [11:59:51<29:11:21, 11.58s/it] 29%|██▉       | 3679/12750 [12:00:03<29:08:22, 11.56s/it] 29%|██▉       | 3680/12750 [12:00:14<29:04:42, 11.54s/it] 29%|██▉       | 3681/12750 [12:00:26<29:00:02, 11.51s/it] 29%|██▉       | 3682/12750 [12:00:37<28:57:27, 11.50s/it] 29%|██▉       | 3683/12750 [12:00:48<28:54:14, 11.48s/it] 29%|██▉       | 3684/12750 [12:01:00<28:52:41, 11.47s/it] 29%|██▉       | 3685/12750 [12:01:11<28:53:23, 11.47s/it] 29%|██▉       | 3686/12750 [12:01:23<28:52:32, 11.47s/it] 29%|██▉       | 3687/12750 [12:01:34<28:53:57, 11.48s/it] 29%|██▉       | 3688/12750 [12:01:46<28:54:55, 11.49s/it] 29%|██▉       | 3689/12750 [12:01:57<28:55:10, 11.49s/it] 29%|██▉       | 3690/12750 [12:02:09<28:55:01, 11.49s/it] 29%|██▉       | 3691/12750 [12:02:20<28:54:57, 11.49s/it] 29%|██▉       | 3692/12750 [12:02:32<28:55:14, 11.49s/it] 29%|██▉       | 3693/12750 [12:02:43<28:57:24, 11.51s/it] 29%|██▉       | 3694/12750 [12:02:55<28:54:40, 11.49s/it] 29%|██▉       | 3695/12750 [12:03:06<28:54:09, 11.49s/it] 29%|██▉       | 3696/12750 [12:03:18<28:53:31, 11.49s/it] 29%|██▉       | 3697/12750 [12:03:29<28:53:07, 11.49s/it] 29%|██▉       | 3698/12750 [12:03:41<28:52:58, 11.49s/it] 29%|██▉       | 3699/12750 [12:03:52<28:51:45, 11.48s/it] 29%|██▉       | 3700/12750 [12:04:11<34:32:14, 13.74s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120248.78lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104628.19lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3700
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3700/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3700/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3675] due to args.save_total_limit
 29%|██▉       | 3701/12750 [12:04:23<33:01:42, 13.14s/it] 29%|██▉       | 3702/12750 [12:04:34<31:46:45, 12.64s/it] 29%|██▉       | 3703/12750 [12:04:46<30:53:14, 12.29s/it] 29%|██▉       | 3704/12750 [12:04:57<30:15:45, 12.04s/it] 29%|██▉       | 3705/12750 [12:05:09<29:47:59, 11.86s/it] 29%|██▉       | 3706/12750 [12:05:20<29:28:53, 11.74s/it] 29%|██▉       | 3707/12750 [12:05:32<29:16:56, 11.66s/it] 29%|██▉       | 3708/12750 [12:05:43<29:08:08, 11.60s/it] 29%|██▉       | 3709/12750 [12:05:55<29:00:24, 11.55s/it] 29%|██▉       | 3710/12750 [12:06:06<28:57:41, 11.53s/it] 29%|██▉       | 3711/12750 [12:06:18<28:54:04, 11.51s/it] 29%|██▉       | 3712/12750 [12:06:29<28:52:01, 11.50s/it] 29%|██▉       | 3713/12750 [12:06:41<28:52:51, 11.51s/it] 29%|██▉       | 3714/12750 [12:06:52<28:51:46, 11.50s/it] 29%|██▉       | 3715/12750 [12:07:03<28:49:15, 11.48s/it] 29%|██▉       | 3716/12750 [12:07:15<28:47:53, 11.48s/it] 29%|██▉       | 3717/12750 [12:07:26<28:46:15, 11.47s/it] 29%|██▉       | 3718/12750 [12:07:38<28:46:40, 11.47s/it] 29%|██▉       | 3719/12750 [12:07:49<28:45:50, 11.47s/it] 29%|██▉       | 3720/12750 [12:08:01<28:44:09, 11.46s/it] 29%|██▉       | 3721/12750 [12:08:12<28:45:01, 11.46s/it] 29%|██▉       | 3722/12750 [12:08:24<28:44:42, 11.46s/it] 29%|██▉       | 3723/12750 [12:08:35<28:44:17, 11.46s/it] 29%|██▉       | 3724/12750 [12:08:47<28:43:20, 11.46s/it] 29%|██▉       | 3725/12750 [12:08:58<28:43:14, 11.46s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120307.03lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104740.93lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3725
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3725/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3725/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3575] due to args.save_total_limit
 29%|██▉       | 3726/12750 [12:09:10<28:57:03, 11.55s/it] 29%|██▉       | 3727/12750 [12:09:21<28:52:31, 11.52s/it] 29%|██▉       | 3728/12750 [12:09:33<28:48:30, 11.50s/it] 29%|██▉       | 3729/12750 [12:09:44<28:46:36, 11.48s/it] 29%|██▉       | 3730/12750 [12:09:56<28:44:05, 11.47s/it] 29%|██▉       | 3731/12750 [12:10:07<28:43:48, 11.47s/it] 29%|██▉       | 3732/12750 [12:10:26<34:18:09, 13.69s/it] 29%|██▉       | 3733/12750 [12:10:37<32:37:23, 13.02s/it] 29%|██▉       | 3734/12750 [12:10:49<31:26:38, 12.56s/it] 29%|██▉       | 3735/12750 [12:11:00<30:36:49, 12.23s/it] 29%|██▉       | 3736/12750 [12:11:12<30:01:26, 11.99s/it] 29%|██▉       | 3737/12750 [12:11:23<29:36:16, 11.82s/it] 29%|██▉       | 3738/12750 [12:11:35<29:18:55, 11.71s/it] 29%|██▉       | 3739/12750 [12:11:46<29:06:33, 11.63s/it] 29%|██▉       | 3740/12750 [12:11:58<28:58:57, 11.58s/it] 29%|██▉       | 3741/12750 [12:12:09<28:54:10, 11.55s/it] 29%|██▉       | 3742/12750 [12:12:21<28:50:09, 11.52s/it] 29%|██▉       | 3743/12750 [12:12:32<28:48:16, 11.51s/it] 29%|██▉       | 3744/12750 [12:12:43<28:45:36, 11.50s/it] 29%|██▉       | 3745/12750 [12:12:55<28:43:57, 11.49s/it] 29%|██▉       | 3746/12750 [12:13:06<28:42:12, 11.48s/it] 29%|██▉       | 3747/12750 [12:13:18<28:41:08, 11.47s/it] 29%|██▉       | 3748/12750 [12:13:29<28:38:35, 11.45s/it] 29%|██▉       | 3749/12750 [12:13:41<28:37:27, 11.45s/it] 29%|██▉       | 3750/12750 [12:13:52<28:38:27, 11.46s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120349.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104648.88lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3750
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3750/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3750/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3700] due to args.save_total_limit
 29%|██▉       | 3751/12750 [12:14:04<28:50:41, 11.54s/it] 29%|██▉       | 3752/12750 [12:14:15<28:44:48, 11.50s/it] 29%|██▉       | 3753/12750 [12:14:27<28:41:22, 11.48s/it] 29%|██▉       | 3754/12750 [12:14:38<28:42:39, 11.49s/it] 29%|██▉       | 3755/12750 [12:14:50<28:41:14, 11.48s/it] 29%|██▉       | 3756/12750 [12:15:01<28:40:05, 11.47s/it] 29%|██▉       | 3757/12750 [12:15:13<28:39:55, 11.48s/it] 29%|██▉       | 3758/12750 [12:15:24<28:39:09, 11.47s/it] 29%|██▉       | 3759/12750 [12:15:36<28:38:44, 11.47s/it] 29%|██▉       | 3760/12750 [12:15:47<28:38:14, 11.47s/it] 29%|██▉       | 3761/12750 [12:15:58<28:35:37, 11.45s/it] 30%|██▉       | 3762/12750 [12:16:10<28:36:26, 11.46s/it] 30%|██▉       | 3763/12750 [12:16:21<28:36:00, 11.46s/it] 30%|██▉       | 3764/12750 [12:16:41<34:47:46, 13.94s/it] 30%|██▉       | 3765/12750 [12:16:53<32:54:14, 13.18s/it] 30%|██▉       | 3766/12750 [12:17:04<31:36:58, 12.67s/it] 30%|██▉       | 3767/12750 [12:17:15<30:41:34, 12.30s/it] 30%|██▉       | 3768/12750 [12:17:27<30:02:42, 12.04s/it] 30%|██▉       | 3769/12750 [12:17:38<29:35:20, 11.86s/it] 30%|██▉       | 3770/12750 [12:17:50<29:15:33, 11.73s/it] 30%|██▉       | 3771/12750 [12:18:01<29:02:51, 11.65s/it] 30%|██▉       | 3772/12750 [12:18:13<28:52:57, 11.58s/it] 30%|██▉       | 3773/12750 [12:18:24<28:46:28, 11.54s/it] 30%|██▉       | 3774/12750 [12:18:36<28:43:44, 11.52s/it] 30%|██▉       | 3775/12750 [12:18:47<28:40:45, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120458.29lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104627.81lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3775
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3775/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3775/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3750] due to args.save_total_limit
 30%|██▉       | 3776/12750 [12:18:59<28:52:16, 11.58s/it] 30%|██▉       | 3777/12750 [12:19:10<28:46:55, 11.55s/it] 30%|██▉       | 3778/12750 [12:19:22<28:42:32, 11.52s/it] 30%|██▉       | 3779/12750 [12:19:33<28:39:45, 11.50s/it] 30%|██▉       | 3780/12750 [12:19:45<28:38:52, 11.50s/it] 30%|██▉       | 3781/12750 [12:19:56<28:37:29, 11.49s/it] 30%|██▉       | 3782/12750 [12:20:08<28:35:19, 11.48s/it] 30%|██▉       | 3783/12750 [12:20:19<28:34:42, 11.47s/it] 30%|██▉       | 3784/12750 [12:20:30<28:33:39, 11.47s/it] 30%|██▉       | 3785/12750 [12:20:42<28:31:57, 11.46s/it] 30%|██▉       | 3786/12750 [12:20:53<28:32:09, 11.46s/it] 30%|██▉       | 3787/12750 [12:21:05<28:32:28, 11.46s/it] 30%|██▉       | 3788/12750 [12:21:16<28:32:51, 11.47s/it] 30%|██▉       | 3789/12750 [12:21:28<28:31:42, 11.46s/it] 30%|██▉       | 3790/12750 [12:21:39<28:31:53, 11.46s/it] 30%|██▉       | 3791/12750 [12:21:51<28:30:58, 11.46s/it] 30%|██▉       | 3792/12750 [12:22:02<28:31:18, 11.46s/it] 30%|██▉       | 3793/12750 [12:22:14<28:31:43, 11.47s/it] 30%|██▉       | 3794/12750 [12:22:25<28:32:43, 11.47s/it] 30%|██▉       | 3795/12750 [12:22:37<28:30:12, 11.46s/it] 30%|██▉       | 3796/12750 [12:22:56<34:06:58, 13.72s/it] 30%|██▉       | 3797/12750 [12:23:07<32:25:34, 13.04s/it] 30%|██▉       | 3798/12750 [12:23:18<31:14:02, 12.56s/it] 30%|██▉       | 3799/12750 [12:23:30<30:22:57, 12.22s/it] 30%|██▉       | 3800/12750 [12:23:41<29:48:37, 11.99s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120495.84lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104809.66lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3800
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3800/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3800/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3775] due to args.save_total_limit
 30%|██▉       | 3801/12750 [12:23:53<29:37:27, 11.92s/it] 30%|██▉       | 3802/12750 [12:24:05<29:16:29, 11.78s/it] 30%|██▉       | 3803/12750 [12:24:16<29:00:20, 11.67s/it] 30%|██▉       | 3804/12750 [12:24:27<28:50:01, 11.60s/it] 30%|██▉       | 3805/12750 [12:24:39<28:41:08, 11.54s/it] 30%|██▉       | 3806/12750 [12:24:50<28:37:47, 11.52s/it] 30%|██▉       | 3807/12750 [12:25:02<28:33:39, 11.50s/it] 30%|██▉       | 3808/12750 [12:25:13<28:32:08, 11.49s/it] 30%|██▉       | 3809/12750 [12:25:25<28:29:08, 11.47s/it] 30%|██▉       | 3810/12750 [12:25:36<28:27:53, 11.46s/it] 30%|██▉       | 3811/12750 [12:25:47<28:26:16, 11.45s/it] 30%|██▉       | 3812/12750 [12:25:59<28:24:54, 11.44s/it] 30%|██▉       | 3813/12750 [12:26:10<28:25:58, 11.45s/it] 30%|██▉       | 3814/12750 [12:26:22<28:25:05, 11.45s/it] 30%|██▉       | 3815/12750 [12:26:33<28:25:13, 11.45s/it] 30%|██▉       | 3816/12750 [12:26:45<28:25:11, 11.45s/it] 30%|██▉       | 3817/12750 [12:26:56<28:23:24, 11.44s/it] 30%|██▉       | 3818/12750 [12:27:08<28:23:54, 11.45s/it] 30%|██▉       | 3819/12750 [12:27:19<28:24:25, 11.45s/it] 30%|██▉       | 3820/12750 [12:27:30<28:24:02, 11.45s/it] 30%|██▉       | 3821/12750 [12:27:42<28:22:16, 11.44s/it] 30%|██▉       | 3822/12750 [12:27:53<28:21:25, 11.43s/it] 30%|██▉       | 3823/12750 [12:28:05<28:21:23, 11.44s/it] 30%|██▉       | 3824/12750 [12:28:16<28:22:03, 11.44s/it] 30%|███       | 3825/12750 [12:28:28<28:22:44, 11.45s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120398.99lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104673.16lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3825
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3825/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3825/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3800] due to args.save_total_limit
 30%|███       | 3826/12750 [12:28:40<28:39:21, 11.56s/it] 30%|███       | 3827/12750 [12:28:51<28:33:52, 11.52s/it] 30%|███       | 3828/12750 [12:29:10<34:08:11, 13.77s/it] 30%|███       | 3829/12750 [12:29:21<32:23:48, 13.07s/it] 30%|███       | 3830/12750 [12:29:33<31:11:35, 12.59s/it] 30%|███       | 3831/12750 [12:29:44<30:20:22, 12.25s/it] 30%|███       | 3832/12750 [12:29:56<29:45:52, 12.02s/it] 30%|███       | 3833/12750 [12:30:07<29:20:37, 11.85s/it] 30%|███       | 3834/12750 [12:30:19<29:03:58, 11.74s/it] 30%|███       | 3835/12750 [12:30:30<28:53:00, 11.66s/it] 30%|███       | 3836/12750 [12:30:42<28:43:37, 11.60s/it] 30%|███       | 3837/12750 [12:30:53<28:34:46, 11.54s/it] 30%|███       | 3838/12750 [12:31:05<28:30:39, 11.52s/it] 30%|███       | 3839/12750 [12:31:16<28:29:29, 11.51s/it] 30%|███       | 3840/12750 [12:31:27<28:26:16, 11.49s/it] 30%|███       | 3841/12750 [12:31:39<28:23:58, 11.48s/it] 30%|███       | 3842/12750 [12:31:50<28:23:56, 11.48s/it] 30%|███       | 3843/12750 [12:32:02<28:23:11, 11.47s/it] 30%|███       | 3844/12750 [12:32:13<28:20:20, 11.46s/it] 30%|███       | 3845/12750 [12:32:25<28:18:45, 11.45s/it] 30%|███       | 3846/12750 [12:32:36<28:17:46, 11.44s/it] 30%|███       | 3847/12750 [12:32:48<28:18:19, 11.45s/it] 30%|███       | 3848/12750 [12:32:59<28:18:39, 11.45s/it] 30%|███       | 3849/12750 [12:33:10<28:17:34, 11.44s/it] 30%|███       | 3850/12750 [12:33:22<28:19:01, 11.45s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120419.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104761.96lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3850
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3850/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3850/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3825] due to args.save_total_limit
 30%|███       | 3851/12750 [12:33:34<28:33:39, 11.55s/it] 30%|███       | 3852/12750 [12:33:45<28:28:00, 11.52s/it] 30%|███       | 3853/12750 [12:33:57<28:24:36, 11.50s/it] 30%|███       | 3854/12750 [12:34:08<28:23:03, 11.49s/it] 30%|███       | 3855/12750 [12:34:20<28:21:31, 11.48s/it] 30%|███       | 3856/12750 [12:34:31<28:19:03, 11.46s/it] 30%|███       | 3857/12750 [12:34:42<28:18:35, 11.46s/it] 30%|███       | 3858/12750 [12:34:54<28:16:54, 11.45s/it] 30%|███       | 3859/12750 [12:35:05<28:14:36, 11.44s/it] 30%|███       | 3860/12750 [12:35:17<28:15:01, 11.44s/it] 30%|███       | 3861/12750 [12:35:35<33:07:22, 13.41s/it] 30%|███       | 3862/12750 [12:35:46<31:41:40, 12.84s/it] 30%|███       | 3863/12750 [12:35:58<30:41:18, 12.43s/it] 30%|███       | 3864/12750 [12:36:09<29:58:28, 12.14s/it] 30%|███       | 3865/12750 [12:36:21<29:28:59, 11.95s/it] 30%|███       | 3866/12750 [12:36:32<29:06:47, 11.80s/it] 30%|███       | 3867/12750 [12:36:44<28:52:20, 11.70s/it] 30%|███       | 3868/12750 [12:36:55<28:42:21, 11.63s/it] 30%|███       | 3869/12750 [12:37:07<28:34:37, 11.58s/it] 30%|███       | 3870/12750 [12:37:18<28:29:46, 11.55s/it] 30%|███       | 3871/12750 [12:37:29<28:24:54, 11.52s/it] 30%|███       | 3872/12750 [12:37:41<28:21:47, 11.50s/it] 30%|███       | 3873/12750 [12:37:52<28:20:22, 11.49s/it] 30%|███       | 3874/12750 [12:38:04<28:18:31, 11.48s/it] 30%|███       | 3875/12750 [12:38:15<28:16:55, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120542.53lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104728.14lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3875
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3875/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3875/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3850] due to args.save_total_limit
 30%|███       | 3876/12750 [12:38:27<28:32:33, 11.58s/it] 30%|███       | 3877/12750 [12:38:39<28:27:57, 11.55s/it] 30%|███       | 3878/12750 [12:38:50<28:25:08, 11.53s/it] 30%|███       | 3879/12750 [12:39:02<28:22:23, 11.51s/it] 30%|███       | 3880/12750 [12:39:13<28:20:43, 11.50s/it] 30%|███       | 3881/12750 [12:39:25<28:18:48, 11.49s/it] 30%|███       | 3882/12750 [12:39:36<28:18:09, 11.49s/it] 30%|███       | 3883/12750 [12:39:47<28:17:07, 11.48s/it] 30%|███       | 3884/12750 [12:39:59<28:16:16, 11.48s/it] 30%|███       | 3885/12750 [12:40:10<28:16:05, 11.48s/it] 30%|███       | 3886/12750 [12:40:22<28:14:46, 11.47s/it] 30%|███       | 3887/12750 [12:40:33<28:15:21, 11.48s/it] 30%|███       | 3888/12750 [12:40:45<28:15:40, 11.48s/it] 31%|███       | 3889/12750 [12:40:56<28:15:39, 11.48s/it] 31%|███       | 3890/12750 [12:41:08<28:13:48, 11.47s/it] 31%|███       | 3891/12750 [12:41:19<28:11:54, 11.46s/it] 31%|███       | 3892/12750 [12:41:31<28:11:02, 11.45s/it] 31%|███       | 3893/12750 [12:41:50<33:48:32, 13.74s/it] 31%|███       | 3894/12750 [12:42:01<32:06:43, 13.05s/it] 31%|███       | 3895/12750 [12:42:13<30:55:08, 12.57s/it] 31%|███       | 3896/12750 [12:42:24<30:06:06, 12.24s/it] 31%|███       | 3897/12750 [12:42:36<29:29:34, 11.99s/it] 31%|███       | 3898/12750 [12:42:47<29:05:41, 11.83s/it] 31%|███       | 3899/12750 [12:42:58<28:48:21, 11.72s/it] 31%|███       | 3900/12750 [12:43:10<28:36:41, 11.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 119997.38lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104430.31lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3900
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3900/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3900/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3875] due to args.save_total_limit
 31%|███       | 3901/12750 [12:43:22<28:41:41, 11.67s/it] 31%|███       | 3902/12750 [12:43:33<28:29:25, 11.59s/it] 31%|███       | 3903/12750 [12:43:44<28:24:16, 11.56s/it] 31%|███       | 3904/12750 [12:43:56<28:19:27, 11.53s/it] 31%|███       | 3905/12750 [12:44:07<28:16:53, 11.51s/it] 31%|███       | 3906/12750 [12:44:19<28:14:12, 11.49s/it] 31%|███       | 3907/12750 [12:44:30<28:13:11, 11.49s/it] 31%|███       | 3908/12750 [12:44:42<28:12:43, 11.49s/it] 31%|███       | 3909/12750 [12:44:53<28:11:27, 11.48s/it] 31%|███       | 3910/12750 [12:45:05<28:11:16, 11.48s/it] 31%|███       | 3911/12750 [12:45:16<28:11:31, 11.48s/it] 31%|███       | 3912/12750 [12:45:28<28:08:33, 11.46s/it] 31%|███       | 3913/12750 [12:45:39<28:07:23, 11.46s/it] 31%|███       | 3914/12750 [12:45:51<28:07:58, 11.46s/it] 31%|███       | 3915/12750 [12:46:02<28:08:25, 11.47s/it] 31%|███       | 3916/12750 [12:46:14<28:07:25, 11.46s/it] 31%|███       | 3917/12750 [12:46:25<28:07:09, 11.46s/it] 31%|███       | 3918/12750 [12:46:36<28:08:33, 11.47s/it] 31%|███       | 3919/12750 [12:46:48<28:06:22, 11.46s/it] 31%|███       | 3920/12750 [12:46:59<28:06:51, 11.46s/it] 31%|███       | 3921/12750 [12:47:11<28:06:08, 11.46s/it] 31%|███       | 3922/12750 [12:47:22<28:06:58, 11.47s/it] 31%|███       | 3923/12750 [12:47:34<28:07:40, 11.47s/it] 31%|███       | 3924/12750 [12:47:45<28:06:35, 11.47s/it] 31%|███       | 3925/12750 [12:48:04<33:36:00, 13.71s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120368.02lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104702.19lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3925
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3925/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3925/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3725] due to args.save_total_limit
 31%|███       | 3926/12750 [12:48:16<32:10:23, 13.13s/it] 31%|███       | 3927/12750 [12:48:27<30:55:50, 12.62s/it] 31%|███       | 3928/12750 [12:48:39<30:03:41, 12.27s/it] 31%|███       | 3929/12750 [12:48:50<29:26:14, 12.01s/it] 31%|███       | 3930/12750 [12:49:02<29:01:06, 11.84s/it] 31%|███       | 3931/12750 [12:49:13<28:43:27, 11.73s/it] 31%|███       | 3932/12750 [12:49:25<28:30:41, 11.64s/it] 31%|███       | 3933/12750 [12:49:36<28:22:00, 11.58s/it] 31%|███       | 3934/12750 [12:49:47<28:15:44, 11.54s/it] 31%|███       | 3935/12750 [12:49:59<28:11:11, 11.51s/it] 31%|███       | 3936/12750 [12:50:10<28:06:44, 11.48s/it] 31%|███       | 3937/12750 [12:50:22<28:04:16, 11.47s/it] 31%|███       | 3938/12750 [12:50:33<28:03:16, 11.46s/it] 31%|███       | 3939/12750 [12:50:45<28:02:37, 11.46s/it] 31%|███       | 3940/12750 [12:50:56<28:01:26, 11.45s/it] 31%|███       | 3941/12750 [12:51:08<28:00:36, 11.45s/it] 31%|███       | 3942/12750 [12:51:19<28:01:23, 11.45s/it] 31%|███       | 3943/12750 [12:51:30<28:00:19, 11.45s/it] 31%|███       | 3944/12750 [12:51:42<27:58:46, 11.44s/it] 31%|███       | 3945/12750 [12:51:53<28:04:32, 11.48s/it] 31%|███       | 3946/12750 [12:52:05<28:01:51, 11.46s/it] 31%|███       | 3947/12750 [12:52:16<28:00:54, 11.46s/it] 31%|███       | 3948/12750 [12:52:28<27:58:52, 11.44s/it] 31%|███       | 3949/12750 [12:52:39<27:58:09, 11.44s/it] 31%|███       | 3950/12750 [12:52:51<27:58:18, 11.44s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120403.60lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104743.55lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3950
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3950/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3950/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3900] due to args.save_total_limit
 31%|███       | 3951/12750 [12:53:02<28:11:21, 11.53s/it] 31%|███       | 3952/12750 [12:53:14<28:16:13, 11.57s/it] 31%|███       | 3953/12750 [12:53:25<28:10:37, 11.53s/it] 31%|███       | 3954/12750 [12:53:37<28:08:01, 11.51s/it] 31%|███       | 3955/12750 [12:53:48<28:05:03, 11.50s/it] 31%|███       | 3956/12750 [12:54:00<28:02:47, 11.48s/it] 31%|███       | 3957/12750 [12:54:19<33:37:38, 13.77s/it] 31%|███       | 3958/12750 [12:54:30<31:56:02, 13.08s/it] 31%|███       | 3959/12750 [12:54:42<30:45:36, 12.60s/it] 31%|███       | 3960/12750 [12:54:53<29:54:35, 12.25s/it] 31%|███       | 3961/12750 [12:55:05<29:20:18, 12.02s/it] 31%|███       | 3962/12750 [12:55:16<28:56:41, 11.86s/it] 31%|███       | 3963/12750 [12:55:28<28:38:55, 11.74s/it] 31%|███       | 3964/12750 [12:55:39<28:26:13, 11.65s/it] 31%|███       | 3965/12750 [12:55:51<28:17:52, 11.60s/it] 31%|███       | 3966/12750 [12:56:02<28:11:01, 11.55s/it] 31%|███       | 3967/12750 [12:56:14<28:06:22, 11.52s/it] 31%|███       | 3968/12750 [12:56:25<28:03:13, 11.50s/it] 31%|███       | 3969/12750 [12:56:36<28:00:21, 11.48s/it] 31%|███       | 3970/12750 [12:56:48<28:00:51, 11.49s/it] 31%|███       | 3971/12750 [12:56:59<27:58:47, 11.47s/it] 31%|███       | 3972/12750 [12:57:11<27:57:42, 11.47s/it] 31%|███       | 3973/12750 [12:57:22<27:57:57, 11.47s/it] 31%|███       | 3974/12750 [12:57:34<27:57:29, 11.47s/it] 31%|███       | 3975/12750 [12:57:45<27:57:37, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120398.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104584.90lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3975
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3975/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3975/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-3975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3950] due to args.save_total_limit
 31%|███       | 3976/12750 [12:57:57<28:11:47, 11.57s/it] 31%|███       | 3977/12750 [12:58:08<28:06:55, 11.54s/it] 31%|███       | 3978/12750 [12:58:20<28:03:26, 11.51s/it] 31%|███       | 3979/12750 [12:58:31<28:00:42, 11.50s/it] 31%|███       | 3980/12750 [12:58:43<27:58:51, 11.49s/it] 31%|███       | 3981/12750 [12:58:54<27:57:26, 11.48s/it] 31%|███       | 3982/12750 [12:59:06<27:55:31, 11.47s/it] 31%|███       | 3983/12750 [12:59:17<27:55:20, 11.47s/it] 31%|███       | 3984/12750 [12:59:29<27:55:19, 11.47s/it] 31%|███▏      | 3985/12750 [12:59:40<27:54:23, 11.46s/it] 31%|███▏      | 3986/12750 [12:59:52<27:55:20, 11.47s/it] 31%|███▏      | 3987/12750 [13:00:03<27:54:51, 11.47s/it] 31%|███▏      | 3988/12750 [13:00:15<27:54:14, 11.46s/it] 31%|███▏      | 3989/12750 [13:00:34<33:22:56, 13.72s/it] 31%|███▏      | 3990/12750 [13:00:45<31:45:36, 13.05s/it] 31%|███▏      | 3991/12750 [13:00:56<30:34:58, 12.57s/it] 31%|███▏      | 3992/12750 [13:01:08<29:46:42, 12.24s/it] 31%|███▏      | 3993/12750 [13:01:19<29:12:54, 12.01s/it] 31%|███▏      | 3994/12750 [13:01:31<28:48:10, 11.84s/it] 31%|███▏      | 3995/12750 [13:01:42<28:31:21, 11.73s/it] 31%|███▏      | 3996/12750 [13:01:54<28:20:19, 11.65s/it] 31%|███▏      | 3997/12750 [13:02:05<28:11:41, 11.60s/it] 31%|███▏      | 3998/12750 [13:02:17<28:05:49, 11.56s/it] 31%|███▏      | 3999/12750 [13:02:28<28:01:08, 11.53s/it] 31%|███▏      | 4000/12750 [13:02:40<27:57:02, 11.50s/it]                                                           31%|███▏      | 4000/12750 [13:02:40<27:57:02, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120538.16lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104878.09lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4000
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4000/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4000/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3975] due to args.save_total_limit
 31%|███▏      | 4001/12750 [13:02:51<28:10:41, 11.59s/it] 31%|███▏      | 4002/12750 [13:03:03<28:04:49, 11.56s/it] 31%|███▏      | 4003/12750 [13:03:14<28:00:21, 11.53s/it] 31%|███▏      | 4004/12750 [13:03:26<27:56:25, 11.50s/it] 31%|███▏      | 4005/12750 [13:03:37<27:53:51, 11.48s/it] 31%|███▏      | 4006/12750 [13:03:49<27:53:38, 11.48s/it] 31%|███▏      | 4007/12750 [13:04:00<27:51:48, 11.47s/it] 31%|███▏      | 4008/12750 [13:04:12<27:52:16, 11.48s/it] 31%|███▏      | 4009/12750 [13:04:23<27:52:21, 11.48s/it] 31%|███▏      | 4010/12750 [13:04:35<27:51:20, 11.47s/it] 31%|███▏      | 4011/12750 [13:04:46<27:51:48, 11.48s/it] 31%|███▏      | 4012/12750 [13:04:58<27:50:40, 11.47s/it] 31%|███▏      | 4013/12750 [13:05:09<27:49:04, 11.46s/it] 31%|███▏      | 4014/12750 [13:05:20<27:48:25, 11.46s/it] 31%|███▏      | 4015/12750 [13:05:32<27:48:19, 11.46s/it] 31%|███▏      | 4016/12750 [13:05:43<27:48:19, 11.46s/it] 32%|███▏      | 4017/12750 [13:05:55<27:48:22, 11.46s/it] 32%|███▏      | 4018/12750 [13:06:06<27:48:26, 11.46s/it] 32%|███▏      | 4019/12750 [13:06:18<27:48:53, 11.47s/it] 32%|███▏      | 4020/12750 [13:06:29<27:48:59, 11.47s/it] 32%|███▏      | 4021/12750 [13:06:48<33:14:14, 13.71s/it] 32%|███▏      | 4022/12750 [13:07:00<31:35:10, 13.03s/it] 32%|███▏      | 4023/12750 [13:07:11<30:26:50, 12.56s/it] 32%|███▏      | 4024/12750 [13:07:23<29:37:48, 12.22s/it] 32%|███▏      | 4025/12750 [13:07:34<29:04:25, 12.00s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120587.71lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104891.30lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4025
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4025/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4025/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4000] due to args.save_total_limit
 32%|███▏      | 4026/12750 [13:07:46<28:53:59, 11.93s/it] 32%|███▏      | 4027/12750 [13:07:57<28:32:33, 11.78s/it] 32%|███▏      | 4028/12750 [13:08:09<28:17:33, 11.68s/it] 32%|███▏      | 4029/12750 [13:08:20<28:07:26, 11.61s/it] 32%|███▏      | 4030/12750 [13:08:32<27:59:27, 11.56s/it] 32%|███▏      | 4031/12750 [13:08:43<27:54:48, 11.53s/it] 32%|███▏      | 4032/12750 [13:08:54<27:52:01, 11.51s/it] 32%|███▏      | 4033/12750 [13:09:06<27:50:07, 11.50s/it] 32%|███▏      | 4034/12750 [13:09:17<27:48:23, 11.49s/it] 32%|███▏      | 4035/12750 [13:09:29<27:45:55, 11.47s/it] 32%|███▏      | 4036/12750 [13:09:40<27:44:29, 11.46s/it] 32%|███▏      | 4037/12750 [13:09:52<27:42:33, 11.45s/it] 32%|███▏      | 4038/12750 [13:10:03<27:42:52, 11.45s/it] 32%|███▏      | 4039/12750 [13:10:15<27:44:09, 11.46s/it] 32%|███▏      | 4040/12750 [13:10:26<27:43:04, 11.46s/it] 32%|███▏      | 4041/12750 [13:10:38<27:43:52, 11.46s/it] 32%|███▏      | 4042/12750 [13:10:49<27:43:36, 11.46s/it] 32%|███▏      | 4043/12750 [13:11:00<27:43:51, 11.47s/it] 32%|███▏      | 4044/12750 [13:11:12<27:43:18, 11.46s/it] 32%|███▏      | 4045/12750 [13:11:23<27:42:40, 11.46s/it] 32%|███▏      | 4046/12750 [13:11:35<27:43:18, 11.47s/it] 32%|███▏      | 4047/12750 [13:11:46<27:44:45, 11.48s/it] 32%|███▏      | 4048/12750 [13:11:58<27:43:12, 11.47s/it] 32%|███▏      | 4049/12750 [13:12:09<27:43:01, 11.47s/it] 32%|███▏      | 4050/12750 [13:12:21<27:41:26, 11.46s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120335.79lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104687.48lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4050
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4050/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4050/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-3925] due to args.save_total_limit
 32%|███▏      | 4051/12750 [13:12:32<27:54:11, 11.55s/it] 32%|███▏      | 4052/12750 [13:12:44<27:50:40, 11.52s/it] 32%|███▏      | 4053/12750 [13:13:02<32:39:48, 13.52s/it] 32%|███▏      | 4054/12750 [13:13:14<31:09:20, 12.90s/it] 32%|███▏      | 4055/12750 [13:13:25<30:06:04, 12.46s/it] 32%|███▏      | 4056/12750 [13:13:36<29:22:35, 12.16s/it] 32%|███▏      | 4057/12750 [13:13:48<28:53:43, 11.97s/it] 32%|███▏      | 4058/12750 [13:13:59<28:31:58, 11.82s/it] 32%|███▏      | 4059/12750 [13:14:11<28:16:39, 11.71s/it] 32%|███▏      | 4060/12750 [13:14:22<28:06:31, 11.64s/it] 32%|███▏      | 4061/12750 [13:14:34<27:58:12, 11.59s/it] 32%|███▏      | 4062/12750 [13:14:45<27:54:14, 11.56s/it] 32%|███▏      | 4063/12750 [13:14:57<27:50:43, 11.54s/it] 32%|███▏      | 4064/12750 [13:15:08<27:46:39, 11.51s/it] 32%|███▏      | 4065/12750 [13:15:20<27:45:47, 11.51s/it] 32%|███▏      | 4066/12750 [13:15:31<27:44:23, 11.50s/it] 32%|███▏      | 4067/12750 [13:15:43<27:44:22, 11.50s/it] 32%|███▏      | 4068/12750 [13:15:54<27:43:48, 11.50s/it] 32%|███▏      | 4069/12750 [13:16:06<27:42:09, 11.49s/it] 32%|███▏      | 4070/12750 [13:16:17<27:41:33, 11.49s/it] 32%|███▏      | 4071/12750 [13:16:29<27:42:26, 11.49s/it] 32%|███▏      | 4072/12750 [13:16:40<27:42:09, 11.49s/it] 32%|███▏      | 4073/12750 [13:16:52<27:41:15, 11.49s/it] 32%|███▏      | 4074/12750 [13:17:03<27:39:56, 11.48s/it] 32%|███▏      | 4075/12750 [13:17:15<27:39:13, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120543.55lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104862.75lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4075
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4075/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4075/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4025] due to args.save_total_limit
 32%|███▏      | 4076/12750 [13:17:26<27:54:01, 11.58s/it] 32%|███▏      | 4077/12750 [13:17:38<27:48:41, 11.54s/it] 32%|███▏      | 4078/12750 [13:17:49<27:44:21, 11.52s/it] 32%|███▏      | 4079/12750 [13:17:56<24:29:31, 10.17s/it] 32%|███▏      | 4080/12750 [13:17:57<17:42:48,  7.36s/it] 32%|███▏      | 4081/12750 [13:18:21<29:15:16, 12.15s/it] 32%|███▏      | 4082/12750 [13:18:32<28:47:12, 11.96s/it] 32%|███▏      | 4083/12750 [13:18:44<28:28:33, 11.83s/it] 32%|███▏      | 4084/12750 [13:18:55<28:15:53, 11.74s/it] 32%|███▏      | 4085/12750 [13:19:07<28:04:21, 11.66s/it] 32%|███▏      | 4086/12750 [13:19:26<33:30:28, 13.92s/it] 32%|███▏      | 4087/12750 [13:19:37<31:44:50, 13.19s/it] 32%|███▏      | 4088/12750 [13:19:49<30:30:39, 12.68s/it] 32%|███▏      | 4089/12750 [13:20:00<29:39:57, 12.33s/it] 32%|███▏      | 4090/12750 [13:20:12<29:05:11, 12.09s/it] 32%|███▏      | 4091/12750 [13:20:23<28:40:16, 11.92s/it] 32%|███▏      | 4092/12750 [13:20:35<28:20:06, 11.78s/it] 32%|███▏      | 4093/12750 [13:20:46<28:10:13, 11.71s/it] 32%|███▏      | 4094/12750 [13:20:58<27:59:47, 11.64s/it] 32%|███▏      | 4095/12750 [13:21:09<27:53:12, 11.60s/it] 32%|███▏      | 4096/12750 [13:21:21<27:49:38, 11.58s/it] 32%|███▏      | 4097/12750 [13:21:32<27:47:06, 11.56s/it] 32%|███▏      | 4098/12750 [13:21:44<27:44:16, 11.54s/it] 32%|███▏      | 4099/12750 [13:21:55<27:42:27, 11.53s/it] 32%|███▏      | 4100/12750 [13:22:07<27:41:24, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120392.72lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104731.15lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4100
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4100/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4100/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4075] due to args.save_total_limit
 32%|███▏      | 4101/12750 [13:22:19<28:00:02, 11.65s/it] 32%|███▏      | 4102/12750 [13:22:30<27:52:53, 11.61s/it] 32%|███▏      | 4103/12750 [13:22:42<27:54:07, 11.62s/it] 32%|███▏      | 4104/12750 [13:22:53<27:48:36, 11.58s/it] 32%|███▏      | 4105/12750 [13:23:05<27:51:26, 11.60s/it] 32%|███▏      | 4106/12750 [13:23:17<27:48:21, 11.58s/it] 32%|███▏      | 4107/12750 [13:23:28<27:45:33, 11.56s/it] 32%|███▏      | 4108/12750 [13:23:40<27:43:29, 11.55s/it] 32%|███▏      | 4109/12750 [13:23:51<27:43:58, 11.55s/it] 32%|███▏      | 4110/12750 [13:24:03<27:41:54, 11.54s/it] 32%|███▏      | 4111/12750 [13:24:14<27:40:33, 11.53s/it] 32%|███▏      | 4112/12750 [13:24:26<27:39:56, 11.53s/it] 32%|███▏      | 4113/12750 [13:24:37<27:40:13, 11.53s/it] 32%|███▏      | 4114/12750 [13:24:49<27:40:45, 11.54s/it] 32%|███▏      | 4115/12750 [13:25:01<27:44:44, 11.57s/it] 32%|███▏      | 4116/12750 [13:25:12<27:44:52, 11.57s/it] 32%|███▏      | 4117/12750 [13:25:24<27:42:31, 11.55s/it] 32%|███▏      | 4118/12750 [13:25:43<33:18:35, 13.89s/it] 32%|███▏      | 4119/12750 [13:25:54<31:33:21, 13.16s/it] 32%|███▏      | 4120/12750 [13:26:06<30:22:18, 12.67s/it] 32%|███▏      | 4121/12750 [13:26:17<29:32:22, 12.32s/it] 32%|███▏      | 4122/12750 [13:26:29<28:56:59, 12.08s/it] 32%|███▏      | 4123/12750 [13:26:40<28:32:11, 11.91s/it] 32%|███▏      | 4124/12750 [13:26:52<28:15:06, 11.79s/it] 32%|███▏      | 4125/12750 [13:27:04<28:04:15, 11.72s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120464.05lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104771.36lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4125
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4125/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4125/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4100] due to args.save_total_limit
 32%|███▏      | 4126/12750 [13:27:15<28:08:29, 11.75s/it] 32%|███▏      | 4127/12750 [13:27:27<28:00:54, 11.70s/it] 32%|███▏      | 4128/12750 [13:27:38<27:52:45, 11.64s/it] 32%|███▏      | 4129/12750 [13:27:50<27:46:15, 11.60s/it] 32%|███▏      | 4130/12750 [13:28:01<27:42:42, 11.57s/it] 32%|███▏      | 4131/12750 [13:28:13<27:40:16, 11.56s/it] 32%|███▏      | 4132/12750 [13:28:25<27:39:26, 11.55s/it] 32%|███▏      | 4133/12750 [13:28:36<27:39:29, 11.56s/it] 32%|███▏      | 4134/12750 [13:28:48<27:39:09, 11.55s/it] 32%|███▏      | 4135/12750 [13:28:59<27:37:16, 11.54s/it] 32%|███▏      | 4136/12750 [13:29:11<27:35:50, 11.53s/it] 32%|███▏      | 4137/12750 [13:29:22<27:35:14, 11.53s/it] 32%|███▏      | 4138/12750 [13:29:34<27:34:29, 11.53s/it] 32%|███▏      | 4139/12750 [13:29:45<27:33:05, 11.52s/it] 32%|███▏      | 4140/12750 [13:29:57<27:34:54, 11.53s/it] 32%|███▏      | 4141/12750 [13:30:08<27:34:08, 11.53s/it] 32%|███▏      | 4142/12750 [13:30:20<27:33:52, 11.53s/it] 32%|███▏      | 4143/12750 [13:30:31<27:31:12, 11.51s/it] 33%|███▎      | 4144/12750 [13:30:43<27:32:20, 11.52s/it] 33%|███▎      | 4145/12750 [13:30:54<27:31:57, 11.52s/it] 33%|███▎      | 4146/12750 [13:31:06<27:31:36, 11.52s/it] 33%|███▎      | 4147/12750 [13:31:17<27:31:44, 11.52s/it] 33%|███▎      | 4148/12750 [13:31:29<27:33:05, 11.53s/it] 33%|███▎      | 4149/12750 [13:31:40<27:32:39, 11.53s/it] 33%|███▎      | 4150/12750 [13:32:00<33:01:33, 13.82s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120282.75lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103624.18lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4150
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4150/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4150/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4125] due to args.save_total_limit
 33%|███▎      | 4151/12750 [13:32:12<31:43:46, 13.28s/it] 33%|███▎      | 4152/12750 [13:32:23<30:26:10, 12.74s/it] 33%|███▎      | 4153/12750 [13:32:35<29:30:03, 12.35s/it] 33%|███▎      | 4154/12750 [13:32:46<28:51:12, 12.08s/it] 33%|███▎      | 4155/12750 [13:32:58<28:26:34, 11.91s/it] 33%|███▎      | 4156/12750 [13:33:09<28:08:07, 11.79s/it] 33%|███▎      | 4157/12750 [13:33:21<27:57:11, 11.71s/it] 33%|███▎      | 4158/12750 [13:33:32<27:51:23, 11.67s/it] 33%|███▎      | 4159/12750 [13:33:44<27:46:51, 11.64s/it] 33%|███▎      | 4160/12750 [13:33:55<27:43:14, 11.62s/it] 33%|███▎      | 4161/12750 [13:34:07<27:40:13, 11.60s/it] 33%|███▎      | 4162/12750 [13:34:19<27:43:17, 11.62s/it] 33%|███▎      | 4163/12750 [13:34:30<27:39:39, 11.60s/it] 33%|███▎      | 4164/12750 [13:34:42<27:36:01, 11.57s/it] 33%|███▎      | 4165/12750 [13:34:53<27:33:47, 11.56s/it] 33%|███▎      | 4166/12750 [13:35:05<27:36:12, 11.58s/it] 33%|███▎      | 4167/12750 [13:35:16<27:37:37, 11.59s/it] 33%|███▎      | 4168/12750 [13:35:28<27:35:28, 11.57s/it] 33%|███▎      | 4169/12750 [13:35:39<27:37:09, 11.59s/it] 33%|███▎      | 4170/12750 [13:35:51<27:34:09, 11.57s/it] 33%|███▎      | 4171/12750 [13:36:02<27:30:02, 11.54s/it] 33%|███▎      | 4172/12750 [13:36:14<27:29:03, 11.53s/it] 33%|███▎      | 4173/12750 [13:36:26<27:30:10, 11.54s/it] 33%|███▎      | 4174/12750 [13:36:37<27:27:18, 11.53s/it] 33%|███▎      | 4175/12750 [13:36:49<27:26:09, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120643.72lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104927.75lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4175
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4175/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4175/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4150] due to args.save_total_limit
 33%|███▎      | 4176/12750 [13:37:00<27:38:24, 11.61s/it] 33%|███▎      | 4177/12750 [13:37:12<27:33:29, 11.57s/it] 33%|███▎      | 4178/12750 [13:37:23<27:27:50, 11.53s/it] 33%|███▎      | 4179/12750 [13:37:35<27:25:25, 11.52s/it] 33%|███▎      | 4180/12750 [13:37:46<27:23:23, 11.51s/it] 33%|███▎      | 4181/12750 [13:37:58<27:23:00, 11.50s/it] 33%|███▎      | 4182/12750 [13:38:09<27:25:22, 11.52s/it] 33%|███▎      | 4183/12750 [13:38:28<32:28:17, 13.65s/it] 33%|███▎      | 4184/12750 [13:38:39<30:55:55, 13.00s/it] 33%|███▎      | 4185/12750 [13:38:51<29:53:22, 12.56s/it] 33%|███▎      | 4186/12750 [13:39:03<29:09:06, 12.25s/it] 33%|███▎      | 4187/12750 [13:39:14<28:35:56, 12.02s/it] 33%|███▎      | 4188/12750 [13:39:26<28:13:57, 11.87s/it] 33%|███▎      | 4189/12750 [13:39:37<27:59:32, 11.77s/it] 33%|███▎      | 4190/12750 [13:39:49<27:48:06, 11.69s/it] 33%|███▎      | 4191/12750 [13:40:00<27:40:25, 11.64s/it] 33%|███▎      | 4192/12750 [13:40:12<27:34:27, 11.60s/it] 33%|███▎      | 4193/12750 [13:40:23<27:35:44, 11.61s/it] 33%|███▎      | 4194/12750 [13:40:35<27:35:00, 11.61s/it] 33%|███▎      | 4195/12750 [13:40:46<27:36:14, 11.62s/it] 33%|███▎      | 4196/12750 [13:40:58<27:34:05, 11.60s/it] 33%|███▎      | 4197/12750 [13:41:10<27:32:18, 11.59s/it] 33%|███▎      | 4198/12750 [13:41:21<27:30:28, 11.58s/it] 33%|███▎      | 4199/12750 [13:41:33<27:28:19, 11.57s/it] 33%|███▎      | 4200/12750 [13:41:44<27:26:01, 11.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120331.06lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104713.72lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4200
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4200/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4200/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4175] due to args.save_total_limit
 33%|███▎      | 4201/12750 [13:41:56<27:37:29, 11.63s/it] 33%|███▎      | 4202/12750 [13:42:08<27:32:14, 11.60s/it] 33%|███▎      | 4203/12750 [13:42:19<27:28:50, 11.57s/it] 33%|███▎      | 4204/12750 [13:42:31<27:24:48, 11.55s/it] 33%|███▎      | 4205/12750 [13:42:42<27:20:43, 11.52s/it] 33%|███▎      | 4206/12750 [13:42:53<27:20:14, 11.52s/it] 33%|███▎      | 4207/12750 [13:43:05<27:20:37, 11.52s/it] 33%|███▎      | 4208/12750 [13:43:17<27:21:08, 11.53s/it] 33%|███▎      | 4209/12750 [13:43:28<27:18:32, 11.51s/it] 33%|███▎      | 4210/12750 [13:43:40<27:17:51, 11.51s/it] 33%|███▎      | 4211/12750 [13:43:51<27:18:47, 11.52s/it] 33%|███▎      | 4212/12750 [13:44:03<27:16:48, 11.50s/it] 33%|███▎      | 4213/12750 [13:44:14<27:15:56, 11.50s/it] 33%|███▎      | 4214/12750 [13:44:26<27:16:33, 11.50s/it] 33%|███▎      | 4215/12750 [13:44:44<32:22:19, 13.65s/it] 33%|███▎      | 4216/12750 [13:44:56<30:50:32, 13.01s/it] 33%|███▎      | 4217/12750 [13:45:07<29:43:50, 12.54s/it] 33%|███▎      | 4218/12750 [13:45:19<28:59:48, 12.23s/it] 33%|███▎      | 4219/12750 [13:45:30<28:28:23, 12.02s/it] 33%|███▎      | 4220/12750 [13:45:42<28:04:27, 11.85s/it] 33%|███▎      | 4221/12750 [13:45:53<27:49:56, 11.75s/it] 33%|███▎      | 4222/12750 [13:46:05<27:39:16, 11.67s/it] 33%|███▎      | 4223/12750 [13:46:16<27:34:55, 11.64s/it] 33%|███▎      | 4224/12750 [13:46:28<27:28:07, 11.60s/it] 33%|███▎      | 4225/12750 [13:46:39<27:22:00, 11.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120491.10lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104811.89lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4225
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4225/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4225/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4200] due to args.save_total_limit
 33%|███▎      | 4226/12750 [13:46:51<27:32:12, 11.63s/it] 33%|███▎      | 4227/12750 [13:47:02<27:25:38, 11.58s/it] 33%|███▎      | 4228/12750 [13:47:14<27:21:39, 11.56s/it] 33%|███▎      | 4229/12750 [13:47:25<27:18:41, 11.54s/it] 33%|███▎      | 4230/12750 [13:47:37<27:21:35, 11.56s/it] 33%|███▎      | 4231/12750 [13:47:49<27:16:47, 11.53s/it] 33%|███▎      | 4232/12750 [13:48:00<27:17:22, 11.53s/it] 33%|███▎      | 4233/12750 [13:48:12<27:20:44, 11.56s/it] 33%|███▎      | 4234/12750 [13:48:23<27:23:33, 11.58s/it] 33%|███▎      | 4235/12750 [13:48:35<27:21:33, 11.57s/it] 33%|███▎      | 4236/12750 [13:48:46<27:20:44, 11.56s/it] 33%|███▎      | 4237/12750 [13:48:58<27:18:04, 11.55s/it] 33%|███▎      | 4238/12750 [13:49:09<27:16:22, 11.53s/it] 33%|███▎      | 4239/12750 [13:49:21<27:14:46, 11.52s/it] 33%|███▎      | 4240/12750 [13:49:32<27:13:30, 11.52s/it] 33%|███▎      | 4241/12750 [13:49:44<27:11:55, 11.51s/it] 33%|███▎      | 4242/12750 [13:49:55<27:10:50, 11.50s/it] 33%|███▎      | 4243/12750 [13:50:07<27:10:02, 11.50s/it] 33%|███▎      | 4244/12750 [13:50:18<27:08:56, 11.49s/it] 33%|███▎      | 4245/12750 [13:50:30<27:08:29, 11.49s/it] 33%|███▎      | 4246/12750 [13:50:41<27:09:04, 11.49s/it] 33%|███▎      | 4247/12750 [13:51:01<32:34:44, 13.79s/it] 33%|███▎      | 4248/12750 [13:51:12<30:55:25, 13.09s/it] 33%|███▎      | 4249/12750 [13:51:23<29:45:39, 12.60s/it] 33%|███▎      | 4250/12750 [13:51:35<28:58:13, 12.27s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120483.02lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104816.84lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4250
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4250/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4250/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4050] due to args.save_total_limit
 33%|███▎      | 4251/12750 [13:51:47<28:37:46, 12.13s/it] 33%|███▎      | 4252/12750 [13:51:58<28:09:55, 11.93s/it] 33%|███▎      | 4253/12750 [13:52:10<27:52:39, 11.81s/it] 33%|███▎      | 4254/12750 [13:52:21<27:39:53, 11.72s/it] 33%|███▎      | 4255/12750 [13:52:33<27:30:27, 11.66s/it] 33%|███▎      | 4256/12750 [13:52:44<27:24:40, 11.62s/it] 33%|███▎      | 4257/12750 [13:52:56<27:18:48, 11.58s/it] 33%|███▎      | 4258/12750 [13:53:07<27:15:31, 11.56s/it] 33%|███▎      | 4259/12750 [13:53:19<27:13:02, 11.54s/it] 33%|███▎      | 4260/12750 [13:53:30<27:09:33, 11.52s/it] 33%|███▎      | 4261/12750 [13:53:42<27:08:01, 11.51s/it] 33%|███▎      | 4262/12750 [13:53:53<27:07:02, 11.50s/it] 33%|███▎      | 4263/12750 [13:54:05<27:05:25, 11.49s/it] 33%|███▎      | 4264/12750 [13:54:16<27:04:26, 11.49s/it] 33%|███▎      | 4265/12750 [13:54:28<27:03:25, 11.48s/it] 33%|███▎      | 4266/12750 [13:54:39<27:03:00, 11.48s/it] 33%|███▎      | 4267/12750 [13:54:51<27:03:25, 11.48s/it] 33%|███▎      | 4268/12750 [13:55:02<27:03:59, 11.49s/it] 33%|███▎      | 4269/12750 [13:55:14<27:03:57, 11.49s/it] 33%|███▎      | 4270/12750 [13:55:25<27:02:55, 11.48s/it] 33%|███▎      | 4271/12750 [13:55:37<27:03:19, 11.49s/it] 34%|███▎      | 4272/12750 [13:55:48<27:03:07, 11.49s/it] 34%|███▎      | 4273/12750 [13:55:59<27:02:00, 11.48s/it] 34%|███▎      | 4274/12750 [13:56:11<27:02:54, 11.49s/it] 34%|███▎      | 4275/12750 [13:56:22<27:03:18, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120548.56lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104874.50lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4275
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4275/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4275/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4225] due to args.save_total_limit
 34%|███▎      | 4276/12750 [13:56:34<27:15:20, 11.58s/it] 34%|███▎      | 4277/12750 [13:56:46<27:13:00, 11.56s/it] 34%|███▎      | 4278/12750 [13:56:57<27:09:16, 11.54s/it] 34%|███▎      | 4279/12750 [13:57:16<31:56:30, 13.57s/it] 34%|███▎      | 4280/12750 [13:57:27<30:27:34, 12.95s/it] 34%|███▎      | 4281/12750 [13:57:39<29:24:35, 12.50s/it] 34%|███▎      | 4282/12750 [13:57:50<28:41:54, 12.20s/it] 34%|███▎      | 4283/12750 [13:58:01<28:09:03, 11.97s/it] 34%|███▎      | 4284/12750 [13:58:13<27:47:55, 11.82s/it] 34%|███▎      | 4285/12750 [13:58:24<27:32:43, 11.71s/it] 34%|███▎      | 4286/12750 [13:58:36<27:21:18, 11.63s/it] 34%|███▎      | 4287/12750 [13:58:47<27:13:58, 11.58s/it] 34%|███▎      | 4288/12750 [13:58:59<27:08:31, 11.55s/it] 34%|███▎      | 4289/12750 [13:59:10<27:03:55, 11.52s/it] 34%|███▎      | 4290/12750 [13:59:22<27:02:11, 11.50s/it] 34%|███▎      | 4291/12750 [13:59:33<27:01:00, 11.50s/it] 34%|███▎      | 4292/12750 [13:59:45<26:59:23, 11.49s/it] 34%|███▎      | 4293/12750 [13:59:56<26:58:08, 11.48s/it] 34%|███▎      | 4294/12750 [14:00:08<26:58:15, 11.48s/it] 34%|███▎      | 4295/12750 [14:00:19<26:57:01, 11.48s/it] 34%|███▎      | 4296/12750 [14:00:31<26:56:29, 11.47s/it] 34%|███▎      | 4297/12750 [14:00:42<26:55:42, 11.47s/it] 34%|███▎      | 4298/12750 [14:00:53<26:55:07, 11.47s/it] 34%|███▎      | 4299/12750 [14:01:05<26:54:10, 11.46s/it] 34%|███▎      | 4300/12750 [14:01:16<26:53:50, 11.46s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120036.30lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104467.39lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4300
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4300/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4300/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4250] due to args.save_total_limit
 34%|███▎      | 4301/12750 [14:01:28<27:11:14, 11.58s/it] 34%|███▎      | 4302/12750 [14:01:40<27:11:16, 11.59s/it] 34%|███▎      | 4303/12750 [14:01:51<27:11:42, 11.59s/it] 34%|███▍      | 4304/12750 [14:02:03<27:12:07, 11.59s/it] 34%|███▍      | 4305/12750 [14:02:15<27:12:01, 11.60s/it] 34%|███▍      | 4306/12750 [14:02:26<27:11:55, 11.60s/it] 34%|███▍      | 4307/12750 [14:02:38<27:12:06, 11.60s/it] 34%|███▍      | 4308/12750 [14:02:50<27:15:49, 11.63s/it] 34%|███▍      | 4309/12750 [14:03:01<27:17:51, 11.64s/it] 34%|███▍      | 4310/12750 [14:03:13<27:18:14, 11.65s/it] 34%|███▍      | 4311/12750 [14:03:32<32:43:32, 13.96s/it] 34%|███▍      | 4312/12750 [14:03:44<31:03:26, 13.25s/it] 34%|███▍      | 4313/12750 [14:03:55<29:56:17, 12.77s/it] 34%|███▍      | 4314/12750 [14:04:07<29:09:28, 12.44s/it] 34%|███▍      | 4315/12750 [14:04:19<28:37:06, 12.21s/it] 34%|███▍      | 4316/12750 [14:04:30<28:13:55, 12.05s/it] 34%|███▍      | 4317/12750 [14:04:42<27:58:08, 11.94s/it] 34%|███▍      | 4318/12750 [14:04:54<27:46:01, 11.86s/it] 34%|███▍      | 4319/12750 [14:05:05<27:37:00, 11.79s/it] 34%|███▍      | 4320/12750 [14:05:17<27:32:38, 11.76s/it] 34%|███▍      | 4321/12750 [14:05:29<27:27:55, 11.73s/it] 34%|███▍      | 4322/12750 [14:05:41<27:26:16, 11.72s/it] 34%|███▍      | 4323/12750 [14:05:52<27:24:53, 11.71s/it] 34%|███▍      | 4324/12750 [14:06:04<27:22:35, 11.70s/it] 34%|███▍      | 4325/12750 [14:06:16<27:22:13, 11.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120611.08lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104914.62lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4325
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4325/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4325/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4275] due to args.save_total_limit
 34%|███▍      | 4326/12750 [14:06:27<27:30:11, 11.75s/it] 34%|███▍      | 4327/12750 [14:06:39<27:22:50, 11.70s/it] 34%|███▍      | 4328/12750 [14:06:51<27:16:55, 11.66s/it] 34%|███▍      | 4329/12750 [14:07:02<27:12:31, 11.63s/it] 34%|███▍      | 4330/12750 [14:07:14<27:09:53, 11.61s/it] 34%|███▍      | 4331/12750 [14:07:25<27:07:13, 11.60s/it] 34%|███▍      | 4332/12750 [14:07:37<27:05:55, 11.59s/it] 34%|███▍      | 4333/12750 [14:07:48<27:06:51, 11.60s/it] 34%|███▍      | 4334/12750 [14:08:00<27:05:03, 11.59s/it] 34%|███▍      | 4335/12750 [14:08:12<27:02:40, 11.57s/it] 34%|███▍      | 4336/12750 [14:08:23<27:01:21, 11.56s/it] 34%|███▍      | 4337/12750 [14:08:35<27:00:44, 11.56s/it] 34%|███▍      | 4338/12750 [14:08:46<27:00:39, 11.56s/it] 34%|███▍      | 4339/12750 [14:08:58<26:59:25, 11.55s/it] 34%|███▍      | 4340/12750 [14:09:09<26:59:28, 11.55s/it] 34%|███▍      | 4341/12750 [14:09:21<26:56:31, 11.53s/it] 34%|███▍      | 4342/12750 [14:09:32<26:53:12, 11.51s/it] 34%|███▍      | 4343/12750 [14:09:51<32:14:48, 13.81s/it] 34%|███▍      | 4344/12750 [14:10:03<30:43:02, 13.16s/it] 34%|███▍      | 4345/12750 [14:10:15<29:33:00, 12.66s/it] 34%|███▍      | 4346/12750 [14:10:26<28:43:44, 12.31s/it] 34%|███▍      | 4347/12750 [14:10:38<28:09:15, 12.06s/it] 34%|███▍      | 4348/12750 [14:10:49<27:46:33, 11.90s/it] 34%|███▍      | 4349/12750 [14:11:01<27:30:57, 11.79s/it] 34%|███▍      | 4350/12750 [14:11:12<27:18:01, 11.70s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120529.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104491.97lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4350
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4350/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4350/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4325] due to args.save_total_limit
 34%|███▍      | 4351/12750 [14:11:24<27:25:59, 11.76s/it] 34%|███▍      | 4352/12750 [14:11:35<27:15:08, 11.68s/it] 34%|███▍      | 4353/12750 [14:11:47<27:08:56, 11.64s/it] 34%|███▍      | 4354/12750 [14:11:59<27:03:09, 11.60s/it] 34%|███▍      | 4355/12750 [14:12:10<27:00:49, 11.58s/it] 34%|███▍      | 4356/12750 [14:12:22<26:58:01, 11.57s/it] 34%|███▍      | 4357/12750 [14:12:33<26:55:41, 11.55s/it] 34%|███▍      | 4358/12750 [14:12:45<26:54:13, 11.54s/it] 34%|███▍      | 4359/12750 [14:12:56<26:51:40, 11.52s/it] 34%|███▍      | 4360/12750 [14:13:08<26:52:04, 11.53s/it] 34%|███▍      | 4361/12750 [14:13:19<26:50:28, 11.52s/it] 34%|███▍      | 4362/12750 [14:13:31<26:51:01, 11.52s/it] 34%|███▍      | 4363/12750 [14:13:42<26:47:47, 11.50s/it] 34%|███▍      | 4364/12750 [14:13:54<26:49:21, 11.51s/it] 34%|███▍      | 4365/12750 [14:14:05<26:48:43, 11.51s/it] 34%|███▍      | 4366/12750 [14:14:17<26:47:57, 11.51s/it] 34%|███▍      | 4367/12750 [14:14:28<26:47:51, 11.51s/it] 34%|███▍      | 4368/12750 [14:14:40<26:49:04, 11.52s/it] 34%|███▍      | 4369/12750 [14:14:51<26:48:10, 11.51s/it] 34%|███▍      | 4370/12750 [14:15:03<26:49:41, 11.53s/it] 34%|███▍      | 4371/12750 [14:15:14<26:50:14, 11.53s/it] 34%|███▍      | 4372/12750 [14:15:26<26:49:18, 11.53s/it] 34%|███▍      | 4373/12750 [14:15:37<26:48:31, 11.52s/it] 34%|███▍      | 4374/12750 [14:15:49<26:46:25, 11.51s/it] 34%|███▍      | 4375/12750 [14:16:08<32:08:11, 13.81s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120651.69lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104947.19lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4375
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4375/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4375/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4350] due to args.save_total_limit
 34%|███▍      | 4376/12750 [14:16:20<30:46:20, 13.23s/it] 34%|███▍      | 4377/12750 [14:16:31<29:31:27, 12.69s/it] 34%|███▍      | 4378/12750 [14:16:43<28:39:55, 12.33s/it] 34%|███▍      | 4379/12750 [14:16:54<28:04:24, 12.07s/it] 34%|███▍      | 4380/12750 [14:17:06<27:38:18, 11.89s/it] 34%|███▍      | 4381/12750 [14:17:17<27:22:48, 11.78s/it] 34%|███▍      | 4382/12750 [14:17:29<27:10:42, 11.69s/it] 34%|███▍      | 4383/12750 [14:17:40<27:06:41, 11.67s/it] 34%|███▍      | 4384/12750 [14:17:52<26:58:05, 11.60s/it] 34%|███▍      | 4385/12750 [14:18:03<26:54:09, 11.58s/it] 34%|███▍      | 4386/12750 [14:18:15<26:50:04, 11.55s/it] 34%|███▍      | 4387/12750 [14:18:27<26:56:02, 11.59s/it] 34%|███▍      | 4388/12750 [14:18:38<26:48:34, 11.54s/it] 34%|███▍      | 4389/12750 [14:18:49<26:43:27, 11.51s/it] 34%|███▍      | 4390/12750 [14:19:01<26:40:06, 11.48s/it] 34%|███▍      | 4391/12750 [14:19:12<26:39:11, 11.48s/it] 34%|███▍      | 4392/12750 [14:19:24<26:37:56, 11.47s/it] 34%|███▍      | 4393/12750 [14:19:35<26:36:56, 11.47s/it] 34%|███▍      | 4394/12750 [14:19:47<26:36:35, 11.46s/it] 34%|███▍      | 4395/12750 [14:19:58<26:35:40, 11.46s/it] 34%|███▍      | 4396/12750 [14:20:10<26:34:39, 11.45s/it] 34%|███▍      | 4397/12750 [14:20:21<26:33:53, 11.45s/it] 34%|███▍      | 4398/12750 [14:20:32<26:33:23, 11.45s/it] 35%|███▍      | 4399/12750 [14:20:44<26:33:31, 11.45s/it] 35%|███▍      | 4400/12750 [14:20:55<26:32:03, 11.44s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120693.61lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104983.48lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4400
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4400/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4400/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4375] due to args.save_total_limit
 35%|███▍      | 4401/12750 [14:21:07<26:44:42, 11.53s/it] 35%|███▍      | 4402/12750 [14:21:18<26:38:51, 11.49s/it] 35%|███▍      | 4403/12750 [14:21:30<26:36:25, 11.48s/it] 35%|███▍      | 4404/12750 [14:21:41<26:33:45, 11.46s/it] 35%|███▍      | 4405/12750 [14:21:53<26:31:48, 11.44s/it] 35%|███▍      | 4406/12750 [14:22:04<26:33:00, 11.46s/it] 35%|███▍      | 4407/12750 [14:22:23<31:56:13, 13.78s/it] 35%|███▍      | 4408/12750 [14:22:35<30:18:48, 13.08s/it] 35%|███▍      | 4409/12750 [14:22:46<29:12:53, 12.61s/it] 35%|███▍      | 4410/12750 [14:22:58<28:24:05, 12.26s/it] 35%|███▍      | 4411/12750 [14:23:09<27:49:34, 12.01s/it] 35%|███▍      | 4412/12750 [14:23:21<27:27:09, 11.85s/it] 35%|███▍      | 4413/12750 [14:23:32<27:10:28, 11.73s/it] 35%|███▍      | 4414/12750 [14:23:44<27:00:08, 11.66s/it] 35%|███▍      | 4415/12750 [14:23:55<26:51:56, 11.60s/it] 35%|███▍      | 4416/12750 [14:24:07<26:44:48, 11.55s/it] 35%|███▍      | 4417/12750 [14:24:18<26:41:03, 11.53s/it] 35%|███▍      | 4418/12750 [14:24:29<26:36:53, 11.50s/it] 35%|███▍      | 4419/12750 [14:24:41<26:34:36, 11.48s/it] 35%|███▍      | 4420/12750 [14:24:52<26:34:04, 11.48s/it] 35%|███▍      | 4421/12750 [14:25:04<26:32:46, 11.47s/it] 35%|███▍      | 4422/12750 [14:25:15<26:33:48, 11.48s/it] 35%|███▍      | 4423/12750 [14:25:27<26:34:07, 11.49s/it] 35%|███▍      | 4424/12750 [14:25:38<26:32:25, 11.48s/it] 35%|███▍      | 4425/12750 [14:25:50<26:30:30, 11.46s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120677.53lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104962.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4425
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4425/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4425/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4400] due to args.save_total_limit
 35%|███▍      | 4426/12750 [14:26:02<26:47:52, 11.59s/it] 35%|███▍      | 4427/12750 [14:26:13<26:41:59, 11.55s/it] 35%|███▍      | 4428/12750 [14:26:25<26:42:48, 11.56s/it] 35%|███▍      | 4429/12750 [14:26:36<26:36:46, 11.51s/it] 35%|███▍      | 4430/12750 [14:26:48<26:34:20, 11.50s/it] 35%|███▍      | 4431/12750 [14:26:59<26:31:24, 11.48s/it] 35%|███▍      | 4432/12750 [14:27:10<26:28:52, 11.46s/it] 35%|███▍      | 4433/12750 [14:27:22<26:26:26, 11.44s/it] 35%|███▍      | 4434/12750 [14:27:33<26:27:37, 11.45s/it] 35%|███▍      | 4435/12750 [14:27:45<26:28:01, 11.46s/it] 35%|███▍      | 4436/12750 [14:27:56<26:28:31, 11.46s/it] 35%|███▍      | 4437/12750 [14:28:08<26:25:43, 11.45s/it] 35%|███▍      | 4438/12750 [14:28:19<26:25:16, 11.44s/it] 35%|███▍      | 4439/12750 [14:28:30<26:25:13, 11.44s/it] 35%|███▍      | 4440/12750 [14:28:50<31:45:05, 13.76s/it] 35%|███▍      | 4441/12750 [14:29:01<30:09:30, 13.07s/it] 35%|███▍      | 4442/12750 [14:29:13<29:02:35, 12.58s/it] 35%|███▍      | 4443/12750 [14:29:24<28:14:39, 12.24s/it] 35%|███▍      | 4444/12750 [14:29:35<27:41:42, 12.00s/it] 35%|███▍      | 4445/12750 [14:29:47<27:18:17, 11.84s/it] 35%|███▍      | 4446/12750 [14:29:58<27:01:22, 11.72s/it] 35%|███▍      | 4447/12750 [14:30:10<26:49:52, 11.63s/it] 35%|███▍      | 4448/12750 [14:30:21<26:42:22, 11.58s/it] 35%|███▍      | 4449/12750 [14:30:33<26:37:43, 11.55s/it] 35%|███▍      | 4450/12750 [14:30:44<26:33:53, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120598.88lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104912.39lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4450
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4450/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4450/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4425] due to args.save_total_limit
 35%|███▍      | 4451/12750 [14:30:56<26:44:36, 11.60s/it] 35%|███▍      | 4452/12750 [14:31:07<26:37:19, 11.55s/it] 35%|███▍      | 4453/12750 [14:31:19<26:33:49, 11.53s/it] 35%|███▍      | 4454/12750 [14:31:30<26:30:10, 11.50s/it] 35%|███▍      | 4455/12750 [14:31:42<26:28:15, 11.49s/it] 35%|███▍      | 4456/12750 [14:31:53<26:27:08, 11.48s/it] 35%|███▍      | 4457/12750 [14:32:05<26:24:06, 11.46s/it] 35%|███▍      | 4458/12750 [14:32:16<26:24:38, 11.47s/it] 35%|███▍      | 4459/12750 [14:32:28<26:24:29, 11.47s/it] 35%|███▍      | 4460/12750 [14:32:39<26:23:33, 11.46s/it] 35%|███▍      | 4461/12750 [14:32:50<26:21:12, 11.45s/it] 35%|███▍      | 4462/12750 [14:33:02<26:21:51, 11.45s/it] 35%|███▌      | 4463/12750 [14:33:13<26:22:16, 11.46s/it] 35%|███▌      | 4464/12750 [14:33:25<26:22:14, 11.46s/it] 35%|███▌      | 4465/12750 [14:33:36<26:20:51, 11.45s/it] 35%|███▌      | 4466/12750 [14:33:48<26:22:42, 11.46s/it] 35%|███▌      | 4467/12750 [14:33:59<26:21:26, 11.46s/it] 35%|███▌      | 4468/12750 [14:34:11<26:24:47, 11.48s/it] 35%|███▌      | 4469/12750 [14:34:22<26:23:43, 11.47s/it] 35%|███▌      | 4470/12750 [14:34:34<26:24:18, 11.48s/it] 35%|███▌      | 4471/12750 [14:34:45<26:22:40, 11.47s/it] 35%|███▌      | 4472/12750 [14:35:04<31:14:32, 13.59s/it] 35%|███▌      | 4473/12750 [14:35:15<29:46:39, 12.95s/it] 35%|███▌      | 4474/12750 [14:35:27<28:45:03, 12.51s/it] 35%|███▌      | 4475/12750 [14:35:38<27:58:02, 12.17s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120563.32lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104500.46lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4475
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4475/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4475/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4450] due to args.save_total_limit
 35%|███▌      | 4476/12750 [14:35:50<27:46:53, 12.09s/it] 35%|███▌      | 4477/12750 [14:36:01<27:20:54, 11.90s/it] 35%|███▌      | 4478/12750 [14:36:13<27:02:37, 11.77s/it] 35%|███▌      | 4479/12750 [14:36:24<26:47:42, 11.66s/it] 35%|███▌      | 4480/12750 [14:36:36<26:40:44, 11.61s/it] 35%|███▌      | 4481/12750 [14:36:47<26:34:24, 11.57s/it] 35%|███▌      | 4482/12750 [14:36:59<26:29:13, 11.53s/it] 35%|███▌      | 4483/12750 [14:37:10<26:25:20, 11.51s/it] 35%|███▌      | 4484/12750 [14:37:21<26:22:13, 11.48s/it] 35%|███▌      | 4485/12750 [14:37:33<26:18:51, 11.46s/it] 35%|███▌      | 4486/12750 [14:37:44<26:17:57, 11.46s/it] 35%|███▌      | 4487/12750 [14:37:56<26:17:15, 11.45s/it] 35%|███▌      | 4488/12750 [14:38:07<26:17:18, 11.45s/it] 35%|███▌      | 4489/12750 [14:38:19<26:17:48, 11.46s/it] 35%|███▌      | 4490/12750 [14:38:30<26:16:51, 11.45s/it] 35%|███▌      | 4491/12750 [14:38:42<26:17:13, 11.46s/it] 35%|███▌      | 4492/12750 [14:38:53<26:17:23, 11.46s/it] 35%|███▌      | 4493/12750 [14:39:05<26:17:03, 11.46s/it] 35%|███▌      | 4494/12750 [14:39:16<26:16:12, 11.45s/it] 35%|███▌      | 4495/12750 [14:39:27<26:15:57, 11.45s/it] 35%|███▌      | 4496/12750 [14:39:39<26:15:42, 11.45s/it] 35%|███▌      | 4497/12750 [14:39:50<26:15:39, 11.46s/it] 35%|███▌      | 4498/12750 [14:40:02<26:14:55, 11.45s/it] 35%|███▌      | 4499/12750 [14:40:13<26:13:49, 11.44s/it] 35%|███▌      | 4500/12750 [14:40:25<26:12:31, 11.44s/it]                                                           35%|███▌      | 4500/12750 [14:40:25<26:12:31, 11.44s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120744.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 105080.60lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4500
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4500/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4500/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4300] due to args.save_total_limit
 35%|███▌      | 4501/12750 [14:40:37<26:31:18, 11.57s/it] 35%|███▌      | 4502/12750 [14:40:48<26:25:26, 11.53s/it] 35%|███▌      | 4503/12750 [14:40:59<26:22:47, 11.52s/it] 35%|███▌      | 4504/12750 [14:41:19<31:43:08, 13.85s/it] 35%|███▌      | 4505/12750 [14:41:30<30:03:51, 13.13s/it] 35%|███▌      | 4506/12750 [14:41:42<28:52:30, 12.61s/it] 35%|███▌      | 4507/12750 [14:41:53<28:04:25, 12.26s/it] 35%|███▌      | 4508/12750 [14:42:05<27:32:03, 12.03s/it] 35%|███▌      | 4509/12750 [14:42:16<27:07:58, 11.85s/it] 35%|███▌      | 4510/12750 [14:42:27<26:51:51, 11.74s/it] 35%|███▌      | 4511/12750 [14:42:39<26:39:48, 11.65s/it] 35%|███▌      | 4512/12750 [14:42:50<26:30:46, 11.59s/it] 35%|███▌      | 4513/12750 [14:43:02<26:23:20, 11.53s/it] 35%|███▌      | 4514/12750 [14:43:13<26:19:40, 11.51s/it] 35%|███▌      | 4515/12750 [14:43:25<26:15:51, 11.48s/it] 35%|███▌      | 4516/12750 [14:43:36<26:14:49, 11.48s/it] 35%|███▌      | 4517/12750 [14:43:47<26:13:17, 11.47s/it] 35%|███▌      | 4518/12750 [14:43:59<26:13:40, 11.47s/it] 35%|███▌      | 4519/12750 [14:44:10<26:12:18, 11.46s/it] 35%|███▌      | 4520/12750 [14:44:22<26:11:56, 11.46s/it] 35%|███▌      | 4521/12750 [14:44:33<26:10:26, 11.45s/it] 35%|███▌      | 4522/12750 [14:44:45<26:09:58, 11.45s/it] 35%|███▌      | 4523/12750 [14:44:56<26:09:14, 11.44s/it] 35%|███▌      | 4524/12750 [14:45:08<26:09:14, 11.45s/it] 35%|███▌      | 4525/12750 [14:45:19<26:08:52, 11.44s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120573.71lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104857.60lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4525
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4525/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4525/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4475] due to args.save_total_limit
 35%|███▌      | 4526/12750 [14:45:31<26:22:31, 11.55s/it] 36%|███▌      | 4527/12750 [14:45:42<26:17:49, 11.51s/it] 36%|███▌      | 4528/12750 [14:45:54<26:15:10, 11.49s/it] 36%|███▌      | 4529/12750 [14:46:05<26:12:35, 11.48s/it] 36%|███▌      | 4530/12750 [14:46:17<26:11:26, 11.47s/it] 36%|███▌      | 4531/12750 [14:46:28<26:11:04, 11.47s/it] 36%|███▌      | 4532/12750 [14:46:40<26:13:09, 11.49s/it] 36%|███▌      | 4533/12750 [14:46:51<26:13:20, 11.49s/it] 36%|███▌      | 4534/12750 [14:47:03<26:11:39, 11.48s/it] 36%|███▌      | 4535/12750 [14:47:14<26:10:46, 11.47s/it] 36%|███▌      | 4536/12750 [14:47:33<31:30:20, 13.81s/it] 36%|███▌      | 4537/12750 [14:47:45<29:57:52, 13.13s/it] 36%|███▌      | 4538/12750 [14:47:56<28:49:37, 12.64s/it] 36%|███▌      | 4539/12750 [14:48:08<28:03:02, 12.30s/it] 36%|███▌      | 4540/12750 [14:48:19<27:30:24, 12.06s/it] 36%|███▌      | 4541/12750 [14:48:31<27:05:47, 11.88s/it] 36%|███▌      | 4542/12750 [14:48:42<26:48:31, 11.76s/it] 36%|███▌      | 4543/12750 [14:48:54<26:34:26, 11.66s/it] 36%|███▌      | 4544/12750 [14:49:05<26:25:42, 11.59s/it] 36%|███▌      | 4545/12750 [14:49:17<26:19:43, 11.55s/it] 36%|███▌      | 4546/12750 [14:49:28<26:14:40, 11.52s/it] 36%|███▌      | 4547/12750 [14:49:39<26:11:50, 11.50s/it] 36%|███▌      | 4548/12750 [14:49:51<26:10:35, 11.49s/it] 36%|███▌      | 4549/12750 [14:50:02<26:08:26, 11.47s/it] 36%|███▌      | 4550/12750 [14:50:14<26:07:44, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120574.87lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104664.46lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4550
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4550/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4550/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4500] due to args.save_total_limit
 36%|███▌      | 4551/12750 [14:50:26<26:20:50, 11.57s/it] 36%|███▌      | 4552/12750 [14:50:37<26:16:14, 11.54s/it] 36%|███▌      | 4553/12750 [14:50:49<26:12:45, 11.51s/it] 36%|███▌      | 4554/12750 [14:51:00<26:11:22, 11.50s/it] 36%|███▌      | 4555/12750 [14:51:11<26:08:41, 11.49s/it] 36%|███▌      | 4556/12750 [14:51:23<26:07:44, 11.48s/it] 36%|███▌      | 4557/12750 [14:51:34<26:06:42, 11.47s/it] 36%|███▌      | 4558/12750 [14:51:46<26:06:01, 11.47s/it] 36%|███▌      | 4559/12750 [14:51:57<26:04:06, 11.46s/it] 36%|███▌      | 4560/12750 [14:52:09<26:04:18, 11.46s/it] 36%|███▌      | 4561/12750 [14:52:20<26:04:32, 11.46s/it] 36%|███▌      | 4562/12750 [14:52:32<26:03:32, 11.46s/it] 36%|███▌      | 4563/12750 [14:52:43<26:02:13, 11.45s/it] 36%|███▌      | 4564/12750 [14:52:55<26:02:03, 11.45s/it] 36%|███▌      | 4565/12750 [14:53:06<26:02:21, 11.45s/it] 36%|███▌      | 4566/12750 [14:53:18<26:02:52, 11.46s/it] 36%|███▌      | 4567/12750 [14:53:29<26:04:18, 11.47s/it] 36%|███▌      | 4568/12750 [14:53:48<31:17:52, 13.77s/it] 36%|███▌      | 4569/12750 [14:54:00<29:41:00, 13.06s/it] 36%|███▌      | 4570/12750 [14:54:11<28:35:29, 12.58s/it] 36%|███▌      | 4571/12750 [14:54:22<27:49:45, 12.25s/it] 36%|███▌      | 4572/12750 [14:54:34<27:17:32, 12.01s/it] 36%|███▌      | 4573/12750 [14:54:45<26:54:28, 11.85s/it] 36%|███▌      | 4574/12750 [14:54:57<26:36:47, 11.72s/it] 36%|███▌      | 4575/12750 [14:55:08<26:25:29, 11.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120492.38lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104757.89lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4575
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4575/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4575/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4525] due to args.save_total_limit
 36%|███▌      | 4576/12750 [14:55:20<26:33:20, 11.70s/it] 36%|███▌      | 4577/12750 [14:55:32<26:28:21, 11.66s/it] 36%|███▌      | 4578/12750 [14:55:43<26:23:23, 11.63s/it] 36%|███▌      | 4579/12750 [14:55:55<26:20:21, 11.60s/it] 36%|███▌      | 4580/12750 [14:56:06<26:17:24, 11.58s/it] 36%|███▌      | 4581/12750 [14:56:18<26:16:47, 11.58s/it] 36%|███▌      | 4582/12750 [14:56:29<26:14:09, 11.56s/it] 36%|███▌      | 4583/12750 [14:56:41<26:13:51, 11.56s/it] 36%|███▌      | 4584/12750 [14:56:52<26:12:03, 11.55s/it] 36%|███▌      | 4585/12750 [14:57:04<26:13:14, 11.56s/it] 36%|███▌      | 4586/12750 [14:57:16<26:08:56, 11.53s/it] 36%|███▌      | 4587/12750 [14:57:27<26:09:37, 11.54s/it] 36%|███▌      | 4588/12750 [14:57:39<26:06:08, 11.51s/it] 36%|███▌      | 4589/12750 [14:57:46<23:03:20, 10.17s/it] 36%|███▌      | 4590/12750 [14:57:46<16:40:26,  7.36s/it] 36%|███▌      | 4591/12750 [14:58:10<27:26:10, 12.11s/it] 36%|███▌      | 4592/12750 [14:58:21<27:01:27, 11.93s/it] 36%|███▌      | 4593/12750 [14:58:33<26:42:40, 11.79s/it] 36%|███▌      | 4594/12750 [14:58:44<26:29:36, 11.69s/it] 36%|███▌      | 4595/12750 [14:58:55<26:19:10, 11.62s/it] 36%|███▌      | 4596/12750 [14:59:07<26:12:37, 11.57s/it] 36%|███▌      | 4597/12750 [14:59:18<26:09:02, 11.55s/it] 36%|███▌      | 4598/12750 [14:59:30<26:05:43, 11.52s/it] 36%|███▌      | 4599/12750 [14:59:41<26:03:33, 11.51s/it] 36%|███▌      | 4600/12750 [14:59:53<26:02:51, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120750.75lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104964.90lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4600
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4600/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4600/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4550] due to args.save_total_limit
 36%|███▌      | 4601/12750 [15:00:12<31:26:41, 13.89s/it] 36%|███▌      | 4602/12750 [15:00:24<29:49:08, 13.17s/it] 36%|███▌      | 4603/12750 [15:00:35<28:40:40, 12.67s/it] 36%|███▌      | 4604/12750 [15:00:47<27:51:41, 12.31s/it] 36%|███▌      | 4605/12750 [15:00:58<27:17:32, 12.06s/it] 36%|███▌      | 4606/12750 [15:01:10<26:51:54, 11.88s/it] 36%|███▌      | 4607/12750 [15:01:21<26:34:40, 11.75s/it] 36%|███▌      | 4608/12750 [15:01:33<26:22:45, 11.66s/it] 36%|███▌      | 4609/12750 [15:01:44<26:14:38, 11.61s/it] 36%|███▌      | 4610/12750 [15:01:56<26:08:29, 11.56s/it] 36%|███▌      | 4611/12750 [15:02:07<26:04:39, 11.53s/it] 36%|███▌      | 4612/12750 [15:02:18<26:01:56, 11.52s/it] 36%|███▌      | 4613/12750 [15:02:30<26:01:03, 11.51s/it] 36%|███▌      | 4614/12750 [15:02:41<25:58:19, 11.49s/it] 36%|███▌      | 4615/12750 [15:02:53<25:57:08, 11.48s/it] 36%|███▌      | 4616/12750 [15:03:04<25:57:32, 11.49s/it] 36%|███▌      | 4617/12750 [15:03:16<25:57:13, 11.49s/it] 36%|███▌      | 4618/12750 [15:03:27<25:56:09, 11.48s/it] 36%|███▌      | 4619/12750 [15:03:39<25:55:23, 11.48s/it] 36%|███▌      | 4620/12750 [15:03:50<25:55:20, 11.48s/it] 36%|███▌      | 4621/12750 [15:04:02<25:55:10, 11.48s/it] 36%|███▋      | 4622/12750 [15:04:13<25:55:37, 11.48s/it] 36%|███▋      | 4623/12750 [15:04:25<25:54:11, 11.47s/it] 36%|███▋      | 4624/12750 [15:04:36<25:56:24, 11.49s/it] 36%|███▋      | 4625/12750 [15:04:48<25:55:59, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120581.03lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104849.83lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4625
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4625/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4625/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4600] due to args.save_total_limit
 36%|███▋      | 4626/12750 [15:05:00<26:07:22, 11.58s/it] 36%|███▋      | 4627/12750 [15:05:11<26:03:06, 11.55s/it] 36%|███▋      | 4628/12750 [15:05:23<26:01:02, 11.53s/it] 36%|███▋      | 4629/12750 [15:05:34<25:57:27, 11.51s/it] 36%|███▋      | 4630/12750 [15:05:45<25:56:24, 11.50s/it] 36%|███▋      | 4631/12750 [15:05:57<25:55:03, 11.49s/it] 36%|███▋      | 4632/12750 [15:06:08<25:54:28, 11.49s/it] 36%|███▋      | 4633/12750 [15:06:28<31:07:15, 13.80s/it] 36%|███▋      | 4634/12750 [15:06:39<29:32:16, 13.10s/it] 36%|███▋      | 4635/12750 [15:06:51<28:25:35, 12.61s/it] 36%|███▋      | 4636/12750 [15:07:02<27:38:38, 12.27s/it] 36%|███▋      | 4637/12750 [15:07:13<27:06:01, 12.03s/it] 36%|███▋      | 4638/12750 [15:07:25<26:42:46, 11.85s/it] 36%|███▋      | 4639/12750 [15:07:36<26:26:49, 11.74s/it] 36%|███▋      | 4640/12750 [15:07:48<26:15:52, 11.66s/it] 36%|███▋      | 4641/12750 [15:07:59<26:07:29, 11.60s/it] 36%|███▋      | 4642/12750 [15:08:11<26:02:00, 11.56s/it] 36%|███▋      | 4643/12750 [15:08:22<25:58:51, 11.54s/it] 36%|███▋      | 4644/12750 [15:08:34<25:56:14, 11.52s/it] 36%|███▋      | 4645/12750 [15:08:45<25:54:39, 11.51s/it] 36%|███▋      | 4646/12750 [15:08:57<25:52:53, 11.50s/it] 36%|███▋      | 4647/12750 [15:09:08<25:52:02, 11.49s/it] 36%|███▋      | 4648/12750 [15:09:20<25:50:02, 11.48s/it] 36%|███▋      | 4649/12750 [15:09:31<25:48:38, 11.47s/it] 36%|███▋      | 4650/12750 [15:09:43<25:48:24, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120642.69lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104975.31lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4650
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4650/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4650/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4625] due to args.save_total_limit
 36%|███▋      | 4651/12750 [15:09:54<26:00:39, 11.56s/it] 36%|███▋      | 4652/12750 [15:10:06<25:57:30, 11.54s/it] 36%|███▋      | 4653/12750 [15:10:17<25:54:16, 11.52s/it] 37%|███▋      | 4654/12750 [15:10:29<25:52:13, 11.50s/it] 37%|███▋      | 4655/12750 [15:10:40<25:49:23, 11.48s/it] 37%|███▋      | 4656/12750 [15:10:52<25:46:18, 11.46s/it] 37%|███▋      | 4657/12750 [15:11:03<25:47:04, 11.47s/it] 37%|███▋      | 4658/12750 [15:11:15<25:48:24, 11.48s/it] 37%|███▋      | 4659/12750 [15:11:26<25:47:40, 11.48s/it] 37%|███▋      | 4660/12750 [15:11:38<25:53:23, 11.52s/it] 37%|███▋      | 4661/12750 [15:11:49<25:51:25, 11.51s/it] 37%|███▋      | 4662/12750 [15:12:01<25:49:36, 11.50s/it] 37%|███▋      | 4663/12750 [15:12:12<25:49:04, 11.49s/it] 37%|███▋      | 4664/12750 [15:12:24<25:49:02, 11.49s/it] 37%|███▋      | 4665/12750 [15:12:43<30:58:48, 13.79s/it] 37%|███▋      | 4666/12750 [15:12:54<29:23:08, 13.09s/it] 37%|███▋      | 4667/12750 [15:13:06<28:18:14, 12.61s/it] 37%|███▋      | 4668/12750 [15:13:17<27:31:59, 12.26s/it] 37%|███▋      | 4669/12750 [15:13:29<26:59:39, 12.03s/it] 37%|███▋      | 4670/12750 [15:13:40<26:35:35, 11.85s/it] 37%|███▋      | 4671/12750 [15:13:52<26:20:51, 11.74s/it] 37%|███▋      | 4672/12750 [15:14:03<26:09:10, 11.66s/it] 37%|███▋      | 4673/12750 [15:14:15<26:03:05, 11.61s/it] 37%|███▋      | 4674/12750 [15:14:26<25:55:32, 11.56s/it] 37%|███▋      | 4675/12750 [15:14:37<25:51:27, 11.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120476.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104797.63lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4675
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4675/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4675/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4650] due to args.save_total_limit
 37%|███▋      | 4676/12750 [15:14:49<26:00:47, 11.60s/it] 37%|███▋      | 4677/12750 [15:15:01<25:54:17, 11.55s/it] 37%|███▋      | 4678/12750 [15:15:12<25:50:58, 11.53s/it] 37%|███▋      | 4679/12750 [15:15:24<25:46:48, 11.50s/it] 37%|███▋      | 4680/12750 [15:15:35<25:44:48, 11.49s/it] 37%|███▋      | 4681/12750 [15:15:46<25:44:14, 11.48s/it] 37%|███▋      | 4682/12750 [15:15:58<25:43:26, 11.48s/it] 37%|███▋      | 4683/12750 [15:16:09<25:46:43, 11.50s/it] 37%|███▋      | 4684/12750 [15:16:21<25:45:10, 11.49s/it] 37%|███▋      | 4685/12750 [15:16:32<25:42:27, 11.48s/it] 37%|███▋      | 4686/12750 [15:16:44<25:42:09, 11.47s/it] 37%|███▋      | 4687/12750 [15:16:55<25:39:59, 11.46s/it] 37%|███▋      | 4688/12750 [15:17:07<25:40:39, 11.47s/it] 37%|███▋      | 4689/12750 [15:17:18<25:40:50, 11.47s/it] 37%|███▋      | 4690/12750 [15:17:30<25:41:34, 11.48s/it] 37%|███▋      | 4691/12750 [15:17:41<25:41:01, 11.47s/it] 37%|███▋      | 4692/12750 [15:17:53<25:39:53, 11.47s/it] 37%|███▋      | 4693/12750 [15:18:04<25:39:34, 11.47s/it] 37%|███▋      | 4694/12750 [15:18:16<25:37:23, 11.45s/it] 37%|███▋      | 4695/12750 [15:18:27<25:37:33, 11.45s/it] 37%|███▋      | 4696/12750 [15:18:38<25:36:53, 11.45s/it] 37%|███▋      | 4697/12750 [15:18:50<25:36:26, 11.45s/it] 37%|███▋      | 4698/12750 [15:19:09<30:44:52, 13.75s/it] 37%|███▋      | 4699/12750 [15:19:20<29:11:51, 13.06s/it] 37%|███▋      | 4700/12750 [15:19:32<28:07:50, 12.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120529.31lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104896.55lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4700
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4700/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4700/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4675] due to args.save_total_limit
 37%|███▋      | 4701/12750 [15:19:44<27:37:15, 12.35s/it] 37%|███▋      | 4702/12750 [15:19:55<27:01:11, 12.09s/it] 37%|███▋      | 4703/12750 [15:20:07<26:35:15, 11.89s/it] 37%|███▋      | 4704/12750 [15:20:18<26:16:20, 11.75s/it] 37%|███▋      | 4705/12750 [15:20:30<26:04:17, 11.67s/it] 37%|███▋      | 4706/12750 [15:20:41<25:56:19, 11.61s/it] 37%|███▋      | 4707/12750 [15:20:52<25:50:40, 11.57s/it] 37%|███▋      | 4708/12750 [15:21:04<25:47:20, 11.54s/it] 37%|███▋      | 4709/12750 [15:21:15<25:42:19, 11.51s/it] 37%|███▋      | 4710/12750 [15:21:27<25:40:31, 11.50s/it] 37%|███▋      | 4711/12750 [15:21:38<25:38:15, 11.48s/it] 37%|███▋      | 4712/12750 [15:21:50<25:37:40, 11.48s/it] 37%|███▋      | 4713/12750 [15:22:01<25:36:47, 11.47s/it] 37%|███▋      | 4714/12750 [15:22:13<25:35:31, 11.46s/it] 37%|███▋      | 4715/12750 [15:22:24<25:37:21, 11.48s/it] 37%|███▋      | 4716/12750 [15:22:36<25:36:30, 11.48s/it] 37%|███▋      | 4717/12750 [15:22:47<25:36:38, 11.48s/it] 37%|███▋      | 4718/12750 [15:22:59<25:35:13, 11.47s/it] 37%|███▋      | 4719/12750 [15:23:10<25:34:26, 11.46s/it] 37%|███▋      | 4720/12750 [15:23:21<25:32:11, 11.45s/it] 37%|███▋      | 4721/12750 [15:23:33<25:32:54, 11.46s/it] 37%|███▋      | 4722/12750 [15:23:44<25:35:00, 11.47s/it] 37%|███▋      | 4723/12750 [15:23:56<25:35:01, 11.47s/it] 37%|███▋      | 4724/12750 [15:24:07<25:34:32, 11.47s/it] 37%|███▋      | 4725/12750 [15:24:19<25:34:10, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120572.17lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104810.82lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4725
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4725/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4725/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4575] due to args.save_total_limit
 37%|███▋      | 4726/12750 [15:24:31<25:47:34, 11.57s/it] 37%|███▋      | 4727/12750 [15:24:42<25:43:29, 11.54s/it] 37%|███▋      | 4728/12750 [15:24:54<25:47:20, 11.57s/it] 37%|███▋      | 4729/12750 [15:25:05<25:50:46, 11.60s/it] 37%|███▋      | 4730/12750 [15:25:25<31:00:29, 13.92s/it] 37%|███▋      | 4731/12750 [15:25:36<29:23:38, 13.20s/it] 37%|███▋      | 4732/12750 [15:25:48<28:14:56, 12.68s/it] 37%|███▋      | 4733/12750 [15:25:59<27:25:58, 12.32s/it] 37%|███▋      | 4734/12750 [15:26:11<26:52:12, 12.07s/it] 37%|███▋      | 4735/12750 [15:26:22<26:28:33, 11.89s/it] 37%|███▋      | 4736/12750 [15:26:34<26:11:58, 11.77s/it] 37%|███▋      | 4737/12750 [15:26:45<25:59:25, 11.68s/it] 37%|███▋      | 4738/12750 [15:26:57<25:51:05, 11.62s/it] 37%|███▋      | 4739/12750 [15:27:08<25:45:37, 11.58s/it] 37%|███▋      | 4740/12750 [15:27:20<25:42:35, 11.55s/it] 37%|███▋      | 4741/12750 [15:27:31<25:39:21, 11.53s/it] 37%|███▋      | 4742/12750 [15:27:43<25:36:50, 11.51s/it] 37%|███▋      | 4743/12750 [15:27:54<25:35:28, 11.51s/it] 37%|███▋      | 4744/12750 [15:28:06<25:34:06, 11.50s/it] 37%|███▋      | 4745/12750 [15:28:17<25:33:13, 11.49s/it] 37%|███▋      | 4746/12750 [15:28:28<25:30:57, 11.48s/it] 37%|███▋      | 4747/12750 [15:28:40<25:32:34, 11.49s/it] 37%|███▋      | 4748/12750 [15:28:51<25:31:56, 11.49s/it] 37%|███▋      | 4749/12750 [15:29:03<25:29:53, 11.47s/it] 37%|███▋      | 4750/12750 [15:29:14<25:29:15, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120630.23lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104551.30lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4750
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4750/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4750/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4700] due to args.save_total_limit
 37%|███▋      | 4751/12750 [15:29:26<25:46:42, 11.60s/it] 37%|███▋      | 4752/12750 [15:29:38<25:41:58, 11.57s/it] 37%|███▋      | 4753/12750 [15:29:49<25:40:19, 11.56s/it] 37%|███▋      | 4754/12750 [15:30:01<25:36:23, 11.53s/it] 37%|███▋      | 4755/12750 [15:30:12<25:33:19, 11.51s/it] 37%|███▋      | 4756/12750 [15:30:24<25:30:28, 11.49s/it] 37%|███▋      | 4757/12750 [15:30:35<25:31:45, 11.50s/it] 37%|███▋      | 4758/12750 [15:30:47<25:30:20, 11.49s/it] 37%|███▋      | 4759/12750 [15:30:58<25:28:54, 11.48s/it] 37%|███▋      | 4760/12750 [15:31:10<25:27:09, 11.47s/it] 37%|███▋      | 4761/12750 [15:31:21<25:27:39, 11.47s/it] 37%|███▋      | 4762/12750 [15:31:39<30:04:42, 13.56s/it] 37%|███▋      | 4763/12750 [15:31:51<28:40:50, 12.93s/it] 37%|███▋      | 4764/12750 [15:32:02<27:41:21, 12.48s/it] 37%|███▋      | 4765/12750 [15:32:14<27:00:32, 12.18s/it] 37%|███▋      | 4766/12750 [15:32:25<26:31:03, 11.96s/it] 37%|███▋      | 4767/12750 [15:32:37<26:11:52, 11.81s/it] 37%|███▋      | 4768/12750 [15:32:48<25:58:13, 11.71s/it] 37%|███▋      | 4769/12750 [15:33:00<25:48:09, 11.64s/it] 37%|███▋      | 4770/12750 [15:33:11<25:41:14, 11.59s/it] 37%|███▋      | 4771/12750 [15:33:23<25:37:07, 11.56s/it] 37%|███▋      | 4772/12750 [15:33:34<25:33:00, 11.53s/it] 37%|███▋      | 4773/12750 [15:33:46<25:31:05, 11.52s/it] 37%|███▋      | 4774/12750 [15:33:57<25:28:47, 11.50s/it] 37%|███▋      | 4775/12750 [15:34:08<25:25:41, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120568.96lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104856.63lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4775
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4775/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4775/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4725] due to args.save_total_limit
 37%|███▋      | 4776/12750 [15:34:20<25:37:02, 11.57s/it] 37%|███▋      | 4777/12750 [15:34:32<25:32:31, 11.53s/it] 37%|███▋      | 4778/12750 [15:34:43<25:29:14, 11.51s/it] 37%|███▋      | 4779/12750 [15:34:55<25:26:43, 11.49s/it] 37%|███▋      | 4780/12750 [15:35:06<25:24:51, 11.48s/it] 37%|███▋      | 4781/12750 [15:35:18<25:25:15, 11.48s/it] 38%|███▊      | 4782/12750 [15:35:29<25:23:54, 11.48s/it] 38%|███▊      | 4783/12750 [15:35:40<25:24:55, 11.48s/it] 38%|███▊      | 4784/12750 [15:35:52<25:24:29, 11.48s/it] 38%|███▊      | 4785/12750 [15:36:03<25:24:25, 11.48s/it] 38%|███▊      | 4786/12750 [15:36:15<25:22:36, 11.47s/it] 38%|███▊      | 4787/12750 [15:36:26<25:21:41, 11.47s/it] 38%|███▊      | 4788/12750 [15:36:38<25:28:04, 11.52s/it] 38%|███▊      | 4789/12750 [15:36:49<25:25:50, 11.50s/it] 38%|███▊      | 4790/12750 [15:37:01<25:24:34, 11.49s/it] 38%|███▊      | 4791/12750 [15:37:12<25:23:22, 11.48s/it] 38%|███▊      | 4792/12750 [15:37:24<25:20:56, 11.47s/it] 38%|███▊      | 4793/12750 [15:37:35<25:19:09, 11.46s/it] 38%|███▊      | 4794/12750 [15:37:54<30:21:54, 13.74s/it] 38%|███▊      | 4795/12750 [15:38:06<28:50:53, 13.06s/it] 38%|███▊      | 4796/12750 [15:38:17<27:46:48, 12.57s/it] 38%|███▊      | 4797/12750 [15:38:29<27:03:35, 12.25s/it] 38%|███▊      | 4798/12750 [15:38:40<26:30:53, 12.00s/it] 38%|███▊      | 4799/12750 [15:38:52<26:07:44, 11.83s/it] 38%|███▊      | 4800/12750 [15:39:03<25:52:50, 11.72s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120531.24lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104819.55lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4800
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4800/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4800/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4775] due to args.save_total_limit
 38%|███▊      | 4801/12750 [15:39:15<25:56:17, 11.75s/it] 38%|███▊      | 4802/12750 [15:39:26<25:44:45, 11.66s/it] 38%|███▊      | 4803/12750 [15:39:38<25:36:28, 11.60s/it] 38%|███▊      | 4804/12750 [15:39:49<25:31:28, 11.56s/it] 38%|███▊      | 4805/12750 [15:40:01<25:25:53, 11.52s/it] 38%|███▊      | 4806/12750 [15:40:12<25:22:41, 11.50s/it] 38%|███▊      | 4807/12750 [15:40:24<25:21:56, 11.50s/it] 38%|███▊      | 4808/12750 [15:40:35<25:21:19, 11.49s/it] 38%|███▊      | 4809/12750 [15:40:47<25:20:11, 11.49s/it] 38%|███▊      | 4810/12750 [15:40:58<25:22:17, 11.50s/it] 38%|███▊      | 4811/12750 [15:41:10<25:20:32, 11.49s/it] 38%|███▊      | 4812/12750 [15:41:21<25:19:34, 11.49s/it] 38%|███▊      | 4813/12750 [15:41:32<25:17:15, 11.47s/it] 38%|███▊      | 4814/12750 [15:41:44<25:17:22, 11.47s/it] 38%|███▊      | 4815/12750 [15:41:55<25:17:24, 11.47s/it] 38%|███▊      | 4816/12750 [15:42:07<25:16:33, 11.47s/it] 38%|███▊      | 4817/12750 [15:42:18<25:16:25, 11.47s/it] 38%|███▊      | 4818/12750 [15:42:30<25:19:33, 11.49s/it] 38%|███▊      | 4819/12750 [15:42:41<25:19:43, 11.50s/it] 38%|███▊      | 4820/12750 [15:42:53<25:18:58, 11.49s/it] 38%|███▊      | 4821/12750 [15:43:04<25:18:40, 11.49s/it] 38%|███▊      | 4822/12750 [15:43:16<25:18:41, 11.49s/it] 38%|███▊      | 4823/12750 [15:43:27<25:18:42, 11.50s/it] 38%|███▊      | 4824/12750 [15:43:39<25:19:19, 11.50s/it] 38%|███▊      | 4825/12750 [15:43:50<25:21:57, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120610.31lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104843.62lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4825
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4825/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4825/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4800] due to args.save_total_limit
 38%|███▊      | 4826/12750 [15:44:10<30:35:18, 13.90s/it] 38%|███▊      | 4827/12750 [15:44:21<28:58:55, 13.17s/it] 38%|███▊      | 4828/12750 [15:44:33<27:50:38, 12.65s/it] 38%|███▊      | 4829/12750 [15:44:44<27:04:19, 12.30s/it] 38%|███▊      | 4830/12750 [15:44:56<26:31:05, 12.05s/it] 38%|███▊      | 4831/12750 [15:45:07<26:08:19, 11.88s/it] 38%|███▊      | 4832/12750 [15:45:19<25:51:15, 11.75s/it] 38%|███▊      | 4833/12750 [15:45:30<25:39:18, 11.67s/it] 38%|███▊      | 4834/12750 [15:45:42<25:32:54, 11.62s/it] 38%|███▊      | 4835/12750 [15:45:53<25:28:01, 11.58s/it] 38%|███▊      | 4836/12750 [15:46:05<25:23:23, 11.55s/it] 38%|███▊      | 4837/12750 [15:46:16<25:21:30, 11.54s/it] 38%|███▊      | 4838/12750 [15:46:28<25:19:15, 11.52s/it] 38%|███▊      | 4839/12750 [15:46:39<25:16:48, 11.50s/it] 38%|███▊      | 4840/12750 [15:46:51<25:14:03, 11.48s/it] 38%|███▊      | 4841/12750 [15:47:02<25:13:07, 11.48s/it] 38%|███▊      | 4842/12750 [15:47:13<25:12:06, 11.47s/it] 38%|███▊      | 4843/12750 [15:47:25<25:11:40, 11.47s/it] 38%|███▊      | 4844/12750 [15:47:36<25:11:18, 11.47s/it] 38%|███▊      | 4845/12750 [15:47:48<25:11:01, 11.47s/it] 38%|███▊      | 4846/12750 [15:47:59<25:10:24, 11.47s/it] 38%|███▊      | 4847/12750 [15:48:11<25:11:24, 11.47s/it] 38%|███▊      | 4848/12750 [15:48:22<25:10:41, 11.47s/it] 38%|███▊      | 4849/12750 [15:48:34<25:11:10, 11.48s/it] 38%|███▊      | 4850/12750 [15:48:45<25:10:43, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120471.74lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104758.47lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4850
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4850/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4850/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4825] due to args.save_total_limit
 38%|███▊      | 4851/12750 [15:48:57<25:22:20, 11.56s/it] 38%|███▊      | 4852/12750 [15:49:08<25:16:50, 11.52s/it] 38%|███▊      | 4853/12750 [15:49:20<25:13:28, 11.50s/it] 38%|███▊      | 4854/12750 [15:49:31<25:11:59, 11.49s/it] 38%|███▊      | 4855/12750 [15:49:43<25:10:36, 11.48s/it] 38%|███▊      | 4856/12750 [15:49:54<25:10:38, 11.48s/it] 38%|███▊      | 4857/12750 [15:50:06<25:09:31, 11.47s/it] 38%|███▊      | 4858/12750 [15:50:25<30:13:43, 13.79s/it] 38%|███▊      | 4859/12750 [15:50:36<28:41:10, 13.09s/it] 38%|███▊      | 4860/12750 [15:50:48<27:37:47, 12.61s/it] 38%|███▊      | 4861/12750 [15:50:59<26:52:42, 12.27s/it] 38%|███▊      | 4862/12750 [15:51:11<26:21:26, 12.03s/it] 38%|███▊      | 4863/12750 [15:51:22<25:58:55, 11.86s/it] 38%|███▊      | 4864/12750 [15:51:34<25:43:27, 11.74s/it] 38%|███▊      | 4865/12750 [15:51:45<25:32:27, 11.66s/it] 38%|███▊      | 4866/12750 [15:51:57<25:24:22, 11.60s/it] 38%|███▊      | 4867/12750 [15:52:08<25:19:20, 11.56s/it] 38%|███▊      | 4868/12750 [15:52:20<25:16:07, 11.54s/it] 38%|███▊      | 4869/12750 [15:52:31<25:12:47, 11.52s/it] 38%|███▊      | 4870/12750 [15:52:43<25:11:07, 11.51s/it] 38%|███▊      | 4871/12750 [15:52:54<25:08:59, 11.49s/it] 38%|███▊      | 4872/12750 [15:53:06<25:08:11, 11.49s/it] 38%|███▊      | 4873/12750 [15:53:17<25:08:04, 11.49s/it] 38%|███▊      | 4874/12750 [15:53:29<25:07:58, 11.49s/it] 38%|███▊      | 4875/12750 [15:53:40<25:07:28, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120558.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104849.35lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4875
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4875/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4875/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4850] due to args.save_total_limit
 38%|███▊      | 4876/12750 [15:53:52<25:18:23, 11.57s/it] 38%|███▊      | 4877/12750 [15:54:03<25:12:48, 11.53s/it] 38%|███▊      | 4878/12750 [15:54:15<25:08:39, 11.50s/it] 38%|███▊      | 4879/12750 [15:54:26<25:07:01, 11.49s/it] 38%|███▊      | 4880/12750 [15:54:38<25:06:22, 11.48s/it] 38%|███▊      | 4881/12750 [15:54:49<25:07:02, 11.49s/it] 38%|███▊      | 4882/12750 [15:55:01<25:06:09, 11.49s/it] 38%|███▊      | 4883/12750 [15:55:12<25:06:28, 11.49s/it] 38%|███▊      | 4884/12750 [15:55:23<25:04:55, 11.48s/it] 38%|███▊      | 4885/12750 [15:55:35<25:03:41, 11.47s/it] 38%|███▊      | 4886/12750 [15:55:46<25:03:30, 11.47s/it] 38%|███▊      | 4887/12750 [15:55:58<25:01:09, 11.45s/it] 38%|███▊      | 4888/12750 [15:56:09<25:01:37, 11.46s/it] 38%|███▊      | 4889/12750 [15:56:21<25:01:42, 11.46s/it] 38%|███▊      | 4890/12750 [15:56:40<30:14:54, 13.85s/it] 38%|███▊      | 4891/12750 [15:56:52<28:39:36, 13.13s/it] 38%|███▊      | 4892/12750 [15:57:03<27:33:05, 12.62s/it] 38%|███▊      | 4893/12750 [15:57:15<26:46:02, 12.26s/it] 38%|███▊      | 4894/12750 [15:57:26<26:15:29, 12.03s/it] 38%|███▊      | 4895/12750 [15:57:37<25:52:48, 11.86s/it] 38%|███▊      | 4896/12750 [15:57:49<25:37:55, 11.75s/it] 38%|███▊      | 4897/12750 [15:58:00<25:27:05, 11.67s/it] 38%|███▊      | 4898/12750 [15:58:12<25:19:21, 11.61s/it] 38%|███▊      | 4899/12750 [15:58:23<25:13:43, 11.57s/it] 38%|███▊      | 4900/12750 [15:58:35<25:10:37, 11.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120629.45lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104770.00lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4900
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4900/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4900/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4875] due to args.save_total_limit
 38%|███▊      | 4901/12750 [15:58:47<25:19:15, 11.61s/it] 38%|███▊      | 4902/12750 [15:58:58<25:13:47, 11.57s/it] 38%|███▊      | 4903/12750 [15:59:10<25:09:45, 11.54s/it] 38%|███▊      | 4904/12750 [15:59:21<25:07:15, 11.53s/it] 38%|███▊      | 4905/12750 [15:59:33<25:05:19, 11.51s/it] 38%|███▊      | 4906/12750 [15:59:44<25:03:52, 11.50s/it] 38%|███▊      | 4907/12750 [15:59:56<25:02:51, 11.50s/it] 38%|███▊      | 4908/12750 [16:00:07<25:01:56, 11.49s/it] 39%|███▊      | 4909/12750 [16:00:18<25:01:05, 11.49s/it] 39%|███▊      | 4910/12750 [16:00:30<25:01:30, 11.49s/it] 39%|███▊      | 4911/12750 [16:00:41<24:59:55, 11.48s/it] 39%|███▊      | 4912/12750 [16:00:53<24:59:00, 11.47s/it] 39%|███▊      | 4913/12750 [16:01:04<24:58:46, 11.47s/it] 39%|███▊      | 4914/12750 [16:01:16<24:58:31, 11.47s/it] 39%|███▊      | 4915/12750 [16:01:27<24:58:14, 11.47s/it] 39%|███▊      | 4916/12750 [16:01:39<24:58:44, 11.48s/it] 39%|███▊      | 4917/12750 [16:01:50<24:58:28, 11.48s/it] 39%|███▊      | 4918/12750 [16:02:02<24:58:36, 11.48s/it] 39%|███▊      | 4919/12750 [16:02:13<24:57:36, 11.47s/it] 39%|███▊      | 4920/12750 [16:02:25<25:00:47, 11.50s/it] 39%|███▊      | 4921/12750 [16:02:36<24:58:38, 11.49s/it] 39%|███▊      | 4922/12750 [16:02:48<24:56:59, 11.47s/it] 39%|███▊      | 4923/12750 [16:03:07<29:56:26, 13.77s/it] 39%|███▊      | 4924/12750 [16:03:18<28:26:03, 13.08s/it] 39%|███▊      | 4925/12750 [16:03:30<27:24:23, 12.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120580.13lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101493.92lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4925
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4925/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4925/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4750] due to args.save_total_limit
 39%|███▊      | 4926/12750 [16:03:42<27:02:03, 12.44s/it] 39%|███▊      | 4927/12750 [16:03:53<26:23:19, 12.14s/it] 39%|███▊      | 4928/12750 [16:04:05<25:56:19, 11.94s/it] 39%|███▊      | 4929/12750 [16:04:16<25:38:55, 11.81s/it] 39%|███▊      | 4930/12750 [16:04:28<25:25:07, 11.70s/it] 39%|███▊      | 4931/12750 [16:04:39<25:16:45, 11.64s/it] 39%|███▊      | 4932/12750 [16:04:51<25:14:27, 11.62s/it] 39%|███▊      | 4933/12750 [16:05:02<25:08:27, 11.58s/it] 39%|███▊      | 4934/12750 [16:05:14<25:03:43, 11.54s/it] 39%|███▊      | 4935/12750 [16:05:25<25:00:58, 11.52s/it] 39%|███▊      | 4936/12750 [16:05:37<24:58:49, 11.51s/it] 39%|███▊      | 4937/12750 [16:05:48<24:57:01, 11.50s/it] 39%|███▊      | 4938/12750 [16:06:00<24:56:41, 11.50s/it] 39%|███▊      | 4939/12750 [16:06:11<24:56:56, 11.50s/it] 39%|███▊      | 4940/12750 [16:06:23<24:55:22, 11.49s/it] 39%|███▉      | 4941/12750 [16:06:34<24:55:21, 11.49s/it] 39%|███▉      | 4942/12750 [16:06:46<24:55:10, 11.49s/it] 39%|███▉      | 4943/12750 [16:06:57<24:53:56, 11.48s/it] 39%|███▉      | 4944/12750 [16:07:09<24:53:30, 11.48s/it] 39%|███▉      | 4945/12750 [16:07:20<24:53:54, 11.48s/it] 39%|███▉      | 4946/12750 [16:07:32<24:53:44, 11.48s/it] 39%|███▉      | 4947/12750 [16:07:43<24:52:41, 11.48s/it] 39%|███▉      | 4948/12750 [16:07:54<24:52:22, 11.48s/it] 39%|███▉      | 4949/12750 [16:08:06<24:51:30, 11.47s/it] 39%|███▉      | 4950/12750 [16:08:17<24:52:32, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120591.56lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104873.53lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4950
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4950/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4950/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4900] due to args.save_total_limit
 39%|███▉      | 4951/12750 [16:08:29<25:08:39, 11.61s/it] 39%|███▉      | 4952/12750 [16:08:41<25:02:39, 11.56s/it] 39%|███▉      | 4953/12750 [16:08:52<24:58:56, 11.53s/it] 39%|███▉      | 4954/12750 [16:09:04<24:57:28, 11.52s/it] 39%|███▉      | 4955/12750 [16:09:23<29:53:38, 13.81s/it] 39%|███▉      | 4956/12750 [16:09:34<28:21:18, 13.10s/it] 39%|███▉      | 4957/12750 [16:09:46<27:17:48, 12.61s/it] 39%|███▉      | 4958/12750 [16:09:57<26:32:44, 12.26s/it] 39%|███▉      | 4959/12750 [16:10:09<26:01:06, 12.02s/it] 39%|███▉      | 4960/12750 [16:10:20<25:41:18, 11.87s/it] 39%|███▉      | 4961/12750 [16:10:32<25:25:51, 11.75s/it] 39%|███▉      | 4962/12750 [16:10:43<25:14:46, 11.67s/it] 39%|███▉      | 4963/12750 [16:10:55<25:08:15, 11.62s/it] 39%|███▉      | 4964/12750 [16:11:06<25:03:21, 11.59s/it] 39%|███▉      | 4965/12750 [16:11:18<24:59:48, 11.56s/it] 39%|███▉      | 4966/12750 [16:11:29<24:55:37, 11.53s/it] 39%|███▉      | 4967/12750 [16:11:41<24:53:14, 11.51s/it] 39%|███▉      | 4968/12750 [16:11:52<24:51:43, 11.50s/it] 39%|███▉      | 4969/12750 [16:12:04<24:49:47, 11.49s/it] 39%|███▉      | 4970/12750 [16:12:15<24:50:11, 11.49s/it] 39%|███▉      | 4971/12750 [16:12:27<24:49:31, 11.49s/it] 39%|███▉      | 4972/12750 [16:12:38<24:49:20, 11.49s/it] 39%|███▉      | 4973/12750 [16:12:49<24:48:35, 11.48s/it] 39%|███▉      | 4974/12750 [16:13:01<24:48:02, 11.48s/it] 39%|███▉      | 4975/12750 [16:13:12<24:47:39, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120558.44lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104849.54lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4975
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4975/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4975/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-4975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4950] due to args.save_total_limit
 39%|███▉      | 4976/12750 [16:13:24<24:58:41, 11.57s/it] 39%|███▉      | 4977/12750 [16:13:36<24:54:01, 11.53s/it] 39%|███▉      | 4978/12750 [16:13:47<24:56:20, 11.55s/it] 39%|███▉      | 4979/12750 [16:13:59<24:58:21, 11.57s/it] 39%|███▉      | 4980/12750 [16:14:10<24:58:07, 11.57s/it] 39%|███▉      | 4981/12750 [16:14:22<24:59:10, 11.58s/it] 39%|███▉      | 4982/12750 [16:14:34<24:59:27, 11.58s/it] 39%|███▉      | 4983/12750 [16:14:45<25:00:57, 11.59s/it] 39%|███▉      | 4984/12750 [16:14:57<24:56:15, 11.56s/it] 39%|███▉      | 4985/12750 [16:15:08<24:56:45, 11.57s/it] 39%|███▉      | 4986/12750 [16:15:20<24:53:38, 11.54s/it] 39%|███▉      | 4987/12750 [16:15:39<29:49:53, 13.83s/it] 39%|███▉      | 4988/12750 [16:15:50<28:17:28, 13.12s/it] 39%|███▉      | 4989/12750 [16:16:02<27:15:05, 12.64s/it] 39%|███▉      | 4990/12750 [16:16:13<26:30:01, 12.29s/it] 39%|███▉      | 4991/12750 [16:16:25<25:59:37, 12.06s/it] 39%|███▉      | 4992/12750 [16:16:36<25:36:17, 11.88s/it] 39%|███▉      | 4993/12750 [16:16:48<25:20:04, 11.76s/it] 39%|███▉      | 4994/12750 [16:16:59<25:08:31, 11.67s/it] 39%|███▉      | 4995/12750 [16:17:11<25:00:07, 11.61s/it] 39%|███▉      | 4996/12750 [16:17:22<24:56:04, 11.58s/it] 39%|███▉      | 4997/12750 [16:17:34<24:53:27, 11.56s/it] 39%|███▉      | 4998/12750 [16:17:45<24:50:35, 11.54s/it] 39%|███▉      | 4999/12750 [16:17:57<24:48:49, 11.52s/it] 39%|███▉      | 5000/12750 [16:18:08<24:46:39, 11.51s/it]                                                           39%|███▉      | 5000/12750 [16:18:08<24:46:39, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120663.90lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104754.49lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5000
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5000/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5000/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4975] due to args.save_total_limit
 39%|███▉      | 5001/12750 [16:18:20<24:57:37, 11.60s/it] 39%|███▉      | 5002/12750 [16:18:32<24:54:08, 11.57s/it] 39%|███▉      | 5003/12750 [16:18:43<24:52:21, 11.56s/it] 39%|███▉      | 5004/12750 [16:18:55<24:49:11, 11.54s/it] 39%|███▉      | 5005/12750 [16:19:06<24:46:46, 11.52s/it] 39%|███▉      | 5006/12750 [16:19:18<24:46:03, 11.51s/it] 39%|███▉      | 5007/12750 [16:19:29<24:44:19, 11.50s/it] 39%|███▉      | 5008/12750 [16:19:41<24:54:47, 11.58s/it] 39%|███▉      | 5009/12750 [16:19:52<24:49:57, 11.55s/it] 39%|███▉      | 5010/12750 [16:20:04<24:47:38, 11.53s/it] 39%|███▉      | 5011/12750 [16:20:15<24:47:24, 11.53s/it] 39%|███▉      | 5012/12750 [16:20:27<24:46:15, 11.52s/it] 39%|███▉      | 5013/12750 [16:20:38<24:45:12, 11.52s/it] 39%|███▉      | 5014/12750 [16:20:50<24:47:27, 11.54s/it] 39%|███▉      | 5015/12750 [16:21:01<24:45:34, 11.52s/it] 39%|███▉      | 5016/12750 [16:21:13<24:43:28, 11.51s/it] 39%|███▉      | 5017/12750 [16:21:24<24:42:38, 11.50s/it] 39%|███▉      | 5018/12750 [16:21:36<24:45:33, 11.53s/it] 39%|███▉      | 5019/12750 [16:21:55<29:43:23, 13.84s/it] 39%|███▉      | 5020/12750 [16:22:07<28:15:00, 13.16s/it] 39%|███▉      | 5021/12750 [16:22:18<27:12:06, 12.67s/it] 39%|███▉      | 5022/12750 [16:22:30<26:30:31, 12.35s/it] 39%|███▉      | 5023/12750 [16:22:41<25:57:43, 12.10s/it] 39%|███▉      | 5024/12750 [16:22:53<25:34:26, 11.92s/it] 39%|███▉      | 5025/12750 [16:23:04<25:21:17, 11.82s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120601.83lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104903.54lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5025
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5025/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5025/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5000] due to args.save_total_limit
 39%|███▉      | 5026/12750 [16:23:16<25:19:28, 11.80s/it] 39%|███▉      | 5027/12750 [16:23:28<25:06:02, 11.70s/it] 39%|███▉      | 5028/12750 [16:23:39<24:56:28, 11.63s/it] 39%|███▉      | 5029/12750 [16:23:51<24:50:51, 11.59s/it] 39%|███▉      | 5030/12750 [16:24:02<24:47:48, 11.56s/it] 39%|███▉      | 5031/12750 [16:24:14<24:44:48, 11.54s/it] 39%|███▉      | 5032/12750 [16:24:25<24:42:25, 11.52s/it] 39%|███▉      | 5033/12750 [16:24:37<24:39:15, 11.50s/it] 39%|███▉      | 5034/12750 [16:24:48<24:37:34, 11.49s/it] 39%|███▉      | 5035/12750 [16:25:00<24:36:49, 11.49s/it] 39%|███▉      | 5036/12750 [16:25:11<24:36:19, 11.48s/it] 40%|███▉      | 5037/12750 [16:25:22<24:35:08, 11.48s/it] 40%|███▉      | 5038/12750 [16:25:34<24:33:58, 11.47s/it] 40%|███▉      | 5039/12750 [16:25:45<24:33:01, 11.46s/it] 40%|███▉      | 5040/12750 [16:25:57<24:33:36, 11.47s/it] 40%|███▉      | 5041/12750 [16:26:08<24:33:30, 11.47s/it] 40%|███▉      | 5042/12750 [16:26:20<24:34:54, 11.48s/it] 40%|███▉      | 5043/12750 [16:26:31<24:34:38, 11.48s/it] 40%|███▉      | 5044/12750 [16:26:43<24:34:43, 11.48s/it] 40%|███▉      | 5045/12750 [16:26:54<24:34:37, 11.48s/it] 40%|███▉      | 5046/12750 [16:27:06<24:33:38, 11.48s/it] 40%|███▉      | 5047/12750 [16:27:17<24:34:32, 11.49s/it] 40%|███▉      | 5048/12750 [16:27:29<24:33:58, 11.48s/it] 40%|███▉      | 5049/12750 [16:27:40<24:32:57, 11.48s/it] 40%|███▉      | 5050/12750 [16:27:52<24:33:13, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120564.60lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104652.66lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5050
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5050/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5050/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5025] due to args.save_total_limit
 40%|███▉      | 5051/12750 [16:28:11<29:46:26, 13.92s/it] 40%|███▉      | 5052/12750 [16:28:23<28:12:38, 13.19s/it] 40%|███▉      | 5053/12750 [16:28:34<27:12:08, 12.72s/it] 40%|███▉      | 5054/12750 [16:28:46<26:28:50, 12.39s/it] 40%|███▉      | 5055/12750 [16:28:58<25:59:10, 12.16s/it] 40%|███▉      | 5056/12750 [16:29:09<25:38:32, 12.00s/it] 40%|███▉      | 5057/12750 [16:29:21<25:23:58, 11.89s/it] 40%|███▉      | 5058/12750 [16:29:32<25:11:40, 11.79s/it] 40%|███▉      | 5059/12750 [16:29:44<25:04:59, 11.74s/it] 40%|███▉      | 5060/12750 [16:29:56<24:59:08, 11.70s/it] 40%|███▉      | 5061/12750 [16:30:07<24:55:10, 11.67s/it] 40%|███▉      | 5062/12750 [16:30:19<24:52:51, 11.65s/it] 40%|███▉      | 5063/12750 [16:30:31<24:52:05, 11.65s/it] 40%|███▉      | 5064/12750 [16:30:42<24:50:55, 11.64s/it] 40%|███▉      | 5065/12750 [16:30:54<24:49:31, 11.63s/it] 40%|███▉      | 5066/12750 [16:31:05<24:48:47, 11.63s/it] 40%|███▉      | 5067/12750 [16:31:17<24:46:46, 11.61s/it] 40%|███▉      | 5068/12750 [16:31:29<24:46:46, 11.61s/it] 40%|███▉      | 5069/12750 [16:31:40<24:46:54, 11.61s/it] 40%|███▉      | 5070/12750 [16:31:52<24:46:11, 11.61s/it] 40%|███▉      | 5071/12750 [16:32:03<24:46:02, 11.61s/it] 40%|███▉      | 5072/12750 [16:32:15<24:46:41, 11.62s/it] 40%|███▉      | 5073/12750 [16:32:27<24:46:26, 11.62s/it] 40%|███▉      | 5074/12750 [16:32:38<24:46:33, 11.62s/it] 40%|███▉      | 5075/12750 [16:32:50<24:47:14, 11.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120591.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104851.58lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5075
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5075/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5075/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-4925] due to args.save_total_limit
 40%|███▉      | 5076/12750 [16:33:02<24:57:41, 11.71s/it] 40%|███▉      | 5077/12750 [16:33:13<24:50:15, 11.65s/it] 40%|███▉      | 5078/12750 [16:33:25<24:47:42, 11.63s/it] 40%|███▉      | 5079/12750 [16:33:37<24:45:31, 11.62s/it] 40%|███▉      | 5080/12750 [16:33:48<24:40:58, 11.59s/it] 40%|███▉      | 5081/12750 [16:34:00<24:41:52, 11.59s/it] 40%|███▉      | 5082/12750 [16:34:11<24:40:57, 11.59s/it] 40%|███▉      | 5083/12750 [16:34:23<24:42:50, 11.60s/it] 40%|███▉      | 5084/12750 [16:34:42<29:36:40, 13.91s/it] 40%|███▉      | 5085/12750 [16:34:54<28:08:54, 13.22s/it] 40%|███▉      | 5086/12750 [16:35:05<27:07:18, 12.74s/it] 40%|███▉      | 5087/12750 [16:35:17<26:25:22, 12.41s/it] 40%|███▉      | 5088/12750 [16:35:29<25:55:54, 12.18s/it] 40%|███▉      | 5089/12750 [16:35:40<25:33:59, 12.01s/it] 40%|███▉      | 5090/12750 [16:35:52<25:19:32, 11.90s/it] 40%|███▉      | 5091/12750 [16:36:04<25:09:10, 11.82s/it] 40%|███▉      | 5092/12750 [16:36:15<25:02:07, 11.77s/it] 40%|███▉      | 5093/12750 [16:36:27<24:56:49, 11.73s/it] 40%|███▉      | 5094/12750 [16:36:38<24:53:26, 11.70s/it] 40%|███▉      | 5095/12750 [16:36:50<24:50:40, 11.68s/it] 40%|███▉      | 5096/12750 [16:37:02<24:48:42, 11.67s/it] 40%|███▉      | 5097/12750 [16:37:13<24:46:15, 11.65s/it] 40%|███▉      | 5098/12750 [16:37:25<24:45:20, 11.65s/it] 40%|███▉      | 5099/12750 [16:37:32<21:50:37, 10.28s/it] 40%|████      | 5100/12750 [16:37:33<15:47:31,  7.43s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120604.92lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104901.02lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5100
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5100/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5100/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5050] due to args.save_total_limit
 40%|████      | 5101/12750 [16:37:57<26:13:14, 12.34s/it] 40%|████      | 5102/12750 [16:38:08<25:46:51, 12.14s/it] 40%|████      | 5103/12750 [16:38:20<25:28:32, 11.99s/it] 40%|████      | 5104/12750 [16:38:32<25:13:56, 11.88s/it] 40%|████      | 5105/12750 [16:38:43<25:05:06, 11.81s/it] 40%|████      | 5106/12750 [16:38:55<24:55:15, 11.74s/it] 40%|████      | 5107/12750 [16:39:06<24:49:54, 11.70s/it] 40%|████      | 5108/12750 [16:39:18<24:48:17, 11.69s/it] 40%|████      | 5109/12750 [16:39:30<24:46:20, 11.67s/it] 40%|████      | 5110/12750 [16:39:41<24:44:46, 11.66s/it] 40%|████      | 5111/12750 [16:39:53<24:43:54, 11.66s/it] 40%|████      | 5112/12750 [16:40:05<24:37:52, 11.61s/it] 40%|████      | 5113/12750 [16:40:16<24:37:55, 11.61s/it] 40%|████      | 5114/12750 [16:40:28<24:38:00, 11.61s/it] 40%|████      | 5115/12750 [16:40:39<24:38:40, 11.62s/it] 40%|████      | 5116/12750 [16:40:59<29:33:40, 13.94s/it] 40%|████      | 5117/12750 [16:41:10<28:05:58, 13.25s/it] 40%|████      | 5118/12750 [16:41:22<27:03:57, 12.77s/it] 40%|████      | 5119/12750 [16:41:34<26:20:28, 12.43s/it] 40%|████      | 5120/12750 [16:41:45<25:51:07, 12.20s/it] 40%|████      | 5121/12750 [16:41:57<25:29:51, 12.03s/it] 40%|████      | 5122/12750 [16:42:09<25:14:30, 11.91s/it] 40%|████      | 5123/12750 [16:42:20<25:10:52, 11.89s/it] 40%|████      | 5124/12750 [16:42:32<25:00:14, 11.80s/it] 40%|████      | 5125/12750 [16:42:44<24:53:13, 11.75s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120636.01lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104674.42lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5125
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5125/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5125/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5100] due to args.save_total_limit
 40%|████      | 5126/12750 [16:42:56<25:01:11, 11.81s/it] 40%|████      | 5127/12750 [16:43:07<24:54:58, 11.77s/it] 40%|████      | 5128/12750 [16:43:19<24:50:53, 11.74s/it] 40%|████      | 5129/12750 [16:43:31<24:48:11, 11.72s/it] 40%|████      | 5130/12750 [16:43:42<24:46:17, 11.70s/it] 40%|████      | 5131/12750 [16:43:54<24:44:33, 11.69s/it] 40%|████      | 5132/12750 [16:44:06<24:42:56, 11.68s/it] 40%|████      | 5133/12750 [16:44:17<24:42:31, 11.68s/it] 40%|████      | 5134/12750 [16:44:29<24:42:34, 11.68s/it] 40%|████      | 5135/12750 [16:44:41<24:40:47, 11.67s/it] 40%|████      | 5136/12750 [16:44:52<24:40:16, 11.66s/it] 40%|████      | 5137/12750 [16:45:04<24:41:19, 11.67s/it] 40%|████      | 5138/12750 [16:45:16<24:40:19, 11.67s/it] 40%|████      | 5139/12750 [16:45:27<24:40:47, 11.67s/it] 40%|████      | 5140/12750 [16:45:39<24:41:01, 11.68s/it] 40%|████      | 5141/12750 [16:45:51<24:41:49, 11.68s/it] 40%|████      | 5142/12750 [16:46:02<24:40:15, 11.67s/it] 40%|████      | 5143/12750 [16:46:14<24:34:01, 11.63s/it] 40%|████      | 5144/12750 [16:46:25<24:34:21, 11.63s/it] 40%|████      | 5145/12750 [16:46:37<24:34:54, 11.64s/it] 40%|████      | 5146/12750 [16:46:49<24:36:20, 11.65s/it] 40%|████      | 5147/12750 [16:47:00<24:36:29, 11.65s/it] 40%|████      | 5148/12750 [16:47:20<29:28:17, 13.96s/it] 40%|████      | 5149/12750 [16:47:31<28:00:54, 13.27s/it] 40%|████      | 5150/12750 [16:47:43<26:58:48, 12.78s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120585.65lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104819.36lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5150
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5150/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5150/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5075] due to args.save_total_limit
 40%|████      | 5151/12750 [16:47:55<26:27:51, 12.54s/it] 40%|████      | 5152/12750 [16:48:07<25:52:15, 12.26s/it] 40%|████      | 5153/12750 [16:48:18<25:28:54, 12.08s/it] 40%|████      | 5154/12750 [16:48:30<25:11:29, 11.94s/it] 40%|████      | 5155/12750 [16:48:41<24:55:03, 11.81s/it] 40%|████      | 5156/12750 [16:48:53<24:48:23, 11.76s/it] 40%|████      | 5157/12750 [16:49:05<24:43:32, 11.72s/it] 40%|████      | 5158/12750 [16:49:16<24:39:06, 11.69s/it] 40%|████      | 5159/12750 [16:49:28<24:36:41, 11.67s/it] 40%|████      | 5160/12750 [16:49:39<24:30:20, 11.62s/it] 40%|████      | 5161/12750 [16:49:51<24:28:00, 11.61s/it] 40%|████      | 5162/12750 [16:50:03<24:29:43, 11.62s/it] 40%|████      | 5163/12750 [16:50:14<24:30:50, 11.63s/it] 41%|████      | 5164/12750 [16:50:26<24:31:50, 11.64s/it] 41%|████      | 5165/12750 [16:50:38<24:32:19, 11.65s/it] 41%|████      | 5166/12750 [16:50:49<24:32:49, 11.65s/it] 41%|████      | 5167/12750 [16:51:01<24:30:55, 11.64s/it] 41%|████      | 5168/12750 [16:51:13<24:29:52, 11.63s/it] 41%|████      | 5169/12750 [16:51:24<24:29:44, 11.63s/it] 41%|████      | 5170/12750 [16:51:36<24:27:47, 11.62s/it] 41%|████      | 5171/12750 [16:51:47<24:29:28, 11.63s/it] 41%|████      | 5172/12750 [16:51:59<24:30:21, 11.64s/it] 41%|████      | 5173/12750 [16:52:11<24:29:29, 11.64s/it] 41%|████      | 5174/12750 [16:52:22<24:28:55, 11.63s/it] 41%|████      | 5175/12750 [16:52:34<24:28:24, 11.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120532.90lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104738.22lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5175
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5175/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5175/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5125] due to args.save_total_limit
 41%|████      | 5176/12750 [16:52:46<24:40:17, 11.73s/it] 41%|████      | 5177/12750 [16:52:57<24:32:57, 11.67s/it] 41%|████      | 5178/12750 [16:53:09<24:31:40, 11.66s/it] 41%|████      | 5179/12750 [16:53:21<24:31:08, 11.66s/it] 41%|████      | 5180/12750 [16:53:40<29:22:15, 13.97s/it] 41%|████      | 5181/12750 [16:53:52<27:53:57, 13.27s/it] 41%|████      | 5182/12750 [16:54:03<26:47:53, 12.75s/it] 41%|████      | 5183/12750 [16:54:15<25:58:22, 12.36s/it] 41%|████      | 5184/12750 [16:54:26<25:30:06, 12.13s/it] 41%|████      | 5185/12750 [16:54:38<25:09:19, 11.97s/it] 41%|████      | 5186/12750 [16:54:50<24:55:35, 11.86s/it] 41%|████      | 5187/12750 [16:55:01<24:46:33, 11.79s/it] 41%|████      | 5188/12750 [16:55:13<24:37:14, 11.72s/it] 41%|████      | 5189/12750 [16:55:24<24:33:34, 11.69s/it] 41%|████      | 5190/12750 [16:55:36<24:31:36, 11.68s/it] 41%|████      | 5191/12750 [16:55:48<24:29:53, 11.67s/it] 41%|████      | 5192/12750 [16:55:59<24:28:07, 11.65s/it] 41%|████      | 5193/12750 [16:56:11<24:26:28, 11.64s/it] 41%|████      | 5194/12750 [16:56:23<24:26:31, 11.65s/it] 41%|████      | 5195/12750 [16:56:34<24:26:30, 11.65s/it] 41%|████      | 5196/12750 [16:56:46<24:25:50, 11.64s/it] 41%|████      | 5197/12750 [16:56:57<24:24:06, 11.63s/it] 41%|████      | 5198/12750 [16:57:09<24:23:04, 11.62s/it] 41%|████      | 5199/12750 [16:57:21<24:22:04, 11.62s/it] 41%|████      | 5200/12750 [16:57:32<24:21:50, 11.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120601.96lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104841.58lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5200
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5200/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5200/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5175] due to args.save_total_limit
 41%|████      | 5201/12750 [16:57:44<24:33:49, 11.71s/it] 41%|████      | 5202/12750 [16:57:56<24:31:12, 11.69s/it] 41%|████      | 5203/12750 [16:58:08<24:29:35, 11.68s/it] 41%|████      | 5204/12750 [16:58:19<24:27:46, 11.67s/it] 41%|████      | 5205/12750 [16:58:31<24:24:35, 11.65s/it] 41%|████      | 5206/12750 [16:58:42<24:24:34, 11.65s/it] 41%|████      | 5207/12750 [16:58:54<24:24:25, 11.65s/it] 41%|████      | 5208/12750 [16:59:06<24:24:42, 11.65s/it] 41%|████      | 5209/12750 [16:59:17<24:24:24, 11.65s/it] 41%|████      | 5210/12750 [16:59:29<24:23:47, 11.65s/it] 41%|████      | 5211/12750 [16:59:41<24:23:16, 11.65s/it] 41%|████      | 5212/12750 [16:59:52<24:24:05, 11.65s/it] 41%|████      | 5213/12750 [17:00:12<29:13:26, 13.96s/it] 41%|████      | 5214/12750 [17:00:23<27:45:53, 13.26s/it] 41%|████      | 5215/12750 [17:00:35<26:42:32, 12.76s/it] 41%|████      | 5216/12750 [17:00:46<25:58:32, 12.41s/it] 41%|████      | 5217/12750 [17:00:58<25:26:32, 12.16s/it] 41%|████      | 5218/12750 [17:01:10<25:04:48, 11.99s/it] 41%|████      | 5219/12750 [17:01:21<24:51:32, 11.88s/it] 41%|████      | 5220/12750 [17:01:33<24:40:34, 11.80s/it] 41%|████      | 5221/12750 [17:01:44<24:33:00, 11.74s/it] 41%|████      | 5222/12750 [17:01:56<24:26:51, 11.69s/it] 41%|████      | 5223/12750 [17:02:08<24:23:37, 11.67s/it] 41%|████      | 5224/12750 [17:02:19<24:21:21, 11.65s/it] 41%|████      | 5225/12750 [17:02:31<24:19:57, 11.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120518.92lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104797.73lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5225
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5225/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5225/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5200] due to args.save_total_limit
 41%|████      | 5226/12750 [17:02:43<24:29:17, 11.72s/it] 41%|████      | 5227/12750 [17:02:54<24:24:50, 11.68s/it] 41%|████      | 5228/12750 [17:03:06<24:21:43, 11.66s/it] 41%|████      | 5229/12750 [17:03:18<24:20:12, 11.65s/it] 41%|████      | 5230/12750 [17:03:29<24:18:09, 11.63s/it] 41%|████      | 5231/12750 [17:03:41<24:17:11, 11.63s/it] 41%|████      | 5232/12750 [17:03:52<24:15:42, 11.62s/it] 41%|████      | 5233/12750 [17:04:04<24:16:10, 11.62s/it] 41%|████      | 5234/12750 [17:04:16<24:12:12, 11.59s/it] 41%|████      | 5235/12750 [17:04:27<24:13:35, 11.61s/it] 41%|████      | 5236/12750 [17:04:39<24:13:04, 11.60s/it] 41%|████      | 5237/12750 [17:04:50<24:14:04, 11.61s/it] 41%|████      | 5238/12750 [17:05:02<24:14:13, 11.62s/it] 41%|████      | 5239/12750 [17:05:14<24:14:28, 11.62s/it] 41%|████      | 5240/12750 [17:05:25<24:13:33, 11.61s/it] 41%|████      | 5241/12750 [17:05:37<24:12:52, 11.61s/it] 41%|████      | 5242/12750 [17:05:49<24:13:45, 11.62s/it] 41%|████      | 5243/12750 [17:06:00<24:14:08, 11.62s/it] 41%|████      | 5244/12750 [17:06:12<24:13:39, 11.62s/it] 41%|████      | 5245/12750 [17:06:31<28:57:41, 13.89s/it] 41%|████      | 5246/12750 [17:06:43<27:32:09, 13.21s/it] 41%|████      | 5247/12750 [17:06:54<26:28:21, 12.70s/it] 41%|████      | 5248/12750 [17:07:06<25:46:27, 12.37s/it] 41%|████      | 5249/12750 [17:07:17<25:17:35, 12.14s/it] 41%|████      | 5250/12750 [17:07:29<24:57:17, 11.98s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120542.01lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104854.69lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5250
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5250/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5250/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5225] due to args.save_total_limit
 41%|████      | 5251/12750 [17:07:41<24:54:09, 11.95s/it] 41%|████      | 5252/12750 [17:07:52<24:36:18, 11.81s/it] 41%|████      | 5253/12750 [17:08:04<24:24:30, 11.72s/it] 41%|████      | 5254/12750 [17:08:15<24:16:22, 11.66s/it] 41%|████      | 5255/12750 [17:08:27<24:09:49, 11.61s/it] 41%|████      | 5256/12750 [17:08:38<24:06:26, 11.58s/it] 41%|████      | 5257/12750 [17:08:50<24:03:47, 11.56s/it] 41%|████      | 5258/12750 [17:09:01<24:02:04, 11.55s/it] 41%|████      | 5259/12750 [17:09:13<24:00:23, 11.54s/it] 41%|████▏     | 5260/12750 [17:09:24<23:58:16, 11.52s/it] 41%|████▏     | 5261/12750 [17:09:36<23:56:30, 11.51s/it] 41%|████▏     | 5262/12750 [17:09:47<23:55:55, 11.51s/it] 41%|████▏     | 5263/12750 [17:09:59<23:53:37, 11.49s/it] 41%|████▏     | 5264/12750 [17:10:10<23:52:25, 11.48s/it] 41%|████▏     | 5265/12750 [17:10:22<23:52:57, 11.49s/it] 41%|████▏     | 5266/12750 [17:10:33<23:54:12, 11.50s/it] 41%|████▏     | 5267/12750 [17:10:45<23:55:01, 11.51s/it] 41%|████▏     | 5268/12750 [17:10:56<23:54:51, 11.51s/it] 41%|████▏     | 5269/12750 [17:11:08<23:54:08, 11.50s/it] 41%|████▏     | 5270/12750 [17:11:19<23:53:34, 11.50s/it] 41%|████▏     | 5271/12750 [17:11:31<23:53:49, 11.50s/it] 41%|████▏     | 5272/12750 [17:11:42<23:53:10, 11.50s/it] 41%|████▏     | 5273/12750 [17:11:54<23:52:46, 11.50s/it] 41%|████▏     | 5274/12750 [17:12:05<23:55:15, 11.52s/it] 41%|████▏     | 5275/12750 [17:12:17<23:54:45, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120627.53lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104929.11lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5275
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5275/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5275/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5250] due to args.save_total_limit
 41%|████▏     | 5276/12750 [17:12:29<24:06:06, 11.61s/it] 41%|████▏     | 5277/12750 [17:12:47<28:29:31, 13.73s/it] 41%|████▏     | 5278/12750 [17:12:59<27:04:39, 13.05s/it] 41%|████▏     | 5279/12750 [17:13:10<26:06:18, 12.58s/it] 41%|████▏     | 5280/12750 [17:13:22<25:25:12, 12.25s/it] 41%|████▏     | 5281/12750 [17:13:33<24:56:45, 12.02s/it] 41%|████▏     | 5282/12750 [17:13:45<24:37:21, 11.87s/it] 41%|████▏     | 5283/12750 [17:13:56<24:21:43, 11.75s/it] 41%|████▏     | 5284/12750 [17:14:08<24:11:55, 11.67s/it] 41%|████▏     | 5285/12750 [17:14:19<24:05:15, 11.62s/it] 41%|████▏     | 5286/12750 [17:14:31<23:59:31, 11.57s/it] 41%|████▏     | 5287/12750 [17:14:42<23:55:32, 11.54s/it] 41%|████▏     | 5288/12750 [17:14:54<23:51:47, 11.51s/it] 41%|████▏     | 5289/12750 [17:15:05<23:50:55, 11.51s/it] 41%|████▏     | 5290/12750 [17:15:17<23:48:54, 11.49s/it] 41%|████▏     | 5291/12750 [17:15:28<23:47:02, 11.48s/it] 42%|████▏     | 5292/12750 [17:15:40<23:48:02, 11.49s/it] 42%|████▏     | 5293/12750 [17:15:51<23:48:19, 11.49s/it] 42%|████▏     | 5294/12750 [17:16:03<23:48:00, 11.49s/it] 42%|████▏     | 5295/12750 [17:16:14<23:47:34, 11.49s/it] 42%|████▏     | 5296/12750 [17:16:25<23:47:07, 11.49s/it] 42%|████▏     | 5297/12750 [17:16:37<23:45:43, 11.48s/it] 42%|████▏     | 5298/12750 [17:16:48<23:46:02, 11.48s/it] 42%|████▏     | 5299/12750 [17:17:00<23:46:11, 11.48s/it] 42%|████▏     | 5300/12750 [17:17:11<23:47:09, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120561.65lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104882.17lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5300
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5300/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5300/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5275] due to args.save_total_limit
 42%|████▏     | 5301/12750 [17:17:23<23:57:27, 11.58s/it] 42%|████▏     | 5302/12750 [17:17:35<23:53:20, 11.55s/it] 42%|████▏     | 5303/12750 [17:17:46<23:50:03, 11.52s/it] 42%|████▏     | 5304/12750 [17:17:58<23:48:21, 11.51s/it] 42%|████▏     | 5305/12750 [17:18:09<23:46:02, 11.49s/it] 42%|████▏     | 5306/12750 [17:18:21<23:45:17, 11.49s/it] 42%|████▏     | 5307/12750 [17:18:32<23:44:02, 11.48s/it] 42%|████▏     | 5308/12750 [17:18:43<23:43:15, 11.47s/it] 42%|████▏     | 5309/12750 [17:19:03<28:28:24, 13.78s/it] 42%|████▏     | 5310/12750 [17:19:14<27:02:16, 13.08s/it] 42%|████▏     | 5311/12750 [17:19:26<26:02:00, 12.60s/it] 42%|████▏     | 5312/12750 [17:19:37<25:20:19, 12.26s/it] 42%|████▏     | 5313/12750 [17:19:49<24:50:43, 12.03s/it] 42%|████▏     | 5314/12750 [17:20:00<24:29:54, 11.86s/it] 42%|████▏     | 5315/12750 [17:20:11<24:15:33, 11.75s/it] 42%|████▏     | 5316/12750 [17:20:23<24:05:18, 11.67s/it] 42%|████▏     | 5317/12750 [17:20:35<24:06:28, 11.68s/it] 42%|████▏     | 5318/12750 [17:20:46<24:00:23, 11.63s/it] 42%|████▏     | 5319/12750 [17:20:58<23:55:01, 11.59s/it] 42%|████▏     | 5320/12750 [17:21:09<23:52:10, 11.57s/it] 42%|████▏     | 5321/12750 [17:21:21<23:48:52, 11.54s/it] 42%|████▏     | 5322/12750 [17:21:32<23:47:22, 11.53s/it] 42%|████▏     | 5323/12750 [17:21:44<23:46:48, 11.53s/it] 42%|████▏     | 5324/12750 [17:21:55<23:45:15, 11.52s/it] 42%|████▏     | 5325/12750 [17:22:07<23:44:40, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120610.44lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104792.30lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5325
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5325/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5325/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5150] due to args.save_total_limit
 42%|████▏     | 5326/12750 [17:22:18<23:54:18, 11.59s/it] 42%|████▏     | 5327/12750 [17:22:30<23:51:11, 11.57s/it] 42%|████▏     | 5328/12750 [17:22:41<23:47:20, 11.54s/it] 42%|████▏     | 5329/12750 [17:22:53<23:45:01, 11.52s/it] 42%|████▏     | 5330/12750 [17:23:04<23:44:02, 11.52s/it] 42%|████▏     | 5331/12750 [17:23:16<23:43:54, 11.52s/it] 42%|████▏     | 5332/12750 [17:23:27<23:44:23, 11.52s/it] 42%|████▏     | 5333/12750 [17:23:39<23:42:07, 11.50s/it] 42%|████▏     | 5334/12750 [17:23:50<23:42:24, 11.51s/it] 42%|████▏     | 5335/12750 [17:24:02<23:40:34, 11.49s/it] 42%|████▏     | 5336/12750 [17:24:13<23:40:01, 11.49s/it] 42%|████▏     | 5337/12750 [17:24:25<23:39:08, 11.49s/it] 42%|████▏     | 5338/12750 [17:24:36<23:39:23, 11.49s/it] 42%|████▏     | 5339/12750 [17:24:48<23:40:06, 11.50s/it] 42%|████▏     | 5340/12750 [17:24:59<23:39:50, 11.50s/it] 42%|████▏     | 5341/12750 [17:25:20<29:10:43, 14.18s/it] 42%|████▏     | 5342/12750 [17:25:31<27:30:43, 13.37s/it] 42%|████▏     | 5343/12750 [17:25:43<26:21:14, 12.81s/it] 42%|████▏     | 5344/12750 [17:25:54<25:32:04, 12.41s/it] 42%|████▏     | 5345/12750 [17:26:06<24:58:15, 12.14s/it] 42%|████▏     | 5346/12750 [17:26:17<24:34:20, 11.95s/it] 42%|████▏     | 5347/12750 [17:26:29<24:16:19, 11.80s/it] 42%|████▏     | 5348/12750 [17:26:40<24:04:12, 11.71s/it] 42%|████▏     | 5349/12750 [17:26:52<23:57:18, 11.65s/it] 42%|████▏     | 5350/12750 [17:27:03<23:51:34, 11.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120533.55lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104774.07lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5350
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5350/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5350/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5300] due to args.save_total_limit
 42%|████▏     | 5351/12750 [17:27:15<23:58:19, 11.66s/it] 42%|████▏     | 5352/12750 [17:27:27<23:52:27, 11.62s/it] 42%|████▏     | 5353/12750 [17:27:38<23:46:45, 11.57s/it] 42%|████▏     | 5354/12750 [17:27:50<23:43:12, 11.55s/it] 42%|████▏     | 5355/12750 [17:28:01<23:39:30, 11.52s/it] 42%|████▏     | 5356/12750 [17:28:12<23:37:43, 11.50s/it] 42%|████▏     | 5357/12750 [17:28:24<23:36:02, 11.49s/it] 42%|████▏     | 5358/12750 [17:28:35<23:36:27, 11.50s/it] 42%|████▏     | 5359/12750 [17:28:47<23:37:13, 11.50s/it] 42%|████▏     | 5360/12750 [17:28:58<23:36:55, 11.50s/it] 42%|████▏     | 5361/12750 [17:29:10<23:37:00, 11.51s/it] 42%|████▏     | 5362/12750 [17:29:21<23:36:27, 11.50s/it] 42%|████▏     | 5363/12750 [17:29:33<23:36:19, 11.50s/it] 42%|████▏     | 5364/12750 [17:29:44<23:36:28, 11.51s/it] 42%|████▏     | 5365/12750 [17:29:56<23:36:27, 11.51s/it] 42%|████▏     | 5366/12750 [17:30:07<23:36:10, 11.51s/it] 42%|████▏     | 5367/12750 [17:30:19<23:36:25, 11.51s/it] 42%|████▏     | 5368/12750 [17:30:30<23:35:34, 11.51s/it] 42%|████▏     | 5369/12750 [17:30:42<23:36:02, 11.51s/it] 42%|████▏     | 5370/12750 [17:30:53<23:34:36, 11.50s/it] 42%|████▏     | 5371/12750 [17:31:05<23:32:53, 11.49s/it] 42%|████▏     | 5372/12750 [17:31:16<23:32:56, 11.49s/it] 42%|████▏     | 5373/12750 [17:31:28<23:33:57, 11.50s/it] 42%|████▏     | 5374/12750 [17:31:47<28:18:00, 13.81s/it] 42%|████▏     | 5375/12750 [17:31:59<26:54:09, 13.13s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120587.84lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104892.76lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5375
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5375/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5375/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5350] due to args.save_total_limit
 42%|████▏     | 5376/12750 [17:32:11<26:07:31, 12.75s/it] 42%|████▏     | 5377/12750 [17:32:22<25:24:25, 12.41s/it] 42%|████▏     | 5378/12750 [17:32:34<24:51:35, 12.14s/it] 42%|████▏     | 5379/12750 [17:32:45<24:28:57, 11.96s/it] 42%|████▏     | 5380/12750 [17:32:57<24:12:45, 11.83s/it] 42%|████▏     | 5381/12750 [17:33:08<24:03:50, 11.76s/it] 42%|████▏     | 5382/12750 [17:33:20<23:56:18, 11.70s/it] 42%|████▏     | 5383/12750 [17:33:31<23:50:34, 11.65s/it] 42%|████▏     | 5384/12750 [17:33:43<23:46:28, 11.62s/it] 42%|████▏     | 5385/12750 [17:33:55<23:42:50, 11.59s/it] 42%|████▏     | 5386/12750 [17:34:06<23:40:39, 11.58s/it] 42%|████▏     | 5387/12750 [17:34:18<23:37:22, 11.55s/it] 42%|████▏     | 5388/12750 [17:34:29<23:36:45, 11.55s/it] 42%|████▏     | 5389/12750 [17:34:41<23:35:56, 11.54s/it] 42%|████▏     | 5390/12750 [17:34:52<23:36:23, 11.55s/it] 42%|████▏     | 5391/12750 [17:35:04<23:36:01, 11.55s/it] 42%|████▏     | 5392/12750 [17:35:15<23:35:07, 11.54s/it] 42%|████▏     | 5393/12750 [17:35:27<23:33:43, 11.53s/it] 42%|████▏     | 5394/12750 [17:35:38<23:33:15, 11.53s/it] 42%|████▏     | 5395/12750 [17:35:50<23:33:58, 11.53s/it] 42%|████▏     | 5396/12750 [17:36:01<23:34:12, 11.54s/it] 42%|████▏     | 5397/12750 [17:36:13<23:33:28, 11.53s/it] 42%|████▏     | 5398/12750 [17:36:24<23:31:31, 11.52s/it] 42%|████▏     | 5399/12750 [17:36:36<23:31:21, 11.52s/it] 42%|████▏     | 5400/12750 [17:36:47<23:31:25, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120613.91lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104991.56lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5400
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5400/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5400/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5375] due to args.save_total_limit
 42%|████▏     | 5401/12750 [17:36:59<23:42:56, 11.62s/it] 42%|████▏     | 5402/12750 [17:37:11<23:37:13, 11.57s/it] 42%|████▏     | 5403/12750 [17:37:22<23:34:54, 11.55s/it] 42%|████▏     | 5404/12750 [17:37:34<23:32:29, 11.54s/it] 42%|████▏     | 5405/12750 [17:37:45<23:31:00, 11.53s/it] 42%|████▏     | 5406/12750 [17:38:04<28:12:06, 13.82s/it] 42%|████▏     | 5407/12750 [17:38:16<26:45:52, 13.12s/it] 42%|████▏     | 5408/12750 [17:38:27<25:45:32, 12.63s/it] 42%|████▏     | 5409/12750 [17:38:39<25:02:25, 12.28s/it] 42%|████▏     | 5410/12750 [17:38:50<24:34:10, 12.05s/it] 42%|████▏     | 5411/12750 [17:39:02<24:13:43, 11.88s/it] 42%|████▏     | 5412/12750 [17:39:13<23:59:38, 11.77s/it] 42%|████▏     | 5413/12750 [17:39:25<23:49:09, 11.69s/it] 42%|████▏     | 5414/12750 [17:39:36<23:42:23, 11.63s/it] 42%|████▏     | 5415/12750 [17:39:48<23:37:33, 11.60s/it] 42%|████▏     | 5416/12750 [17:39:59<23:33:56, 11.57s/it] 42%|████▏     | 5417/12750 [17:40:11<23:31:16, 11.55s/it] 42%|████▏     | 5418/12750 [17:40:22<23:30:22, 11.54s/it] 43%|████▎     | 5419/12750 [17:40:34<23:27:46, 11.52s/it] 43%|████▎     | 5420/12750 [17:40:45<23:25:17, 11.50s/it] 43%|████▎     | 5421/12750 [17:40:57<23:25:05, 11.50s/it] 43%|████▎     | 5422/12750 [17:41:08<23:24:33, 11.50s/it] 43%|████▎     | 5423/12750 [17:41:20<23:24:38, 11.50s/it] 43%|████▎     | 5424/12750 [17:41:31<23:24:37, 11.50s/it] 43%|████▎     | 5425/12750 [17:41:43<23:24:41, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120648.73lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104952.83lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5425
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5425/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5425/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5400] due to args.save_total_limit
 43%|████▎     | 5426/12750 [17:41:55<23:36:44, 11.61s/it] 43%|████▎     | 5427/12750 [17:42:06<23:32:46, 11.58s/it] 43%|████▎     | 5428/12750 [17:42:18<23:30:37, 11.56s/it] 43%|████▎     | 5429/12750 [17:42:29<23:28:20, 11.54s/it] 43%|████▎     | 5430/12750 [17:42:41<23:27:12, 11.53s/it] 43%|████▎     | 5431/12750 [17:42:52<23:26:12, 11.53s/it] 43%|████▎     | 5432/12750 [17:43:04<23:24:58, 11.52s/it] 43%|████▎     | 5433/12750 [17:43:15<23:24:30, 11.52s/it] 43%|████▎     | 5434/12750 [17:43:27<23:23:49, 11.51s/it] 43%|████▎     | 5435/12750 [17:43:38<23:24:29, 11.52s/it] 43%|████▎     | 5436/12750 [17:43:50<23:24:27, 11.52s/it] 43%|████▎     | 5437/12750 [17:44:01<23:24:15, 11.52s/it] 43%|████▎     | 5438/12750 [17:44:20<28:01:07, 13.79s/it] 43%|████▎     | 5439/12750 [17:44:32<26:37:33, 13.11s/it] 43%|████▎     | 5440/12750 [17:44:44<25:39:58, 12.64s/it] 43%|████▎     | 5441/12750 [17:44:55<24:59:04, 12.31s/it] 43%|████▎     | 5442/12750 [17:45:07<24:27:58, 12.05s/it] 43%|████▎     | 5443/12750 [17:45:18<24:07:12, 11.88s/it] 43%|████▎     | 5444/12750 [17:45:30<23:52:43, 11.77s/it] 43%|████▎     | 5445/12750 [17:45:41<23:43:21, 11.69s/it] 43%|████▎     | 5446/12750 [17:45:53<23:37:13, 11.64s/it] 43%|████▎     | 5447/12750 [17:46:04<23:33:06, 11.61s/it] 43%|████▎     | 5448/12750 [17:46:16<23:30:06, 11.59s/it] 43%|████▎     | 5449/12750 [17:46:27<23:27:52, 11.57s/it] 43%|████▎     | 5450/12750 [17:46:39<23:26:36, 11.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120694.38lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104983.68lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5450
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5450/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5450/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5425] due to args.save_total_limit
 43%|████▎     | 5451/12750 [17:46:51<23:35:46, 11.64s/it] 43%|████▎     | 5452/12750 [17:47:02<23:30:23, 11.60s/it] 43%|████▎     | 5453/12750 [17:47:13<23:26:01, 11.56s/it] 43%|████▎     | 5454/12750 [17:47:25<23:24:14, 11.55s/it] 43%|████▎     | 5455/12750 [17:47:37<23:23:24, 11.54s/it] 43%|████▎     | 5456/12750 [17:47:48<23:22:31, 11.54s/it] 43%|████▎     | 5457/12750 [17:48:00<23:21:14, 11.53s/it] 43%|████▎     | 5458/12750 [17:48:11<23:19:55, 11.52s/it] 43%|████▎     | 5459/12750 [17:48:23<23:21:22, 11.53s/it] 43%|████▎     | 5460/12750 [17:48:34<23:21:47, 11.54s/it] 43%|████▎     | 5461/12750 [17:48:46<23:25:44, 11.57s/it] 43%|████▎     | 5462/12750 [17:48:57<23:23:50, 11.56s/it] 43%|████▎     | 5463/12750 [17:49:09<23:22:14, 11.55s/it] 43%|████▎     | 5464/12750 [17:49:20<23:20:30, 11.53s/it] 43%|████▎     | 5465/12750 [17:49:32<23:18:55, 11.52s/it] 43%|████▎     | 5466/12750 [17:49:43<23:17:49, 11.51s/it] 43%|████▎     | 5467/12750 [17:49:55<23:16:40, 11.51s/it] 43%|████▎     | 5468/12750 [17:50:06<23:15:18, 11.50s/it] 43%|████▎     | 5469/12750 [17:50:18<23:15:08, 11.50s/it] 43%|████▎     | 5470/12750 [17:50:37<27:55:27, 13.81s/it] 43%|████▎     | 5471/12750 [17:50:49<26:30:48, 13.11s/it] 43%|████▎     | 5472/12750 [17:51:00<25:32:09, 12.63s/it] 43%|████▎     | 5473/12750 [17:51:12<24:50:13, 12.29s/it] 43%|████▎     | 5474/12750 [17:51:23<24:21:30, 12.05s/it] 43%|████▎     | 5475/12750 [17:51:34<24:00:47, 11.88s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120614.68lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104862.07lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5475
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5475/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5475/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5325] due to args.save_total_limit
 43%|████▎     | 5476/12750 [17:51:46<23:57:56, 11.86s/it] 43%|████▎     | 5477/12750 [17:51:58<23:44:30, 11.75s/it] 43%|████▎     | 5478/12750 [17:52:09<23:35:07, 11.68s/it] 43%|████▎     | 5479/12750 [17:52:21<23:28:16, 11.62s/it] 43%|████▎     | 5480/12750 [17:52:32<23:22:34, 11.58s/it] 43%|████▎     | 5481/12750 [17:52:44<23:20:21, 11.56s/it] 43%|████▎     | 5482/12750 [17:52:55<23:17:32, 11.54s/it] 43%|████▎     | 5483/12750 [17:53:07<23:16:04, 11.53s/it] 43%|████▎     | 5484/12750 [17:53:18<23:14:36, 11.52s/it] 43%|████▎     | 5485/12750 [17:53:30<23:13:21, 11.51s/it] 43%|████▎     | 5486/12750 [17:53:41<23:12:14, 11.50s/it] 43%|████▎     | 5487/12750 [17:53:53<23:12:55, 11.51s/it] 43%|████▎     | 5488/12750 [17:54:04<23:12:37, 11.51s/it] 43%|████▎     | 5489/12750 [17:54:16<23:15:40, 11.53s/it] 43%|████▎     | 5490/12750 [17:54:27<23:13:49, 11.52s/it] 43%|████▎     | 5491/12750 [17:54:39<23:13:34, 11.52s/it] 43%|████▎     | 5492/12750 [17:54:50<23:12:10, 11.51s/it] 43%|████▎     | 5493/12750 [17:55:02<23:12:23, 11.51s/it] 43%|████▎     | 5494/12750 [17:55:13<23:11:43, 11.51s/it] 43%|████▎     | 5495/12750 [17:55:25<23:10:14, 11.50s/it] 43%|████▎     | 5496/12750 [17:55:36<23:08:52, 11.49s/it] 43%|████▎     | 5497/12750 [17:55:48<23:10:34, 11.50s/it] 43%|████▎     | 5498/12750 [17:55:59<23:10:17, 11.50s/it] 43%|████▎     | 5499/12750 [17:56:11<23:10:25, 11.51s/it] 43%|████▎     | 5500/12750 [17:56:22<23:11:06, 11.51s/it]                                                           43%|████▎     | 5500/12750 [17:56:22<23:11:06, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120796.34lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 105035.97lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5500
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5500/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5500/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5450] due to args.save_total_limit
 43%|████▎     | 5501/12750 [17:56:34<23:22:37, 11.61s/it] 43%|████▎     | 5502/12750 [17:56:54<28:01:00, 13.92s/it] 43%|████▎     | 5503/12750 [17:57:05<26:31:08, 13.17s/it] 43%|████▎     | 5504/12750 [17:57:16<25:29:37, 12.67s/it] 43%|████▎     | 5505/12750 [17:57:28<24:46:20, 12.31s/it] 43%|████▎     | 5506/12750 [17:57:39<24:16:17, 12.06s/it] 43%|████▎     | 5507/12750 [17:57:51<23:56:05, 11.90s/it] 43%|████▎     | 5508/12750 [17:58:02<23:41:59, 11.78s/it] 43%|████▎     | 5509/12750 [17:58:14<23:39:37, 11.76s/it] 43%|████▎     | 5510/12750 [17:58:26<23:30:15, 11.69s/it] 43%|████▎     | 5511/12750 [17:58:37<23:22:44, 11.63s/it] 43%|████▎     | 5512/12750 [17:58:49<23:18:40, 11.59s/it] 43%|████▎     | 5513/12750 [17:59:00<23:13:52, 11.56s/it] 43%|████▎     | 5514/12750 [17:59:12<23:10:46, 11.53s/it] 43%|████▎     | 5515/12750 [17:59:23<23:08:41, 11.52s/it] 43%|████▎     | 5516/12750 [17:59:35<23:05:53, 11.49s/it] 43%|████▎     | 5517/12750 [17:59:46<23:05:35, 11.49s/it] 43%|████▎     | 5518/12750 [17:59:57<23:04:19, 11.48s/it] 43%|████▎     | 5519/12750 [18:00:09<23:06:25, 11.50s/it] 43%|████▎     | 5520/12750 [18:00:20<23:04:49, 11.49s/it] 43%|████▎     | 5521/12750 [18:00:32<23:04:28, 11.49s/it] 43%|████▎     | 5522/12750 [18:00:43<23:03:30, 11.48s/it] 43%|████▎     | 5523/12750 [18:00:55<23:03:10, 11.48s/it] 43%|████▎     | 5524/12750 [18:01:06<23:02:53, 11.48s/it] 43%|████▎     | 5525/12750 [18:01:18<23:03:07, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120626.88lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104789.00lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5525
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5525/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5525/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5500] due to args.save_total_limit
 43%|████▎     | 5526/12750 [18:01:30<23:14:37, 11.58s/it] 43%|████▎     | 5527/12750 [18:01:41<23:09:34, 11.54s/it] 43%|████▎     | 5528/12750 [18:01:53<23:07:52, 11.53s/it] 43%|████▎     | 5529/12750 [18:02:04<23:06:33, 11.52s/it] 43%|████▎     | 5530/12750 [18:02:16<23:05:38, 11.52s/it] 43%|████▎     | 5531/12750 [18:02:27<23:04:11, 11.50s/it] 43%|████▎     | 5532/12750 [18:02:39<23:03:25, 11.50s/it] 43%|████▎     | 5533/12750 [18:02:50<23:03:18, 11.50s/it] 43%|████▎     | 5534/12750 [18:03:09<27:26:58, 13.69s/it] 43%|████▎     | 5535/12750 [18:03:20<26:07:11, 13.03s/it] 43%|████▎     | 5536/12750 [18:03:32<25:10:59, 12.57s/it] 43%|████▎     | 5537/12750 [18:03:43<24:32:27, 12.25s/it] 43%|████▎     | 5538/12750 [18:03:55<24:04:19, 12.02s/it] 43%|████▎     | 5539/12750 [18:04:06<23:45:37, 11.86s/it] 43%|████▎     | 5540/12750 [18:04:18<23:31:49, 11.75s/it] 43%|████▎     | 5541/12750 [18:04:29<23:21:57, 11.67s/it] 43%|████▎     | 5542/12750 [18:04:41<23:14:56, 11.61s/it] 43%|████▎     | 5543/12750 [18:04:52<23:09:49, 11.57s/it] 43%|████▎     | 5544/12750 [18:05:04<23:05:30, 11.54s/it] 43%|████▎     | 5545/12750 [18:05:15<23:04:10, 11.53s/it] 43%|████▎     | 5546/12750 [18:05:27<23:01:40, 11.51s/it] 44%|████▎     | 5547/12750 [18:05:38<23:00:15, 11.50s/it] 44%|████▎     | 5548/12750 [18:05:50<22:59:29, 11.49s/it] 44%|████▎     | 5549/12750 [18:06:01<22:58:50, 11.49s/it] 44%|████▎     | 5550/12750 [18:06:13<22:57:32, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120627.40lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104943.79lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5550
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5550/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5550/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5525] due to args.save_total_limit
 44%|████▎     | 5551/12750 [18:06:24<23:09:20, 11.58s/it] 44%|████▎     | 5552/12750 [18:06:36<23:05:12, 11.55s/it] 44%|████▎     | 5553/12750 [18:06:47<23:01:39, 11.52s/it] 44%|████▎     | 5554/12750 [18:06:59<22:58:39, 11.50s/it] 44%|████▎     | 5555/12750 [18:07:10<22:56:46, 11.48s/it] 44%|████▎     | 5556/12750 [18:07:22<22:56:09, 11.48s/it] 44%|████▎     | 5557/12750 [18:07:33<22:55:34, 11.47s/it] 44%|████▎     | 5558/12750 [18:07:45<22:56:04, 11.48s/it] 44%|████▎     | 5559/12750 [18:07:56<22:55:46, 11.48s/it] 44%|████▎     | 5560/12750 [18:08:08<22:55:34, 11.48s/it] 44%|████▎     | 5561/12750 [18:08:19<22:54:33, 11.47s/it] 44%|████▎     | 5562/12750 [18:08:31<22:54:13, 11.47s/it] 44%|████▎     | 5563/12750 [18:08:42<22:54:00, 11.47s/it] 44%|████▎     | 5564/12750 [18:08:54<22:55:02, 11.48s/it] 44%|████▎     | 5565/12750 [18:09:05<22:55:54, 11.49s/it] 44%|████▎     | 5566/12750 [18:09:24<27:32:27, 13.80s/it] 44%|████▎     | 5567/12750 [18:09:36<26:08:11, 13.10s/it] 44%|████▎     | 5568/12750 [18:09:47<25:10:22, 12.62s/it] 44%|████▎     | 5569/12750 [18:09:59<24:28:50, 12.27s/it] 44%|████▎     | 5570/12750 [18:10:10<24:00:48, 12.04s/it] 44%|████▎     | 5571/12750 [18:10:22<23:40:32, 11.87s/it] 44%|████▎     | 5572/12750 [18:10:33<23:26:36, 11.76s/it] 44%|████▎     | 5573/12750 [18:10:45<23:15:56, 11.67s/it] 44%|████▎     | 5574/12750 [18:10:56<23:08:30, 11.61s/it] 44%|████▎     | 5575/12750 [18:11:08<23:02:49, 11.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120603.12lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104956.14lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5575
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5575/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5575/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5550] due to args.save_total_limit
 44%|████▎     | 5576/12750 [18:11:19<23:11:24, 11.64s/it] 44%|████▎     | 5577/12750 [18:11:31<23:05:32, 11.59s/it] 44%|████▎     | 5578/12750 [18:11:42<23:00:49, 11.55s/it] 44%|████▍     | 5579/12750 [18:11:54<22:58:07, 11.53s/it] 44%|████▍     | 5580/12750 [18:12:05<22:56:17, 11.52s/it] 44%|████▍     | 5581/12750 [18:12:17<22:54:30, 11.50s/it] 44%|████▍     | 5582/12750 [18:12:28<22:53:52, 11.50s/it] 44%|████▍     | 5583/12750 [18:12:40<22:52:40, 11.49s/it] 44%|████▍     | 5584/12750 [18:12:51<22:51:59, 11.49s/it] 44%|████▍     | 5585/12750 [18:13:03<22:51:34, 11.49s/it] 44%|████▍     | 5586/12750 [18:13:14<22:50:18, 11.48s/it] 44%|████▍     | 5587/12750 [18:13:26<22:50:50, 11.48s/it] 44%|████▍     | 5588/12750 [18:13:37<22:51:47, 11.49s/it] 44%|████▍     | 5589/12750 [18:13:49<22:51:42, 11.49s/it] 44%|████▍     | 5590/12750 [18:14:00<22:51:09, 11.49s/it] 44%|████▍     | 5591/12750 [18:14:12<22:50:04, 11.48s/it] 44%|████▍     | 5592/12750 [18:14:23<22:50:17, 11.49s/it] 44%|████▍     | 5593/12750 [18:14:35<22:49:51, 11.48s/it] 44%|████▍     | 5594/12750 [18:14:46<22:50:16, 11.49s/it] 44%|████▍     | 5595/12750 [18:14:58<22:49:29, 11.48s/it] 44%|████▍     | 5596/12750 [18:15:09<22:48:53, 11.48s/it] 44%|████▍     | 5597/12750 [18:15:20<22:48:29, 11.48s/it] 44%|████▍     | 5598/12750 [18:15:40<27:25:42, 13.81s/it] 44%|████▍     | 5599/12750 [18:15:51<26:02:49, 13.11s/it] 44%|████▍     | 5600/12750 [18:16:03<25:03:35, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120597.72lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104871.10lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5600
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5600/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5600/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5575] due to args.save_total_limit
 44%|████▍     | 5601/12750 [18:16:14<24:34:33, 12.38s/it] 44%|████▍     | 5602/12750 [18:16:26<24:03:01, 12.11s/it] 44%|████▍     | 5603/12750 [18:16:37<23:39:57, 11.92s/it] 44%|████▍     | 5604/12750 [18:16:49<23:24:57, 11.80s/it] 44%|████▍     | 5605/12750 [18:17:00<23:13:53, 11.71s/it] 44%|████▍     | 5606/12750 [18:17:12<23:05:30, 11.64s/it] 44%|████▍     | 5607/12750 [18:17:23<23:00:06, 11.59s/it] 44%|████▍     | 5608/12750 [18:17:35<22:55:36, 11.56s/it] 44%|████▍     | 5609/12750 [18:17:42<20:12:56, 10.19s/it] 44%|████▍     | 5610/12750 [18:17:43<14:37:09,  7.37s/it] 44%|████▍     | 5611/12750 [18:18:06<24:08:36, 12.17s/it] 44%|████▍     | 5612/12750 [18:18:18<23:48:02, 12.00s/it] 44%|████▍     | 5613/12750 [18:18:29<23:31:44, 11.87s/it] 44%|████▍     | 5614/12750 [18:18:41<23:21:00, 11.78s/it] 44%|████▍     | 5615/12750 [18:18:52<23:13:44, 11.72s/it] 44%|████▍     | 5616/12750 [18:19:04<23:07:52, 11.67s/it] 44%|████▍     | 5617/12750 [18:19:16<23:04:28, 11.65s/it] 44%|████▍     | 5618/12750 [18:19:27<23:01:43, 11.62s/it] 44%|████▍     | 5619/12750 [18:19:39<22:59:35, 11.61s/it] 44%|████▍     | 5620/12750 [18:19:50<22:57:41, 11.59s/it] 44%|████▍     | 5621/12750 [18:20:02<22:56:30, 11.59s/it] 44%|████▍     | 5622/12750 [18:20:13<22:55:10, 11.58s/it] 44%|████▍     | 5623/12750 [18:20:25<22:55:42, 11.58s/it] 44%|████▍     | 5624/12750 [18:20:36<22:54:31, 11.57s/it] 44%|████▍     | 5625/12750 [18:20:48<22:54:19, 11.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120646.93lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104926.87lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5625
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5625/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5625/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5600] due to args.save_total_limit
 44%|████▍     | 5626/12750 [18:21:00<23:05:26, 11.67s/it] 44%|████▍     | 5627/12750 [18:21:11<23:00:18, 11.63s/it] 44%|████▍     | 5628/12750 [18:21:23<22:56:53, 11.60s/it] 44%|████▍     | 5629/12750 [18:21:35<22:54:51, 11.58s/it] 44%|████▍     | 5630/12750 [18:21:46<22:56:53, 11.60s/it] 44%|████▍     | 5631/12750 [18:22:05<27:20:30, 13.83s/it] 44%|████▍     | 5632/12750 [18:22:17<25:57:54, 13.13s/it] 44%|████▍     | 5633/12750 [18:22:28<24:58:50, 12.64s/it] 44%|████▍     | 5634/12750 [18:22:40<24:18:58, 12.30s/it] 44%|████▍     | 5635/12750 [18:22:51<23:51:06, 12.07s/it] 44%|████▍     | 5636/12750 [18:23:03<23:30:41, 11.90s/it] 44%|████▍     | 5637/12750 [18:23:14<23:16:10, 11.78s/it] 44%|████▍     | 5638/12750 [18:23:26<23:07:00, 11.70s/it] 44%|████▍     | 5639/12750 [18:23:37<22:58:38, 11.63s/it] 44%|████▍     | 5640/12750 [18:23:49<22:53:30, 11.59s/it] 44%|████▍     | 5641/12750 [18:24:00<22:50:33, 11.57s/it] 44%|████▍     | 5642/12750 [18:24:12<22:46:19, 11.53s/it] 44%|████▍     | 5643/12750 [18:24:23<22:44:27, 11.52s/it] 44%|████▍     | 5644/12750 [18:24:35<22:42:32, 11.50s/it] 44%|████▍     | 5645/12750 [18:24:46<22:41:53, 11.50s/it] 44%|████▍     | 5646/12750 [18:24:58<22:41:31, 11.50s/it] 44%|████▍     | 5647/12750 [18:25:09<22:41:05, 11.50s/it] 44%|████▍     | 5648/12750 [18:25:21<22:40:42, 11.50s/it] 44%|████▍     | 5649/12750 [18:25:32<22:41:02, 11.50s/it] 44%|████▍     | 5650/12750 [18:25:44<22:41:18, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120711.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104971.81lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5650
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5650/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5650/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5625] due to args.save_total_limit
 44%|████▍     | 5651/12750 [18:25:56<22:53:31, 11.61s/it] 44%|████▍     | 5652/12750 [18:26:07<22:50:51, 11.59s/it] 44%|████▍     | 5653/12750 [18:26:19<22:50:22, 11.59s/it] 44%|████▍     | 5654/12750 [18:26:30<22:49:22, 11.58s/it] 44%|████▍     | 5655/12750 [18:26:42<22:47:41, 11.57s/it] 44%|████▍     | 5656/12750 [18:26:53<22:47:18, 11.56s/it] 44%|████▍     | 5657/12750 [18:27:05<22:46:04, 11.56s/it] 44%|████▍     | 5658/12750 [18:27:16<22:46:05, 11.56s/it] 44%|████▍     | 5659/12750 [18:27:28<22:44:51, 11.55s/it] 44%|████▍     | 5660/12750 [18:27:39<22:43:43, 11.54s/it] 44%|████▍     | 5661/12750 [18:27:51<22:44:19, 11.55s/it] 44%|████▍     | 5662/12750 [18:28:03<22:44:13, 11.55s/it] 44%|████▍     | 5663/12750 [18:28:22<27:17:43, 13.87s/it] 44%|████▍     | 5664/12750 [18:28:33<25:53:30, 13.15s/it] 44%|████▍     | 5665/12750 [18:28:45<24:55:30, 12.66s/it] 44%|████▍     | 5666/12750 [18:28:56<24:13:48, 12.31s/it] 44%|████▍     | 5667/12750 [18:29:08<23:43:50, 12.06s/it] 44%|████▍     | 5668/12750 [18:29:19<23:23:21, 11.89s/it] 44%|████▍     | 5669/12750 [18:29:31<23:10:15, 11.78s/it] 44%|████▍     | 5670/12750 [18:29:42<23:00:06, 11.70s/it] 44%|████▍     | 5671/12750 [18:29:54<22:53:30, 11.64s/it] 44%|████▍     | 5672/12750 [18:30:05<22:49:02, 11.61s/it] 44%|████▍     | 5673/12750 [18:30:17<22:46:02, 11.58s/it] 45%|████▍     | 5674/12750 [18:30:28<22:44:00, 11.57s/it] 45%|████▍     | 5675/12750 [18:30:40<22:41:25, 11.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120599.14lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104885.86lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5675
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5675/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5675/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5650] due to args.save_total_limit
 45%|████▍     | 5676/12750 [18:30:52<22:51:41, 11.63s/it] 45%|████▍     | 5677/12750 [18:31:03<22:51:13, 11.63s/it] 45%|████▍     | 5678/12750 [18:31:15<22:48:37, 11.61s/it] 45%|████▍     | 5679/12750 [18:31:26<22:45:56, 11.59s/it] 45%|████▍     | 5680/12750 [18:31:38<22:43:20, 11.57s/it] 45%|████▍     | 5681/12750 [18:31:50<22:41:56, 11.56s/it] 45%|████▍     | 5682/12750 [18:32:01<22:41:05, 11.55s/it] 45%|████▍     | 5683/12750 [18:32:13<22:40:09, 11.55s/it] 45%|████▍     | 5684/12750 [18:32:24<22:39:14, 11.54s/it] 45%|████▍     | 5685/12750 [18:32:36<22:38:24, 11.54s/it] 45%|████▍     | 5686/12750 [18:32:47<22:37:10, 11.53s/it] 45%|████▍     | 5687/12750 [18:32:59<22:37:44, 11.53s/it] 45%|████▍     | 5688/12750 [18:33:10<22:36:52, 11.53s/it] 45%|████▍     | 5689/12750 [18:33:22<22:36:13, 11.52s/it] 45%|████▍     | 5690/12750 [18:33:33<22:36:32, 11.53s/it] 45%|████▍     | 5691/12750 [18:33:45<22:36:53, 11.53s/it] 45%|████▍     | 5692/12750 [18:33:56<22:36:07, 11.53s/it] 45%|████▍     | 5693/12750 [18:34:08<22:35:38, 11.53s/it] 45%|████▍     | 5694/12750 [18:34:19<22:35:31, 11.53s/it] 45%|████▍     | 5695/12750 [18:34:31<22:34:03, 11.52s/it] 45%|████▍     | 5696/12750 [18:34:50<27:05:41, 13.83s/it] 45%|████▍     | 5697/12750 [18:35:02<25:47:31, 13.16s/it] 45%|████▍     | 5698/12750 [18:35:13<24:47:39, 12.66s/it] 45%|████▍     | 5699/12750 [18:35:25<24:08:29, 12.33s/it] 45%|████▍     | 5700/12750 [18:35:36<23:39:27, 12.08s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120570.89lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104878.28lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5700
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5700/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5700/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5675] due to args.save_total_limit
 45%|████▍     | 5701/12750 [18:35:48<23:33:11, 12.03s/it] 45%|████▍     | 5702/12750 [18:36:00<23:14:26, 11.87s/it] 45%|████▍     | 5703/12750 [18:36:11<23:12:05, 11.85s/it] 45%|████▍     | 5704/12750 [18:36:23<23:00:31, 11.76s/it] 45%|████▍     | 5705/12750 [18:36:35<22:52:43, 11.69s/it] 45%|████▍     | 5706/12750 [18:36:46<22:49:09, 11.66s/it] 45%|████▍     | 5707/12750 [18:36:58<22:43:31, 11.62s/it] 45%|████▍     | 5708/12750 [18:37:09<22:40:40, 11.59s/it] 45%|████▍     | 5709/12750 [18:37:21<22:39:50, 11.59s/it] 45%|████▍     | 5710/12750 [18:37:32<22:39:02, 11.58s/it] 45%|████▍     | 5711/12750 [18:37:44<22:37:11, 11.57s/it] 45%|████▍     | 5712/12750 [18:37:55<22:36:22, 11.56s/it] 45%|████▍     | 5713/12750 [18:38:07<22:36:56, 11.57s/it] 45%|████▍     | 5714/12750 [18:38:19<22:36:19, 11.57s/it] 45%|████▍     | 5715/12750 [18:38:30<22:35:08, 11.56s/it] 45%|████▍     | 5716/12750 [18:38:42<22:32:13, 11.53s/it] 45%|████▍     | 5717/12750 [18:38:53<22:31:17, 11.53s/it] 45%|████▍     | 5718/12750 [18:39:05<22:30:38, 11.52s/it] 45%|████▍     | 5719/12750 [18:39:16<22:31:21, 11.53s/it] 45%|████▍     | 5720/12750 [18:39:28<22:32:31, 11.54s/it] 45%|████▍     | 5721/12750 [18:39:39<22:32:16, 11.54s/it] 45%|████▍     | 5722/12750 [18:39:51<22:31:25, 11.54s/it] 45%|████▍     | 5723/12750 [18:40:02<22:30:04, 11.53s/it] 45%|████▍     | 5724/12750 [18:40:14<22:29:54, 11.53s/it] 45%|████▍     | 5725/12750 [18:40:25<22:29:20, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120607.61lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104727.66lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5725
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5725/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5725/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5700] due to args.save_total_limit
 45%|████▍     | 5726/12750 [18:40:37<22:41:02, 11.63s/it] 45%|████▍     | 5727/12750 [18:40:49<22:36:46, 11.59s/it] 45%|████▍     | 5728/12750 [18:41:07<26:43:00, 13.70s/it] 45%|████▍     | 5729/12750 [18:41:19<25:24:39, 13.03s/it] 45%|████▍     | 5730/12750 [18:41:30<24:30:01, 12.56s/it] 45%|████▍     | 5731/12750 [18:41:42<23:52:03, 12.24s/it] 45%|████▍     | 5732/12750 [18:41:53<23:25:46, 12.02s/it] 45%|████▍     | 5733/12750 [18:42:05<23:07:34, 11.86s/it] 45%|████▍     | 5734/12750 [18:42:16<22:54:05, 11.75s/it] 45%|████▍     | 5735/12750 [18:42:28<22:44:50, 11.67s/it] 45%|████▍     | 5736/12750 [18:42:39<22:38:17, 11.62s/it] 45%|████▍     | 5737/12750 [18:42:51<22:33:08, 11.58s/it] 45%|████▌     | 5738/12750 [18:43:02<22:29:50, 11.55s/it] 45%|████▌     | 5739/12750 [18:43:14<22:28:24, 11.54s/it] 45%|████▌     | 5740/12750 [18:43:25<22:26:54, 11.53s/it] 45%|████▌     | 5741/12750 [18:43:37<22:24:27, 11.51s/it] 45%|████▌     | 5742/12750 [18:43:48<22:22:44, 11.50s/it] 45%|████▌     | 5743/12750 [18:44:00<22:21:42, 11.49s/it] 45%|████▌     | 5744/12750 [18:44:11<22:22:21, 11.50s/it] 45%|████▌     | 5745/12750 [18:44:23<22:21:03, 11.49s/it] 45%|████▌     | 5746/12750 [18:44:34<22:19:45, 11.48s/it] 45%|████▌     | 5747/12750 [18:44:46<22:19:12, 11.47s/it] 45%|████▌     | 5748/12750 [18:44:57<22:19:34, 11.48s/it] 45%|████▌     | 5749/12750 [18:45:08<22:18:35, 11.47s/it] 45%|████▌     | 5750/12750 [18:45:20<22:18:51, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120667.24lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104926.87lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5750
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5750/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5750/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5475] due to args.save_total_limit
 45%|████▌     | 5751/12750 [18:45:32<22:31:31, 11.59s/it] 45%|████▌     | 5752/12750 [18:45:43<22:29:32, 11.57s/it] 45%|████▌     | 5753/12750 [18:45:55<22:26:33, 11.55s/it] 45%|████▌     | 5754/12750 [18:46:06<22:23:29, 11.52s/it] 45%|████▌     | 5755/12750 [18:46:18<22:23:10, 11.52s/it] 45%|████▌     | 5756/12750 [18:46:29<22:22:54, 11.52s/it] 45%|████▌     | 5757/12750 [18:46:41<22:22:21, 11.52s/it] 45%|████▌     | 5758/12750 [18:46:52<22:20:42, 11.50s/it] 45%|████▌     | 5759/12750 [18:47:04<22:20:59, 11.51s/it] 45%|████▌     | 5760/12750 [18:47:23<27:01:05, 13.91s/it] 45%|████▌     | 5761/12750 [18:47:35<25:34:42, 13.18s/it] 45%|████▌     | 5762/12750 [18:47:46<24:35:54, 12.67s/it] 45%|████▌     | 5763/12750 [18:47:58<23:55:14, 12.32s/it] 45%|████▌     | 5764/12750 [18:48:09<23:25:51, 12.07s/it] 45%|████▌     | 5765/12750 [18:48:21<23:05:44, 11.90s/it] 45%|████▌     | 5766/12750 [18:48:32<22:51:25, 11.78s/it] 45%|████▌     | 5767/12750 [18:48:44<22:40:50, 11.69s/it] 45%|████▌     | 5768/12750 [18:48:55<22:33:31, 11.63s/it] 45%|████▌     | 5769/12750 [18:49:07<22:27:33, 11.58s/it] 45%|████▌     | 5770/12750 [18:49:18<22:24:08, 11.55s/it] 45%|████▌     | 5771/12750 [18:49:30<22:21:36, 11.53s/it] 45%|████▌     | 5772/12750 [18:49:41<22:18:30, 11.51s/it] 45%|████▌     | 5773/12750 [18:49:53<22:18:19, 11.51s/it] 45%|████▌     | 5774/12750 [18:50:04<22:17:43, 11.51s/it] 45%|████▌     | 5775/12750 [18:50:16<22:18:42, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120751.65lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104745.48lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5775
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5775/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5775/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5725] due to args.save_total_limit
 45%|████▌     | 5776/12750 [18:50:28<22:28:38, 11.60s/it] 45%|████▌     | 5777/12750 [18:50:39<22:23:46, 11.56s/it] 45%|████▌     | 5778/12750 [18:50:51<22:21:15, 11.54s/it] 45%|████▌     | 5779/12750 [18:51:02<22:19:49, 11.53s/it] 45%|████▌     | 5780/12750 [18:51:14<22:18:43, 11.52s/it] 45%|████▌     | 5781/12750 [18:51:25<22:18:14, 11.52s/it] 45%|████▌     | 5782/12750 [18:51:37<22:16:29, 11.51s/it] 45%|████▌     | 5783/12750 [18:51:48<22:16:34, 11.51s/it] 45%|████▌     | 5784/12750 [18:52:00<22:16:17, 11.51s/it] 45%|████▌     | 5785/12750 [18:52:11<22:16:10, 11.51s/it] 45%|████▌     | 5786/12750 [18:52:23<22:16:07, 11.51s/it] 45%|████▌     | 5787/12750 [18:52:34<22:16:31, 11.52s/it] 45%|████▌     | 5788/12750 [18:52:46<22:16:12, 11.52s/it] 45%|████▌     | 5789/12750 [18:52:57<22:15:12, 11.51s/it] 45%|████▌     | 5790/12750 [18:53:09<22:14:58, 11.51s/it] 45%|████▌     | 5791/12750 [18:53:20<22:14:58, 11.51s/it] 45%|████▌     | 5792/12750 [18:53:38<26:07:33, 13.52s/it] 45%|████▌     | 5793/12750 [18:53:50<24:56:10, 12.90s/it] 45%|████▌     | 5794/12750 [18:54:01<24:05:55, 12.47s/it] 45%|████▌     | 5795/12750 [18:54:13<23:30:52, 12.17s/it] 45%|████▌     | 5796/12750 [18:54:24<23:05:33, 11.95s/it] 45%|████▌     | 5797/12750 [18:54:36<22:47:35, 11.80s/it] 45%|████▌     | 5798/12750 [18:54:47<22:35:46, 11.70s/it] 45%|████▌     | 5799/12750 [18:54:59<22:27:17, 11.63s/it] 45%|████▌     | 5800/12750 [18:55:10<22:21:38, 11.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120631.25lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104924.73lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5800
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5800/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5800/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5775] due to args.save_total_limit
 45%|████▌     | 5801/12750 [18:55:22<22:29:22, 11.65s/it] 46%|████▌     | 5802/12750 [18:55:33<22:23:37, 11.60s/it] 46%|████▌     | 5803/12750 [18:55:45<22:19:40, 11.57s/it] 46%|████▌     | 5804/12750 [18:55:56<22:17:27, 11.55s/it] 46%|████▌     | 5805/12750 [18:56:08<22:13:13, 11.52s/it] 46%|████▌     | 5806/12750 [18:56:19<22:12:31, 11.51s/it] 46%|████▌     | 5807/12750 [18:56:31<22:10:59, 11.50s/it] 46%|████▌     | 5808/12750 [18:56:42<22:10:22, 11.50s/it] 46%|████▌     | 5809/12750 [18:56:54<22:09:49, 11.50s/it] 46%|████▌     | 5810/12750 [18:57:05<22:08:25, 11.48s/it] 46%|████▌     | 5811/12750 [18:57:17<22:08:49, 11.49s/it] 46%|████▌     | 5812/12750 [18:57:28<22:07:40, 11.48s/it] 46%|████▌     | 5813/12750 [18:57:40<22:07:28, 11.48s/it] 46%|████▌     | 5814/12750 [18:57:51<22:08:08, 11.49s/it] 46%|████▌     | 5815/12750 [18:58:03<22:08:21, 11.49s/it] 46%|████▌     | 5816/12750 [18:58:14<22:06:40, 11.48s/it] 46%|████▌     | 5817/12750 [18:58:26<22:06:39, 11.48s/it] 46%|████▌     | 5818/12750 [18:58:37<22:06:11, 11.48s/it] 46%|████▌     | 5819/12750 [18:58:49<22:05:48, 11.48s/it] 46%|████▌     | 5820/12750 [18:59:00<22:05:48, 11.48s/it] 46%|████▌     | 5821/12750 [18:59:11<22:05:08, 11.47s/it] 46%|████▌     | 5822/12750 [18:59:23<22:05:42, 11.48s/it] 46%|████▌     | 5823/12750 [18:59:34<22:04:56, 11.48s/it] 46%|████▌     | 5824/12750 [18:59:54<26:31:55, 13.79s/it] 46%|████▌     | 5825/12750 [19:00:05<25:11:45, 13.10s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120709.95lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104829.16lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5825
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5825/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5825/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5800] due to args.save_total_limit
 46%|████▌     | 5826/12750 [19:00:17<24:26:05, 12.70s/it] 46%|████▌     | 5827/12750 [19:00:28<23:44:07, 12.34s/it] 46%|████▌     | 5828/12750 [19:00:40<23:14:33, 12.09s/it] 46%|████▌     | 5829/12750 [19:00:51<22:52:56, 11.90s/it] 46%|████▌     | 5830/12750 [19:01:03<22:38:29, 11.78s/it] 46%|████▌     | 5831/12750 [19:01:14<22:29:11, 11.70s/it] 46%|████▌     | 5832/12750 [19:01:26<22:21:50, 11.64s/it] 46%|████▌     | 5833/12750 [19:01:37<22:15:24, 11.58s/it] 46%|████▌     | 5834/12750 [19:01:49<22:12:26, 11.56s/it] 46%|████▌     | 5835/12750 [19:02:00<22:10:49, 11.55s/it] 46%|████▌     | 5836/12750 [19:02:12<22:08:50, 11.53s/it] 46%|████▌     | 5837/12750 [19:02:23<22:07:36, 11.52s/it] 46%|████▌     | 5838/12750 [19:02:35<22:05:51, 11.51s/it] 46%|████▌     | 5839/12750 [19:02:46<22:05:21, 11.51s/it] 46%|████▌     | 5840/12750 [19:02:58<22:03:42, 11.49s/it] 46%|████▌     | 5841/12750 [19:03:09<22:05:33, 11.51s/it] 46%|████▌     | 5842/12750 [19:03:21<22:05:16, 11.51s/it] 46%|████▌     | 5843/12750 [19:03:32<22:04:18, 11.50s/it] 46%|████▌     | 5844/12750 [19:03:44<22:03:30, 11.50s/it] 46%|████▌     | 5845/12750 [19:03:55<22:02:30, 11.49s/it] 46%|████▌     | 5846/12750 [19:04:07<22:01:13, 11.48s/it] 46%|████▌     | 5847/12750 [19:04:18<22:01:32, 11.49s/it] 46%|████▌     | 5848/12750 [19:04:30<22:01:05, 11.48s/it] 46%|████▌     | 5849/12750 [19:04:41<22:00:00, 11.48s/it] 46%|████▌     | 5850/12750 [19:04:53<21:59:20, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 116938.42lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 102030.78lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5850
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5850/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5850/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5825] due to args.save_total_limit
 46%|████▌     | 5851/12750 [19:05:04<22:10:15, 11.57s/it] 46%|████▌     | 5852/12750 [19:05:16<22:07:49, 11.55s/it] 46%|████▌     | 5853/12750 [19:05:27<22:05:05, 11.53s/it] 46%|████▌     | 5854/12750 [19:05:39<22:04:28, 11.52s/it] 46%|████▌     | 5855/12750 [19:05:50<22:02:47, 11.51s/it] 46%|████▌     | 5856/12750 [19:06:10<26:27:31, 13.82s/it] 46%|████▌     | 5857/12750 [19:06:21<25:07:18, 13.12s/it] 46%|████▌     | 5858/12750 [19:06:33<24:10:39, 12.63s/it] 46%|████▌     | 5859/12750 [19:06:44<23:30:47, 12.28s/it] 46%|████▌     | 5860/12750 [19:06:56<23:03:19, 12.05s/it] 46%|████▌     | 5861/12750 [19:07:07<22:44:01, 11.88s/it] 46%|████▌     | 5862/12750 [19:07:18<22:28:37, 11.75s/it] 46%|████▌     | 5863/12750 [19:07:30<22:18:30, 11.66s/it] 46%|████▌     | 5864/12750 [19:07:41<22:10:46, 11.60s/it] 46%|████▌     | 5865/12750 [19:07:53<22:05:46, 11.55s/it] 46%|████▌     | 5866/12750 [19:08:04<22:03:28, 11.54s/it] 46%|████▌     | 5867/12750 [19:08:16<22:01:32, 11.52s/it] 46%|████▌     | 5868/12750 [19:08:27<22:00:39, 11.51s/it] 46%|████▌     | 5869/12750 [19:08:39<21:58:21, 11.50s/it] 46%|████▌     | 5870/12750 [19:08:50<21:57:16, 11.49s/it] 46%|████▌     | 5871/12750 [19:09:02<21:57:14, 11.49s/it] 46%|████▌     | 5872/12750 [19:09:13<21:56:25, 11.48s/it] 46%|████▌     | 5873/12750 [19:09:25<21:56:06, 11.48s/it] 46%|████▌     | 5874/12750 [19:09:36<21:56:03, 11.48s/it] 46%|████▌     | 5875/12750 [19:09:48<21:55:04, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120645.52lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104837.02lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5875
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5875/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5875/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5850] due to args.save_total_limit
 46%|████▌     | 5876/12750 [19:09:59<22:04:50, 11.56s/it] 46%|████▌     | 5877/12750 [19:10:11<22:02:48, 11.55s/it] 46%|████▌     | 5878/12750 [19:10:22<22:00:01, 11.53s/it] 46%|████▌     | 5879/12750 [19:10:34<21:57:20, 11.50s/it] 46%|████▌     | 5880/12750 [19:10:45<21:57:02, 11.50s/it] 46%|████▌     | 5881/12750 [19:10:57<21:56:22, 11.50s/it] 46%|████▌     | 5882/12750 [19:11:08<21:55:10, 11.49s/it] 46%|████▌     | 5883/12750 [19:11:20<21:55:08, 11.49s/it] 46%|████▌     | 5884/12750 [19:11:31<21:54:34, 11.49s/it] 46%|████▌     | 5885/12750 [19:11:43<21:53:20, 11.48s/it] 46%|████▌     | 5886/12750 [19:11:54<21:53:54, 11.49s/it] 46%|████▌     | 5887/12750 [19:12:06<21:52:43, 11.48s/it] 46%|████▌     | 5888/12750 [19:12:24<26:00:08, 13.64s/it] 46%|████▌     | 5889/12750 [19:12:36<24:45:20, 12.99s/it] 46%|████▌     | 5890/12750 [19:12:47<23:53:00, 12.53s/it] 46%|████▌     | 5891/12750 [19:12:59<23:15:53, 12.21s/it] 46%|████▌     | 5892/12750 [19:13:10<22:49:34, 11.98s/it] 46%|████▌     | 5893/12750 [19:13:22<22:32:29, 11.83s/it] 46%|████▌     | 5894/12750 [19:13:33<22:20:16, 11.73s/it] 46%|████▌     | 5895/12750 [19:13:45<22:11:14, 11.65s/it] 46%|████▌     | 5896/12750 [19:13:56<22:05:21, 11.60s/it] 46%|████▋     | 5897/12750 [19:14:08<22:00:05, 11.56s/it] 46%|████▋     | 5898/12750 [19:14:19<21:57:01, 11.53s/it] 46%|████▋     | 5899/12750 [19:14:31<21:55:03, 11.52s/it] 46%|████▋     | 5900/12750 [19:14:42<21:52:10, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120599.27lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101354.94lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5900
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5900/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5900/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5875] due to args.save_total_limit
 46%|████▋     | 5901/12750 [19:14:54<22:09:39, 11.65s/it] 46%|████▋     | 5902/12750 [19:15:06<22:04:06, 11.60s/it] 46%|████▋     | 5903/12750 [19:15:17<22:00:25, 11.57s/it] 46%|████▋     | 5904/12750 [19:15:28<21:55:43, 11.53s/it] 46%|████▋     | 5905/12750 [19:15:40<21:53:50, 11.52s/it] 46%|████▋     | 5906/12750 [19:15:51<21:51:28, 11.50s/it] 46%|████▋     | 5907/12750 [19:16:03<21:50:49, 11.49s/it] 46%|████▋     | 5908/12750 [19:16:14<21:50:11, 11.49s/it] 46%|████▋     | 5909/12750 [19:16:26<21:49:47, 11.49s/it] 46%|████▋     | 5910/12750 [19:16:37<21:48:41, 11.48s/it] 46%|████▋     | 5911/12750 [19:16:49<21:47:52, 11.47s/it] 46%|████▋     | 5912/12750 [19:17:00<21:46:57, 11.47s/it] 46%|████▋     | 5913/12750 [19:17:12<21:47:14, 11.47s/it] 46%|████▋     | 5914/12750 [19:17:23<21:46:56, 11.47s/it] 46%|████▋     | 5915/12750 [19:17:35<21:47:05, 11.47s/it] 46%|████▋     | 5916/12750 [19:17:46<21:52:42, 11.53s/it] 46%|████▋     | 5917/12750 [19:17:58<21:50:40, 11.51s/it] 46%|████▋     | 5918/12750 [19:18:09<21:47:52, 11.49s/it] 46%|████▋     | 5919/12750 [19:18:21<21:45:58, 11.47s/it] 46%|████▋     | 5920/12750 [19:18:32<21:45:43, 11.47s/it] 46%|████▋     | 5921/12750 [19:18:51<26:13:12, 13.82s/it] 46%|████▋     | 5922/12750 [19:19:03<24:54:02, 13.13s/it] 46%|████▋     | 5923/12750 [19:19:14<23:57:01, 12.63s/it] 46%|████▋     | 5924/12750 [19:19:26<23:16:38, 12.28s/it] 46%|████▋     | 5925/12750 [19:19:37<22:52:59, 12.07s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120638.84lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104915.60lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5925
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5925/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5925/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5900] due to args.save_total_limit
 46%|████▋     | 5926/12750 [19:19:49<22:49:16, 12.04s/it] 46%|████▋     | 5927/12750 [19:20:01<22:34:56, 11.91s/it] 46%|████▋     | 5928/12750 [19:20:13<22:22:30, 11.81s/it] 47%|████▋     | 5929/12750 [19:20:24<22:15:35, 11.75s/it] 47%|████▋     | 5930/12750 [19:20:36<22:10:48, 11.71s/it] 47%|████▋     | 5931/12750 [19:20:47<22:03:30, 11.65s/it] 47%|████▋     | 5932/12750 [19:20:59<22:02:51, 11.64s/it] 47%|████▋     | 5933/12750 [19:21:11<22:00:34, 11.62s/it] 47%|████▋     | 5934/12750 [19:21:22<22:00:17, 11.62s/it] 47%|████▋     | 5935/12750 [19:21:34<21:55:33, 11.58s/it] 47%|████▋     | 5936/12750 [19:21:45<21:56:35, 11.59s/it] 47%|████▋     | 5937/12750 [19:21:57<21:55:57, 11.59s/it] 47%|████▋     | 5938/12750 [19:22:08<21:55:50, 11.59s/it] 47%|████▋     | 5939/12750 [19:22:20<21:55:37, 11.59s/it] 47%|████▋     | 5940/12750 [19:22:32<21:56:08, 11.60s/it] 47%|████▋     | 5941/12750 [19:22:43<21:56:21, 11.60s/it] 47%|████▋     | 5942/12750 [19:22:55<21:56:44, 11.60s/it] 47%|████▋     | 5943/12750 [19:23:06<21:57:20, 11.61s/it] 47%|████▋     | 5944/12750 [19:23:18<21:57:34, 11.62s/it] 47%|████▋     | 5945/12750 [19:23:30<21:52:32, 11.57s/it] 47%|████▋     | 5946/12750 [19:23:41<21:53:51, 11.59s/it] 47%|████▋     | 5947/12750 [19:23:53<21:55:18, 11.60s/it] 47%|████▋     | 5948/12750 [19:24:04<21:51:30, 11.57s/it] 47%|████▋     | 5949/12750 [19:24:16<21:48:27, 11.54s/it] 47%|████▋     | 5950/12750 [19:24:27<21:49:09, 11.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120333.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104656.52lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5950
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5950/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5950/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5925] due to args.save_total_limit
 47%|████▋     | 5951/12750 [19:24:39<22:01:09, 11.66s/it] 47%|████▋     | 5952/12750 [19:24:51<21:57:43, 11.63s/it] 47%|████▋     | 5953/12750 [19:25:10<26:20:09, 13.95s/it] 47%|████▋     | 5954/12750 [19:25:22<25:00:18, 13.25s/it] 47%|████▋     | 5955/12750 [19:25:33<24:04:18, 12.75s/it] 47%|████▋     | 5956/12750 [19:25:45<23:23:08, 12.39s/it] 47%|████▋     | 5957/12750 [19:25:56<22:53:12, 12.13s/it] 47%|████▋     | 5958/12750 [19:26:08<22:29:40, 11.92s/it] 47%|████▋     | 5959/12750 [19:26:19<22:16:42, 11.81s/it] 47%|████▋     | 5960/12750 [19:26:31<22:04:58, 11.71s/it] 47%|████▋     | 5961/12750 [19:26:42<21:58:20, 11.65s/it] 47%|████▋     | 5962/12750 [19:26:54<21:50:55, 11.59s/it] 47%|████▋     | 5963/12750 [19:27:05<21:47:04, 11.56s/it] 47%|████▋     | 5964/12750 [19:27:17<21:44:56, 11.54s/it] 47%|████▋     | 5965/12750 [19:27:28<21:43:28, 11.53s/it] 47%|████▋     | 5966/12750 [19:27:40<21:42:17, 11.52s/it] 47%|████▋     | 5967/12750 [19:27:51<21:41:01, 11.51s/it] 47%|████▋     | 5968/12750 [19:28:03<21:39:41, 11.50s/it] 47%|████▋     | 5969/12750 [19:28:14<21:39:05, 11.49s/it] 47%|████▋     | 5970/12750 [19:28:26<21:38:14, 11.49s/it] 47%|████▋     | 5971/12750 [19:28:37<21:37:44, 11.49s/it] 47%|████▋     | 5972/12750 [19:28:49<21:36:22, 11.48s/it] 47%|████▋     | 5973/12750 [19:29:00<21:38:33, 11.50s/it] 47%|████▋     | 5974/12750 [19:29:12<21:36:48, 11.48s/it] 47%|████▋     | 5975/12750 [19:29:23<21:35:53, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120619.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104787.26lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5975
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5975/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5975/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-5975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5950] due to args.save_total_limit
 47%|████▋     | 5976/12750 [19:29:35<21:46:12, 11.57s/it] 47%|████▋     | 5977/12750 [19:29:46<21:44:13, 11.55s/it] 47%|████▋     | 5978/12750 [19:29:58<21:44:02, 11.55s/it] 47%|████▋     | 5979/12750 [19:30:10<21:42:20, 11.54s/it] 47%|████▋     | 5980/12750 [19:30:21<21:41:37, 11.54s/it] 47%|████▋     | 5981/12750 [19:30:33<21:39:55, 11.52s/it] 47%|████▋     | 5982/12750 [19:30:44<21:37:31, 11.50s/it] 47%|████▋     | 5983/12750 [19:30:56<21:40:08, 11.53s/it] 47%|████▋     | 5984/12750 [19:31:07<21:37:21, 11.50s/it] 47%|████▋     | 5985/12750 [19:31:26<25:59:29, 13.83s/it] 47%|████▋     | 5986/12750 [19:31:38<24:37:44, 13.11s/it] 47%|████▋     | 5987/12750 [19:31:49<23:41:58, 12.62s/it] 47%|████▋     | 5988/12750 [19:32:01<23:02:49, 12.27s/it] 47%|████▋     | 5989/12750 [19:32:12<22:38:34, 12.06s/it] 47%|████▋     | 5990/12750 [19:32:24<22:18:43, 11.88s/it] 47%|████▋     | 5991/12750 [19:32:35<22:08:29, 11.79s/it] 47%|████▋     | 5992/12750 [19:32:47<22:01:30, 11.73s/it] 47%|████▋     | 5993/12750 [19:32:58<21:51:45, 11.65s/it] 47%|████▋     | 5994/12750 [19:33:10<21:49:11, 11.63s/it] 47%|████▋     | 5995/12750 [19:33:22<21:49:01, 11.63s/it] 47%|████▋     | 5996/12750 [19:33:33<21:44:11, 11.59s/it] 47%|████▋     | 5997/12750 [19:33:45<21:44:29, 11.59s/it] 47%|████▋     | 5998/12750 [19:33:56<21:42:56, 11.58s/it] 47%|████▋     | 5999/12750 [19:34:08<21:38:55, 11.54s/it] 47%|████▋     | 6000/12750 [19:34:19<21:39:26, 11.55s/it]                                                           47%|████▋     | 6000/12750 [19:34:19<21:39:26, 11.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120686.40lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104953.81lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6000
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6000/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6000/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5975] due to args.save_total_limit
 47%|████▋     | 6001/12750 [19:34:31<21:48:23, 11.63s/it] 47%|████▋     | 6002/12750 [19:34:42<21:43:27, 11.59s/it] 47%|████▋     | 6003/12750 [19:34:54<21:42:28, 11.58s/it] 47%|████▋     | 6004/12750 [19:35:06<21:40:12, 11.56s/it] 47%|████▋     | 6005/12750 [19:35:17<21:37:32, 11.54s/it] 47%|████▋     | 6006/12750 [19:35:29<21:35:02, 11.52s/it] 47%|████▋     | 6007/12750 [19:35:40<21:34:04, 11.51s/it] 47%|████▋     | 6008/12750 [19:35:52<21:36:57, 11.54s/it] 47%|████▋     | 6009/12750 [19:36:03<21:33:49, 11.52s/it] 47%|████▋     | 6010/12750 [19:36:15<21:31:55, 11.50s/it] 47%|████▋     | 6011/12750 [19:36:26<21:30:47, 11.49s/it] 47%|████▋     | 6012/12750 [19:36:38<21:30:54, 11.50s/it] 47%|████▋     | 6013/12750 [19:36:49<21:29:49, 11.49s/it] 47%|████▋     | 6014/12750 [19:37:01<21:30:18, 11.49s/it] 47%|████▋     | 6015/12750 [19:37:12<21:29:38, 11.49s/it] 47%|████▋     | 6016/12750 [19:37:23<21:28:07, 11.48s/it] 47%|████▋     | 6017/12750 [19:37:42<25:24:24, 13.58s/it] 47%|████▋     | 6018/12750 [19:37:53<24:12:48, 12.95s/it] 47%|████▋     | 6019/12750 [19:38:05<23:21:55, 12.50s/it] 47%|████▋     | 6020/12750 [19:38:16<22:46:30, 12.18s/it] 47%|████▋     | 6021/12750 [19:38:28<22:22:23, 11.97s/it] 47%|████▋     | 6022/12750 [19:38:39<22:04:05, 11.81s/it] 47%|████▋     | 6023/12750 [19:38:51<21:57:36, 11.75s/it] 47%|████▋     | 6024/12750 [19:39:02<21:49:22, 11.68s/it] 47%|████▋     | 6025/12750 [19:39:14<21:42:13, 11.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120562.93lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104873.33lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6025
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6025/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6025/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6000] due to args.save_total_limit
 47%|████▋     | 6026/12750 [19:39:26<21:51:26, 11.70s/it] 47%|████▋     | 6027/12750 [19:39:37<21:44:04, 11.64s/it] 47%|████▋     | 6028/12750 [19:39:49<21:39:04, 11.60s/it] 47%|████▋     | 6029/12750 [19:40:00<21:33:51, 11.55s/it] 47%|████▋     | 6030/12750 [19:40:12<21:31:01, 11.53s/it] 47%|████▋     | 6031/12750 [19:40:23<21:28:13, 11.50s/it] 47%|████▋     | 6032/12750 [19:40:35<21:25:59, 11.49s/it] 47%|████▋     | 6033/12750 [19:40:46<21:30:24, 11.53s/it] 47%|████▋     | 6034/12750 [19:40:58<21:29:52, 11.52s/it] 47%|████▋     | 6035/12750 [19:41:09<21:27:58, 11.51s/it] 47%|████▋     | 6036/12750 [19:41:21<21:27:52, 11.51s/it] 47%|████▋     | 6037/12750 [19:41:32<21:28:41, 11.52s/it] 47%|████▋     | 6038/12750 [19:41:44<21:29:20, 11.53s/it] 47%|████▋     | 6039/12750 [19:41:55<21:26:28, 11.50s/it] 47%|████▋     | 6040/12750 [19:42:07<21:26:52, 11.51s/it] 47%|████▋     | 6041/12750 [19:42:18<21:25:47, 11.50s/it] 47%|████▋     | 6042/12750 [19:42:30<21:23:55, 11.48s/it] 47%|████▋     | 6043/12750 [19:42:41<21:22:43, 11.48s/it] 47%|████▋     | 6044/12750 [19:42:53<21:21:49, 11.47s/it] 47%|████▋     | 6045/12750 [19:43:04<21:20:12, 11.46s/it] 47%|████▋     | 6046/12750 [19:43:15<21:21:57, 11.47s/it] 47%|████▋     | 6047/12750 [19:43:27<21:20:44, 11.46s/it] 47%|████▋     | 6048/12750 [19:43:38<21:23:39, 11.49s/it] 47%|████▋     | 6049/12750 [19:43:58<25:37:42, 13.77s/it] 47%|████▋     | 6050/12750 [19:44:09<24:21:31, 13.09s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120630.23lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104825.08lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6050
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6050/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6050/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6025] due to args.save_total_limit
 47%|████▋     | 6051/12750 [19:44:21<23:41:09, 12.73s/it] 47%|████▋     | 6052/12750 [19:44:32<22:58:35, 12.35s/it] 47%|████▋     | 6053/12750 [19:44:44<22:29:06, 12.09s/it] 47%|████▋     | 6054/12750 [19:44:55<22:09:39, 11.91s/it] 47%|████▋     | 6055/12750 [19:45:07<21:56:11, 11.80s/it] 47%|████▋     | 6056/12750 [19:45:18<21:48:55, 11.73s/it] 48%|████▊     | 6057/12750 [19:45:30<21:42:26, 11.68s/it] 48%|████▊     | 6058/12750 [19:45:41<21:34:09, 11.60s/it] 48%|████▊     | 6059/12750 [19:45:53<21:31:06, 11.58s/it] 48%|████▊     | 6060/12750 [19:46:05<21:31:11, 11.58s/it] 48%|████▊     | 6061/12750 [19:46:16<21:25:51, 11.53s/it] 48%|████▊     | 6062/12750 [19:46:27<21:21:44, 11.50s/it] 48%|████▊     | 6063/12750 [19:46:39<21:23:45, 11.52s/it] 48%|████▊     | 6064/12750 [19:46:51<21:25:24, 11.54s/it] 48%|████▊     | 6065/12750 [19:47:02<21:21:58, 11.51s/it] 48%|████▊     | 6066/12750 [19:47:14<21:22:00, 11.51s/it] 48%|████▊     | 6067/12750 [19:47:25<21:21:11, 11.50s/it] 48%|████▊     | 6068/12750 [19:47:36<21:20:32, 11.50s/it] 48%|████▊     | 6069/12750 [19:47:48<21:21:55, 11.51s/it] 48%|████▊     | 6070/12750 [19:48:00<21:20:18, 11.50s/it] 48%|████▊     | 6071/12750 [19:48:11<21:18:38, 11.49s/it] 48%|████▊     | 6072/12750 [19:48:23<21:21:10, 11.51s/it] 48%|████▊     | 6073/12750 [19:48:34<21:19:42, 11.50s/it] 48%|████▊     | 6074/12750 [19:48:45<21:19:17, 11.50s/it] 48%|████▊     | 6075/12750 [19:48:57<21:16:10, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120266.02lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104615.24lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6075
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6075/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6075/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6050] due to args.save_total_limit
 48%|████▊     | 6076/12750 [19:49:09<21:27:01, 11.57s/it] 48%|████▊     | 6077/12750 [19:49:20<21:22:37, 11.53s/it] 48%|████▊     | 6078/12750 [19:49:32<21:18:45, 11.50s/it] 48%|████▊     | 6079/12750 [19:49:43<21:16:09, 11.48s/it] 48%|████▊     | 6080/12750 [19:49:54<21:14:31, 11.46s/it] 48%|████▊     | 6081/12750 [19:50:13<25:11:34, 13.60s/it] 48%|████▊     | 6082/12750 [19:50:24<23:59:37, 12.95s/it] 48%|████▊     | 6083/12750 [19:50:36<23:08:44, 12.50s/it] 48%|████▊     | 6084/12750 [19:50:47<22:32:04, 12.17s/it] 48%|████▊     | 6085/12750 [19:50:59<22:08:44, 11.96s/it] 48%|████▊     | 6086/12750 [19:51:10<21:50:48, 11.80s/it] 48%|████▊     | 6087/12750 [19:51:22<21:43:43, 11.74s/it] 48%|████▊     | 6088/12750 [19:51:33<21:33:36, 11.65s/it] 48%|████▊     | 6089/12750 [19:51:45<21:26:50, 11.59s/it] 48%|████▊     | 6090/12750 [19:51:56<21:22:01, 11.55s/it] 48%|████▊     | 6091/12750 [19:52:08<21:18:32, 11.52s/it] 48%|████▊     | 6092/12750 [19:52:19<21:15:30, 11.49s/it] 48%|████▊     | 6093/12750 [19:52:30<21:13:39, 11.48s/it] 48%|████▊     | 6094/12750 [19:52:42<21:11:51, 11.47s/it] 48%|████▊     | 6095/12750 [19:52:54<21:18:16, 11.52s/it] 48%|████▊     | 6096/12750 [19:53:05<21:15:12, 11.50s/it] 48%|████▊     | 6097/12750 [19:53:16<21:13:30, 11.49s/it] 48%|████▊     | 6098/12750 [19:53:28<21:11:37, 11.47s/it] 48%|████▊     | 6099/12750 [19:53:39<21:09:48, 11.46s/it] 48%|████▊     | 6100/12750 [19:53:51<21:13:16, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120611.60lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104738.02lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6100
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6100/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6100/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6075] due to args.save_total_limit
 48%|████▊     | 6101/12750 [19:54:03<21:22:17, 11.57s/it] 48%|████▊     | 6102/12750 [19:54:14<21:18:41, 11.54s/it] 48%|████▊     | 6103/12750 [19:54:26<21:18:25, 11.54s/it] 48%|████▊     | 6104/12750 [19:54:37<21:17:24, 11.53s/it] 48%|████▊     | 6105/12750 [19:54:49<21:18:04, 11.54s/it] 48%|████▊     | 6106/12750 [19:55:00<21:20:22, 11.56s/it] 48%|████▊     | 6107/12750 [19:55:12<21:19:32, 11.56s/it] 48%|████▊     | 6108/12750 [19:55:23<21:17:44, 11.54s/it] 48%|████▊     | 6109/12750 [19:55:35<21:17:55, 11.55s/it] 48%|████▊     | 6110/12750 [19:55:46<21:14:57, 11.52s/it] 48%|████▊     | 6111/12750 [19:55:58<21:17:24, 11.54s/it] 48%|████▊     | 6112/12750 [19:56:09<21:14:34, 11.52s/it] 48%|████▊     | 6113/12750 [19:56:21<21:14:00, 11.52s/it] 48%|████▊     | 6114/12750 [19:56:40<25:27:06, 13.81s/it] 48%|████▊     | 6115/12750 [19:56:52<24:08:58, 13.10s/it] 48%|████▊     | 6116/12750 [19:57:03<23:14:30, 12.61s/it] 48%|████▊     | 6117/12750 [19:57:15<22:39:20, 12.30s/it] 48%|████▊     | 6118/12750 [19:57:26<22:11:42, 12.05s/it] 48%|████▊     | 6119/12750 [19:57:33<19:28:36, 10.57s/it] 48%|████▊     | 6120/12750 [19:57:34<14:04:06,  7.64s/it] 48%|████▊     | 6121/12750 [19:57:58<22:52:12, 12.42s/it] 48%|████▊     | 6122/12750 [19:58:09<22:25:05, 12.18s/it] 48%|████▊     | 6123/12750 [19:58:21<22:05:08, 12.00s/it] 48%|████▊     | 6124/12750 [19:58:32<21:52:17, 11.88s/it] 48%|████▊     | 6125/12750 [19:58:44<21:43:29, 11.81s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120577.82lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104875.86lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6125
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6125/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6125/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6100] due to args.save_total_limit
 48%|████▊     | 6126/12750 [19:58:56<21:47:47, 11.85s/it] 48%|████▊     | 6127/12750 [19:59:08<21:39:34, 11.77s/it] 48%|████▊     | 6128/12750 [19:59:19<21:35:32, 11.74s/it] 48%|████▊     | 6129/12750 [19:59:31<21:30:59, 11.70s/it] 48%|████▊     | 6130/12750 [19:59:42<21:28:42, 11.68s/it] 48%|████▊     | 6131/12750 [19:59:54<21:24:15, 11.64s/it] 48%|████▊     | 6132/12750 [20:00:06<21:24:42, 11.65s/it] 48%|████▊     | 6133/12750 [20:00:17<21:22:54, 11.63s/it] 48%|████▊     | 6134/12750 [20:00:29<21:21:28, 11.62s/it] 48%|████▊     | 6135/12750 [20:00:40<21:19:21, 11.60s/it] 48%|████▊     | 6136/12750 [20:00:52<21:19:34, 11.61s/it] 48%|████▊     | 6137/12750 [20:01:04<21:20:53, 11.62s/it] 48%|████▊     | 6138/12750 [20:01:15<21:21:06, 11.63s/it] 48%|████▊     | 6139/12750 [20:01:27<21:18:34, 11.60s/it] 48%|████▊     | 6140/12750 [20:01:38<21:17:11, 11.59s/it] 48%|████▊     | 6141/12750 [20:01:50<21:15:42, 11.58s/it] 48%|████▊     | 6142/12750 [20:02:02<21:14:34, 11.57s/it] 48%|████▊     | 6143/12750 [20:02:13<21:13:34, 11.57s/it] 48%|████▊     | 6144/12750 [20:02:25<21:11:51, 11.55s/it] 48%|████▊     | 6145/12750 [20:02:36<21:10:42, 11.54s/it] 48%|████▊     | 6146/12750 [20:02:55<25:24:40, 13.85s/it] 48%|████▊     | 6147/12750 [20:03:07<24:05:03, 13.13s/it] 48%|████▊     | 6148/12750 [20:03:18<23:13:09, 12.66s/it] 48%|████▊     | 6149/12750 [20:03:30<22:33:38, 12.30s/it] 48%|████▊     | 6150/12750 [20:03:42<22:11:23, 12.10s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120644.10lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104856.05lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6150
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6150/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6150/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6125] due to args.save_total_limit
 48%|████▊     | 6151/12750 [20:03:53<22:03:06, 12.03s/it] 48%|████▊     | 6152/12750 [20:04:05<21:46:50, 11.88s/it] 48%|████▊     | 6153/12750 [20:04:17<21:38:23, 11.81s/it] 48%|████▊     | 6154/12750 [20:04:28<21:32:18, 11.76s/it] 48%|████▊     | 6155/12750 [20:04:40<21:28:46, 11.73s/it] 48%|████▊     | 6156/12750 [20:04:51<21:25:00, 11.69s/it] 48%|████▊     | 6157/12750 [20:05:03<21:22:30, 11.67s/it] 48%|████▊     | 6158/12750 [20:05:15<21:22:09, 11.67s/it] 48%|████▊     | 6159/12750 [20:05:26<21:22:00, 11.67s/it] 48%|████▊     | 6160/12750 [20:05:38<21:16:25, 11.62s/it] 48%|████▊     | 6161/12750 [20:05:50<21:15:15, 11.61s/it] 48%|████▊     | 6162/12750 [20:06:01<21:16:17, 11.62s/it] 48%|████▊     | 6163/12750 [20:06:13<21:15:09, 11.62s/it] 48%|████▊     | 6164/12750 [20:06:24<21:16:15, 11.63s/it] 48%|████▊     | 6165/12750 [20:06:36<21:15:25, 11.62s/it] 48%|████▊     | 6166/12750 [20:06:48<21:13:34, 11.61s/it] 48%|████▊     | 6167/12750 [20:06:59<21:14:29, 11.62s/it] 48%|████▊     | 6168/12750 [20:07:11<21:15:17, 11.63s/it] 48%|████▊     | 6169/12750 [20:07:22<21:13:43, 11.61s/it] 48%|████▊     | 6170/12750 [20:07:34<21:12:07, 11.60s/it] 48%|████▊     | 6171/12750 [20:07:46<21:12:26, 11.60s/it] 48%|████▊     | 6172/12750 [20:07:57<21:13:30, 11.62s/it] 48%|████▊     | 6173/12750 [20:08:09<21:10:41, 11.59s/it] 48%|████▊     | 6174/12750 [20:08:20<21:12:42, 11.61s/it] 48%|████▊     | 6175/12750 [20:08:32<21:08:22, 11.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120722.43lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104997.50lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6175
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6175/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6175/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6150] due to args.save_total_limit
 48%|████▊     | 6176/12750 [20:08:44<21:19:01, 11.67s/it] 48%|████▊     | 6177/12750 [20:08:55<21:14:51, 11.64s/it] 48%|████▊     | 6178/12750 [20:09:07<21:12:45, 11.62s/it] 48%|████▊     | 6179/12750 [20:09:27<25:32:56, 14.00s/it] 48%|████▊     | 6180/12750 [20:09:38<24:14:51, 13.29s/it] 48%|████▊     | 6181/12750 [20:09:50<23:20:14, 12.79s/it] 48%|████▊     | 6182/12750 [20:10:01<22:42:51, 12.45s/it] 48%|████▊     | 6183/12750 [20:10:13<22:13:50, 12.19s/it] 49%|████▊     | 6184/12750 [20:10:25<21:51:02, 11.98s/it] 49%|████▊     | 6185/12750 [20:10:36<21:36:00, 11.84s/it] 49%|████▊     | 6186/12750 [20:10:48<21:27:56, 11.77s/it] 49%|████▊     | 6187/12750 [20:10:59<21:20:29, 11.71s/it] 49%|████▊     | 6188/12750 [20:11:11<21:15:59, 11.67s/it] 49%|████▊     | 6189/12750 [20:11:22<21:13:56, 11.65s/it] 49%|████▊     | 6190/12750 [20:11:34<21:11:50, 11.63s/it] 49%|████▊     | 6191/12750 [20:11:46<21:09:29, 11.61s/it] 49%|████▊     | 6192/12750 [20:11:57<21:07:35, 11.60s/it] 49%|████▊     | 6193/12750 [20:12:09<21:05:42, 11.58s/it] 49%|████▊     | 6194/12750 [20:12:20<21:03:32, 11.56s/it] 49%|████▊     | 6195/12750 [20:12:32<21:01:35, 11.55s/it] 49%|████▊     | 6196/12750 [20:12:43<20:59:10, 11.53s/it] 49%|████▊     | 6197/12750 [20:12:55<21:02:05, 11.56s/it] 49%|████▊     | 6198/12750 [20:13:06<21:00:43, 11.55s/it] 49%|████▊     | 6199/12750 [20:13:18<21:01:47, 11.56s/it] 49%|████▊     | 6200/12750 [20:13:29<20:59:56, 11.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120662.87lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104743.45lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6200
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6200/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6200/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6175] due to args.save_total_limit
 49%|████▊     | 6201/12750 [20:13:41<21:10:14, 11.64s/it] 49%|████▊     | 6202/12750 [20:13:53<21:08:03, 11.62s/it] 49%|████▊     | 6203/12750 [20:14:05<21:09:06, 11.63s/it] 49%|████▊     | 6204/12750 [20:14:16<21:07:00, 11.61s/it] 49%|████▊     | 6205/12750 [20:14:28<21:07:07, 11.62s/it] 49%|████▊     | 6206/12750 [20:14:39<21:05:11, 11.60s/it] 49%|████▊     | 6207/12750 [20:14:51<21:04:00, 11.59s/it] 49%|████▊     | 6208/12750 [20:15:02<21:00:50, 11.56s/it] 49%|████▊     | 6209/12750 [20:15:14<21:02:20, 11.58s/it] 49%|████▊     | 6210/12750 [20:15:26<21:02:56, 11.59s/it] 49%|████▊     | 6211/12750 [20:15:45<25:14:55, 13.90s/it] 49%|████▊     | 6212/12750 [20:15:56<23:57:07, 13.19s/it] 49%|████▊     | 6213/12750 [20:16:08<23:05:57, 12.72s/it] 49%|████▊     | 6214/12750 [20:16:20<22:29:03, 12.38s/it] 49%|████▊     | 6215/12750 [20:16:31<22:00:09, 12.12s/it] 49%|████▉     | 6216/12750 [20:16:43<21:41:07, 11.95s/it] 49%|████▉     | 6217/12750 [20:16:54<21:27:34, 11.83s/it] 49%|████▉     | 6218/12750 [20:17:06<21:19:02, 11.75s/it] 49%|████▉     | 6219/12750 [20:17:17<21:11:32, 11.68s/it] 49%|████▉     | 6220/12750 [20:17:29<21:06:05, 11.63s/it] 49%|████▉     | 6221/12750 [20:17:40<21:01:26, 11.59s/it] 49%|████▉     | 6222/12750 [20:17:52<21:02:00, 11.60s/it] 49%|████▉     | 6223/12750 [20:18:03<20:57:17, 11.56s/it] 49%|████▉     | 6224/12750 [20:18:15<20:54:32, 11.53s/it] 49%|████▉     | 6225/12750 [20:18:26<20:51:50, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120711.75lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104965.19lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6225
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6225/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6225/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6200] due to args.save_total_limit
 49%|████▉     | 6226/12750 [20:18:38<21:06:08, 11.64s/it] 49%|████▉     | 6227/12750 [20:18:50<21:03:52, 11.63s/it] 49%|████▉     | 6228/12750 [20:19:01<21:00:16, 11.59s/it] 49%|████▉     | 6229/12750 [20:19:13<20:57:09, 11.57s/it] 49%|████▉     | 6230/12750 [20:19:24<20:55:27, 11.55s/it] 49%|████▉     | 6231/12750 [20:19:36<20:54:10, 11.54s/it] 49%|████▉     | 6232/12750 [20:19:47<20:53:33, 11.54s/it] 49%|████▉     | 6233/12750 [20:19:59<20:56:10, 11.57s/it] 49%|████▉     | 6234/12750 [20:20:11<20:57:35, 11.58s/it] 49%|████▉     | 6235/12750 [20:20:22<20:59:54, 11.60s/it] 49%|████▉     | 6236/12750 [20:20:34<21:01:03, 11.62s/it] 49%|████▉     | 6237/12750 [20:20:46<21:02:03, 11.63s/it] 49%|████▉     | 6238/12750 [20:20:57<20:59:08, 11.60s/it] 49%|████▉     | 6239/12750 [20:21:09<20:57:18, 11.59s/it] 49%|████▉     | 6240/12750 [20:21:20<20:57:50, 11.59s/it] 49%|████▉     | 6241/12750 [20:21:32<20:54:30, 11.56s/it] 49%|████▉     | 6242/12750 [20:21:43<20:54:27, 11.57s/it] 49%|████▉     | 6243/12750 [20:22:03<25:02:11, 13.85s/it] 49%|████▉     | 6244/12750 [20:22:14<23:47:21, 13.16s/it] 49%|████▉     | 6245/12750 [20:22:26<22:52:28, 12.66s/it] 49%|████▉     | 6246/12750 [20:22:37<22:14:34, 12.31s/it] 49%|████▉     | 6247/12750 [20:22:49<21:47:28, 12.06s/it] 49%|████▉     | 6248/12750 [20:23:00<21:32:16, 11.93s/it] 49%|████▉     | 6249/12750 [20:23:12<21:18:13, 11.80s/it] 49%|████▉     | 6250/12750 [20:23:23<21:09:38, 11.72s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120657.99lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104912.29lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6250
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6250/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6250/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6225] due to args.save_total_limit
 49%|████▉     | 6251/12750 [20:23:35<21:17:57, 11.80s/it] 49%|████▉     | 6252/12750 [20:23:47<21:07:45, 11.71s/it] 49%|████▉     | 6253/12750 [20:23:58<21:02:36, 11.66s/it] 49%|████▉     | 6254/12750 [20:24:10<20:59:27, 11.63s/it] 49%|████▉     | 6255/12750 [20:24:21<20:55:35, 11.60s/it] 49%|████▉     | 6256/12750 [20:24:33<20:52:36, 11.57s/it] 49%|████▉     | 6257/12750 [20:24:44<20:51:29, 11.56s/it] 49%|████▉     | 6258/12750 [20:24:56<20:48:53, 11.54s/it] 49%|████▉     | 6259/12750 [20:25:07<20:48:26, 11.54s/it] 49%|████▉     | 6260/12750 [20:25:19<20:49:27, 11.55s/it] 49%|████▉     | 6261/12750 [20:25:31<20:47:56, 11.54s/it] 49%|████▉     | 6262/12750 [20:25:42<20:47:32, 11.54s/it] 49%|████▉     | 6263/12750 [20:25:54<20:48:58, 11.55s/it] 49%|████▉     | 6264/12750 [20:26:05<20:49:25, 11.56s/it] 49%|████▉     | 6265/12750 [20:26:17<20:46:48, 11.54s/it] 49%|████▉     | 6266/12750 [20:26:28<20:49:10, 11.56s/it] 49%|████▉     | 6267/12750 [20:26:40<20:47:59, 11.55s/it] 49%|████▉     | 6268/12750 [20:26:51<20:46:50, 11.54s/it] 49%|████▉     | 6269/12750 [20:27:03<20:47:40, 11.55s/it] 49%|████▉     | 6270/12750 [20:27:15<20:46:39, 11.54s/it] 49%|████▉     | 6271/12750 [20:27:26<20:45:22, 11.53s/it] 49%|████▉     | 6272/12750 [20:27:38<20:46:14, 11.54s/it] 49%|████▉     | 6273/12750 [20:27:49<20:47:31, 11.56s/it] 49%|████▉     | 6274/12750 [20:28:01<20:46:30, 11.55s/it] 49%|████▉     | 6275/12750 [20:28:20<24:53:35, 13.84s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120620.08lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104907.14lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6275
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6275/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6275/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6250] due to args.save_total_limit
 49%|████▉     | 6276/12750 [20:28:32<23:51:13, 13.26s/it] 49%|████▉     | 6277/12750 [20:28:43<22:55:55, 12.75s/it] 49%|████▉     | 6278/12750 [20:28:55<22:16:04, 12.39s/it] 49%|████▉     | 6279/12750 [20:29:06<21:48:08, 12.13s/it] 49%|████▉     | 6280/12750 [20:29:18<21:28:14, 11.95s/it] 49%|████▉     | 6281/12750 [20:29:29<21:13:39, 11.81s/it] 49%|████▉     | 6282/12750 [20:29:41<21:06:23, 11.75s/it] 49%|████▉     | 6283/12750 [20:29:53<21:00:15, 11.69s/it] 49%|████▉     | 6284/12750 [20:30:04<20:54:20, 11.64s/it] 49%|████▉     | 6285/12750 [20:30:16<20:52:04, 11.62s/it] 49%|████▉     | 6286/12750 [20:30:27<20:49:55, 11.60s/it] 49%|████▉     | 6287/12750 [20:30:39<20:47:21, 11.58s/it] 49%|████▉     | 6288/12750 [20:30:51<20:52:26, 11.63s/it] 49%|████▉     | 6289/12750 [20:31:02<20:47:08, 11.58s/it] 49%|████▉     | 6290/12750 [20:31:14<20:47:23, 11.59s/it] 49%|████▉     | 6291/12750 [20:31:25<20:47:54, 11.59s/it] 49%|████▉     | 6292/12750 [20:31:37<20:46:20, 11.58s/it] 49%|████▉     | 6293/12750 [20:31:48<20:46:18, 11.58s/it] 49%|████▉     | 6294/12750 [20:32:00<20:47:04, 11.59s/it] 49%|████▉     | 6295/12750 [20:32:11<20:43:46, 11.56s/it] 49%|████▉     | 6296/12750 [20:32:23<20:45:06, 11.58s/it] 49%|████▉     | 6297/12750 [20:32:35<20:45:17, 11.58s/it] 49%|████▉     | 6298/12750 [20:32:46<20:45:31, 11.58s/it] 49%|████▉     | 6299/12750 [20:32:58<20:44:18, 11.57s/it] 49%|████▉     | 6300/12750 [20:33:09<20:45:08, 11.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120675.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104788.03lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6300
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6300/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6300/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6275] due to args.save_total_limit
 49%|████▉     | 6301/12750 [20:33:21<20:51:45, 11.65s/it] 49%|████▉     | 6302/12750 [20:33:33<20:48:13, 11.61s/it] 49%|████▉     | 6303/12750 [20:33:44<20:45:32, 11.59s/it] 49%|████▉     | 6304/12750 [20:33:56<20:43:17, 11.57s/it] 49%|████▉     | 6305/12750 [20:34:07<20:40:42, 11.55s/it] 49%|████▉     | 6306/12750 [20:34:19<20:37:50, 11.53s/it] 49%|████▉     | 6307/12750 [20:34:38<24:51:41, 13.89s/it] 49%|████▉     | 6308/12750 [20:34:50<23:36:43, 13.20s/it] 49%|████▉     | 6309/12750 [20:35:01<22:45:05, 12.72s/it] 49%|████▉     | 6310/12750 [20:35:13<22:07:13, 12.37s/it] 49%|████▉     | 6311/12750 [20:35:25<21:42:52, 12.14s/it] 50%|████▉     | 6312/12750 [20:35:36<21:23:49, 11.96s/it] 50%|████▉     | 6313/12750 [20:35:48<21:10:43, 11.84s/it] 50%|████▉     | 6314/12750 [20:35:59<20:58:18, 11.73s/it] 50%|████▉     | 6315/12750 [20:36:11<20:54:39, 11.70s/it] 50%|████▉     | 6316/12750 [20:36:22<20:50:17, 11.66s/it] 50%|████▉     | 6317/12750 [20:36:34<20:45:55, 11.62s/it] 50%|████▉     | 6318/12750 [20:36:45<20:42:53, 11.59s/it] 50%|████▉     | 6319/12750 [20:36:57<20:40:47, 11.58s/it] 50%|████▉     | 6320/12750 [20:37:08<20:39:31, 11.57s/it] 50%|████▉     | 6321/12750 [20:37:20<20:39:06, 11.56s/it] 50%|████▉     | 6322/12750 [20:37:32<20:38:57, 11.56s/it] 50%|████▉     | 6323/12750 [20:37:43<20:39:51, 11.57s/it] 50%|████▉     | 6324/12750 [20:37:55<20:38:45, 11.57s/it] 50%|████▉     | 6325/12750 [20:38:06<20:36:42, 11.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120562.93lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104805.97lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6325
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6325/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6325/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6300] due to args.save_total_limit
 50%|████▉     | 6326/12750 [20:38:18<20:47:46, 11.65s/it] 50%|████▉     | 6327/12750 [20:38:30<20:42:31, 11.61s/it] 50%|████▉     | 6328/12750 [20:38:41<20:40:23, 11.59s/it] 50%|████▉     | 6329/12750 [20:38:53<20:38:04, 11.57s/it] 50%|████▉     | 6330/12750 [20:39:04<20:35:17, 11.54s/it] 50%|████▉     | 6331/12750 [20:39:16<20:35:12, 11.55s/it] 50%|████▉     | 6332/12750 [20:39:27<20:36:18, 11.56s/it] 50%|████▉     | 6333/12750 [20:39:39<20:35:39, 11.55s/it] 50%|████▉     | 6334/12750 [20:39:50<20:36:02, 11.56s/it] 50%|████▉     | 6335/12750 [20:40:02<20:36:04, 11.56s/it] 50%|████▉     | 6336/12750 [20:40:14<20:37:03, 11.57s/it] 50%|████▉     | 6337/12750 [20:40:25<20:35:10, 11.56s/it] 50%|████▉     | 6338/12750 [20:40:37<20:35:32, 11.56s/it] 50%|████▉     | 6339/12750 [20:40:55<24:21:21, 13.68s/it] 50%|████▉     | 6340/12750 [20:41:07<23:12:45, 13.04s/it] 50%|████▉     | 6341/12750 [20:41:18<22:23:18, 12.58s/it] 50%|████▉     | 6342/12750 [20:41:30<21:48:24, 12.25s/it] 50%|████▉     | 6343/12750 [20:41:41<21:23:20, 12.02s/it] 50%|████▉     | 6344/12750 [20:41:53<21:06:43, 11.86s/it] 50%|████▉     | 6345/12750 [20:42:04<20:54:24, 11.75s/it] 50%|████▉     | 6346/12750 [20:42:16<20:46:47, 11.68s/it] 50%|████▉     | 6347/12750 [20:42:27<20:41:56, 11.64s/it] 50%|████▉     | 6348/12750 [20:42:39<20:36:16, 11.59s/it] 50%|████▉     | 6349/12750 [20:42:50<20:35:37, 11.58s/it] 50%|████▉     | 6350/12750 [20:43:02<20:31:05, 11.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 116832.50lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 102078.70lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6350
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6350/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6350/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6325] due to args.save_total_limit
 50%|████▉     | 6351/12750 [20:43:14<20:39:54, 11.63s/it] 50%|████▉     | 6352/12750 [20:43:25<20:35:54, 11.59s/it] 50%|████▉     | 6353/12750 [20:43:37<20:36:39, 11.60s/it] 50%|████▉     | 6354/12750 [20:43:48<20:32:52, 11.57s/it] 50%|████▉     | 6355/12750 [20:44:00<20:32:48, 11.57s/it] 50%|████▉     | 6356/12750 [20:44:11<20:31:43, 11.56s/it] 50%|████▉     | 6357/12750 [20:44:23<20:32:52, 11.57s/it] 50%|████▉     | 6358/12750 [20:44:34<20:29:39, 11.54s/it] 50%|████▉     | 6359/12750 [20:44:46<20:27:10, 11.52s/it] 50%|████▉     | 6360/12750 [20:44:57<20:27:02, 11.52s/it] 50%|████▉     | 6361/12750 [20:45:09<20:25:54, 11.51s/it] 50%|████▉     | 6362/12750 [20:45:20<20:24:53, 11.50s/it] 50%|████▉     | 6363/12750 [20:45:32<20:22:46, 11.49s/it] 50%|████▉     | 6364/12750 [20:45:43<20:22:39, 11.49s/it] 50%|████▉     | 6365/12750 [20:45:55<20:25:18, 11.51s/it] 50%|████▉     | 6366/12750 [20:46:06<20:23:43, 11.50s/it] 50%|████▉     | 6367/12750 [20:46:18<20:26:18, 11.53s/it] 50%|████▉     | 6368/12750 [20:46:30<20:27:47, 11.54s/it] 50%|████▉     | 6369/12750 [20:46:41<20:27:48, 11.55s/it] 50%|████▉     | 6370/12750 [20:46:53<20:27:07, 11.54s/it] 50%|████▉     | 6371/12750 [20:47:12<24:32:57, 13.85s/it] 50%|████▉     | 6372/12750 [20:47:24<23:21:20, 13.18s/it] 50%|████▉     | 6373/12750 [20:47:35<22:28:17, 12.69s/it] 50%|████▉     | 6374/12750 [20:47:47<21:52:02, 12.35s/it] 50%|█████     | 6375/12750 [20:47:58<21:27:11, 12.11s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120651.95lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104778.92lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6375
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6375/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6375/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6350] due to args.save_total_limit
 50%|█████     | 6376/12750 [20:48:10<21:17:20, 12.02s/it] 50%|█████     | 6377/12750 [20:48:21<21:00:41, 11.87s/it] 50%|█████     | 6378/12750 [20:48:33<20:51:31, 11.78s/it] 50%|█████     | 6379/12750 [20:48:45<20:45:48, 11.73s/it] 50%|█████     | 6380/12750 [20:48:56<20:37:38, 11.66s/it] 50%|█████     | 6381/12750 [20:49:08<20:31:23, 11.60s/it] 50%|█████     | 6382/12750 [20:49:19<20:26:24, 11.56s/it] 50%|█████     | 6383/12750 [20:49:31<20:22:05, 11.52s/it] 50%|█████     | 6384/12750 [20:49:42<20:20:51, 11.51s/it] 50%|█████     | 6385/12750 [20:49:53<20:19:56, 11.50s/it] 50%|█████     | 6386/12750 [20:50:05<20:18:57, 11.49s/it] 50%|█████     | 6387/12750 [20:50:16<20:17:29, 11.48s/it] 50%|█████     | 6388/12750 [20:50:28<20:17:21, 11.48s/it] 50%|█████     | 6389/12750 [20:50:39<20:17:11, 11.48s/it] 50%|█████     | 6390/12750 [20:50:51<20:17:16, 11.48s/it] 50%|█████     | 6391/12750 [20:51:02<20:16:24, 11.48s/it] 50%|█████     | 6392/12750 [20:51:14<20:15:44, 11.47s/it] 50%|█████     | 6393/12750 [20:51:25<20:15:32, 11.47s/it] 50%|█████     | 6394/12750 [20:51:37<20:15:04, 11.47s/it] 50%|█████     | 6395/12750 [20:51:48<20:16:46, 11.49s/it] 50%|█████     | 6396/12750 [20:52:00<20:16:34, 11.49s/it] 50%|█████     | 6397/12750 [20:52:11<20:15:37, 11.48s/it] 50%|█████     | 6398/12750 [20:52:23<20:14:39, 11.47s/it] 50%|█████     | 6399/12750 [20:52:34<20:14:33, 11.47s/it] 50%|█████     | 6400/12750 [20:52:46<20:14:52, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120772.38lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 105079.63lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6400
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6400/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6400/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6375] due to args.save_total_limit
 50%|█████     | 6401/12750 [20:52:57<20:25:19, 11.58s/it] 50%|█████     | 6402/12750 [20:53:09<20:21:08, 11.54s/it] 50%|█████     | 6403/12750 [20:53:28<24:21:40, 13.82s/it] 50%|█████     | 6404/12750 [20:53:40<23:09:33, 13.14s/it] 50%|█████     | 6405/12750 [20:53:51<22:17:19, 12.65s/it] 50%|█████     | 6406/12750 [20:54:03<21:41:33, 12.31s/it] 50%|█████     | 6407/12750 [20:54:14<21:14:39, 12.06s/it] 50%|█████     | 6408/12750 [20:54:26<20:56:50, 11.89s/it] 50%|█████     | 6409/12750 [20:54:37<20:43:34, 11.77s/it] 50%|█████     | 6410/12750 [20:54:49<20:34:08, 11.68s/it] 50%|█████     | 6411/12750 [20:55:00<20:27:34, 11.62s/it] 50%|█████     | 6412/12750 [20:55:11<20:23:19, 11.58s/it] 50%|█████     | 6413/12750 [20:55:23<20:20:12, 11.55s/it] 50%|█████     | 6414/12750 [20:55:34<20:17:20, 11.53s/it] 50%|█████     | 6415/12750 [20:55:46<20:16:09, 11.52s/it] 50%|█████     | 6416/12750 [20:55:57<20:14:29, 11.50s/it] 50%|█████     | 6417/12750 [20:56:09<20:13:49, 11.50s/it] 50%|█████     | 6418/12750 [20:56:20<20:12:07, 11.49s/it] 50%|█████     | 6419/12750 [20:56:32<20:14:02, 11.51s/it] 50%|█████     | 6420/12750 [20:56:43<20:12:45, 11.50s/it] 50%|█████     | 6421/12750 [20:56:55<20:12:13, 11.49s/it] 50%|█████     | 6422/12750 [20:57:06<20:11:55, 11.49s/it] 50%|█████     | 6423/12750 [20:57:18<20:12:54, 11.50s/it] 50%|█████     | 6424/12750 [20:57:29<20:11:01, 11.49s/it] 50%|█████     | 6425/12750 [20:57:41<20:11:14, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120618.28lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104893.05lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6425
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6425/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6425/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6400] due to args.save_total_limit
 50%|█████     | 6426/12750 [20:57:53<20:21:30, 11.59s/it] 50%|█████     | 6427/12750 [20:58:04<20:21:21, 11.59s/it] 50%|█████     | 6428/12750 [20:58:16<20:17:04, 11.55s/it] 50%|█████     | 6429/12750 [20:58:27<20:13:18, 11.52s/it] 50%|█████     | 6430/12750 [20:58:39<20:11:39, 11.50s/it] 50%|█████     | 6431/12750 [20:58:50<20:11:07, 11.50s/it] 50%|█████     | 6432/12750 [20:59:02<20:09:29, 11.49s/it] 50%|█████     | 6433/12750 [20:59:13<20:08:14, 11.48s/it] 50%|█████     | 6434/12750 [20:59:24<20:06:54, 11.47s/it] 50%|█████     | 6435/12750 [20:59:36<20:06:05, 11.46s/it] 50%|█████     | 6436/12750 [20:59:55<24:14:16, 13.82s/it] 50%|█████     | 6437/12750 [21:00:07<23:00:25, 13.12s/it] 50%|█████     | 6438/12750 [21:00:18<22:08:08, 12.62s/it] 51%|█████     | 6439/12750 [21:00:30<21:31:34, 12.28s/it] 51%|█████     | 6440/12750 [21:00:41<21:05:22, 12.03s/it] 51%|█████     | 6441/12750 [21:00:53<20:48:24, 11.87s/it] 51%|█████     | 6442/12750 [21:01:04<20:35:27, 11.75s/it] 51%|█████     | 6443/12750 [21:01:16<20:26:58, 11.67s/it] 51%|█████     | 6444/12750 [21:01:27<20:20:34, 11.61s/it] 51%|█████     | 6445/12750 [21:01:39<20:16:27, 11.58s/it] 51%|█████     | 6446/12750 [21:01:50<20:15:11, 11.57s/it] 51%|█████     | 6447/12750 [21:02:02<20:11:59, 11.54s/it] 51%|█████     | 6448/12750 [21:02:13<20:09:50, 11.52s/it] 51%|█████     | 6449/12750 [21:02:25<20:08:45, 11.51s/it] 51%|█████     | 6450/12750 [21:02:36<20:07:18, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120614.42lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104717.59lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6450
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6450/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6450/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6425] due to args.save_total_limit
 51%|█████     | 6451/12750 [21:02:48<20:16:51, 11.59s/it] 51%|█████     | 6452/12750 [21:02:59<20:13:21, 11.56s/it] 51%|█████     | 6453/12750 [21:03:11<20:10:50, 11.54s/it] 51%|█████     | 6454/12750 [21:03:22<20:08:20, 11.52s/it] 51%|█████     | 6455/12750 [21:03:34<20:05:53, 11.49s/it] 51%|█████     | 6456/12750 [21:03:45<20:04:47, 11.49s/it] 51%|█████     | 6457/12750 [21:03:57<20:03:34, 11.48s/it] 51%|█████     | 6458/12750 [21:04:08<20:02:41, 11.47s/it] 51%|█████     | 6459/12750 [21:04:20<20:02:43, 11.47s/it] 51%|█████     | 6460/12750 [21:04:31<20:02:21, 11.47s/it] 51%|█████     | 6461/12750 [21:04:42<20:02:41, 11.47s/it] 51%|█████     | 6462/12750 [21:04:54<20:02:10, 11.47s/it] 51%|█████     | 6463/12750 [21:05:05<20:02:44, 11.48s/it] 51%|█████     | 6464/12750 [21:05:17<20:04:54, 11.50s/it] 51%|█████     | 6465/12750 [21:05:28<20:03:38, 11.49s/it] 51%|█████     | 6466/12750 [21:05:40<20:03:23, 11.49s/it] 51%|█████     | 6467/12750 [21:05:51<20:03:15, 11.49s/it] 51%|█████     | 6468/12750 [21:06:11<24:03:21, 13.79s/it] 51%|█████     | 6469/12750 [21:06:22<22:49:47, 13.09s/it] 51%|█████     | 6470/12750 [21:06:33<21:58:23, 12.60s/it] 51%|█████     | 6471/12750 [21:06:45<21:21:49, 12.25s/it] 51%|█████     | 6472/12750 [21:06:56<20:57:38, 12.02s/it] 51%|█████     | 6473/12750 [21:07:08<20:43:48, 11.89s/it] 51%|█████     | 6474/12750 [21:07:19<20:31:30, 11.77s/it] 51%|█████     | 6475/12750 [21:07:31<20:21:20, 11.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120551.25lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104813.44lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6475
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6475/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6475/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6450] due to args.save_total_limit
 51%|█████     | 6476/12750 [21:07:43<20:26:05, 11.73s/it] 51%|█████     | 6477/12750 [21:07:54<20:19:58, 11.67s/it] 51%|█████     | 6478/12750 [21:08:06<20:13:31, 11.61s/it] 51%|█████     | 6479/12750 [21:08:17<20:10:21, 11.58s/it] 51%|█████     | 6480/12750 [21:08:29<20:07:29, 11.55s/it] 51%|█████     | 6481/12750 [21:08:40<20:09:18, 11.57s/it] 51%|█████     | 6482/12750 [21:08:52<20:06:23, 11.55s/it] 51%|█████     | 6483/12750 [21:09:03<20:04:21, 11.53s/it] 51%|█████     | 6484/12750 [21:09:15<20:02:14, 11.51s/it] 51%|█████     | 6485/12750 [21:09:26<20:01:25, 11.51s/it] 51%|█████     | 6486/12750 [21:09:38<20:00:00, 11.49s/it] 51%|█████     | 6487/12750 [21:09:49<19:59:55, 11.50s/it] 51%|█████     | 6488/12750 [21:10:01<19:59:26, 11.49s/it] 51%|█████     | 6489/12750 [21:10:12<19:58:47, 11.49s/it] 51%|█████     | 6490/12750 [21:10:24<19:58:49, 11.49s/it] 51%|█████     | 6491/12750 [21:10:35<19:58:43, 11.49s/it] 51%|█████     | 6492/12750 [21:10:47<19:58:32, 11.49s/it] 51%|█████     | 6493/12750 [21:10:58<19:57:22, 11.48s/it] 51%|█████     | 6494/12750 [21:11:10<19:56:48, 11.48s/it] 51%|█████     | 6495/12750 [21:11:21<20:01:10, 11.52s/it] 51%|█████     | 6496/12750 [21:11:33<20:02:08, 11.53s/it] 51%|█████     | 6497/12750 [21:11:44<20:00:06, 11.52s/it] 51%|█████     | 6498/12750 [21:11:56<19:58:52, 11.51s/it] 51%|█████     | 6499/12750 [21:12:07<19:57:59, 11.50s/it] 51%|█████     | 6500/12750 [21:12:26<23:56:44, 13.79s/it]                                                           51%|█████     | 6500/12750 [21:12:26<23:56:44, 13.79s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120592.84lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104720.40lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6500
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6500/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6500/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6475] due to args.save_total_limit
 51%|█████     | 6501/12750 [21:12:38<22:56:55, 13.22s/it] 51%|█████     | 6502/12750 [21:12:50<22:01:41, 12.69s/it] 51%|█████     | 6503/12750 [21:13:01<21:23:06, 12.32s/it] 51%|█████     | 6504/12750 [21:13:13<20:56:32, 12.07s/it] 51%|█████     | 6505/12750 [21:13:24<20:37:10, 11.89s/it] 51%|█████     | 6506/12750 [21:13:36<20:23:30, 11.76s/it] 51%|█████     | 6507/12750 [21:13:47<20:13:45, 11.67s/it] 51%|█████     | 6508/12750 [21:13:59<20:06:50, 11.60s/it] 51%|█████     | 6509/12750 [21:14:10<20:02:22, 11.56s/it] 51%|█████     | 6510/12750 [21:14:21<19:59:58, 11.54s/it] 51%|█████     | 6511/12750 [21:14:33<19:57:02, 11.51s/it] 51%|█████     | 6512/12750 [21:14:44<19:55:37, 11.50s/it] 51%|█████     | 6513/12750 [21:14:56<19:55:25, 11.50s/it] 51%|█████     | 6514/12750 [21:15:07<19:54:08, 11.49s/it] 51%|█████     | 6515/12750 [21:15:19<19:53:43, 11.49s/it] 51%|█████     | 6516/12750 [21:15:30<19:52:53, 11.48s/it] 51%|█████     | 6517/12750 [21:15:42<19:52:26, 11.48s/it] 51%|█████     | 6518/12750 [21:15:53<19:52:01, 11.48s/it] 51%|█████     | 6519/12750 [21:16:05<19:50:54, 11.47s/it] 51%|█████     | 6520/12750 [21:16:16<19:50:34, 11.47s/it] 51%|█████     | 6521/12750 [21:16:28<19:50:53, 11.47s/it] 51%|█████     | 6522/12750 [21:16:39<19:49:57, 11.46s/it] 51%|█████     | 6523/12750 [21:16:51<19:49:33, 11.46s/it] 51%|█████     | 6524/12750 [21:17:02<19:48:24, 11.45s/it] 51%|█████     | 6525/12750 [21:17:13<19:48:20, 11.45s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120730.28lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 105034.21lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6525
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6525/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6525/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-5750] due to args.save_total_limit
 51%|█████     | 6526/12750 [21:17:25<20:03:34, 11.60s/it] 51%|█████     | 6527/12750 [21:17:37<20:02:13, 11.59s/it] 51%|█████     | 6528/12750 [21:17:49<20:02:42, 11.60s/it] 51%|█████     | 6529/12750 [21:18:00<20:02:32, 11.60s/it] 51%|█████     | 6530/12750 [21:18:12<20:01:01, 11.59s/it] 51%|█████     | 6531/12750 [21:18:23<20:00:08, 11.58s/it] 51%|█████     | 6532/12750 [21:18:42<23:53:42, 13.83s/it] 51%|█████     | 6533/12750 [21:18:54<22:42:58, 13.15s/it] 51%|█████     | 6534/12750 [21:19:06<21:54:18, 12.69s/it] 51%|█████▏    | 6535/12750 [21:19:17<21:21:27, 12.37s/it] 51%|█████▏    | 6536/12750 [21:19:29<20:58:27, 12.15s/it] 51%|█████▏    | 6537/12750 [21:19:40<20:42:16, 12.00s/it] 51%|█████▏    | 6538/12750 [21:19:52<20:31:45, 11.90s/it] 51%|█████▏    | 6539/12750 [21:20:04<20:22:14, 11.81s/it] 51%|█████▏    | 6540/12750 [21:20:15<20:16:20, 11.75s/it] 51%|█████▏    | 6541/12750 [21:20:27<20:11:57, 11.71s/it] 51%|█████▏    | 6542/12750 [21:20:39<20:07:54, 11.67s/it] 51%|█████▏    | 6543/12750 [21:20:50<20:05:53, 11.66s/it] 51%|█████▏    | 6544/12750 [21:21:02<20:04:33, 11.65s/it] 51%|█████▏    | 6545/12750 [21:21:13<20:03:39, 11.64s/it] 51%|█████▏    | 6546/12750 [21:21:25<20:02:09, 11.63s/it] 51%|█████▏    | 6547/12750 [21:21:37<20:00:27, 11.61s/it] 51%|█████▏    | 6548/12750 [21:21:48<19:59:42, 11.61s/it] 51%|█████▏    | 6549/12750 [21:22:00<19:59:30, 11.61s/it] 51%|█████▏    | 6550/12750 [21:22:11<19:58:27, 11.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120696.82lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104944.67lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6550
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6550/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6550/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6500] due to args.save_total_limit
 51%|█████▏    | 6551/12750 [21:22:23<20:09:04, 11.70s/it] 51%|█████▏    | 6552/12750 [21:22:35<20:04:41, 11.66s/it] 51%|█████▏    | 6553/12750 [21:22:46<20:01:33, 11.63s/it] 51%|█████▏    | 6554/12750 [21:22:58<20:00:51, 11.63s/it] 51%|█████▏    | 6555/12750 [21:23:10<19:59:35, 11.62s/it] 51%|█████▏    | 6556/12750 [21:23:21<19:58:12, 11.61s/it] 51%|█████▏    | 6557/12750 [21:23:33<19:57:27, 11.60s/it] 51%|█████▏    | 6558/12750 [21:23:44<19:57:34, 11.60s/it] 51%|█████▏    | 6559/12750 [21:23:56<19:56:23, 11.59s/it] 51%|█████▏    | 6560/12750 [21:24:08<19:55:10, 11.58s/it] 51%|█████▏    | 6561/12750 [21:24:19<19:54:27, 11.58s/it] 51%|█████▏    | 6562/12750 [21:24:31<19:55:01, 11.59s/it] 51%|█████▏    | 6563/12750 [21:24:42<19:54:36, 11.59s/it] 51%|█████▏    | 6564/12750 [21:25:01<23:47:50, 13.85s/it] 51%|█████▏    | 6565/12750 [21:25:13<22:38:28, 13.18s/it] 51%|█████▏    | 6566/12750 [21:25:25<21:48:47, 12.70s/it] 52%|█████▏    | 6567/12750 [21:25:36<21:14:23, 12.37s/it] 52%|█████▏    | 6568/12750 [21:25:48<20:50:20, 12.14s/it] 52%|█████▏    | 6569/12750 [21:25:59<20:34:53, 11.99s/it] 52%|█████▏    | 6570/12750 [21:26:11<20:27:11, 11.91s/it] 52%|█████▏    | 6571/12750 [21:26:23<20:17:26, 11.82s/it] 52%|█████▏    | 6572/12750 [21:26:34<20:09:52, 11.75s/it] 52%|█████▏    | 6573/12750 [21:26:46<20:05:37, 11.71s/it] 52%|█████▏    | 6574/12750 [21:26:58<20:02:21, 11.68s/it] 52%|█████▏    | 6575/12750 [21:27:09<19:59:40, 11.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120655.80lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104892.56lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6575
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6575/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6575/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6525] due to args.save_total_limit
 52%|█████▏    | 6576/12750 [21:27:21<20:10:03, 11.76s/it] 52%|█████▏    | 6577/12750 [21:27:33<20:05:15, 11.71s/it] 52%|█████▏    | 6578/12750 [21:27:44<20:01:08, 11.68s/it] 52%|█████▏    | 6579/12750 [21:27:56<19:58:38, 11.65s/it] 52%|█████▏    | 6580/12750 [21:28:08<19:55:42, 11.63s/it] 52%|█████▏    | 6581/12750 [21:28:19<19:54:24, 11.62s/it] 52%|█████▏    | 6582/12750 [21:28:31<19:54:12, 11.62s/it] 52%|█████▏    | 6583/12750 [21:28:42<19:52:43, 11.60s/it] 52%|█████▏    | 6584/12750 [21:28:54<19:52:42, 11.61s/it] 52%|█████▏    | 6585/12750 [21:29:06<19:52:33, 11.61s/it] 52%|█████▏    | 6586/12750 [21:29:17<19:52:23, 11.61s/it] 52%|█████▏    | 6587/12750 [21:29:29<19:51:36, 11.60s/it] 52%|█████▏    | 6588/12750 [21:29:40<19:51:32, 11.60s/it] 52%|█████▏    | 6589/12750 [21:29:52<19:51:31, 11.60s/it] 52%|█████▏    | 6590/12750 [21:30:04<19:50:36, 11.60s/it] 52%|█████▏    | 6591/12750 [21:30:15<19:52:25, 11.62s/it] 52%|█████▏    | 6592/12750 [21:30:27<19:51:22, 11.61s/it] 52%|█████▏    | 6593/12750 [21:30:38<19:50:29, 11.60s/it] 52%|█████▏    | 6594/12750 [21:30:50<19:49:55, 11.60s/it] 52%|█████▏    | 6595/12750 [21:31:02<19:51:03, 11.61s/it] 52%|█████▏    | 6596/12750 [21:31:21<23:44:32, 13.89s/it] 52%|█████▏    | 6597/12750 [21:31:32<22:32:32, 13.19s/it] 52%|█████▏    | 6598/12750 [21:31:44<21:43:26, 12.71s/it] 52%|█████▏    | 6599/12750 [21:31:56<21:07:55, 12.37s/it] 52%|█████▏    | 6600/12750 [21:32:07<20:44:44, 12.14s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120272.40lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104635.35lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6600
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6600/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6600/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6575] due to args.save_total_limit
 52%|█████▏    | 6601/12750 [21:32:19<20:36:37, 12.07s/it] 52%|█████▏    | 6602/12750 [21:32:31<20:20:34, 11.91s/it] 52%|█████▏    | 6603/12750 [21:32:42<20:10:39, 11.82s/it] 52%|█████▏    | 6604/12750 [21:32:54<20:03:06, 11.75s/it] 52%|█████▏    | 6605/12750 [21:33:05<19:57:05, 11.69s/it] 52%|█████▏    | 6606/12750 [21:33:17<19:52:30, 11.65s/it] 52%|█████▏    | 6607/12750 [21:33:29<19:50:33, 11.63s/it] 52%|█████▏    | 6608/12750 [21:33:40<19:49:08, 11.62s/it] 52%|█████▏    | 6609/12750 [21:33:52<19:48:36, 11.61s/it] 52%|█████▏    | 6610/12750 [21:34:03<19:47:25, 11.60s/it] 52%|█████▏    | 6611/12750 [21:34:15<19:50:38, 11.64s/it] 52%|█████▏    | 6612/12750 [21:34:27<19:49:09, 11.62s/it] 52%|█████▏    | 6613/12750 [21:34:38<19:47:48, 11.61s/it] 52%|█████▏    | 6614/12750 [21:34:50<19:46:36, 11.60s/it] 52%|█████▏    | 6615/12750 [21:35:01<19:45:49, 11.60s/it] 52%|█████▏    | 6616/12750 [21:35:13<19:45:13, 11.59s/it] 52%|█████▏    | 6617/12750 [21:35:25<19:44:54, 11.59s/it] 52%|█████▏    | 6618/12750 [21:35:36<19:43:27, 11.58s/it] 52%|█████▏    | 6619/12750 [21:35:48<19:43:07, 11.58s/it] 52%|█████▏    | 6620/12750 [21:35:59<19:42:52, 11.58s/it] 52%|█████▏    | 6621/12750 [21:36:11<19:43:11, 11.58s/it] 52%|█████▏    | 6622/12750 [21:36:22<19:43:00, 11.58s/it] 52%|█████▏    | 6623/12750 [21:36:34<19:43:04, 11.59s/it] 52%|█████▏    | 6624/12750 [21:36:46<19:42:14, 11.58s/it] 52%|█████▏    | 6625/12750 [21:36:57<19:42:20, 11.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120696.05lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104911.42lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6625
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6625/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6625/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6600] due to args.save_total_limit
 52%|█████▏    | 6626/12750 [21:37:09<19:52:37, 11.68s/it] 52%|█████▏    | 6627/12750 [21:37:21<19:48:56, 11.65s/it] 52%|█████▏    | 6628/12750 [21:37:32<19:46:34, 11.63s/it] 52%|█████▏    | 6629/12750 [21:37:47<21:08:15, 12.43s/it] 52%|█████▏    | 6630/12750 [21:37:47<15:11:48,  8.94s/it] 52%|█████▏    | 6631/12750 [21:38:11<22:36:52, 13.30s/it] 52%|█████▏    | 6632/12750 [21:38:22<21:44:52, 12.80s/it] 52%|█████▏    | 6633/12750 [21:38:34<21:08:33, 12.44s/it] 52%|█████▏    | 6634/12750 [21:38:46<20:43:57, 12.20s/it] 52%|█████▏    | 6635/12750 [21:38:57<20:26:03, 12.03s/it] 52%|█████▏    | 6636/12750 [21:39:09<20:13:42, 11.91s/it] 52%|█████▏    | 6637/12750 [21:39:21<20:08:32, 11.86s/it] 52%|█████▏    | 6638/12750 [21:39:32<20:01:03, 11.79s/it] 52%|█████▏    | 6639/12750 [21:39:44<19:56:44, 11.75s/it] 52%|█████▏    | 6640/12750 [21:39:56<19:52:34, 11.71s/it] 52%|█████▏    | 6641/12750 [21:40:07<19:49:38, 11.68s/it] 52%|█████▏    | 6642/12750 [21:40:19<19:48:17, 11.67s/it] 52%|█████▏    | 6643/12750 [21:40:30<19:45:45, 11.65s/it] 52%|█████▏    | 6644/12750 [21:40:42<19:44:25, 11.64s/it] 52%|█████▏    | 6645/12750 [21:40:54<19:44:07, 11.64s/it] 52%|█████▏    | 6646/12750 [21:41:05<19:43:51, 11.64s/it] 52%|█████▏    | 6647/12750 [21:41:17<19:43:44, 11.64s/it] 52%|█████▏    | 6648/12750 [21:41:29<19:42:54, 11.63s/it] 52%|█████▏    | 6649/12750 [21:41:40<19:42:56, 11.63s/it] 52%|█████▏    | 6650/12750 [21:41:52<19:42:49, 11.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120846.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 105027.69lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6650
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6650/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6650/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6625] due to args.save_total_limit
 52%|█████▏    | 6651/12750 [21:42:04<19:52:16, 11.73s/it] 52%|█████▏    | 6652/12750 [21:42:15<19:49:02, 11.70s/it] 52%|█████▏    | 6653/12750 [21:42:27<19:46:44, 11.68s/it] 52%|█████▏    | 6654/12750 [21:42:39<19:43:33, 11.65s/it] 52%|█████▏    | 6655/12750 [21:42:50<19:42:14, 11.64s/it] 52%|█████▏    | 6656/12750 [21:43:02<19:41:20, 11.63s/it] 52%|█████▏    | 6657/12750 [21:43:14<19:40:32, 11.63s/it] 52%|█████▏    | 6658/12750 [21:43:25<19:40:58, 11.63s/it] 52%|█████▏    | 6659/12750 [21:43:37<19:40:43, 11.63s/it] 52%|█████▏    | 6660/12750 [21:43:48<19:39:24, 11.62s/it] 52%|█████▏    | 6661/12750 [21:44:08<23:29:29, 13.89s/it] 52%|█████▏    | 6662/12750 [21:44:19<22:19:02, 13.20s/it] 52%|█████▏    | 6663/12750 [21:44:31<21:31:13, 12.73s/it] 52%|█████▏    | 6664/12750 [21:44:42<20:57:11, 12.39s/it] 52%|█████▏    | 6665/12750 [21:44:54<20:33:29, 12.16s/it] 52%|█████▏    | 6666/12750 [21:45:06<20:15:52, 11.99s/it] 52%|█████▏    | 6667/12750 [21:45:17<20:03:54, 11.87s/it] 52%|█████▏    | 6668/12750 [21:45:29<19:56:17, 11.80s/it] 52%|█████▏    | 6669/12750 [21:45:40<19:50:34, 11.75s/it] 52%|█████▏    | 6670/12750 [21:45:52<19:45:32, 11.70s/it] 52%|█████▏    | 6671/12750 [21:46:04<19:44:21, 11.69s/it] 52%|█████▏    | 6672/12750 [21:46:15<19:41:35, 11.66s/it] 52%|█████▏    | 6673/12750 [21:46:27<19:39:42, 11.65s/it] 52%|█████▏    | 6674/12750 [21:46:39<19:41:07, 11.66s/it] 52%|█████▏    | 6675/12750 [21:46:50<19:37:30, 11.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120535.85lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 100763.25lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6675
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6675/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6675/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6650] due to args.save_total_limit
 52%|█████▏    | 6676/12750 [21:47:02<19:52:18, 11.78s/it] 52%|█████▏    | 6677/12750 [21:47:14<19:47:32, 11.73s/it] 52%|█████▏    | 6678/12750 [21:47:26<19:42:29, 11.68s/it] 52%|█████▏    | 6679/12750 [21:47:37<19:39:12, 11.65s/it] 52%|█████▏    | 6680/12750 [21:47:49<19:36:38, 11.63s/it] 52%|█████▏    | 6681/12750 [21:48:00<19:35:48, 11.62s/it] 52%|█████▏    | 6682/12750 [21:48:12<19:34:11, 11.61s/it] 52%|█████▏    | 6683/12750 [21:48:23<19:31:45, 11.59s/it] 52%|█████▏    | 6684/12750 [21:48:35<19:31:11, 11.58s/it] 52%|█████▏    | 6685/12750 [21:48:47<19:30:36, 11.58s/it] 52%|█████▏    | 6686/12750 [21:48:58<19:34:24, 11.62s/it] 52%|█████▏    | 6687/12750 [21:49:10<19:33:26, 11.61s/it] 52%|█████▏    | 6688/12750 [21:49:21<19:32:08, 11.60s/it] 52%|█████▏    | 6689/12750 [21:49:33<19:31:47, 11.60s/it] 52%|█████▏    | 6690/12750 [21:49:45<19:31:16, 11.60s/it] 52%|█████▏    | 6691/12750 [21:49:56<19:31:50, 11.60s/it] 52%|█████▏    | 6692/12750 [21:50:08<19:29:40, 11.58s/it] 52%|█████▏    | 6693/12750 [21:50:27<23:17:19, 13.84s/it] 53%|█████▎    | 6694/12750 [21:50:38<22:07:55, 13.16s/it] 53%|█████▎    | 6695/12750 [21:50:50<21:19:23, 12.68s/it] 53%|█████▎    | 6696/12750 [21:51:02<20:45:35, 12.34s/it] 53%|█████▎    | 6697/12750 [21:51:13<20:21:57, 12.11s/it] 53%|█████▎    | 6698/12750 [21:51:25<20:06:34, 11.96s/it] 53%|█████▎    | 6699/12750 [21:51:36<19:54:45, 11.85s/it] 53%|█████▎    | 6700/12750 [21:51:48<19:47:09, 11.77s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120501.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104752.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6700
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6700/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6700/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6675] due to args.save_total_limit
 53%|█████▎    | 6701/12750 [21:52:00<19:50:46, 11.81s/it] 53%|█████▎    | 6702/12750 [21:52:11<19:43:17, 11.74s/it] 53%|█████▎    | 6703/12750 [21:52:23<19:38:12, 11.69s/it] 53%|█████▎    | 6704/12750 [21:52:35<19:33:55, 11.65s/it] 53%|█████▎    | 6705/12750 [21:52:46<19:30:35, 11.62s/it] 53%|█████▎    | 6706/12750 [21:52:58<19:28:39, 11.60s/it] 53%|█████▎    | 6707/12750 [21:53:09<19:27:28, 11.59s/it] 53%|█████▎    | 6708/12750 [21:53:21<19:26:32, 11.58s/it] 53%|█████▎    | 6709/12750 [21:53:32<19:26:52, 11.59s/it] 53%|█████▎    | 6710/12750 [21:53:44<19:25:44, 11.58s/it] 53%|█████▎    | 6711/12750 [21:53:55<19:24:35, 11.57s/it] 53%|█████▎    | 6712/12750 [21:54:07<19:23:15, 11.56s/it] 53%|█████▎    | 6713/12750 [21:54:19<19:22:32, 11.55s/it] 53%|█████▎    | 6714/12750 [21:54:30<19:21:08, 11.54s/it] 53%|█████▎    | 6715/12750 [21:54:42<19:21:10, 11.54s/it] 53%|█████▎    | 6716/12750 [21:54:53<19:21:16, 11.55s/it] 53%|█████▎    | 6717/12750 [21:55:05<19:21:46, 11.55s/it] 53%|█████▎    | 6718/12750 [21:55:16<19:20:35, 11.54s/it] 53%|█████▎    | 6719/12750 [21:55:28<19:20:46, 11.55s/it] 53%|█████▎    | 6720/12750 [21:55:39<19:20:21, 11.55s/it] 53%|█████▎    | 6721/12750 [21:55:51<19:20:41, 11.55s/it] 53%|█████▎    | 6722/12750 [21:56:02<19:19:51, 11.54s/it] 53%|█████▎    | 6723/12750 [21:56:14<19:20:26, 11.55s/it] 53%|█████▎    | 6724/12750 [21:56:26<19:20:25, 11.55s/it] 53%|█████▎    | 6725/12750 [21:56:37<19:20:20, 11.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120566.53lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104894.80lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6725
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6725/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6725/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6700] due to args.save_total_limit
 53%|█████▎    | 6726/12750 [21:56:57<23:15:51, 13.90s/it] 53%|█████▎    | 6727/12750 [21:57:08<22:04:55, 13.20s/it] 53%|█████▎    | 6728/12750 [21:57:20<21:16:12, 12.72s/it] 53%|█████▎    | 6729/12750 [21:57:31<20:41:39, 12.37s/it] 53%|█████▎    | 6730/12750 [21:57:43<20:15:55, 12.12s/it] 53%|█████▎    | 6731/12750 [21:57:54<19:59:25, 11.96s/it] 53%|█████▎    | 6732/12750 [21:58:06<19:47:26, 11.84s/it] 53%|█████▎    | 6733/12750 [21:58:17<19:38:20, 11.75s/it] 53%|█████▎    | 6734/12750 [21:58:29<19:32:21, 11.69s/it] 53%|█████▎    | 6735/12750 [21:58:41<19:28:40, 11.66s/it] 53%|█████▎    | 6736/12750 [21:58:52<19:25:10, 11.62s/it] 53%|█████▎    | 6737/12750 [21:59:04<19:23:06, 11.61s/it] 53%|█████▎    | 6738/12750 [21:59:15<19:21:15, 11.59s/it] 53%|█████▎    | 6739/12750 [21:59:27<19:20:21, 11.58s/it] 53%|█████▎    | 6740/12750 [21:59:38<19:20:37, 11.59s/it] 53%|█████▎    | 6741/12750 [21:59:50<19:19:05, 11.57s/it] 53%|█████▎    | 6742/12750 [22:00:01<19:18:20, 11.57s/it] 53%|█████▎    | 6743/12750 [22:00:13<19:17:50, 11.56s/it] 53%|█████▎    | 6744/12750 [22:00:25<19:21:01, 11.60s/it] 53%|█████▎    | 6745/12750 [22:00:36<19:20:17, 11.59s/it] 53%|█████▎    | 6746/12750 [22:00:48<19:19:57, 11.59s/it] 53%|█████▎    | 6747/12750 [22:00:59<19:18:25, 11.58s/it] 53%|█████▎    | 6748/12750 [22:01:11<19:22:12, 11.62s/it] 53%|█████▎    | 6749/12750 [22:01:23<19:19:59, 11.60s/it] 53%|█████▎    | 6750/12750 [22:01:34<19:21:06, 11.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120429.21lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104702.29lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6750
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6750/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6750/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6725] due to args.save_total_limit
 53%|█████▎    | 6751/12750 [22:01:46<19:28:45, 11.69s/it] 53%|█████▎    | 6752/12750 [22:01:58<19:24:16, 11.65s/it] 53%|█████▎    | 6753/12750 [22:02:09<19:25:38, 11.66s/it] 53%|█████▎    | 6754/12750 [22:02:21<19:22:39, 11.63s/it] 53%|█████▎    | 6755/12750 [22:02:33<19:20:00, 11.61s/it] 53%|█████▎    | 6756/12750 [22:02:44<19:20:45, 11.62s/it] 53%|█████▎    | 6757/12750 [22:02:56<19:19:05, 11.60s/it] 53%|█████▎    | 6758/12750 [22:03:15<23:03:26, 13.85s/it] 53%|█████▎    | 6759/12750 [22:03:26<21:54:41, 13.17s/it] 53%|█████▎    | 6760/12750 [22:03:38<21:05:14, 12.67s/it] 53%|█████▎    | 6761/12750 [22:03:50<20:32:22, 12.35s/it] 53%|█████▎    | 6762/12750 [22:04:01<20:09:49, 12.12s/it] 53%|█████▎    | 6763/12750 [22:04:13<19:52:36, 11.95s/it] 53%|█████▎    | 6764/12750 [22:04:24<19:40:44, 11.84s/it] 53%|█████▎    | 6765/12750 [22:04:36<19:32:27, 11.75s/it] 53%|█████▎    | 6766/12750 [22:04:47<19:25:36, 11.69s/it] 53%|█████▎    | 6767/12750 [22:04:59<19:21:25, 11.65s/it] 53%|█████▎    | 6768/12750 [22:05:10<19:17:52, 11.61s/it] 53%|█████▎    | 6769/12750 [22:05:22<19:16:35, 11.60s/it] 53%|█████▎    | 6770/12750 [22:05:34<19:15:07, 11.59s/it] 53%|█████▎    | 6771/12750 [22:05:45<19:15:12, 11.59s/it] 53%|█████▎    | 6772/12750 [22:05:57<19:13:08, 11.57s/it] 53%|█████▎    | 6773/12750 [22:06:08<19:13:10, 11.58s/it] 53%|█████▎    | 6774/12750 [22:06:20<19:12:46, 11.57s/it] 53%|█████▎    | 6775/12750 [22:06:31<19:11:34, 11.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120622.64lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104905.88lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6775
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6775/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6775/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6750] due to args.save_total_limit
 53%|█████▎    | 6776/12750 [22:06:43<19:19:14, 11.64s/it] 53%|█████▎    | 6777/12750 [22:06:55<19:16:10, 11.61s/it] 53%|█████▎    | 6778/12750 [22:07:06<19:13:14, 11.59s/it] 53%|█████▎    | 6779/12750 [22:07:18<19:11:18, 11.57s/it] 53%|█████▎    | 6780/12750 [22:07:29<19:10:59, 11.57s/it] 53%|█████▎    | 6781/12750 [22:07:41<19:10:02, 11.56s/it] 53%|█████▎    | 6782/12750 [22:07:52<19:09:02, 11.55s/it] 53%|█████▎    | 6783/12750 [22:08:04<19:08:26, 11.55s/it] 53%|█████▎    | 6784/12750 [22:08:16<19:08:26, 11.55s/it] 53%|█████▎    | 6785/12750 [22:08:27<19:08:28, 11.55s/it] 53%|█████▎    | 6786/12750 [22:08:39<19:07:57, 11.55s/it] 53%|█████▎    | 6787/12750 [22:08:50<19:07:14, 11.54s/it] 53%|█████▎    | 6788/12750 [22:09:02<19:07:09, 11.54s/it] 53%|█████▎    | 6789/12750 [22:09:13<19:07:01, 11.55s/it] 53%|█████▎    | 6790/12750 [22:09:32<22:53:33, 13.83s/it] 53%|█████▎    | 6791/12750 [22:09:44<21:45:56, 13.15s/it] 53%|█████▎    | 6792/12750 [22:09:56<20:57:47, 12.67s/it] 53%|█████▎    | 6793/12750 [22:10:07<20:24:38, 12.33s/it] 53%|█████▎    | 6794/12750 [22:10:19<20:00:56, 12.10s/it] 53%|█████▎    | 6795/12750 [22:10:30<19:44:04, 11.93s/it] 53%|█████▎    | 6796/12750 [22:10:42<19:32:02, 11.81s/it] 53%|█████▎    | 6797/12750 [22:10:53<19:23:28, 11.73s/it] 53%|█████▎    | 6798/12750 [22:11:05<19:17:39, 11.67s/it] 53%|█████▎    | 6799/12750 [22:11:16<19:13:45, 11.63s/it] 53%|█████▎    | 6800/12750 [22:11:28<19:11:14, 11.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120440.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104280.96lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6800
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6800/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6800/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6775] due to args.save_total_limit
 53%|█████▎    | 6801/12750 [22:11:40<19:17:37, 11.68s/it] 53%|█████▎    | 6802/12750 [22:11:51<19:16:44, 11.67s/it] 53%|█████▎    | 6803/12750 [22:12:03<19:12:04, 11.62s/it] 53%|█████▎    | 6804/12750 [22:12:15<19:12:17, 11.63s/it] 53%|█████▎    | 6805/12750 [22:12:26<19:11:16, 11.62s/it] 53%|█████▎    | 6806/12750 [22:12:38<19:09:35, 11.60s/it] 53%|█████▎    | 6807/12750 [22:12:49<19:08:21, 11.59s/it] 53%|█████▎    | 6808/12750 [22:13:01<19:08:05, 11.59s/it] 53%|█████▎    | 6809/12750 [22:13:12<19:07:41, 11.59s/it] 53%|█████▎    | 6810/12750 [22:13:24<19:07:32, 11.59s/it] 53%|█████▎    | 6811/12750 [22:13:36<19:06:15, 11.58s/it] 53%|█████▎    | 6812/12750 [22:13:47<19:05:54, 11.58s/it] 53%|█████▎    | 6813/12750 [22:13:59<19:04:19, 11.56s/it] 53%|█████▎    | 6814/12750 [22:14:10<19:05:09, 11.58s/it] 53%|█████▎    | 6815/12750 [22:14:22<19:05:21, 11.58s/it] 53%|█████▎    | 6816/12750 [22:14:33<19:04:33, 11.57s/it] 53%|█████▎    | 6817/12750 [22:14:45<19:03:23, 11.56s/it] 53%|█████▎    | 6818/12750 [22:14:57<19:02:30, 11.56s/it] 53%|█████▎    | 6819/12750 [22:15:08<19:02:22, 11.56s/it] 53%|█████▎    | 6820/12750 [22:15:20<19:02:35, 11.56s/it] 53%|█████▎    | 6821/12750 [22:15:31<19:02:12, 11.56s/it] 54%|█████▎    | 6822/12750 [22:15:50<22:27:04, 13.63s/it] 54%|█████▎    | 6823/12750 [22:16:01<21:24:26, 13.00s/it] 54%|█████▎    | 6824/12750 [22:16:13<20:42:36, 12.58s/it] 54%|█████▎    | 6825/12750 [22:16:24<20:12:36, 12.28s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120594.13lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104838.67lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6825
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6825/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6825/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6800] due to args.save_total_limit
 54%|█████▎    | 6826/12750 [22:16:36<20:01:29, 12.17s/it] 54%|█████▎    | 6827/12750 [22:16:48<19:43:24, 11.99s/it] 54%|█████▎    | 6828/12750 [22:16:59<19:30:20, 11.86s/it] 54%|█████▎    | 6829/12750 [22:17:11<19:20:58, 11.76s/it] 54%|█████▎    | 6830/12750 [22:17:23<19:14:23, 11.70s/it] 54%|█████▎    | 6831/12750 [22:17:34<19:09:18, 11.65s/it] 54%|█████▎    | 6832/12750 [22:17:46<19:06:59, 11.63s/it] 54%|█████▎    | 6833/12750 [22:17:57<19:05:32, 11.62s/it] 54%|█████▎    | 6834/12750 [22:18:09<19:02:45, 11.59s/it] 54%|█████▎    | 6835/12750 [22:18:20<19:01:07, 11.58s/it] 54%|█████▎    | 6836/12750 [22:18:32<18:59:52, 11.56s/it] 54%|█████▎    | 6837/12750 [22:18:44<19:03:24, 11.60s/it] 54%|█████▎    | 6838/12750 [22:18:55<19:01:18, 11.58s/it] 54%|█████▎    | 6839/12750 [22:19:07<18:59:33, 11.57s/it] 54%|█████▎    | 6840/12750 [22:19:18<18:57:40, 11.55s/it] 54%|█████▎    | 6841/12750 [22:19:30<18:56:59, 11.55s/it] 54%|█████▎    | 6842/12750 [22:19:41<18:57:00, 11.55s/it] 54%|█████▎    | 6843/12750 [22:19:53<18:57:06, 11.55s/it] 54%|█████▎    | 6844/12750 [22:20:04<18:56:02, 11.54s/it] 54%|█████▎    | 6845/12750 [22:20:16<18:55:59, 11.54s/it] 54%|█████▎    | 6846/12750 [22:20:27<18:55:31, 11.54s/it] 54%|█████▎    | 6847/12750 [22:20:39<18:56:22, 11.55s/it] 54%|█████▎    | 6848/12750 [22:20:50<18:55:11, 11.54s/it] 54%|█████▎    | 6849/12750 [22:21:02<18:55:32, 11.55s/it] 54%|█████▎    | 6850/12750 [22:21:14<18:55:31, 11.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 117021.92lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 102112.38lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6850
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6850/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6850/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6825] due to args.save_total_limit
 54%|█████▎    | 6851/12750 [22:21:25<19:04:43, 11.64s/it] 54%|█████▎    | 6852/12750 [22:21:37<19:00:08, 11.60s/it] 54%|█████▎    | 6853/12750 [22:21:48<18:57:37, 11.57s/it] 54%|█████▍    | 6854/12750 [22:22:08<22:43:30, 13.88s/it] 54%|█████▍    | 6855/12750 [22:22:19<21:38:23, 13.22s/it] 54%|█████▍    | 6856/12750 [22:22:31<20:48:16, 12.71s/it] 54%|█████▍    | 6857/12750 [22:22:42<20:13:02, 12.35s/it] 54%|█████▍    | 6858/12750 [22:22:54<19:48:41, 12.10s/it] 54%|█████▍    | 6859/12750 [22:23:05<19:32:18, 11.94s/it] 54%|█████▍    | 6860/12750 [22:23:17<19:21:08, 11.83s/it] 54%|█████▍    | 6861/12750 [22:23:29<19:15:23, 11.77s/it] 54%|█████▍    | 6862/12750 [22:23:40<19:10:06, 11.72s/it] 54%|█████▍    | 6863/12750 [22:23:52<19:05:04, 11.67s/it] 54%|█████▍    | 6864/12750 [22:24:03<19:01:38, 11.64s/it] 54%|█████▍    | 6865/12750 [22:24:15<18:59:43, 11.62s/it] 54%|█████▍    | 6866/12750 [22:24:27<18:57:28, 11.60s/it] 54%|█████▍    | 6867/12750 [22:24:38<18:56:09, 11.59s/it] 54%|█████▍    | 6868/12750 [22:24:50<18:54:36, 11.57s/it] 54%|█████▍    | 6869/12750 [22:25:01<18:54:14, 11.57s/it] 54%|█████▍    | 6870/12750 [22:25:13<18:53:55, 11.57s/it] 54%|█████▍    | 6871/12750 [22:25:24<18:53:06, 11.56s/it] 54%|█████▍    | 6872/12750 [22:25:36<18:55:10, 11.59s/it] 54%|█████▍    | 6873/12750 [22:25:48<19:00:53, 11.65s/it] 54%|█████▍    | 6874/12750 [22:25:59<19:00:33, 11.65s/it] 54%|█████▍    | 6875/12750 [22:26:11<18:57:58, 11.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120674.06lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104839.54lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6875
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6875/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6875/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6850] due to args.save_total_limit
 54%|█████▍    | 6876/12750 [22:26:23<19:05:45, 11.70s/it] 54%|█████▍    | 6877/12750 [22:26:34<18:59:59, 11.65s/it] 54%|█████▍    | 6878/12750 [22:26:46<18:56:30, 11.61s/it] 54%|█████▍    | 6879/12750 [22:26:57<18:53:44, 11.59s/it] 54%|█████▍    | 6880/12750 [22:27:09<18:52:07, 11.57s/it] 54%|█████▍    | 6881/12750 [22:27:21<18:51:24, 11.57s/it] 54%|█████▍    | 6882/12750 [22:27:32<18:50:45, 11.56s/it] 54%|█████▍    | 6883/12750 [22:27:44<18:50:50, 11.56s/it] 54%|█████▍    | 6884/12750 [22:27:55<18:50:00, 11.56s/it] 54%|█████▍    | 6885/12750 [22:28:07<18:50:00, 11.56s/it] 54%|█████▍    | 6886/12750 [22:28:26<22:35:55, 13.87s/it] 54%|█████▍    | 6887/12750 [22:28:38<21:28:13, 13.18s/it] 54%|█████▍    | 6888/12750 [22:28:49<20:40:30, 12.70s/it] 54%|█████▍    | 6889/12750 [22:29:01<20:09:03, 12.38s/it] 54%|█████▍    | 6890/12750 [22:29:12<19:43:42, 12.12s/it] 54%|█████▍    | 6891/12750 [22:29:24<19:27:35, 11.96s/it] 54%|█████▍    | 6892/12750 [22:29:35<19:15:30, 11.84s/it] 54%|█████▍    | 6893/12750 [22:29:47<19:07:40, 11.76s/it] 54%|█████▍    | 6894/12750 [22:29:59<19:01:54, 11.70s/it] 54%|█████▍    | 6895/12750 [22:30:10<18:57:34, 11.66s/it] 54%|█████▍    | 6896/12750 [22:30:22<18:54:08, 11.62s/it] 54%|█████▍    | 6897/12750 [22:30:33<18:51:56, 11.60s/it] 54%|█████▍    | 6898/12750 [22:30:45<18:50:27, 11.59s/it] 54%|█████▍    | 6899/12750 [22:30:56<18:49:25, 11.58s/it] 54%|█████▍    | 6900/12750 [22:31:08<18:49:13, 11.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120648.47lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104931.93lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6900
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6900/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6900/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6875] due to args.save_total_limit
 54%|█████▍    | 6901/12750 [22:31:20<18:58:27, 11.68s/it] 54%|█████▍    | 6902/12750 [22:31:31<18:55:00, 11.65s/it] 54%|█████▍    | 6903/12750 [22:31:43<18:52:58, 11.63s/it] 54%|█████▍    | 6904/12750 [22:31:55<18:50:19, 11.60s/it] 54%|█████▍    | 6905/12750 [22:32:06<18:48:46, 11.59s/it] 54%|█████▍    | 6906/12750 [22:32:18<18:47:39, 11.58s/it] 54%|█████▍    | 6907/12750 [22:32:29<18:46:40, 11.57s/it] 54%|█████▍    | 6908/12750 [22:32:41<18:46:09, 11.57s/it] 54%|█████▍    | 6909/12750 [22:32:52<18:45:29, 11.56s/it] 54%|█████▍    | 6910/12750 [22:33:04<18:44:21, 11.55s/it] 54%|█████▍    | 6911/12750 [22:33:15<18:43:58, 11.55s/it] 54%|█████▍    | 6912/12750 [22:33:27<18:43:19, 11.54s/it] 54%|█████▍    | 6913/12750 [22:33:38<18:42:55, 11.54s/it] 54%|█████▍    | 6914/12750 [22:33:50<18:43:02, 11.55s/it] 54%|█████▍    | 6915/12750 [22:34:02<18:43:00, 11.55s/it] 54%|█████▍    | 6916/12750 [22:34:13<18:42:15, 11.54s/it] 54%|█████▍    | 6917/12750 [22:34:25<18:46:46, 11.59s/it] 54%|█████▍    | 6918/12750 [22:34:36<18:45:31, 11.58s/it] 54%|█████▍    | 6919/12750 [22:34:56<22:32:54, 13.92s/it] 54%|█████▍    | 6920/12750 [22:35:07<21:27:46, 13.25s/it] 54%|█████▍    | 6921/12750 [22:35:19<20:41:02, 12.77s/it] 54%|█████▍    | 6922/12750 [22:35:31<20:06:18, 12.42s/it] 54%|█████▍    | 6923/12750 [22:35:42<19:40:44, 12.16s/it] 54%|█████▍    | 6924/12750 [22:35:54<19:23:31, 11.98s/it] 54%|█████▍    | 6925/12750 [22:36:05<19:11:00, 11.86s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120598.50lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104901.11lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6925
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6925/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6925/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6900] due to args.save_total_limit
 54%|█████▍    | 6926/12750 [22:36:17<19:15:07, 11.90s/it] 54%|█████▍    | 6927/12750 [22:36:29<19:04:16, 11.79s/it] 54%|█████▍    | 6928/12750 [22:36:40<18:57:13, 11.72s/it] 54%|█████▍    | 6929/12750 [22:36:52<18:52:42, 11.68s/it] 54%|█████▍    | 6930/12750 [22:37:04<18:49:44, 11.65s/it] 54%|█████▍    | 6931/12750 [22:37:15<18:46:54, 11.62s/it] 54%|█████▍    | 6932/12750 [22:37:27<18:44:56, 11.60s/it] 54%|█████▍    | 6933/12750 [22:37:38<18:43:31, 11.59s/it] 54%|█████▍    | 6934/12750 [22:37:50<18:42:38, 11.58s/it] 54%|█████▍    | 6935/12750 [22:38:01<18:41:39, 11.57s/it] 54%|█████▍    | 6936/12750 [22:38:13<18:41:13, 11.57s/it] 54%|█████▍    | 6937/12750 [22:38:25<18:40:48, 11.57s/it] 54%|█████▍    | 6938/12750 [22:38:36<18:39:56, 11.56s/it] 54%|█████▍    | 6939/12750 [22:38:48<18:39:41, 11.56s/it] 54%|█████▍    | 6940/12750 [22:38:59<18:38:52, 11.55s/it] 54%|█████▍    | 6941/12750 [22:39:11<18:38:27, 11.55s/it] 54%|█████▍    | 6942/12750 [22:39:22<18:37:35, 11.55s/it] 54%|█████▍    | 6943/12750 [22:39:34<18:37:34, 11.55s/it] 54%|█████▍    | 6944/12750 [22:39:45<18:37:29, 11.55s/it] 54%|█████▍    | 6945/12750 [22:39:57<18:40:01, 11.58s/it] 54%|█████▍    | 6946/12750 [22:40:09<18:40:23, 11.58s/it] 54%|█████▍    | 6947/12750 [22:40:20<18:39:27, 11.57s/it] 54%|█████▍    | 6948/12750 [22:40:32<18:38:29, 11.57s/it] 55%|█████▍    | 6949/12750 [22:40:43<18:37:34, 11.56s/it] 55%|█████▍    | 6950/12750 [22:40:55<18:37:18, 11.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120568.45lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104865.08lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6950
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6950/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6950/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6925] due to args.save_total_limit
 55%|█████▍    | 6951/12750 [22:41:14<22:29:44, 13.97s/it] 55%|█████▍    | 6952/12750 [22:41:26<21:19:24, 13.24s/it] 55%|█████▍    | 6953/12750 [22:41:37<20:29:30, 12.73s/it] 55%|█████▍    | 6954/12750 [22:41:49<19:55:52, 12.38s/it] 55%|█████▍    | 6955/12750 [22:42:01<19:30:56, 12.12s/it] 55%|█████▍    | 6956/12750 [22:42:12<19:15:37, 11.97s/it] 55%|█████▍    | 6957/12750 [22:42:24<19:03:42, 11.85s/it] 55%|█████▍    | 6958/12750 [22:42:35<18:54:59, 11.76s/it] 55%|█████▍    | 6959/12750 [22:42:47<18:49:17, 11.70s/it] 55%|█████▍    | 6960/12750 [22:42:58<18:47:03, 11.68s/it] 55%|█████▍    | 6961/12750 [22:43:10<18:44:25, 11.65s/it] 55%|█████▍    | 6962/12750 [22:43:22<18:42:20, 11.63s/it] 55%|█████▍    | 6963/12750 [22:43:33<18:40:10, 11.61s/it] 55%|█████▍    | 6964/12750 [22:43:45<18:37:23, 11.59s/it] 55%|█████▍    | 6965/12750 [22:43:56<18:36:15, 11.58s/it] 55%|█████▍    | 6966/12750 [22:44:08<18:35:54, 11.58s/it] 55%|█████▍    | 6967/12750 [22:44:19<18:35:24, 11.57s/it] 55%|█████▍    | 6968/12750 [22:44:31<18:35:09, 11.57s/it] 55%|█████▍    | 6969/12750 [22:44:43<18:35:42, 11.58s/it] 55%|█████▍    | 6970/12750 [22:44:54<18:33:41, 11.56s/it] 55%|█████▍    | 6971/12750 [22:45:06<18:32:49, 11.55s/it] 55%|█████▍    | 6972/12750 [22:45:17<18:32:36, 11.55s/it] 55%|█████▍    | 6973/12750 [22:45:29<18:33:16, 11.56s/it] 55%|█████▍    | 6974/12750 [22:45:40<18:33:51, 11.57s/it] 55%|█████▍    | 6975/12750 [22:45:52<18:35:04, 11.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120648.09lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104792.78lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6975
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6975/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6975/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-6975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6950] due to args.save_total_limit
 55%|█████▍    | 6976/12750 [22:46:04<18:48:18, 11.72s/it] 55%|█████▍    | 6977/12750 [22:46:16<18:46:18, 11.71s/it] 55%|█████▍    | 6978/12750 [22:46:27<18:42:18, 11.67s/it] 55%|█████▍    | 6979/12750 [22:46:39<18:38:10, 11.63s/it] 55%|█████▍    | 6980/12750 [22:46:50<18:33:47, 11.58s/it] 55%|█████▍    | 6981/12750 [22:47:02<18:30:36, 11.55s/it] 55%|█████▍    | 6982/12750 [22:47:13<18:28:55, 11.54s/it] 55%|█████▍    | 6983/12750 [22:47:32<22:09:05, 13.83s/it] 55%|█████▍    | 6984/12750 [22:47:44<21:04:48, 13.16s/it] 55%|█████▍    | 6985/12750 [22:47:56<20:16:16, 12.66s/it] 55%|█████▍    | 6986/12750 [22:48:07<19:43:33, 12.32s/it] 55%|█████▍    | 6987/12750 [22:48:19<19:19:39, 12.07s/it] 55%|█████▍    | 6988/12750 [22:48:30<19:01:52, 11.89s/it] 55%|█████▍    | 6989/12750 [22:48:42<18:50:28, 11.77s/it] 55%|█████▍    | 6990/12750 [22:48:53<18:43:59, 11.71s/it] 55%|█████▍    | 6991/12750 [22:49:05<18:40:35, 11.67s/it] 55%|█████▍    | 6992/12750 [22:49:16<18:37:14, 11.64s/it] 55%|█████▍    | 6993/12750 [22:49:28<18:36:50, 11.64s/it] 55%|█████▍    | 6994/12750 [22:49:39<18:33:53, 11.61s/it] 55%|█████▍    | 6995/12750 [22:49:51<18:31:40, 11.59s/it] 55%|█████▍    | 6996/12750 [22:50:03<18:32:04, 11.60s/it] 55%|█████▍    | 6997/12750 [22:50:14<18:30:59, 11.59s/it] 55%|█████▍    | 6998/12750 [22:50:26<18:31:17, 11.59s/it] 55%|█████▍    | 6999/12750 [22:50:37<18:32:34, 11.61s/it] 55%|█████▍    | 7000/12750 [22:50:49<18:32:19, 11.61s/it]                                                           55%|█████▍    | 7000/12750 [22:50:49<18:32:19, 11.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120679.33lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104934.45lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7000
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7000/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7000/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6975] due to args.save_total_limit
 55%|█████▍    | 7001/12750 [22:51:01<18:41:54, 11.71s/it] 55%|█████▍    | 7002/12750 [22:51:13<18:38:18, 11.67s/it] 55%|█████▍    | 7003/12750 [22:51:24<18:35:07, 11.64s/it] 55%|█████▍    | 7004/12750 [22:51:36<18:32:58, 11.62s/it] 55%|█████▍    | 7005/12750 [22:51:47<18:32:53, 11.62s/it] 55%|█████▍    | 7006/12750 [22:51:59<18:33:02, 11.63s/it] 55%|█████▍    | 7007/12750 [22:52:11<18:31:49, 11.62s/it] 55%|█████▍    | 7008/12750 [22:52:22<18:29:29, 11.59s/it] 55%|█████▍    | 7009/12750 [22:52:34<18:30:16, 11.60s/it] 55%|█████▍    | 7010/12750 [22:52:45<18:30:19, 11.61s/it] 55%|█████▍    | 7011/12750 [22:52:57<18:30:15, 11.61s/it] 55%|█████▍    | 7012/12750 [22:53:09<18:29:36, 11.60s/it] 55%|█████▌    | 7013/12750 [22:53:20<18:29:58, 11.61s/it] 55%|█████▌    | 7014/12750 [22:53:32<18:29:44, 11.61s/it] 55%|█████▌    | 7015/12750 [22:53:51<22:09:35, 13.91s/it] 55%|█████▌    | 7016/12750 [22:54:03<21:03:02, 13.22s/it] 55%|█████▌    | 7017/12750 [22:54:14<20:17:48, 12.75s/it] 55%|█████▌    | 7018/12750 [22:54:26<19:45:03, 12.40s/it] 55%|█████▌    | 7019/12750 [22:54:38<19:23:05, 12.18s/it] 55%|█████▌    | 7020/12750 [22:54:49<19:06:21, 12.00s/it] 55%|█████▌    | 7021/12750 [22:55:01<18:55:09, 11.89s/it] 55%|█████▌    | 7022/12750 [22:55:12<18:47:21, 11.81s/it] 55%|█████▌    | 7023/12750 [22:55:24<18:41:31, 11.75s/it] 55%|█████▌    | 7024/12750 [22:55:36<18:37:49, 11.71s/it] 55%|█████▌    | 7025/12750 [22:55:47<18:34:48, 11.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120635.24lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104917.93lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7025
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7025/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7025/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7000] due to args.save_total_limit
 55%|█████▌    | 7026/12750 [22:55:59<18:37:17, 11.71s/it] 55%|█████▌    | 7027/12750 [22:56:11<18:31:43, 11.66s/it] 55%|█████▌    | 7028/12750 [22:56:22<18:27:33, 11.61s/it] 55%|█████▌    | 7029/12750 [22:56:34<18:26:36, 11.61s/it] 55%|█████▌    | 7030/12750 [22:56:45<18:23:04, 11.57s/it] 55%|█████▌    | 7031/12750 [22:56:57<18:22:36, 11.57s/it] 55%|█████▌    | 7032/12750 [22:57:08<18:21:42, 11.56s/it] 55%|█████▌    | 7033/12750 [22:57:20<18:23:03, 11.58s/it] 55%|█████▌    | 7034/12750 [22:57:31<18:19:53, 11.55s/it] 55%|█████▌    | 7035/12750 [22:57:43<18:18:59, 11.54s/it] 55%|█████▌    | 7036/12750 [22:57:54<18:16:36, 11.51s/it] 55%|█████▌    | 7037/12750 [22:58:06<18:15:47, 11.51s/it] 55%|█████▌    | 7038/12750 [22:58:17<18:15:42, 11.51s/it] 55%|█████▌    | 7039/12750 [22:58:29<18:15:13, 11.51s/it] 55%|█████▌    | 7040/12750 [22:58:40<18:17:04, 11.53s/it] 55%|█████▌    | 7041/12750 [22:58:52<18:16:42, 11.53s/it] 55%|█████▌    | 7042/12750 [22:59:04<18:20:27, 11.57s/it] 55%|█████▌    | 7043/12750 [22:59:15<18:23:26, 11.60s/it] 55%|█████▌    | 7044/12750 [22:59:27<18:23:55, 11.61s/it] 55%|█████▌    | 7045/12750 [22:59:39<18:25:08, 11.62s/it] 55%|█████▌    | 7046/12750 [22:59:50<18:26:51, 11.64s/it] 55%|█████▌    | 7047/12750 [23:00:09<21:57:16, 13.86s/it] 55%|█████▌    | 7048/12750 [23:00:21<20:54:22, 13.20s/it] 55%|█████▌    | 7049/12750 [23:00:33<20:10:23, 12.74s/it] 55%|█████▌    | 7050/12750 [23:00:44<19:39:44, 12.42s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120637.55lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104948.07lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7050
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7050/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7050/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7025] due to args.save_total_limit
 55%|█████▌    | 7051/12750 [23:00:56<19:28:07, 12.30s/it] 55%|█████▌    | 7052/12750 [23:01:08<19:09:05, 12.10s/it] 55%|█████▌    | 7053/12750 [23:01:20<18:55:40, 11.96s/it] 55%|█████▌    | 7054/12750 [23:01:31<18:46:48, 11.87s/it] 55%|█████▌    | 7055/12750 [23:01:43<18:40:18, 11.80s/it] 55%|█████▌    | 7056/12750 [23:01:54<18:35:24, 11.75s/it] 55%|█████▌    | 7057/12750 [23:02:06<18:32:15, 11.72s/it] 55%|█████▌    | 7058/12750 [23:02:18<18:29:19, 11.69s/it] 55%|█████▌    | 7059/12750 [23:02:29<18:26:53, 11.67s/it] 55%|█████▌    | 7060/12750 [23:02:41<18:25:39, 11.66s/it] 55%|█████▌    | 7061/12750 [23:02:53<18:24:59, 11.65s/it] 55%|█████▌    | 7062/12750 [23:03:04<18:24:47, 11.65s/it] 55%|█████▌    | 7063/12750 [23:03:16<18:23:17, 11.64s/it] 55%|█████▌    | 7064/12750 [23:03:28<18:29:20, 11.71s/it] 55%|█████▌    | 7065/12750 [23:03:39<18:26:35, 11.68s/it] 55%|█████▌    | 7066/12750 [23:03:51<18:24:27, 11.66s/it] 55%|█████▌    | 7067/12750 [23:04:03<18:23:53, 11.65s/it] 55%|█████▌    | 7068/12750 [23:04:14<18:23:25, 11.65s/it] 55%|█████▌    | 7069/12750 [23:04:26<18:23:15, 11.65s/it] 55%|█████▌    | 7070/12750 [23:04:38<18:22:28, 11.65s/it] 55%|█████▌    | 7071/12750 [23:04:49<18:21:53, 11.64s/it] 55%|█████▌    | 7072/12750 [23:05:01<18:21:27, 11.64s/it] 55%|█████▌    | 7073/12750 [23:05:12<18:22:22, 11.65s/it] 55%|█████▌    | 7074/12750 [23:05:24<18:21:46, 11.65s/it] 55%|█████▌    | 7075/12750 [23:05:36<18:20:35, 11.64s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120692.71lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104776.11lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7075
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7075/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7075/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7050] due to args.save_total_limit
 55%|█████▌    | 7076/12750 [23:05:48<18:29:49, 11.74s/it] 56%|█████▌    | 7077/12750 [23:05:59<18:26:41, 11.70s/it] 56%|█████▌    | 7078/12750 [23:06:11<18:24:27, 11.68s/it] 56%|█████▌    | 7079/12750 [23:06:30<21:59:15, 13.96s/it] 56%|█████▌    | 7080/12750 [23:06:42<20:52:56, 13.26s/it] 56%|█████▌    | 7081/12750 [23:06:53<20:06:36, 12.77s/it] 56%|█████▌    | 7082/12750 [23:07:05<19:33:58, 12.43s/it] 56%|█████▌    | 7083/12750 [23:07:17<19:10:51, 12.18s/it] 56%|█████▌    | 7084/12750 [23:07:28<18:55:21, 12.02s/it] 56%|█████▌    | 7085/12750 [23:07:40<18:44:07, 11.91s/it] 56%|█████▌    | 7086/12750 [23:07:52<18:36:07, 11.82s/it] 56%|█████▌    | 7087/12750 [23:08:03<18:29:49, 11.76s/it] 56%|█████▌    | 7088/12750 [23:08:15<18:25:33, 11.72s/it] 56%|█████▌    | 7089/12750 [23:08:26<18:22:06, 11.68s/it] 56%|█████▌    | 7090/12750 [23:08:38<18:19:56, 11.66s/it] 56%|█████▌    | 7091/12750 [23:08:50<18:18:11, 11.64s/it] 56%|█████▌    | 7092/12750 [23:09:01<18:17:11, 11.64s/it] 56%|█████▌    | 7093/12750 [23:09:13<18:16:03, 11.63s/it] 56%|█████▌    | 7094/12750 [23:09:25<18:15:41, 11.62s/it] 56%|█████▌    | 7095/12750 [23:09:36<18:15:17, 11.62s/it] 56%|█████▌    | 7096/12750 [23:09:48<18:15:38, 11.63s/it] 56%|█████▌    | 7097/12750 [23:09:59<18:15:42, 11.63s/it] 56%|█████▌    | 7098/12750 [23:10:11<18:14:46, 11.62s/it] 56%|█████▌    | 7099/12750 [23:10:23<18:14:33, 11.62s/it] 56%|█████▌    | 7100/12750 [23:10:34<18:14:57, 11.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120622.26lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104904.71lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7100
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7100/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7100/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7075] due to args.save_total_limit
 56%|█████▌    | 7101/12750 [23:10:46<18:23:43, 11.72s/it] 56%|█████▌    | 7102/12750 [23:10:58<18:19:27, 11.68s/it] 56%|█████▌    | 7103/12750 [23:11:09<18:17:27, 11.66s/it] 56%|█████▌    | 7104/12750 [23:11:21<18:15:46, 11.64s/it] 56%|█████▌    | 7105/12750 [23:11:33<18:15:16, 11.64s/it] 56%|█████▌    | 7106/12750 [23:11:44<18:13:54, 11.63s/it] 56%|█████▌    | 7107/12750 [23:11:56<18:13:16, 11.62s/it] 56%|█████▌    | 7108/12750 [23:12:08<18:13:11, 11.63s/it] 56%|█████▌    | 7109/12750 [23:12:19<18:12:44, 11.62s/it] 56%|█████▌    | 7110/12750 [23:12:31<18:11:54, 11.62s/it] 56%|█████▌    | 7111/12750 [23:12:42<18:11:15, 11.61s/it] 56%|█████▌    | 7112/12750 [23:13:02<21:53:14, 13.98s/it] 56%|█████▌    | 7113/12750 [23:13:13<20:46:40, 13.27s/it] 56%|█████▌    | 7114/12750 [23:13:25<20:00:43, 12.78s/it] 56%|█████▌    | 7115/12750 [23:13:37<19:27:05, 12.43s/it] 56%|█████▌    | 7116/12750 [23:13:48<19:04:18, 12.19s/it] 56%|█████▌    | 7117/12750 [23:14:00<18:49:12, 12.03s/it] 56%|█████▌    | 7118/12750 [23:14:12<18:37:53, 11.91s/it] 56%|█████▌    | 7119/12750 [23:14:23<18:30:48, 11.84s/it] 56%|█████▌    | 7120/12750 [23:14:35<18:25:13, 11.78s/it] 56%|█████▌    | 7121/12750 [23:14:47<18:21:21, 11.74s/it] 56%|█████▌    | 7122/12750 [23:14:58<18:17:15, 11.70s/it] 56%|█████▌    | 7123/12750 [23:15:10<18:15:08, 11.68s/it] 56%|█████▌    | 7124/12750 [23:15:21<18:13:47, 11.67s/it] 56%|█████▌    | 7125/12750 [23:15:33<18:12:57, 11.66s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120740.58lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 105011.42lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7125
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7125/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7125/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7100] due to args.save_total_limit
 56%|█████▌    | 7126/12750 [23:15:45<18:22:06, 11.76s/it] 56%|█████▌    | 7127/12750 [23:15:57<18:17:59, 11.72s/it] 56%|█████▌    | 7128/12750 [23:16:08<18:15:36, 11.69s/it] 56%|█████▌    | 7129/12750 [23:16:20<18:13:34, 11.67s/it] 56%|█████▌    | 7130/12750 [23:16:32<18:11:43, 11.66s/it] 56%|█████▌    | 7131/12750 [23:16:43<18:10:08, 11.64s/it] 56%|█████▌    | 7132/12750 [23:16:55<18:08:00, 11.62s/it] 56%|█████▌    | 7133/12750 [23:17:06<18:08:01, 11.62s/it] 56%|█████▌    | 7134/12750 [23:17:18<18:07:51, 11.62s/it] 56%|█████▌    | 7135/12750 [23:17:30<18:07:47, 11.62s/it] 56%|█████▌    | 7136/12750 [23:17:41<18:08:39, 11.64s/it] 56%|█████▌    | 7137/12750 [23:17:53<18:08:23, 11.63s/it] 56%|█████▌    | 7138/12750 [23:18:05<18:07:03, 11.62s/it] 56%|█████▌    | 7139/12750 [23:18:12<16:01:27, 10.28s/it] 56%|█████▌    | 7140/12750 [23:18:12<11:35:03,  7.43s/it] 56%|█████▌    | 7141/12750 [23:18:36<19:05:43, 12.26s/it] 56%|█████▌    | 7142/12750 [23:18:48<18:48:38, 12.08s/it] 56%|█████▌    | 7143/12750 [23:18:59<18:37:23, 11.96s/it] 56%|█████▌    | 7144/12750 [23:19:19<22:04:39, 14.18s/it] 56%|█████▌    | 7145/12750 [23:19:30<20:52:36, 13.41s/it] 56%|█████▌    | 7146/12750 [23:19:42<20:02:32, 12.88s/it] 56%|█████▌    | 7147/12750 [23:19:54<19:27:57, 12.51s/it] 56%|█████▌    | 7148/12750 [23:20:05<19:03:25, 12.25s/it] 56%|█████▌    | 7149/12750 [23:20:17<18:46:02, 12.06s/it] 56%|█████▌    | 7150/12750 [23:20:28<18:33:38, 11.93s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120627.40lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104851.00lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7150
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7150/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7150/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7125] due to args.save_total_limit
 56%|█████▌    | 7151/12750 [23:20:40<18:34:28, 11.94s/it] 56%|█████▌    | 7152/12750 [23:20:52<18:25:35, 11.85s/it] 56%|█████▌    | 7153/12750 [23:21:04<18:19:38, 11.79s/it] 56%|█████▌    | 7154/12750 [23:21:15<18:14:22, 11.73s/it] 56%|█████▌    | 7155/12750 [23:21:27<18:12:00, 11.71s/it] 56%|█████▌    | 7156/12750 [23:21:39<18:09:49, 11.69s/it] 56%|█████▌    | 7157/12750 [23:21:50<18:07:56, 11.67s/it] 56%|█████▌    | 7158/12750 [23:22:02<18:06:06, 11.65s/it] 56%|█████▌    | 7159/12750 [23:22:13<18:04:52, 11.64s/it] 56%|█████▌    | 7160/12750 [23:22:25<18:04:16, 11.64s/it] 56%|█████▌    | 7161/12750 [23:22:37<18:04:56, 11.65s/it] 56%|█████▌    | 7162/12750 [23:22:48<18:04:35, 11.65s/it] 56%|█████▌    | 7163/12750 [23:23:00<18:04:40, 11.65s/it] 56%|█████▌    | 7164/12750 [23:23:12<18:03:05, 11.63s/it] 56%|█████▌    | 7165/12750 [23:23:23<18:02:23, 11.63s/it] 56%|█████▌    | 7166/12750 [23:23:35<18:02:31, 11.63s/it] 56%|█████▌    | 7167/12750 [23:23:46<18:01:14, 11.62s/it] 56%|█████▌    | 7168/12750 [23:23:58<18:01:41, 11.63s/it] 56%|█████▌    | 7169/12750 [23:24:10<18:02:25, 11.64s/it] 56%|█████▌    | 7170/12750 [23:24:21<18:01:36, 11.63s/it] 56%|█████▌    | 7171/12750 [23:24:33<18:01:59, 11.64s/it] 56%|█████▋    | 7172/12750 [23:24:45<18:01:04, 11.63s/it] 56%|█████▋    | 7173/12750 [23:24:56<18:00:44, 11.63s/it] 56%|█████▋    | 7174/12750 [23:25:08<18:00:14, 11.62s/it] 56%|█████▋    | 7175/12750 [23:25:20<18:00:33, 11.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120617.25lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104926.87lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7175
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7175/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7175/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7150] due to args.save_total_limit
 56%|█████▋    | 7176/12750 [23:25:39<21:46:18, 14.06s/it] 56%|█████▋    | 7177/12750 [23:25:51<20:38:28, 13.33s/it] 56%|█████▋    | 7178/12750 [23:26:03<19:51:05, 12.83s/it] 56%|█████▋    | 7179/12750 [23:26:14<19:17:57, 12.47s/it] 56%|█████▋    | 7180/12750 [23:26:26<18:54:26, 12.22s/it] 56%|█████▋    | 7181/12750 [23:26:37<18:37:06, 12.04s/it] 56%|█████▋    | 7182/12750 [23:26:49<18:25:27, 11.91s/it] 56%|█████▋    | 7183/12750 [23:27:01<18:17:33, 11.83s/it] 56%|█████▋    | 7184/12750 [23:27:12<18:12:37, 11.78s/it] 56%|█████▋    | 7185/12750 [23:27:24<18:09:11, 11.74s/it] 56%|█████▋    | 7186/12750 [23:27:36<18:05:12, 11.70s/it] 56%|█████▋    | 7187/12750 [23:27:47<18:04:07, 11.69s/it] 56%|█████▋    | 7188/12750 [23:27:59<18:03:17, 11.69s/it] 56%|█████▋    | 7189/12750 [23:28:11<18:02:33, 11.68s/it] 56%|█████▋    | 7190/12750 [23:28:22<18:02:02, 11.68s/it] 56%|█████▋    | 7191/12750 [23:28:34<18:01:33, 11.67s/it] 56%|█████▋    | 7192/12750 [23:28:46<18:00:24, 11.66s/it] 56%|█████▋    | 7193/12750 [23:28:57<17:55:25, 11.61s/it] 56%|█████▋    | 7194/12750 [23:29:09<17:55:59, 11.62s/it] 56%|█████▋    | 7195/12750 [23:29:20<17:56:05, 11.62s/it] 56%|█████▋    | 7196/12750 [23:29:32<17:56:47, 11.63s/it] 56%|█████▋    | 7197/12750 [23:29:44<17:57:02, 11.64s/it] 56%|█████▋    | 7198/12750 [23:29:55<17:56:28, 11.63s/it] 56%|█████▋    | 7199/12750 [23:30:07<17:57:14, 11.64s/it] 56%|█████▋    | 7200/12750 [23:30:19<17:57:21, 11.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120585.91lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104899.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7200
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7200/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7200/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7175] due to args.save_total_limit
 56%|█████▋    | 7201/12750 [23:30:31<18:05:25, 11.74s/it] 56%|█████▋    | 7202/12750 [23:30:42<18:02:59, 11.71s/it] 56%|█████▋    | 7203/12750 [23:30:54<18:00:28, 11.69s/it] 57%|█████▋    | 7204/12750 [23:31:05<17:58:02, 11.66s/it] 57%|█████▋    | 7205/12750 [23:31:17<17:57:09, 11.66s/it] 57%|█████▋    | 7206/12750 [23:31:29<17:57:07, 11.66s/it] 57%|█████▋    | 7207/12750 [23:31:40<17:57:01, 11.66s/it] 57%|█████▋    | 7208/12750 [23:31:52<17:55:58, 11.65s/it] 57%|█████▋    | 7209/12750 [23:32:11<21:28:39, 13.95s/it] 57%|█████▋    | 7210/12750 [23:32:23<20:24:02, 13.26s/it] 57%|█████▋    | 7211/12750 [23:32:35<19:39:10, 12.77s/it] 57%|█████▋    | 7212/12750 [23:32:46<19:07:47, 12.44s/it] 57%|█████▋    | 7213/12750 [23:32:58<18:45:25, 12.20s/it] 57%|█████▋    | 7214/12750 [23:33:10<18:30:13, 12.03s/it] 57%|█████▋    | 7215/12750 [23:33:21<18:23:10, 11.96s/it] 57%|█████▋    | 7216/12750 [23:33:33<18:16:18, 11.89s/it] 57%|█████▋    | 7217/12750 [23:33:45<18:12:21, 11.85s/it] 57%|█████▋    | 7218/12750 [23:33:57<18:09:32, 11.82s/it] 57%|█████▋    | 7219/12750 [23:34:08<18:07:33, 11.80s/it] 57%|█████▋    | 7220/12750 [23:34:20<18:02:26, 11.74s/it] 57%|█████▋    | 7221/12750 [23:34:32<18:01:59, 11.74s/it] 57%|█████▋    | 7222/12750 [23:34:43<18:01:57, 11.74s/it] 57%|█████▋    | 7223/12750 [23:34:55<18:01:56, 11.75s/it] 57%|█████▋    | 7224/12750 [23:35:07<18:00:46, 11.73s/it] 57%|█████▋    | 7225/12750 [23:35:19<18:00:06, 11.73s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 119957.60lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104368.90lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7225
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7225/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7225/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7200] due to args.save_total_limit
 57%|█████▋    | 7226/12750 [23:35:31<18:09:42, 11.84s/it] 57%|█████▋    | 7227/12750 [23:35:42<18:03:41, 11.77s/it] 57%|█████▋    | 7228/12750 [23:35:54<17:58:53, 11.72s/it] 57%|█████▋    | 7229/12750 [23:36:06<17:54:19, 11.68s/it] 57%|█████▋    | 7230/12750 [23:36:17<17:54:07, 11.68s/it] 57%|█████▋    | 7231/12750 [23:36:29<17:55:20, 11.69s/it] 57%|█████▋    | 7232/12750 [23:36:41<17:56:52, 11.71s/it] 57%|█████▋    | 7233/12750 [23:36:52<17:58:05, 11.72s/it] 57%|█████▋    | 7234/12750 [23:37:04<17:58:41, 11.73s/it] 57%|█████▋    | 7235/12750 [23:37:16<17:58:39, 11.74s/it] 57%|█████▋    | 7236/12750 [23:37:28<17:58:23, 11.73s/it] 57%|█████▋    | 7237/12750 [23:37:39<17:58:18, 11.74s/it] 57%|█████▋    | 7238/12750 [23:37:51<18:00:33, 11.76s/it] 57%|█████▋    | 7239/12750 [23:38:03<18:01:26, 11.77s/it] 57%|█████▋    | 7240/12750 [23:38:15<18:01:19, 11.77s/it] 57%|█████▋    | 7241/12750 [23:38:34<21:31:13, 14.06s/it] 57%|█████▋    | 7242/12750 [23:38:46<20:27:10, 13.37s/it] 57%|█████▋    | 7243/12750 [23:38:58<19:41:37, 12.87s/it] 57%|█████▋    | 7244/12750 [23:39:09<19:09:44, 12.53s/it] 57%|█████▋    | 7245/12750 [23:39:21<18:46:46, 12.28s/it] 57%|█████▋    | 7246/12750 [23:39:33<18:32:17, 12.13s/it] 57%|█████▋    | 7247/12750 [23:39:45<18:20:48, 12.00s/it] 57%|█████▋    | 7248/12750 [23:39:56<18:13:04, 11.92s/it] 57%|█████▋    | 7249/12750 [23:40:08<18:08:18, 11.87s/it] 57%|█████▋    | 7250/12750 [23:40:20<18:05:10, 11.84s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120691.16lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104903.54lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7250
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7250/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7250/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7225] due to args.save_total_limit
 57%|█████▋    | 7251/12750 [23:40:32<18:10:37, 11.90s/it] 57%|█████▋    | 7252/12750 [23:40:44<18:05:17, 11.84s/it] 57%|█████▋    | 7253/12750 [23:40:55<18:01:46, 11.81s/it] 57%|█████▋    | 7254/12750 [23:41:07<17:58:53, 11.78s/it] 57%|█████▋    | 7255/12750 [23:41:19<17:56:35, 11.76s/it] 57%|█████▋    | 7256/12750 [23:41:31<18:00:48, 11.80s/it] 57%|█████▋    | 7257/12750 [23:41:42<17:57:34, 11.77s/it] 57%|█████▋    | 7258/12750 [23:41:54<17:56:06, 11.76s/it] 57%|█████▋    | 7259/12750 [23:42:06<17:53:44, 11.73s/it] 57%|█████▋    | 7260/12750 [23:42:17<17:53:37, 11.73s/it] 57%|█████▋    | 7261/12750 [23:42:29<17:52:38, 11.73s/it] 57%|█████▋    | 7262/12750 [23:42:41<17:51:59, 11.72s/it] 57%|█████▋    | 7263/12750 [23:42:53<17:51:49, 11.72s/it] 57%|█████▋    | 7264/12750 [23:43:04<17:52:02, 11.72s/it] 57%|█████▋    | 7265/12750 [23:43:16<17:52:08, 11.73s/it] 57%|█████▋    | 7266/12750 [23:43:28<17:51:09, 11.72s/it] 57%|█████▋    | 7267/12750 [23:43:39<17:50:26, 11.71s/it] 57%|█████▋    | 7268/12750 [23:43:51<17:48:49, 11.70s/it] 57%|█████▋    | 7269/12750 [23:44:03<17:48:11, 11.69s/it] 57%|█████▋    | 7270/12750 [23:44:15<17:48:55, 11.70s/it] 57%|█████▋    | 7271/12750 [23:44:26<17:48:58, 11.71s/it] 57%|█████▋    | 7272/12750 [23:44:38<17:49:08, 11.71s/it] 57%|█████▋    | 7273/12750 [23:44:57<21:16:50, 13.99s/it] 57%|█████▋    | 7274/12750 [23:45:09<20:14:26, 13.31s/it] 57%|█████▋    | 7275/12750 [23:45:21<19:30:20, 12.83s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120697.59lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104958.87lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7275
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7275/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7275/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7250] due to args.save_total_limit
 57%|█████▋    | 7276/12750 [23:45:33<19:06:18, 12.56s/it] 57%|█████▋    | 7277/12750 [23:45:44<18:39:55, 12.28s/it] 57%|█████▋    | 7278/12750 [23:45:56<18:22:37, 12.09s/it] 57%|█████▋    | 7279/12750 [23:46:08<18:10:28, 11.96s/it] 57%|█████▋    | 7280/12750 [23:46:19<18:01:55, 11.87s/it] 57%|█████▋    | 7281/12750 [23:46:31<17:55:44, 11.80s/it] 57%|█████▋    | 7282/12750 [23:46:42<17:50:53, 11.75s/it] 57%|█████▋    | 7283/12750 [23:46:54<17:47:39, 11.72s/it] 57%|█████▋    | 7284/12750 [23:47:06<17:46:04, 11.70s/it] 57%|█████▋    | 7285/12750 [23:47:17<17:43:53, 11.68s/it] 57%|█████▋    | 7286/12750 [23:47:29<17:42:03, 11.66s/it] 57%|█████▋    | 7287/12750 [23:47:41<17:40:55, 11.65s/it] 57%|█████▋    | 7288/12750 [23:47:52<17:39:58, 11.64s/it] 57%|█████▋    | 7289/12750 [23:48:04<17:39:17, 11.64s/it] 57%|█████▋    | 7290/12750 [23:48:16<17:39:23, 11.64s/it] 57%|█████▋    | 7291/12750 [23:48:27<17:38:07, 11.63s/it] 57%|█████▋    | 7292/12750 [23:48:39<17:37:14, 11.62s/it] 57%|█████▋    | 7293/12750 [23:48:50<17:37:24, 11.63s/it] 57%|█████▋    | 7294/12750 [23:49:02<17:37:30, 11.63s/it] 57%|█████▋    | 7295/12750 [23:49:14<17:35:56, 11.61s/it] 57%|█████▋    | 7296/12750 [23:49:25<17:35:49, 11.62s/it] 57%|█████▋    | 7297/12750 [23:49:37<17:36:17, 11.62s/it] 57%|█████▋    | 7298/12750 [23:49:48<17:35:46, 11.62s/it] 57%|█████▋    | 7299/12750 [23:50:00<17:35:14, 11.62s/it] 57%|█████▋    | 7300/12750 [23:50:12<17:34:58, 11.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120621.75lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104849.64lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7300
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7300/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7300/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7275] due to args.save_total_limit
 57%|█████▋    | 7301/12750 [23:50:24<17:42:51, 11.70s/it] 57%|█████▋    | 7302/12750 [23:50:35<17:40:20, 11.68s/it] 57%|█████▋    | 7303/12750 [23:50:47<17:38:38, 11.66s/it] 57%|█████▋    | 7304/12750 [23:50:59<17:38:21, 11.66s/it] 57%|█████▋    | 7305/12750 [23:51:18<21:06:31, 13.96s/it] 57%|█████▋    | 7306/12750 [23:51:29<20:01:53, 13.25s/it] 57%|█████▋    | 7307/12750 [23:51:41<19:17:46, 12.76s/it] 57%|█████▋    | 7308/12750 [23:51:53<18:47:27, 12.43s/it] 57%|█████▋    | 7309/12750 [23:52:04<18:26:00, 12.20s/it] 57%|█████▋    | 7310/12750 [23:52:16<18:10:31, 12.03s/it] 57%|█████▋    | 7311/12750 [23:52:28<17:59:46, 11.91s/it] 57%|█████▋    | 7312/12750 [23:52:39<17:50:49, 11.81s/it] 57%|█████▋    | 7313/12750 [23:52:51<17:44:22, 11.75s/it] 57%|█████▋    | 7314/12750 [23:53:02<17:42:15, 11.72s/it] 57%|█████▋    | 7315/12750 [23:53:14<17:39:40, 11.70s/it] 57%|█████▋    | 7316/12750 [23:53:26<17:36:52, 11.67s/it] 57%|█████▋    | 7317/12750 [23:53:37<17:35:55, 11.66s/it] 57%|█████▋    | 7318/12750 [23:53:49<17:34:22, 11.65s/it] 57%|█████▋    | 7319/12750 [23:54:01<17:34:09, 11.65s/it] 57%|█████▋    | 7320/12750 [23:54:12<17:34:03, 11.65s/it] 57%|█████▋    | 7321/12750 [23:54:24<17:32:43, 11.63s/it] 57%|█████▋    | 7322/12750 [23:54:35<17:31:47, 11.63s/it] 57%|█████▋    | 7323/12750 [23:54:47<17:31:44, 11.63s/it] 57%|█████▋    | 7324/12750 [23:54:59<17:31:34, 11.63s/it] 57%|█████▋    | 7325/12750 [23:55:10<17:31:28, 11.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120582.06lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104886.64lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7325
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7325/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7325/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7300] due to args.save_total_limit
 57%|█████▋    | 7326/12750 [23:55:22<17:39:24, 11.72s/it] 57%|█████▋    | 7327/12750 [23:55:34<17:36:28, 11.69s/it] 57%|█████▋    | 7328/12750 [23:55:45<17:32:29, 11.65s/it] 57%|█████▋    | 7329/12750 [23:55:57<17:32:11, 11.65s/it] 57%|█████▋    | 7330/12750 [23:56:09<17:30:27, 11.63s/it] 57%|█████▋    | 7331/12750 [23:56:20<17:29:35, 11.62s/it] 58%|█████▊    | 7332/12750 [23:56:32<17:28:13, 11.61s/it] 58%|█████▊    | 7333/12750 [23:56:43<17:27:56, 11.61s/it] 58%|█████▊    | 7334/12750 [23:56:55<17:26:53, 11.60s/it] 58%|█████▊    | 7335/12750 [23:57:07<17:27:13, 11.60s/it] 58%|█████▊    | 7336/12750 [23:57:18<17:25:37, 11.59s/it] 58%|█████▊    | 7337/12750 [23:57:39<21:27:43, 14.27s/it] 58%|█████▊    | 7338/12750 [23:57:50<20:14:13, 13.46s/it] 58%|█████▊    | 7339/12750 [23:58:02<19:23:58, 12.91s/it] 58%|█████▊    | 7340/12750 [23:58:13<18:46:03, 12.49s/it] 58%|█████▊    | 7341/12750 [23:58:25<18:20:55, 12.21s/it] 58%|█████▊    | 7342/12750 [23:58:37<18:03:24, 12.02s/it] 58%|█████▊    | 7343/12750 [23:58:48<17:51:11, 11.89s/it] 58%|█████▊    | 7344/12750 [23:59:00<17:43:11, 11.80s/it] 58%|█████▊    | 7345/12750 [23:59:11<17:39:08, 11.76s/it] 58%|█████▊    | 7346/12750 [23:59:23<17:35:06, 11.71s/it] 58%|█████▊    | 7347/12750 [23:59:35<17:32:44, 11.69s/it] 58%|█████▊    | 7348/12750 [23:59:46<17:30:39, 11.67s/it] 58%|█████▊    | 7349/12750 [23:59:58<17:28:52, 11.65s/it] 58%|█████▊    | 7350/12750 [24:00:10<17:26:51, 11.63s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120809.23lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 105137.58lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7350
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7350/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7350/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7325] due to args.save_total_limit
 58%|█████▊    | 7351/12750 [24:00:21<17:35:04, 11.73s/it] 58%|█████▊    | 7352/12750 [24:00:33<17:31:07, 11.68s/it] 58%|█████▊    | 7353/12750 [24:00:45<17:27:14, 11.64s/it] 58%|█████▊    | 7354/12750 [24:00:56<17:26:28, 11.64s/it] 58%|█████▊    | 7355/12750 [24:01:08<17:25:39, 11.63s/it] 58%|█████▊    | 7356/12750 [24:01:19<17:23:22, 11.61s/it] 58%|█████▊    | 7357/12750 [24:01:31<17:22:09, 11.59s/it] 58%|█████▊    | 7358/12750 [24:01:43<17:22:36, 11.60s/it] 58%|█████▊    | 7359/12750 [24:01:54<17:23:42, 11.62s/it] 58%|█████▊    | 7360/12750 [24:02:06<17:24:29, 11.63s/it] 58%|█████▊    | 7361/12750 [24:02:17<17:22:58, 11.61s/it] 58%|█████▊    | 7362/12750 [24:02:29<17:22:07, 11.60s/it] 58%|█████▊    | 7363/12750 [24:02:41<17:22:21, 11.61s/it] 58%|█████▊    | 7364/12750 [24:02:52<17:20:17, 11.59s/it] 58%|█████▊    | 7365/12750 [24:03:04<17:20:41, 11.60s/it] 58%|█████▊    | 7366/12750 [24:03:15<17:20:28, 11.60s/it] 58%|█████▊    | 7367/12750 [24:03:27<17:20:32, 11.60s/it] 58%|█████▊    | 7368/12750 [24:03:39<17:20:34, 11.60s/it] 58%|█████▊    | 7369/12750 [24:03:58<20:42:53, 13.86s/it] 58%|█████▊    | 7370/12750 [24:04:09<19:39:32, 13.15s/it] 58%|█████▊    | 7371/12750 [24:04:21<18:54:57, 12.66s/it] 58%|█████▊    | 7372/12750 [24:04:32<18:23:51, 12.32s/it] 58%|█████▊    | 7373/12750 [24:04:44<18:02:26, 12.08s/it] 58%|█████▊    | 7374/12750 [24:04:55<17:46:15, 11.90s/it] 58%|█████▊    | 7375/12750 [24:05:07<17:35:02, 11.78s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120641.02lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104893.34lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7375
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7375/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7375/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7350] due to args.save_total_limit
 58%|█████▊    | 7376/12750 [24:05:19<17:36:25, 11.79s/it] 58%|█████▊    | 7377/12750 [24:05:30<17:28:26, 11.71s/it] 58%|█████▊    | 7378/12750 [24:05:42<17:22:40, 11.65s/it] 58%|█████▊    | 7379/12750 [24:05:53<17:18:35, 11.60s/it] 58%|█████▊    | 7380/12750 [24:06:05<17:15:35, 11.57s/it] 58%|█████▊    | 7381/12750 [24:06:16<17:13:49, 11.55s/it] 58%|█████▊    | 7382/12750 [24:06:28<17:12:01, 11.54s/it] 58%|█████▊    | 7383/12750 [24:06:39<17:11:29, 11.53s/it] 58%|█████▊    | 7384/12750 [24:06:51<17:10:41, 11.52s/it] 58%|█████▊    | 7385/12750 [24:07:02<17:08:46, 11.51s/it] 58%|█████▊    | 7386/12750 [24:07:14<17:07:32, 11.49s/it] 58%|█████▊    | 7387/12750 [24:07:25<17:06:26, 11.48s/it] 58%|█████▊    | 7388/12750 [24:07:37<17:06:35, 11.49s/it] 58%|█████▊    | 7389/12750 [24:07:48<17:06:26, 11.49s/it] 58%|█████▊    | 7390/12750 [24:08:00<17:06:36, 11.49s/it] 58%|█████▊    | 7391/12750 [24:08:11<17:06:57, 11.50s/it] 58%|█████▊    | 7392/12750 [24:08:23<17:07:13, 11.50s/it] 58%|█████▊    | 7393/12750 [24:08:34<17:06:37, 11.50s/it] 58%|█████▊    | 7394/12750 [24:08:46<17:06:42, 11.50s/it] 58%|█████▊    | 7395/12750 [24:08:57<17:05:53, 11.49s/it] 58%|█████▊    | 7396/12750 [24:09:08<17:05:29, 11.49s/it] 58%|█████▊    | 7397/12750 [24:09:20<17:05:35, 11.50s/it] 58%|█████▊    | 7398/12750 [24:09:31<17:05:14, 11.49s/it] 58%|█████▊    | 7399/12750 [24:09:43<17:05:10, 11.50s/it] 58%|█████▊    | 7400/12750 [24:09:54<17:04:35, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120640.51lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104930.37lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7400
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7400/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7400/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-6550] due to args.save_total_limit
 58%|█████▊    | 7401/12750 [24:10:06<17:13:33, 11.59s/it] 58%|█████▊    | 7402/12750 [24:10:25<20:12:49, 13.61s/it] 58%|█████▊    | 7403/12750 [24:10:36<19:15:40, 12.97s/it] 58%|█████▊    | 7404/12750 [24:10:48<18:36:31, 12.53s/it] 58%|█████▊    | 7405/12750 [24:10:59<18:08:03, 12.21s/it] 58%|█████▊    | 7406/12750 [24:11:11<17:49:26, 12.01s/it] 58%|█████▊    | 7407/12750 [24:11:22<17:36:26, 11.86s/it] 58%|█████▊    | 7408/12750 [24:11:34<17:26:42, 11.76s/it] 58%|█████▊    | 7409/12750 [24:11:45<17:20:04, 11.68s/it] 58%|█████▊    | 7410/12750 [24:11:57<17:14:48, 11.63s/it] 58%|█████▊    | 7411/12750 [24:12:08<17:11:06, 11.59s/it] 58%|█████▊    | 7412/12750 [24:12:20<17:08:08, 11.56s/it] 58%|█████▊    | 7413/12750 [24:12:31<17:06:43, 11.54s/it] 58%|█████▊    | 7414/12750 [24:12:43<17:05:18, 11.53s/it] 58%|█████▊    | 7415/12750 [24:12:54<17:04:44, 11.52s/it] 58%|█████▊    | 7416/12750 [24:13:06<17:03:44, 11.52s/it] 58%|█████▊    | 7417/12750 [24:13:17<17:03:02, 11.51s/it] 58%|█████▊    | 7418/12750 [24:13:29<17:01:41, 11.50s/it] 58%|█████▊    | 7419/12750 [24:13:40<17:02:12, 11.50s/it] 58%|█████▊    | 7420/12750 [24:13:52<17:03:00, 11.52s/it] 58%|█████▊    | 7421/12750 [24:14:03<17:03:22, 11.52s/it] 58%|█████▊    | 7422/12750 [24:14:15<17:01:54, 11.51s/it] 58%|█████▊    | 7423/12750 [24:14:26<17:01:52, 11.51s/it] 58%|█████▊    | 7424/12750 [24:14:38<17:01:57, 11.51s/it] 58%|█████▊    | 7425/12750 [24:14:49<17:01:40, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120769.68lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 105088.11lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7425
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7425/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7425/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7375] due to args.save_total_limit
 58%|█████▊    | 7426/12750 [24:15:01<17:08:57, 11.60s/it] 58%|█████▊    | 7427/12750 [24:15:12<17:05:31, 11.56s/it] 58%|█████▊    | 7428/12750 [24:15:24<17:02:37, 11.53s/it] 58%|█████▊    | 7429/12750 [24:15:35<17:00:23, 11.51s/it] 58%|█████▊    | 7430/12750 [24:15:47<16:59:04, 11.49s/it] 58%|█████▊    | 7431/12750 [24:15:58<16:58:20, 11.49s/it] 58%|█████▊    | 7432/12750 [24:16:10<16:57:42, 11.48s/it] 58%|█████▊    | 7433/12750 [24:16:21<16:57:53, 11.49s/it] 58%|█████▊    | 7434/12750 [24:16:40<20:18:55, 13.76s/it] 58%|█████▊    | 7435/12750 [24:16:52<19:18:06, 13.07s/it] 58%|█████▊    | 7436/12750 [24:17:03<18:36:59, 12.61s/it] 58%|█████▊    | 7437/12750 [24:17:15<18:07:00, 12.28s/it] 58%|█████▊    | 7438/12750 [24:17:26<17:45:54, 12.04s/it] 58%|█████▊    | 7439/12750 [24:17:38<17:31:33, 11.88s/it] 58%|█████▊    | 7440/12750 [24:17:49<17:21:21, 11.77s/it] 58%|█████▊    | 7441/12750 [24:18:01<17:13:37, 11.68s/it] 58%|█████▊    | 7442/12750 [24:18:12<17:08:30, 11.63s/it] 58%|█████▊    | 7443/12750 [24:18:24<17:04:42, 11.59s/it] 58%|█████▊    | 7444/12750 [24:18:35<17:02:31, 11.56s/it] 58%|█████▊    | 7445/12750 [24:18:47<16:59:35, 11.53s/it] 58%|█████▊    | 7446/12750 [24:18:58<16:58:08, 11.52s/it] 58%|█████▊    | 7447/12750 [24:19:10<16:57:21, 11.51s/it] 58%|█████▊    | 7448/12750 [24:19:21<16:57:15, 11.51s/it] 58%|█████▊    | 7449/12750 [24:19:33<16:56:41, 11.51s/it] 58%|█████▊    | 7450/12750 [24:19:44<16:55:45, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120585.27lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104893.15lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7450
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7450/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7450/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7425] due to args.save_total_limit
 58%|█████▊    | 7451/12750 [24:19:56<17:09:57, 11.66s/it] 58%|█████▊    | 7452/12750 [24:20:08<17:04:19, 11.60s/it] 58%|█████▊    | 7453/12750 [24:20:19<17:01:20, 11.57s/it] 58%|█████▊    | 7454/12750 [24:20:31<16:59:15, 11.55s/it] 58%|█████▊    | 7455/12750 [24:20:42<16:57:02, 11.52s/it] 58%|█████▊    | 7456/12750 [24:20:54<16:56:54, 11.53s/it] 58%|█████▊    | 7457/12750 [24:21:05<16:56:28, 11.52s/it] 58%|█████▊    | 7458/12750 [24:21:17<16:54:56, 11.51s/it] 59%|█████▊    | 7459/12750 [24:21:28<16:53:29, 11.49s/it] 59%|█████▊    | 7460/12750 [24:21:40<16:52:52, 11.49s/it] 59%|█████▊    | 7461/12750 [24:21:51<16:52:02, 11.48s/it] 59%|█████▊    | 7462/12750 [24:22:03<16:50:21, 11.46s/it] 59%|█████▊    | 7463/12750 [24:22:14<16:49:37, 11.46s/it] 59%|█████▊    | 7464/12750 [24:22:25<16:49:54, 11.46s/it] 59%|█████▊    | 7465/12750 [24:22:37<16:50:37, 11.47s/it] 59%|█████▊    | 7466/12750 [24:22:56<20:12:41, 13.77s/it] 59%|█████▊    | 7467/12750 [24:23:08<19:11:21, 13.08s/it] 59%|█████▊    | 7468/12750 [24:23:19<18:28:50, 12.60s/it] 59%|█████▊    | 7469/12750 [24:23:31<18:00:46, 12.28s/it] 59%|█████▊    | 7470/12750 [24:23:42<17:40:15, 12.05s/it] 59%|█████▊    | 7471/12750 [24:23:54<17:24:25, 11.87s/it] 59%|█████▊    | 7472/12750 [24:24:05<17:14:04, 11.76s/it] 59%|█████▊    | 7473/12750 [24:24:17<17:06:22, 11.67s/it] 59%|█████▊    | 7474/12750 [24:24:28<17:01:26, 11.62s/it] 59%|█████▊    | 7475/12750 [24:24:39<16:58:02, 11.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120587.71lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104564.43lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7475
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7475/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7475/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7450] due to args.save_total_limit
 59%|█████▊    | 7476/12750 [24:24:51<17:04:39, 11.66s/it] 59%|█████▊    | 7477/12750 [24:25:03<16:59:33, 11.60s/it] 59%|█████▊    | 7478/12750 [24:25:14<16:56:41, 11.57s/it] 59%|█████▊    | 7479/12750 [24:25:26<16:53:30, 11.54s/it] 59%|█████▊    | 7480/12750 [24:25:37<16:52:07, 11.52s/it] 59%|█████▊    | 7481/12750 [24:25:49<16:50:49, 11.51s/it] 59%|█████▊    | 7482/12750 [24:26:00<16:50:44, 11.51s/it] 59%|█████▊    | 7483/12750 [24:26:12<16:50:26, 11.51s/it] 59%|█████▊    | 7484/12750 [24:26:23<16:49:44, 11.50s/it] 59%|█████▊    | 7485/12750 [24:26:35<16:49:46, 11.51s/it] 59%|█████▊    | 7486/12750 [24:26:46<16:49:17, 11.50s/it] 59%|█████▊    | 7487/12750 [24:26:58<16:48:20, 11.50s/it] 59%|█████▊    | 7488/12750 [24:27:09<16:48:53, 11.50s/it] 59%|█████▊    | 7489/12750 [24:27:21<16:48:13, 11.50s/it] 59%|█████▊    | 7490/12750 [24:27:32<16:48:17, 11.50s/it] 59%|█████▉    | 7491/12750 [24:27:44<16:47:39, 11.50s/it] 59%|█████▉    | 7492/12750 [24:27:55<16:47:28, 11.50s/it] 59%|█████▉    | 7493/12750 [24:28:07<16:46:37, 11.49s/it] 59%|█████▉    | 7494/12750 [24:28:18<16:46:37, 11.49s/it] 59%|█████▉    | 7495/12750 [24:28:30<16:46:19, 11.49s/it] 59%|█████▉    | 7496/12750 [24:28:41<16:45:59, 11.49s/it] 59%|█████▉    | 7497/12750 [24:28:53<16:46:29, 11.50s/it] 59%|█████▉    | 7498/12750 [24:29:12<20:07:40, 13.80s/it] 59%|█████▉    | 7499/12750 [24:29:23<19:06:55, 13.11s/it] 59%|█████▉    | 7500/12750 [24:29:35<18:24:39, 12.62s/it]                                                           59%|█████▉    | 7500/12750 [24:29:35<18:24:39, 12.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120776.89lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104970.93lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7500
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7500/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7500/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7475] due to args.save_total_limit
 59%|█████▉    | 7501/12750 [24:29:47<18:06:37, 12.42s/it] 59%|█████▉    | 7502/12750 [24:29:58<17:42:36, 12.15s/it] 59%|█████▉    | 7503/12750 [24:30:10<17:24:47, 11.95s/it] 59%|█████▉    | 7504/12750 [24:30:21<17:12:54, 11.81s/it] 59%|█████▉    | 7505/12750 [24:30:33<17:04:30, 11.72s/it] 59%|█████▉    | 7506/12750 [24:30:44<16:58:44, 11.66s/it] 59%|█████▉    | 7507/12750 [24:30:56<16:54:08, 11.61s/it] 59%|█████▉    | 7508/12750 [24:31:07<16:51:08, 11.57s/it] 59%|█████▉    | 7509/12750 [24:31:19<16:49:41, 11.56s/it] 59%|█████▉    | 7510/12750 [24:31:30<16:47:37, 11.54s/it] 59%|█████▉    | 7511/12750 [24:31:42<16:45:50, 11.52s/it] 59%|█████▉    | 7512/12750 [24:31:53<16:45:26, 11.52s/it] 59%|█████▉    | 7513/12750 [24:32:05<16:44:31, 11.51s/it] 59%|█████▉    | 7514/12750 [24:32:16<16:45:19, 11.52s/it] 59%|█████▉    | 7515/12750 [24:32:28<16:44:13, 11.51s/it] 59%|█████▉    | 7516/12750 [24:32:39<16:43:42, 11.51s/it] 59%|█████▉    | 7517/12750 [24:32:51<16:42:33, 11.50s/it] 59%|█████▉    | 7518/12750 [24:33:02<16:42:07, 11.49s/it] 59%|█████▉    | 7519/12750 [24:33:14<16:42:06, 11.49s/it] 59%|█████▉    | 7520/12750 [24:33:25<16:42:53, 11.51s/it] 59%|█████▉    | 7521/12750 [24:33:37<16:44:13, 11.52s/it] 59%|█████▉    | 7522/12750 [24:33:48<16:43:39, 11.52s/it] 59%|█████▉    | 7523/12750 [24:34:00<16:43:09, 11.52s/it] 59%|█████▉    | 7524/12750 [24:34:11<16:41:11, 11.49s/it] 59%|█████▉    | 7525/12750 [24:34:23<16:41:11, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120540.09lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104756.34lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7525
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7525/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7525/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7500] due to args.save_total_limit
 59%|█████▉    | 7526/12750 [24:34:35<16:49:20, 11.59s/it] 59%|█████▉    | 7527/12750 [24:34:46<16:46:58, 11.57s/it] 59%|█████▉    | 7528/12750 [24:34:58<16:44:43, 11.54s/it] 59%|█████▉    | 7529/12750 [24:35:09<16:44:06, 11.54s/it] 59%|█████▉    | 7530/12750 [24:35:28<20:00:13, 13.80s/it] 59%|█████▉    | 7531/12750 [24:35:40<19:00:04, 13.11s/it] 59%|█████▉    | 7532/12750 [24:35:51<18:18:12, 12.63s/it] 59%|█████▉    | 7533/12750 [24:36:03<17:48:18, 12.29s/it] 59%|█████▉    | 7534/12750 [24:36:14<17:27:13, 12.05s/it] 59%|█████▉    | 7535/12750 [24:36:26<17:12:37, 11.88s/it] 59%|█████▉    | 7536/12750 [24:36:37<17:02:22, 11.77s/it] 59%|█████▉    | 7537/12750 [24:36:49<16:54:43, 11.68s/it] 59%|█████▉    | 7538/12750 [24:37:00<16:49:14, 11.62s/it] 59%|█████▉    | 7539/12750 [24:37:12<16:46:30, 11.59s/it] 59%|█████▉    | 7540/12750 [24:37:23<16:44:25, 11.57s/it] 59%|█████▉    | 7541/12750 [24:37:35<16:41:25, 11.53s/it] 59%|█████▉    | 7542/12750 [24:37:46<16:40:23, 11.53s/it] 59%|█████▉    | 7543/12750 [24:37:58<16:39:13, 11.51s/it] 59%|█████▉    | 7544/12750 [24:38:09<16:38:19, 11.51s/it] 59%|█████▉    | 7545/12750 [24:38:21<16:37:41, 11.50s/it] 59%|█████▉    | 7546/12750 [24:38:32<16:38:18, 11.51s/it] 59%|█████▉    | 7547/12750 [24:38:44<16:37:44, 11.51s/it] 59%|█████▉    | 7548/12750 [24:38:55<16:37:00, 11.50s/it] 59%|█████▉    | 7549/12750 [24:39:07<16:35:37, 11.49s/it] 59%|█████▉    | 7550/12750 [24:39:18<16:36:10, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120604.53lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104886.06lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7550
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7550/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7550/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7525] due to args.save_total_limit
 59%|█████▉    | 7551/12750 [24:39:30<16:43:52, 11.59s/it] 59%|█████▉    | 7552/12750 [24:39:41<16:41:44, 11.56s/it] 59%|█████▉    | 7553/12750 [24:39:53<16:40:02, 11.55s/it] 59%|█████▉    | 7554/12750 [24:40:04<16:38:27, 11.53s/it] 59%|█████▉    | 7555/12750 [24:40:16<16:37:26, 11.52s/it] 59%|█████▉    | 7556/12750 [24:40:27<16:36:41, 11.51s/it] 59%|█████▉    | 7557/12750 [24:40:39<16:35:24, 11.50s/it] 59%|█████▉    | 7558/12750 [24:40:50<16:35:23, 11.50s/it] 59%|█████▉    | 7559/12750 [24:41:02<16:35:18, 11.50s/it] 59%|█████▉    | 7560/12750 [24:41:13<16:35:01, 11.50s/it] 59%|█████▉    | 7561/12750 [24:41:25<16:33:56, 11.49s/it] 59%|█████▉    | 7562/12750 [24:41:44<19:54:11, 13.81s/it] 59%|█████▉    | 7563/12750 [24:41:56<18:53:56, 13.12s/it] 59%|█████▉    | 7564/12750 [24:42:07<18:12:21, 12.64s/it] 59%|█████▉    | 7565/12750 [24:42:19<17:42:42, 12.30s/it] 59%|█████▉    | 7566/12750 [24:42:30<17:21:59, 12.06s/it] 59%|█████▉    | 7567/12750 [24:42:42<17:07:34, 11.90s/it] 59%|█████▉    | 7568/12750 [24:42:53<16:57:08, 11.78s/it] 59%|█████▉    | 7569/12750 [24:43:05<16:51:25, 11.71s/it] 59%|█████▉    | 7570/12750 [24:43:16<16:46:11, 11.65s/it] 59%|█████▉    | 7571/12750 [24:43:28<16:43:22, 11.62s/it] 59%|█████▉    | 7572/12750 [24:43:39<16:39:20, 11.58s/it] 59%|█████▉    | 7573/12750 [24:43:51<16:36:29, 11.55s/it] 59%|█████▉    | 7574/12750 [24:44:02<16:36:27, 11.55s/it] 59%|█████▉    | 7575/12750 [24:44:14<16:35:01, 11.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120680.75lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104948.56lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7575
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7575/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7575/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7550] due to args.save_total_limit
 59%|█████▉    | 7576/12750 [24:44:26<16:42:00, 11.62s/it] 59%|█████▉    | 7577/12750 [24:44:37<16:38:43, 11.58s/it] 59%|█████▉    | 7578/12750 [24:44:49<16:35:49, 11.55s/it] 59%|█████▉    | 7579/12750 [24:45:00<16:33:20, 11.53s/it] 59%|█████▉    | 7580/12750 [24:45:11<16:32:03, 11.51s/it] 59%|█████▉    | 7581/12750 [24:45:23<16:30:58, 11.50s/it] 59%|█████▉    | 7582/12750 [24:45:34<16:30:27, 11.50s/it] 59%|█████▉    | 7583/12750 [24:45:46<16:29:36, 11.49s/it] 59%|█████▉    | 7584/12750 [24:45:57<16:29:23, 11.49s/it] 59%|█████▉    | 7585/12750 [24:46:09<16:29:13, 11.49s/it] 59%|█████▉    | 7586/12750 [24:46:20<16:28:06, 11.48s/it] 60%|█████▉    | 7587/12750 [24:46:32<16:27:16, 11.47s/it] 60%|█████▉    | 7588/12750 [24:46:43<16:26:58, 11.47s/it] 60%|█████▉    | 7589/12750 [24:46:55<16:26:52, 11.47s/it] 60%|█████▉    | 7590/12750 [24:47:06<16:27:11, 11.48s/it] 60%|█████▉    | 7591/12750 [24:47:18<16:26:43, 11.48s/it] 60%|█████▉    | 7592/12750 [24:47:29<16:25:55, 11.47s/it] 60%|█████▉    | 7593/12750 [24:47:41<16:25:55, 11.47s/it] 60%|█████▉    | 7594/12750 [24:47:52<16:25:58, 11.47s/it] 60%|█████▉    | 7595/12750 [24:48:10<19:19:02, 13.49s/it] 60%|█████▉    | 7596/12750 [24:48:22<18:27:16, 12.89s/it] 60%|█████▉    | 7597/12750 [24:48:33<17:50:47, 12.47s/it] 60%|█████▉    | 7598/12750 [24:48:45<17:25:38, 12.18s/it] 60%|█████▉    | 7599/12750 [24:48:56<17:07:43, 11.97s/it] 60%|█████▉    | 7600/12750 [24:49:08<16:55:33, 11.83s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120708.02lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 105037.53lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7600
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7600/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7600/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7400] due to args.save_total_limit
 60%|█████▉    | 7601/12750 [24:49:20<16:55:47, 11.84s/it] 60%|█████▉    | 7602/12750 [24:49:31<16:46:11, 11.73s/it] 60%|█████▉    | 7603/12750 [24:49:43<16:39:54, 11.66s/it] 60%|█████▉    | 7604/12750 [24:49:54<16:35:24, 11.61s/it] 60%|█████▉    | 7605/12750 [24:50:06<16:33:00, 11.58s/it] 60%|█████▉    | 7606/12750 [24:50:17<16:30:35, 11.55s/it] 60%|█████▉    | 7607/12750 [24:50:29<16:29:19, 11.54s/it] 60%|█████▉    | 7608/12750 [24:50:40<16:27:45, 11.53s/it] 60%|█████▉    | 7609/12750 [24:50:52<16:27:02, 11.52s/it] 60%|█████▉    | 7610/12750 [24:51:03<16:26:00, 11.51s/it] 60%|█████▉    | 7611/12750 [24:51:15<16:26:06, 11.51s/it] 60%|█████▉    | 7612/12750 [24:51:26<16:25:26, 11.51s/it] 60%|█████▉    | 7613/12750 [24:51:38<16:25:08, 11.51s/it] 60%|█████▉    | 7614/12750 [24:51:49<16:25:12, 11.51s/it] 60%|█████▉    | 7615/12750 [24:52:01<16:24:46, 11.51s/it] 60%|█████▉    | 7616/12750 [24:52:12<16:24:49, 11.51s/it] 60%|█████▉    | 7617/12750 [24:52:24<16:24:53, 11.51s/it] 60%|█████▉    | 7618/12750 [24:52:35<16:24:48, 11.51s/it] 60%|█████▉    | 7619/12750 [24:52:47<16:24:51, 11.52s/it] 60%|█████▉    | 7620/12750 [24:52:58<16:24:35, 11.52s/it] 60%|█████▉    | 7621/12750 [24:53:10<16:23:48, 11.51s/it] 60%|█████▉    | 7622/12750 [24:53:21<16:23:50, 11.51s/it] 60%|█████▉    | 7623/12750 [24:53:33<16:22:53, 11.50s/it] 60%|█████▉    | 7624/12750 [24:53:44<16:22:37, 11.50s/it] 60%|█████▉    | 7625/12750 [24:53:56<16:23:32, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120606.59lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104883.14lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7625
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7625/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7625/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7575] due to args.save_total_limit
 60%|█████▉    | 7626/12750 [24:54:08<16:30:41, 11.60s/it] 60%|█████▉    | 7627/12750 [24:54:27<19:43:59, 13.87s/it] 60%|█████▉    | 7628/12750 [24:54:38<18:43:57, 13.17s/it] 60%|█████▉    | 7629/12750 [24:54:50<18:01:18, 12.67s/it] 60%|█████▉    | 7630/12750 [24:55:01<17:30:57, 12.32s/it] 60%|█████▉    | 7631/12750 [24:55:13<17:10:08, 12.07s/it] 60%|█████▉    | 7632/12750 [24:55:24<16:55:51, 11.91s/it] 60%|█████▉    | 7633/12750 [24:55:36<16:46:59, 11.81s/it] 60%|█████▉    | 7634/12750 [24:55:47<16:39:31, 11.72s/it] 60%|█████▉    | 7635/12750 [24:55:59<16:33:17, 11.65s/it] 60%|█████▉    | 7636/12750 [24:56:10<16:29:57, 11.61s/it] 60%|█████▉    | 7637/12750 [24:56:22<16:27:49, 11.59s/it] 60%|█████▉    | 7638/12750 [24:56:34<16:27:12, 11.59s/it] 60%|█████▉    | 7639/12750 [24:56:45<16:25:34, 11.57s/it] 60%|█████▉    | 7640/12750 [24:56:57<16:24:21, 11.56s/it] 60%|█████▉    | 7641/12750 [24:57:08<16:22:38, 11.54s/it] 60%|█████▉    | 7642/12750 [24:57:20<16:22:44, 11.54s/it] 60%|█████▉    | 7643/12750 [24:57:31<16:22:25, 11.54s/it] 60%|█████▉    | 7644/12750 [24:57:43<16:20:53, 11.53s/it] 60%|█████▉    | 7645/12750 [24:57:54<16:20:52, 11.53s/it] 60%|█████▉    | 7646/12750 [24:58:06<16:20:23, 11.52s/it] 60%|█████▉    | 7647/12750 [24:58:17<16:19:21, 11.52s/it] 60%|█████▉    | 7648/12750 [24:58:29<16:19:52, 11.52s/it] 60%|█████▉    | 7649/12750 [24:58:36<14:25:50, 10.18s/it] 60%|██████    | 7650/12750 [24:58:37<10:26:07,  7.37s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120388.37lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104703.84lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7650
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7650/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7650/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7625] due to args.save_total_limit
 60%|██████    | 7651/12750 [24:59:00<17:21:47, 12.26s/it] 60%|██████    | 7652/12750 [24:59:12<17:03:24, 12.04s/it] 60%|██████    | 7653/12750 [24:59:23<16:49:25, 11.88s/it] 60%|██████    | 7654/12750 [24:59:35<16:39:15, 11.77s/it] 60%|██████    | 7655/12750 [24:59:46<16:32:36, 11.69s/it] 60%|██████    | 7656/12750 [24:59:58<16:27:16, 11.63s/it] 60%|██████    | 7657/12750 [25:00:09<16:23:38, 11.59s/it] 60%|██████    | 7658/12750 [25:00:21<16:21:44, 11.57s/it] 60%|██████    | 7659/12750 [25:00:40<19:35:19, 13.85s/it] 60%|██████    | 7660/12750 [25:00:52<18:36:03, 13.16s/it] 60%|██████    | 7661/12750 [25:01:03<17:53:34, 12.66s/it] 60%|██████    | 7662/12750 [25:01:15<17:24:08, 12.31s/it] 60%|██████    | 7663/12750 [25:01:26<17:03:45, 12.07s/it] 60%|██████    | 7664/12750 [25:01:38<16:49:15, 11.91s/it] 60%|██████    | 7665/12750 [25:01:49<16:37:59, 11.78s/it] 60%|██████    | 7666/12750 [25:02:01<16:30:09, 11.69s/it] 60%|██████    | 7667/12750 [25:02:12<16:25:19, 11.63s/it] 60%|██████    | 7668/12750 [25:02:24<16:22:00, 11.59s/it] 60%|██████    | 7669/12750 [25:02:35<16:19:10, 11.56s/it] 60%|██████    | 7670/12750 [25:02:47<16:18:00, 11.55s/it] 60%|██████    | 7671/12750 [25:02:58<16:16:48, 11.54s/it] 60%|██████    | 7672/12750 [25:03:10<16:15:08, 11.52s/it] 60%|██████    | 7673/12750 [25:03:21<16:14:04, 11.51s/it] 60%|██████    | 7674/12750 [25:03:33<16:13:33, 11.51s/it] 60%|██████    | 7675/12750 [25:03:44<16:12:52, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120498.15lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104828.19lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7675
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7675/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7675/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7650] due to args.save_total_limit
 60%|██████    | 7676/12750 [25:03:56<16:21:02, 11.60s/it] 60%|██████    | 7677/12750 [25:04:07<16:17:53, 11.57s/it] 60%|██████    | 7678/12750 [25:04:19<16:15:48, 11.54s/it] 60%|██████    | 7679/12750 [25:04:30<16:14:02, 11.52s/it] 60%|██████    | 7680/12750 [25:04:42<16:13:01, 11.52s/it] 60%|██████    | 7681/12750 [25:04:53<16:12:49, 11.52s/it] 60%|██████    | 7682/12750 [25:05:05<16:12:09, 11.51s/it] 60%|██████    | 7683/12750 [25:05:16<16:11:39, 11.51s/it] 60%|██████    | 7684/12750 [25:05:28<16:10:58, 11.50s/it] 60%|██████    | 7685/12750 [25:05:39<16:10:24, 11.50s/it] 60%|██████    | 7686/12750 [25:05:51<16:09:09, 11.48s/it] 60%|██████    | 7687/12750 [25:06:02<16:09:21, 11.49s/it] 60%|██████    | 7688/12750 [25:06:14<16:08:36, 11.48s/it] 60%|██████    | 7689/12750 [25:06:25<16:09:15, 11.49s/it] 60%|██████    | 7690/12750 [25:06:37<16:09:44, 11.50s/it] 60%|██████    | 7691/12750 [25:06:56<19:27:28, 13.85s/it] 60%|██████    | 7692/12750 [25:07:08<18:27:34, 13.14s/it] 60%|██████    | 7693/12750 [25:07:19<17:46:30, 12.65s/it] 60%|██████    | 7694/12750 [25:07:31<17:16:58, 12.31s/it] 60%|██████    | 7695/12750 [25:07:42<16:56:53, 12.07s/it] 60%|██████    | 7696/12750 [25:07:54<16:42:49, 11.91s/it] 60%|██████    | 7697/12750 [25:08:05<16:31:35, 11.77s/it] 60%|██████    | 7698/12750 [25:08:17<16:24:00, 11.69s/it] 60%|██████    | 7699/12750 [25:08:28<16:19:30, 11.64s/it] 60%|██████    | 7700/12750 [25:08:40<16:15:52, 11.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120614.94lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104912.10lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7700
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7700/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7700/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7675] due to args.save_total_limit
 60%|██████    | 7701/12750 [25:08:51<16:21:04, 11.66s/it] 60%|██████    | 7702/12750 [25:09:03<16:17:13, 11.62s/it] 60%|██████    | 7703/12750 [25:09:14<16:13:58, 11.58s/it] 60%|██████    | 7704/12750 [25:09:26<16:12:03, 11.56s/it] 60%|██████    | 7705/12750 [25:09:37<16:10:30, 11.54s/it] 60%|██████    | 7706/12750 [25:09:49<16:08:46, 11.52s/it] 60%|██████    | 7707/12750 [25:10:00<16:07:51, 11.52s/it] 60%|██████    | 7708/12750 [25:10:12<16:06:48, 11.51s/it] 60%|██████    | 7709/12750 [25:10:23<16:06:54, 11.51s/it] 60%|██████    | 7710/12750 [25:10:35<16:06:13, 11.50s/it] 60%|██████    | 7711/12750 [25:10:46<16:06:15, 11.51s/it] 60%|██████    | 7712/12750 [25:10:58<16:06:09, 11.51s/it] 60%|██████    | 7713/12750 [25:11:09<16:06:02, 11.51s/it] 61%|██████    | 7714/12750 [25:11:21<16:05:14, 11.50s/it] 61%|██████    | 7715/12750 [25:11:32<16:04:56, 11.50s/it] 61%|██████    | 7716/12750 [25:11:44<16:04:52, 11.50s/it] 61%|██████    | 7717/12750 [25:11:55<16:04:29, 11.50s/it] 61%|██████    | 7718/12750 [25:12:07<16:04:39, 11.50s/it] 61%|██████    | 7719/12750 [25:12:18<16:04:12, 11.50s/it] 61%|██████    | 7720/12750 [25:12:30<16:03:41, 11.50s/it] 61%|██████    | 7721/12750 [25:12:41<16:03:38, 11.50s/it] 61%|██████    | 7722/12750 [25:12:53<16:02:53, 11.49s/it] 61%|██████    | 7723/12750 [25:13:04<16:02:57, 11.49s/it] 61%|██████    | 7724/12750 [25:13:24<19:18:41, 13.83s/it] 61%|██████    | 7725/12750 [25:13:35<18:19:58, 13.13s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120563.32lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104814.51lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7725
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7725/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7725/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7700] due to args.save_total_limit
 61%|██████    | 7726/12750 [25:13:47<17:46:13, 12.73s/it] 61%|██████    | 7727/12750 [25:13:58<17:14:39, 12.36s/it] 61%|██████    | 7728/12750 [25:14:10<16:51:51, 12.09s/it] 61%|██████    | 7729/12750 [25:14:21<16:36:08, 11.90s/it] 61%|██████    | 7730/12750 [25:14:33<16:25:12, 11.78s/it] 61%|██████    | 7731/12750 [25:14:44<16:17:58, 11.69s/it] 61%|██████    | 7732/12750 [25:14:56<16:12:37, 11.63s/it] 61%|██████    | 7733/12750 [25:15:07<16:08:53, 11.59s/it] 61%|██████    | 7734/12750 [25:15:19<16:06:31, 11.56s/it] 61%|██████    | 7735/12750 [25:15:30<16:04:13, 11.54s/it] 61%|██████    | 7736/12750 [25:15:42<16:02:52, 11.52s/it] 61%|██████    | 7737/12750 [25:15:53<16:01:50, 11.51s/it] 61%|██████    | 7738/12750 [25:16:05<16:01:10, 11.51s/it] 61%|██████    | 7739/12750 [25:16:16<16:00:35, 11.50s/it] 61%|██████    | 7740/12750 [25:16:28<15:58:59, 11.48s/it] 61%|██████    | 7741/12750 [25:16:39<15:58:45, 11.48s/it] 61%|██████    | 7742/12750 [25:16:51<15:58:49, 11.49s/it] 61%|██████    | 7743/12750 [25:17:02<15:58:39, 11.49s/it] 61%|██████    | 7744/12750 [25:17:14<15:58:41, 11.49s/it] 61%|██████    | 7745/12750 [25:17:25<15:58:52, 11.49s/it] 61%|██████    | 7746/12750 [25:17:37<15:58:41, 11.50s/it] 61%|██████    | 7747/12750 [25:17:48<15:58:49, 11.50s/it] 61%|██████    | 7748/12750 [25:18:00<15:57:50, 11.49s/it] 61%|██████    | 7749/12750 [25:18:11<15:57:24, 11.49s/it] 61%|██████    | 7750/12750 [25:18:23<15:56:58, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120553.56lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104851.77lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7750
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7750/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7750/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7725] due to args.save_total_limit
 61%|██████    | 7751/12750 [25:18:34<16:05:22, 11.59s/it] 61%|██████    | 7752/12750 [25:18:46<16:02:40, 11.56s/it] 61%|██████    | 7753/12750 [25:18:57<16:00:40, 11.54s/it] 61%|██████    | 7754/12750 [25:19:09<15:58:55, 11.52s/it] 61%|██████    | 7755/12750 [25:19:20<15:58:02, 11.51s/it] 61%|██████    | 7756/12750 [25:19:39<19:00:30, 13.70s/it] 61%|██████    | 7757/12750 [25:19:51<18:05:32, 13.04s/it] 61%|██████    | 7758/12750 [25:20:02<17:26:12, 12.57s/it] 61%|██████    | 7759/12750 [25:20:14<16:59:10, 12.25s/it] 61%|██████    | 7760/12750 [25:20:25<16:40:05, 12.03s/it] 61%|██████    | 7761/12750 [25:20:37<16:26:01, 11.86s/it] 61%|██████    | 7762/12750 [25:20:48<16:16:40, 11.75s/it] 61%|██████    | 7763/12750 [25:21:00<16:09:32, 11.66s/it] 61%|██████    | 7764/12750 [25:21:11<16:05:12, 11.62s/it] 61%|██████    | 7765/12750 [25:21:23<16:01:55, 11.58s/it] 61%|██████    | 7766/12750 [25:21:34<15:59:38, 11.55s/it] 61%|██████    | 7767/12750 [25:21:46<15:57:59, 11.54s/it] 61%|██████    | 7768/12750 [25:21:57<15:56:52, 11.52s/it] 61%|██████    | 7769/12750 [25:22:08<15:55:14, 11.51s/it] 61%|██████    | 7770/12750 [25:22:20<15:54:07, 11.50s/it] 61%|██████    | 7771/12750 [25:22:31<15:54:19, 11.50s/it] 61%|██████    | 7772/12750 [25:22:43<15:53:56, 11.50s/it] 61%|██████    | 7773/12750 [25:22:54<15:52:35, 11.48s/it] 61%|██████    | 7774/12750 [25:23:06<15:51:45, 11.48s/it] 61%|██████    | 7775/12750 [25:23:17<15:51:31, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120685.25lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104979.10lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7775
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7775/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7775/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7750] due to args.save_total_limit
 61%|██████    | 7776/12750 [25:23:29<15:58:54, 11.57s/it] 61%|██████    | 7777/12750 [25:23:41<15:56:45, 11.54s/it] 61%|██████    | 7778/12750 [25:23:52<15:55:30, 11.53s/it] 61%|██████    | 7779/12750 [25:24:04<15:53:10, 11.50s/it] 61%|██████    | 7780/12750 [25:24:15<15:52:14, 11.50s/it] 61%|██████    | 7781/12750 [25:24:27<15:51:48, 11.49s/it] 61%|██████    | 7782/12750 [25:24:38<15:50:50, 11.48s/it] 61%|██████    | 7783/12750 [25:24:49<15:50:22, 11.48s/it] 61%|██████    | 7784/12750 [25:25:01<15:50:13, 11.48s/it] 61%|██████    | 7785/12750 [25:25:12<15:50:27, 11.49s/it] 61%|██████    | 7786/12750 [25:25:24<15:49:48, 11.48s/it] 61%|██████    | 7787/12750 [25:25:35<15:49:51, 11.48s/it] 61%|██████    | 7788/12750 [25:25:55<19:11:24, 13.92s/it] 61%|██████    | 7789/12750 [25:26:07<18:10:51, 13.19s/it] 61%|██████    | 7790/12750 [25:26:18<17:28:54, 12.69s/it] 61%|██████    | 7791/12750 [25:26:30<16:59:32, 12.34s/it] 61%|██████    | 7792/12750 [25:26:41<16:38:26, 12.08s/it] 61%|██████    | 7793/12750 [25:26:53<16:23:51, 11.91s/it] 61%|██████    | 7794/12750 [25:27:04<16:13:00, 11.78s/it] 61%|██████    | 7795/12750 [25:27:15<16:05:37, 11.69s/it] 61%|██████    | 7796/12750 [25:27:27<16:00:27, 11.63s/it] 61%|██████    | 7797/12750 [25:27:38<15:56:57, 11.59s/it] 61%|██████    | 7798/12750 [25:27:50<15:54:27, 11.56s/it] 61%|██████    | 7799/12750 [25:28:01<15:52:37, 11.54s/it] 61%|██████    | 7800/12750 [25:28:13<15:51:00, 11.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120606.84lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104898.39lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7800
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7800/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7800/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7775] due to args.save_total_limit
 61%|██████    | 7801/12750 [25:28:25<15:57:12, 11.60s/it] 61%|██████    | 7802/12750 [25:28:36<15:53:27, 11.56s/it] 61%|██████    | 7803/12750 [25:28:48<15:51:15, 11.54s/it] 61%|██████    | 7804/12750 [25:28:59<15:49:17, 11.52s/it] 61%|██████    | 7805/12750 [25:29:11<15:48:00, 11.50s/it] 61%|██████    | 7806/12750 [25:29:22<15:48:18, 11.51s/it] 61%|██████    | 7807/12750 [25:29:34<15:48:05, 11.51s/it] 61%|██████    | 7808/12750 [25:29:45<15:47:25, 11.50s/it] 61%|██████    | 7809/12750 [25:29:57<15:46:55, 11.50s/it] 61%|██████▏   | 7810/12750 [25:30:08<15:46:58, 11.50s/it] 61%|██████▏   | 7811/12750 [25:30:20<15:46:19, 11.50s/it] 61%|██████▏   | 7812/12750 [25:30:31<15:46:14, 11.50s/it] 61%|██████▏   | 7813/12750 [25:30:43<15:45:46, 11.49s/it] 61%|██████▏   | 7814/12750 [25:30:54<15:45:35, 11.49s/it] 61%|██████▏   | 7815/12750 [25:31:06<15:45:37, 11.50s/it] 61%|██████▏   | 7816/12750 [25:31:17<15:45:27, 11.50s/it] 61%|██████▏   | 7817/12750 [25:31:29<15:45:30, 11.50s/it] 61%|██████▏   | 7818/12750 [25:31:40<15:45:34, 11.50s/it] 61%|██████▏   | 7819/12750 [25:31:52<15:45:26, 11.50s/it] 61%|██████▏   | 7820/12750 [25:32:13<19:51:25, 14.50s/it] 61%|██████▏   | 7821/12750 [25:32:25<18:36:51, 13.60s/it] 61%|██████▏   | 7822/12750 [25:32:36<17:43:44, 12.95s/it] 61%|██████▏   | 7823/12750 [25:32:48<17:07:31, 12.51s/it] 61%|██████▏   | 7824/12750 [25:32:59<16:41:59, 12.20s/it] 61%|██████▏   | 7825/12750 [25:33:11<16:24:03, 11.99s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120681.52lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 105025.45lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7825
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7825/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7825/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7800] due to args.save_total_limit
 61%|██████▏   | 7826/12750 [25:33:22<16:18:14, 11.92s/it] 61%|██████▏   | 7827/12750 [25:33:34<16:07:19, 11.79s/it] 61%|██████▏   | 7828/12750 [25:33:45<15:58:59, 11.69s/it] 61%|██████▏   | 7829/12750 [25:33:57<15:53:32, 11.63s/it] 61%|██████▏   | 7830/12750 [25:34:08<15:49:49, 11.58s/it] 61%|██████▏   | 7831/12750 [25:34:20<15:47:08, 11.55s/it] 61%|██████▏   | 7832/12750 [25:34:31<15:45:33, 11.54s/it] 61%|██████▏   | 7833/12750 [25:34:43<15:43:36, 11.51s/it] 61%|██████▏   | 7834/12750 [25:34:54<15:43:09, 11.51s/it] 61%|██████▏   | 7835/12750 [25:35:06<15:41:48, 11.50s/it] 61%|██████▏   | 7836/12750 [25:35:17<15:41:34, 11.50s/it] 61%|██████▏   | 7837/12750 [25:35:29<15:40:34, 11.49s/it] 61%|██████▏   | 7838/12750 [25:35:40<15:40:06, 11.48s/it] 61%|██████▏   | 7839/12750 [25:35:52<15:40:07, 11.49s/it] 61%|██████▏   | 7840/12750 [25:36:03<15:38:58, 11.47s/it] 61%|██████▏   | 7841/12750 [25:36:14<15:38:30, 11.47s/it] 62%|██████▏   | 7842/12750 [25:36:26<15:42:55, 11.53s/it] 62%|██████▏   | 7843/12750 [25:36:38<15:41:20, 11.51s/it] 62%|██████▏   | 7844/12750 [25:36:49<15:40:10, 11.50s/it] 62%|██████▏   | 7845/12750 [25:37:01<15:39:17, 11.49s/it] 62%|██████▏   | 7846/12750 [25:37:12<15:38:21, 11.48s/it] 62%|██████▏   | 7847/12750 [25:37:23<15:37:47, 11.48s/it] 62%|██████▏   | 7848/12750 [25:37:35<15:38:17, 11.48s/it] 62%|██████▏   | 7849/12750 [25:37:46<15:38:16, 11.49s/it] 62%|██████▏   | 7850/12750 [25:37:58<15:38:02, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120600.16lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104831.00lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7850
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7850/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7850/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7825] due to args.save_total_limit
 62%|██████▏   | 7851/12750 [25:38:10<15:44:47, 11.57s/it] 62%|██████▏   | 7852/12750 [25:38:29<18:53:41, 13.89s/it] 62%|██████▏   | 7853/12750 [25:38:40<17:54:57, 13.17s/it] 62%|██████▏   | 7854/12750 [25:38:52<17:13:14, 12.66s/it] 62%|██████▏   | 7855/12750 [25:39:03<16:43:57, 12.31s/it] 62%|██████▏   | 7856/12750 [25:39:15<16:22:52, 12.05s/it] 62%|██████▏   | 7857/12750 [25:39:26<16:08:30, 11.88s/it] 62%|██████▏   | 7858/12750 [25:39:38<15:59:00, 11.76s/it] 62%|██████▏   | 7859/12750 [25:39:49<15:51:43, 11.68s/it] 62%|██████▏   | 7860/12750 [25:40:01<15:46:53, 11.62s/it] 62%|██████▏   | 7861/12750 [25:40:12<15:42:51, 11.57s/it] 62%|██████▏   | 7862/12750 [25:40:24<15:40:12, 11.54s/it] 62%|██████▏   | 7863/12750 [25:40:35<15:38:13, 11.52s/it] 62%|██████▏   | 7864/12750 [25:40:47<15:37:18, 11.51s/it] 62%|██████▏   | 7865/12750 [25:40:58<15:35:51, 11.49s/it] 62%|██████▏   | 7866/12750 [25:41:10<15:35:35, 11.49s/it] 62%|██████▏   | 7867/12750 [25:41:21<15:34:52, 11.49s/it] 62%|██████▏   | 7868/12750 [25:41:33<15:33:54, 11.48s/it] 62%|██████▏   | 7869/12750 [25:41:44<15:33:39, 11.48s/it] 62%|██████▏   | 7870/12750 [25:41:56<15:33:35, 11.48s/it] 62%|██████▏   | 7871/12750 [25:42:07<15:33:30, 11.48s/it] 62%|██████▏   | 7872/12750 [25:42:18<15:33:20, 11.48s/it] 62%|██████▏   | 7873/12750 [25:42:30<15:33:24, 11.48s/it] 62%|██████▏   | 7874/12750 [25:42:41<15:33:03, 11.48s/it] 62%|██████▏   | 7875/12750 [25:42:53<15:32:34, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120741.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 105003.92lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7875
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7875/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7875/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7850] due to args.save_total_limit
 62%|██████▏   | 7876/12750 [25:43:05<15:40:13, 11.57s/it] 62%|██████▏   | 7877/12750 [25:43:16<15:37:56, 11.55s/it] 62%|██████▏   | 7878/12750 [25:43:28<15:36:02, 11.53s/it] 62%|██████▏   | 7879/12750 [25:43:39<15:34:14, 11.51s/it] 62%|██████▏   | 7880/12750 [25:43:51<15:32:39, 11.49s/it] 62%|██████▏   | 7881/12750 [25:44:02<15:30:57, 11.47s/it] 62%|██████▏   | 7882/12750 [25:44:13<15:29:43, 11.46s/it] 62%|██████▏   | 7883/12750 [25:44:25<15:29:29, 11.46s/it] 62%|██████▏   | 7884/12750 [25:44:44<18:35:18, 13.75s/it] 62%|██████▏   | 7885/12750 [25:44:55<17:38:06, 13.05s/it] 62%|██████▏   | 7886/12750 [25:45:07<16:59:47, 12.58s/it] 62%|██████▏   | 7887/12750 [25:45:18<16:32:04, 12.24s/it] 62%|██████▏   | 7888/12750 [25:45:30<16:13:06, 12.01s/it] 62%|██████▏   | 7889/12750 [25:45:41<15:58:48, 11.83s/it] 62%|██████▏   | 7890/12750 [25:45:53<15:50:01, 11.73s/it] 62%|██████▏   | 7891/12750 [25:46:04<15:43:41, 11.65s/it] 62%|██████▏   | 7892/12750 [25:46:16<15:39:07, 11.60s/it] 62%|██████▏   | 7893/12750 [25:46:27<15:35:05, 11.55s/it] 62%|██████▏   | 7894/12750 [25:46:39<15:33:02, 11.53s/it] 62%|██████▏   | 7895/12750 [25:46:50<15:30:06, 11.49s/it] 62%|██████▏   | 7896/12750 [25:47:01<15:28:41, 11.48s/it] 62%|██████▏   | 7897/12750 [25:47:13<15:27:57, 11.47s/it] 62%|██████▏   | 7898/12750 [25:47:24<15:27:21, 11.47s/it] 62%|██████▏   | 7899/12750 [25:47:36<15:26:25, 11.46s/it] 62%|██████▏   | 7900/12750 [25:47:47<15:26:53, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120654.64lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104901.50lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7900
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7900/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7900/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7875] due to args.save_total_limit
 62%|██████▏   | 7901/12750 [25:47:59<15:34:40, 11.57s/it] 62%|██████▏   | 7902/12750 [25:48:11<15:31:35, 11.53s/it] 62%|██████▏   | 7903/12750 [25:48:22<15:30:00, 11.51s/it] 62%|██████▏   | 7904/12750 [25:48:33<15:28:46, 11.50s/it] 62%|██████▏   | 7905/12750 [25:48:45<15:27:33, 11.49s/it] 62%|██████▏   | 7906/12750 [25:48:56<15:26:43, 11.48s/it] 62%|██████▏   | 7907/12750 [25:49:08<15:26:18, 11.48s/it] 62%|██████▏   | 7908/12750 [25:49:19<15:25:27, 11.47s/it] 62%|██████▏   | 7909/12750 [25:49:31<15:24:45, 11.46s/it] 62%|██████▏   | 7910/12750 [25:49:42<15:24:59, 11.47s/it] 62%|██████▏   | 7911/12750 [25:49:54<15:25:10, 11.47s/it] 62%|██████▏   | 7912/12750 [25:50:05<15:24:43, 11.47s/it] 62%|██████▏   | 7913/12750 [25:50:17<15:24:52, 11.47s/it] 62%|██████▏   | 7914/12750 [25:50:28<15:23:50, 11.46s/it] 62%|██████▏   | 7915/12750 [25:50:40<15:22:48, 11.45s/it] 62%|██████▏   | 7916/12750 [25:50:51<15:23:01, 11.46s/it] 62%|██████▏   | 7917/12750 [25:51:10<18:28:10, 13.76s/it] 62%|██████▏   | 7918/12750 [25:51:22<17:32:29, 13.07s/it] 62%|██████▏   | 7919/12750 [25:51:33<16:53:12, 12.58s/it] 62%|██████▏   | 7920/12750 [25:51:45<16:26:33, 12.26s/it] 62%|██████▏   | 7921/12750 [25:51:56<16:07:36, 12.02s/it] 62%|██████▏   | 7922/12750 [25:52:07<15:54:02, 11.86s/it] 62%|██████▏   | 7923/12750 [25:52:19<15:45:00, 11.75s/it] 62%|██████▏   | 7924/12750 [25:52:30<15:38:03, 11.66s/it] 62%|██████▏   | 7925/12750 [25:52:42<15:33:24, 11.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120612.62lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104921.23lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7925
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7925/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7925/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7900] due to args.save_total_limit
 62%|██████▏   | 7926/12750 [25:52:54<15:37:40, 11.66s/it] 62%|██████▏   | 7927/12750 [25:53:05<15:32:33, 11.60s/it] 62%|██████▏   | 7928/12750 [25:53:17<15:28:50, 11.56s/it] 62%|██████▏   | 7929/12750 [25:53:28<15:26:32, 11.53s/it] 62%|██████▏   | 7930/12750 [25:53:40<15:24:52, 11.51s/it] 62%|██████▏   | 7931/12750 [25:53:51<15:23:28, 11.50s/it] 62%|██████▏   | 7932/12750 [25:54:02<15:22:33, 11.49s/it] 62%|██████▏   | 7933/12750 [25:54:14<15:21:06, 11.47s/it] 62%|██████▏   | 7934/12750 [25:54:25<15:19:40, 11.46s/it] 62%|██████▏   | 7935/12750 [25:54:37<15:20:44, 11.47s/it] 62%|██████▏   | 7936/12750 [25:54:48<15:20:11, 11.47s/it] 62%|██████▏   | 7937/12750 [25:55:00<15:20:23, 11.47s/it] 62%|██████▏   | 7938/12750 [25:55:11<15:19:54, 11.47s/it] 62%|██████▏   | 7939/12750 [25:55:23<15:19:51, 11.47s/it] 62%|██████▏   | 7940/12750 [25:55:34<15:20:09, 11.48s/it] 62%|██████▏   | 7941/12750 [25:55:46<15:19:45, 11.48s/it] 62%|██████▏   | 7942/12750 [25:55:57<15:19:00, 11.47s/it] 62%|██████▏   | 7943/12750 [25:56:09<15:18:45, 11.47s/it] 62%|██████▏   | 7944/12750 [25:56:20<15:18:58, 11.47s/it] 62%|██████▏   | 7945/12750 [25:56:32<15:18:04, 11.46s/it] 62%|██████▏   | 7946/12750 [25:56:43<15:17:48, 11.46s/it] 62%|██████▏   | 7947/12750 [25:56:54<15:17:46, 11.47s/it] 62%|██████▏   | 7948/12750 [25:57:06<15:17:14, 11.46s/it] 62%|██████▏   | 7949/12750 [25:57:25<18:22:39, 13.78s/it] 62%|██████▏   | 7950/12750 [25:57:37<17:26:41, 13.08s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120598.24lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104896.94lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7950
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7950/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7950/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7925] due to args.save_total_limit
 62%|██████▏   | 7951/12750 [25:57:48<16:55:16, 12.69s/it] 62%|██████▏   | 7952/12750 [25:58:00<16:25:09, 12.32s/it] 62%|██████▏   | 7953/12750 [25:58:11<16:04:01, 12.06s/it] 62%|██████▏   | 7954/12750 [25:58:23<15:49:58, 11.88s/it] 62%|██████▏   | 7955/12750 [25:58:34<15:39:43, 11.76s/it] 62%|██████▏   | 7956/12750 [25:58:46<15:31:40, 11.66s/it] 62%|██████▏   | 7957/12750 [25:58:57<15:25:41, 11.59s/it] 62%|██████▏   | 7958/12750 [25:59:09<15:22:26, 11.55s/it] 62%|██████▏   | 7959/12750 [25:59:20<15:19:28, 11.52s/it] 62%|██████▏   | 7960/12750 [25:59:31<15:17:58, 11.50s/it] 62%|██████▏   | 7961/12750 [25:59:43<15:17:01, 11.49s/it] 62%|██████▏   | 7962/12750 [25:59:54<15:16:30, 11.49s/it] 62%|██████▏   | 7963/12750 [26:00:06<15:16:04, 11.48s/it] 62%|██████▏   | 7964/12750 [26:00:17<15:15:35, 11.48s/it] 62%|██████▏   | 7965/12750 [26:00:29<15:14:57, 11.47s/it] 62%|██████▏   | 7966/12750 [26:00:40<15:14:31, 11.47s/it] 62%|██████▏   | 7967/12750 [26:00:52<15:13:43, 11.46s/it] 62%|██████▏   | 7968/12750 [26:01:03<15:13:30, 11.46s/it] 63%|██████▎   | 7969/12750 [26:01:15<15:13:34, 11.47s/it] 63%|██████▎   | 7970/12750 [26:01:26<15:13:10, 11.46s/it] 63%|██████▎   | 7971/12750 [26:01:37<15:12:27, 11.46s/it] 63%|██████▎   | 7972/12750 [26:01:49<15:12:58, 11.46s/it] 63%|██████▎   | 7973/12750 [26:02:00<15:12:39, 11.46s/it] 63%|██████▎   | 7974/12750 [26:02:12<15:12:42, 11.47s/it] 63%|██████▎   | 7975/12750 [26:02:23<15:12:49, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120641.28lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104941.94lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7975
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7975/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7975/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-7975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7950] due to args.save_total_limit
 63%|██████▎   | 7976/12750 [26:02:35<15:19:38, 11.56s/it] 63%|██████▎   | 7977/12750 [26:02:47<15:16:34, 11.52s/it] 63%|██████▎   | 7978/12750 [26:02:58<15:15:13, 11.51s/it] 63%|██████▎   | 7979/12750 [26:03:10<15:13:45, 11.49s/it] 63%|██████▎   | 7980/12750 [26:03:21<15:12:57, 11.48s/it] 63%|██████▎   | 7981/12750 [26:03:40<18:13:58, 13.76s/it] 63%|██████▎   | 7982/12750 [26:03:52<17:19:25, 13.08s/it] 63%|██████▎   | 7983/12750 [26:04:03<16:40:51, 12.60s/it] 63%|██████▎   | 7984/12750 [26:04:15<16:14:12, 12.26s/it] 63%|██████▎   | 7985/12750 [26:04:26<15:55:42, 12.03s/it] 63%|██████▎   | 7986/12750 [26:04:37<15:41:57, 11.86s/it] 63%|██████▎   | 7987/12750 [26:04:49<15:33:06, 11.75s/it] 63%|██████▎   | 7988/12750 [26:05:00<15:25:40, 11.66s/it] 63%|██████▎   | 7989/12750 [26:05:12<15:21:23, 11.61s/it] 63%|██████▎   | 7990/12750 [26:05:23<15:17:54, 11.57s/it] 63%|██████▎   | 7991/12750 [26:05:35<15:15:43, 11.55s/it] 63%|██████▎   | 7992/12750 [26:05:46<15:13:39, 11.52s/it] 63%|██████▎   | 7993/12750 [26:05:58<15:12:07, 11.50s/it] 63%|██████▎   | 7994/12750 [26:06:09<15:11:27, 11.50s/it] 63%|██████▎   | 7995/12750 [26:06:21<15:10:24, 11.49s/it] 63%|██████▎   | 7996/12750 [26:06:32<15:10:04, 11.49s/it] 63%|██████▎   | 7997/12750 [26:06:44<15:09:48, 11.49s/it] 63%|██████▎   | 7998/12750 [26:06:55<15:10:16, 11.49s/it] 63%|██████▎   | 7999/12750 [26:07:07<15:09:44, 11.49s/it] 63%|██████▎   | 8000/12750 [26:07:18<15:09:46, 11.49s/it]                                                           63%|██████▎   | 8000/12750 [26:07:18<15:09:46, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120725.64lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104965.29lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8000
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8000/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8000/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7975] due to args.save_total_limit
 63%|██████▎   | 8001/12750 [26:07:30<15:16:21, 11.58s/it] 63%|██████▎   | 8002/12750 [26:07:41<15:13:28, 11.54s/it] 63%|██████▎   | 8003/12750 [26:07:53<15:11:20, 11.52s/it] 63%|██████▎   | 8004/12750 [26:08:04<15:10:03, 11.51s/it] 63%|██████▎   | 8005/12750 [26:08:16<15:08:55, 11.49s/it] 63%|██████▎   | 8006/12750 [26:08:27<15:08:05, 11.49s/it] 63%|██████▎   | 8007/12750 [26:08:39<15:07:54, 11.49s/it] 63%|██████▎   | 8008/12750 [26:08:50<15:07:33, 11.48s/it] 63%|██████▎   | 8009/12750 [26:09:02<15:07:29, 11.48s/it] 63%|██████▎   | 8010/12750 [26:09:13<15:06:15, 11.47s/it] 63%|██████▎   | 8011/12750 [26:09:25<15:05:10, 11.46s/it] 63%|██████▎   | 8012/12750 [26:09:36<15:04:16, 11.45s/it] 63%|██████▎   | 8013/12750 [26:09:55<17:59:19, 13.67s/it] 63%|██████▎   | 8014/12750 [26:10:06<17:06:40, 13.01s/it] 63%|██████▎   | 8015/12750 [26:10:18<16:29:17, 12.54s/it] 63%|██████▎   | 8016/12750 [26:10:29<16:03:17, 12.21s/it] 63%|██████▎   | 8017/12750 [26:10:41<15:45:05, 11.98s/it] 63%|██████▎   | 8018/12750 [26:10:52<15:31:40, 11.81s/it] 63%|██████▎   | 8019/12750 [26:11:04<15:22:52, 11.70s/it] 63%|██████▎   | 8020/12750 [26:11:15<15:16:17, 11.62s/it] 63%|██████▎   | 8021/12750 [26:11:26<15:11:34, 11.57s/it] 63%|██████▎   | 8022/12750 [26:11:38<15:08:01, 11.52s/it] 63%|██████▎   | 8023/12750 [26:11:49<15:06:10, 11.50s/it] 63%|██████▎   | 8024/12750 [26:12:01<15:04:12, 11.48s/it] 63%|██████▎   | 8025/12750 [26:12:12<15:04:00, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120606.84lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104918.22lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8025
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8025/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8025/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-7600] due to args.save_total_limit
 63%|██████▎   | 8026/12750 [26:12:24<15:10:45, 11.57s/it] 63%|██████▎   | 8027/12750 [26:12:35<15:07:33, 11.53s/it] 63%|██████▎   | 8028/12750 [26:12:47<15:05:32, 11.51s/it] 63%|██████▎   | 8029/12750 [26:12:58<15:03:38, 11.48s/it] 63%|██████▎   | 8030/12750 [26:13:10<15:02:01, 11.47s/it] 63%|██████▎   | 8031/12750 [26:13:21<15:01:27, 11.46s/it] 63%|██████▎   | 8032/12750 [26:13:33<15:00:49, 11.46s/it] 63%|██████▎   | 8033/12750 [26:13:44<15:00:44, 11.46s/it] 63%|██████▎   | 8034/12750 [26:13:56<15:00:43, 11.46s/it] 63%|██████▎   | 8035/12750 [26:14:07<15:05:01, 11.52s/it] 63%|██████▎   | 8036/12750 [26:14:19<15:04:01, 11.51s/it] 63%|██████▎   | 8037/12750 [26:14:30<15:03:02, 11.50s/it] 63%|██████▎   | 8038/12750 [26:14:42<15:01:41, 11.48s/it] 63%|██████▎   | 8039/12750 [26:14:53<15:00:47, 11.47s/it] 63%|██████▎   | 8040/12750 [26:15:05<14:59:48, 11.46s/it] 63%|██████▎   | 8041/12750 [26:15:16<14:59:42, 11.46s/it] 63%|██████▎   | 8042/12750 [26:15:27<14:59:20, 11.46s/it] 63%|██████▎   | 8043/12750 [26:15:39<14:58:43, 11.46s/it] 63%|██████▎   | 8044/12750 [26:15:50<14:57:45, 11.45s/it] 63%|██████▎   | 8045/12750 [26:16:09<17:58:19, 13.75s/it] 63%|██████▎   | 8046/12750 [26:16:21<17:04:18, 13.07s/it] 63%|██████▎   | 8047/12750 [26:16:32<16:25:49, 12.58s/it] 63%|██████▎   | 8048/12750 [26:16:44<15:58:42, 12.23s/it] 63%|██████▎   | 8049/12750 [26:16:55<15:40:22, 12.00s/it] 63%|██████▎   | 8050/12750 [26:17:07<15:27:35, 11.84s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120558.95lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104678.48lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8050
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8050/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8050/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8000] due to args.save_total_limit
 63%|██████▎   | 8051/12750 [26:17:19<15:26:13, 11.83s/it] 63%|██████▎   | 8052/12750 [26:17:30<15:17:24, 11.72s/it] 63%|██████▎   | 8053/12750 [26:17:41<15:10:16, 11.63s/it] 63%|██████▎   | 8054/12750 [26:17:53<15:06:11, 11.58s/it] 63%|██████▎   | 8055/12750 [26:18:04<15:04:06, 11.55s/it] 63%|██████▎   | 8056/12750 [26:18:16<15:01:39, 11.53s/it] 63%|██████▎   | 8057/12750 [26:18:27<15:00:28, 11.51s/it] 63%|██████▎   | 8058/12750 [26:18:39<14:58:50, 11.49s/it] 63%|██████▎   | 8059/12750 [26:18:50<14:58:35, 11.49s/it] 63%|██████▎   | 8060/12750 [26:19:02<14:57:49, 11.49s/it] 63%|██████▎   | 8061/12750 [26:19:13<14:57:19, 11.48s/it] 63%|██████▎   | 8062/12750 [26:19:25<14:56:52, 11.48s/it] 63%|██████▎   | 8063/12750 [26:19:36<14:56:01, 11.47s/it] 63%|██████▎   | 8064/12750 [26:19:48<14:56:07, 11.47s/it] 63%|██████▎   | 8065/12750 [26:19:59<14:55:51, 11.47s/it] 63%|██████▎   | 8066/12750 [26:20:10<14:55:03, 11.47s/it] 63%|██████▎   | 8067/12750 [26:20:22<14:55:07, 11.47s/it] 63%|██████▎   | 8068/12750 [26:20:33<14:54:52, 11.47s/it] 63%|██████▎   | 8069/12750 [26:20:45<14:55:05, 11.47s/it] 63%|██████▎   | 8070/12750 [26:20:56<14:55:20, 11.48s/it] 63%|██████▎   | 8071/12750 [26:21:08<14:54:18, 11.47s/it] 63%|██████▎   | 8072/12750 [26:21:19<14:55:02, 11.48s/it] 63%|██████▎   | 8073/12750 [26:21:31<14:54:43, 11.48s/it] 63%|██████▎   | 8074/12750 [26:21:42<14:53:54, 11.47s/it] 63%|██████▎   | 8075/12750 [26:21:54<14:53:21, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120602.99lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104920.16lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8075
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8075/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8075/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8025] due to args.save_total_limit
 63%|██████▎   | 8076/12750 [26:22:06<15:00:33, 11.56s/it] 63%|██████▎   | 8077/12750 [26:22:25<17:55:50, 13.81s/it] 63%|██████▎   | 8078/12750 [26:22:36<17:00:43, 13.11s/it] 63%|██████▎   | 8079/12750 [26:22:48<16:21:52, 12.61s/it] 63%|██████▎   | 8080/12750 [26:22:59<15:55:22, 12.27s/it] 63%|██████▎   | 8081/12750 [26:23:10<15:36:32, 12.04s/it] 63%|██████▎   | 8082/12750 [26:23:22<15:22:53, 11.86s/it] 63%|██████▎   | 8083/12750 [26:23:33<15:13:10, 11.74s/it] 63%|██████▎   | 8084/12750 [26:23:45<15:06:27, 11.66s/it] 63%|██████▎   | 8085/12750 [26:23:56<15:01:17, 11.59s/it] 63%|██████▎   | 8086/12750 [26:24:08<14:58:16, 11.56s/it] 63%|██████▎   | 8087/12750 [26:24:19<14:55:52, 11.53s/it] 63%|██████▎   | 8088/12750 [26:24:31<14:54:23, 11.51s/it] 63%|██████▎   | 8089/12750 [26:24:42<14:53:30, 11.50s/it] 63%|██████▎   | 8090/12750 [26:24:54<14:51:46, 11.48s/it] 63%|██████▎   | 8091/12750 [26:25:05<14:51:20, 11.48s/it] 63%|██████▎   | 8092/12750 [26:25:17<14:50:14, 11.47s/it] 63%|██████▎   | 8093/12750 [26:25:28<14:50:12, 11.47s/it] 63%|██████▎   | 8094/12750 [26:25:39<14:50:01, 11.47s/it] 63%|██████▎   | 8095/12750 [26:25:51<14:49:51, 11.47s/it] 63%|██████▎   | 8096/12750 [26:26:02<14:49:11, 11.46s/it] 64%|██████▎   | 8097/12750 [26:26:14<14:49:08, 11.47s/it] 64%|██████▎   | 8098/12750 [26:26:25<14:48:27, 11.46s/it] 64%|██████▎   | 8099/12750 [26:26:37<14:47:40, 11.45s/it] 64%|██████▎   | 8100/12750 [26:26:48<14:46:55, 11.44s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120564.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104886.64lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8100
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8100/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8100/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8075] due to args.save_total_limit
 64%|██████▎   | 8101/12750 [26:27:00<14:54:40, 11.55s/it] 64%|██████▎   | 8102/12750 [26:27:11<14:52:24, 11.52s/it] 64%|██████▎   | 8103/12750 [26:27:23<14:51:01, 11.50s/it] 64%|██████▎   | 8104/12750 [26:27:34<14:49:07, 11.48s/it] 64%|██████▎   | 8105/12750 [26:27:46<14:48:24, 11.48s/it] 64%|██████▎   | 8106/12750 [26:27:57<14:47:29, 11.47s/it] 64%|██████▎   | 8107/12750 [26:28:09<14:46:56, 11.46s/it] 64%|██████▎   | 8108/12750 [26:28:20<14:46:17, 11.46s/it] 64%|██████▎   | 8109/12750 [26:28:32<14:46:00, 11.45s/it] 64%|██████▎   | 8110/12750 [26:28:51<17:44:15, 13.76s/it] 64%|██████▎   | 8111/12750 [26:29:02<16:51:33, 13.08s/it] 64%|██████▎   | 8112/12750 [26:29:14<16:15:06, 12.61s/it] 64%|██████▎   | 8113/12750 [26:29:25<15:48:24, 12.27s/it] 64%|██████▎   | 8114/12750 [26:29:37<15:30:33, 12.04s/it] 64%|██████▎   | 8115/12750 [26:29:48<15:17:03, 11.87s/it] 64%|██████▎   | 8116/12750 [26:30:00<15:08:34, 11.76s/it] 64%|██████▎   | 8117/12750 [26:30:11<15:01:54, 11.68s/it] 64%|██████▎   | 8118/12750 [26:30:23<14:57:09, 11.62s/it] 64%|██████▎   | 8119/12750 [26:30:34<14:53:58, 11.58s/it] 64%|██████▎   | 8120/12750 [26:30:46<14:52:48, 11.57s/it] 64%|██████▎   | 8121/12750 [26:30:57<14:51:11, 11.55s/it] 64%|██████▎   | 8122/12750 [26:31:09<14:50:12, 11.54s/it] 64%|██████▎   | 8123/12750 [26:31:20<14:49:48, 11.54s/it] 64%|██████▎   | 8124/12750 [26:31:32<14:48:46, 11.53s/it] 64%|██████▎   | 8125/12750 [26:31:43<14:47:18, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120378.26lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104756.82lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8125
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8125/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8125/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8100] due to args.save_total_limit
 64%|██████▎   | 8126/12750 [26:31:55<14:54:42, 11.61s/it] 64%|██████▎   | 8127/12750 [26:32:07<14:51:37, 11.57s/it] 64%|██████▎   | 8128/12750 [26:32:18<14:50:02, 11.55s/it] 64%|██████▍   | 8129/12750 [26:32:30<14:48:50, 11.54s/it] 64%|██████▍   | 8130/12750 [26:32:41<14:48:07, 11.53s/it] 64%|██████▍   | 8131/12750 [26:32:53<14:47:16, 11.53s/it] 64%|██████▍   | 8132/12750 [26:33:04<14:46:25, 11.52s/it] 64%|██████▍   | 8133/12750 [26:33:16<14:46:55, 11.53s/it] 64%|██████▍   | 8134/12750 [26:33:27<14:45:45, 11.51s/it] 64%|██████▍   | 8135/12750 [26:33:39<14:45:17, 11.51s/it] 64%|██████▍   | 8136/12750 [26:33:50<14:44:48, 11.51s/it] 64%|██████▍   | 8137/12750 [26:34:02<14:45:27, 11.52s/it] 64%|██████▍   | 8138/12750 [26:34:13<14:44:26, 11.51s/it] 64%|██████▍   | 8139/12750 [26:34:25<14:43:22, 11.49s/it] 64%|██████▍   | 8140/12750 [26:34:36<14:42:58, 11.49s/it] 64%|██████▍   | 8141/12750 [26:34:48<14:43:04, 11.50s/it] 64%|██████▍   | 8142/12750 [26:35:07<17:40:21, 13.81s/it] 64%|██████▍   | 8143/12750 [26:35:18<16:46:25, 13.11s/it] 64%|██████▍   | 8144/12750 [26:35:30<16:08:28, 12.62s/it] 64%|██████▍   | 8145/12750 [26:35:41<15:42:23, 12.28s/it] 64%|██████▍   | 8146/12750 [26:35:53<15:24:46, 12.05s/it] 64%|██████▍   | 8147/12750 [26:36:04<15:11:29, 11.88s/it] 64%|██████▍   | 8148/12750 [26:36:16<15:02:19, 11.76s/it] 64%|██████▍   | 8149/12750 [26:36:27<14:55:46, 11.68s/it] 64%|██████▍   | 8150/12750 [26:36:39<14:50:43, 11.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120533.67lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104783.57lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8150
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8150/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8150/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8125] due to args.save_total_limit
 64%|██████▍   | 8151/12750 [26:36:51<14:54:57, 11.68s/it] 64%|██████▍   | 8152/12750 [26:37:02<14:51:17, 11.63s/it] 64%|██████▍   | 8153/12750 [26:37:14<14:47:35, 11.58s/it] 64%|██████▍   | 8154/12750 [26:37:25<14:45:30, 11.56s/it] 64%|██████▍   | 8155/12750 [26:37:37<14:43:50, 11.54s/it] 64%|██████▍   | 8156/12750 [26:37:48<14:42:37, 11.53s/it] 64%|██████▍   | 8157/12750 [26:38:00<14:42:08, 11.52s/it] 64%|██████▍   | 8158/12750 [26:38:11<14:42:11, 11.53s/it] 64%|██████▍   | 8159/12750 [26:38:18<12:59:02, 10.18s/it] 64%|██████▍   | 8160/12750 [26:38:19<9:23:20,  7.36s/it]  64%|██████▍   | 8161/12750 [26:38:42<15:28:09, 12.14s/it] 64%|██████▍   | 8162/12750 [26:38:54<15:14:29, 11.96s/it] 64%|██████▍   | 8163/12750 [26:39:05<15:04:38, 11.83s/it] 64%|██████▍   | 8164/12750 [26:39:17<14:57:07, 11.74s/it] 64%|██████▍   | 8165/12750 [26:39:28<14:52:07, 11.67s/it] 64%|██████▍   | 8166/12750 [26:39:40<14:48:28, 11.63s/it] 64%|██████▍   | 8167/12750 [26:39:51<14:44:47, 11.58s/it] 64%|██████▍   | 8168/12750 [26:40:03<14:43:04, 11.56s/it] 64%|██████▍   | 8169/12750 [26:40:14<14:42:00, 11.55s/it] 64%|██████▍   | 8170/12750 [26:40:26<14:41:05, 11.54s/it] 64%|██████▍   | 8171/12750 [26:40:37<14:38:53, 11.52s/it] 64%|██████▍   | 8172/12750 [26:40:49<14:38:36, 11.52s/it] 64%|██████▍   | 8173/12750 [26:41:00<14:38:24, 11.51s/it] 64%|██████▍   | 8174/12750 [26:41:19<17:22:02, 13.66s/it] 64%|██████▍   | 8175/12750 [26:41:30<16:32:00, 13.01s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120565.50lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104854.10lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8175
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8175/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8175/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8150] due to args.save_total_limit
 64%|██████▍   | 8176/12750 [26:41:42<16:04:14, 12.65s/it] 64%|██████▍   | 8177/12750 [26:41:54<15:38:03, 12.31s/it] 64%|██████▍   | 8178/12750 [26:42:05<15:18:51, 12.06s/it] 64%|██████▍   | 8179/12750 [26:42:17<15:05:44, 11.89s/it] 64%|██████▍   | 8180/12750 [26:42:28<14:57:45, 11.79s/it] 64%|██████▍   | 8181/12750 [26:42:40<14:51:09, 11.70s/it] 64%|██████▍   | 8182/12750 [26:42:51<14:46:18, 11.64s/it] 64%|██████▍   | 8183/12750 [26:43:03<14:43:02, 11.60s/it] 64%|██████▍   | 8184/12750 [26:43:14<14:41:08, 11.58s/it] 64%|██████▍   | 8185/12750 [26:43:26<14:39:13, 11.56s/it] 64%|██████▍   | 8186/12750 [26:43:37<14:37:45, 11.54s/it] 64%|██████▍   | 8187/12750 [26:43:49<14:36:27, 11.52s/it] 64%|██████▍   | 8188/12750 [26:44:00<14:35:44, 11.52s/it] 64%|██████▍   | 8189/12750 [26:44:12<14:34:07, 11.50s/it] 64%|██████▍   | 8190/12750 [26:44:23<14:33:57, 11.50s/it] 64%|██████▍   | 8191/12750 [26:44:35<14:34:55, 11.51s/it] 64%|██████▍   | 8192/12750 [26:44:46<14:34:26, 11.51s/it] 64%|██████▍   | 8193/12750 [26:44:58<14:33:51, 11.51s/it] 64%|██████▍   | 8194/12750 [26:45:09<14:34:09, 11.51s/it] 64%|██████▍   | 8195/12750 [26:45:21<14:33:49, 11.51s/it] 64%|██████▍   | 8196/12750 [26:45:32<14:33:36, 11.51s/it] 64%|██████▍   | 8197/12750 [26:45:44<14:33:18, 11.51s/it] 64%|██████▍   | 8198/12750 [26:45:55<14:32:45, 11.50s/it] 64%|██████▍   | 8199/12750 [26:46:07<14:32:08, 11.50s/it] 64%|██████▍   | 8200/12750 [26:46:18<14:31:16, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120606.72lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104879.94lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8200
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8200/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8200/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8175] due to args.save_total_limit
 64%|██████▍   | 8201/12750 [26:46:30<14:38:34, 11.59s/it] 64%|██████▍   | 8202/12750 [26:46:42<14:36:44, 11.57s/it] 64%|██████▍   | 8203/12750 [26:46:53<14:34:29, 11.54s/it] 64%|██████▍   | 8204/12750 [26:47:05<14:33:10, 11.52s/it] 64%|██████▍   | 8205/12750 [26:47:16<14:32:35, 11.52s/it] 64%|██████▍   | 8206/12750 [26:47:35<17:25:37, 13.81s/it] 64%|██████▍   | 8207/12750 [26:47:47<16:32:46, 13.11s/it] 64%|██████▍   | 8208/12750 [26:47:58<15:56:04, 12.63s/it] 64%|██████▍   | 8209/12750 [26:48:10<15:29:38, 12.28s/it] 64%|██████▍   | 8210/12750 [26:48:21<15:12:34, 12.06s/it] 64%|██████▍   | 8211/12750 [26:48:33<15:00:04, 11.90s/it] 64%|██████▍   | 8212/12750 [26:48:44<14:51:23, 11.79s/it] 64%|██████▍   | 8213/12750 [26:48:56<14:44:54, 11.70s/it] 64%|██████▍   | 8214/12750 [26:49:07<14:39:08, 11.63s/it] 64%|██████▍   | 8215/12750 [26:49:19<14:35:38, 11.59s/it] 64%|██████▍   | 8216/12750 [26:49:30<14:33:26, 11.56s/it] 64%|██████▍   | 8217/12750 [26:49:42<14:31:44, 11.54s/it] 64%|██████▍   | 8218/12750 [26:49:53<14:30:09, 11.52s/it] 64%|██████▍   | 8219/12750 [26:50:05<14:29:11, 11.51s/it] 64%|██████▍   | 8220/12750 [26:50:16<14:29:01, 11.51s/it] 64%|██████▍   | 8221/12750 [26:50:28<14:28:35, 11.51s/it] 64%|██████▍   | 8222/12750 [26:50:39<14:28:13, 11.50s/it] 64%|██████▍   | 8223/12750 [26:50:51<14:27:33, 11.50s/it] 65%|██████▍   | 8224/12750 [26:51:02<14:27:40, 11.50s/it] 65%|██████▍   | 8225/12750 [26:51:14<14:28:06, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120605.17lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104820.72lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8225
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8225/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8225/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8200] due to args.save_total_limit
 65%|██████▍   | 8226/12750 [26:51:26<14:34:32, 11.60s/it] 65%|██████▍   | 8227/12750 [26:51:37<14:31:19, 11.56s/it] 65%|██████▍   | 8228/12750 [26:51:49<14:29:28, 11.54s/it] 65%|██████▍   | 8229/12750 [26:52:00<14:31:45, 11.57s/it] 65%|██████▍   | 8230/12750 [26:52:12<14:29:22, 11.54s/it] 65%|██████▍   | 8231/12750 [26:52:23<14:27:53, 11.52s/it] 65%|██████▍   | 8232/12750 [26:52:35<14:26:39, 11.51s/it] 65%|██████▍   | 8233/12750 [26:52:46<14:26:04, 11.50s/it] 65%|██████▍   | 8234/12750 [26:52:58<14:25:37, 11.50s/it] 65%|██████▍   | 8235/12750 [26:53:09<14:24:53, 11.49s/it] 65%|██████▍   | 8236/12750 [26:53:21<14:24:19, 11.49s/it] 65%|██████▍   | 8237/12750 [26:53:32<14:23:16, 11.48s/it] 65%|██████▍   | 8238/12750 [26:53:51<17:17:00, 13.79s/it] 65%|██████▍   | 8239/12750 [26:54:03<16:25:09, 13.10s/it] 65%|██████▍   | 8240/12750 [26:54:14<15:47:51, 12.61s/it] 65%|██████▍   | 8241/12750 [26:54:26<15:21:23, 12.26s/it] 65%|██████▍   | 8242/12750 [26:54:37<15:02:22, 12.01s/it] 65%|██████▍   | 8243/12750 [26:54:49<14:51:27, 11.87s/it] 65%|██████▍   | 8244/12750 [26:55:00<14:42:32, 11.75s/it] 65%|██████▍   | 8245/12750 [26:55:12<14:36:40, 11.68s/it] 65%|██████▍   | 8246/12750 [26:55:23<14:32:36, 11.62s/it] 65%|██████▍   | 8247/12750 [26:55:35<14:28:36, 11.57s/it] 65%|██████▍   | 8248/12750 [26:55:46<14:26:02, 11.54s/it] 65%|██████▍   | 8249/12750 [26:55:57<14:24:20, 11.52s/it] 65%|██████▍   | 8250/12750 [26:56:09<14:23:40, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120408.98lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104381.02lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8250
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8250/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8250/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8225] due to args.save_total_limit
 65%|██████▍   | 8251/12750 [26:56:21<14:30:13, 11.61s/it] 65%|██████▍   | 8252/12750 [26:56:32<14:27:35, 11.57s/it] 65%|██████▍   | 8253/12750 [26:56:44<14:25:42, 11.55s/it] 65%|██████▍   | 8254/12750 [26:56:55<14:23:56, 11.53s/it] 65%|██████▍   | 8255/12750 [26:57:07<14:22:26, 11.51s/it] 65%|██████▍   | 8256/12750 [26:57:18<14:20:55, 11.49s/it] 65%|██████▍   | 8257/12750 [26:57:30<14:20:44, 11.49s/it] 65%|██████▍   | 8258/12750 [26:57:41<14:20:22, 11.49s/it] 65%|██████▍   | 8259/12750 [26:57:53<14:20:05, 11.49s/it] 65%|██████▍   | 8260/12750 [26:58:04<14:18:26, 11.47s/it] 65%|██████▍   | 8261/12750 [26:58:16<14:18:39, 11.48s/it] 65%|██████▍   | 8262/12750 [26:58:27<14:19:31, 11.49s/it] 65%|██████▍   | 8263/12750 [26:58:39<14:19:09, 11.49s/it] 65%|██████▍   | 8264/12750 [26:58:50<14:19:14, 11.49s/it] 65%|██████▍   | 8265/12750 [26:59:02<14:19:33, 11.50s/it] 65%|██████▍   | 8266/12750 [26:59:13<14:19:27, 11.50s/it] 65%|██████▍   | 8267/12750 [26:59:25<14:19:19, 11.50s/it] 65%|██████▍   | 8268/12750 [26:59:36<14:17:38, 11.48s/it] 65%|██████▍   | 8269/12750 [26:59:48<14:18:30, 11.50s/it] 65%|██████▍   | 8270/12750 [26:59:59<14:16:52, 11.48s/it] 65%|██████▍   | 8271/12750 [27:00:18<17:08:18, 13.78s/it] 65%|██████▍   | 8272/12750 [27:00:30<16:16:33, 13.08s/it] 65%|██████▍   | 8273/12750 [27:00:41<15:39:36, 12.59s/it] 65%|██████▍   | 8274/12750 [27:00:52<15:14:11, 12.25s/it] 65%|██████▍   | 8275/12750 [27:01:04<14:56:24, 12.02s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120581.93lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104892.27lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8275
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8275/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8275/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8250] due to args.save_total_limit
 65%|██████▍   | 8276/12750 [27:01:16<14:51:08, 11.95s/it] 65%|██████▍   | 8277/12750 [27:01:27<14:39:45, 11.80s/it] 65%|██████▍   | 8278/12750 [27:01:39<14:32:02, 11.70s/it] 65%|██████▍   | 8279/12750 [27:01:50<14:26:53, 11.63s/it] 65%|██████▍   | 8280/12750 [27:02:02<14:23:36, 11.59s/it] 65%|██████▍   | 8281/12750 [27:02:13<14:20:44, 11.56s/it] 65%|██████▍   | 8282/12750 [27:02:25<14:18:43, 11.53s/it] 65%|██████▍   | 8283/12750 [27:02:36<14:17:51, 11.52s/it] 65%|██████▍   | 8284/12750 [27:02:48<14:17:33, 11.52s/it] 65%|██████▍   | 8285/12750 [27:02:59<14:15:43, 11.50s/it] 65%|██████▍   | 8286/12750 [27:03:11<14:14:59, 11.49s/it] 65%|██████▍   | 8287/12750 [27:03:22<14:14:51, 11.49s/it] 65%|██████▌   | 8288/12750 [27:03:34<14:14:09, 11.49s/it] 65%|██████▌   | 8289/12750 [27:03:45<14:13:19, 11.48s/it] 65%|██████▌   | 8290/12750 [27:03:56<14:12:57, 11.47s/it] 65%|██████▌   | 8291/12750 [27:04:08<14:11:47, 11.46s/it] 65%|██████▌   | 8292/12750 [27:04:19<14:11:59, 11.47s/it] 65%|██████▌   | 8293/12750 [27:04:31<14:11:01, 11.46s/it] 65%|██████▌   | 8294/12750 [27:04:42<14:10:49, 11.46s/it] 65%|██████▌   | 8295/12750 [27:04:54<14:11:06, 11.46s/it] 65%|██████▌   | 8296/12750 [27:05:05<14:11:18, 11.47s/it] 65%|██████▌   | 8297/12750 [27:05:17<14:11:17, 11.47s/it] 65%|██████▌   | 8298/12750 [27:05:28<14:11:27, 11.48s/it] 65%|██████▌   | 8299/12750 [27:05:40<14:11:06, 11.47s/it] 65%|██████▌   | 8300/12750 [27:05:51<14:10:58, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120549.84lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104863.91lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8300
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8300/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8300/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8275] due to args.save_total_limit
 65%|██████▌   | 8301/12750 [27:06:03<14:17:47, 11.57s/it] 65%|██████▌   | 8302/12750 [27:06:14<14:15:49, 11.54s/it] 65%|██████▌   | 8303/12750 [27:06:34<17:06:32, 13.85s/it] 65%|██████▌   | 8304/12750 [27:06:45<16:13:19, 13.14s/it] 65%|██████▌   | 8305/12750 [27:06:57<15:36:02, 12.64s/it] 65%|██████▌   | 8306/12750 [27:07:08<15:10:06, 12.29s/it] 65%|██████▌   | 8307/12750 [27:07:19<14:52:07, 12.05s/it] 65%|██████▌   | 8308/12750 [27:07:31<14:39:06, 11.87s/it] 65%|██████▌   | 8309/12750 [27:07:42<14:30:10, 11.76s/it] 65%|██████▌   | 8310/12750 [27:07:54<14:23:52, 11.67s/it] 65%|██████▌   | 8311/12750 [27:08:05<14:19:17, 11.61s/it] 65%|██████▌   | 8312/12750 [27:08:17<14:15:39, 11.57s/it] 65%|██████▌   | 8313/12750 [27:08:28<14:14:01, 11.55s/it] 65%|██████▌   | 8314/12750 [27:08:44<15:38:58, 12.70s/it] 65%|██████▌   | 8315/12750 [27:08:55<15:11:29, 12.33s/it] 65%|██████▌   | 8316/12750 [27:09:07<14:52:00, 12.07s/it] 65%|██████▌   | 8317/12750 [27:09:18<14:38:44, 11.89s/it] 65%|██████▌   | 8318/12750 [27:09:30<14:29:21, 11.77s/it] 65%|██████▌   | 8319/12750 [27:09:41<14:22:56, 11.68s/it] 65%|██████▌   | 8320/12750 [27:09:53<14:18:30, 11.63s/it] 65%|██████▌   | 8321/12750 [27:10:04<14:14:26, 11.58s/it] 65%|██████▌   | 8322/12750 [27:10:16<14:11:36, 11.54s/it] 65%|██████▌   | 8323/12750 [27:10:27<14:10:09, 11.52s/it] 65%|██████▌   | 8324/12750 [27:10:38<14:08:34, 11.50s/it] 65%|██████▌   | 8325/12750 [27:10:50<14:07:09, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120509.56lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104793.95lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8325
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8325/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8325/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8300] due to args.save_total_limit
 65%|██████▌   | 8326/12750 [27:11:02<14:13:38, 11.58s/it] 65%|██████▌   | 8327/12750 [27:11:13<14:10:40, 11.54s/it] 65%|██████▌   | 8328/12750 [27:11:25<14:09:08, 11.52s/it] 65%|██████▌   | 8329/12750 [27:11:36<14:07:16, 11.50s/it] 65%|██████▌   | 8330/12750 [27:11:48<14:07:19, 11.50s/it] 65%|██████▌   | 8331/12750 [27:11:59<14:06:18, 11.49s/it] 65%|██████▌   | 8332/12750 [27:12:11<14:05:53, 11.49s/it] 65%|██████▌   | 8333/12750 [27:12:22<14:06:36, 11.50s/it] 65%|██████▌   | 8334/12750 [27:12:34<14:06:49, 11.51s/it] 65%|██████▌   | 8335/12750 [27:12:52<16:44:06, 13.65s/it] 65%|██████▌   | 8336/12750 [27:13:04<15:56:23, 13.00s/it] 65%|██████▌   | 8337/12750 [27:13:15<15:22:28, 12.54s/it] 65%|██████▌   | 8338/12750 [27:13:27<14:58:07, 12.21s/it] 65%|██████▌   | 8339/12750 [27:13:38<14:41:40, 11.99s/it] 65%|██████▌   | 8340/12750 [27:13:50<14:30:11, 11.84s/it] 65%|██████▌   | 8341/12750 [27:14:01<14:21:54, 11.73s/it] 65%|██████▌   | 8342/12750 [27:14:13<14:16:00, 11.65s/it] 65%|██████▌   | 8343/12750 [27:14:24<14:11:41, 11.60s/it] 65%|██████▌   | 8344/12750 [27:14:35<14:08:42, 11.56s/it] 65%|██████▌   | 8345/12750 [27:14:47<14:06:53, 11.54s/it] 65%|██████▌   | 8346/12750 [27:14:58<14:05:05, 11.51s/it] 65%|██████▌   | 8347/12750 [27:15:10<14:04:00, 11.50s/it] 65%|██████▌   | 8348/12750 [27:15:21<14:02:23, 11.48s/it] 65%|██████▌   | 8349/12750 [27:15:33<14:01:53, 11.48s/it] 65%|██████▌   | 8350/12750 [27:15:44<14:01:24, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120688.33lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104972.10lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8350
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8350/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8350/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8325] due to args.save_total_limit
 65%|██████▌   | 8351/12750 [27:15:56<14:07:38, 11.56s/it] 66%|██████▌   | 8352/12750 [27:16:08<14:05:51, 11.54s/it] 66%|██████▌   | 8353/12750 [27:16:19<14:03:58, 11.52s/it] 66%|██████▌   | 8354/12750 [27:16:31<14:03:37, 11.51s/it] 66%|██████▌   | 8355/12750 [27:16:42<14:02:54, 11.51s/it] 66%|██████▌   | 8356/12750 [27:16:53<14:01:53, 11.50s/it] 66%|██████▌   | 8357/12750 [27:17:05<14:00:42, 11.48s/it] 66%|██████▌   | 8358/12750 [27:17:16<14:00:14, 11.48s/it] 66%|██████▌   | 8359/12750 [27:17:28<14:00:40, 11.49s/it] 66%|██████▌   | 8360/12750 [27:17:39<14:00:18, 11.48s/it] 66%|██████▌   | 8361/12750 [27:17:51<13:59:50, 11.48s/it] 66%|██████▌   | 8362/12750 [27:18:02<13:59:14, 11.48s/it] 66%|██████▌   | 8363/12750 [27:18:14<13:59:12, 11.48s/it] 66%|██████▌   | 8364/12750 [27:18:25<13:58:42, 11.47s/it] 66%|██████▌   | 8365/12750 [27:18:37<13:58:33, 11.47s/it] 66%|██████▌   | 8366/12750 [27:18:48<13:59:25, 11.49s/it] 66%|██████▌   | 8367/12750 [27:19:07<16:28:01, 13.53s/it] 66%|██████▌   | 8368/12750 [27:19:18<15:43:06, 12.91s/it] 66%|██████▌   | 8369/12750 [27:19:30<15:11:58, 12.49s/it] 66%|██████▌   | 8370/12750 [27:19:41<14:49:49, 12.19s/it] 66%|██████▌   | 8371/12750 [27:19:52<14:33:49, 11.97s/it] 66%|██████▌   | 8372/12750 [27:20:04<14:22:49, 11.82s/it] 66%|██████▌   | 8373/12750 [27:20:15<14:14:57, 11.72s/it] 66%|██████▌   | 8374/12750 [27:20:27<14:09:25, 11.65s/it] 66%|██████▌   | 8375/12750 [27:20:38<14:05:13, 11.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120773.41lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 105031.68lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8375
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8375/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8375/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8350] due to args.save_total_limit
 66%|██████▌   | 8376/12750 [27:20:50<14:09:18, 11.65s/it] 66%|██████▌   | 8377/12750 [27:21:02<14:05:22, 11.60s/it] 66%|██████▌   | 8378/12750 [27:21:13<14:03:14, 11.57s/it] 66%|██████▌   | 8379/12750 [27:21:25<14:01:35, 11.55s/it] 66%|██████▌   | 8380/12750 [27:21:36<14:00:25, 11.54s/it] 66%|██████▌   | 8381/12750 [27:21:48<13:58:44, 11.52s/it] 66%|██████▌   | 8382/12750 [27:21:59<13:57:44, 11.51s/it] 66%|██████▌   | 8383/12750 [27:22:11<13:57:34, 11.51s/it] 66%|██████▌   | 8384/12750 [27:22:22<13:57:34, 11.51s/it] 66%|██████▌   | 8385/12750 [27:22:34<13:57:20, 11.51s/it] 66%|██████▌   | 8386/12750 [27:22:45<13:56:41, 11.50s/it] 66%|██████▌   | 8387/12750 [27:22:57<13:55:18, 11.49s/it] 66%|██████▌   | 8388/12750 [27:23:08<13:54:52, 11.48s/it] 66%|██████▌   | 8389/12750 [27:23:20<13:54:53, 11.49s/it] 66%|██████▌   | 8390/12750 [27:23:31<13:54:17, 11.48s/it] 66%|██████▌   | 8391/12750 [27:23:42<13:53:59, 11.48s/it] 66%|██████▌   | 8392/12750 [27:23:54<13:53:42, 11.48s/it] 66%|██████▌   | 8393/12750 [27:24:05<13:53:05, 11.47s/it] 66%|██████▌   | 8394/12750 [27:24:17<13:53:04, 11.47s/it] 66%|██████▌   | 8395/12750 [27:24:28<13:52:58, 11.48s/it] 66%|██████▌   | 8396/12750 [27:24:40<13:52:21, 11.47s/it] 66%|██████▌   | 8397/12750 [27:24:51<13:52:59, 11.48s/it] 66%|██████▌   | 8398/12750 [27:25:03<13:53:12, 11.49s/it] 66%|██████▌   | 8399/12750 [27:25:22<16:40:02, 13.79s/it] 66%|██████▌   | 8400/12750 [27:25:34<15:49:47, 13.10s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120632.02lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104922.89lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8400
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8400/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8400/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8375] due to args.save_total_limit
 66%|██████▌   | 8401/12750 [27:25:45<15:20:53, 12.70s/it] 66%|██████▌   | 8402/12750 [27:25:57<14:53:43, 12.33s/it] 66%|██████▌   | 8403/12750 [27:26:08<14:34:13, 12.07s/it] 66%|██████▌   | 8404/12750 [27:26:20<14:21:11, 11.89s/it] 66%|██████▌   | 8405/12750 [27:26:31<14:12:32, 11.77s/it] 66%|██████▌   | 8406/12750 [27:26:43<14:06:12, 11.69s/it] 66%|██████▌   | 8407/12750 [27:26:54<14:01:10, 11.62s/it] 66%|██████▌   | 8408/12750 [27:27:06<13:57:18, 11.57s/it] 66%|██████▌   | 8409/12750 [27:27:17<13:55:54, 11.55s/it] 66%|██████▌   | 8410/12750 [27:27:29<13:53:27, 11.52s/it] 66%|██████▌   | 8411/12750 [27:27:40<13:52:27, 11.51s/it] 66%|██████▌   | 8412/12750 [27:27:52<13:51:30, 11.50s/it] 66%|██████▌   | 8413/12750 [27:28:03<13:50:52, 11.49s/it] 66%|██████▌   | 8414/12750 [27:28:14<13:49:43, 11.48s/it] 66%|██████▌   | 8415/12750 [27:28:26<13:49:02, 11.47s/it] 66%|██████▌   | 8416/12750 [27:28:37<13:48:57, 11.48s/it] 66%|██████▌   | 8417/12750 [27:28:49<13:48:32, 11.47s/it] 66%|██████▌   | 8418/12750 [27:29:00<13:48:50, 11.48s/it] 66%|██████▌   | 8419/12750 [27:29:12<13:48:07, 11.47s/it] 66%|██████▌   | 8420/12750 [27:29:23<13:47:47, 11.47s/it] 66%|██████▌   | 8421/12750 [27:29:35<13:47:33, 11.47s/it] 66%|██████▌   | 8422/12750 [27:29:46<13:47:54, 11.48s/it] 66%|██████▌   | 8423/12750 [27:29:58<13:47:10, 11.47s/it] 66%|██████▌   | 8424/12750 [27:30:09<13:47:44, 11.48s/it] 66%|██████▌   | 8425/12750 [27:30:21<13:47:20, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120534.96lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 101357.94lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8425
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8425/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8425/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8400] due to args.save_total_limit
 66%|██████▌   | 8426/12750 [27:30:33<13:59:02, 11.64s/it] 66%|██████▌   | 8427/12750 [27:30:44<13:55:19, 11.59s/it] 66%|██████▌   | 8428/12750 [27:30:56<13:52:43, 11.56s/it] 66%|██████▌   | 8429/12750 [27:31:07<13:51:09, 11.54s/it] 66%|██████▌   | 8430/12750 [27:31:19<13:49:33, 11.52s/it] 66%|██████▌   | 8431/12750 [27:31:30<13:49:17, 11.52s/it] 66%|██████▌   | 8432/12750 [27:31:49<16:34:35, 13.82s/it] 66%|██████▌   | 8433/12750 [27:32:01<15:43:46, 13.12s/it] 66%|██████▌   | 8434/12750 [27:32:12<15:08:07, 12.62s/it] 66%|██████▌   | 8435/12750 [27:32:24<14:43:51, 12.29s/it] 66%|██████▌   | 8436/12750 [27:32:35<14:26:08, 12.05s/it] 66%|██████▌   | 8437/12750 [27:32:47<14:14:43, 11.89s/it] 66%|██████▌   | 8438/12750 [27:32:58<14:05:29, 11.76s/it] 66%|██████▌   | 8439/12750 [27:33:10<13:58:50, 11.67s/it] 66%|██████▌   | 8440/12750 [27:33:21<13:55:24, 11.63s/it] 66%|██████▌   | 8441/12750 [27:33:33<13:52:14, 11.59s/it] 66%|██████▌   | 8442/12750 [27:33:44<13:50:36, 11.57s/it] 66%|██████▌   | 8443/12750 [27:33:56<13:48:40, 11.54s/it] 66%|██████▌   | 8444/12750 [27:34:07<13:47:04, 11.52s/it] 66%|██████▌   | 8445/12750 [27:34:19<13:46:40, 11.52s/it] 66%|██████▌   | 8446/12750 [27:34:30<13:45:43, 11.51s/it] 66%|██████▋   | 8447/12750 [27:34:42<13:44:52, 11.50s/it] 66%|██████▋   | 8448/12750 [27:34:53<13:43:57, 11.49s/it] 66%|██████▋   | 8449/12750 [27:35:05<13:44:22, 11.50s/it] 66%|██████▋   | 8450/12750 [27:35:16<13:44:09, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120890.99lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 105213.67lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8450
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8450/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8450/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8425] due to args.save_total_limit
 66%|██████▋   | 8451/12750 [27:35:28<13:50:07, 11.59s/it] 66%|██████▋   | 8452/12750 [27:35:39<13:47:31, 11.55s/it] 66%|██████▋   | 8453/12750 [27:35:51<13:47:07, 11.55s/it] 66%|██████▋   | 8454/12750 [27:36:02<13:44:34, 11.52s/it] 66%|██████▋   | 8455/12750 [27:36:14<13:44:01, 11.51s/it] 66%|██████▋   | 8456/12750 [27:36:25<13:44:08, 11.52s/it] 66%|██████▋   | 8457/12750 [27:36:37<13:44:06, 11.52s/it] 66%|██████▋   | 8458/12750 [27:36:48<13:43:17, 11.51s/it] 66%|██████▋   | 8459/12750 [27:37:00<13:43:05, 11.51s/it] 66%|██████▋   | 8460/12750 [27:37:11<13:42:49, 11.51s/it] 66%|██████▋   | 8461/12750 [27:37:23<13:42:08, 11.50s/it] 66%|██████▋   | 8462/12750 [27:37:34<13:41:15, 11.49s/it] 66%|██████▋   | 8463/12750 [27:37:46<13:41:40, 11.50s/it] 66%|██████▋   | 8464/12750 [27:38:05<16:24:53, 13.79s/it] 66%|██████▋   | 8465/12750 [27:38:17<15:35:52, 13.10s/it] 66%|██████▋   | 8466/12750 [27:38:28<15:01:23, 12.62s/it] 66%|██████▋   | 8467/12750 [27:38:40<14:37:01, 12.29s/it] 66%|██████▋   | 8468/12750 [27:38:51<14:20:14, 12.05s/it] 66%|██████▋   | 8469/12750 [27:39:03<14:08:45, 11.90s/it] 66%|██████▋   | 8470/12750 [27:39:14<13:59:44, 11.77s/it] 66%|██████▋   | 8471/12750 [27:39:26<13:53:33, 11.69s/it] 66%|██████▋   | 8472/12750 [27:39:37<13:49:01, 11.63s/it] 66%|██████▋   | 8473/12750 [27:39:49<13:45:54, 11.59s/it] 66%|██████▋   | 8474/12750 [27:40:00<13:44:16, 11.57s/it] 66%|██████▋   | 8475/12750 [27:40:12<13:42:00, 11.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120588.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104944.96lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8475
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8475/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8475/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8450] due to args.save_total_limit
 66%|██████▋   | 8476/12750 [27:40:23<13:48:32, 11.63s/it] 66%|██████▋   | 8477/12750 [27:40:35<13:45:28, 11.59s/it] 66%|██████▋   | 8478/12750 [27:40:46<13:42:46, 11.56s/it] 67%|██████▋   | 8479/12750 [27:40:58<13:41:01, 11.53s/it] 67%|██████▋   | 8480/12750 [27:41:09<13:40:05, 11.52s/it] 67%|██████▋   | 8481/12750 [27:41:21<13:39:32, 11.52s/it] 67%|██████▋   | 8482/12750 [27:41:32<13:39:06, 11.52s/it] 67%|██████▋   | 8483/12750 [27:41:44<13:39:11, 11.52s/it] 67%|██████▋   | 8484/12750 [27:41:55<13:38:25, 11.51s/it] 67%|██████▋   | 8485/12750 [27:42:07<13:37:37, 11.50s/it] 67%|██████▋   | 8486/12750 [27:42:18<13:37:41, 11.51s/it] 67%|██████▋   | 8487/12750 [27:42:30<13:36:51, 11.50s/it] 67%|██████▋   | 8488/12750 [27:42:41<13:36:35, 11.50s/it] 67%|██████▋   | 8489/12750 [27:42:53<13:37:03, 11.51s/it] 67%|██████▋   | 8490/12750 [27:43:04<13:36:29, 11.50s/it] 67%|██████▋   | 8491/12750 [27:43:16<13:35:56, 11.49s/it] 67%|██████▋   | 8492/12750 [27:43:27<13:36:09, 11.50s/it] 67%|██████▋   | 8493/12750 [27:43:39<13:35:59, 11.50s/it] 67%|██████▋   | 8494/12750 [27:43:50<13:35:43, 11.50s/it] 67%|██████▋   | 8495/12750 [27:44:02<13:35:42, 11.50s/it] 67%|██████▋   | 8496/12750 [27:44:21<16:19:57, 13.82s/it] 67%|██████▋   | 8497/12750 [27:44:33<15:29:46, 13.12s/it] 67%|██████▋   | 8498/12750 [27:44:44<14:55:32, 12.64s/it] 67%|██████▋   | 8499/12750 [27:44:56<14:30:55, 12.29s/it] 67%|██████▋   | 8500/12750 [27:45:07<14:13:54, 12.06s/it]                                                           67%|██████▋   | 8500/12750 [27:45:07<14:13:54, 12.06s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120576.02lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104893.05lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8500
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8500/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8500/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8475] due to args.save_total_limit
 67%|██████▋   | 8501/12750 [27:45:19<14:07:55, 11.97s/it] 67%|██████▋   | 8502/12750 [27:45:30<13:57:32, 11.83s/it] 67%|██████▋   | 8503/12750 [27:45:42<13:49:31, 11.72s/it] 67%|██████▋   | 8504/12750 [27:45:53<13:45:20, 11.66s/it] 67%|██████▋   | 8505/12750 [27:46:05<13:42:01, 11.62s/it] 67%|██████▋   | 8506/12750 [27:46:16<13:39:27, 11.59s/it] 67%|██████▋   | 8507/12750 [27:46:28<13:37:30, 11.56s/it] 67%|██████▋   | 8508/12750 [27:46:39<13:36:00, 11.54s/it] 67%|██████▋   | 8509/12750 [27:46:51<13:34:44, 11.53s/it] 67%|██████▋   | 8510/12750 [27:47:02<13:33:46, 11.52s/it] 67%|██████▋   | 8511/12750 [27:47:14<13:33:18, 11.51s/it] 67%|██████▋   | 8512/12750 [27:47:25<13:32:30, 11.50s/it] 67%|██████▋   | 8513/12750 [27:47:37<13:32:20, 11.50s/it] 67%|██████▋   | 8514/12750 [27:47:48<13:32:44, 11.51s/it] 67%|██████▋   | 8515/12750 [27:48:00<13:32:11, 11.51s/it] 67%|██████▋   | 8516/12750 [27:48:11<13:31:59, 11.51s/it] 67%|██████▋   | 8517/12750 [27:48:23<13:30:50, 11.49s/it] 67%|██████▋   | 8518/12750 [27:48:34<13:30:12, 11.49s/it] 67%|██████▋   | 8519/12750 [27:48:46<13:29:49, 11.48s/it] 67%|██████▋   | 8520/12750 [27:48:57<13:30:14, 11.49s/it] 67%|██████▋   | 8521/12750 [27:49:09<13:31:03, 11.51s/it] 67%|██████▋   | 8522/12750 [27:49:20<13:31:03, 11.51s/it] 67%|██████▋   | 8523/12750 [27:49:32<13:30:41, 11.51s/it] 67%|██████▋   | 8524/12750 [27:49:43<13:30:02, 11.50s/it] 67%|██████▋   | 8525/12750 [27:49:55<13:29:31, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120509.94lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104823.05lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8525
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8525/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8525/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8500] due to args.save_total_limit
 67%|██████▋   | 8526/12750 [27:50:07<13:37:41, 11.61s/it] 67%|██████▋   | 8527/12750 [27:50:18<13:34:50, 11.58s/it] 67%|██████▋   | 8528/12750 [27:50:37<16:14:36, 13.85s/it] 67%|██████▋   | 8529/12750 [27:50:49<15:25:46, 13.16s/it] 67%|██████▋   | 8530/12750 [27:51:00<14:50:39, 12.66s/it] 67%|██████▋   | 8531/12750 [27:51:12<14:25:45, 12.31s/it] 67%|██████▋   | 8532/12750 [27:51:23<14:08:34, 12.07s/it] 67%|██████▋   | 8533/12750 [27:51:35<13:56:23, 11.90s/it] 67%|██████▋   | 8534/12750 [27:51:46<13:47:29, 11.78s/it] 67%|██████▋   | 8535/12750 [27:51:58<13:41:23, 11.69s/it] 67%|██████▋   | 8536/12750 [27:52:09<13:36:52, 11.63s/it] 67%|██████▋   | 8537/12750 [27:52:21<13:33:42, 11.59s/it] 67%|██████▋   | 8538/12750 [27:52:32<13:31:12, 11.56s/it] 67%|██████▋   | 8539/12750 [27:52:44<13:29:51, 11.54s/it] 67%|██████▋   | 8540/12750 [27:52:55<13:28:19, 11.52s/it] 67%|██████▋   | 8541/12750 [27:53:07<13:27:25, 11.51s/it] 67%|██████▋   | 8542/12750 [27:53:18<13:27:02, 11.51s/it] 67%|██████▋   | 8543/12750 [27:53:30<13:27:01, 11.51s/it] 67%|██████▋   | 8544/12750 [27:53:41<13:27:18, 11.52s/it] 67%|██████▋   | 8545/12750 [27:53:53<13:26:49, 11.51s/it] 67%|██████▋   | 8546/12750 [27:54:04<13:25:53, 11.50s/it] 67%|██████▋   | 8547/12750 [27:54:16<13:25:00, 11.49s/it] 67%|██████▋   | 8548/12750 [27:54:27<13:24:47, 11.49s/it] 67%|██████▋   | 8549/12750 [27:54:39<13:24:38, 11.49s/it] 67%|██████▋   | 8550/12750 [27:54:50<13:25:25, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120631.12lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104975.31lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8550
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8550/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8550/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8525] due to args.save_total_limit
 67%|██████▋   | 8551/12750 [27:55:02<13:31:39, 11.60s/it] 67%|██████▋   | 8552/12750 [27:55:14<13:29:08, 11.56s/it] 67%|██████▋   | 8553/12750 [27:55:25<13:27:41, 11.55s/it] 67%|██████▋   | 8554/12750 [27:55:37<13:26:09, 11.53s/it] 67%|██████▋   | 8555/12750 [27:55:48<13:25:22, 11.52s/it] 67%|██████▋   | 8556/12750 [27:56:00<13:24:08, 11.50s/it] 67%|██████▋   | 8557/12750 [27:56:11<13:22:38, 11.49s/it] 67%|██████▋   | 8558/12750 [27:56:23<13:22:21, 11.48s/it] 67%|██████▋   | 8559/12750 [27:56:34<13:22:17, 11.49s/it] 67%|██████▋   | 8560/12750 [27:56:53<16:07:03, 13.85s/it] 67%|██████▋   | 8561/12750 [27:57:05<15:18:14, 13.15s/it] 67%|██████▋   | 8562/12750 [27:57:16<14:42:52, 12.65s/it] 67%|██████▋   | 8563/12750 [27:57:28<14:17:53, 12.29s/it] 67%|██████▋   | 8564/12750 [27:57:39<14:00:29, 12.05s/it] 67%|██████▋   | 8565/12750 [27:57:51<13:49:10, 11.89s/it] 67%|██████▋   | 8566/12750 [27:58:02<13:40:20, 11.76s/it] 67%|██████▋   | 8567/12750 [27:58:14<13:34:47, 11.69s/it] 67%|██████▋   | 8568/12750 [27:58:25<13:30:49, 11.63s/it] 67%|██████▋   | 8569/12750 [27:58:37<13:28:18, 11.60s/it] 67%|██████▋   | 8570/12750 [27:58:48<13:25:42, 11.57s/it] 67%|██████▋   | 8571/12750 [27:59:00<13:24:05, 11.54s/it] 67%|██████▋   | 8572/12750 [27:59:11<13:22:53, 11.53s/it] 67%|██████▋   | 8573/12750 [27:59:23<13:21:10, 11.51s/it] 67%|██████▋   | 8574/12750 [27:59:34<13:20:29, 11.50s/it] 67%|██████▋   | 8575/12750 [27:59:46<13:20:43, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120632.15lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104913.07lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8575
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8575/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8575/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8550] due to args.save_total_limit
 67%|██████▋   | 8576/12750 [27:59:58<13:26:42, 11.60s/it] 67%|██████▋   | 8577/12750 [28:00:09<13:24:19, 11.56s/it] 67%|██████▋   | 8578/12750 [28:00:21<13:23:03, 11.55s/it] 67%|██████▋   | 8579/12750 [28:00:32<13:20:55, 11.52s/it] 67%|██████▋   | 8580/12750 [28:00:44<13:20:34, 11.52s/it] 67%|██████▋   | 8581/12750 [28:00:55<13:20:23, 11.52s/it] 67%|██████▋   | 8582/12750 [28:01:07<13:19:38, 11.51s/it] 67%|██████▋   | 8583/12750 [28:01:18<13:19:13, 11.51s/it] 67%|██████▋   | 8584/12750 [28:01:30<13:18:45, 11.50s/it] 67%|██████▋   | 8585/12750 [28:01:41<13:18:40, 11.51s/it] 67%|██████▋   | 8586/12750 [28:01:53<13:18:06, 11.50s/it] 67%|██████▋   | 8587/12750 [28:02:04<13:18:04, 11.50s/it] 67%|██████▋   | 8588/12750 [28:02:16<13:17:31, 11.50s/it] 67%|██████▋   | 8589/12750 [28:02:27<13:17:42, 11.50s/it] 67%|██████▋   | 8590/12750 [28:02:39<13:17:13, 11.50s/it] 67%|██████▋   | 8591/12750 [28:02:50<13:17:37, 11.51s/it] 67%|██████▋   | 8592/12750 [28:03:09<15:44:39, 13.63s/it] 67%|██████▋   | 8593/12750 [28:03:20<14:59:59, 12.99s/it] 67%|██████▋   | 8594/12750 [28:03:32<14:29:13, 12.55s/it] 67%|██████▋   | 8595/12750 [28:03:43<14:07:39, 12.24s/it] 67%|██████▋   | 8596/12750 [28:03:55<13:51:31, 12.01s/it] 67%|██████▋   | 8597/12750 [28:04:06<13:41:07, 11.86s/it] 67%|██████▋   | 8598/12750 [28:04:18<13:33:32, 11.76s/it] 67%|██████▋   | 8599/12750 [28:04:29<13:27:29, 11.67s/it] 67%|██████▋   | 8600/12750 [28:04:41<13:23:38, 11.62s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120594.39lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104902.28lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8600
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8600/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8600/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8575] due to args.save_total_limit
 67%|██████▋   | 8601/12750 [28:04:53<13:28:16, 11.69s/it] 67%|██████▋   | 8602/12750 [28:05:04<13:23:45, 11.63s/it] 67%|██████▋   | 8603/12750 [28:05:16<13:20:26, 11.58s/it] 67%|██████▋   | 8604/12750 [28:05:27<13:18:39, 11.56s/it] 67%|██████▋   | 8605/12750 [28:05:39<13:17:31, 11.54s/it] 67%|██████▋   | 8606/12750 [28:05:50<13:15:50, 11.52s/it] 68%|██████▊   | 8607/12750 [28:06:01<13:14:48, 11.51s/it] 68%|██████▊   | 8608/12750 [28:06:13<13:14:09, 11.50s/it] 68%|██████▊   | 8609/12750 [28:06:24<13:13:52, 11.50s/it] 68%|██████▊   | 8610/12750 [28:06:36<13:13:19, 11.50s/it] 68%|██████▊   | 8611/12750 [28:06:47<13:12:31, 11.49s/it] 68%|██████▊   | 8612/12750 [28:06:59<13:12:22, 11.49s/it] 68%|██████▊   | 8613/12750 [28:07:10<13:11:51, 11.48s/it] 68%|██████▊   | 8614/12750 [28:07:22<13:12:09, 11.49s/it] 68%|██████▊   | 8615/12750 [28:07:33<13:11:47, 11.49s/it] 68%|██████▊   | 8616/12750 [28:07:45<13:12:00, 11.50s/it] 68%|██████▊   | 8617/12750 [28:07:56<13:12:09, 11.50s/it] 68%|██████▊   | 8618/12750 [28:08:08<13:12:00, 11.50s/it] 68%|██████▊   | 8619/12750 [28:08:19<13:12:11, 11.51s/it] 68%|██████▊   | 8620/12750 [28:08:31<13:11:59, 11.51s/it] 68%|██████▊   | 8621/12750 [28:08:42<13:12:01, 11.51s/it] 68%|██████▊   | 8622/12750 [28:08:54<13:14:33, 11.55s/it] 68%|██████▊   | 8623/12750 [28:09:06<13:13:44, 11.54s/it] 68%|██████▊   | 8624/12750 [28:09:17<13:12:50, 11.53s/it] 68%|██████▊   | 8625/12750 [28:09:36<15:53:11, 13.86s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120609.41lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104633.22lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8625
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8625/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8625/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8600] due to args.save_total_limit
 68%|██████▊   | 8626/12750 [28:09:48<15:10:20, 13.24s/it] 68%|██████▊   | 8627/12750 [28:10:00<14:33:55, 12.72s/it] 68%|██████▊   | 8628/12750 [28:10:11<14:08:43, 12.35s/it] 68%|██████▊   | 8629/12750 [28:10:23<13:51:24, 12.10s/it] 68%|██████▊   | 8630/12750 [28:10:34<13:39:03, 11.93s/it] 68%|██████▊   | 8631/12750 [28:10:46<13:30:34, 11.81s/it] 68%|██████▊   | 8632/12750 [28:10:57<13:24:42, 11.72s/it] 68%|██████▊   | 8633/12750 [28:11:09<13:20:32, 11.67s/it] 68%|██████▊   | 8634/12750 [28:11:20<13:17:54, 11.63s/it] 68%|██████▊   | 8635/12750 [28:11:32<13:15:46, 11.60s/it] 68%|██████▊   | 8636/12750 [28:11:43<13:14:04, 11.58s/it] 68%|██████▊   | 8637/12750 [28:11:55<13:12:56, 11.57s/it] 68%|██████▊   | 8638/12750 [28:12:07<13:11:19, 11.55s/it] 68%|██████▊   | 8639/12750 [28:12:18<13:10:33, 11.54s/it] 68%|██████▊   | 8640/12750 [28:12:30<13:09:50, 11.53s/it] 68%|██████▊   | 8641/12750 [28:12:41<13:10:01, 11.54s/it] 68%|██████▊   | 8642/12750 [28:12:53<13:09:44, 11.53s/it] 68%|██████▊   | 8643/12750 [28:13:04<13:09:15, 11.53s/it] 68%|██████▊   | 8644/12750 [28:13:16<13:08:09, 11.52s/it] 68%|██████▊   | 8645/12750 [28:13:27<13:07:52, 11.52s/it] 68%|██████▊   | 8646/12750 [28:13:39<13:06:44, 11.50s/it] 68%|██████▊   | 8647/12750 [28:13:50<13:06:36, 11.50s/it] 68%|██████▊   | 8648/12750 [28:14:02<13:06:02, 11.50s/it] 68%|██████▊   | 8649/12750 [28:14:13<13:06:23, 11.51s/it] 68%|██████▊   | 8650/12750 [28:14:25<13:06:49, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120576.15lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104884.02lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8650
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8650/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8650/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8625] due to args.save_total_limit
 68%|██████▊   | 8651/12750 [28:14:36<13:13:02, 11.61s/it] 68%|██████▊   | 8652/12750 [28:14:48<13:10:46, 11.58s/it] 68%|██████▊   | 8653/12750 [28:15:00<13:09:27, 11.56s/it] 68%|██████▊   | 8654/12750 [28:15:11<13:08:55, 11.56s/it] 68%|██████▊   | 8655/12750 [28:15:23<13:08:17, 11.55s/it] 68%|██████▊   | 8656/12750 [28:15:34<13:06:33, 11.53s/it] 68%|██████▊   | 8657/12750 [28:15:53<15:43:48, 13.84s/it] 68%|██████▊   | 8658/12750 [28:16:05<14:56:55, 13.15s/it] 68%|██████▊   | 8659/12750 [28:16:16<14:23:17, 12.66s/it] 68%|██████▊   | 8660/12750 [28:16:28<13:59:55, 12.32s/it] 68%|██████▊   | 8661/12750 [28:16:39<13:43:15, 12.08s/it] 68%|██████▊   | 8662/12750 [28:16:51<13:31:30, 11.91s/it] 68%|██████▊   | 8663/12750 [28:17:02<13:23:51, 11.80s/it] 68%|██████▊   | 8664/12750 [28:17:14<13:18:09, 11.72s/it] 68%|██████▊   | 8665/12750 [28:17:26<13:13:52, 11.66s/it] 68%|██████▊   | 8666/12750 [28:17:37<13:11:15, 11.62s/it] 68%|██████▊   | 8667/12750 [28:17:49<13:09:22, 11.60s/it] 68%|██████▊   | 8668/12750 [28:18:00<13:07:46, 11.58s/it] 68%|██████▊   | 8669/12750 [28:18:07<11:35:39, 10.23s/it] 68%|██████▊   | 8670/12750 [28:18:08<8:22:57,  7.40s/it]  68%|██████▊   | 8671/12750 [28:18:31<13:46:11, 12.15s/it] 68%|██████▊   | 8672/12750 [28:18:43<13:33:06, 11.96s/it] 68%|██████▊   | 8673/12750 [28:18:54<13:24:14, 11.84s/it] 68%|██████▊   | 8674/12750 [28:19:06<13:17:38, 11.74s/it] 68%|██████▊   | 8675/12750 [28:19:17<13:13:21, 11.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120734.53lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 105001.20lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8675
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8675/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8675/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8650] due to args.save_total_limit
 68%|██████▊   | 8676/12750 [28:19:29<13:16:35, 11.73s/it] 68%|██████▊   | 8677/12750 [28:19:41<13:11:29, 11.66s/it] 68%|██████▊   | 8678/12750 [28:19:52<13:08:23, 11.62s/it] 68%|██████▊   | 8679/12750 [28:20:04<13:06:12, 11.59s/it] 68%|██████▊   | 8680/12750 [28:20:15<13:05:22, 11.58s/it] 68%|██████▊   | 8681/12750 [28:20:27<13:03:34, 11.55s/it] 68%|██████▊   | 8682/12750 [28:20:38<13:02:36, 11.54s/it] 68%|██████▊   | 8683/12750 [28:20:50<13:02:30, 11.54s/it] 68%|██████▊   | 8684/12750 [28:21:01<13:01:16, 11.53s/it] 68%|██████▊   | 8685/12750 [28:21:13<13:00:36, 11.52s/it] 68%|██████▊   | 8686/12750 [28:21:24<13:00:03, 11.52s/it] 68%|██████▊   | 8687/12750 [28:21:36<13:00:14, 11.52s/it] 68%|██████▊   | 8688/12750 [28:21:47<12:59:43, 11.52s/it] 68%|██████▊   | 8689/12750 [28:22:07<15:34:47, 13.81s/it] 68%|██████▊   | 8690/12750 [28:22:18<14:48:10, 13.13s/it] 68%|██████▊   | 8691/12750 [28:22:30<14:15:16, 12.64s/it] 68%|██████▊   | 8692/12750 [28:22:41<13:52:23, 12.31s/it] 68%|██████▊   | 8693/12750 [28:22:53<13:36:30, 12.08s/it] 68%|██████▊   | 8694/12750 [28:23:04<13:25:20, 11.91s/it] 68%|██████▊   | 8695/12750 [28:23:16<13:16:41, 11.79s/it] 68%|██████▊   | 8696/12750 [28:23:27<13:11:00, 11.71s/it] 68%|██████▊   | 8697/12750 [28:23:39<13:07:15, 11.65s/it] 68%|██████▊   | 8698/12750 [28:23:50<13:04:42, 11.62s/it] 68%|██████▊   | 8699/12750 [28:24:02<13:03:01, 11.60s/it] 68%|██████▊   | 8700/12750 [28:24:13<13:01:06, 11.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120545.99lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104850.80lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8700
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8700/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8700/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8675] due to args.save_total_limit
 68%|██████▊   | 8701/12750 [28:24:25<13:05:57, 11.65s/it] 68%|██████▊   | 8702/12750 [28:24:37<13:02:31, 11.60s/it] 68%|██████▊   | 8703/12750 [28:24:48<13:00:04, 11.57s/it] 68%|██████▊   | 8704/12750 [28:25:00<12:58:15, 11.54s/it] 68%|██████▊   | 8705/12750 [28:25:11<12:57:44, 11.54s/it] 68%|██████▊   | 8706/12750 [28:25:23<12:56:31, 11.52s/it] 68%|██████▊   | 8707/12750 [28:25:34<12:55:40, 11.51s/it] 68%|██████▊   | 8708/12750 [28:25:46<12:55:20, 11.51s/it] 68%|██████▊   | 8709/12750 [28:25:57<12:54:53, 11.51s/it] 68%|██████▊   | 8710/12750 [28:26:09<12:54:47, 11.51s/it] 68%|██████▊   | 8711/12750 [28:26:20<12:54:59, 11.51s/it] 68%|██████▊   | 8712/12750 [28:26:32<12:54:22, 11.51s/it] 68%|██████▊   | 8713/12750 [28:26:43<12:54:29, 11.51s/it] 68%|██████▊   | 8714/12750 [28:26:55<12:54:23, 11.51s/it] 68%|██████▊   | 8715/12750 [28:27:06<12:54:35, 11.52s/it] 68%|██████▊   | 8716/12750 [28:27:18<12:54:01, 11.51s/it] 68%|██████▊   | 8717/12750 [28:27:29<12:53:39, 11.51s/it] 68%|██████▊   | 8718/12750 [28:27:41<12:53:01, 11.50s/it] 68%|██████▊   | 8719/12750 [28:27:52<12:52:42, 11.50s/it] 68%|██████▊   | 8720/12750 [28:28:04<12:52:39, 11.50s/it] 68%|██████▊   | 8721/12750 [28:28:23<15:26:40, 13.80s/it] 68%|██████▊   | 8722/12750 [28:28:34<14:40:25, 13.11s/it] 68%|██████▊   | 8723/12750 [28:28:46<14:07:59, 12.63s/it] 68%|██████▊   | 8724/12750 [28:28:57<13:45:13, 12.30s/it] 68%|██████▊   | 8725/12750 [28:29:09<13:29:14, 12.06s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120619.69lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104802.29lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8725
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8725/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8725/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8700] due to args.save_total_limit
 68%|██████▊   | 8726/12750 [28:29:21<13:24:39, 12.00s/it] 68%|██████▊   | 8727/12750 [28:29:32<13:15:13, 11.86s/it] 68%|██████▊   | 8728/12750 [28:29:44<13:07:46, 11.75s/it] 68%|██████▊   | 8729/12750 [28:29:55<13:02:52, 11.68s/it] 68%|██████▊   | 8730/12750 [28:30:07<12:59:32, 11.63s/it] 68%|██████▊   | 8731/12750 [28:30:18<12:56:16, 11.59s/it] 68%|██████▊   | 8732/12750 [28:30:30<12:53:42, 11.55s/it] 68%|██████▊   | 8733/12750 [28:30:41<12:52:25, 11.54s/it] 69%|██████▊   | 8734/12750 [28:30:53<12:51:55, 11.53s/it] 69%|██████▊   | 8735/12750 [28:31:04<12:51:23, 11.53s/it] 69%|██████▊   | 8736/12750 [28:31:16<12:50:52, 11.52s/it] 69%|██████▊   | 8737/12750 [28:31:27<12:50:35, 11.52s/it] 69%|██████▊   | 8738/12750 [28:31:39<12:49:51, 11.51s/it] 69%|██████▊   | 8739/12750 [28:31:50<12:49:45, 11.51s/it] 69%|██████▊   | 8740/12750 [28:32:02<12:49:20, 11.51s/it] 69%|██████▊   | 8741/12750 [28:32:13<12:48:59, 11.51s/it] 69%|██████▊   | 8742/12750 [28:32:25<12:49:13, 11.52s/it] 69%|██████▊   | 8743/12750 [28:32:36<12:48:49, 11.51s/it] 69%|██████▊   | 8744/12750 [28:32:48<12:48:15, 11.51s/it] 69%|██████▊   | 8745/12750 [28:32:59<12:47:21, 11.50s/it] 69%|██████▊   | 8746/12750 [28:33:11<12:46:41, 11.49s/it] 69%|██████▊   | 8747/12750 [28:33:22<12:46:34, 11.49s/it] 69%|██████▊   | 8748/12750 [28:33:34<12:46:18, 11.49s/it] 69%|██████▊   | 8749/12750 [28:33:45<12:46:32, 11.50s/it] 69%|██████▊   | 8750/12750 [28:33:57<12:46:39, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120611.98lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104953.32lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8750
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8750/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8750/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8725] due to args.save_total_limit
 69%|██████▊   | 8751/12750 [28:34:09<12:52:07, 11.58s/it] 69%|██████▊   | 8752/12750 [28:34:20<12:50:00, 11.56s/it] 69%|██████▊   | 8753/12750 [28:34:32<12:48:50, 11.54s/it] 69%|██████▊   | 8754/12750 [28:34:51<15:22:58, 13.86s/it] 69%|██████▊   | 8755/12750 [28:35:02<14:36:03, 13.16s/it] 69%|██████▊   | 8756/12750 [28:35:14<14:03:13, 12.67s/it] 69%|██████▊   | 8757/12750 [28:35:25<13:39:39, 12.32s/it] 69%|██████▊   | 8758/12750 [28:35:37<13:23:49, 12.08s/it] 69%|██████▊   | 8759/12750 [28:35:49<13:12:45, 11.92s/it] 69%|██████▊   | 8760/12750 [28:36:00<13:04:25, 11.80s/it] 69%|██████▊   | 8761/12750 [28:36:12<12:58:38, 11.71s/it] 69%|██████▊   | 8762/12750 [28:36:23<12:55:11, 11.66s/it] 69%|██████▊   | 8763/12750 [28:36:35<12:52:07, 11.62s/it] 69%|██████▊   | 8764/12750 [28:36:46<12:50:13, 11.59s/it] 69%|██████▊   | 8765/12750 [28:36:58<12:49:25, 11.58s/it] 69%|██████▉   | 8766/12750 [28:37:09<12:47:50, 11.56s/it] 69%|██████▉   | 8767/12750 [28:37:21<12:46:46, 11.55s/it] 69%|██████▉   | 8768/12750 [28:37:32<12:46:18, 11.55s/it] 69%|██████▉   | 8769/12750 [28:37:44<12:45:14, 11.53s/it] 69%|██████▉   | 8770/12750 [28:37:55<12:45:39, 11.54s/it] 69%|██████▉   | 8771/12750 [28:38:07<12:45:27, 11.54s/it] 69%|██████▉   | 8772/12750 [28:38:18<12:44:42, 11.53s/it] 69%|██████▉   | 8773/12750 [28:38:30<12:43:48, 11.52s/it] 69%|██████▉   | 8774/12750 [28:38:41<12:43:23, 11.52s/it] 69%|██████▉   | 8775/12750 [28:38:53<12:43:14, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120587.58lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104835.08lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8775
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8775/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8775/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8750] due to args.save_total_limit
 69%|██████▉   | 8776/12750 [28:39:05<12:49:30, 11.62s/it] 69%|██████▉   | 8777/12750 [28:39:16<12:47:21, 11.59s/it] 69%|██████▉   | 8778/12750 [28:39:28<12:45:58, 11.57s/it] 69%|██████▉   | 8779/12750 [28:39:39<12:43:56, 11.54s/it] 69%|██████▉   | 8780/12750 [28:39:51<12:43:36, 11.54s/it] 69%|██████▉   | 8781/12750 [28:40:02<12:42:44, 11.53s/it] 69%|██████▉   | 8782/12750 [28:40:14<12:41:55, 11.52s/it] 69%|██████▉   | 8783/12750 [28:40:25<12:41:46, 11.52s/it] 69%|██████▉   | 8784/12750 [28:40:37<12:41:20, 11.52s/it] 69%|██████▉   | 8785/12750 [28:40:48<12:40:26, 11.51s/it] 69%|██████▉   | 8786/12750 [28:41:07<14:54:13, 13.54s/it] 69%|██████▉   | 8787/12750 [28:41:18<14:13:46, 12.93s/it] 69%|██████▉   | 8788/12750 [28:41:30<13:45:22, 12.50s/it] 69%|██████▉   | 8789/12750 [28:41:41<13:25:59, 12.21s/it] 69%|██████▉   | 8790/12750 [28:41:53<13:11:29, 11.99s/it] 69%|██████▉   | 8791/12750 [28:42:04<13:01:38, 11.85s/it] 69%|██████▉   | 8792/12750 [28:42:16<12:54:46, 11.74s/it] 69%|██████▉   | 8793/12750 [28:42:27<12:49:57, 11.68s/it] 69%|██████▉   | 8794/12750 [28:42:39<12:46:19, 11.62s/it] 69%|██████▉   | 8795/12750 [28:42:50<12:44:01, 11.59s/it] 69%|██████▉   | 8796/12750 [28:43:02<12:42:32, 11.57s/it] 69%|██████▉   | 8797/12750 [28:43:13<12:40:57, 11.55s/it] 69%|██████▉   | 8798/12750 [28:43:25<12:39:37, 11.53s/it] 69%|██████▉   | 8799/12750 [28:43:36<12:38:55, 11.53s/it] 69%|██████▉   | 8800/12750 [28:43:48<12:37:38, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120623.93lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104634.09lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8800
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8800/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8800/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8775] due to args.save_total_limit
 69%|██████▉   | 8801/12750 [28:44:00<12:44:02, 11.61s/it] 69%|██████▉   | 8802/12750 [28:44:11<12:42:07, 11.58s/it] 69%|██████▉   | 8803/12750 [28:44:23<12:40:47, 11.57s/it] 69%|██████▉   | 8804/12750 [28:44:34<12:39:17, 11.55s/it] 69%|██████▉   | 8805/12750 [28:44:46<12:38:12, 11.53s/it] 69%|██████▉   | 8806/12750 [28:44:57<12:37:22, 11.52s/it] 69%|██████▉   | 8807/12750 [28:45:09<12:37:01, 11.52s/it] 69%|██████▉   | 8808/12750 [28:45:20<12:37:32, 11.53s/it] 69%|██████▉   | 8809/12750 [28:45:32<12:37:24, 11.53s/it] 69%|██████▉   | 8810/12750 [28:45:43<12:37:42, 11.54s/it] 69%|██████▉   | 8811/12750 [28:45:55<12:36:20, 11.52s/it] 69%|██████▉   | 8812/12750 [28:46:06<12:36:18, 11.52s/it] 69%|██████▉   | 8813/12750 [28:46:18<12:34:56, 11.51s/it] 69%|██████▉   | 8814/12750 [28:46:29<12:35:05, 11.51s/it] 69%|██████▉   | 8815/12750 [28:46:41<12:36:22, 11.53s/it] 69%|██████▉   | 8816/12750 [28:46:52<12:36:04, 11.53s/it] 69%|██████▉   | 8817/12750 [28:47:04<12:35:46, 11.53s/it] 69%|██████▉   | 8818/12750 [28:47:24<15:19:57, 14.04s/it] 69%|██████▉   | 8819/12750 [28:47:35<14:30:19, 13.28s/it] 69%|██████▉   | 8820/12750 [28:47:47<13:55:29, 12.76s/it] 69%|██████▉   | 8821/12750 [28:47:58<13:31:03, 12.39s/it] 69%|██████▉   | 8822/12750 [28:48:10<13:13:31, 12.12s/it] 69%|██████▉   | 8823/12750 [28:48:21<13:02:04, 11.95s/it] 69%|██████▉   | 8824/12750 [28:48:33<12:52:54, 11.81s/it] 69%|██████▉   | 8825/12750 [28:48:44<12:46:32, 11.72s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120563.96lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104670.55lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8825
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8825/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8825/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8800] due to args.save_total_limit
 69%|██████▉   | 8826/12750 [28:48:56<12:48:33, 11.75s/it] 69%|██████▉   | 8827/12750 [28:49:08<12:43:05, 11.67s/it] 69%|██████▉   | 8828/12750 [28:49:19<12:40:20, 11.63s/it] 69%|██████▉   | 8829/12750 [28:49:31<12:37:51, 11.60s/it] 69%|██████▉   | 8830/12750 [28:49:42<12:36:18, 11.58s/it] 69%|██████▉   | 8831/12750 [28:49:54<12:34:52, 11.56s/it] 69%|██████▉   | 8832/12750 [28:50:05<12:33:57, 11.55s/it] 69%|██████▉   | 8833/12750 [28:50:17<12:33:04, 11.54s/it] 69%|██████▉   | 8834/12750 [28:50:28<12:32:13, 11.53s/it] 69%|██████▉   | 8835/12750 [28:50:40<12:31:53, 11.52s/it] 69%|██████▉   | 8836/12750 [28:50:51<12:32:25, 11.53s/it] 69%|██████▉   | 8837/12750 [28:51:03<12:32:20, 11.54s/it] 69%|██████▉   | 8838/12750 [28:51:15<12:34:02, 11.57s/it] 69%|██████▉   | 8839/12750 [28:51:26<12:34:08, 11.57s/it] 69%|██████▉   | 8840/12750 [28:51:38<12:34:28, 11.58s/it] 69%|██████▉   | 8841/12750 [28:51:49<12:34:47, 11.59s/it] 69%|██████▉   | 8842/12750 [28:52:01<12:34:49, 11.59s/it] 69%|██████▉   | 8843/12750 [28:52:13<12:34:47, 11.59s/it] 69%|██████▉   | 8844/12750 [28:52:24<12:33:47, 11.58s/it] 69%|██████▉   | 8845/12750 [28:52:36<12:32:59, 11.57s/it] 69%|██████▉   | 8846/12750 [28:52:47<12:32:49, 11.57s/it] 69%|██████▉   | 8847/12750 [28:52:59<12:32:44, 11.57s/it] 69%|██████▉   | 8848/12750 [28:53:10<12:33:34, 11.59s/it] 69%|██████▉   | 8849/12750 [28:53:22<12:34:02, 11.60s/it] 69%|██████▉   | 8850/12750 [28:53:41<14:48:18, 13.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 117035.71lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 102139.18lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8850
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8850/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8850/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8050] due to args.save_total_limit
 69%|██████▉   | 8851/12750 [28:53:52<14:13:55, 13.14s/it] 69%|██████▉   | 8852/12750 [28:54:04<13:42:52, 12.67s/it] 69%|██████▉   | 8853/12750 [28:54:16<13:21:41, 12.34s/it] 69%|██████▉   | 8854/12750 [28:54:27<13:06:40, 12.12s/it] 69%|██████▉   | 8855/12750 [28:54:39<12:56:28, 11.96s/it] 69%|██████▉   | 8856/12750 [28:54:50<12:49:32, 11.86s/it] 69%|██████▉   | 8857/12750 [28:55:02<12:43:46, 11.77s/it] 69%|██████▉   | 8858/12750 [28:55:14<12:40:18, 11.72s/it] 69%|██████▉   | 8859/12750 [28:55:25<12:37:06, 11.67s/it] 69%|██████▉   | 8860/12750 [28:55:37<12:34:46, 11.64s/it] 69%|██████▉   | 8861/12750 [28:55:48<12:32:52, 11.62s/it] 70%|██████▉   | 8862/12750 [28:56:00<12:32:09, 11.61s/it] 70%|██████▉   | 8863/12750 [28:56:11<12:32:01, 11.61s/it] 70%|██████▉   | 8864/12750 [28:56:23<12:31:23, 11.60s/it] 70%|██████▉   | 8865/12750 [28:56:35<12:30:31, 11.59s/it] 70%|██████▉   | 8866/12750 [28:56:46<12:30:17, 11.59s/it] 70%|██████▉   | 8867/12750 [28:56:58<12:29:56, 11.59s/it] 70%|██████▉   | 8868/12750 [28:57:09<12:29:55, 11.59s/it] 70%|██████▉   | 8869/12750 [28:57:21<12:29:41, 11.59s/it] 70%|██████▉   | 8870/12750 [28:57:33<12:29:40, 11.59s/it] 70%|██████▉   | 8871/12750 [28:57:44<12:28:52, 11.58s/it] 70%|██████▉   | 8872/12750 [28:57:56<12:29:01, 11.59s/it] 70%|██████▉   | 8873/12750 [28:58:07<12:29:07, 11.59s/it] 70%|██████▉   | 8874/12750 [28:58:19<12:28:49, 11.59s/it] 70%|██████▉   | 8875/12750 [28:58:30<12:27:39, 11.58s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120573.84lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104917.54lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8875
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8875/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8875/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8825] due to args.save_total_limit
 70%|██████▉   | 8876/12750 [28:58:42<12:33:58, 11.68s/it] 70%|██████▉   | 8877/12750 [28:58:54<12:31:28, 11.64s/it] 70%|██████▉   | 8878/12750 [28:59:06<12:29:44, 11.62s/it] 70%|██████▉   | 8879/12750 [28:59:17<12:29:14, 11.61s/it] 70%|██████▉   | 8880/12750 [28:59:29<12:27:37, 11.59s/it] 70%|██████▉   | 8881/12750 [28:59:40<12:27:06, 11.59s/it] 70%|██████▉   | 8882/12750 [28:59:59<14:39:00, 13.64s/it] 70%|██████▉   | 8883/12750 [29:00:10<13:59:06, 13.02s/it] 70%|██████▉   | 8884/12750 [29:00:22<13:31:18, 12.59s/it] 70%|██████▉   | 8885/12750 [29:00:33<13:11:13, 12.28s/it] 70%|██████▉   | 8886/12750 [29:00:45<12:57:54, 12.08s/it] 70%|██████▉   | 8887/12750 [29:00:57<12:48:25, 11.94s/it] 70%|██████▉   | 8888/12750 [29:01:08<12:42:11, 11.84s/it] 70%|██████▉   | 8889/12750 [29:01:20<12:36:45, 11.76s/it] 70%|██████▉   | 8890/12750 [29:01:31<12:33:38, 11.71s/it] 70%|██████▉   | 8891/12750 [29:01:43<12:31:20, 11.68s/it] 70%|██████▉   | 8892/12750 [29:01:55<12:29:14, 11.65s/it] 70%|██████▉   | 8893/12750 [29:02:06<12:27:06, 11.62s/it] 70%|██████▉   | 8894/12750 [29:02:18<12:25:58, 11.61s/it] 70%|██████▉   | 8895/12750 [29:02:29<12:25:59, 11.61s/it] 70%|██████▉   | 8896/12750 [29:02:41<12:24:50, 11.60s/it] 70%|██████▉   | 8897/12750 [29:02:52<12:24:33, 11.59s/it] 70%|██████▉   | 8898/12750 [29:03:04<12:25:01, 11.60s/it] 70%|██████▉   | 8899/12750 [29:03:16<12:26:32, 11.63s/it] 70%|██████▉   | 8900/12750 [29:03:27<12:24:22, 11.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120636.26lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104864.30lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8900
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8900/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8900/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8875] due to args.save_total_limit
 70%|██████▉   | 8901/12750 [29:03:39<12:29:54, 11.69s/it] 70%|██████▉   | 8902/12750 [29:03:51<12:27:39, 11.66s/it] 70%|██████▉   | 8903/12750 [29:04:02<12:24:46, 11.62s/it] 70%|██████▉   | 8904/12750 [29:04:14<12:24:04, 11.61s/it] 70%|██████▉   | 8905/12750 [29:04:25<12:23:07, 11.60s/it] 70%|██████▉   | 8906/12750 [29:04:37<12:22:15, 11.59s/it] 70%|██████▉   | 8907/12750 [29:04:49<12:22:00, 11.58s/it] 70%|██████▉   | 8908/12750 [29:05:00<12:22:26, 11.59s/it] 70%|██████▉   | 8909/12750 [29:05:12<12:22:11, 11.59s/it] 70%|██████▉   | 8910/12750 [29:05:23<12:21:48, 11.59s/it] 70%|██████▉   | 8911/12750 [29:05:35<12:21:28, 11.59s/it] 70%|██████▉   | 8912/12750 [29:05:47<12:21:05, 11.59s/it] 70%|██████▉   | 8913/12750 [29:05:58<12:20:28, 11.58s/it] 70%|██████▉   | 8914/12750 [29:06:17<14:39:13, 13.75s/it] 70%|██████▉   | 8915/12750 [29:06:29<13:57:07, 13.10s/it] 70%|██████▉   | 8916/12750 [29:06:40<13:27:17, 12.63s/it] 70%|██████▉   | 8917/12750 [29:06:52<13:06:43, 12.31s/it] 70%|██████▉   | 8918/12750 [29:07:03<12:52:10, 12.09s/it] 70%|██████▉   | 8919/12750 [29:07:15<12:42:15, 11.94s/it] 70%|██████▉   | 8920/12750 [29:07:26<12:35:14, 11.83s/it] 70%|██████▉   | 8921/12750 [29:07:38<12:29:54, 11.75s/it] 70%|██████▉   | 8922/12750 [29:07:50<12:26:11, 11.70s/it] 70%|██████▉   | 8923/12750 [29:08:01<12:23:33, 11.66s/it] 70%|██████▉   | 8924/12750 [29:08:13<12:21:32, 11.63s/it] 70%|███████   | 8925/12750 [29:08:24<12:20:04, 11.61s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120484.30lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104869.83lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8925
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8925/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8925/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8900] due to args.save_total_limit
 70%|███████   | 8926/12750 [29:08:36<12:24:48, 11.69s/it] 70%|███████   | 8927/12750 [29:08:48<12:22:32, 11.65s/it] 70%|███████   | 8928/12750 [29:08:59<12:20:39, 11.63s/it] 70%|███████   | 8929/12750 [29:09:11<12:19:04, 11.61s/it] 70%|███████   | 8930/12750 [29:09:22<12:18:08, 11.59s/it] 70%|███████   | 8931/12750 [29:09:34<12:17:18, 11.58s/it] 70%|███████   | 8932/12750 [29:09:46<12:17:31, 11.59s/it] 70%|███████   | 8933/12750 [29:09:57<12:16:07, 11.57s/it] 70%|███████   | 8934/12750 [29:10:09<12:15:55, 11.57s/it] 70%|███████   | 8935/12750 [29:10:20<12:16:54, 11.59s/it] 70%|███████   | 8936/12750 [29:10:32<12:16:07, 11.58s/it] 70%|███████   | 8937/12750 [29:10:43<12:15:50, 11.58s/it] 70%|███████   | 8938/12750 [29:10:55<12:15:28, 11.58s/it] 70%|███████   | 8939/12750 [29:11:07<12:14:55, 11.57s/it] 70%|███████   | 8940/12750 [29:11:18<12:14:29, 11.57s/it] 70%|███████   | 8941/12750 [29:11:30<12:14:26, 11.57s/it] 70%|███████   | 8942/12750 [29:11:41<12:14:13, 11.57s/it] 70%|███████   | 8943/12750 [29:11:53<12:14:06, 11.57s/it] 70%|███████   | 8944/12750 [29:12:04<12:13:38, 11.57s/it] 70%|███████   | 8945/12750 [29:12:16<12:13:15, 11.56s/it] 70%|███████   | 8946/12750 [29:12:35<14:41:01, 13.90s/it] 70%|███████   | 8947/12750 [29:12:47<13:56:16, 13.19s/it] 70%|███████   | 8948/12750 [29:12:58<13:24:54, 12.70s/it] 70%|███████   | 8949/12750 [29:13:10<13:03:13, 12.36s/it] 70%|███████   | 8950/12750 [29:13:21<12:48:00, 12.13s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120570.12lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104889.55lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8950
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8950/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8950/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8925] due to args.save_total_limit
 70%|███████   | 8951/12750 [29:13:34<12:45:54, 12.10s/it] 70%|███████   | 8952/12750 [29:13:45<12:35:29, 11.93s/it] 70%|███████   | 8953/12750 [29:13:57<12:27:48, 11.82s/it] 70%|███████   | 8954/12750 [29:14:08<12:22:31, 11.74s/it] 70%|███████   | 8955/12750 [29:14:20<12:18:41, 11.68s/it] 70%|███████   | 8956/12750 [29:14:31<12:15:22, 11.63s/it] 70%|███████   | 8957/12750 [29:14:43<12:13:45, 11.61s/it] 70%|███████   | 8958/12750 [29:14:54<12:12:27, 11.59s/it] 70%|███████   | 8959/12750 [29:15:06<12:11:42, 11.58s/it] 70%|███████   | 8960/12750 [29:15:17<12:10:40, 11.57s/it] 70%|███████   | 8961/12750 [29:15:29<12:09:25, 11.55s/it] 70%|███████   | 8962/12750 [29:15:40<12:09:03, 11.55s/it] 70%|███████   | 8963/12750 [29:15:52<12:09:14, 11.55s/it] 70%|███████   | 8964/12750 [29:16:04<12:08:58, 11.55s/it] 70%|███████   | 8965/12750 [29:16:15<12:07:17, 11.53s/it] 70%|███████   | 8966/12750 [29:16:27<12:06:19, 11.52s/it] 70%|███████   | 8967/12750 [29:16:38<12:05:12, 11.50s/it] 70%|███████   | 8968/12750 [29:16:50<12:04:54, 11.50s/it] 70%|███████   | 8969/12750 [29:17:01<12:04:38, 11.50s/it] 70%|███████   | 8970/12750 [29:17:12<12:03:39, 11.49s/it] 70%|███████   | 8971/12750 [29:17:24<12:02:50, 11.48s/it] 70%|███████   | 8972/12750 [29:17:35<12:02:23, 11.47s/it] 70%|███████   | 8973/12750 [29:17:47<12:02:13, 11.47s/it] 70%|███████   | 8974/12750 [29:17:58<12:02:10, 11.48s/it] 70%|███████   | 8975/12750 [29:18:10<12:02:03, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120624.44lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104919.97lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8975
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8975/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8975/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-8975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8950] due to args.save_total_limit
 70%|███████   | 8976/12750 [29:18:22<12:07:24, 11.56s/it] 70%|███████   | 8977/12750 [29:18:33<12:05:39, 11.54s/it] 70%|███████   | 8978/12750 [29:18:45<12:04:34, 11.53s/it] 70%|███████   | 8979/12750 [29:19:04<14:26:51, 13.79s/it] 70%|███████   | 8980/12750 [29:19:15<13:43:56, 13.11s/it] 70%|███████   | 8981/12750 [29:19:27<13:13:14, 12.63s/it] 70%|███████   | 8982/12750 [29:19:38<12:51:16, 12.28s/it] 70%|███████   | 8983/12750 [29:19:50<12:37:18, 12.06s/it] 70%|███████   | 8984/12750 [29:20:01<12:27:00, 11.90s/it] 70%|███████   | 8985/12750 [29:20:13<12:19:25, 11.78s/it] 70%|███████   | 8986/12750 [29:20:24<12:13:56, 11.70s/it] 70%|███████   | 8987/12750 [29:20:36<12:10:31, 11.65s/it] 70%|███████   | 8988/12750 [29:20:47<12:07:27, 11.60s/it] 71%|███████   | 8989/12750 [29:20:59<12:05:37, 11.58s/it] 71%|███████   | 8990/12750 [29:21:10<12:04:14, 11.56s/it] 71%|███████   | 8991/12750 [29:21:22<12:02:20, 11.53s/it] 71%|███████   | 8992/12750 [29:21:33<12:00:56, 11.51s/it] 71%|███████   | 8993/12750 [29:21:45<12:00:49, 11.51s/it] 71%|███████   | 8994/12750 [29:21:56<11:59:28, 11.49s/it] 71%|███████   | 8995/12750 [29:22:08<11:58:59, 11.49s/it] 71%|███████   | 8996/12750 [29:22:19<11:59:30, 11.50s/it] 71%|███████   | 8997/12750 [29:22:31<11:59:40, 11.51s/it] 71%|███████   | 8998/12750 [29:22:42<11:58:53, 11.50s/it] 71%|███████   | 8999/12750 [29:22:54<11:58:43, 11.50s/it] 71%|███████   | 9000/12750 [29:23:05<11:58:10, 11.49s/it]                                                           71%|███████   | 9000/12750 [29:23:05<11:58:10, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120564.86lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104835.37lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9000
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9000/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9000/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8975] due to args.save_total_limit
 71%|███████   | 9001/12750 [29:23:17<12:04:54, 11.60s/it] 71%|███████   | 9002/12750 [29:23:29<12:02:41, 11.57s/it] 71%|███████   | 9003/12750 [29:23:40<12:01:19, 11.55s/it] 71%|███████   | 9004/12750 [29:23:51<11:59:27, 11.52s/it] 71%|███████   | 9005/12750 [29:24:03<11:58:19, 11.51s/it] 71%|███████   | 9006/12750 [29:24:14<11:57:23, 11.50s/it] 71%|███████   | 9007/12750 [29:24:26<12:01:24, 11.56s/it] 71%|███████   | 9008/12750 [29:24:38<11:59:50, 11.54s/it] 71%|███████   | 9009/12750 [29:24:49<11:59:19, 11.54s/it] 71%|███████   | 9010/12750 [29:25:01<11:58:19, 11.52s/it] 71%|███████   | 9011/12750 [29:25:20<14:19:48, 13.80s/it] 71%|███████   | 9012/12750 [29:25:31<13:36:34, 13.11s/it] 71%|███████   | 9013/12750 [29:25:43<13:05:44, 12.62s/it] 71%|███████   | 9014/12750 [29:25:54<12:44:38, 12.28s/it] 71%|███████   | 9015/12750 [29:26:06<12:29:28, 12.04s/it] 71%|███████   | 9016/12750 [29:26:17<12:18:45, 11.87s/it] 71%|███████   | 9017/12750 [29:26:29<12:11:34, 11.76s/it] 71%|███████   | 9018/12750 [29:26:40<12:06:45, 11.68s/it] 71%|███████   | 9019/12750 [29:26:52<12:03:10, 11.63s/it] 71%|███████   | 9020/12750 [29:27:03<12:00:37, 11.59s/it] 71%|███████   | 9021/12750 [29:27:15<11:58:40, 11.56s/it] 71%|███████   | 9022/12750 [29:27:26<11:58:04, 11.56s/it] 71%|███████   | 9023/12750 [29:27:38<11:56:48, 11.54s/it] 71%|███████   | 9024/12750 [29:27:49<11:56:08, 11.53s/it] 71%|███████   | 9025/12750 [29:28:01<11:55:31, 11.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120671.23lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104764.28lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9025
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9025/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9025/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9000] due to args.save_total_limit
 71%|███████   | 9026/12750 [29:28:13<12:00:39, 11.61s/it] 71%|███████   | 9027/12750 [29:28:24<11:57:47, 11.57s/it] 71%|███████   | 9028/12750 [29:28:36<11:56:17, 11.55s/it] 71%|███████   | 9029/12750 [29:28:47<11:55:27, 11.54s/it] 71%|███████   | 9030/12750 [29:28:59<11:54:10, 11.52s/it] 71%|███████   | 9031/12750 [29:29:10<11:53:43, 11.51s/it] 71%|███████   | 9032/12750 [29:29:22<11:53:19, 11.51s/it] 71%|███████   | 9033/12750 [29:29:33<11:52:57, 11.51s/it] 71%|███████   | 9034/12750 [29:29:45<11:53:26, 11.52s/it] 71%|███████   | 9035/12750 [29:29:56<11:52:43, 11.51s/it] 71%|███████   | 9036/12750 [29:30:08<11:52:26, 11.51s/it] 71%|███████   | 9037/12750 [29:30:19<11:52:40, 11.52s/it] 71%|███████   | 9038/12750 [29:30:31<11:52:59, 11.52s/it] 71%|███████   | 9039/12750 [29:30:42<11:52:31, 11.52s/it] 71%|███████   | 9040/12750 [29:30:54<11:51:57, 11.51s/it] 71%|███████   | 9041/12750 [29:31:05<11:51:02, 11.50s/it] 71%|███████   | 9042/12750 [29:31:17<11:50:43, 11.50s/it] 71%|███████   | 9043/12750 [29:31:36<14:12:03, 13.79s/it] 71%|███████   | 9044/12750 [29:31:47<13:31:45, 13.14s/it] 71%|███████   | 9045/12750 [29:31:59<13:01:30, 12.66s/it] 71%|███████   | 9046/12750 [29:32:10<12:39:55, 12.31s/it] 71%|███████   | 9047/12750 [29:32:22<12:25:29, 12.08s/it] 71%|███████   | 9048/12750 [29:32:33<12:14:55, 11.91s/it] 71%|███████   | 9049/12750 [29:32:45<12:07:45, 11.80s/it] 71%|███████   | 9050/12750 [29:32:57<12:04:34, 11.75s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120630.35lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104917.05lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9050
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9050/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9050/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9025] due to args.save_total_limit
 71%|███████   | 9051/12750 [29:33:08<12:05:25, 11.77s/it] 71%|███████   | 9052/12750 [29:33:20<12:00:34, 11.69s/it] 71%|███████   | 9053/12750 [29:33:31<11:57:03, 11.64s/it] 71%|███████   | 9054/12750 [29:33:43<11:55:34, 11.62s/it] 71%|███████   | 9055/12750 [29:33:55<11:52:54, 11.58s/it] 71%|███████   | 9056/12750 [29:34:06<11:52:46, 11.58s/it] 71%|███████   | 9057/12750 [29:34:18<11:50:48, 11.55s/it] 71%|███████   | 9058/12750 [29:34:29<11:49:41, 11.53s/it] 71%|███████   | 9059/12750 [29:34:41<11:48:54, 11.52s/it] 71%|███████   | 9060/12750 [29:34:52<11:48:44, 11.52s/it] 71%|███████   | 9061/12750 [29:35:04<11:47:35, 11.51s/it] 71%|███████   | 9062/12750 [29:35:15<11:47:10, 11.51s/it] 71%|███████   | 9063/12750 [29:35:27<11:46:49, 11.50s/it] 71%|███████   | 9064/12750 [29:35:38<11:46:39, 11.50s/it] 71%|███████   | 9065/12750 [29:35:50<11:46:21, 11.50s/it] 71%|███████   | 9066/12750 [29:36:01<11:46:25, 11.51s/it] 71%|███████   | 9067/12750 [29:36:13<11:45:31, 11.49s/it] 71%|███████   | 9068/12750 [29:36:24<11:45:48, 11.50s/it] 71%|███████   | 9069/12750 [29:36:36<11:46:03, 11.51s/it] 71%|███████   | 9070/12750 [29:36:47<11:45:21, 11.50s/it] 71%|███████   | 9071/12750 [29:36:59<11:46:09, 11.52s/it] 71%|███████   | 9072/12750 [29:37:10<11:45:51, 11.51s/it] 71%|███████   | 9073/12750 [29:37:22<11:45:30, 11.51s/it] 71%|███████   | 9074/12750 [29:37:33<11:44:53, 11.51s/it] 71%|███████   | 9075/12750 [29:37:52<14:08:31, 13.85s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120565.75lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104869.83lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9075
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9075/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9075/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9050] due to args.save_total_limit
 71%|███████   | 9076/12750 [29:38:04<13:30:47, 13.24s/it] 71%|███████   | 9077/12750 [29:38:16<12:58:56, 12.72s/it] 71%|███████   | 9078/12750 [29:38:27<12:35:36, 12.35s/it] 71%|███████   | 9079/12750 [29:38:39<12:19:30, 12.09s/it] 71%|███████   | 9080/12750 [29:38:50<12:08:29, 11.91s/it] 71%|███████   | 9081/12750 [29:39:02<12:00:10, 11.78s/it] 71%|███████   | 9082/12750 [29:39:13<11:54:13, 11.68s/it] 71%|███████   | 9083/12750 [29:39:25<11:50:21, 11.62s/it] 71%|███████   | 9084/12750 [29:39:36<11:47:38, 11.58s/it] 71%|███████▏  | 9085/12750 [29:39:48<11:46:05, 11.56s/it] 71%|███████▏  | 9086/12750 [29:39:59<11:45:33, 11.55s/it] 71%|███████▏  | 9087/12750 [29:40:11<11:44:00, 11.53s/it] 71%|███████▏  | 9088/12750 [29:40:22<11:44:30, 11.54s/it] 71%|███████▏  | 9089/12750 [29:40:34<11:43:18, 11.53s/it] 71%|███████▏  | 9090/12750 [29:40:45<11:41:57, 11.51s/it] 71%|███████▏  | 9091/12750 [29:40:57<11:40:51, 11.49s/it] 71%|███████▏  | 9092/12750 [29:41:08<11:40:21, 11.49s/it] 71%|███████▏  | 9093/12750 [29:41:20<11:40:27, 11.49s/it] 71%|███████▏  | 9094/12750 [29:41:31<11:40:33, 11.50s/it] 71%|███████▏  | 9095/12750 [29:41:43<11:40:17, 11.50s/it] 71%|███████▏  | 9096/12750 [29:41:54<11:42:08, 11.53s/it] 71%|███████▏  | 9097/12750 [29:42:06<11:40:51, 11.51s/it] 71%|███████▏  | 9098/12750 [29:42:17<11:40:02, 11.50s/it] 71%|███████▏  | 9099/12750 [29:42:29<11:39:43, 11.50s/it] 71%|███████▏  | 9100/12750 [29:42:40<11:41:07, 11.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120560.11lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104870.81lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9100
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9100/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9100/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9075] due to args.save_total_limit
 71%|███████▏  | 9101/12750 [29:42:52<11:46:53, 11.62s/it] 71%|███████▏  | 9102/12750 [29:43:04<11:44:27, 11.59s/it] 71%|███████▏  | 9103/12750 [29:43:15<11:42:34, 11.56s/it] 71%|███████▏  | 9104/12750 [29:43:27<11:41:11, 11.54s/it] 71%|███████▏  | 9105/12750 [29:43:38<11:39:41, 11.52s/it] 71%|███████▏  | 9106/12750 [29:43:50<11:39:24, 11.52s/it] 71%|███████▏  | 9107/12750 [29:44:09<13:58:11, 13.81s/it] 71%|███████▏  | 9108/12750 [29:44:20<13:16:00, 13.11s/it] 71%|███████▏  | 9109/12750 [29:44:32<12:45:18, 12.61s/it] 71%|███████▏  | 9110/12750 [29:44:43<12:24:51, 12.28s/it] 71%|███████▏  | 9111/12750 [29:44:55<12:10:49, 12.05s/it] 71%|███████▏  | 9112/12750 [29:45:06<12:01:30, 11.90s/it] 71%|███████▏  | 9113/12750 [29:45:18<11:55:49, 11.81s/it] 71%|███████▏  | 9114/12750 [29:45:29<11:51:44, 11.74s/it] 71%|███████▏  | 9115/12750 [29:45:41<11:47:32, 11.68s/it] 71%|███████▏  | 9116/12750 [29:45:53<11:44:55, 11.64s/it] 72%|███████▏  | 9117/12750 [29:46:04<11:44:37, 11.64s/it] 72%|███████▏  | 9118/12750 [29:46:16<11:43:04, 11.61s/it] 72%|███████▏  | 9119/12750 [29:46:27<11:43:05, 11.62s/it] 72%|███████▏  | 9120/12750 [29:46:39<11:42:11, 11.61s/it] 72%|███████▏  | 9121/12750 [29:46:50<11:40:12, 11.58s/it] 72%|███████▏  | 9122/12750 [29:47:02<11:40:42, 11.59s/it] 72%|███████▏  | 9123/12750 [29:47:14<11:38:23, 11.55s/it] 72%|███████▏  | 9124/12750 [29:47:25<11:39:24, 11.57s/it] 72%|███████▏  | 9125/12750 [29:47:37<11:37:38, 11.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120612.88lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104825.96lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9125
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9125/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9125/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9100] due to args.save_total_limit
 72%|███████▏  | 9126/12750 [29:47:49<11:44:57, 11.67s/it] 72%|███████▏  | 9127/12750 [29:48:00<11:40:48, 11.61s/it] 72%|███████▏  | 9128/12750 [29:48:11<11:37:48, 11.56s/it] 72%|███████▏  | 9129/12750 [29:48:23<11:35:33, 11.53s/it] 72%|███████▏  | 9130/12750 [29:48:34<11:33:43, 11.50s/it] 72%|███████▏  | 9131/12750 [29:48:46<11:33:21, 11.50s/it] 72%|███████▏  | 9132/12750 [29:48:57<11:32:38, 11.49s/it] 72%|███████▏  | 9133/12750 [29:49:09<11:31:39, 11.47s/it] 72%|███████▏  | 9134/12750 [29:49:20<11:32:20, 11.49s/it] 72%|███████▏  | 9135/12750 [29:49:32<11:32:49, 11.50s/it] 72%|███████▏  | 9136/12750 [29:49:43<11:34:04, 11.52s/it] 72%|███████▏  | 9137/12750 [29:49:55<11:33:15, 11.51s/it] 72%|███████▏  | 9138/12750 [29:50:06<11:32:51, 11.51s/it] 72%|███████▏  | 9139/12750 [29:50:26<13:51:03, 13.81s/it] 72%|███████▏  | 9140/12750 [29:50:37<13:08:43, 13.11s/it] 72%|███████▏  | 9141/12750 [29:50:49<12:39:21, 12.62s/it] 72%|███████▏  | 9142/12750 [29:51:00<12:19:12, 12.29s/it] 72%|███████▏  | 9143/12750 [29:51:12<12:05:15, 12.06s/it] 72%|███████▏  | 9144/12750 [29:51:23<11:54:21, 11.89s/it] 72%|███████▏  | 9145/12750 [29:51:35<11:49:15, 11.80s/it] 72%|███████▏  | 9146/12750 [29:51:46<11:43:50, 11.72s/it] 72%|███████▏  | 9147/12750 [29:51:58<11:39:35, 11.65s/it] 72%|███████▏  | 9148/12750 [29:52:09<11:36:19, 11.60s/it] 72%|███████▏  | 9149/12750 [29:52:21<11:34:32, 11.57s/it] 72%|███████▏  | 9150/12750 [29:52:32<11:32:57, 11.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120581.67lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104857.31lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9150
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9150/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9150/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9125] due to args.save_total_limit
 72%|███████▏  | 9151/12750 [29:52:44<11:38:56, 11.65s/it] 72%|███████▏  | 9152/12750 [29:52:56<11:36:55, 11.62s/it] 72%|███████▏  | 9153/12750 [29:53:07<11:34:20, 11.58s/it] 72%|███████▏  | 9154/12750 [29:53:19<11:32:34, 11.56s/it] 72%|███████▏  | 9155/12750 [29:53:30<11:30:43, 11.53s/it] 72%|███████▏  | 9156/12750 [29:53:41<11:29:16, 11.51s/it] 72%|███████▏  | 9157/12750 [29:53:53<11:28:59, 11.51s/it] 72%|███████▏  | 9158/12750 [29:54:04<11:27:47, 11.49s/it] 72%|███████▏  | 9159/12750 [29:54:16<11:27:37, 11.49s/it] 72%|███████▏  | 9160/12750 [29:54:27<11:26:48, 11.48s/it] 72%|███████▏  | 9161/12750 [29:54:39<11:26:03, 11.47s/it] 72%|███████▏  | 9162/12750 [29:54:50<11:26:10, 11.47s/it] 72%|███████▏  | 9163/12750 [29:55:02<11:26:41, 11.49s/it] 72%|███████▏  | 9164/12750 [29:55:13<11:26:46, 11.49s/it] 72%|███████▏  | 9165/12750 [29:55:25<11:26:00, 11.48s/it] 72%|███████▏  | 9166/12750 [29:55:36<11:25:55, 11.48s/it] 72%|███████▏  | 9167/12750 [29:55:48<11:27:01, 11.50s/it] 72%|███████▏  | 9168/12750 [29:55:59<11:26:00, 11.49s/it] 72%|███████▏  | 9169/12750 [29:56:11<11:25:16, 11.48s/it] 72%|███████▏  | 9170/12750 [29:56:22<11:25:17, 11.49s/it] 72%|███████▏  | 9171/12750 [29:56:41<13:42:50, 13.79s/it] 72%|███████▏  | 9172/12750 [29:56:53<13:01:23, 13.10s/it] 72%|███████▏  | 9173/12750 [29:57:04<12:32:05, 12.62s/it] 72%|███████▏  | 9174/12750 [29:57:16<12:11:51, 12.28s/it] 72%|███████▏  | 9175/12750 [29:57:27<11:57:31, 12.04s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120554.08lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104866.63lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9175
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9175/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9175/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9150] due to args.save_total_limit
 72%|███████▏  | 9176/12750 [29:57:39<11:54:05, 11.99s/it] 72%|███████▏  | 9177/12750 [29:57:51<11:45:41, 11.85s/it] 72%|███████▏  | 9178/12750 [29:58:02<11:39:12, 11.74s/it] 72%|███████▏  | 9179/12750 [29:58:09<10:14:36, 10.33s/it] 72%|███████▏  | 9180/12750 [29:58:10<7:24:12,  7.47s/it]  72%|███████▏  | 9181/12750 [29:58:33<12:04:14, 12.18s/it] 72%|███████▏  | 9182/12750 [29:58:45<11:52:24, 11.98s/it] 72%|███████▏  | 9183/12750 [29:58:56<11:44:01, 11.84s/it] 72%|███████▏  | 9184/12750 [29:59:08<11:37:39, 11.74s/it] 72%|███████▏  | 9185/12750 [29:59:19<11:33:39, 11.67s/it] 72%|███████▏  | 9186/12750 [29:59:31<11:30:22, 11.62s/it] 72%|███████▏  | 9187/12750 [29:59:42<11:27:50, 11.58s/it] 72%|███████▏  | 9188/12750 [29:59:54<11:26:08, 11.56s/it] 72%|███████▏  | 9189/12750 [30:00:05<11:24:57, 11.54s/it] 72%|███████▏  | 9190/12750 [30:00:17<11:24:06, 11.53s/it] 72%|███████▏  | 9191/12750 [30:00:28<11:23:16, 11.52s/it] 72%|███████▏  | 9192/12750 [30:00:40<11:23:13, 11.52s/it] 72%|███████▏  | 9193/12750 [30:00:51<11:24:16, 11.54s/it] 72%|███████▏  | 9194/12750 [30:01:03<11:23:20, 11.53s/it] 72%|███████▏  | 9195/12750 [30:01:14<11:23:00, 11.53s/it] 72%|███████▏  | 9196/12750 [30:01:26<11:22:45, 11.53s/it] 72%|███████▏  | 9197/12750 [30:01:37<11:22:01, 11.52s/it] 72%|███████▏  | 9198/12750 [30:01:49<11:21:50, 11.52s/it] 72%|███████▏  | 9199/12750 [30:02:01<11:21:41, 11.52s/it] 72%|███████▏  | 9200/12750 [30:02:12<11:20:57, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120297.83lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104750.42lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9200
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9200/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9200/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9175] due to args.save_total_limit
 72%|███████▏  | 9201/12750 [30:02:24<11:32:08, 11.70s/it] 72%|███████▏  | 9202/12750 [30:02:36<11:28:45, 11.65s/it] 72%|███████▏  | 9203/12750 [30:02:47<11:26:36, 11.61s/it] 72%|███████▏  | 9204/12750 [30:03:05<13:24:32, 13.61s/it] 72%|███████▏  | 9205/12750 [30:03:17<12:47:34, 12.99s/it] 72%|███████▏  | 9206/12750 [30:03:29<12:20:38, 12.54s/it] 72%|███████▏  | 9207/12750 [30:03:40<12:02:22, 12.23s/it] 72%|███████▏  | 9208/12750 [30:03:52<11:49:31, 12.02s/it] 72%|███████▏  | 9209/12750 [30:04:03<11:40:17, 11.87s/it] 72%|███████▏  | 9210/12750 [30:04:15<11:34:06, 11.76s/it] 72%|███████▏  | 9211/12750 [30:04:26<11:28:46, 11.68s/it] 72%|███████▏  | 9212/12750 [30:04:38<11:25:42, 11.63s/it] 72%|███████▏  | 9213/12750 [30:04:49<11:23:47, 11.60s/it] 72%|███████▏  | 9214/12750 [30:05:01<11:22:15, 11.58s/it] 72%|███████▏  | 9215/12750 [30:05:12<11:20:30, 11.55s/it] 72%|███████▏  | 9216/12750 [30:05:24<11:20:37, 11.56s/it] 72%|███████▏  | 9217/12750 [30:05:35<11:19:41, 11.54s/it] 72%|███████▏  | 9218/12750 [30:05:47<11:19:12, 11.54s/it] 72%|███████▏  | 9219/12750 [30:05:58<11:18:31, 11.53s/it] 72%|███████▏  | 9220/12750 [30:06:10<11:17:28, 11.52s/it] 72%|███████▏  | 9221/12750 [30:06:21<11:17:15, 11.51s/it] 72%|███████▏  | 9222/12750 [30:06:33<11:16:41, 11.51s/it] 72%|███████▏  | 9223/12750 [30:06:44<11:15:54, 11.50s/it] 72%|███████▏  | 9224/12750 [30:06:56<11:16:24, 11.51s/it] 72%|███████▏  | 9225/12750 [30:07:07<11:15:22, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120590.28lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104724.75lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9225
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9225/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9225/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9200] due to args.save_total_limit
 72%|███████▏  | 9226/12750 [30:07:19<11:23:12, 11.63s/it] 72%|███████▏  | 9227/12750 [30:07:31<11:20:39, 11.59s/it] 72%|███████▏  | 9228/12750 [30:07:42<11:19:04, 11.57s/it] 72%|███████▏  | 9229/12750 [30:07:54<11:17:02, 11.54s/it] 72%|███████▏  | 9230/12750 [30:08:05<11:16:57, 11.54s/it] 72%|███████▏  | 9231/12750 [30:08:17<11:16:39, 11.54s/it] 72%|███████▏  | 9232/12750 [30:08:28<11:15:48, 11.53s/it] 72%|███████▏  | 9233/12750 [30:08:40<11:16:40, 11.54s/it] 72%|███████▏  | 9234/12750 [30:08:51<11:16:28, 11.54s/it] 72%|███████▏  | 9235/12750 [30:09:03<11:15:31, 11.53s/it] 72%|███████▏  | 9236/12750 [30:09:22<13:30:18, 13.84s/it] 72%|███████▏  | 9237/12750 [30:09:34<12:49:51, 13.15s/it] 72%|███████▏  | 9238/12750 [30:09:45<12:21:03, 12.66s/it] 72%|███████▏  | 9239/12750 [30:09:57<12:00:52, 12.32s/it] 72%|███████▏  | 9240/12750 [30:10:08<11:46:59, 12.09s/it] 72%|███████▏  | 9241/12750 [30:10:20<11:36:59, 11.92s/it] 72%|███████▏  | 9242/12750 [30:10:31<11:29:48, 11.80s/it] 72%|███████▏  | 9243/12750 [30:10:43<11:24:30, 11.71s/it] 73%|███████▎  | 9244/12750 [30:10:54<11:20:25, 11.64s/it] 73%|███████▎  | 9245/12750 [30:11:06<11:17:22, 11.60s/it] 73%|███████▎  | 9246/12750 [30:11:17<11:16:06, 11.58s/it] 73%|███████▎  | 9247/12750 [30:11:29<11:14:40, 11.56s/it] 73%|███████▎  | 9248/12750 [30:11:40<11:14:11, 11.55s/it] 73%|███████▎  | 9249/12750 [30:11:52<11:13:18, 11.54s/it] 73%|███████▎  | 9250/12750 [30:12:03<11:12:52, 11.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120572.30lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104886.54lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9250
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9250/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9250/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9225] due to args.save_total_limit
 73%|███████▎  | 9251/12750 [30:12:15<11:17:51, 11.62s/it] 73%|███████▎  | 9252/12750 [30:12:27<11:15:00, 11.58s/it] 73%|███████▎  | 9253/12750 [30:12:38<11:12:57, 11.55s/it] 73%|███████▎  | 9254/12750 [30:12:50<11:12:09, 11.54s/it] 73%|███████▎  | 9255/12750 [30:13:01<11:13:46, 11.57s/it] 73%|███████▎  | 9256/12750 [30:13:13<11:12:21, 11.55s/it] 73%|███████▎  | 9257/12750 [30:13:24<11:11:42, 11.54s/it] 73%|███████▎  | 9258/12750 [30:13:36<11:11:10, 11.53s/it] 73%|███████▎  | 9259/12750 [30:13:47<11:10:56, 11.53s/it] 73%|███████▎  | 9260/12750 [30:13:59<11:10:04, 11.52s/it] 73%|███████▎  | 9261/12750 [30:14:10<11:09:43, 11.52s/it] 73%|███████▎  | 9262/12750 [30:14:22<11:09:38, 11.52s/it] 73%|███████▎  | 9263/12750 [30:14:33<11:09:02, 11.51s/it] 73%|███████▎  | 9264/12750 [30:14:45<11:08:44, 11.51s/it] 73%|███████▎  | 9265/12750 [30:14:56<11:08:27, 11.51s/it] 73%|███████▎  | 9266/12750 [30:15:08<11:08:02, 11.50s/it] 73%|███████▎  | 9267/12750 [30:15:19<11:10:17, 11.55s/it] 73%|███████▎  | 9268/12750 [30:15:31<11:08:34, 11.52s/it] 73%|███████▎  | 9269/12750 [30:15:50<13:22:05, 13.83s/it] 73%|███████▎  | 9270/12750 [30:16:02<12:42:05, 13.14s/it] 73%|███████▎  | 9271/12750 [30:16:13<12:13:18, 12.65s/it] 73%|███████▎  | 9272/12750 [30:16:25<11:54:45, 12.33s/it] 73%|███████▎  | 9273/12750 [30:16:36<11:39:24, 12.07s/it] 73%|███████▎  | 9274/12750 [30:16:48<11:29:26, 11.90s/it] 73%|███████▎  | 9275/12750 [30:16:59<11:22:21, 11.78s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120529.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104831.88lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9275
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9275/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9275/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9250] due to args.save_total_limit
 73%|███████▎  | 9276/12750 [30:17:11<11:24:42, 11.83s/it] 73%|███████▎  | 9277/12750 [30:17:23<11:19:54, 11.75s/it] 73%|███████▎  | 9278/12750 [30:17:34<11:15:18, 11.67s/it] 73%|███████▎  | 9279/12750 [30:17:46<11:11:29, 11.61s/it] 73%|███████▎  | 9280/12750 [30:17:57<11:09:46, 11.58s/it] 73%|███████▎  | 9281/12750 [30:18:09<11:08:07, 11.56s/it] 73%|███████▎  | 9282/12750 [30:18:20<11:06:43, 11.53s/it] 73%|███████▎  | 9283/12750 [30:18:32<11:06:10, 11.53s/it] 73%|███████▎  | 9284/12750 [30:18:43<11:05:32, 11.52s/it] 73%|███████▎  | 9285/12750 [30:18:55<11:05:03, 11.52s/it] 73%|███████▎  | 9286/12750 [30:19:06<11:04:22, 11.51s/it] 73%|███████▎  | 9287/12750 [30:19:18<11:04:31, 11.51s/it] 73%|███████▎  | 9288/12750 [30:19:29<11:03:57, 11.51s/it] 73%|███████▎  | 9289/12750 [30:19:41<11:04:02, 11.51s/it] 73%|███████▎  | 9290/12750 [30:19:52<11:03:58, 11.51s/it] 73%|███████▎  | 9291/12750 [30:20:04<11:03:59, 11.52s/it] 73%|███████▎  | 9292/12750 [30:20:15<11:03:20, 11.51s/it] 73%|███████▎  | 9293/12750 [30:20:27<11:02:51, 11.50s/it] 73%|███████▎  | 9294/12750 [30:20:38<11:02:51, 11.51s/it] 73%|███████▎  | 9295/12750 [30:20:50<11:02:24, 11.50s/it] 73%|███████▎  | 9296/12750 [30:21:01<11:01:52, 11.50s/it] 73%|███████▎  | 9297/12750 [30:21:13<11:01:37, 11.50s/it] 73%|███████▎  | 9298/12750 [30:21:24<11:02:11, 11.51s/it] 73%|███████▎  | 9299/12750 [30:21:36<11:01:45, 11.51s/it] 73%|███████▎  | 9300/12750 [30:21:47<11:01:29, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120549.20lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104934.75lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9300
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9300/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9300/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9275] due to args.save_total_limit
 73%|███████▎  | 9301/12750 [30:22:07<13:20:10, 13.92s/it] 73%|███████▎  | 9302/12750 [30:22:18<12:38:50, 13.21s/it] 73%|███████▎  | 9303/12750 [30:22:30<12:09:10, 12.69s/it] 73%|███████▎  | 9304/12750 [30:22:41<11:49:30, 12.35s/it] 73%|███████▎  | 9305/12750 [30:22:53<11:35:46, 12.12s/it] 73%|███████▎  | 9306/12750 [30:23:05<11:25:14, 11.94s/it] 73%|███████▎  | 9307/12750 [30:23:16<11:17:23, 11.80s/it] 73%|███████▎  | 9308/12750 [30:23:28<11:11:44, 11.71s/it] 73%|███████▎  | 9309/12750 [30:23:39<11:07:33, 11.64s/it] 73%|███████▎  | 9310/12750 [30:23:50<11:05:00, 11.60s/it] 73%|███████▎  | 9311/12750 [30:24:02<11:03:43, 11.58s/it] 73%|███████▎  | 9312/12750 [30:24:14<11:02:10, 11.56s/it] 73%|███████▎  | 9313/12750 [30:24:25<11:02:12, 11.56s/it] 73%|███████▎  | 9314/12750 [30:24:37<11:00:43, 11.54s/it] 73%|███████▎  | 9315/12750 [30:24:48<10:59:48, 11.52s/it] 73%|███████▎  | 9316/12750 [30:25:00<10:59:34, 11.52s/it] 73%|███████▎  | 9317/12750 [30:25:11<10:58:41, 11.51s/it] 73%|███████▎  | 9318/12750 [30:25:23<10:58:13, 11.51s/it] 73%|███████▎  | 9319/12750 [30:25:34<10:57:38, 11.50s/it] 73%|███████▎  | 9320/12750 [30:25:46<10:57:10, 11.50s/it] 73%|███████▎  | 9321/12750 [30:25:57<10:56:18, 11.48s/it] 73%|███████▎  | 9322/12750 [30:26:08<10:55:28, 11.47s/it] 73%|███████▎  | 9323/12750 [30:26:20<10:55:31, 11.48s/it] 73%|███████▎  | 9324/12750 [30:26:31<10:55:25, 11.48s/it] 73%|███████▎  | 9325/12750 [30:26:43<10:54:36, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120501.23lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104791.43lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9325
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9325/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9325/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9300] due to args.save_total_limit
 73%|███████▎  | 9326/12750 [30:26:55<11:00:27, 11.57s/it] 73%|███████▎  | 9327/12750 [30:27:06<11:00:21, 11.57s/it] 73%|███████▎  | 9328/12750 [30:27:18<11:00:01, 11.57s/it] 73%|███████▎  | 9329/12750 [30:27:29<10:58:36, 11.55s/it] 73%|███████▎  | 9330/12750 [30:27:41<10:57:25, 11.53s/it] 73%|███████▎  | 9331/12750 [30:27:52<10:58:16, 11.55s/it] 73%|███████▎  | 9332/12750 [30:28:04<10:58:58, 11.57s/it] 73%|███████▎  | 9333/12750 [30:28:23<13:08:25, 13.84s/it] 73%|███████▎  | 9334/12750 [30:28:35<12:28:18, 13.14s/it] 73%|███████▎  | 9335/12750 [30:28:46<12:00:01, 12.65s/it] 73%|███████▎  | 9336/12750 [30:28:58<11:40:31, 12.31s/it] 73%|███████▎  | 9337/12750 [30:29:09<11:27:09, 12.08s/it] 73%|███████▎  | 9338/12750 [30:29:21<11:17:34, 11.92s/it] 73%|███████▎  | 9339/12750 [30:29:32<11:10:51, 11.80s/it] 73%|███████▎  | 9340/12750 [30:29:44<11:05:55, 11.72s/it] 73%|███████▎  | 9341/12750 [30:29:55<11:02:35, 11.66s/it] 73%|███████▎  | 9342/12750 [30:30:07<11:00:01, 11.62s/it] 73%|███████▎  | 9343/12750 [30:30:18<10:58:10, 11.59s/it] 73%|███████▎  | 9344/12750 [30:30:30<10:56:00, 11.56s/it] 73%|███████▎  | 9345/12750 [30:30:41<10:55:13, 11.55s/it] 73%|███████▎  | 9346/12750 [30:30:53<10:54:26, 11.54s/it] 73%|███████▎  | 9347/12750 [30:31:04<10:53:35, 11.52s/it] 73%|███████▎  | 9348/12750 [30:31:16<10:53:28, 11.53s/it] 73%|███████▎  | 9349/12750 [30:31:27<10:52:50, 11.52s/it] 73%|███████▎  | 9350/12750 [30:31:39<10:53:08, 11.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 117252.01lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 102350.58lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9350
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9350/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9350/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9325] due to args.save_total_limit
 73%|███████▎  | 9351/12750 [30:31:51<10:57:51, 11.61s/it] 73%|███████▎  | 9352/12750 [30:32:02<10:55:48, 11.58s/it] 73%|███████▎  | 9353/12750 [30:32:14<10:53:03, 11.53s/it] 73%|███████▎  | 9354/12750 [30:32:25<10:52:24, 11.53s/it] 73%|███████▎  | 9355/12750 [30:32:37<10:51:15, 11.51s/it] 73%|███████▎  | 9356/12750 [30:32:48<10:51:14, 11.51s/it] 73%|███████▎  | 9357/12750 [30:33:00<10:50:17, 11.50s/it] 73%|███████▎  | 9358/12750 [30:33:11<10:50:17, 11.50s/it] 73%|███████▎  | 9359/12750 [30:33:23<10:50:05, 11.50s/it] 73%|███████▎  | 9360/12750 [30:33:34<10:50:07, 11.51s/it] 73%|███████▎  | 9361/12750 [30:33:46<10:50:21, 11.51s/it] 73%|███████▎  | 9362/12750 [30:33:57<10:51:04, 11.53s/it] 73%|███████▎  | 9363/12750 [30:34:09<10:49:57, 11.51s/it] 73%|███████▎  | 9364/12750 [30:34:20<10:49:37, 11.51s/it] 73%|███████▎  | 9365/12750 [30:34:39<12:48:36, 13.62s/it] 73%|███████▎  | 9366/12750 [30:34:50<12:11:56, 12.98s/it] 73%|███████▎  | 9367/12750 [30:35:02<11:46:23, 12.53s/it] 73%|███████▎  | 9368/12750 [30:35:13<11:29:08, 12.23s/it] 73%|███████▎  | 9369/12750 [30:35:25<11:16:39, 12.01s/it] 73%|███████▎  | 9370/12750 [30:35:36<11:08:06, 11.86s/it] 73%|███████▎  | 9371/12750 [30:35:48<11:02:22, 11.76s/it] 74%|███████▎  | 9372/12750 [30:35:59<10:58:39, 11.70s/it] 74%|███████▎  | 9373/12750 [30:36:11<10:54:35, 11.63s/it] 74%|███████▎  | 9374/12750 [30:36:22<10:53:01, 11.61s/it] 74%|███████▎  | 9375/12750 [30:36:34<10:50:39, 11.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120547.40lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104816.45lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9375
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9375/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9375/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9350] due to args.save_total_limit
 74%|███████▎  | 9376/12750 [30:36:46<10:57:13, 11.69s/it] 74%|███████▎  | 9377/12750 [30:36:57<10:53:32, 11.63s/it] 74%|███████▎  | 9378/12750 [30:37:09<10:51:28, 11.59s/it] 74%|███████▎  | 9379/12750 [30:37:20<10:49:56, 11.57s/it] 74%|███████▎  | 9380/12750 [30:37:32<10:49:03, 11.56s/it] 74%|███████▎  | 9381/12750 [30:37:43<10:48:13, 11.54s/it] 74%|███████▎  | 9382/12750 [30:37:55<10:47:02, 11.53s/it] 74%|███████▎  | 9383/12750 [30:38:06<10:46:06, 11.51s/it] 74%|███████▎  | 9384/12750 [30:38:18<10:46:12, 11.52s/it] 74%|███████▎  | 9385/12750 [30:38:29<10:45:50, 11.52s/it] 74%|███████▎  | 9386/12750 [30:38:41<10:45:19, 11.51s/it] 74%|███████▎  | 9387/12750 [30:38:52<10:44:43, 11.50s/it] 74%|███████▎  | 9388/12750 [30:39:04<10:44:21, 11.50s/it] 74%|███████▎  | 9389/12750 [30:39:15<10:43:57, 11.50s/it] 74%|███████▎  | 9390/12750 [30:39:27<10:43:55, 11.50s/it] 74%|███████▎  | 9391/12750 [30:39:38<10:43:56, 11.50s/it] 74%|███████▎  | 9392/12750 [30:39:50<10:44:19, 11.51s/it] 74%|███████▎  | 9393/12750 [30:40:01<10:44:00, 11.51s/it] 74%|███████▎  | 9394/12750 [30:40:13<10:43:37, 11.51s/it] 74%|███████▎  | 9395/12750 [30:40:24<10:43:11, 11.50s/it] 74%|███████▎  | 9396/12750 [30:40:36<10:43:02, 11.50s/it] 74%|███████▎  | 9397/12750 [30:40:56<12:58:42, 13.93s/it] 74%|███████▎  | 9398/12750 [30:41:07<12:17:42, 13.20s/it] 74%|███████▎  | 9399/12750 [30:41:19<11:49:08, 12.70s/it] 74%|███████▎  | 9400/12750 [30:41:30<11:34:17, 12.44s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120645.52lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104754.98lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9400
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9400/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9400/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-8850] due to args.save_total_limit
 74%|███████▎  | 9401/12750 [30:41:42<11:25:17, 12.28s/it] 74%|███████▎  | 9402/12750 [30:41:54<11:13:49, 12.08s/it] 74%|███████▎  | 9403/12750 [30:42:05<11:03:15, 11.89s/it] 74%|███████▍  | 9404/12750 [30:42:17<10:56:10, 11.77s/it] 74%|███████▍  | 9405/12750 [30:42:28<10:51:02, 11.68s/it] 74%|███████▍  | 9406/12750 [30:42:40<10:48:14, 11.63s/it] 74%|███████▍  | 9407/12750 [30:42:51<10:45:05, 11.58s/it] 74%|███████▍  | 9408/12750 [30:43:03<10:43:15, 11.55s/it] 74%|███████▍  | 9409/12750 [30:43:14<10:41:50, 11.53s/it] 74%|███████▍  | 9410/12750 [30:43:26<10:43:47, 11.57s/it] 74%|███████▍  | 9411/12750 [30:43:38<10:43:57, 11.57s/it] 74%|███████▍  | 9412/12750 [30:43:49<10:44:18, 11.58s/it] 74%|███████▍  | 9413/12750 [30:44:01<10:44:55, 11.60s/it] 74%|███████▍  | 9414/12750 [30:44:12<10:44:23, 11.59s/it] 74%|███████▍  | 9415/12750 [30:44:24<10:44:10, 11.59s/it] 74%|███████▍  | 9416/12750 [30:44:36<10:44:39, 11.60s/it] 74%|███████▍  | 9417/12750 [30:44:47<10:44:17, 11.60s/it] 74%|███████▍  | 9418/12750 [30:44:59<10:43:43, 11.59s/it] 74%|███████▍  | 9419/12750 [30:45:10<10:41:21, 11.55s/it] 74%|███████▍  | 9420/12750 [30:45:22<10:39:32, 11.52s/it] 74%|███████▍  | 9421/12750 [30:45:33<10:38:03, 11.50s/it] 74%|███████▍  | 9422/12750 [30:45:45<10:37:26, 11.49s/it] 74%|███████▍  | 9423/12750 [30:45:56<10:37:05, 11.49s/it] 74%|███████▍  | 9424/12750 [30:46:07<10:35:52, 11.47s/it] 74%|███████▍  | 9425/12750 [30:46:19<10:35:41, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120577.95lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104884.02lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9425
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9425/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9425/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9375] due to args.save_total_limit
 74%|███████▍  | 9426/12750 [30:46:31<10:42:54, 11.60s/it] 74%|███████▍  | 9427/12750 [30:46:42<10:40:03, 11.56s/it] 74%|███████▍  | 9428/12750 [30:46:54<10:38:21, 11.53s/it] 74%|███████▍  | 9429/12750 [30:47:13<12:49:17, 13.90s/it] 74%|███████▍  | 9430/12750 [30:47:25<12:09:06, 13.18s/it] 74%|███████▍  | 9431/12750 [30:47:36<11:41:35, 12.68s/it] 74%|███████▍  | 9432/12750 [30:47:48<11:21:16, 12.32s/it] 74%|███████▍  | 9433/12750 [30:47:59<11:08:11, 12.09s/it] 74%|███████▍  | 9434/12750 [30:48:11<10:57:53, 11.90s/it] 74%|███████▍  | 9435/12750 [30:48:22<10:50:08, 11.77s/it] 74%|███████▍  | 9436/12750 [30:48:34<10:45:19, 11.68s/it] 74%|███████▍  | 9437/12750 [30:48:45<10:41:27, 11.62s/it] 74%|███████▍  | 9438/12750 [30:48:57<10:39:17, 11.58s/it] 74%|███████▍  | 9439/12750 [30:49:08<10:37:39, 11.56s/it] 74%|███████▍  | 9440/12750 [30:49:20<10:36:15, 11.53s/it] 74%|███████▍  | 9441/12750 [30:49:31<10:34:34, 11.51s/it] 74%|███████▍  | 9442/12750 [30:49:43<10:34:19, 11.51s/it] 74%|███████▍  | 9443/12750 [30:49:54<10:33:59, 11.50s/it] 74%|███████▍  | 9444/12750 [30:50:05<10:32:53, 11.49s/it] 74%|███████▍  | 9445/12750 [30:50:17<10:32:33, 11.48s/it] 74%|███████▍  | 9446/12750 [30:50:28<10:32:25, 11.48s/it] 74%|███████▍  | 9447/12750 [30:50:40<10:31:55, 11.48s/it] 74%|███████▍  | 9448/12750 [30:50:51<10:31:13, 11.47s/it] 74%|███████▍  | 9449/12750 [30:51:03<10:31:06, 11.47s/it] 74%|███████▍  | 9450/12750 [30:51:14<10:31:52, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120610.31lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104491.01lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9450
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9450/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9450/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9425] due to args.save_total_limit
 74%|███████▍  | 9451/12750 [30:51:26<10:37:34, 11.60s/it] 74%|███████▍  | 9452/12750 [30:51:38<10:34:37, 11.55s/it] 74%|███████▍  | 9453/12750 [30:51:49<10:32:37, 11.51s/it] 74%|███████▍  | 9454/12750 [30:52:01<10:31:22, 11.49s/it] 74%|███████▍  | 9455/12750 [30:52:12<10:33:08, 11.53s/it] 74%|███████▍  | 9456/12750 [30:52:24<10:31:51, 11.51s/it] 74%|███████▍  | 9457/12750 [30:52:35<10:31:14, 11.50s/it] 74%|███████▍  | 9458/12750 [30:52:47<10:31:02, 11.50s/it] 74%|███████▍  | 9459/12750 [30:52:58<10:30:09, 11.49s/it] 74%|███████▍  | 9460/12750 [30:53:09<10:29:06, 11.47s/it] 74%|███████▍  | 9461/12750 [30:53:21<10:29:16, 11.48s/it] 74%|███████▍  | 9462/12750 [30:53:41<12:41:45, 13.90s/it] 74%|███████▍  | 9463/12750 [30:53:52<12:01:57, 13.18s/it] 74%|███████▍  | 9464/12750 [30:54:03<11:34:08, 12.67s/it] 74%|███████▍  | 9465/12750 [30:54:15<11:15:13, 12.33s/it] 74%|███████▍  | 9466/12750 [30:54:27<11:01:31, 12.09s/it] 74%|███████▍  | 9467/12750 [30:54:38<10:51:36, 11.91s/it] 74%|███████▍  | 9468/12750 [30:54:49<10:44:00, 11.77s/it] 74%|███████▍  | 9469/12750 [30:55:01<10:39:21, 11.69s/it] 74%|███████▍  | 9470/12750 [30:55:12<10:35:28, 11.62s/it] 74%|███████▍  | 9471/12750 [30:55:24<10:33:06, 11.58s/it] 74%|███████▍  | 9472/12750 [30:55:36<10:32:14, 11.57s/it] 74%|███████▍  | 9473/12750 [30:55:47<10:32:51, 11.59s/it] 74%|███████▍  | 9474/12750 [30:55:59<10:31:15, 11.56s/it] 74%|███████▍  | 9475/12750 [30:56:10<10:29:40, 11.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120558.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104802.87lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9475
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9475/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9475/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9450] due to args.save_total_limit
 74%|███████▍  | 9476/12750 [30:56:22<10:35:49, 11.65s/it] 74%|███████▍  | 9477/12750 [30:56:34<10:34:01, 11.62s/it] 74%|███████▍  | 9478/12750 [30:56:45<10:31:34, 11.58s/it] 74%|███████▍  | 9479/12750 [30:56:57<10:29:58, 11.56s/it] 74%|███████▍  | 9480/12750 [30:57:08<10:28:13, 11.53s/it] 74%|███████▍  | 9481/12750 [30:57:20<10:27:36, 11.52s/it] 74%|███████▍  | 9482/12750 [30:57:31<10:26:40, 11.51s/it] 74%|███████▍  | 9483/12750 [30:57:42<10:25:56, 11.50s/it] 74%|███████▍  | 9484/12750 [30:57:54<10:25:30, 11.49s/it] 74%|███████▍  | 9485/12750 [30:58:05<10:25:27, 11.49s/it] 74%|███████▍  | 9486/12750 [30:58:17<10:25:13, 11.49s/it] 74%|███████▍  | 9487/12750 [30:58:28<10:25:21, 11.50s/it] 74%|███████▍  | 9488/12750 [30:58:40<10:24:43, 11.49s/it] 74%|███████▍  | 9489/12750 [30:58:51<10:24:18, 11.49s/it] 74%|███████▍  | 9490/12750 [30:59:03<10:23:53, 11.48s/it] 74%|███████▍  | 9491/12750 [30:59:14<10:23:15, 11.47s/it] 74%|███████▍  | 9492/12750 [30:59:26<10:23:04, 11.47s/it] 74%|███████▍  | 9493/12750 [30:59:37<10:22:35, 11.47s/it] 74%|███████▍  | 9494/12750 [30:59:57<12:34:50, 13.91s/it] 74%|███████▍  | 9495/12750 [31:00:08<11:54:52, 13.18s/it] 74%|███████▍  | 9496/12750 [31:00:20<11:26:29, 12.66s/it] 74%|███████▍  | 9497/12750 [31:00:31<11:06:36, 12.30s/it] 74%|███████▍  | 9498/12750 [31:00:43<10:53:21, 12.05s/it] 75%|███████▍  | 9499/12750 [31:00:54<10:44:42, 11.90s/it] 75%|███████▍  | 9500/12750 [31:01:06<10:40:03, 11.82s/it]                                                           75%|███████▍  | 9500/12750 [31:01:06<10:40:03, 11.82s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120739.55lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104972.78lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9500
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9500/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9500/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9475] due to args.save_total_limit
 75%|███████▍  | 9501/12750 [31:01:18<10:39:04, 11.80s/it] 75%|███████▍  | 9502/12750 [31:01:29<10:33:21, 11.70s/it] 75%|███████▍  | 9503/12750 [31:01:41<10:29:29, 11.63s/it] 75%|███████▍  | 9504/12750 [31:01:52<10:26:08, 11.57s/it] 75%|███████▍  | 9505/12750 [31:02:04<10:25:19, 11.56s/it] 75%|███████▍  | 9506/12750 [31:02:15<10:23:46, 11.54s/it] 75%|███████▍  | 9507/12750 [31:02:26<10:22:18, 11.51s/it] 75%|███████▍  | 9508/12750 [31:02:38<10:23:43, 11.54s/it] 75%|███████▍  | 9509/12750 [31:02:50<10:22:36, 11.53s/it] 75%|███████▍  | 9510/12750 [31:03:01<10:21:16, 11.51s/it] 75%|███████▍  | 9511/12750 [31:03:12<10:19:59, 11.48s/it] 75%|███████▍  | 9512/12750 [31:03:24<10:19:12, 11.47s/it] 75%|███████▍  | 9513/12750 [31:03:35<10:19:45, 11.49s/it] 75%|███████▍  | 9514/12750 [31:03:47<10:19:00, 11.48s/it] 75%|███████▍  | 9515/12750 [31:03:58<10:20:02, 11.50s/it] 75%|███████▍  | 9516/12750 [31:04:10<10:19:03, 11.49s/it] 75%|███████▍  | 9517/12750 [31:04:21<10:18:56, 11.49s/it] 75%|███████▍  | 9518/12750 [31:04:33<10:18:35, 11.48s/it] 75%|███████▍  | 9519/12750 [31:04:44<10:18:37, 11.49s/it] 75%|███████▍  | 9520/12750 [31:04:56<10:17:41, 11.47s/it] 75%|███████▍  | 9521/12750 [31:05:07<10:17:54, 11.48s/it] 75%|███████▍  | 9522/12750 [31:05:19<10:17:12, 11.47s/it] 75%|███████▍  | 9523/12750 [31:05:30<10:17:33, 11.48s/it] 75%|███████▍  | 9524/12750 [31:05:42<10:17:16, 11.48s/it] 75%|███████▍  | 9525/12750 [31:05:53<10:18:13, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120809.87lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 105124.01lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9525
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9525/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9525/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9500] due to args.save_total_limit
 75%|███████▍  | 9526/12750 [31:06:13<12:33:01, 14.01s/it] 75%|███████▍  | 9527/12750 [31:06:25<11:51:44, 13.25s/it] 75%|███████▍  | 9528/12750 [31:06:36<11:22:53, 12.72s/it] 75%|███████▍  | 9529/12750 [31:06:48<11:02:28, 12.34s/it] 75%|███████▍  | 9530/12750 [31:06:59<10:47:48, 12.07s/it] 75%|███████▍  | 9531/12750 [31:07:10<10:37:43, 11.89s/it] 75%|███████▍  | 9532/12750 [31:07:22<10:30:31, 11.76s/it] 75%|███████▍  | 9533/12750 [31:07:33<10:25:54, 11.67s/it] 75%|███████▍  | 9534/12750 [31:07:45<10:21:59, 11.60s/it] 75%|███████▍  | 9535/12750 [31:07:56<10:18:57, 11.55s/it] 75%|███████▍  | 9536/12750 [31:08:08<10:17:19, 11.52s/it] 75%|███████▍  | 9537/12750 [31:08:19<10:15:43, 11.50s/it] 75%|███████▍  | 9538/12750 [31:08:31<10:14:38, 11.48s/it] 75%|███████▍  | 9539/12750 [31:08:42<10:13:47, 11.47s/it] 75%|███████▍  | 9540/12750 [31:08:54<10:13:38, 11.47s/it] 75%|███████▍  | 9541/12750 [31:09:05<10:13:22, 11.47s/it] 75%|███████▍  | 9542/12750 [31:09:16<10:13:21, 11.47s/it] 75%|███████▍  | 9543/12750 [31:09:28<10:13:10, 11.47s/it] 75%|███████▍  | 9544/12750 [31:09:39<10:12:44, 11.47s/it] 75%|███████▍  | 9545/12750 [31:09:51<10:12:37, 11.47s/it] 75%|███████▍  | 9546/12750 [31:10:02<10:12:33, 11.47s/it] 75%|███████▍  | 9547/12750 [31:10:14<10:12:11, 11.47s/it] 75%|███████▍  | 9548/12750 [31:10:25<10:11:52, 11.47s/it] 75%|███████▍  | 9549/12750 [31:10:37<10:11:31, 11.46s/it] 75%|███████▍  | 9550/12750 [31:10:48<10:11:06, 11.46s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120286.96lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104666.00lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9550
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9550/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9550/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9525] due to args.save_total_limit
 75%|███████▍  | 9551/12750 [31:11:00<10:16:29, 11.56s/it] 75%|███████▍  | 9552/12750 [31:11:11<10:14:40, 11.53s/it] 75%|███████▍  | 9553/12750 [31:11:23<10:13:35, 11.52s/it] 75%|███████▍  | 9554/12750 [31:11:34<10:12:38, 11.50s/it] 75%|███████▍  | 9555/12750 [31:11:46<10:12:06, 11.50s/it] 75%|███████▍  | 9556/12750 [31:11:57<10:11:19, 11.48s/it] 75%|███████▍  | 9557/12750 [31:12:09<10:10:23, 11.47s/it] 75%|███████▍  | 9558/12750 [31:12:28<12:15:20, 13.82s/it] 75%|███████▍  | 9559/12750 [31:12:40<11:37:15, 13.11s/it] 75%|███████▍  | 9560/12750 [31:12:51<11:10:26, 12.61s/it] 75%|███████▍  | 9561/12750 [31:13:03<10:54:20, 12.31s/it] 75%|███████▍  | 9562/12750 [31:13:14<10:41:07, 12.07s/it] 75%|███████▌  | 9563/12750 [31:13:26<10:31:41, 11.89s/it] 75%|███████▌  | 9564/12750 [31:13:37<10:25:20, 11.78s/it] 75%|███████▌  | 9565/12750 [31:13:49<10:20:59, 11.70s/it] 75%|███████▌  | 9566/12750 [31:14:00<10:17:25, 11.63s/it] 75%|███████▌  | 9567/12750 [31:14:12<10:14:49, 11.59s/it] 75%|███████▌  | 9568/12750 [31:14:23<10:13:33, 11.57s/it] 75%|███████▌  | 9569/12750 [31:14:35<10:11:52, 11.54s/it] 75%|███████▌  | 9570/12750 [31:14:46<10:10:28, 11.52s/it] 75%|███████▌  | 9571/12750 [31:14:58<10:09:35, 11.51s/it] 75%|███████▌  | 9572/12750 [31:15:09<10:10:01, 11.52s/it] 75%|███████▌  | 9573/12750 [31:15:21<10:10:12, 11.52s/it] 75%|███████▌  | 9574/12750 [31:15:32<10:09:21, 11.51s/it] 75%|███████▌  | 9575/12750 [31:15:44<10:08:44, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120613.91lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104897.13lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9575
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9575/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9575/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9550] due to args.save_total_limit
 75%|███████▌  | 9576/12750 [31:15:55<10:13:42, 11.60s/it] 75%|███████▌  | 9577/12750 [31:16:07<10:11:26, 11.56s/it] 75%|███████▌  | 9578/12750 [31:16:18<10:09:54, 11.54s/it] 75%|███████▌  | 9579/12750 [31:16:30<10:08:53, 11.52s/it] 75%|███████▌  | 9580/12750 [31:16:41<10:07:48, 11.50s/it] 75%|███████▌  | 9581/12750 [31:16:53<10:07:00, 11.49s/it] 75%|███████▌  | 9582/12750 [31:17:04<10:06:49, 11.49s/it] 75%|███████▌  | 9583/12750 [31:17:16<10:06:07, 11.48s/it] 75%|███████▌  | 9584/12750 [31:17:27<10:05:45, 11.48s/it] 75%|███████▌  | 9585/12750 [31:17:39<10:05:55, 11.49s/it] 75%|███████▌  | 9586/12750 [31:17:50<10:05:17, 11.48s/it] 75%|███████▌  | 9587/12750 [31:18:02<10:04:55, 11.48s/it] 75%|███████▌  | 9588/12750 [31:18:13<10:04:32, 11.47s/it] 75%|███████▌  | 9589/12750 [31:18:25<10:04:25, 11.47s/it] 75%|███████▌  | 9590/12750 [31:18:44<12:10:57, 13.88s/it] 75%|███████▌  | 9591/12750 [31:18:56<11:35:19, 13.21s/it] 75%|███████▌  | 9592/12750 [31:19:07<11:07:25, 12.68s/it] 75%|███████▌  | 9593/12750 [31:19:19<10:47:48, 12.31s/it] 75%|███████▌  | 9594/12750 [31:19:30<10:33:53, 12.05s/it] 75%|███████▌  | 9595/12750 [31:19:41<10:24:39, 11.88s/it] 75%|███████▌  | 9596/12750 [31:19:53<10:18:00, 11.76s/it] 75%|███████▌  | 9597/12750 [31:20:04<10:13:27, 11.67s/it] 75%|███████▌  | 9598/12750 [31:20:16<10:10:03, 11.61s/it] 75%|███████▌  | 9599/12750 [31:20:27<10:07:26, 11.57s/it] 75%|███████▌  | 9600/12750 [31:20:39<10:06:08, 11.55s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120798.53lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104964.02lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9600
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9600/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9600/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9575] due to args.save_total_limit
 75%|███████▌  | 9601/12750 [31:20:51<10:09:15, 11.61s/it] 75%|███████▌  | 9602/12750 [31:21:02<10:06:39, 11.56s/it] 75%|███████▌  | 9603/12750 [31:21:14<10:05:12, 11.54s/it] 75%|███████▌  | 9604/12750 [31:21:25<10:03:39, 11.51s/it] 75%|███████▌  | 9605/12750 [31:21:36<10:02:55, 11.50s/it] 75%|███████▌  | 9606/12750 [31:21:48<10:02:28, 11.50s/it] 75%|███████▌  | 9607/12750 [31:21:59<10:01:27, 11.48s/it] 75%|███████▌  | 9608/12750 [31:22:11<10:01:13, 11.48s/it] 75%|███████▌  | 9609/12750 [31:22:22<10:00:45, 11.48s/it] 75%|███████▌  | 9610/12750 [31:22:34<10:00:37, 11.48s/it] 75%|███████▌  | 9611/12750 [31:22:45<10:00:20, 11.48s/it] 75%|███████▌  | 9612/12750 [31:22:57<10:00:16, 11.48s/it] 75%|███████▌  | 9613/12750 [31:23:08<9:59:53, 11.47s/it]  75%|███████▌  | 9614/12750 [31:23:20<9:59:24, 11.47s/it] 75%|███████▌  | 9615/12750 [31:23:31<9:58:46, 11.46s/it] 75%|███████▌  | 9616/12750 [31:23:43<9:58:54, 11.47s/it] 75%|███████▌  | 9617/12750 [31:23:54<9:58:49, 11.47s/it] 75%|███████▌  | 9618/12750 [31:24:06<9:59:04, 11.48s/it] 75%|███████▌  | 9619/12750 [31:24:17<9:58:40, 11.47s/it] 75%|███████▌  | 9620/12750 [31:24:29<9:58:48, 11.48s/it] 75%|███████▌  | 9621/12750 [31:24:40<9:58:43, 11.48s/it] 75%|███████▌  | 9622/12750 [31:24:52<9:58:54, 11.49s/it] 75%|███████▌  | 9623/12750 [31:25:10<11:52:32, 13.67s/it] 75%|███████▌  | 9624/12750 [31:25:22<11:18:38, 13.03s/it] 75%|███████▌  | 9625/12750 [31:25:33<10:54:30, 12.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120608.51lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104894.02lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9625
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9625/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9625/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9600] due to args.save_total_limit
 75%|███████▌  | 9626/12750 [31:25:45<10:42:17, 12.34s/it] 76%|███████▌  | 9627/12750 [31:25:57<10:28:17, 12.07s/it] 76%|███████▌  | 9628/12750 [31:26:08<10:18:31, 11.89s/it] 76%|███████▌  | 9629/12750 [31:26:20<10:12:07, 11.77s/it] 76%|███████▌  | 9630/12750 [31:26:31<10:07:33, 11.68s/it] 76%|███████▌  | 9631/12750 [31:26:43<10:04:54, 11.64s/it] 76%|███████▌  | 9632/12750 [31:26:54<10:02:55, 11.60s/it] 76%|███████▌  | 9633/12750 [31:27:06<10:01:11, 11.57s/it] 76%|███████▌  | 9634/12750 [31:27:17<9:59:35, 11.55s/it]  76%|███████▌  | 9635/12750 [31:27:29<9:58:27, 11.53s/it] 76%|███████▌  | 9636/12750 [31:27:40<9:57:34, 11.51s/it] 76%|███████▌  | 9637/12750 [31:27:52<9:57:17, 11.51s/it] 76%|███████▌  | 9638/12750 [31:28:03<9:57:13, 11.51s/it] 76%|███████▌  | 9639/12750 [31:28:15<9:56:41, 11.51s/it] 76%|███████▌  | 9640/12750 [31:28:26<9:56:01, 11.50s/it] 76%|███████▌  | 9641/12750 [31:28:38<9:55:47, 11.50s/it] 76%|███████▌  | 9642/12750 [31:28:49<9:55:30, 11.50s/it] 76%|███████▌  | 9643/12750 [31:29:01<9:55:38, 11.50s/it] 76%|███████▌  | 9644/12750 [31:29:12<9:55:41, 11.51s/it] 76%|███████▌  | 9645/12750 [31:29:24<9:55:24, 11.51s/it] 76%|███████▌  | 9646/12750 [31:29:35<9:55:25, 11.51s/it] 76%|███████▌  | 9647/12750 [31:29:47<9:55:33, 11.52s/it] 76%|███████▌  | 9648/12750 [31:29:58<9:54:51, 11.51s/it] 76%|███████▌  | 9649/12750 [31:30:10<9:54:22, 11.50s/it] 76%|███████▌  | 9650/12750 [31:30:21<9:53:29, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120627.27lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104951.67lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9650
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9650/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9650/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9625] due to args.save_total_limit
 76%|███████▌  | 9651/12750 [31:30:33<9:58:27, 11.59s/it] 76%|███████▌  | 9652/12750 [31:30:44<9:56:52, 11.56s/it] 76%|███████▌  | 9653/12750 [31:30:56<9:55:18, 11.53s/it] 76%|███████▌  | 9654/12750 [31:31:07<9:54:18, 11.52s/it] 76%|███████▌  | 9655/12750 [31:31:27<12:01:20, 13.98s/it] 76%|███████▌  | 9656/12750 [31:31:39<11:22:25, 13.23s/it] 76%|███████▌  | 9657/12750 [31:31:50<10:55:12, 12.71s/it] 76%|███████▌  | 9658/12750 [31:32:01<10:36:04, 12.34s/it] 76%|███████▌  | 9659/12750 [31:32:13<10:22:10, 12.08s/it] 76%|███████▌  | 9660/12750 [31:32:24<10:12:44, 11.90s/it] 76%|███████▌  | 9661/12750 [31:32:36<10:05:44, 11.77s/it] 76%|███████▌  | 9662/12750 [31:32:47<10:00:41, 11.67s/it] 76%|███████▌  | 9663/12750 [31:32:59<9:57:29, 11.61s/it]  76%|███████▌  | 9664/12750 [31:33:10<9:55:32, 11.58s/it] 76%|███████▌  | 9665/12750 [31:33:22<9:54:02, 11.55s/it] 76%|███████▌  | 9666/12750 [31:33:33<9:53:07, 11.54s/it] 76%|███████▌  | 9667/12750 [31:33:45<9:52:29, 11.53s/it] 76%|███████▌  | 9668/12750 [31:33:56<9:52:25, 11.53s/it] 76%|███████▌  | 9669/12750 [31:34:08<9:51:18, 11.52s/it] 76%|███████▌  | 9670/12750 [31:34:19<9:50:58, 11.51s/it] 76%|███████▌  | 9671/12750 [31:34:31<9:50:32, 11.51s/it] 76%|███████▌  | 9672/12750 [31:34:42<9:50:21, 11.51s/it] 76%|███████▌  | 9673/12750 [31:34:54<9:50:11, 11.51s/it] 76%|███████▌  | 9674/12750 [31:35:05<9:49:45, 11.50s/it] 76%|███████▌  | 9675/12750 [31:35:17<9:49:54, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120654.26lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104879.55lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9675
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9675/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9675/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9675/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9650] due to args.save_total_limit
 76%|███████▌  | 9676/12750 [31:35:29<9:54:23, 11.60s/it] 76%|███████▌  | 9677/12750 [31:35:40<9:52:24, 11.57s/it] 76%|███████▌  | 9678/12750 [31:35:52<9:50:29, 11.53s/it] 76%|███████▌  | 9679/12750 [31:36:03<9:49:05, 11.51s/it] 76%|███████▌  | 9680/12750 [31:36:15<9:48:25, 11.50s/it] 76%|███████▌  | 9681/12750 [31:36:26<9:48:01, 11.50s/it] 76%|███████▌  | 9682/12750 [31:36:38<9:47:58, 11.50s/it] 76%|███████▌  | 9683/12750 [31:36:49<9:47:40, 11.50s/it] 76%|███████▌  | 9684/12750 [31:37:01<9:47:13, 11.49s/it] 76%|███████▌  | 9685/12750 [31:37:12<9:46:42, 11.49s/it] 76%|███████▌  | 9686/12750 [31:37:23<9:46:34, 11.49s/it] 76%|███████▌  | 9687/12750 [31:37:43<11:43:59, 13.79s/it] 76%|███████▌  | 9688/12750 [31:37:54<11:08:13, 13.09s/it] 76%|███████▌  | 9689/12750 [31:38:01<9:34:57, 11.27s/it]  76%|███████▌  | 9690/12750 [31:38:02<6:54:25,  8.13s/it] 76%|███████▌  | 9691/12750 [31:38:25<10:44:24, 12.64s/it] 76%|███████▌  | 9692/12750 [31:38:37<10:26:51, 12.30s/it] 76%|███████▌  | 9693/12750 [31:38:48<10:14:38, 12.06s/it] 76%|███████▌  | 9694/12750 [31:39:00<10:06:03, 11.90s/it] 76%|███████▌  | 9695/12750 [31:39:11<10:00:05, 11.79s/it] 76%|███████▌  | 9696/12750 [31:39:23<9:56:05, 11.71s/it]  76%|███████▌  | 9697/12750 [31:39:34<9:53:10, 11.66s/it] 76%|███████▌  | 9698/12750 [31:39:46<9:50:27, 11.61s/it] 76%|███████▌  | 9699/12750 [31:39:57<9:49:06, 11.59s/it] 76%|███████▌  | 9700/12750 [31:40:09<9:47:34, 11.56s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120663.00lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104936.40lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9700
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9700/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9700/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9700/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9675] due to args.save_total_limit
 76%|███████▌  | 9701/12750 [31:40:21<9:51:28, 11.64s/it] 76%|███████▌  | 9702/12750 [31:40:32<9:50:34, 11.63s/it] 76%|███████▌  | 9703/12750 [31:40:44<9:48:50, 11.60s/it] 76%|███████▌  | 9704/12750 [31:40:55<9:47:36, 11.57s/it] 76%|███████▌  | 9705/12750 [31:41:07<9:46:38, 11.56s/it] 76%|███████▌  | 9706/12750 [31:41:18<9:45:54, 11.55s/it] 76%|███████▌  | 9707/12750 [31:41:30<9:44:50, 11.53s/it] 76%|███████▌  | 9708/12750 [31:41:41<9:43:58, 11.52s/it] 76%|███████▌  | 9709/12750 [31:41:53<9:43:56, 11.52s/it] 76%|███████▌  | 9710/12750 [31:42:04<9:43:33, 11.52s/it] 76%|███████▌  | 9711/12750 [31:42:16<9:43:12, 11.51s/it] 76%|███████▌  | 9712/12750 [31:42:27<9:42:29, 11.50s/it] 76%|███████▌  | 9713/12750 [31:42:39<9:41:48, 11.49s/it] 76%|███████▌  | 9714/12750 [31:42:50<9:42:18, 11.51s/it] 76%|███████▌  | 9715/12750 [31:43:02<9:42:10, 11.51s/it] 76%|███████▌  | 9716/12750 [31:43:13<9:42:16, 11.51s/it] 76%|███████▌  | 9717/12750 [31:43:25<9:41:50, 11.51s/it] 76%|███████▌  | 9718/12750 [31:43:36<9:41:23, 11.51s/it] 76%|███████▌  | 9719/12750 [31:43:56<11:42:51, 13.91s/it] 76%|███████▌  | 9720/12750 [31:44:07<11:05:45, 13.18s/it] 76%|███████▌  | 9721/12750 [31:44:19<10:40:27, 12.69s/it] 76%|███████▋  | 9722/12750 [31:44:30<10:22:01, 12.33s/it] 76%|███████▋  | 9723/12750 [31:44:42<10:10:40, 12.10s/it] 76%|███████▋  | 9724/12750 [31:44:53<10:00:57, 11.92s/it] 76%|███████▋  | 9725/12750 [31:45:05<9:54:10, 11.79s/it] 
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120719.34lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104956.73lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9725
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9725/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9725/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9725/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9700] due to args.save_total_limit
 76%|███████▋  | 9726/12750 [31:45:17<9:54:32, 11.80s/it] 76%|███████▋  | 9727/12750 [31:45:28<9:49:36, 11.70s/it] 76%|███████▋  | 9728/12750 [31:45:40<9:46:27, 11.64s/it] 76%|███████▋  | 9729/12750 [31:45:51<9:43:59, 11.60s/it] 76%|███████▋  | 9730/12750 [31:46:03<9:42:08, 11.57s/it] 76%|███████▋  | 9731/12750 [31:46:14<9:41:24, 11.56s/it] 76%|███████▋  | 9732/12750 [31:46:26<9:40:36, 11.54s/it] 76%|███████▋  | 9733/12750 [31:46:37<9:39:55, 11.53s/it] 76%|███████▋  | 9734/12750 [31:46:49<9:39:35, 11.53s/it] 76%|███████▋  | 9735/12750 [31:47:00<9:39:37, 11.53s/it] 76%|███████▋  | 9736/12750 [31:47:12<9:38:45, 11.52s/it] 76%|███████▋  | 9737/12750 [31:47:23<9:38:33, 11.52s/it] 76%|███████▋  | 9738/12750 [31:47:35<9:37:48, 11.51s/it] 76%|███████▋  | 9739/12750 [31:47:46<9:37:13, 11.50s/it] 76%|███████▋  | 9740/12750 [31:47:58<9:37:16, 11.51s/it] 76%|███████▋  | 9741/12750 [31:48:09<9:37:06, 11.51s/it] 76%|███████▋  | 9742/12750 [31:48:21<9:36:38, 11.50s/it] 76%|███████▋  | 9743/12750 [31:48:32<9:36:39, 11.51s/it] 76%|███████▋  | 9744/12750 [31:48:44<9:36:14, 11.50s/it] 76%|███████▋  | 9745/12750 [31:48:55<9:35:39, 11.49s/it] 76%|███████▋  | 9746/12750 [31:49:07<9:35:28, 11.49s/it] 76%|███████▋  | 9747/12750 [31:49:18<9:35:17, 11.49s/it] 76%|███████▋  | 9748/12750 [31:49:30<9:35:26, 11.50s/it] 76%|███████▋  | 9749/12750 [31:49:41<9:35:37, 11.51s/it] 76%|███████▋  | 9750/12750 [31:49:53<9:35:08, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120579.49lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104879.26lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9750
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9750/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9750/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9750/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9725] due to args.save_total_limit
 76%|███████▋  | 9751/12750 [31:50:13<11:41:03, 14.03s/it] 76%|███████▋  | 9752/12750 [31:50:24<11:02:07, 13.25s/it] 76%|███████▋  | 9753/12750 [31:50:36<10:35:11, 12.72s/it] 77%|███████▋  | 9754/12750 [31:50:47<10:16:33, 12.35s/it] 77%|███████▋  | 9755/12750 [31:50:59<10:03:31, 12.09s/it] 77%|███████▋  | 9756/12750 [31:51:10<9:54:17, 11.91s/it]  77%|███████▋  | 9757/12750 [31:51:22<9:47:54, 11.79s/it] 77%|███████▋  | 9758/12750 [31:51:33<9:43:59, 11.71s/it] 77%|███████▋  | 9759/12750 [31:51:45<9:41:02, 11.66s/it] 77%|███████▋  | 9760/12750 [31:51:56<9:38:07, 11.60s/it] 77%|███████▋  | 9761/12750 [31:52:08<9:36:41, 11.58s/it] 77%|███████▋  | 9762/12750 [31:52:19<9:35:39, 11.56s/it] 77%|███████▋  | 9763/12750 [31:52:31<9:34:13, 11.53s/it] 77%|███████▋  | 9764/12750 [31:52:42<9:33:10, 11.52s/it] 77%|███████▋  | 9765/12750 [31:52:54<9:32:25, 11.51s/it] 77%|███████▋  | 9766/12750 [31:53:05<9:32:07, 11.50s/it] 77%|███████▋  | 9767/12750 [31:53:17<9:31:48, 11.50s/it] 77%|███████▋  | 9768/12750 [31:53:28<9:31:24, 11.50s/it] 77%|███████▋  | 9769/12750 [31:53:40<9:31:04, 11.49s/it] 77%|███████▋  | 9770/12750 [31:53:51<9:30:43, 11.49s/it] 77%|███████▋  | 9771/12750 [31:54:03<9:30:58, 11.50s/it] 77%|███████▋  | 9772/12750 [31:54:14<9:30:31, 11.49s/it] 77%|███████▋  | 9773/12750 [31:54:26<9:30:02, 11.49s/it] 77%|███████▋  | 9774/12750 [31:54:37<9:30:23, 11.50s/it] 77%|███████▋  | 9775/12750 [31:54:49<9:30:06, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120648.22lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104918.51lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9775
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9775/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9775/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9775/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9750] due to args.save_total_limit
 77%|███████▋  | 9776/12750 [31:55:00<9:34:10, 11.58s/it] 77%|███████▋  | 9777/12750 [31:55:12<9:32:16, 11.55s/it] 77%|███████▋  | 9778/12750 [31:55:23<9:31:07, 11.53s/it] 77%|███████▋  | 9779/12750 [31:55:35<9:30:19, 11.52s/it] 77%|███████▋  | 9780/12750 [31:55:46<9:29:30, 11.51s/it] 77%|███████▋  | 9781/12750 [31:55:58<9:28:44, 11.49s/it] 77%|███████▋  | 9782/12750 [31:56:09<9:28:43, 11.50s/it] 77%|███████▋  | 9783/12750 [31:56:21<9:28:05, 11.49s/it] 77%|███████▋  | 9784/12750 [31:56:40<11:31:07, 13.98s/it] 77%|███████▋  | 9785/12750 [31:56:52<10:53:53, 13.23s/it] 77%|███████▋  | 9786/12750 [31:57:03<10:27:58, 12.71s/it] 77%|███████▋  | 9787/12750 [31:57:15<10:09:59, 12.35s/it] 77%|███████▋  | 9788/12750 [31:57:26<9:57:13, 12.10s/it]  77%|███████▋  | 9789/12750 [31:57:38<9:47:59, 11.91s/it] 77%|███████▋  | 9790/12750 [31:57:49<9:41:27, 11.79s/it] 77%|███████▋  | 9791/12750 [31:58:01<9:36:58, 11.70s/it] 77%|███████▋  | 9792/12750 [31:58:12<9:33:37, 11.64s/it] 77%|███████▋  | 9793/12750 [31:58:24<9:31:32, 11.60s/it] 77%|███████▋  | 9794/12750 [31:58:35<9:30:02, 11.57s/it] 77%|███████▋  | 9795/12750 [31:58:47<9:29:10, 11.56s/it] 77%|███████▋  | 9796/12750 [31:58:58<9:28:11, 11.54s/it] 77%|███████▋  | 9797/12750 [31:59:10<9:26:33, 11.51s/it] 77%|███████▋  | 9798/12750 [31:59:21<9:26:47, 11.52s/it] 77%|███████▋  | 9799/12750 [31:59:33<9:25:49, 11.50s/it] 77%|███████▋  | 9800/12750 [31:59:44<9:25:03, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120555.23lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104620.85lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9800
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9800/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9800/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9800/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9775] due to args.save_total_limit
 77%|███████▋  | 9801/12750 [31:59:56<9:29:36, 11.59s/it] 77%|███████▋  | 9802/12750 [32:00:08<9:28:36, 11.57s/it] 77%|███████▋  | 9803/12750 [32:00:19<9:27:20, 11.55s/it] 77%|███████▋  | 9804/12750 [32:00:31<9:26:05, 11.53s/it] 77%|███████▋  | 9805/12750 [32:00:42<9:25:53, 11.53s/it] 77%|███████▋  | 9806/12750 [32:00:54<9:25:18, 11.52s/it] 77%|███████▋  | 9807/12750 [32:01:05<9:24:55, 11.52s/it] 77%|███████▋  | 9808/12750 [32:01:17<9:24:33, 11.51s/it] 77%|███████▋  | 9809/12750 [32:01:28<9:24:18, 11.51s/it] 77%|███████▋  | 9810/12750 [32:01:40<9:24:12, 11.51s/it] 77%|███████▋  | 9811/12750 [32:01:51<9:23:46, 11.51s/it] 77%|███████▋  | 9812/12750 [32:02:03<9:23:26, 11.51s/it] 77%|███████▋  | 9813/12750 [32:02:14<9:23:10, 11.50s/it] 77%|███████▋  | 9814/12750 [32:02:26<9:22:48, 11.50s/it] 77%|███████▋  | 9815/12750 [32:02:37<9:22:34, 11.50s/it] 77%|███████▋  | 9816/12750 [32:02:57<11:21:04, 13.93s/it] 77%|███████▋  | 9817/12750 [32:03:08<10:45:14, 13.20s/it] 77%|███████▋  | 9818/12750 [32:03:20<10:20:24, 12.70s/it] 77%|███████▋  | 9819/12750 [32:03:31<10:02:49, 12.34s/it] 77%|███████▋  | 9820/12750 [32:03:43<9:50:05, 12.08s/it]  77%|███████▋  | 9821/12750 [32:03:54<9:40:59, 11.90s/it] 77%|███████▋  | 9822/12750 [32:04:06<9:35:03, 11.78s/it] 77%|███████▋  | 9823/12750 [32:04:17<9:30:57, 11.70s/it] 77%|███████▋  | 9824/12750 [32:04:29<9:27:58, 11.65s/it] 77%|███████▋  | 9825/12750 [32:04:40<9:25:13, 11.59s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120574.48lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104844.20lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9825
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9825/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9825/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9825/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9800] due to args.save_total_limit
 77%|███████▋  | 9826/12750 [32:04:52<9:27:59, 11.66s/it] 77%|███████▋  | 9827/12750 [32:05:04<9:25:01, 11.60s/it] 77%|███████▋  | 9828/12750 [32:05:15<9:23:21, 11.57s/it] 77%|███████▋  | 9829/12750 [32:05:27<9:22:52, 11.56s/it] 77%|███████▋  | 9830/12750 [32:05:38<9:22:01, 11.55s/it] 77%|███████▋  | 9831/12750 [32:05:50<9:20:45, 11.53s/it] 77%|███████▋  | 9832/12750 [32:06:01<9:19:43, 11.51s/it] 77%|███████▋  | 9833/12750 [32:06:13<9:19:01, 11.50s/it] 77%|███████▋  | 9834/12750 [32:06:24<9:19:16, 11.51s/it] 77%|███████▋  | 9835/12750 [32:06:36<9:18:49, 11.50s/it] 77%|███████▋  | 9836/12750 [32:06:47<9:17:55, 11.49s/it] 77%|███████▋  | 9837/12750 [32:06:59<9:17:43, 11.49s/it] 77%|███████▋  | 9838/12750 [32:07:10<9:17:22, 11.48s/it] 77%|███████▋  | 9839/12750 [32:07:22<9:17:10, 11.48s/it] 77%|███████▋  | 9840/12750 [32:07:33<9:16:25, 11.47s/it] 77%|███████▋  | 9841/12750 [32:07:44<9:16:06, 11.47s/it] 77%|███████▋  | 9842/12750 [32:07:56<9:16:08, 11.47s/it] 77%|███████▋  | 9843/12750 [32:08:07<9:15:54, 11.47s/it] 77%|███████▋  | 9844/12750 [32:08:19<9:15:46, 11.48s/it] 77%|███████▋  | 9845/12750 [32:08:30<9:15:45, 11.48s/it] 77%|███████▋  | 9846/12750 [32:08:42<9:16:12, 11.49s/it] 77%|███████▋  | 9847/12750 [32:08:53<9:15:51, 11.49s/it] 77%|███████▋  | 9848/12750 [32:09:13<11:12:08, 13.90s/it] 77%|███████▋  | 9849/12750 [32:09:24<10:36:52, 13.17s/it] 77%|███████▋  | 9850/12750 [32:09:36<10:12:14, 12.67s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120425.49lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104783.38lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9850
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9850/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9850/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9850/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9825] due to args.save_total_limit
 77%|███████▋  | 9851/12750 [32:09:48<9:59:37, 12.41s/it]  77%|███████▋  | 9852/12750 [32:09:59<9:45:42, 12.13s/it] 77%|███████▋  | 9853/12750 [32:10:11<9:36:08, 11.93s/it] 77%|███████▋  | 9854/12750 [32:10:22<9:29:42, 11.80s/it] 77%|███████▋  | 9855/12750 [32:10:34<9:24:48, 11.71s/it] 77%|███████▋  | 9856/12750 [32:10:45<9:21:51, 11.65s/it] 77%|███████▋  | 9857/12750 [32:10:57<9:19:02, 11.59s/it] 77%|███████▋  | 9858/12750 [32:11:08<9:17:12, 11.56s/it] 77%|███████▋  | 9859/12750 [32:11:20<9:15:50, 11.54s/it] 77%|███████▋  | 9860/12750 [32:11:31<9:14:32, 11.51s/it] 77%|███████▋  | 9861/12750 [32:11:43<9:13:54, 11.50s/it] 77%|███████▋  | 9862/12750 [32:11:54<9:13:31, 11.50s/it] 77%|███████▋  | 9863/12750 [32:12:05<9:13:21, 11.50s/it] 77%|███████▋  | 9864/12750 [32:12:17<9:12:53, 11.49s/it] 77%|███████▋  | 9865/12750 [32:12:28<9:12:43, 11.50s/it] 77%|███████▋  | 9866/12750 [32:12:40<9:12:26, 11.49s/it] 77%|███████▋  | 9867/12750 [32:12:51<9:12:14, 11.49s/it] 77%|███████▋  | 9868/12750 [32:13:03<9:12:09, 11.50s/it] 77%|███████▋  | 9869/12750 [32:13:14<9:12:06, 11.50s/it] 77%|███████▋  | 9870/12750 [32:13:26<9:11:32, 11.49s/it] 77%|███████▋  | 9871/12750 [32:13:37<9:11:26, 11.49s/it] 77%|███████▋  | 9872/12750 [32:13:49<9:11:26, 11.50s/it] 77%|███████▋  | 9873/12750 [32:14:00<9:10:57, 11.49s/it] 77%|███████▋  | 9874/12750 [32:14:12<9:10:42, 11.49s/it] 77%|███████▋  | 9875/12750 [32:14:23<9:10:32, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120629.20lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104925.22lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9875
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9875/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9875/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9875/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9850] due to args.save_total_limit
 77%|███████▋  | 9876/12750 [32:14:35<9:14:34, 11.58s/it] 77%|███████▋  | 9877/12750 [32:14:47<9:12:36, 11.54s/it] 77%|███████▋  | 9878/12750 [32:14:58<9:11:24, 11.52s/it] 77%|███████▋  | 9879/12750 [32:15:10<9:10:32, 11.51s/it] 77%|███████▋  | 9880/12750 [32:15:29<11:00:13, 13.80s/it] 77%|███████▋  | 9881/12750 [32:15:40<10:26:40, 13.11s/it] 78%|███████▊  | 9882/12750 [32:15:52<10:03:39, 12.63s/it] 78%|███████▊  | 9883/12750 [32:16:03<9:46:46, 12.28s/it]  78%|███████▊  | 9884/12750 [32:16:15<9:35:22, 12.05s/it] 78%|███████▊  | 9885/12750 [32:16:26<9:27:04, 11.88s/it] 78%|███████▊  | 9886/12750 [32:16:38<9:21:11, 11.76s/it] 78%|███████▊  | 9887/12750 [32:16:49<9:17:25, 11.68s/it] 78%|███████▊  | 9888/12750 [32:17:01<9:15:11, 11.64s/it] 78%|███████▊  | 9889/12750 [32:17:12<9:12:57, 11.60s/it] 78%|███████▊  | 9890/12750 [32:17:24<9:11:11, 11.56s/it] 78%|███████▊  | 9891/12750 [32:17:35<9:09:38, 11.53s/it] 78%|███████▊  | 9892/12750 [32:17:47<9:09:14, 11.53s/it] 78%|███████▊  | 9893/12750 [32:17:58<9:08:18, 11.51s/it] 78%|███████▊  | 9894/12750 [32:18:10<9:07:47, 11.51s/it] 78%|███████▊  | 9895/12750 [32:18:21<9:07:15, 11.50s/it] 78%|███████▊  | 9896/12750 [32:18:33<9:06:42, 11.49s/it] 78%|███████▊  | 9897/12750 [32:18:44<9:06:26, 11.49s/it] 78%|███████▊  | 9898/12750 [32:18:56<9:05:45, 11.48s/it] 78%|███████▊  | 9899/12750 [32:19:07<9:05:39, 11.48s/it] 78%|███████▊  | 9900/12750 [32:19:19<9:05:40, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120522.13lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104824.50lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9900
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9900/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9900/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9900/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9875] due to args.save_total_limit
 78%|███████▊  | 9901/12750 [32:19:30<9:09:50, 11.58s/it] 78%|███████▊  | 9902/12750 [32:19:42<9:07:58, 11.54s/it] 78%|███████▊  | 9903/12750 [32:19:53<9:06:42, 11.52s/it] 78%|███████▊  | 9904/12750 [32:20:05<9:05:19, 11.50s/it] 78%|███████▊  | 9905/12750 [32:20:16<9:04:46, 11.49s/it] 78%|███████▊  | 9906/12750 [32:20:28<9:04:08, 11.48s/it] 78%|███████▊  | 9907/12750 [32:20:39<9:03:42, 11.47s/it] 78%|███████▊  | 9908/12750 [32:20:51<9:02:55, 11.46s/it] 78%|███████▊  | 9909/12750 [32:21:02<9:02:19, 11.45s/it] 78%|███████▊  | 9910/12750 [32:21:13<9:02:27, 11.46s/it] 78%|███████▊  | 9911/12750 [32:21:25<9:02:26, 11.46s/it] 78%|███████▊  | 9912/12750 [32:21:44<10:56:35, 13.88s/it] 78%|███████▊  | 9913/12750 [32:21:56<10:22:24, 13.16s/it] 78%|███████▊  | 9914/12750 [32:22:07<9:58:13, 12.66s/it]  78%|███████▊  | 9915/12750 [32:22:19<9:41:26, 12.31s/it] 78%|███████▊  | 9916/12750 [32:22:30<9:29:25, 12.06s/it] 78%|███████▊  | 9917/12750 [32:22:42<9:20:53, 11.88s/it] 78%|███████▊  | 9918/12750 [32:22:53<9:14:23, 11.75s/it] 78%|███████▊  | 9919/12750 [32:23:05<9:10:11, 11.66s/it] 78%|███████▊  | 9920/12750 [32:23:16<9:07:28, 11.61s/it] 78%|███████▊  | 9921/12750 [32:23:28<9:05:11, 11.56s/it] 78%|███████▊  | 9922/12750 [32:23:39<9:03:48, 11.54s/it] 78%|███████▊  | 9923/12750 [32:23:51<9:02:43, 11.52s/it] 78%|███████▊  | 9924/12750 [32:24:02<9:02:02, 11.51s/it] 78%|███████▊  | 9925/12750 [32:24:14<9:01:29, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120574.10lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104856.53lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9925
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9925/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9925/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9925/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9900] due to args.save_total_limit
 78%|███████▊  | 9926/12750 [32:24:25<9:04:43, 11.57s/it] 78%|███████▊  | 9927/12750 [32:24:37<9:02:54, 11.54s/it] 78%|███████▊  | 9928/12750 [32:24:48<9:02:00, 11.52s/it] 78%|███████▊  | 9929/12750 [32:25:00<9:01:02, 11.51s/it] 78%|███████▊  | 9930/12750 [32:25:11<9:00:26, 11.50s/it] 78%|███████▊  | 9931/12750 [32:25:23<8:59:49, 11.49s/it] 78%|███████▊  | 9932/12750 [32:25:34<8:59:19, 11.48s/it] 78%|███████▊  | 9933/12750 [32:25:46<8:58:21, 11.47s/it] 78%|███████▊  | 9934/12750 [32:25:57<8:58:04, 11.46s/it] 78%|███████▊  | 9935/12750 [32:26:09<8:58:05, 11.47s/it] 78%|███████▊  | 9936/12750 [32:26:20<8:57:48, 11.47s/it] 78%|███████▊  | 9937/12750 [32:26:31<8:57:06, 11.46s/it] 78%|███████▊  | 9938/12750 [32:26:43<8:56:46, 11.45s/it] 78%|███████▊  | 9939/12750 [32:26:54<8:56:38, 11.45s/it] 78%|███████▊  | 9940/12750 [32:27:06<8:56:33, 11.46s/it] 78%|███████▊  | 9941/12750 [32:27:17<8:56:23, 11.46s/it] 78%|███████▊  | 9942/12750 [32:27:29<8:56:23, 11.46s/it] 78%|███████▊  | 9943/12750 [32:27:40<8:56:13, 11.46s/it] 78%|███████▊  | 9944/12750 [32:27:52<8:55:35, 11.45s/it] 78%|███████▊  | 9945/12750 [32:28:11<10:49:39, 13.90s/it] 78%|███████▊  | 9946/12750 [32:28:23<10:16:05, 13.18s/it] 78%|███████▊  | 9947/12750 [32:28:34<9:52:48, 12.69s/it]  78%|███████▊  | 9948/12750 [32:28:46<9:36:22, 12.34s/it] 78%|███████▊  | 9949/12750 [32:28:57<9:23:53, 12.08s/it] 78%|███████▊  | 9950/12750 [32:29:09<9:15:32, 11.90s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120646.29lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104972.00lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9950
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9950/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9950/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9950/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9925] due to args.save_total_limit
 78%|███████▊  | 9951/12750 [32:29:21<9:13:57, 11.87s/it] 78%|███████▊  | 9952/12750 [32:29:32<9:08:04, 11.75s/it] 78%|███████▊  | 9953/12750 [32:29:44<9:04:19, 11.68s/it] 78%|███████▊  | 9954/12750 [32:29:55<9:01:23, 11.62s/it] 78%|███████▊  | 9955/12750 [32:30:06<8:59:24, 11.58s/it] 78%|███████▊  | 9956/12750 [32:30:18<8:57:58, 11.55s/it] 78%|███████▊  | 9957/12750 [32:30:29<8:57:18, 11.54s/it] 78%|███████▊  | 9958/12750 [32:30:41<8:56:37, 11.53s/it] 78%|███████▊  | 9959/12750 [32:30:53<8:55:55, 11.52s/it] 78%|███████▊  | 9960/12750 [32:31:04<8:54:47, 11.50s/it] 78%|███████▊  | 9961/12750 [32:31:15<8:54:26, 11.50s/it] 78%|███████▊  | 9962/12750 [32:31:27<8:54:01, 11.49s/it] 78%|███████▊  | 9963/12750 [32:31:38<8:53:22, 11.48s/it] 78%|███████▊  | 9964/12750 [32:31:50<8:53:21, 11.49s/it] 78%|███████▊  | 9965/12750 [32:32:01<8:53:09, 11.49s/it] 78%|███████▊  | 9966/12750 [32:32:13<8:53:06, 11.49s/it] 78%|███████▊  | 9967/12750 [32:32:24<8:52:39, 11.48s/it] 78%|███████▊  | 9968/12750 [32:32:36<8:52:26, 11.48s/it] 78%|███████▊  | 9969/12750 [32:32:47<8:52:02, 11.48s/it] 78%|███████▊  | 9970/12750 [32:32:59<8:52:01, 11.48s/it] 78%|███████▊  | 9971/12750 [32:33:10<8:51:52, 11.48s/it] 78%|███████▊  | 9972/12750 [32:33:22<8:51:47, 11.49s/it] 78%|███████▊  | 9973/12750 [32:33:33<8:51:50, 11.49s/it] 78%|███████▊  | 9974/12750 [32:33:45<8:52:29, 11.51s/it] 78%|███████▊  | 9975/12750 [32:33:56<8:52:19, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120627.27lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104877.02lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9975
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9975/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9975/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-9975/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9950] due to args.save_total_limit
 78%|███████▊  | 9976/12750 [32:34:08<8:56:17, 11.60s/it] 78%|███████▊  | 9977/12750 [32:34:28<10:46:31, 13.99s/it] 78%|███████▊  | 9978/12750 [32:34:39<10:12:25, 13.26s/it] 78%|███████▊  | 9979/12750 [32:34:51<9:48:16, 12.74s/it]  78%|███████▊  | 9980/12750 [32:35:02<9:31:21, 12.38s/it] 78%|███████▊  | 9981/12750 [32:35:14<9:18:59, 12.11s/it] 78%|███████▊  | 9982/12750 [32:35:25<9:10:36, 11.94s/it] 78%|███████▊  | 9983/12750 [32:35:37<9:04:30, 11.81s/it] 78%|███████▊  | 9984/12750 [32:35:48<9:00:09, 11.72s/it] 78%|███████▊  | 9985/12750 [32:36:00<8:56:53, 11.65s/it] 78%|███████▊  | 9986/12750 [32:36:11<8:55:05, 11.62s/it] 78%|███████▊  | 9987/12750 [32:36:23<8:53:26, 11.58s/it] 78%|███████▊  | 9988/12750 [32:36:34<8:52:14, 11.56s/it] 78%|███████▊  | 9989/12750 [32:36:46<8:51:17, 11.55s/it] 78%|███████▊  | 9990/12750 [32:36:57<8:51:07, 11.55s/it] 78%|███████▊  | 9991/12750 [32:37:09<8:50:31, 11.54s/it] 78%|███████▊  | 9992/12750 [32:37:20<8:50:06, 11.53s/it] 78%|███████▊  | 9993/12750 [32:37:32<8:49:28, 11.52s/it] 78%|███████▊  | 9994/12750 [32:37:43<8:49:12, 11.52s/it] 78%|███████▊  | 9995/12750 [32:37:55<8:49:01, 11.52s/it] 78%|███████▊  | 9996/12750 [32:38:07<8:48:49, 11.52s/it] 78%|███████▊  | 9997/12750 [32:38:18<8:48:35, 11.52s/it] 78%|███████▊  | 9998/12750 [32:38:30<8:48:41, 11.53s/it] 78%|███████▊  | 9999/12750 [32:38:41<8:48:00, 11.52s/it] 78%|███████▊  | 10000/12750 [32:38:53<8:48:10, 11.52s/it]                                                           78%|███████▊  | 10000/12750 [32:38:53<8:48:10, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120566.65lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104715.46lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10000
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10000/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10000/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10000/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-9975] due to args.save_total_limit
 78%|███████▊  | 10001/12750 [32:39:04<8:51:43, 11.61s/it] 78%|███████▊  | 10002/12750 [32:39:16<8:50:13, 11.58s/it] 78%|███████▊  | 10003/12750 [32:39:27<8:49:06, 11.56s/it] 78%|███████▊  | 10004/12750 [32:39:39<8:48:17, 11.54s/it] 78%|███████▊  | 10005/12750 [32:39:50<8:47:49, 11.54s/it] 78%|███████▊  | 10006/12750 [32:40:02<8:47:17, 11.53s/it] 78%|███████▊  | 10007/12750 [32:40:14<8:47:00, 11.53s/it] 78%|███████▊  | 10008/12750 [32:40:25<8:46:27, 11.52s/it] 79%|███████▊  | 10009/12750 [32:40:44<10:32:57, 13.86s/it] 79%|███████▊  | 10010/12750 [32:40:56<10:01:12, 13.17s/it] 79%|███████▊  | 10011/12750 [32:41:07<9:38:39, 12.68s/it]  79%|███████▊  | 10012/12750 [32:41:19<9:22:54, 12.34s/it] 79%|███████▊  | 10013/12750 [32:41:30<9:11:09, 12.08s/it] 79%|███████▊  | 10014/12750 [32:41:42<9:03:10, 11.91s/it] 79%|███████▊  | 10015/12750 [32:41:53<8:57:10, 11.78s/it] 79%|███████▊  | 10016/12750 [32:42:05<8:53:00, 11.70s/it] 79%|███████▊  | 10017/12750 [32:42:16<8:50:06, 11.64s/it] 79%|███████▊  | 10018/12750 [32:42:28<8:48:10, 11.60s/it] 79%|███████▊  | 10019/12750 [32:42:39<8:46:54, 11.58s/it] 79%|███████▊  | 10020/12750 [32:42:51<8:45:52, 11.56s/it] 79%|███████▊  | 10021/12750 [32:43:02<8:44:45, 11.54s/it] 79%|███████▊  | 10022/12750 [32:43:14<8:44:31, 11.54s/it] 79%|███████▊  | 10023/12750 [32:43:26<8:44:11, 11.53s/it] 79%|███████▊  | 10024/12750 [32:43:37<8:44:00, 11.53s/it] 79%|███████▊  | 10025/12750 [32:43:49<8:43:32, 11.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120035.67lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104541.84lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10025
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10025/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10025/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10025/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10000] due to args.save_total_limit
 79%|███████▊  | 10026/12750 [32:44:00<8:46:47, 11.60s/it] 79%|███████▊  | 10027/12750 [32:44:12<8:44:44, 11.56s/it] 79%|███████▊  | 10028/12750 [32:44:23<8:43:44, 11.54s/it] 79%|███████▊  | 10029/12750 [32:44:35<8:42:55, 11.53s/it] 79%|███████▊  | 10030/12750 [32:44:46<8:42:43, 11.53s/it] 79%|███████▊  | 10031/12750 [32:44:58<8:42:14, 11.52s/it] 79%|███████▊  | 10032/12750 [32:45:09<8:41:27, 11.51s/it] 79%|███████▊  | 10033/12750 [32:45:21<8:41:10, 11.51s/it] 79%|███████▊  | 10034/12750 [32:45:32<8:41:15, 11.52s/it] 79%|███████▊  | 10035/12750 [32:45:44<8:40:44, 11.51s/it] 79%|███████▊  | 10036/12750 [32:45:55<8:40:31, 11.51s/it] 79%|███████▊  | 10037/12750 [32:46:07<8:40:18, 11.51s/it] 79%|███████▊  | 10038/12750 [32:46:18<8:40:11, 11.51s/it] 79%|███████▊  | 10039/12750 [32:46:30<8:39:31, 11.50s/it] 79%|███████▊  | 10040/12750 [32:46:41<8:39:25, 11.50s/it] 79%|███████▉  | 10041/12750 [32:47:01<10:23:20, 13.81s/it] 79%|███████▉  | 10042/12750 [32:47:12<9:51:41, 13.11s/it]  79%|███████▉  | 10043/12750 [32:47:24<9:29:50, 12.63s/it] 79%|███████▉  | 10044/12750 [32:47:35<9:14:31, 12.30s/it] 79%|███████▉  | 10045/12750 [32:47:47<9:03:50, 12.06s/it] 79%|███████▉  | 10046/12750 [32:47:58<8:56:28, 11.90s/it] 79%|███████▉  | 10047/12750 [32:48:10<8:50:41, 11.78s/it] 79%|███████▉  | 10048/12750 [32:48:21<8:46:56, 11.70s/it] 79%|███████▉  | 10049/12750 [32:48:33<8:44:30, 11.65s/it] 79%|███████▉  | 10050/12750 [32:48:44<8:42:12, 11.60s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120443.81lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104790.07lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10050
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10050/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10050/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10050/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10025] due to args.save_total_limit
 79%|███████▉  | 10051/12750 [32:48:56<8:45:01, 11.67s/it] 79%|███████▉  | 10052/12750 [32:49:08<8:42:51, 11.63s/it] 79%|███████▉  | 10053/12750 [32:49:19<8:40:54, 11.59s/it] 79%|███████▉  | 10054/12750 [32:49:31<8:39:31, 11.56s/it] 79%|███████▉  | 10055/12750 [32:49:42<8:38:13, 11.54s/it] 79%|███████▉  | 10056/12750 [32:49:53<8:37:03, 11.52s/it] 79%|███████▉  | 10057/12750 [32:50:05<8:36:29, 11.51s/it] 79%|███████▉  | 10058/12750 [32:50:16<8:36:10, 11.50s/it] 79%|███████▉  | 10059/12750 [32:50:28<8:35:52, 11.50s/it] 79%|███████▉  | 10060/12750 [32:50:39<8:35:41, 11.50s/it] 79%|███████▉  | 10061/12750 [32:50:51<8:35:14, 11.50s/it] 79%|███████▉  | 10062/12750 [32:51:02<8:34:58, 11.49s/it] 79%|███████▉  | 10063/12750 [32:51:14<8:34:41, 11.49s/it] 79%|███████▉  | 10064/12750 [32:51:25<8:34:36, 11.50s/it] 79%|███████▉  | 10065/12750 [32:51:37<8:34:36, 11.50s/it] 79%|███████▉  | 10066/12750 [32:51:48<8:34:33, 11.50s/it] 79%|███████▉  | 10067/12750 [32:52:00<8:34:17, 11.50s/it] 79%|███████▉  | 10068/12750 [32:52:11<8:33:44, 11.49s/it] 79%|███████▉  | 10069/12750 [32:52:23<8:33:53, 11.50s/it] 79%|███████▉  | 10070/12750 [32:52:34<8:33:42, 11.50s/it] 79%|███████▉  | 10071/12750 [32:52:46<8:33:52, 11.51s/it] 79%|███████▉  | 10072/12750 [32:52:57<8:33:43, 11.51s/it] 79%|███████▉  | 10073/12750 [32:53:17<10:16:26, 13.82s/it] 79%|███████▉  | 10074/12750 [32:53:28<9:45:25, 13.13s/it]  79%|███████▉  | 10075/12750 [32:53:40<9:23:51, 12.65s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120406.29lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104766.61lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10075
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10075/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10075/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10075/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10050] due to args.save_total_limit
 79%|███████▉  | 10076/12750 [32:53:52<9:12:20, 12.39s/it] 79%|███████▉  | 10077/12750 [32:54:03<8:59:57, 12.12s/it] 79%|███████▉  | 10078/12750 [32:54:14<8:51:17, 11.93s/it] 79%|███████▉  | 10079/12750 [32:54:26<8:45:25, 11.80s/it] 79%|███████▉  | 10080/12750 [32:54:37<8:41:13, 11.71s/it] 79%|███████▉  | 10081/12750 [32:54:49<8:38:30, 11.66s/it] 79%|███████▉  | 10082/12750 [32:55:01<8:36:34, 11.62s/it] 79%|███████▉  | 10083/12750 [32:55:12<8:34:51, 11.58s/it] 79%|███████▉  | 10084/12750 [32:55:24<8:33:17, 11.55s/it] 79%|███████▉  | 10085/12750 [32:55:35<8:32:32, 11.54s/it] 79%|███████▉  | 10086/12750 [32:55:47<8:31:55, 11.53s/it] 79%|███████▉  | 10087/12750 [32:55:58<8:31:34, 11.53s/it] 79%|███████▉  | 10088/12750 [32:56:10<8:31:09, 11.52s/it] 79%|███████▉  | 10089/12750 [32:56:21<8:30:50, 11.52s/it] 79%|███████▉  | 10090/12750 [32:56:33<8:30:45, 11.52s/it] 79%|███████▉  | 10091/12750 [32:56:44<8:30:35, 11.52s/it] 79%|███████▉  | 10092/12750 [32:56:56<8:30:10, 11.52s/it] 79%|███████▉  | 10093/12750 [32:57:07<8:29:51, 11.51s/it] 79%|███████▉  | 10094/12750 [32:57:19<8:29:20, 11.51s/it] 79%|███████▉  | 10095/12750 [32:57:30<8:29:17, 11.51s/it] 79%|███████▉  | 10096/12750 [32:57:42<8:28:29, 11.50s/it] 79%|███████▉  | 10097/12750 [32:57:53<8:28:24, 11.50s/it] 79%|███████▉  | 10098/12750 [32:58:05<8:27:57, 11.49s/it] 79%|███████▉  | 10099/12750 [32:58:16<8:27:29, 11.49s/it] 79%|███████▉  | 10100/12750 [32:58:28<8:27:26, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120483.79lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104796.18lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10100
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10100/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10100/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10100/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10075] due to args.save_total_limit
 79%|███████▉  | 10101/12750 [32:58:39<8:31:27, 11.58s/it] 79%|███████▉  | 10102/12750 [32:58:51<8:30:00, 11.56s/it] 79%|███████▉  | 10103/12750 [32:59:02<8:28:41, 11.53s/it] 79%|███████▉  | 10104/12750 [32:59:14<8:28:00, 11.52s/it] 79%|███████▉  | 10105/12750 [32:59:32<10:01:48, 13.65s/it] 79%|███████▉  | 10106/12750 [32:59:44<9:33:03, 13.00s/it]  79%|███████▉  | 10107/12750 [32:59:55<9:12:59, 12.55s/it] 79%|███████▉  | 10108/12750 [33:00:07<8:58:35, 12.23s/it] 79%|███████▉  | 10109/12750 [33:00:18<8:48:39, 12.01s/it] 79%|███████▉  | 10110/12750 [33:00:30<8:41:47, 11.86s/it] 79%|███████▉  | 10111/12750 [33:00:41<8:36:20, 11.74s/it] 79%|███████▉  | 10112/12750 [33:00:53<8:32:54, 11.67s/it] 79%|███████▉  | 10113/12750 [33:01:04<8:30:41, 11.62s/it] 79%|███████▉  | 10114/12750 [33:01:16<8:28:42, 11.58s/it] 79%|███████▉  | 10115/12750 [33:01:27<8:27:43, 11.56s/it] 79%|███████▉  | 10116/12750 [33:01:39<8:26:51, 11.55s/it] 79%|███████▉  | 10117/12750 [33:01:50<8:26:03, 11.53s/it] 79%|███████▉  | 10118/12750 [33:02:02<8:25:35, 11.53s/it] 79%|███████▉  | 10119/12750 [33:02:13<8:25:02, 11.52s/it] 79%|███████▉  | 10120/12750 [33:02:25<8:24:27, 11.51s/it] 79%|███████▉  | 10121/12750 [33:02:36<8:24:01, 11.50s/it] 79%|███████▉  | 10122/12750 [33:02:48<8:23:26, 11.49s/it] 79%|███████▉  | 10123/12750 [33:02:59<8:23:34, 11.50s/it] 79%|███████▉  | 10124/12750 [33:03:11<8:23:19, 11.50s/it] 79%|███████▉  | 10125/12750 [33:03:22<8:23:12, 11.50s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120345.77lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104289.99lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10125
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10125/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10125/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10125/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10100] due to args.save_total_limit
 79%|███████▉  | 10126/12750 [33:03:34<8:26:51, 11.59s/it] 79%|███████▉  | 10127/12750 [33:03:46<8:25:18, 11.56s/it] 79%|███████▉  | 10128/12750 [33:03:57<8:24:18, 11.54s/it] 79%|███████▉  | 10129/12750 [33:04:09<8:23:30, 11.53s/it] 79%|███████▉  | 10130/12750 [33:04:20<8:22:56, 11.52s/it] 79%|███████▉  | 10131/12750 [33:04:32<8:22:29, 11.51s/it] 79%|███████▉  | 10132/12750 [33:04:43<8:22:16, 11.51s/it] 79%|███████▉  | 10133/12750 [33:04:55<8:21:52, 11.51s/it] 79%|███████▉  | 10134/12750 [33:05:06<8:21:13, 11.50s/it] 79%|███████▉  | 10135/12750 [33:05:18<8:21:19, 11.50s/it] 79%|███████▉  | 10136/12750 [33:05:29<8:21:11, 11.50s/it] 80%|███████▉  | 10137/12750 [33:05:47<9:49:47, 13.54s/it] 80%|███████▉  | 10138/12750 [33:05:59<9:22:24, 12.92s/it] 80%|███████▉  | 10139/12750 [33:06:10<9:03:24, 12.49s/it] 80%|███████▉  | 10140/12750 [33:06:22<8:49:49, 12.18s/it] 80%|███████▉  | 10141/12750 [33:06:33<8:40:06, 11.96s/it] 80%|███████▉  | 10142/12750 [33:06:45<8:33:29, 11.81s/it] 80%|███████▉  | 10143/12750 [33:06:56<8:29:03, 11.72s/it] 80%|███████▉  | 10144/12750 [33:07:08<8:26:08, 11.65s/it] 80%|███████▉  | 10145/12750 [33:07:19<8:23:27, 11.60s/it] 80%|███████▉  | 10146/12750 [33:07:31<8:21:53, 11.56s/it] 80%|███████▉  | 10147/12750 [33:07:42<8:20:49, 11.54s/it] 80%|███████▉  | 10148/12750 [33:07:54<8:20:01, 11.53s/it] 80%|███████▉  | 10149/12750 [33:08:05<8:19:15, 11.52s/it] 80%|███████▉  | 10150/12750 [33:08:17<8:18:33, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120394.64lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104726.59lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10150
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10150/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10150/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10150/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10125] due to args.save_total_limit
 80%|███████▉  | 10151/12750 [33:08:29<8:22:37, 11.60s/it] 80%|███████▉  | 10152/12750 [33:08:40<8:21:03, 11.57s/it] 80%|███████▉  | 10153/12750 [33:08:52<8:19:51, 11.55s/it] 80%|███████▉  | 10154/12750 [33:09:03<8:18:58, 11.53s/it] 80%|███████▉  | 10155/12750 [33:09:14<8:18:10, 11.52s/it] 80%|███████▉  | 10156/12750 [33:09:26<8:17:28, 11.51s/it] 80%|███████▉  | 10157/12750 [33:09:37<8:17:06, 11.50s/it] 80%|███████▉  | 10158/12750 [33:09:49<8:16:43, 11.50s/it] 80%|███████▉  | 10159/12750 [33:10:00<8:16:30, 11.50s/it] 80%|███████▉  | 10160/12750 [33:10:12<8:16:14, 11.50s/it] 80%|███████▉  | 10161/12750 [33:10:23<8:15:53, 11.49s/it] 80%|███████▉  | 10162/12750 [33:10:35<8:15:23, 11.49s/it] 80%|███████▉  | 10163/12750 [33:10:46<8:15:28, 11.49s/it] 80%|███████▉  | 10164/12750 [33:10:58<8:15:21, 11.49s/it] 80%|███████▉  | 10165/12750 [33:11:09<8:15:25, 11.50s/it] 80%|███████▉  | 10166/12750 [33:11:21<8:15:25, 11.50s/it] 80%|███████▉  | 10167/12750 [33:11:32<8:14:51, 11.50s/it] 80%|███████▉  | 10168/12750 [33:11:44<8:14:44, 11.50s/it] 80%|███████▉  | 10169/12750 [33:12:03<9:53:53, 13.81s/it] 80%|███████▉  | 10170/12750 [33:12:15<9:23:32, 13.11s/it] 80%|███████▉  | 10171/12750 [33:12:26<9:02:30, 12.62s/it] 80%|███████▉  | 10172/12750 [33:12:38<8:47:53, 12.29s/it] 80%|███████▉  | 10173/12750 [33:12:49<8:37:29, 12.05s/it] 80%|███████▉  | 10174/12750 [33:13:01<8:30:10, 11.88s/it] 80%|███████▉  | 10175/12750 [33:13:12<8:24:41, 11.76s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120041.52lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 103900.08lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10175
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10175/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10175/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10175/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10150] due to args.save_total_limit
 80%|███████▉  | 10176/12750 [33:13:24<8:27:46, 11.84s/it] 80%|███████▉  | 10177/12750 [33:13:35<8:22:43, 11.72s/it] 80%|███████▉  | 10178/12750 [33:13:47<8:19:25, 11.65s/it] 80%|███████▉  | 10179/12750 [33:13:58<8:17:14, 11.60s/it] 80%|███████▉  | 10180/12750 [33:14:10<8:15:17, 11.56s/it] 80%|███████▉  | 10181/12750 [33:14:21<8:14:23, 11.55s/it] 80%|███████▉  | 10182/12750 [33:14:33<8:13:15, 11.52s/it] 80%|███████▉  | 10183/12750 [33:14:44<8:12:36, 11.51s/it] 80%|███████▉  | 10184/12750 [33:14:56<8:11:58, 11.50s/it] 80%|███████▉  | 10185/12750 [33:15:07<8:11:26, 11.50s/it] 80%|███████▉  | 10186/12750 [33:15:19<8:11:01, 11.49s/it] 80%|███████▉  | 10187/12750 [33:15:30<8:10:25, 11.48s/it] 80%|███████▉  | 10188/12750 [33:15:42<8:10:24, 11.49s/it] 80%|███████▉  | 10189/12750 [33:15:53<8:10:09, 11.48s/it] 80%|███████▉  | 10190/12750 [33:16:05<8:10:01, 11.49s/it] 80%|███████▉  | 10191/12750 [33:16:16<8:09:15, 11.47s/it] 80%|███████▉  | 10192/12750 [33:16:28<8:09:02, 11.47s/it] 80%|███████▉  | 10193/12750 [33:16:39<8:09:15, 11.48s/it] 80%|███████▉  | 10194/12750 [33:16:51<8:09:11, 11.48s/it] 80%|███████▉  | 10195/12750 [33:17:02<8:09:10, 11.49s/it] 80%|███████▉  | 10196/12750 [33:17:14<8:09:15, 11.49s/it] 80%|███████▉  | 10197/12750 [33:17:25<8:08:47, 11.49s/it] 80%|███████▉  | 10198/12750 [33:17:37<8:08:34, 11.49s/it] 80%|███████▉  | 10199/12750 [33:17:44<7:11:39, 10.15s/it] 80%|████████  | 10200/12750 [33:17:44<5:12:06,  7.34s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120477.00lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104652.95lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10200
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10200/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10200/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10200/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10175] due to args.save_total_limit
 80%|████████  | 10201/12750 [33:18:08<8:35:35, 12.14s/it] 80%|████████  | 10202/12750 [33:18:27<10:06:54, 14.29s/it] 80%|████████  | 10203/12750 [33:18:39<9:31:12, 13.46s/it]  80%|████████  | 10204/12750 [33:18:50<9:06:07, 12.87s/it] 80%|████████  | 10205/12750 [33:19:02<8:48:56, 12.47s/it] 80%|████████  | 10206/12750 [33:19:13<8:36:37, 12.18s/it] 80%|████████  | 10207/12750 [33:19:25<8:27:58, 11.99s/it] 80%|████████  | 10208/12750 [33:19:36<8:22:18, 11.86s/it] 80%|████████  | 10209/12750 [33:19:48<8:18:17, 11.77s/it] 80%|████████  | 10210/12750 [33:19:59<8:15:10, 11.70s/it] 80%|████████  | 10211/12750 [33:20:11<8:12:46, 11.64s/it] 80%|████████  | 10212/12750 [33:20:22<8:10:47, 11.60s/it] 80%|████████  | 10213/12750 [33:20:34<8:09:19, 11.57s/it] 80%|████████  | 10214/12750 [33:20:45<8:08:48, 11.56s/it] 80%|████████  | 10215/12750 [33:20:57<8:07:46, 11.54s/it] 80%|████████  | 10216/12750 [33:21:08<8:07:29, 11.54s/it] 80%|████████  | 10217/12750 [33:21:20<8:06:47, 11.53s/it] 80%|████████  | 10218/12750 [33:21:31<8:06:47, 11.54s/it] 80%|████████  | 10219/12750 [33:21:43<8:05:48, 11.52s/it] 80%|████████  | 10220/12750 [33:21:55<8:05:53, 11.52s/it] 80%|████████  | 10221/12750 [33:22:06<8:05:41, 11.52s/it] 80%|████████  | 10222/12750 [33:22:18<8:05:25, 11.52s/it] 80%|████████  | 10223/12750 [33:22:29<8:04:56, 11.51s/it] 80%|████████  | 10224/12750 [33:22:41<8:04:51, 11.52s/it] 80%|████████  | 10225/12750 [33:22:52<8:04:34, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120451.75lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104790.07lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10225
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10225/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10225/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10225/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10200] due to args.save_total_limit
 80%|████████  | 10226/12750 [33:23:04<8:08:01, 11.60s/it] 80%|████████  | 10227/12750 [33:23:15<8:07:21, 11.59s/it] 80%|████████  | 10228/12750 [33:23:27<8:06:31, 11.57s/it] 80%|████████  | 10229/12750 [33:23:38<8:05:34, 11.56s/it] 80%|████████  | 10230/12750 [33:23:50<8:04:53, 11.55s/it] 80%|████████  | 10231/12750 [33:24:02<8:04:01, 11.53s/it] 80%|████████  | 10232/12750 [33:24:13<8:03:42, 11.53s/it] 80%|████████  | 10233/12750 [33:24:25<8:03:32, 11.53s/it] 80%|████████  | 10234/12750 [33:24:44<9:38:43, 13.80s/it] 80%|████████  | 10235/12750 [33:24:55<9:09:53, 13.12s/it] 80%|████████  | 10236/12750 [33:25:07<8:49:49, 12.65s/it] 80%|████████  | 10237/12750 [33:25:18<8:35:48, 12.32s/it] 80%|████████  | 10238/12750 [33:25:30<8:25:49, 12.08s/it] 80%|████████  | 10239/12750 [33:25:41<8:18:27, 11.91s/it] 80%|████████  | 10240/12750 [33:25:53<8:13:30, 11.80s/it] 80%|████████  | 10241/12750 [33:26:04<8:09:49, 11.71s/it] 80%|████████  | 10242/12750 [33:26:16<8:07:17, 11.66s/it] 80%|████████  | 10243/12750 [33:26:27<8:05:07, 11.61s/it] 80%|████████  | 10244/12750 [33:26:39<8:03:43, 11.58s/it] 80%|████████  | 10245/12750 [33:26:50<8:03:10, 11.57s/it] 80%|████████  | 10246/12750 [33:27:02<8:02:13, 11.55s/it] 80%|████████  | 10247/12750 [33:27:14<8:01:48, 11.55s/it] 80%|████████  | 10248/12750 [33:27:25<8:01:01, 11.54s/it] 80%|████████  | 10249/12750 [33:27:37<8:00:56, 11.54s/it] 80%|████████  | 10250/12750 [33:27:48<8:00:26, 11.53s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120445.60lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104872.75lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10250
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10250/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10250/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10250/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10225] due to args.save_total_limit
 80%|████████  | 10251/12750 [33:28:00<8:04:17, 11.63s/it] 80%|████████  | 10252/12750 [33:28:11<8:02:30, 11.59s/it] 80%|████████  | 10253/12750 [33:28:23<8:01:17, 11.56s/it] 80%|████████  | 10254/12750 [33:28:34<8:00:34, 11.55s/it] 80%|████████  | 10255/12750 [33:28:46<7:59:48, 11.54s/it] 80%|████████  | 10256/12750 [33:28:57<7:59:07, 11.53s/it] 80%|████████  | 10257/12750 [33:29:09<7:58:36, 11.52s/it] 80%|████████  | 10258/12750 [33:29:21<7:58:39, 11.52s/it] 80%|████████  | 10259/12750 [33:29:32<7:58:17, 11.52s/it] 80%|████████  | 10260/12750 [33:29:44<7:57:58, 11.52s/it] 80%|████████  | 10261/12750 [33:29:55<7:57:30, 11.51s/it] 80%|████████  | 10262/12750 [33:30:07<7:57:36, 11.52s/it] 80%|████████  | 10263/12750 [33:30:18<7:57:33, 11.52s/it] 81%|████████  | 10264/12750 [33:30:30<7:57:30, 11.52s/it] 81%|████████  | 10265/12750 [33:30:41<7:57:02, 11.52s/it] 81%|████████  | 10266/12750 [33:30:53<7:56:50, 11.52s/it] 81%|████████  | 10267/12750 [33:31:12<9:33:36, 13.86s/it] 81%|████████  | 10268/12750 [33:31:23<9:04:14, 13.16s/it] 81%|████████  | 10269/12750 [33:31:35<8:43:38, 12.66s/it] 81%|████████  | 10270/12750 [33:31:47<8:29:19, 12.32s/it] 81%|████████  | 10271/12750 [33:31:58<8:19:48, 12.10s/it] 81%|████████  | 10272/12750 [33:32:10<8:12:36, 11.93s/it] 81%|████████  | 10273/12750 [33:32:21<8:08:00, 11.82s/it] 81%|████████  | 10274/12750 [33:32:33<8:04:23, 11.74s/it] 81%|████████  | 10275/12750 [33:32:44<8:01:43, 11.68s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120472.38lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104758.66lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10275
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10275/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10275/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10275/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10250] due to args.save_total_limit
 81%|████████  | 10276/12750 [33:32:56<8:03:15, 11.72s/it] 81%|████████  | 10277/12750 [33:33:08<8:00:35, 11.66s/it] 81%|████████  | 10278/12750 [33:33:19<7:58:39, 11.62s/it] 81%|████████  | 10279/12750 [33:33:31<7:56:59, 11.58s/it] 81%|████████  | 10280/12750 [33:33:42<7:55:57, 11.56s/it] 81%|████████  | 10281/12750 [33:33:54<7:55:06, 11.55s/it] 81%|████████  | 10282/12750 [33:34:05<7:54:34, 11.54s/it] 81%|████████  | 10283/12750 [33:34:17<7:54:16, 11.53s/it] 81%|████████  | 10284/12750 [33:34:28<7:54:00, 11.53s/it] 81%|████████  | 10285/12750 [33:34:40<7:53:22, 11.52s/it] 81%|████████  | 10286/12750 [33:34:51<7:53:03, 11.52s/it] 81%|████████  | 10287/12750 [33:35:03<7:52:35, 11.51s/it] 81%|████████  | 10288/12750 [33:35:14<7:52:09, 11.51s/it] 81%|████████  | 10289/12750 [33:35:26<7:51:57, 11.51s/it] 81%|████████  | 10290/12750 [33:35:37<7:51:59, 11.51s/it] 81%|████████  | 10291/12750 [33:35:49<7:51:58, 11.52s/it] 81%|████████  | 10292/12750 [33:36:00<7:52:10, 11.53s/it] 81%|████████  | 10293/12750 [33:36:12<7:52:10, 11.53s/it] 81%|████████  | 10294/12750 [33:36:23<7:52:27, 11.54s/it] 81%|████████  | 10295/12750 [33:36:35<7:51:59, 11.54s/it] 81%|████████  | 10296/12750 [33:36:47<7:51:54, 11.54s/it] 81%|████████  | 10297/12750 [33:36:58<7:51:34, 11.53s/it] 81%|████████  | 10298/12750 [33:37:10<7:51:25, 11.54s/it] 81%|████████  | 10299/12750 [33:37:29<9:27:28, 13.89s/it] 81%|████████  | 10300/12750 [33:37:41<8:58:21, 13.18s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120294.12lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104653.24lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10300
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10300/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10300/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10300/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10275] due to args.save_total_limit
 81%|████████  | 10301/12750 [33:37:52<8:41:33, 12.78s/it] 81%|████████  | 10302/12750 [33:38:04<8:25:37, 12.39s/it] 81%|████████  | 10303/12750 [33:38:15<8:14:59, 12.14s/it] 81%|████████  | 10304/12750 [33:38:27<8:06:54, 11.94s/it] 81%|████████  | 10305/12750 [33:38:38<8:01:22, 11.81s/it] 81%|████████  | 10306/12750 [33:38:50<7:57:18, 11.72s/it] 81%|████████  | 10307/12750 [33:39:01<7:54:46, 11.66s/it] 81%|████████  | 10308/12750 [33:39:13<7:52:39, 11.61s/it] 81%|████████  | 10309/12750 [33:39:24<7:51:08, 11.58s/it] 81%|████████  | 10310/12750 [33:39:36<7:50:15, 11.56s/it] 81%|████████  | 10311/12750 [33:39:47<7:49:27, 11.55s/it] 81%|████████  | 10312/12750 [33:39:59<7:49:15, 11.55s/it] 81%|████████  | 10313/12750 [33:40:11<7:48:50, 11.54s/it] 81%|████████  | 10314/12750 [33:40:22<7:48:37, 11.54s/it] 81%|████████  | 10315/12750 [33:40:34<7:48:35, 11.55s/it] 81%|████████  | 10316/12750 [33:40:45<7:48:36, 11.55s/it] 81%|████████  | 10317/12750 [33:40:57<7:48:34, 11.56s/it] 81%|████████  | 10318/12750 [33:41:08<7:48:19, 11.55s/it] 81%|████████  | 10319/12750 [33:41:20<7:47:59, 11.55s/it] 81%|████████  | 10320/12750 [33:41:31<7:47:42, 11.55s/it] 81%|████████  | 10321/12750 [33:41:43<7:47:15, 11.54s/it] 81%|████████  | 10322/12750 [33:41:54<7:46:51, 11.54s/it] 81%|████████  | 10323/12750 [33:42:06<7:46:25, 11.53s/it] 81%|████████  | 10324/12750 [33:42:17<7:45:47, 11.52s/it] 81%|████████  | 10325/12750 [33:42:29<7:45:31, 11.52s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120355.36lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104591.38lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10325
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10325/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10325/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10325/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10300] due to args.save_total_limit
 81%|████████  | 10326/12750 [33:42:41<7:48:41, 11.60s/it] 81%|████████  | 10327/12750 [33:42:52<7:47:03, 11.57s/it] 81%|████████  | 10328/12750 [33:43:04<7:45:45, 11.54s/it] 81%|████████  | 10329/12750 [33:43:15<7:44:54, 11.52s/it] 81%|████████  | 10330/12750 [33:43:27<7:44:08, 11.51s/it] 81%|████████  | 10331/12750 [33:43:46<9:18:28, 13.85s/it] 81%|████████  | 10332/12750 [33:43:57<8:49:25, 13.14s/it] 81%|████████  | 10333/12750 [33:44:09<8:29:16, 12.64s/it] 81%|████████  | 10334/12750 [33:44:20<8:15:06, 12.30s/it] 81%|████████  | 10335/12750 [33:44:32<8:05:26, 12.06s/it] 81%|████████  | 10336/12750 [33:44:43<7:58:36, 11.90s/it] 81%|████████  | 10337/12750 [33:44:55<7:53:43, 11.78s/it] 81%|████████  | 10338/12750 [33:45:06<7:50:28, 11.70s/it] 81%|████████  | 10339/12750 [33:45:18<7:47:46, 11.64s/it] 81%|████████  | 10340/12750 [33:45:29<7:45:35, 11.59s/it] 81%|████████  | 10341/12750 [33:45:41<7:44:11, 11.56s/it] 81%|████████  | 10342/12750 [33:45:52<7:43:15, 11.54s/it] 81%|████████  | 10343/12750 [33:46:04<7:42:18, 11.52s/it] 81%|████████  | 10344/12750 [33:46:15<7:41:54, 11.52s/it] 81%|████████  | 10345/12750 [33:46:27<7:41:29, 11.51s/it] 81%|████████  | 10346/12750 [33:46:38<7:41:08, 11.51s/it] 81%|████████  | 10347/12750 [33:46:50<7:40:48, 11.51s/it] 81%|████████  | 10348/12750 [33:47:01<7:41:00, 11.52s/it] 81%|████████  | 10349/12750 [33:47:13<7:40:53, 11.52s/it] 81%|████████  | 10350/12750 [33:47:25<7:40:34, 11.51s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120320.32lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104760.89lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10350
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10350/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10350/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10350/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10325] due to args.save_total_limit
 81%|████████  | 10351/12750 [33:47:36<7:43:42, 11.60s/it] 81%|████████  | 10352/12750 [33:47:48<7:42:13, 11.57s/it] 81%|████████  | 10353/12750 [33:47:59<7:41:02, 11.54s/it] 81%|████████  | 10354/12750 [33:48:11<7:40:22, 11.53s/it] 81%|████████  | 10355/12750 [33:48:22<7:39:40, 11.52s/it] 81%|████████  | 10356/12750 [33:48:34<7:39:02, 11.50s/it] 81%|████████  | 10357/12750 [33:48:45<7:38:40, 11.50s/it] 81%|████████  | 10358/12750 [33:48:57<7:39:15, 11.52s/it] 81%|████████  | 10359/12750 [33:49:08<7:39:04, 11.52s/it] 81%|████████▏ | 10360/12750 [33:49:20<7:38:11, 11.50s/it] 81%|████████▏ | 10361/12750 [33:49:31<7:38:07, 11.51s/it] 81%|████████▏ | 10362/12750 [33:49:43<7:37:22, 11.49s/it] 81%|████████▏ | 10363/12750 [33:50:02<9:10:23, 13.83s/it] 81%|████████▏ | 10364/12750 [33:50:14<8:42:18, 13.13s/it] 81%|████████▏ | 10365/12750 [33:50:25<8:22:32, 12.64s/it] 81%|████████▏ | 10366/12750 [33:50:37<8:08:46, 12.30s/it] 81%|████████▏ | 10367/12750 [33:50:48<7:59:03, 12.06s/it] 81%|████████▏ | 10368/12750 [33:51:00<7:52:20, 11.90s/it] 81%|████████▏ | 10369/12750 [33:51:11<7:47:12, 11.77s/it] 81%|████████▏ | 10370/12750 [33:51:23<7:43:53, 11.69s/it] 81%|████████▏ | 10371/12750 [33:51:34<7:41:16, 11.63s/it] 81%|████████▏ | 10372/12750 [33:51:46<7:39:33, 11.60s/it] 81%|████████▏ | 10373/12750 [33:51:57<7:38:19, 11.57s/it] 81%|████████▏ | 10374/12750 [33:52:09<7:37:23, 11.55s/it] 81%|████████▏ | 10375/12750 [33:52:20<7:36:42, 11.54s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120428.06lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104580.56lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10375
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10375/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10375/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10375/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10350] due to args.save_total_limit
 81%|████████▏ | 10376/12750 [33:52:32<7:39:29, 11.61s/it] 81%|████████▏ | 10377/12750 [33:52:43<7:37:41, 11.57s/it] 81%|████████▏ | 10378/12750 [33:52:55<7:36:07, 11.54s/it] 81%|████████▏ | 10379/12750 [33:53:06<7:35:18, 11.52s/it] 81%|████████▏ | 10380/12750 [33:53:18<7:34:18, 11.50s/it] 81%|████████▏ | 10381/12750 [33:53:29<7:33:50, 11.49s/it] 81%|████████▏ | 10382/12750 [33:53:41<7:33:19, 11.49s/it] 81%|████████▏ | 10383/12750 [33:53:52<7:33:01, 11.48s/it] 81%|████████▏ | 10384/12750 [33:54:04<7:32:49, 11.48s/it] 81%|████████▏ | 10385/12750 [33:54:15<7:32:40, 11.48s/it] 81%|████████▏ | 10386/12750 [33:54:27<7:32:32, 11.49s/it] 81%|████████▏ | 10387/12750 [33:54:38<7:32:22, 11.49s/it] 81%|████████▏ | 10388/12750 [33:54:50<7:32:09, 11.49s/it] 81%|████████▏ | 10389/12750 [33:55:01<7:31:58, 11.49s/it] 81%|████████▏ | 10390/12750 [33:55:13<7:31:49, 11.49s/it] 81%|████████▏ | 10391/12750 [33:55:24<7:31:32, 11.48s/it] 82%|████████▏ | 10392/12750 [33:55:36<7:31:02, 11.48s/it] 82%|████████▏ | 10393/12750 [33:55:47<7:31:32, 11.49s/it] 82%|████████▏ | 10394/12750 [33:55:59<7:32:09, 11.51s/it] 82%|████████▏ | 10395/12750 [33:56:18<9:05:57, 13.91s/it] 82%|████████▏ | 10396/12750 [33:56:30<8:38:08, 13.21s/it] 82%|████████▏ | 10397/12750 [33:56:41<8:18:44, 12.72s/it] 82%|████████▏ | 10398/12750 [33:56:53<8:05:03, 12.37s/it] 82%|████████▏ | 10399/12750 [33:57:04<7:55:45, 12.14s/it] 82%|████████▏ | 10400/12750 [33:57:16<7:49:03, 11.98s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120305.37lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104685.45lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10400
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10400/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10400/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10400/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10375] due to args.save_total_limit
 82%|████████▏ | 10401/12750 [33:57:28<7:47:30, 11.94s/it] 82%|████████▏ | 10402/12750 [33:57:39<7:42:53, 11.83s/it] 82%|████████▏ | 10403/12750 [33:57:51<7:39:18, 11.74s/it] 82%|████████▏ | 10404/12750 [33:58:03<7:37:11, 11.69s/it] 82%|████████▏ | 10405/12750 [33:58:14<7:35:45, 11.66s/it] 82%|████████▏ | 10406/12750 [33:58:26<7:34:23, 11.63s/it] 82%|████████▏ | 10407/12750 [33:58:37<7:33:05, 11.60s/it] 82%|████████▏ | 10408/12750 [33:58:49<7:33:03, 11.61s/it] 82%|████████▏ | 10409/12750 [33:59:00<7:32:31, 11.60s/it] 82%|████████▏ | 10410/12750 [33:59:12<7:31:49, 11.59s/it] 82%|████████▏ | 10411/12750 [33:59:24<7:31:18, 11.58s/it] 82%|████████▏ | 10412/12750 [33:59:35<7:30:43, 11.57s/it] 82%|████████▏ | 10413/12750 [33:59:47<7:30:21, 11.56s/it] 82%|████████▏ | 10414/12750 [33:59:58<7:30:19, 11.57s/it] 82%|████████▏ | 10415/12750 [34:00:10<7:29:44, 11.56s/it] 82%|████████▏ | 10416/12750 [34:00:21<7:29:33, 11.56s/it] 82%|████████▏ | 10417/12750 [34:00:33<7:29:38, 11.56s/it] 82%|████████▏ | 10418/12750 [34:00:44<7:29:26, 11.56s/it] 82%|████████▏ | 10419/12750 [34:00:56<7:28:43, 11.55s/it] 82%|████████▏ | 10420/12750 [34:01:08<7:28:40, 11.55s/it] 82%|████████▏ | 10421/12750 [34:01:19<7:28:49, 11.56s/it] 82%|████████▏ | 10422/12750 [34:01:31<7:28:56, 11.57s/it] 82%|████████▏ | 10423/12750 [34:01:42<7:28:52, 11.57s/it] 82%|████████▏ | 10424/12750 [34:01:54<7:28:44, 11.58s/it] 82%|████████▏ | 10425/12750 [34:02:05<7:28:26, 11.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120343.85lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104688.45lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10425
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10425/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10425/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10425/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10400] due to args.save_total_limit
 82%|████████▏ | 10426/12750 [34:02:17<7:31:28, 11.66s/it] 82%|████████▏ | 10427/12750 [34:02:37<9:01:04, 13.98s/it] 82%|████████▏ | 10428/12750 [34:02:48<8:32:40, 13.25s/it] 82%|████████▏ | 10429/12750 [34:03:00<8:12:59, 12.74s/it] 82%|████████▏ | 10430/12750 [34:03:11<7:58:57, 12.39s/it] 82%|████████▏ | 10431/12750 [34:03:23<7:49:27, 12.15s/it] 82%|████████▏ | 10432/12750 [34:03:34<7:42:23, 11.97s/it] 82%|████████▏ | 10433/12750 [34:03:46<7:37:50, 11.86s/it] 82%|████████▏ | 10434/12750 [34:03:58<7:35:02, 11.79s/it] 82%|████████▏ | 10435/12750 [34:04:09<7:32:05, 11.72s/it] 82%|████████▏ | 10436/12750 [34:04:21<7:30:18, 11.68s/it] 82%|████████▏ | 10437/12750 [34:04:32<7:28:58, 11.65s/it] 82%|████████▏ | 10438/12750 [34:04:44<7:28:01, 11.63s/it] 82%|████████▏ | 10439/12750 [34:04:56<7:27:17, 11.61s/it] 82%|████████▏ | 10440/12750 [34:05:07<7:27:00, 11.61s/it] 82%|████████▏ | 10441/12750 [34:05:19<7:26:32, 11.60s/it] 82%|████████▏ | 10442/12750 [34:05:30<7:25:54, 11.59s/it] 82%|████████▏ | 10443/12750 [34:05:42<7:25:28, 11.59s/it] 82%|████████▏ | 10444/12750 [34:05:54<7:25:39, 11.60s/it] 82%|████████▏ | 10445/12750 [34:06:05<7:24:57, 11.58s/it] 82%|████████▏ | 10446/12750 [34:06:17<7:24:31, 11.58s/it] 82%|████████▏ | 10447/12750 [34:06:28<7:23:48, 11.56s/it] 82%|████████▏ | 10448/12750 [34:06:40<7:24:29, 11.59s/it] 82%|████████▏ | 10449/12750 [34:06:51<7:24:02, 11.58s/it] 82%|████████▏ | 10450/12750 [34:07:03<7:23:38, 11.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120391.70lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104579.69lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10450
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10450/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10450/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10450/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10425] due to args.save_total_limit
 82%|████████▏ | 10451/12750 [34:07:15<7:26:32, 11.65s/it] 82%|████████▏ | 10452/12750 [34:07:26<7:25:02, 11.62s/it] 82%|████████▏ | 10453/12750 [34:07:38<7:23:57, 11.60s/it] 82%|████████▏ | 10454/12750 [34:07:49<7:23:18, 11.58s/it] 82%|████████▏ | 10455/12750 [34:08:01<7:22:09, 11.56s/it] 82%|████████▏ | 10456/12750 [34:08:12<7:21:37, 11.55s/it] 82%|████████▏ | 10457/12750 [34:08:24<7:21:20, 11.55s/it] 82%|████████▏ | 10458/12750 [34:08:36<7:21:03, 11.55s/it] 82%|████████▏ | 10459/12750 [34:08:54<8:43:23, 13.71s/it] 82%|████████▏ | 10460/12750 [34:09:06<8:18:18, 13.06s/it] 82%|████████▏ | 10461/12750 [34:09:17<8:00:56, 12.61s/it] 82%|████████▏ | 10462/12750 [34:09:29<7:50:24, 12.34s/it] 82%|████████▏ | 10463/12750 [34:09:41<7:41:57, 12.12s/it] 82%|████████▏ | 10464/12750 [34:09:52<7:35:13, 11.95s/it] 82%|████████▏ | 10465/12750 [34:10:04<7:30:27, 11.83s/it] 82%|████████▏ | 10466/12750 [34:10:15<7:27:01, 11.74s/it] 82%|████████▏ | 10467/12750 [34:10:27<7:24:37, 11.69s/it] 82%|████████▏ | 10468/12750 [34:10:38<7:23:19, 11.66s/it] 82%|████████▏ | 10469/12750 [34:10:50<7:22:31, 11.64s/it] 82%|████████▏ | 10470/12750 [34:11:02<7:21:29, 11.62s/it] 82%|████████▏ | 10471/12750 [34:11:13<7:20:41, 11.60s/it] 82%|████████▏ | 10472/12750 [34:11:25<7:20:09, 11.59s/it] 82%|████████▏ | 10473/12750 [34:11:36<7:19:33, 11.58s/it] 82%|████████▏ | 10474/12750 [34:11:48<7:19:09, 11.58s/it] 82%|████████▏ | 10475/12750 [34:11:59<7:18:49, 11.57s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120286.07lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104646.95lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10475
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10475/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10475/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10475/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10450] due to args.save_total_limit
 82%|████████▏ | 10476/12750 [34:12:11<7:21:51, 11.66s/it] 82%|████████▏ | 10477/12750 [34:12:23<7:20:18, 11.62s/it] 82%|████████▏ | 10478/12750 [34:12:34<7:19:29, 11.61s/it] 82%|████████▏ | 10479/12750 [34:12:46<7:18:38, 11.59s/it] 82%|████████▏ | 10480/12750 [34:12:58<7:18:16, 11.58s/it] 82%|████████▏ | 10481/12750 [34:13:09<7:18:02, 11.58s/it] 82%|████████▏ | 10482/12750 [34:13:21<7:17:42, 11.58s/it] 82%|████████▏ | 10483/12750 [34:13:32<7:17:45, 11.59s/it] 82%|████████▏ | 10484/12750 [34:13:44<7:17:18, 11.58s/it] 82%|████████▏ | 10485/12750 [34:13:55<7:16:46, 11.57s/it] 82%|████████▏ | 10486/12750 [34:14:07<7:16:29, 11.57s/it] 82%|████████▏ | 10487/12750 [34:14:19<7:15:50, 11.56s/it] 82%|████████▏ | 10488/12750 [34:14:30<7:15:36, 11.55s/it] 82%|████████▏ | 10489/12750 [34:14:42<7:15:39, 11.56s/it] 82%|████████▏ | 10490/12750 [34:14:53<7:15:35, 11.56s/it] 82%|████████▏ | 10491/12750 [34:15:05<7:15:26, 11.57s/it] 82%|████████▏ | 10492/12750 [34:15:24<8:42:32, 13.89s/it] 82%|████████▏ | 10493/12750 [34:15:36<8:16:13, 13.19s/it] 82%|████████▏ | 10494/12750 [34:15:47<7:57:25, 12.70s/it] 82%|████████▏ | 10495/12750 [34:15:59<7:44:40, 12.36s/it] 82%|████████▏ | 10496/12750 [34:16:10<7:35:43, 12.13s/it] 82%|████████▏ | 10497/12750 [34:16:22<7:29:01, 11.96s/it] 82%|████████▏ | 10498/12750 [34:16:34<7:24:43, 11.85s/it] 82%|████████▏ | 10499/12750 [34:16:45<7:21:29, 11.77s/it] 82%|████████▏ | 10500/12750 [34:16:57<7:18:57, 11.71s/it]                                                           82%|████████▏ | 10500/12750 [34:16:57<7:18:57, 11.71s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120370.45lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104551.40lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10500
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10500/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10500/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10500/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10475] due to args.save_total_limit
 82%|████████▏ | 10501/12750 [34:17:09<7:20:39, 11.76s/it] 82%|████████▏ | 10502/12750 [34:17:20<7:18:19, 11.70s/it] 82%|████████▏ | 10503/12750 [34:17:32<7:16:41, 11.66s/it] 82%|████████▏ | 10504/12750 [34:17:43<7:15:27, 11.63s/it] 82%|████████▏ | 10505/12750 [34:17:55<7:14:24, 11.61s/it] 82%|████████▏ | 10506/12750 [34:18:06<7:13:24, 11.59s/it] 82%|████████▏ | 10507/12750 [34:18:18<7:12:44, 11.58s/it] 82%|████████▏ | 10508/12750 [34:18:29<7:12:34, 11.58s/it] 82%|████████▏ | 10509/12750 [34:18:41<7:12:28, 11.58s/it] 82%|████████▏ | 10510/12750 [34:18:53<7:12:14, 11.58s/it] 82%|████████▏ | 10511/12750 [34:19:04<7:11:57, 11.58s/it] 82%|████████▏ | 10512/12750 [34:19:16<7:11:50, 11.58s/it] 82%|████████▏ | 10513/12750 [34:19:27<7:11:43, 11.58s/it] 82%|████████▏ | 10514/12750 [34:19:39<7:11:29, 11.58s/it] 82%|████████▏ | 10515/12750 [34:19:50<7:11:14, 11.58s/it] 82%|████████▏ | 10516/12750 [34:20:02<7:11:11, 11.58s/it] 82%|████████▏ | 10517/12750 [34:20:14<7:10:43, 11.57s/it] 82%|████████▏ | 10518/12750 [34:20:25<7:10:24, 11.57s/it] 83%|████████▎ | 10519/12750 [34:20:37<7:10:18, 11.57s/it] 83%|████████▎ | 10520/12750 [34:20:48<7:09:11, 11.55s/it] 83%|████████▎ | 10521/12750 [34:21:00<7:08:25, 11.53s/it] 83%|████████▎ | 10522/12750 [34:21:11<7:07:47, 11.52s/it] 83%|████████▎ | 10523/12750 [34:21:23<7:07:12, 11.51s/it] 83%|████████▎ | 10524/12750 [34:21:42<8:33:04, 13.83s/it] 83%|████████▎ | 10525/12750 [34:21:53<8:06:37, 13.12s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120418.84lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104686.90lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10525
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10525/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10525/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10525/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10500] due to args.save_total_limit
 83%|████████▎ | 10526/12750 [34:22:05<7:52:24, 12.74s/it] 83%|████████▎ | 10527/12750 [34:22:17<7:38:12, 12.37s/it] 83%|████████▎ | 10528/12750 [34:22:28<7:28:23, 12.11s/it] 83%|████████▎ | 10529/12750 [34:22:40<7:21:24, 11.92s/it] 83%|████████▎ | 10530/12750 [34:22:51<7:16:35, 11.80s/it] 83%|████████▎ | 10531/12750 [34:23:03<7:12:17, 11.69s/it] 83%|████████▎ | 10532/12750 [34:23:14<7:10:01, 11.63s/it] 83%|████████▎ | 10533/12750 [34:23:26<7:08:16, 11.59s/it] 83%|████████▎ | 10534/12750 [34:23:37<7:06:36, 11.55s/it] 83%|████████▎ | 10535/12750 [34:23:49<7:05:28, 11.53s/it] 83%|████████▎ | 10536/12750 [34:24:00<7:04:35, 11.51s/it] 83%|████████▎ | 10537/12750 [34:24:12<7:03:45, 11.49s/it] 83%|████████▎ | 10538/12750 [34:24:23<7:03:11, 11.48s/it] 83%|████████▎ | 10539/12750 [34:24:35<7:03:11, 11.48s/it] 83%|████████▎ | 10540/12750 [34:24:46<7:02:58, 11.48s/it] 83%|████████▎ | 10541/12750 [34:24:58<7:04:04, 11.52s/it] 83%|████████▎ | 10542/12750 [34:25:09<7:03:25, 11.51s/it] 83%|████████▎ | 10543/12750 [34:25:21<7:03:17, 11.51s/it] 83%|████████▎ | 10544/12750 [34:25:32<7:03:08, 11.51s/it] 83%|████████▎ | 10545/12750 [34:25:44<7:02:35, 11.50s/it] 83%|████████▎ | 10546/12750 [34:25:55<7:02:17, 11.50s/it] 83%|████████▎ | 10547/12750 [34:26:07<7:01:44, 11.49s/it] 83%|████████▎ | 10548/12750 [34:26:18<7:01:31, 11.49s/it] 83%|████████▎ | 10549/12750 [34:26:29<7:00:52, 11.47s/it] 83%|████████▎ | 10550/12750 [34:26:41<7:00:49, 11.48s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120355.10lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104682.64lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10550
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10550/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10550/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10550/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10525] due to args.save_total_limit
 83%|████████▎ | 10551/12750 [34:26:53<7:03:42, 11.56s/it] 83%|████████▎ | 10552/12750 [34:27:04<7:02:23, 11.53s/it] 83%|████████▎ | 10553/12750 [34:27:16<7:01:18, 11.51s/it] 83%|████████▎ | 10554/12750 [34:27:27<7:00:36, 11.49s/it] 83%|████████▎ | 10555/12750 [34:27:39<6:59:46, 11.47s/it] 83%|████████▎ | 10556/12750 [34:27:58<8:24:43, 13.80s/it] 83%|████████▎ | 10557/12750 [34:28:09<7:59:15, 13.11s/it] 83%|████████▎ | 10558/12750 [34:28:21<7:41:00, 12.62s/it] 83%|████████▎ | 10559/12750 [34:28:32<7:28:16, 12.28s/it] 83%|████████▎ | 10560/12750 [34:28:44<7:21:21, 12.09s/it] 83%|████████▎ | 10561/12750 [34:28:55<7:14:37, 11.91s/it] 83%|████████▎ | 10562/12750 [34:29:07<7:09:31, 11.78s/it] 83%|████████▎ | 10563/12750 [34:29:18<7:05:48, 11.68s/it] 83%|████████▎ | 10564/12750 [34:29:30<7:03:13, 11.62s/it] 83%|████████▎ | 10565/12750 [34:29:41<7:01:18, 11.57s/it] 83%|████████▎ | 10566/12750 [34:29:53<7:00:02, 11.54s/it] 83%|████████▎ | 10567/12750 [34:30:04<6:58:35, 11.50s/it] 83%|████████▎ | 10568/12750 [34:30:16<6:57:56, 11.49s/it] 83%|████████▎ | 10569/12750 [34:30:27<6:57:31, 11.49s/it] 83%|████████▎ | 10570/12750 [34:30:38<6:57:05, 11.48s/it] 83%|████████▎ | 10571/12750 [34:30:50<6:57:01, 11.48s/it] 83%|████████▎ | 10572/12750 [34:31:01<6:56:26, 11.47s/it] 83%|████████▎ | 10573/12750 [34:31:13<6:56:16, 11.47s/it] 83%|████████▎ | 10574/12750 [34:31:24<6:56:08, 11.47s/it] 83%|████████▎ | 10575/12750 [34:31:36<6:55:49, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120370.58lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104572.93lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10575
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10575/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10575/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10575/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10550] due to args.save_total_limit
 83%|████████▎ | 10576/12750 [34:31:48<6:58:39, 11.55s/it] 83%|████████▎ | 10577/12750 [34:31:59<6:57:16, 11.52s/it] 83%|████████▎ | 10578/12750 [34:32:11<6:56:44, 11.51s/it] 83%|████████▎ | 10579/12750 [34:32:22<6:55:55, 11.49s/it] 83%|████████▎ | 10580/12750 [34:32:33<6:55:18, 11.48s/it] 83%|████████▎ | 10581/12750 [34:32:45<6:54:46, 11.47s/it] 83%|████████▎ | 10582/12750 [34:32:56<6:54:41, 11.48s/it] 83%|████████▎ | 10583/12750 [34:33:08<6:54:23, 11.47s/it] 83%|████████▎ | 10584/12750 [34:33:19<6:54:17, 11.48s/it] 83%|████████▎ | 10585/12750 [34:33:31<6:53:36, 11.46s/it] 83%|████████▎ | 10586/12750 [34:33:42<6:53:40, 11.47s/it] 83%|████████▎ | 10587/12750 [34:33:54<6:53:26, 11.47s/it] 83%|████████▎ | 10588/12750 [34:34:13<8:17:30, 13.81s/it] 83%|████████▎ | 10589/12750 [34:34:24<7:51:49, 13.10s/it] 83%|████████▎ | 10590/12750 [34:34:36<7:33:40, 12.60s/it] 83%|████████▎ | 10591/12750 [34:34:47<7:21:00, 12.26s/it] 83%|████████▎ | 10592/12750 [34:34:59<7:12:31, 12.03s/it] 83%|████████▎ | 10593/12750 [34:35:10<7:06:23, 11.86s/it] 83%|████████▎ | 10594/12750 [34:35:22<7:01:47, 11.74s/it] 83%|████████▎ | 10595/12750 [34:35:33<6:58:33, 11.65s/it] 83%|████████▎ | 10596/12750 [34:35:45<6:56:17, 11.60s/it] 83%|████████▎ | 10597/12750 [34:35:56<6:54:35, 11.55s/it] 83%|████████▎ | 10598/12750 [34:36:08<6:53:26, 11.53s/it] 83%|████████▎ | 10599/12750 [34:36:19<6:52:24, 11.50s/it] 83%|████████▎ | 10600/12750 [34:36:30<6:51:54, 11.49s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120096.13lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104510.20lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10600
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10600/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10600/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10600/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10575] due to args.save_total_limit
 83%|████████▎ | 10601/12750 [34:36:42<6:54:52, 11.58s/it] 83%|████████▎ | 10602/12750 [34:36:54<6:53:11, 11.54s/it] 83%|████████▎ | 10603/12750 [34:37:05<6:52:08, 11.52s/it] 83%|████████▎ | 10604/12750 [34:37:17<6:51:19, 11.50s/it] 83%|████████▎ | 10605/12750 [34:37:28<6:50:29, 11.48s/it] 83%|████████▎ | 10606/12750 [34:37:40<6:50:07, 11.48s/it] 83%|████████▎ | 10607/12750 [34:37:51<6:49:43, 11.47s/it] 83%|████████▎ | 10608/12750 [34:38:02<6:49:21, 11.47s/it] 83%|████████▎ | 10609/12750 [34:38:14<6:49:05, 11.46s/it] 83%|████████▎ | 10610/12750 [34:38:25<6:49:03, 11.47s/it] 83%|████████▎ | 10611/12750 [34:38:37<6:49:01, 11.47s/it] 83%|████████▎ | 10612/12750 [34:38:48<6:48:34, 11.47s/it] 83%|████████▎ | 10613/12750 [34:39:00<6:48:30, 11.47s/it] 83%|████████▎ | 10614/12750 [34:39:11<6:48:14, 11.47s/it] 83%|████████▎ | 10615/12750 [34:39:23<6:48:06, 11.47s/it] 83%|████████▎ | 10616/12750 [34:39:34<6:47:45, 11.46s/it] 83%|████████▎ | 10617/12750 [34:39:46<6:47:59, 11.48s/it] 83%|████████▎ | 10618/12750 [34:39:57<6:47:56, 11.48s/it] 83%|████████▎ | 10619/12750 [34:40:09<6:47:22, 11.47s/it] 83%|████████▎ | 10620/12750 [34:40:29<8:23:49, 14.19s/it] 83%|████████▎ | 10621/12750 [34:40:41<7:54:40, 13.38s/it] 83%|████████▎ | 10622/12750 [34:40:52<7:34:12, 12.81s/it] 83%|████████▎ | 10623/12750 [34:41:04<7:19:31, 12.40s/it] 83%|████████▎ | 10624/12750 [34:41:15<7:09:24, 12.12s/it] 83%|████████▎ | 10625/12750 [34:41:27<7:02:22, 11.93s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120509.18lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104815.19lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10625
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10625/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10625/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10625/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10600] due to args.save_total_limit
 83%|████████▎ | 10626/12750 [34:41:38<7:00:45, 11.89s/it] 83%|████████▎ | 10627/12750 [34:41:50<6:56:04, 11.76s/it] 83%|████████▎ | 10628/12750 [34:42:01<6:52:51, 11.67s/it] 83%|████████▎ | 10629/12750 [34:42:13<6:50:28, 11.61s/it] 83%|████████▎ | 10630/12750 [34:42:24<6:48:41, 11.57s/it] 83%|████████▎ | 10631/12750 [34:42:36<6:47:30, 11.54s/it] 83%|████████▎ | 10632/12750 [34:42:47<6:46:40, 11.52s/it] 83%|████████▎ | 10633/12750 [34:42:59<6:46:01, 11.51s/it] 83%|████████▎ | 10634/12750 [34:43:10<6:45:18, 11.49s/it] 83%|████████▎ | 10635/12750 [34:43:22<6:45:10, 11.49s/it] 83%|████████▎ | 10636/12750 [34:43:33<6:44:39, 11.49s/it] 83%|████████▎ | 10637/12750 [34:43:44<6:44:16, 11.48s/it] 83%|████████▎ | 10638/12750 [34:43:56<6:44:15, 11.48s/it] 83%|████████▎ | 10639/12750 [34:44:07<6:43:48, 11.48s/it] 83%|████████▎ | 10640/12750 [34:44:19<6:43:35, 11.48s/it] 83%|████████▎ | 10641/12750 [34:44:30<6:43:29, 11.48s/it] 83%|████████▎ | 10642/12750 [34:44:42<6:43:13, 11.48s/it] 83%|████████▎ | 10643/12750 [34:44:53<6:43:09, 11.48s/it] 83%|████████▎ | 10644/12750 [34:45:05<6:42:44, 11.47s/it] 83%|████████▎ | 10645/12750 [34:45:16<6:42:41, 11.48s/it] 83%|████████▎ | 10646/12750 [34:45:28<6:42:02, 11.47s/it] 84%|████████▎ | 10647/12750 [34:45:39<6:41:58, 11.47s/it] 84%|████████▎ | 10648/12750 [34:45:51<6:41:51, 11.47s/it] 84%|████████▎ | 10649/12750 [34:46:02<6:41:30, 11.47s/it] 84%|████████▎ | 10650/12750 [34:46:14<6:41:26, 11.47s/it]
Generating Predictions:   0%|          | 0/27000 [00:00<?, ?lines/s][AGenerate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}


Generating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 120364.31lines/s][AGenerating Predictions: 100%|██████████| 27000/27000 [00:00<00:00, 104494.48lines/s]
Saving model checkpoint to final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10650
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10650/config.json
Configuration saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10650/generation_config.json
Model weights saved in final-anticlk-microGPT-2k-2223-eval-either-22-or-23/tmp-checkpoint-10650/pytorch_model.bin
Deleting older checkpoint [final-anticlk-microGPT-2k-2223-eval-either-22-or-23/checkpoint-10625] due to args.save_total_limit
 84%|████████▎ | 10651/12750 [34:46:25<6:44:26, 11.56s/it] 84%|████████▎ | 10652/12750 [34:46:44<7:58:00, 13.67s/it]slurmstepd: error: *** JOB 52507695 ON gpu-q-35 CANCELLED AT 2024-05-17T21:08:13 DUE TO TIME LIMIT ***
